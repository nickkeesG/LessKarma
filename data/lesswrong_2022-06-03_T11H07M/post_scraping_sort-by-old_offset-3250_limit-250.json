{"results": [{"createdAt": null, "postedAt": "2011-04-19T19:28:08.226Z", "modifiedAt": null, "url": null, "title": "Insufficiently Awesome", "slug": "insufficiently-awesome", "viewCount": null, "lastCommentedAt": "2020-11-17T13:49:44.541Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cayenne", "createdAt": "2010-12-27T22:47:02.994Z", "isAdmin": false, "displayName": "Cayenne"}, "userId": "xXoNkpxZ5i5TfDHK8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/knLZY52Yx9G23u3Ka/insufficiently-awesome", "pageUrlRelative": "/posts/knLZY52Yx9G23u3Ka/insufficiently-awesome", "linkUrl": "https://www.lesswrong.com/posts/knLZY52Yx9G23u3Ka/insufficiently-awesome", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Insufficiently%20Awesome&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInsufficiently%20Awesome%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FknLZY52Yx9G23u3Ka%2Finsufficiently-awesome%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Insufficiently%20Awesome%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FknLZY52Yx9G23u3Ka%2Finsufficiently-awesome", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FknLZY52Yx9G23u3Ka%2Finsufficiently-awesome", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 245, "htmlBody": "<p>Apologies for the wasted time spent reading and replying to this post. &nbsp;Please disregard it.</p>\n<p>&nbsp;</p>\n<p>I've been feeling non-awesome for a long time. &nbsp;I don't know if anyone else here feels the same way, but I'm going to assume that at least a few people do. &nbsp;I want to correct this horrible deficiency.</p>\n<p>We already have the LW meetups in a lot of places, monthly in some places and weekly in others. &nbsp;I've gone to a few, and they're interesting and I get to meet a lot of very smart people (and get intimidated by them)... but mostly all we've done is talk and sometimes go and eat at a&nbsp;restaurant. &nbsp;I want more than this!</p>\n<p>&nbsp;</p>\n<p>We already talk, we need an action-based meetup. &nbsp;I want to propose another kind of meetup, the Insufficiently Awesome meetup. &nbsp;It should aim to make us good at baseline things like fitness, social skills, strategy, and reflexes, and to make us very good at specialized awesome things like master-level chess/go/shogi, public speaking, various sports, dancing, making music, making art.</p>\n<p>I think this meetup should be daily, though not everyone would want to go every day. &nbsp;Nonetheless, we should have <em>something</em>&nbsp;happening every day that we're not spending talking. &nbsp;The goal shouldn't be just to be fit in different situations, but to instead become <em>totally awesome</em>.</p>\n<p>Is there anyone else that feels the same? &nbsp;If so, what things do you think we need to learn for the baseline, and what things should we get very good at?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "knLZY52Yx9G23u3Ka", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 41, "extendedScore": null, "score": 7e-05, "legacy": true, "legacyId": "6884", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 94, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T19:39:41.706Z", "modifiedAt": null, "url": null, "title": "Introduction to the Sequence Reruns", "slug": "introduction-to-the-sequence-reruns", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.125Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Unnamed", "createdAt": "2009-02-27T06:08:10.900Z", "isAdmin": false, "displayName": "Unnamed"}, "userId": "PdzQ73mN7S4SvRMhu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/m9PsRxu65FuL9c8xp/introduction-to-the-sequence-reruns", "pageUrlRelative": "/posts/m9PsRxu65FuL9c8xp/introduction-to-the-sequence-reruns", "linkUrl": "https://www.lesswrong.com/posts/m9PsRxu65FuL9c8xp/introduction-to-the-sequence-reruns", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Introduction%20to%20the%20Sequence%20Reruns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntroduction%20to%20the%20Sequence%20Reruns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm9PsRxu65FuL9c8xp%2Fintroduction-to-the-sequence-reruns%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Introduction%20to%20the%20Sequence%20Reruns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm9PsRxu65FuL9c8xp%2Fintroduction-to-the-sequence-reruns", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm9PsRxu65FuL9c8xp%2Fintroduction-to-the-sequence-reruns", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1541, "htmlBody": "<p><strong>BACKGROUND</strong><br /><br />The <a href=\"http://wiki.lesswrong.com/wiki/Sequences\">sequences</a> - hundreds of posts written by Eliezer Yudkowsky from 2006 through 2009 - contain the core material behind Less Wrong, including many ideas that are often treated as background knowledge in new posts. New LW members are encouraged to read the sequences and many LW regulars have expressed interest in rereading them, but even though the posts are sitting in the archives for anyone to read it takes <a href=\"/lw/f1/beware_trivial_inconveniences/\">another step</a> to actually read them.&nbsp; The sheer number of words can be overwhelming, and many people find that they never quite get around to delving in. To many people, reading new blog posts is fun but going through the sequences is work. And it can be hard to have lively discussions on years-old posts.<br /><br />As announced <a href=\"/r/discussion/lw/55t/new_less_wrong_feature_rerunning_the_sequences/\">here</a>, we are introducing the Rerunning the Sequences series to the discussion section as an attempt to make the sequences more accessible by making them more like new blog posts. We will be going through the sequence posts in order, one post per day, making posts that contain a link to the sequence post and a summary of it.&nbsp; If you're interested, follow along (the posts will all have [SEQ RERUN] in the title and will be easy to spot), take part in the discussion, and get involved in other ways described below.&nbsp; If you're not interested, you can ignore these discussion section posts (they all have [SEQ RERUN] in the title and will be easy to spot).<br /><br /><br /><strong>DETAILS</strong><br /><br />For our purposes, we're currently considering the sequences to consist of Eliezer's 702 posts (listed in order <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/All_articles\">here</a>) beginning with <a href=\"/lw/gn/the_martial_art_of_rationality/\">The Martial Art of Rationality</a>, ending with <a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a>, and excluding quotes threads.&nbsp; The list of posts has not been finalized yet - there are still some other posts to exclude (like purely administrative posts) and some more posts to add, perhaps including some posts not by Eliezer (like Robin Hanson's side of the <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">AI Foom Debate</a>). Each day, there will be a post in the discussion section which links to one of these posts and follows the standard template included below.&nbsp; We'll go through the posts in chronological order, one per day, beginning today (April 19, 2011) with <a href=\"/r/discussion/lw/5b6/seq_rerun_the_martial_art_of_rationality/\">The Martial Art of Rationality</a>. These posts will be clearly identified by the [SEQ RERUN] tag in the title, easy to find under the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns</a> tag, and easy to follow with a feed reader by subscribing to the <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> for the sequence_reruns tag.&nbsp; Hopefully, this will capture the feel of reading a blog, with a new post to read each day.<br /><br />Each post also serves as a focal point for discussion. Discussion should take place in the comments to the new post in the discussion section, not the original post, since this is a fresh discussion which is taking place a few years after the original post was made. This will also keep everything in the discussion section, so that the main page doesn't get flooded with comments on old posts.<br /><br />This is a community-driven effort, and in order for it to work people will need to get involved. Someone needs to make the sequence reruns post each day, and that role is open to anyone who will do it (just like with the open threads and quotes threads). If you're ever wondering where a day's sequence reruns post is, go ahead and make the post. There is a standard template to follow in order to make posting as simple as possible - it shouldn't take more than five minutes (especially after you've done it once).&nbsp; Instructions (along with the template to copy and paste) are included at the end of this post.&nbsp; If you have something that you'd like to say about the sequence post, you should put it in the comments to your post rather than in the post itself.<br /><br />Each sequence reruns post includes a summary of the post that it links to, which is taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>. But many of the posts don't have a summary written yet, and some of the others don't have a good summary yet. So another way to be involved is by writing summaries for the posts that need them and adding them to the LW wiki before we get to those posts. After a sequence reruns post has been made, if it is missing a summary or its summary isn't very good then you could write a new summary for it then and leave it in the comments so that the post can be edited. But it's better to get the summaries written ahead of time.<br /><br />Finally, there are other issues that can arise with the sequence reruns and ways to make it better.&nbsp; For instance: deciding precisely which posts to include (e.g., should we <a href=\"/r/discussion/lw/55t/new_less_wrong_feature_rerunning_the_sequences/3wot\">include all the posts</a> in the AI Foom Debate?). Things will run more smoothly if folks are involved in coming up with improvements, spotting issues ahead of time, and helping to make the decisions. Discussion about these kinds of issues, and other kinds of meta discussion about the Rerunning the Sequences series, should mostly take place in the comments to this post or in other meta posts, rather than in the comments to individual posts in the series. Discussion in the individual posts should be based on the linked sequence post, rather than on these kinds of meta issues.<br /><br /><br /><strong>POSTING INSTRUCTIONS</strong><br /><br />To make a post in the Rerunning the Sequences series, you will need to copy and paste a standard template (included below) and add links and information from the original sequence post, the previous Sequence Reruns post, and the LW wiki page which has summaries.&nbsp; There are 8 things to change in the template, which I've labeled 111111, 222222, &hellip;, 888888. <br /><br />1. Find the previous Sequence Reruns post and find the sequence post that is due for that day (which will generally be the next post listed <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/All_articles\">here</a>)<br /><br />2. Go to the LW wiki to find a summary of the sequence post (summaries arranged by year: <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">2006</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">2007</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">2008</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">2009</a>); if there are multiple summaries available choose the one that looks best<br /><br />3. Copy and paste the template below into a text document and make the 8 edits to the template:<br /><br />111111 the title of the sequence post (e.g., Why truth? And... )<br /><br />222222 the url of the sequence post (e.g., http://lesswrong.com/lw/go/why_truth_and/ )<br /><br />333333 the title of the sequence post, again (e.g., Why truth? And... )<br /><br />444444 the date when the sequence post was originally published (e.g., November 26, 2006 )<br /><br />555555 the lw wiki page where you found the summary (e.g., http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries )<br /><br />666666 the summary of the sequence post which you took from the lw wiki (e.g., You have an instrumental motive to care about the truth of your beliefs about anything you care about. )<br /><br />777777 the url of the previous Sequence Reruns post (e.g., )<br /><br />888888 the title of the previous sequence post (e.g., The Martial Art of Rationality )<br /><br />4. Click to create a new article<br /><br />5. Make the title: [SEQ RERUN] 111111<br /><br />6. Make the tags: sequence_reruns<br /><br />7. On the \"submit article\" page, click where it says \"HTML\" (edit HTML source) and paste the edited version of the template that you've created.&nbsp; Click \"update.\"<br /><br />8. Check and make sure your post looks okay. Does it have the appropriate title and tag? Have all of the strings of numbers been replaced? Was there any special formatting (like italics) in the summary which you need to add to the post?<br /><br />9. Make the post. If there is a \"Post to\" option set it to \"Less Wrong Discussion\" (if there is not, you're already in the discussion section and will automatically post there) and click \"Submit.\"<br /><br /><br /><br /><strong>TEMPLATE</strong><br /><br />Title: [SEQ RERUN] 111111<br /><br />Tags: sequence_reruns<br /><br />Today's post, &lt;a href=\"222222\"&gt;333333&lt;/a&gt; was originally published on 444444.&amp;nbsp; A summary (taken from the &lt;a href=\"555555\"&gt;LW wiki&lt;/a&gt;):&lt;/p&gt;<br /><br />&lt;blockquote&gt;666666&lt;/blockquote&gt;<br /><br />&lt;p&gt;&lt;br /&gt;Discuss the post here (rather than in the comments to the original post).&lt;br /&gt;&lt;br /&gt;&lt;em&gt;This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.&amp;nbsp; The previous post was &lt;a href=\"777777\"&gt;888888&lt;/a&gt;, and you can use the &lt;a href=\"/r/discussion/tag/sequence_reruns/\"&gt;sequence_reruns tag&lt;/a&gt; or &lt;a href=\"/r/discussion/tag/sequence_reruns/.rss\"&gt;rss feed&lt;/a&gt; to follow the rest of the series.&lt;br /&gt;&lt;br /&gt;Sequence reruns are a community-driven effort.&amp;nbsp; You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go &lt;a href=\"http://lesswrong.com/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\"&gt;here&lt;/a&gt; for more details, or to have meta discussions about the Rerunning the Sequences series.&lt;/em&gt;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "m9PsRxu65FuL9c8xp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 7.043716978921627e-07, "legacy": true, "legacyId": "6868", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["reitXJgJXFzKpdKyd", "7XPZQddvD2RBEMdQq", "teaxCFgtmCQ3E9fy8", "LqjKP255fPRY7aMzw", "vWM9fBWacWzjzPGQR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T19:41:19.699Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Martial Art of Rationality", "slug": "seq-rerun-the-martial-art-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:34.932Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Unnamed", "createdAt": "2009-02-27T06:08:10.900Z", "isAdmin": false, "displayName": "Unnamed"}, "userId": "PdzQ73mN7S4SvRMhu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vWM9fBWacWzjzPGQR/seq-rerun-the-martial-art-of-rationality", "pageUrlRelative": "/posts/vWM9fBWacWzjzPGQR/seq-rerun-the-martial-art-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/vWM9fBWacWzjzPGQR/seq-rerun-the-martial-art-of-rationality", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Martial%20Art%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Martial%20Art%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvWM9fBWacWzjzPGQR%2Fseq-rerun-the-martial-art-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Martial%20Art%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvWM9fBWacWzjzPGQR%2Fseq-rerun-the-martial-art-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvWM9fBWacWzjzPGQR%2Fseq-rerun-the-martial-art-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 237, "htmlBody": "<p>Today's post, <a href=\"/lw/gn/the_martial_art_of_rationality/\">The Martial Art of Rationality</a> was originally published on November 22, 2006.&nbsp; A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Rationality is the martial art of the mind, building on universally human machinery. But developing rationality is more difficult than developing physical martial arts. One reason is because rationality skill is harder to verify. In recent decades, scientific fields like heuristics and biases, Bayesian probability theory, evolutionary psychology, and social psychology have given us a theoretical body of work on which to build the martial art of rationality. It remains to develop and especially to communicate techniques that apply this theoretical work introspectively to our own minds.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.&nbsp; It is the first post in the series; the introductory post was <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.&nbsp; You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vWM9fBWacWzjzPGQR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 7.043721593894063e-07, "legacy": true, "legacyId": "6882", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["teaxCFgtmCQ3E9fy8", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T00:03:19.734Z", "modifiedAt": null, "url": null, "title": "Genes are overrated", "slug": "genes-are-overrated", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:34.092Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iQ4EZuZiLEqEv3YfX/genes-are-overrated", "pageUrlRelative": "/posts/iQ4EZuZiLEqEv3YfX/genes-are-overrated", "linkUrl": "https://www.lesswrong.com/posts/iQ4EZuZiLEqEv3YfX/genes-are-overrated", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Genes%20are%20overrated&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGenes%20are%20overrated%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQ4EZuZiLEqEv3YfX%2Fgenes-are-overrated%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Genes%20are%20overrated%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQ4EZuZiLEqEv3YfX%2Fgenes-are-overrated", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQ4EZuZiLEqEv3YfX%2Fgenes-are-overrated", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 581, "htmlBody": "<p>This is hardly news, but <a href=\"http://www.guardian.co.uk/commentisfree/2011/apr/17/human-genome-genetics-twin-studies\">this Guardian article</a> reminded me of it - genes are really overrated, both among unwashed masses, and also here on Less Wrong.</p>\n<p>I don't want to repeat things which have been said by so many before me, so I'll just link a lot.</p>\n<p>Summary of evidence against genes being important:</p>\n<ul>\n<li>Almost no genes correlating with anything interesting been found. This is totally crushing evidence. If genes were important, Bayesian surprise of this lack of results would be in the land of impossible.</li>\n<li>Massive very fast changes of various supposedly highly hereditary characteristic with time in same populations. To name a few - <a href=\"http://en.wikipedia.org/wiki/Flynn_effect\">Flynn effect</a>, changes in people's height, obesity epidemic.</li>\n<li>Plenty of evidence of very large very reliable associations of various environmental factors with various important outcomes. For example unlike with genes and cancer where we get just noise, we know very well how much smoking increases chance of lung cancer.</li>\n</ul>\n<p>Summary of evidence for genes being important:</p>\n<ul>\n<li>Some twin and adoption studies - which rely on very tiny highly atypical samples and a lot of statistical manipulation  to get results they want. To make matters worse, results they got were  wildly inconsistent.</li>\n</ul>\n<p>And there's nothing more. Decades ago, before we had direct evidence of lack of correlation between genes and outcomes, it was excusable to believe genes matter a lot, even if it was never the best interpretation of data. Now it's just going against bulk of the evidence.</p>\n<p>And in case you're wondering how could twin studies show high heredity when everything else says otherwise, I have two examples for you.</p>\n<p>This one from a critique of <a href=\"http://www.ssc.wisc.edu/econ/archive/wp2001-08.pdf\">twin studies</a> by Kamin and Goldberger:</p>\n<p style=\"padding-left: 30px;\">\"A case in point is  provided by the recent study of regular tobacco use among SATSA's twins  (24). Heritability was estimated as 60% for men, only 20% for women.  Separate analyses were then performed for three distinct age cohorts.  For men, the heritability estimates were nearly identical for each  cohort. But for women, heritability increased from zero for those born  between 1910 and 1924, to 21% for those in the 1925-39 birth cohort, to  64% for the 1940-58 cohort. The authors suggested that the most  plausible explanation for this finding was that \"a reduction in the  social restrictions on smoking in women in Sweden as the 20th century  progressed permitted genetic factors increasing the risk for regular  tobacco use to express themselves.\" If purportedly genetic factors can  be so readily suppressed by social restrictions, one must ask the  question, \"For what conceivable purpose is the phenotypic variance being  allocated?\" This question is not addressed seriously by MISTRA or  SATSA. The numbers, and the associated modeling, appear to be ends in  themselves.\"</p>\n<p>As the final nail in the coffin of heredity studies:</p>\n<p style=\"padding-left: 30px;\"><a href=\"http://www.nejm.org/doi/full/10.1056/NEJM199005243222102#t=articleTop\">The Body-Mass Index of Twins Who Have Been Reared Apart</a></p>\n<p style=\"padding-left: 30px;\">We  conclude that genetic influences on body-mass index are substantial,  whereas the childhood environment has little or no influence. These  findings corroborate and extend the results of earlier studies of twins  and adoptees. (N Engl J Med 1990; 322:1483&ndash;7.)</p>\n<p>Or as paraphrased by a certain commenter on Marginal Revolution:</p>\n<p style=\"padding-left: 30px;\">IOWs,  the reason why white kids of today are much fatter than white kids of  the 50s and 60s is due to genetic influences and environment has little  or no influence</p>\n<p>To summarize - heredity studies are pretty much totally worthless data manipulation. Once we accept that, all other evidence points for environment being extremely important, and genes mattering very little. We should accept that already.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iQ4EZuZiLEqEv3YfX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": -16, "extendedScore": null, "score": -3.3e-05, "legacy": true, "legacyId": "6887", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T12:54:55.934Z", "modifiedAt": null, "url": null, "title": "Is it possible to build a safe oracle AI?", "slug": "is-it-possible-to-build-a-safe-oracle-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:38.619Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Karl", "createdAt": "2010-10-27T21:06:59.318Z", "isAdmin": false, "displayName": "Karl"}, "userId": "EN2BxuvFHRgmLbbp3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SFtJq2vwTXQNATEZe/is-it-possible-to-build-a-safe-oracle-ai", "pageUrlRelative": "/posts/SFtJq2vwTXQNATEZe/is-it-possible-to-build-a-safe-oracle-ai", "linkUrl": "https://www.lesswrong.com/posts/SFtJq2vwTXQNATEZe/is-it-possible-to-build-a-safe-oracle-ai", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20it%20possible%20to%20build%20a%20safe%20oracle%20AI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20it%20possible%20to%20build%20a%20safe%20oracle%20AI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFtJq2vwTXQNATEZe%2Fis-it-possible-to-build-a-safe-oracle-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20it%20possible%20to%20build%20a%20safe%20oracle%20AI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFtJq2vwTXQNATEZe%2Fis-it-possible-to-build-a-safe-oracle-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFtJq2vwTXQNATEZe%2Fis-it-possible-to-build-a-safe-oracle-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 368, "htmlBody": "<div id=\"body_t1_3yz5\" class=\"comment-content\">\n<div class=\"md\">\n<p>It seem to me possible to create a safe oracle AI.</p>\n<p>Suppose that you have a sequence predictor which is a good approximation of Solomonoff induction but which run in reasonable time. This sequence predictor can potentially be really useful (for example, predict future siai publications from past siai publications then proceed to read the article which give a complete account of Friendliness theory...) and is not dangerous in itself.</p>\n<p>The question, of course, is how to obtain such a thing.</p>\n<p>The trick rely on the concept of program predictor. A program predictor is a function which predict, more or less accurately, the output of the program (note that when we refer to a program we refer to a program without side effect that just calculate an output.) it take as it's input but within reasonable time. If you have a very accurate program predictor then you can obviously use it to gain a good approximation of Solomonoff induction which run in reasonable time.</p>\n<p>But of course, this just displace the problem: how do you get such an accurate program predictor?</p>\n<p>Well, suppose you have a program predictor which is good enough to be improved on. Then, you use it to predict the program of less than N bits of length (with N sufficiently big of course) which maximize a utility function which measure how accurate the output of that program is as a program predictor given that it generate this output in less than T steps (where T is a reasonable number given the hardware you have access to). Then you run that program. Check the accuracy of the obtained program predictor. If insufficient repeat the process. You should eventually obtain a very accurate program predictor. QED.</p>\n<p>So we've reduced our problem to the problem of creating a program predictor good enough to be improved upon. That should be possible. In particular, it is related to the problem of logical uncertainty. If we can get a passable understanding of logical uncertainty it should be possible to build such a program predictor using it. Thus a minimal understanding of logical uncertainty should be sufficient to obtain agi. In fact even without such understanding, it may be possible to patch together such a program predictor...</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb26d": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SFtJq2vwTXQNATEZe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 1, "extendedScore": null, "score": 7.046643374810244e-07, "legacy": true, "legacyId": "6906", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T16:11:10.085Z", "modifiedAt": null, "url": null, "title": "No, Seriously. Just Try It.", "slug": "no-seriously-just-try-it", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:37.266Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zmfo388RA9oky3KYe/no-seriously-just-try-it", "pageUrlRelative": "/posts/Zmfo388RA9oky3KYe/no-seriously-just-try-it", "linkUrl": "https://www.lesswrong.com/posts/Zmfo388RA9oky3KYe/no-seriously-just-try-it", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20No%2C%20Seriously.%20Just%20Try%20It.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANo%2C%20Seriously.%20Just%20Try%20It.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZmfo388RA9oky3KYe%2Fno-seriously-just-try-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=No%2C%20Seriously.%20Just%20Try%20It.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZmfo388RA9oky3KYe%2Fno-seriously-just-try-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZmfo388RA9oky3KYe%2Fno-seriously-just-try-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 664, "htmlBody": "<p>In <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">Scientific Self-Help</a>, I explained that huge sections of the self-help industry pay little or no attention to the scientific data on self-help. Partly, this is because self-help products are usually written to <em>sell</em>, not to <em>help</em>.</p>\n<p>Another reason for this is that there are huge gaps in our scientific knowledge about self-help. Unlike electrons, humans are complex beings and very different from each other.</p>\n<p>When considering a self-help goal, it may be helpful to at least <em>start</em>&nbsp;with methods that have been <a href=\"/lw/3w3/how_to_beat_procrastination/\">scientifically</a> <a href=\"/lw/4su/how_to_be_happy/\">demonstrated</a> to work on a large number of people. On the other hand, there are so many gaps in our knowledge that it's definitely worth <em>just trying things</em>&nbsp;to see what works for <em>you</em>. This point has been recently emphasized by atucker in <a href=\"/lw/4ln/go_try_things/\">Go Try Things</a>, <a href=\"/lw/4up/dont_fear_failure/\">Don't Fear Failure</a>, and <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just Try It: Quantity Trumps Quality</a>. Also see:&nbsp;<a href=\"/lw/ui/use_the_try_harder_luke/\">Use the Try Harder, Luke</a>&nbsp;and <a href=\"/lw/2sh/break_your_habits_be_more_empirical/\">Break Your Habits: Be More Empirical</a>.</p>\n<p><a href=\"http://www.scientificamerican.com/article.cfm?id=self-experimenters\">Self-experimenters</a>&nbsp;like <a href=\"http://zenhabits.net/4-hour-body/\">Tim Ferris</a>&nbsp;and&nbsp;<a href=\"http://www.scientificamerican.com/article.cfm?id=self-experimenter-free-from-insomnia\">Seth Roberts</a>&nbsp;are masters of the Just Try It method.</p>\n<p>To cure his insomnia, Seth Roberts tried exercise, calcium supplements, and adjusting the lamps near his bed. In the end what worked was delaying his breakfast until 11am. Within a week, his insomnia was gone. Three months later he tried eating at 7am again, and the insomnia returned.</p>\n<p>No controlled scientific study says that delaying breakfast until 11am will cure insomnia. For most insomniacs, it probably <em>won't</em> work. That's why it's important to Just Try It. In a way, you <em>are </em>a special snowflake, and the only way to figure out what works for <em>you</em>&nbsp;is to Just Try It. Controlled scientific studies are, pardon my language, a&nbsp;<em>godsend</em>&nbsp;- but you can't wait for busy scientists to decode your personal psychology. You're going to have to do that yourself.</p>\n<p>Roberts did the same with dieting, trying an endless combination of things and weighing himself constantly. He found that drinking unflavored fructose water between meals did the trick, and he lost 35 pounds. Later, he discovered that a few teaspoonfuls of flavorless vegetable oil worked just as well.</p>\n<p>See <a href=\"http://curetogether.com/blog/2010/03/12/how-to-run-a-successful-self-experiment/\">How to Run a Successful Self-Experiment</a> and <a href=\"http://quantifiedself.com/\">Quantified Self</a> for ideas.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>When to try, when to not try</h4>\n<p>Of course, there are some things you shouldn't \"just try.\" Physically dangerous things should not be tried on a whim. Financially dangerous options deserve much forethought.&nbsp;</p>\n<p>But in many domains we <em>overestimate</em>&nbsp;the risks involved in trying. Social interaction with strangers is a good example.</p>\n<p>Why does Johnny feel frozen with anxiety when he considers the prospect of approaching the cute girl on the corner, flirting with her, and asking for her number? What is the risk to him? There is no physical or financial danger. Johnny's social status won't drop, because nobody need know about the rejection, and he will probably never see her again.</p>\n<p>A story often told here is that in our ancestral environment, one or two rejections in a small tribe where everybody knows everything about everyone could be fatal to someone's prospects for reproducing. So most of us have inherited a strong anxiety about the possibility of rejection by potential mates. But this anxiety serves us poorly in the current environment. In a large city, Johnny could ask 15 women out on a date every day, get rejected 95% of the time, and end up with lots of dates and no major hit to his social status from all those rejections. Unfortunately, the <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">chimp brain</a> that mostly determines his actions doesn't know that.</p>\n<p>I don't know if this story is true, but it makes some sense. In any case, the point remains that social interaction with strangers - for mating or other reasons - carries almost no risk. And yet we often <em>feel</em> as though there is a large risk.</p>\n<p>Thus, social interaction with strangers is a domain in which we should be <em>just trying things</em>&nbsp;far more often than we do.</p>\n<p>Self-experiment is another domain in which it is highly valuable to just try things.</p>\n<p>There are others: taking classes and workshops for skills and hobbies, asking influential people for things, re-arranging your personal environment, etc.</p>\n<p>No, seriously. Just try it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AodfCFefLAuwDyj7Z": 1, "fkABsGCJZ6y9qConW": 1, "7thPfS2WbD2JKizr7": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zmfo388RA9oky3KYe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 68, "baseScore": 79, "extendedScore": null, "score": 0.000149, "legacy": true, "legacyId": "6845", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 79, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["33KewgYhNSxFpbpXg", "RWo4LwFzpHNQCTcYt", "ZbgCx2ntD5eu8Cno9", "ADaZaEsmJMnKKhRqS", "83naYmTXYcupTRGRW", "hY86FhYysQ7dBg3d8", "fhEPnveFhb9tmd7Pe", "iA25AvZqAr6G8mAXR", "du395YvCnQXBPSJax"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T17:51:13.493Z", "modifiedAt": null, "url": null, "title": "Evaluating weather forecast accuracy: an interview with Eric Floehr", "slug": "evaluating-weather-forecast-accuracy-an-interview-with-eric", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:32.323Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Johnicholas", "createdAt": "2009-02-27T15:01:52.708Z", "isAdmin": false, "displayName": "Johnicholas"}, "userId": "kBvTXutfPytNtzPyD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C2oHhEHekw8DTuDuY/evaluating-weather-forecast-accuracy-an-interview-with-eric", "pageUrlRelative": "/posts/C2oHhEHekw8DTuDuY/evaluating-weather-forecast-accuracy-an-interview-with-eric", "linkUrl": "https://www.lesswrong.com/posts/C2oHhEHekw8DTuDuY/evaluating-weather-forecast-accuracy-an-interview-with-eric", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Evaluating%20weather%20forecast%20accuracy%3A%20an%20interview%20with%20Eric%20Floehr&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEvaluating%20weather%20forecast%20accuracy%3A%20an%20interview%20with%20Eric%20Floehr%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC2oHhEHekw8DTuDuY%2Fevaluating-weather-forecast-accuracy-an-interview-with-eric%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Evaluating%20weather%20forecast%20accuracy%3A%20an%20interview%20with%20Eric%20Floehr%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC2oHhEHekw8DTuDuY%2Fevaluating-weather-forecast-accuracy-an-interview-with-eric", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC2oHhEHekw8DTuDuY%2Fevaluating-weather-forecast-accuracy-an-interview-with-eric", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 34, "htmlBody": "<p>Eric Floehr has a business that \"holds a mirror up\" to weather forecasters, and aggregates and evaluates forecasters for weather forecast consumers. Rationalists interested in improving our societies truth orientation might be mildly interested.</p>\n<p><a href=\"http://www.johndcook.com/blog/2011/04/12/weather-forecast-accuracy/\">http://www.johndcook.com/blog/2011/04/12/weather-forecast-accuracy/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C2oHhEHekw8DTuDuY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 7.047481327540138e-07, "legacy": true, "legacyId": "6909", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T17:56:53.152Z", "modifiedAt": "2021-03-21T20:58:50.346Z", "url": null, "title": "Official Less Wrong Redesign: Call for Suggestions ", "slug": "official-less-wrong-redesign-call-for-suggestions", "viewCount": null, "lastCommentedAt": "2012-04-20T14:28:21.204Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Louie", "createdAt": "2010-05-10T21:41:14.619Z", "isAdmin": false, "displayName": "Louie"}, "userId": "JPwZspDjBcfwwuy7W", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g96zwWHArQFK8HjNd/official-less-wrong-redesign-call-for-suggestions", "pageUrlRelative": "/posts/g96zwWHArQFK8HjNd/official-less-wrong-redesign-call-for-suggestions", "linkUrl": "https://www.lesswrong.com/posts/g96zwWHArQFK8HjNd/official-less-wrong-redesign-call-for-suggestions", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Official%20Less%20Wrong%20Redesign%3A%20Call%20for%20Suggestions%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOfficial%20Less%20Wrong%20Redesign%3A%20Call%20for%20Suggestions%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg96zwWHArQFK8HjNd%2Fofficial-less-wrong-redesign-call-for-suggestions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Official%20Less%20Wrong%20Redesign%3A%20Call%20for%20Suggestions%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg96zwWHArQFK8HjNd%2Fofficial-less-wrong-redesign-call-for-suggestions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg96zwWHArQFK8HjNd%2Fofficial-less-wrong-redesign-call-for-suggestions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 154, "htmlBody": "<p>In the next month, the administrators of Less Wrong are going to sit down with a <a href=\"http://www.jimmygleeson.com/\">professional designer</a> to tweak the site design. But before they do, now is your chance to make suggestions that will guide their redesign efforts.</p>\n<p>How can we improve the Less Wrong user experience? What features aren&rsquo;t working? What features don&rsquo;t exist? What would you change about the layout, templates, images, navigation, comment nesting, post/comment editing, side-bars, RSS feeds, color schemes, etc? Do you have specific CSS or HTML changes you'd make to improve load time, SEO, or other valuable metrics?</p>\n<p>The rules for this thread are:</p>\n<ul>\n<li>One suggestion per comment.</li>\n<li>Upvote all comments you&rsquo;d like to see implemented.</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>BUT DON&rsquo;T JUMP TO THE COMMENTS JUST YET</strong>: Take a few minutes to collect your thoughts and write down your own ideas <em>before</em>&nbsp;reading others&rsquo; suggestions. Less <a href=\"/lw/k3/priming_and_contamination/ \">contamination</a> = more unique ideas + better feature coverage!</p>\n<p>Thanks for your help!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g96zwWHArQFK8HjNd", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 26, "extendedScore": null, "score": 7.047497339230963e-07, "legacy": true, "legacyId": "6910", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 582, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BaCWFCxBQYjJXSsah"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-04-20T17:56:53.152Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T19:20:55.178Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Why truth? And...", "slug": "seq-rerun-why-truth-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:23.281Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AzQaTGBMBbzkP2msc/seq-rerun-why-truth-and", "pageUrlRelative": "/posts/AzQaTGBMBbzkP2msc/seq-rerun-why-truth-and", "linkUrl": "https://www.lesswrong.com/posts/AzQaTGBMBbzkP2msc/seq-rerun-why-truth-and", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Why%20truth%3F%20And...&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Why%20truth%3F%20And...%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzQaTGBMBbzkP2msc%2Fseq-rerun-why-truth-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Why%20truth%3F%20And...%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzQaTGBMBbzkP2msc%2Fseq-rerun-why-truth-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzQaTGBMBbzkP2msc%2Fseq-rerun-why-truth-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 214, "htmlBody": "<p>Today's post, <a href=\"/lw/go/why_truth_and/\">Why truth? And...</a> was originally published on 27 November 2006. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Why should we seek truth? Pure curiosity is an emotion, but not therefore irrational. Instrumental value is another reason, with the advantage of giving an outside verification criterion. A third reason is conceiving of truth as a moral duty, but this might invite moralizing about \"proper\" modes of thinking that don't work. Still, we need to figure out how to think properly. That means avoiding biases, for which see the next post.</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/5b6/seq_rerun_the_martial_art_of_rationality/\">The Martial Art of Rationality</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AzQaTGBMBbzkP2msc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 7.047733649297898e-07, "legacy": true, "legacyId": "6911", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YshRbqZHYFoEMqFAu", "vWM9fBWacWzjzPGQR", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T21:13:07.106Z", "modifiedAt": null, "url": null, "title": "Epistle to the New York Less Wrongians", "slug": "epistle-to-the-new-york-less-wrongians", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:29.569Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jP583FwKepjiWbeoQ/epistle-to-the-new-york-less-wrongians", "pageUrlRelative": "/posts/jP583FwKepjiWbeoQ/epistle-to-the-new-york-less-wrongians", "linkUrl": "https://www.lesswrong.com/posts/jP583FwKepjiWbeoQ/epistle-to-the-new-york-less-wrongians", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Epistle%20to%20the%20New%20York%20Less%20Wrongians&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEpistle%20to%20the%20New%20York%20Less%20Wrongians%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjP583FwKepjiWbeoQ%2Fepistle-to-the-new-york-less-wrongians%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Epistle%20to%20the%20New%20York%20Less%20Wrongians%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjP583FwKepjiWbeoQ%2Fepistle-to-the-new-york-less-wrongians", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjP583FwKepjiWbeoQ%2Fepistle-to-the-new-york-less-wrongians", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2940, "htmlBody": "<p><em>(At the suggestion and request of Tom McCabe, I&#x27;m posting the essay that I sent to the New York LW group after my first visit there, and before the second visit:)</em></p><p>Having some kind of global rationalist community come into existence seems like a quite extremely good idea.  The NYLW group is the forerunner of that, the first group of LW-style rationalists to form a real community, and to confront the challenges involved in staying on track while growing as a community.</p><p>&quot;Stay on track toward what?&quot; you ask, and my best shot at describing the vision is as follows:</p><p>&quot;Through rationality we shall become awesome, and invent and test systematic methods for making people awesome, and plot to optimize everything in sight, and the more fun we have the more people will want to join us.&quot;</p><p>(That last part is something I only realized was Really Important after visiting New York.)</p><p>Michael Vassar says he&#x27;s worried that you might be losing track of the &quot;rationality&quot; and &quot;world optimization&quot; parts of this - that people might be wondering what sort of benefit &quot;rationality&quot; delivers as opposed to, say, paleo dieting.  <em>(Note - less worried about this now that I&#x27;ve met the group in person.  -EY.)</em></p><p>I admit that the original Less Wrong sequences did not heavily emphasize the benefits for everyday life (as opposed to solving ridiculously hard scientific problems). This is something I plan to fix with my forthcoming book - along with the problem where the key info is scattered over six hundred blog posts that only truly dedicated people and/or serious procrastinators can find the time to read.</p><p>But I really don&#x27;t think the whole rationality/fun association you&#x27;ve got going - my congratulations on pulling that off, by the way, it&#x27;s damned impressive - is something that can (let alone <em>should</em>) be untangled. Most groups of people capable of becoming enthusiastic about strange new nonconformist ways of living their lives would have started trying to read each other&#x27;s auras by now. Rationality is the master lifehack which distinguishes which other lifehacks to use.</p><p>The way an LW-rationality meetup usually gets started is that there is a joy of being around <em>reasonable</em> people - a joy that comes, in a very direct way, from those people caring about what&#x27;s true and what&#x27;s effective, and being able to reflect on more than their first impulse to see whether it makes sense.  You wouldn&#x27;t want to lose that either.</p><p>But the thing about <em>effective</em> rationality is that you can also use it to distinguish truth from falsehood, and realize that the best methods aren&#x27;t always the ones everyone else is using; and you can start assembling a pool of lifehacks that doesn&#x27;t include homeopathy. You become stronger, and that makes you start thinking that you can also help other people become stronger. Through the systematic accumulation of good ideas and the rejection of bad ideas, you can get so awesome that even other people notice, and this means that you can start attracting a new sort of person, one who starts out <em>wanting to become awesome</em> instead of being attracted <em>specifically</em> to the rationality thing.  This is fine in theory, since indeed the Art must have a purpose higher than itself or it collapses into infinite recursion. But some of these new recruits may be a bit skeptical, at first, that all this &quot;rationality&quot; stuff is really contributing all that much to the awesome.</p><p>Real life is not a morality tale, and I don&#x27;t know if I&#x27;d prophesy that the instant you get too much awesome and not enough rationality, the group will be punished for that sin by going off and trying to read auras. But I think I <em>would</em> prophesy that if you got too large and insufficiently reasonable, and if you lost sight of your higher purposes and your dreams of world optimization, the first major speedbump you hit would splinter the group. (There <em>will</em> be <em>some</em> speedbump, though I don&#x27;t know what it will be.)</p><p>Rationality isn&#x27;t just about knowing about things like Bayes&#x27;s Theorem. It&#x27;s also about:</p><ul><li>Saying oops and changing your mind occasionally.</li><li>Knowing that clever arguing isn&#x27;t the same as looking for truth.</li><li>Actually paying attention to what succeeds and what fails, instead of just being driven by your internal theories.</li><li>Reserving your self-congratulations for the occasions when you actually change a policy or belief, because while not every change is an improvement, every improvement is a change.</li><li>Self-awareness - a core rational skill, but at the same time, a caterpillar that spent all day obsessing about being a caterpillar would never become a butterfly.</li><li>Having enough grasp of evolutionary psychology to realize that this is no longer an eighty-person hunter-gatherer band and that getting into huge shouting matches about Republicans versus Democrats does not actually change very much.</li><li>Asking whether your most cherished beliefs to shout about actually control your anticipations, whether they mean <em>anything,</em> never mind whether their predictions are actually correct.</li><li>Understanding that correspondence bias means that most of your enemies are not inherently evil mutants but rather people who live in a different perceived world than you do. (Albeit of course that some people are selfish bastards and a very few of them are psychopaths.)</li><li>Being able to accept and consider advice from other people who think you&#x27;re doing something stupid, without lashing out at them; and the more you <em>show</em> them this is true, and the more they can trust you not to be offended if they&#x27;re frank with you, the better the advice you can get. (Yes, this has a failure mode where insulting other people becomes a status display. But you can also have too much politeness, and it is a traditional strength of rationalists that they sometimes tell each other the truth. Now and then I&#x27;ve told college students that they are emitting terrible body odors, and the reply I usually get is that they had no idea and I am the first person ever to suggest this to them.)</li><li>Comprehending the <em>nontechnical</em> arguments for Aumann&#x27;s Agreement Theorem well enough to realize that when two people have common knowledge of a persistent disagreement, <em>something</em> is wrong somewhere - not that you can necessarily do better by automatically agreeing with everyone who persistently disagrees with you; but still, knowing that <em>ideal</em> rational agents wouldn&#x27;t just go around yelling at each other all the time.</li><li>Knowing about scope insensitivity and diminishing marginal returns doesn&#x27;t just mean that you donate charitable dollars to &quot;existential risks that few other people are working on&quot;, instead of &quot;The Society For Curing Rare Diseases In Cute Puppies&quot;. It means you know that eating half a chocolate brownie appears as essentially the same pleasurable memory in retrospect as eating a whole brownie, so long as the other half isn&#x27;t in front of you and you don&#x27;t have the unpleasant memory of exerting willpower not to eat it. (Seriously, I didn&#x27;t emphasize all the practical applications of every cognitive bias in the Less Wrong sequences but there are a <em>lot</em> of things like that.)</li><li>The ability to dissent from conformity; realizing the difficulty and importance of being the <em>first</em> to dissent.</li><li>Knowing that to avoid pluralistic ignorance everyone should write down their opinion on a sheet of paper <em>before</em> hearing what everyone else thinks.</li></ul><p>But then one of the chief surprising lessons I learned, after writing the original Less Wrong sequences, was that if you <em>succeed</em> in teaching people a bunch of amazing stuff about epistemic rationality, this reveals...</p><p>(drum roll)</p><p>...that, having repaired <em>some</em> of people&#x27;s flaws, you can now see more clearly all the <em>other </em>qualities required to be awesome. The most important and notable of these other qualities, needless to say, is Getting Crap Done.</p><p>(Those of you reading Methods of Rationality will note that it emphasizes a lot of things that aren&#x27;t in the original Less Wrong, such as the virtues of hard work and practice. This is because I have Learned From Experience.)</p><p>Similarly, courage isn&#x27;t something I emphasized enough in the original Less Wrong (as opposed to MoR) but the thought has since occurred to me that most people can&#x27;t do things which require even small amounts of courage. (Leaving NYC, I had two Metrocards with small amounts of remaining value to give away. I felt reluctant to call out anything, or approach anyone and offer them a free Metrocard, and I thought to myself, <em>well, of course I&#x27;m reluctant, this task requires a small amount of courage</em> and then I asked three times before I found someone who wanted them. Not, mind you, that this was an important task in the grand scheme of things - just a little bit of rejection therapy, a little bit of practice in doing things which require <em>small</em> amounts of courage.)</p><p>Or there&#x27;s Munchkinism, the quality that lets people try out lifehacks that sound a bit weird. A Munchkin is the sort of person who, faced with a role-playing game, reads through the rulebooks over and over until he finds a way to combine three innocuous-seeming magical items into a cycle of infinite <em>wish</em> spells. Or who, in real life, composes a surprisingly effective diet out of drinking a quarter-cup of extra-light olive oil at least one hour before and after tasting anything else. Or combines liquid nitrogen and antifreeze and life-insurance policies into a ridiculously cheap method of defeating the invincible specter of unavoidable Death. Or figures out how to build the real-life version of the cycle of infinite <em>wish</em> spells. <em>Magic the Gathering</em> is a Munchkin game, and MoR is a Munchkin story.</p><p>It would be really awesome if the New York Less Wrong groups figures out how to teach its members hard work and courage and Muchkinism and so on.</p><p>It would be even more awesome if you could muster up the energy to track the results in any sort of systematic way so that you can do small-N Science (based on Bayesian likelihoods thank you, not the usual statistical significance bullhockey) and find out how effective different teaching methods are, or track the effectiveness of other lifehacks as well - the Quantitative Self road. This, of course, would require Getting Crap Done; but I do think that in the long run, whether we end up with really effective rationalists is going to depend a lot on whether we can come up with evidence-based metrics for how well a teaching method works, or if we&#x27;re stuck in the failure mode of psychoanalysis, where we just go around trying things that sound like good ideas.</p><p>And of course it would be really truly amazingly awesome if some of you became energetic gung-ho intelligent people who can see the world full of low-hanging fruit in front of them, who would go on to form multiple startups which would make millions and billions of dollars. That would also be cool.</p><p>But not everyone has to start a startup, not everyone has to be there to Get Stuff Done, it <em>is</em> okay to have Fun. The more of you there are, the more likely it is that any given five of you will want to form a new band, or like the same sort of dancing, or fall in love, or decide to try learning meditation and reporting back to the group on how it went. Growth in general <em>is</em> good. Every added person who&#x27;s above the absolute threshold of competence is one more person who can try out new lifehacks, recruit new people, or just be there putting the whole thing on a larger scale and making the group more Fun. On the other hand there <em>is</em> a world out there to optimize, and also the scaling of the group is limited by the number of people who can be organizers (more on this below). There&#x27;s a narrow path to walk between &quot;recruit everyone above the absolute threshold who seems like fun&quot; and &quot;recruit people with visibly unusually high potential to do interesting things&quot;. I would suggest making <em>extra effort</em> to recruit people who seem like they have high potential but not anything like a <em>rule</em>. But if someone not <em>only</em> seems to like explicit rationality and want to learn more, but <em>also</em> seems like a smart executive type who gets things done, perhaps their invitation to a meetup should be prioritized?</p><p>So that was the main thing I had to say, but now onward to some other points.</p><p>A sensitive issue is what happens when someone can&#x27;t reach the absolute threshold of competence. I think the main relevant Less Wrong post on this subject is &quot;Well-Kept Gardens Die By Pacifism.&quot; There are people who cannot be saved - or at least people who cannot be saved by any means currently known to you. And there is a whole world out there to be optimized; sometimes even if a person <em>can</em> be saved, it takes a ridiculous amount of effort that you could better use to save four other people instead. We&#x27;ve had similar problems on the West Coast - I would hear about someone who wasn&#x27;t Getting Stuff Done, but who seemed to be making amazing strides on self-improvement, and then a month later I would hear the same thing again, and isn&#x27;t it remarkable how we keep hearing about so much progress but never about amazing things the person gets<em> done</em> -</p><p>(I will parenthetically emphasize that every single useful mental technique I have ever developed over the course of my entire life has been developed in the course of <em>trying to accomplish some particular real task</em> and <em>none</em> of it is the result of me sitting around and thinking, &quot;Hm, however shall I Improve Myself today?&quot; I should advise a mindset in which <em>making tremendous progress on fixing yourself</em> doesn&#x27;t merit much congratulation and only <em>particular deeds actually accomplished</em> are praised; and also that you always have some <em>thing</em> you&#x27;re trying to <em>do</em> in the course of any particular project of self-improvement - a target <em>real-world accomplishment </em>to which your self-improvements are a means, <em>not</em> definable in terms of any personality quality unless it is weight loss or words output on a writing project or something else visible and measurable.)</p><p>- and the other thing is that trying to save people who cannot be saved can drag down a whole community, because it becomes less Fun, and <em>that</em> means new people don&#x27;t want to join.</p><p>I would suggest having a known and fixed period of time, like four months, that you are allowed to spend on trying to fix anyone who seems fixable, and if after that their outputs do not exceed their inputs and they are dragging down the Fun level relative to the average group member, fire them. You could maybe have a Special Committee with three people who would decide this - one of the things I pushed for on the West Coast was to have the Board deciding whether to retain people, with <em>nobody</em> else authorized to make promises. There should be no one person who can be appealed to, who can be moved by pity and impulsively say &quot;Yes, you can stay.&quot; Short of having Voldemort do it, the best you can do to reduce pity and mercy is to have the decision made by committee.</p><p>And if anyone is making the group less Fun or scaring off new members, and yes this includes being a creep who offends potential heroine recruits, give them an instant ultimatum or just fire them on the spot.</p><p>You have to be able to do this. This is not the ancestral environment where there&#x27;s only eighty people in your tribe and exiling any one of them is a huge decision that can never be undone. It&#x27;s a large world out there and there are literally <em>hundreds of millions of people</em> whom you <em>do not</em> want in your community, at least relative to your current ability to improve them. I&#x27;m sorry but it <em>has</em> to be done.</p><p>Finally, if you grow much further it may no longer be possible for everyone to meet all the time as a group. I&#x27;m not quite sure what to advise about this - splitting up into meetings on particular interests, maybe, but it seems more like the sort of thing where you ought to discuss the problem as thoroughly as possible before proposing any policy solutions. My main advice is that if there&#x27;s any separatish group that forms, I am skeptical about its ability to stay on track if there isn&#x27;t at least one high-level epistemic rationalist executive type to organize it, someone who not only knows Bayes&#x27;s Theorem but who can also Get Things Done. Retired successful startup entrepreneurs would be great for this if you could get them, but smart driven young people might be more mentally flexible and a lot more recruitable if far less experienced. In any case, I suspect that your ability to grow is going to be ultimately limited by the percentage of members who have the ability to be organizers, <em>and</em> the time to spend organizing, <em>and</em> who&#x27;ve also leveled up into good enough rationalists to keep things on track.  Implication, make an extra effort to recruit people who can become organizers.</p><p>And whenever someone does start doing something interesting with their life, or successfully recruits someone who seems unusually promising, or spends time organizing things, don&#x27;t forget to give them a well-deserved cookie.</p><p>Finally, remember that the trouble with the exact phrasing of &quot;become awesome&quot; - though it does nicely for a gloss - is that Awesome isn&#x27;t a static quality of a person. Awesome is as awesome does.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 2, "fkABsGCJZ6y9qConW": 1, "zv7v2ziqexSn5iS9v": 1, "T57Qd9J3AfxmwhQtY": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jP583FwKepjiWbeoQ", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 115, "baseScore": 152, "extendedScore": null, "score": 0.000281, "legacy": true, "legacyId": "6912", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 152, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 275, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 12, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T22:07:34.703Z", "modifiedAt": null, "url": null, "title": "Ben Goertzel interviews Michael Anissimov regarding existential risk [link]", "slug": "ben-goertzel-interviews-michael-anissimov-regarding", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:35.213Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/34f6AZTdzpdRwWvti/ben-goertzel-interviews-michael-anissimov-regarding", "pageUrlRelative": "/posts/34f6AZTdzpdRwWvti/ben-goertzel-interviews-michael-anissimov-regarding", "linkUrl": "https://www.lesswrong.com/posts/34f6AZTdzpdRwWvti/ben-goertzel-interviews-michael-anissimov-regarding", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ben%20Goertzel%20interviews%20Michael%20Anissimov%20regarding%20existential%20risk%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABen%20Goertzel%20interviews%20Michael%20Anissimov%20regarding%20existential%20risk%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34f6AZTdzpdRwWvti%2Fben-goertzel-interviews-michael-anissimov-regarding%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ben%20Goertzel%20interviews%20Michael%20Anissimov%20regarding%20existential%20risk%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34f6AZTdzpdRwWvti%2Fben-goertzel-interviews-michael-anissimov-regarding", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34f6AZTdzpdRwWvti%2Fben-goertzel-interviews-michael-anissimov-regarding", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://hplusmagazine.com/2011/04/20/mitigating-the-risks-of-artificial-superintelligence/\">http://hplusmagazine.com/2011/04/20/mitigating-the-risks-of-artificial-superintelligence/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "34f6AZTdzpdRwWvti", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.048206469722707e-07, "legacy": true, "legacyId": "6913", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-20T23:41:02.332Z", "modifiedAt": null, "url": null, "title": "A Problem with Human Intuition about Conventional Statistics:", "slug": "a-problem-with-human-intuition-about-conventional-statistics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:32.278Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kai-o-logos", "createdAt": "2011-03-31T11:37:53.516Z", "isAdmin": false, "displayName": "Kai-o-logos"}, "userId": "ruBEoAJzDQhD8HzXq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HfA6d9neFPhbTvgTH/a-problem-with-human-intuition-about-conventional-statistics", "pageUrlRelative": "/posts/HfA6d9neFPhbTvgTH/a-problem-with-human-intuition-about-conventional-statistics", "linkUrl": "https://www.lesswrong.com/posts/HfA6d9neFPhbTvgTH/a-problem-with-human-intuition-about-conventional-statistics", "postedAtFormatted": "Wednesday, April 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Problem%20with%20Human%20Intuition%20about%20Conventional%20Statistics%3A&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Problem%20with%20Human%20Intuition%20about%20Conventional%20Statistics%3A%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHfA6d9neFPhbTvgTH%2Fa-problem-with-human-intuition-about-conventional-statistics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Problem%20with%20Human%20Intuition%20about%20Conventional%20Statistics%3A%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHfA6d9neFPhbTvgTH%2Fa-problem-with-human-intuition-about-conventional-statistics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHfA6d9neFPhbTvgTH%2Fa-problem-with-human-intuition-about-conventional-statistics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 579, "htmlBody": "<!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} -->\n<p>&nbsp;</p>\n<!--[endif]-->\n<p class=\"MsoNormal\"><span>As an aspiring scientist, I hold the Truth above all. As Hodgell once said, <em>\"That which can be destroyed by the truth should be.\" </em>But what if the thing that is holding our pursuit of the Truth back is our own system? I will share an example of an argument I overheard between a theist and an atheist once - showing an instance where human intuition might fail us.</span></p>\n<p class=\"MsoNormal\"><span>*General Transcript*<br /></span></p>\n<p class=\"MsoNormal\"><span>Atheist: Prove to me that God exists!</span></p>\n<p class=\"MsoNormal\"><span>Theist: He obviously exists &ndash; can&rsquo;t you see that plants growing, humans thinking, [insert laundry list here], is all His work?</span></p>\n<p class=\"MsoNormal\"><span>Atheist: Those can easily be explained by evolutionary mechanisms!</span></p>\n<p class=\"MsoNormal\"><span>Theist: Well prove to me that God doesn&rsquo;t exist!</span></p>\n<p class=\"MsoNormal\"><span>Atheist: I don&rsquo;t have to! There may be an invisible pink unicorn baby flying around my head, there is probably not. I can&rsquo;t prove that there is no unicorn, that doesn&rsquo;t mean it exists!</span></p>\n<p class=\"MsoNormal\"><span>Theist: That&rsquo;s just complete <em>reductio ad ridiculo</em>, you could do infrared, polaroid, uv, vacuum scans, and if nothing appears it is statistically unlikely that the unicorn exists! But God is something metaphysical, you can&rsquo;t do that with Him!</span></p>\n<p class=\"MsoNormal\"><span>Atheist: Well Nietzsche killed metaphysics when he killed God. God is dead!</span></p>\n<p class=\"MsoNormal\"><span>Theist: That is just words without argument. Can you actually&hellip;..</span></p>\n<p class=\"MsoNormal\"><span>As one can see, the biggest problem is determining <strong><em>burden of proof</em></strong>.<span>&nbsp; </span>Statistically speaking, this is much like the problem of defining the null hypothesis. </span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>A theist would define: H<sub>0</sub> : God exists. H<sub>a</sub>: God does not exist.</span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>An atheist would define: H<sub>0</sub>: God does not exist. H<sub>a</sub> God does exist.</span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>Both conclude that there is no significant evidence hinting at H<sub>a</sub> over H&shy;<sub>0</sub>. Furthermore, <em>and this is key</em>, they both <span style=\"text-decoration: underline;\">accept the null hypothesis. </span>The correct statistical term for the proper conclusion if insignificant evidence exists for the acceptance of the alternate hypothesis is that one <em>fails to reject</em> the null hypothesis. However, human intuition fails to grasp this concept, and think in black and white, and instead we tend to <em>accept </em>the null hypothesis. </span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>This is not so much a problem with statistics as it is with human intuition. Statistics usually take this form because simultaneous 100+ hypothesis considerations are taxing on the human brain. Therefore, we think of hypotheses to be <em>defended</em> or <em>attacked, but not considered neutrally</em>. </span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>Considered a Bayesian outlook on this problem.</span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>There are two possible outcomes: At least one deity exists(D). No deities exist(N).</span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>Let us consider the natural evidence (Let&rsquo;s call this E) before us.</span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>P(D+N) = 1. P[(D+N)|E] = 1. P(D|E) + P(N|E) = 1. P(D|E) = 1- P(N|E).</span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>Although the calculation of the prior probability of the probability of god existing is rather strange, and seems to reek of bias, I still argue that this is a better system of analysis than just the classical H<sub>0</sub> and H<sub>a</sub>, because it effectively compares the probability of D and N with no bias inherent in the brain&rsquo;s perception of the system.</span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>Example such as these, I believe, show the flaws that result from faulty interpretations of the classical system. If instead we introduced a Bayesian perspective &ndash; the faulty interpretation would vanish. </span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>This is a case for the expanded introduction of Bayesian probability theory. Even if cannot be applied correctly to every problem, even if it is apparently more complicated than the standard method they teach in statistics class ( I disagree here), it teaches people to analyze situations from a more objective perspective. </span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>And if we can avoid Truth-seekers going awry due to simple biases such as those mentioned above, won&rsquo;t we be that much closer to finding Truth?<br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 12pt;\"><span>&nbsp;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HfA6d9neFPhbTvgTH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -1, "extendedScore": null, "score": 7.04847087226537e-07, "legacy": true, "legacyId": "6914", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T01:13:35.570Z", "modifiedAt": null, "url": null, "title": "Things That Shouldn't Need Pointing Out", "slug": "things-that-shouldn-t-need-pointing-out", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:04.703Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XDjiHqyy6vhHG4BEG/things-that-shouldn-t-need-pointing-out", "pageUrlRelative": "/posts/XDjiHqyy6vhHG4BEG/things-that-shouldn-t-need-pointing-out", "linkUrl": "https://www.lesswrong.com/posts/XDjiHqyy6vhHG4BEG/things-that-shouldn-t-need-pointing-out", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Things%20That%20Shouldn't%20Need%20Pointing%20Out&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThings%20That%20Shouldn't%20Need%20Pointing%20Out%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXDjiHqyy6vhHG4BEG%2Fthings-that-shouldn-t-need-pointing-out%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Things%20That%20Shouldn't%20Need%20Pointing%20Out%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXDjiHqyy6vhHG4BEG%2Fthings-that-shouldn-t-need-pointing-out", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXDjiHqyy6vhHG4BEG%2Fthings-that-shouldn-t-need-pointing-out", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 160, "htmlBody": "<p>Today I learned that you can toast marshmallows in the oven.</p>\n<p>By \"learned\", I mean \"I read a recipe which included as a step toasting marshmallows in the oven\".&nbsp; I didn't have to try it out to realize that this would <em>obviously work</em>.&nbsp; It was plain as soon as I heard the idea.&nbsp; And it shouldn't have needed pointing out.&nbsp; I know how ovens work.&nbsp; I am familiar with the marshmallow species of food.&nbsp; I <em>love</em> roasted marshmallows while hating them in most other forms and often occurrently lament the difficulty of arranging open flames over which one may safely toast them.&nbsp; I routinely try new things in the kitchen to get results I want.</p>\n<p>And yet I read it, and was surprised.&nbsp; And so were the people I reported this finding to.&nbsp; It needed pointing out.</p>\n<p>What other facts need pointing out, although they are plain on inspection?&nbsp; What is the pattern behind these facts and a good way to find more?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XDjiHqyy6vhHG4BEG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 40, "extendedScore": null, "score": 7.04873272763175e-07, "legacy": true, "legacyId": "6915", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T02:37:59.986Z", "modifiedAt": null, "url": null, "title": "How can I make money?", "slug": "how-can-i-make-money", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:08.488Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qCoKkY3ms4RdBqrs4/how-can-i-make-money", "pageUrlRelative": "/posts/qCoKkY3ms4RdBqrs4/how-can-i-make-money", "linkUrl": "https://www.lesswrong.com/posts/qCoKkY3ms4RdBqrs4/how-can-i-make-money", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20can%20I%20make%20money%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20can%20I%20make%20money%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqCoKkY3ms4RdBqrs4%2Fhow-can-i-make-money%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20can%20I%20make%20money%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqCoKkY3ms4RdBqrs4%2Fhow-can-i-make-money", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqCoKkY3ms4RdBqrs4%2Fhow-can-i-make-money", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p>Hey everyone,</p>\r\n<p>I'd like too see if I can&nbsp;utilize the&nbsp;rational powers&nbsp;of Less Wrong</p>\r\n<p>Currently I work full time. Am well paid for my age. Have approximately $20,000 AU in savings.</p>\r\n<p>My spouse is in uni. Will finish this year and begin working next year. But currently I am supporting our household.</p>\r\n<p>I have recently concluded that $20k is too much to be sitting idle, and the rational thing to do would be to find a way of putting those savings to work in some fashion. But how?</p>\r\n<p>What would be the best way of utilizing these finances in terms of self-development and/or monetary return?</p>\r\n<p>A few things to consider:</p>\r\n<p>a) My skillset at the moment is limited, but I am eager to learn anything.</p>\r\n<p>b) I only desire money in that it enables me to carry out many plans that would be difficult otherwise.</p>\r\n<p>c) Relationships are far more important to me than money, however money is still pretty high up there.</p>\r\n<p>&nbsp;</p>\r\n<p>I come to Less Wrong because it is the only community whose advice I would trust. The rest of the internet as many scammers, most friends and family feel threatened by the idea of investment/new things etc. Also they just aren't as rational as Less Wrong.</p>\r\n<p>I would be so appreciative of any advice given.</p>\r\n<p>&nbsp;</p>\r\n<p>Also anyone in the same boat?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qCoKkY3ms4RdBqrs4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 15, "extendedScore": null, "score": 7.048968748725234e-07, "legacy": true, "legacyId": "6920", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T06:28:56.928Z", "modifiedAt": null, "url": null, "title": "Looking for companies affiliated with transhumanism", "slug": "looking-for-companies-affiliated-with-transhumanism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:31.980Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/t97r9voozdFqaYacZ/looking-for-companies-affiliated-with-transhumanism", "pageUrlRelative": "/posts/t97r9voozdFqaYacZ/looking-for-companies-affiliated-with-transhumanism", "linkUrl": "https://www.lesswrong.com/posts/t97r9voozdFqaYacZ/looking-for-companies-affiliated-with-transhumanism", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Looking%20for%20companies%20affiliated%20with%20transhumanism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALooking%20for%20companies%20affiliated%20with%20transhumanism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft97r9voozdFqaYacZ%2Flooking-for-companies-affiliated-with-transhumanism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Looking%20for%20companies%20affiliated%20with%20transhumanism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft97r9voozdFqaYacZ%2Flooking-for-companies-affiliated-with-transhumanism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft97r9voozdFqaYacZ%2Flooking-for-companies-affiliated-with-transhumanism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 201, "htmlBody": "<p>I want to make a list of companies that are affiliated with transhumanism. I'm looking for companies pursuing transhumanist goals (ex: VR, gene sequencing) or built by transhumanists themselves (ex: arguably Elon Musk).</p>\n<p>What places do you know of? Which look like cool places to work? Extra points if you've worked there.</p>\n<p>Aside from my personal reasons for seeking those companies (internships, research for future projects), I think a list of transhumanist companies will be a good thing to keep around for other future endeavors.</p>\n<p>Also: The Seasteading Institute, SIAI, <a href=\"http://www.kickstarter.com/projects/1040581998/biocurious-a-hackerspace-for-biotech-the-community\">BioCurious</a>, etc are all incredibly cool, but I'm not looking for non-profits.&nbsp;</p>\n<p><span style=\"text-decoration: underline;\">My list so far:</span></p>\n<ul>\n<li>The obvious ones to start with are anything connected with <a href=\"http://en.wikipedia.org/wiki/Peter_Thiel\">Peter Thiel</a>&nbsp;and the Founders' Fund.</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Tesla_motors\">Tesla Motors</a> and <a href=\"http://en.wikipedia.org/wiki/Spacex\">SpaceX</a> are projects of&nbsp;<a href=\"http://en.wikipedia.org/wiki/Elon_musk\">Elon Musk</a>. Tesla Motors is making electric cars and SpaceX is chasing private space flight.</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Luke_Nosek\">Luke Nosek</a>, who worked on PayPal with Elon Musk, has started a company called <a href=\"http://halcyonmolecular.com/\">Halcyon Molecular</a> and is also connected with <a href=\"http://en.wikipedia.org/wiki/Pathway_Genomics\">Pathway Genomics</a>. The first does gene sequencing, the second&nbsp;offers personal genetics reports.</li>\n<li><a href=\"http://novamente.net/\">Novamente LLC</a> is working on \"intelligent virtual agents for virtual worlds, computer games, and simulations.\" <a href=\"http://en.wikipedia.org/wiki/Ben_Goertzel\">Ben Goertzel</a> leads it.</li>\n</ul>\n<p>What am I missing?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "t97r9voozdFqaYacZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 3, "extendedScore": null, "score": 7.049625065580708e-07, "legacy": true, "legacyId": "6932", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T14:53:05.925Z", "modifiedAt": null, "url": null, "title": "Publishing industry contacts, anyone?", "slug": "publishing-industry-contacts-anyone", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:33.017Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R2c92TWL4EuypyGjm/publishing-industry-contacts-anyone", "pageUrlRelative": "/posts/R2c92TWL4EuypyGjm/publishing-industry-contacts-anyone", "linkUrl": "https://www.lesswrong.com/posts/R2c92TWL4EuypyGjm/publishing-industry-contacts-anyone", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Publishing%20industry%20contacts%2C%20anyone%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APublishing%20industry%20contacts%2C%20anyone%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR2c92TWL4EuypyGjm%2Fpublishing-industry-contacts-anyone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Publishing%20industry%20contacts%2C%20anyone%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR2c92TWL4EuypyGjm%2Fpublishing-industry-contacts-anyone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR2c92TWL4EuypyGjm%2Fpublishing-industry-contacts-anyone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 263, "htmlBody": "<p>I finished a novel last September, did most of the editing over Christmas, and have been procrastinating ever since. My novel has significant rationalist themes and would probably be of interest to a number of people here. Below is a plot synopsis. If you would be interesting in reading it, send me a private message with your email address and I can email you the Word file. I am still acceptiong editing suggestions.</p>\r\n<p>Also, if anyone has suggestions as to where I could submit it, that would be very helpful.</p>\r\n<p>&nbsp;</p>\r\n<p>Plot Synopsis: After the Flood</p>\r\n<p>Ten-year-old Ash lives with a band&nbsp;of&nbsp;orphans&nbsp;in the flooded remains of a 21st-century city, where they live by diving for salvage in submerged buildings and trading it to adults in the mainland city.&nbsp;One day, when&nbsp;she&nbsp;watches a stranger attempting&nbsp;to climb the Wall, a mysterious and impregnable structure in the flooded city, he is injured and she saves his life. He claims that there are people living in the Wall, people who still have the knowledge and power that were lost during the long-ago flood.</p>\r\n<p>Armed with her determination and cunning mind, Ash manages to break into the Wall and obtain medicine for the boy's sister, who is dying of tuberculosis. In the mainland city, however, the boy's parents are captured by the Church of Candles, which controls the city, and executed for their attempt to use the old knowledge.</p>\r\n<p>Six years later, now a young&nbsp;adult apprenticed to a herb-woman on the outskirts of the city, Ash meets the brother and sister again and continues searching for the truth about the flood and the city's past.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R2c92TWL4EuypyGjm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.051052037909415e-07, "legacy": true, "legacyId": "6935", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T17:25:40.786Z", "modifiedAt": null, "url": null, "title": "Sequence exercises/ reruns coordination?", "slug": "sequence-exercises-reruns-coordination", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B9MDXMC7WF8P87fu9/sequence-exercises-reruns-coordination", "pageUrlRelative": "/posts/B9MDXMC7WF8P87fu9/sequence-exercises-reruns-coordination", "linkUrl": "https://www.lesswrong.com/posts/B9MDXMC7WF8P87fu9/sequence-exercises-reruns-coordination", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sequence%20exercises%2F%20reruns%20coordination%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASequence%20exercises%2F%20reruns%20coordination%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB9MDXMC7WF8P87fu9%2Fsequence-exercises-reruns-coordination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sequence%20exercises%2F%20reruns%20coordination%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB9MDXMC7WF8P87fu9%2Fsequence-exercises-reruns-coordination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB9MDXMC7WF8P87fu9%2Fsequence-exercises-reruns-coordination", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 15, "htmlBody": "<p>I'm not involved in either effort, but it would upvote any coordination between the two.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B9MDXMC7WF8P87fu9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 7.05148401185207e-07, "legacy": true, "legacyId": "6936", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T17:30:39.444Z", "modifiedAt": null, "url": null, "title": "Rationalist (well, skeptic, at least) webcomic.", "slug": "rationalist-well-skeptic-at-least-webcomic", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:34.204Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aCsFt6zymMTqRg4fR/rationalist-well-skeptic-at-least-webcomic", "pageUrlRelative": "/posts/aCsFt6zymMTqRg4fR/rationalist-well-skeptic-at-least-webcomic", "linkUrl": "https://www.lesswrong.com/posts/aCsFt6zymMTqRg4fR/rationalist-well-skeptic-at-least-webcomic", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20(well%2C%20skeptic%2C%20at%20least)%20webcomic.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20(well%2C%20skeptic%2C%20at%20least)%20webcomic.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaCsFt6zymMTqRg4fR%2Frationalist-well-skeptic-at-least-webcomic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20(well%2C%20skeptic%2C%20at%20least)%20webcomic.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaCsFt6zymMTqRg4fR%2Frationalist-well-skeptic-at-least-webcomic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaCsFt6zymMTqRg4fR%2Frationalist-well-skeptic-at-least-webcomic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 24, "htmlBody": "<p><a href=\"http://www.mysterysolvedcomic.com\">Mystery Solved</a>&nbsp;is more or less a webcomic about a gentleman adventurer/debunker.</p>\n<p>&nbsp;</p>\n<p>I came across it earlier today and I figured some here might be amused.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aCsFt6zymMTqRg4fR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 4, "extendedScore": null, "score": 7.051498104788263e-07, "legacy": true, "legacyId": "6937", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T18:52:13.827Z", "modifiedAt": null, "url": null, "title": "Reading Nonfiction Selectively", "slug": "reading-nonfiction-selectively", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:34.746Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bo5fAmpJNWGzkQzRn/reading-nonfiction-selectively", "pageUrlRelative": "/posts/bo5fAmpJNWGzkQzRn/reading-nonfiction-selectively", "linkUrl": "https://www.lesswrong.com/posts/bo5fAmpJNWGzkQzRn/reading-nonfiction-selectively", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reading%20Nonfiction%20Selectively&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReading%20Nonfiction%20Selectively%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbo5fAmpJNWGzkQzRn%2Freading-nonfiction-selectively%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reading%20Nonfiction%20Selectively%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbo5fAmpJNWGzkQzRn%2Freading-nonfiction-selectively", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbo5fAmpJNWGzkQzRn%2Freading-nonfiction-selectively", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 777, "htmlBody": "<p>This post is intended to be conversational. I'm noticing something about myself and changing it; take it for what you will.</p>\n<p>I read quickly; about two and a half times as fast as I read it aloud. A more useful number might be a page a minute, but that's obviously subject to massive uncertainty. I've also read a lot of books in my life- many of them were fiction, but for the last several years it's been mostly nonfiction.</p>\n<p>I have the feeling that I should read every word of a book. That's only half-true; as far as I can tell, I often don't read every word of a <em>paragraph</em>. But glancing at a paragraph and guessing its meaning is a far cry from writing off a lump of text as not worth my time. I suspect that's a habit from fiction reading- every paragraph is there because it's pleasant or it advances the story, and the story is far more valuable as a whole than as a series of disconnected events. But with nonfiction reading, the value of different paragraphs is massively variable. <a href=\"http://www.amazon.com/Conflict-Visions-Ideological-Political-Struggles/dp/0465002056/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1303408365&amp;sr=1-1\">A Conflict of Visions</a>, for example, is a massively insightful and valuable book. But I got the feeling when I read it that there was a lot of repetition and reiteration; to me, the first two chapters (35 pages) had about 90% of the value of the book (263 pages). If I had known to just read those pages and stop, I could have gotten 90% of the value for 13% of the time, and saved myself almost four hours.</p>\n<p>(As an aside, I suspect this is one of the reasons blogs posts can be so valuable- many ideas only need a few pages to express, and books simply cannot be 30 pages long. Either you don't publish it, or you extend it to ten times the size.)</p>\n<p>And yet, it is <em>hard</em> to take advantage of this. I'm familiar with the 80/20 principle (and, with the case of A Conflict of Visions, it was more extreme at 90/13) but there's the fear that I'll miss some gem, or won't fully understand the ideas if I don't read all the pieces. And so I do read many of my nonfiction books cover to cover. But the main thing I'm cultivating is a <em>willingness to skip</em>, not just words in a sentence, but paragraphs, pages, or even <em>chapters</em>. The main test I'm using is whether or not I want to read the sentence I'm reading right now. If I feel the least bit of disinterest, I flip ahead. (If I find I missed something, I can always flip back, and at this stage I suspect I'm so ignorant of my interest that if I've noticed my disinterest, it's serious enough.) And so those books I read cover to cover (at least, didn't skip any paragraphs) are the books that were fascinating the whole way through, not just any book I put my hands on.</p>\n<p>At the moment, I just finished <a href=\"http://www.amazon.com/Somatics-Reawakening-Control-Movement-Flexibility/dp/0738209570/ref=sr_1_1?ie=UTF8&amp;qid=1303410042&amp;sr=8-1\">Somatic</a><a href=\"http://www.amazon.com/Somatics-Reawakening-Control-Movement-Flexibility/dp/0738209570/ref=sr_1_1?ie=UTF8&amp;qid=1303410042&amp;sr=8-1\">s</a> (recommended by NancyLebovitz <a href=\"/lw/20l/ureshiku_naritai/2lg9\">here</a>, with a link to a free, mostly complete version) and am reading <a href=\"http://www.amazon.com/Awareness-Through-Movement-Easy---Do/dp/0062503227/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1303410148&amp;sr=1-1\">Awareness Through Movement</a>. I've found myself skipping substantial parts of the second one, for a few reasons:</p>\n<p>1. It's well-organized. Each few paragraphs is introduced by a header that often will tell me I want to skip that section (either because the summary is sufficient or the content isn't worth it). The atomic nature of this- every few paragraphs instead of every few pages or every chapter- really helps because it's much easier to feel comfortable rejecting 3 paragraphs than 30 pages (what if one of those pages contains the best idea of the book?).</p>\n<p>2. The author has a focus that is frequently different from mine. Many sections stress self-image, self-education, man's relationship to society, and other things that simply aren't why I'm reading this book. When I figure out he's going to talk about that for a while, I can go ahead and rejoin him when he's talking to me again.</p>\n<p>3. I just read a book on a similar subject, and feel more comfortable separating useful and useless, especially since I've got a narrow definition of use. I want to develop my personal awareness and control over my muscles and posture, and the subgoal is extracting information to aid that goal from this book.</p>\n<p>Suggestion: when you read a piece of nonfiction, have a goal in mind. If that goal is \"eat up time,\" well, read everything! If that goal is \"learn about X\" then you may want to do some planning. The table of contents is your friend, and one that before this I've only used to measure the length of chapters.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bo5fAmpJNWGzkQzRn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "6938", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T19:18:16.923Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] ...What's a bias, again?", "slug": "seq-rerun-what-s-a-bias-again", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:30.927Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fbAp3YYRdGWGLgPdi/seq-rerun-what-s-a-bias-again", "pageUrlRelative": "/posts/fbAp3YYRdGWGLgPdi/seq-rerun-what-s-a-bias-again", "linkUrl": "https://www.lesswrong.com/posts/fbAp3YYRdGWGLgPdi/seq-rerun-what-s-a-bias-again", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20...What's%20a%20bias%2C%20again%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20...What's%20a%20bias%2C%20again%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfbAp3YYRdGWGLgPdi%2Fseq-rerun-what-s-a-bias-again%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20...What's%20a%20bias%2C%20again%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfbAp3YYRdGWGLgPdi%2Fseq-rerun-what-s-a-bias-again", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfbAp3YYRdGWGLgPdi%2Fseq-rerun-what-s-a-bias-again", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 153, "htmlBody": "<p>Today's post, <a href=\"/lw/gp/whats_a_bias_again/\">...What's a bias, again?</a> was originally published on 27 November 2006. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>\n<p>Biases are obstacles to truth seeking caused by one's own mental machinery.</p>\n</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was</em>&nbsp; <a href=\"/lw/go/why_truth_and\">Why truth? And...</a><em> and you can use the <a href=\"/r/discussion/tag/sequence_reruns\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fbAp3YYRdGWGLgPdi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 7.051802831278929e-07, "legacy": true, "legacyId": "6939", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jnZbHi873v9vcpGpZ", "YshRbqZHYFoEMqFAu", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-21T21:35:31.080Z", "modifiedAt": null, "url": null, "title": "Ottawa LW Meetup: Thursday April 28, 7:00pm (ADDED: Bayes study group satellite meeting)", "slug": "ottawa-lw-meetup-thursday-april-28-7-00pm-added-bayes-study", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:09.336Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ufsdiCCJtvmbnaijW/ottawa-lw-meetup-thursday-april-28-7-00pm-added-bayes-study", "pageUrlRelative": "/posts/ufsdiCCJtvmbnaijW/ottawa-lw-meetup-thursday-april-28-7-00pm-added-bayes-study", "linkUrl": "https://www.lesswrong.com/posts/ufsdiCCJtvmbnaijW/ottawa-lw-meetup-thursday-april-28-7-00pm-added-bayes-study", "postedAtFormatted": "Thursday, April 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ottawa%20LW%20Meetup%3A%20Thursday%20April%2028%2C%207%3A00pm%20(ADDED%3A%20Bayes%20study%20group%20satellite%20meeting)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOttawa%20LW%20Meetup%3A%20Thursday%20April%2028%2C%207%3A00pm%20(ADDED%3A%20Bayes%20study%20group%20satellite%20meeting)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufsdiCCJtvmbnaijW%2Fottawa-lw-meetup-thursday-april-28-7-00pm-added-bayes-study%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ottawa%20LW%20Meetup%3A%20Thursday%20April%2028%2C%207%3A00pm%20(ADDED%3A%20Bayes%20study%20group%20satellite%20meeting)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufsdiCCJtvmbnaijW%2Fottawa-lw-meetup-thursday-april-28-7-00pm-added-bayes-study", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufsdiCCJtvmbnaijW%2Fottawa-lw-meetup-thursday-april-28-7-00pm-added-bayes-study", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><strong>Less Wrong meeting:</strong></p>\n<p>Date: Thursday April 28, 7:00pm until at least 9:00pm.</p>\n<p>Venue: 347 Preston St., cafe seating behind the security desk.</p>\n<p><strong>Bayes study group:&nbsp;</strong>Anyone in the region interested in learning how to do Bayesian statistics is welcome to join us. High school algebra and calculus are the prerequisites for Bayes, but if you don't know them, I'll be happy to teach them to you.&nbsp;</p>\n<p>Date: Tuesday April 26, 9:00pm to 10:00pm.</p>\n<p>Venue: 347 Preston St., cafe seating behind the security desk.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ufsdiCCJtvmbnaijW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 7.05219143263884e-07, "legacy": true, "legacyId": "6941", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T02:37:08.383Z", "modifiedAt": null, "url": null, "title": "The Black Team - A Parable of Group Effectiveness", "slug": "the-black-team-a-parable-of-group-effectiveness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:58.660Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4Yws8Q5PskgvQqs5G/the-black-team-a-parable-of-group-effectiveness", "pageUrlRelative": "/posts/4Yws8Q5PskgvQqs5G/the-black-team-a-parable-of-group-effectiveness", "linkUrl": "https://www.lesswrong.com/posts/4Yws8Q5PskgvQqs5G/the-black-team-a-parable-of-group-effectiveness", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Black%20Team%20-%20A%20Parable%20of%20Group%20Effectiveness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Black%20Team%20-%20A%20Parable%20of%20Group%20Effectiveness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yws8Q5PskgvQqs5G%2Fthe-black-team-a-parable-of-group-effectiveness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Black%20Team%20-%20A%20Parable%20of%20Group%20Effectiveness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yws8Q5PskgvQqs5G%2Fthe-black-team-a-parable-of-group-effectiveness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yws8Q5PskgvQqs5G%2Fthe-black-team-a-parable-of-group-effectiveness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<blockquote>\n<p>Management noticed that certain software                testers were 10 to 20 percent better at finding defects than their                peers. By putting these people on the same team, they reasoned,                they could form a group that would be 10 or 20 percent more effective                and then put the team to work testing the most critical system components.</p>\n<p>It didn't turn out that way.</p>\n<p>The individuals who made up the team were not exceptionally intelligent                or talented, but they all enjoyed testing software and were better                than average at it. When these like minded individuals were assembled,                they they spent their working hours, lunches and sometimes free                time collaborating on how to better find software defects.</p>\n<p>Soon the members of team were twice and then dozens of times more                effective than their peers, and they began to view their jobs not                as testing software, but as breaking software. Team members took                a well-deserved pride in their abilities and began to cultivate                an image of villainous destroyers. As a group, they began coming                to work dressed in black and took to calling themselves \"The                Black Team.\"</p>\n</blockquote>\n<p>From <a href=\"http://www.t3.org/tangledwebs/07/tw0706.html\">The Black Team</a>. (Hat tip to Adam \"ata\" Atlas and Mike Blume.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4kQXps8dYsKJgaayN": 1, "HFou6RHqFagkyrKkW": 1, "zv7v2ziqexSn5iS9v": 1, "x6evH6MyPK3nxsoff": 1, "uL87Bw3TKzsYFMpZp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4Yws8Q5PskgvQqs5G", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}], "voteCount": 40, "baseScore": 60, "extendedScore": null, "score": 0.00013314234041543417, "legacy": true, "legacyId": "6942", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 47, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T06:05:34.902Z", "modifiedAt": null, "url": null, "title": "Gary Johnson - the best presidential candidate for rationalists?", "slug": "gary-johnson-the-best-presidential-candidate-for", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:33.025Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BwuGe3ELy89etNYrf/gary-johnson-the-best-presidential-candidate-for", "pageUrlRelative": "/posts/BwuGe3ELy89etNYrf/gary-johnson-the-best-presidential-candidate-for", "linkUrl": "https://www.lesswrong.com/posts/BwuGe3ELy89etNYrf/gary-johnson-the-best-presidential-candidate-for", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Gary%20Johnson%20-%20the%20best%20presidential%20candidate%20for%20rationalists%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGary%20Johnson%20-%20the%20best%20presidential%20candidate%20for%20rationalists%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBwuGe3ELy89etNYrf%2Fgary-johnson-the-best-presidential-candidate-for%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Gary%20Johnson%20-%20the%20best%20presidential%20candidate%20for%20rationalists%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBwuGe3ELy89etNYrf%2Fgary-johnson-the-best-presidential-candidate-for", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBwuGe3ELy89etNYrf%2Fgary-johnson-the-best-presidential-candidate-for", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 377, "htmlBody": "<p><a href=\"http://www.weeklystandard.com/print/blogs/meet-gary-johnson-ron-paul-2012_520775.html?page=2\">http://www.weeklystandard.com/print/blogs/meet-gary-johnson-ron-paul-2012_520775.html?page=2</a></p>\n<p>So, he just announced his plans to run for president. While I realize that he has no chance at winning the nomination, I was quite astonished to see how rational he is.</p>\n<p>For one thing, he had a \"philosophy of looking at all things for their cost-benefit ratio and his axe fell on Republicans as well as Democrats\". I don't know any other politician who even mentions cost-benefit ratios, since many politicans have to cater to their special interests with very high cost-benefit ratios. Of course, there are many cases when the ratios are very uncertain (innovation in particular), but there are numerous current policies that have blatantly high ratios.</p>\n<p>For another thing, he's simply beyond the tribal mind moral-ideological crusades that characterize much of the left and right (\"X deserves Y, thus we SHOULD give Y to X irrespective of whether it will work or not\"). I'm not going to mention most of his particular policies (as many of them may be debated), but what was particularly important for me was that he believes that global warming does exist and that it is man-made, but at the same time, he is skeptical of the efficacy of currently-popular emission-reduction programs (global warming denialism makes me automatically want to strike any name off the list). But I'll just say that I really respect his positions on school vouchers, all the major social issues (I especially respect his nuanced position to overturn Roe vs Wade based on state's rights, while still supporting the right to an abortion, although I may not entirely agree with it), and his desire to aggressively slash entitlement spending. He also distances himself from the hardcore Ayn Rand fans (he is even understanding of humanitarian interventionism at times) and does not buy into the conspiracy theories that Ron Paul gave credence to. In particular, his positions seem closest to the positions you can read at&nbsp;<a href=\"http://www.triplenine.org/poll/index.html\">http://www.triplenine.org/poll/index.html</a>. I'm not as hardcore libertarian as others, as my preference ranking goes along the lines of \"certain types of rational government\" &gt; libertarianism &gt; current government</p>\n<p>Anyways, I'm just curious to see how other LWers perceive him and his policies. Of course, the most rational politician may have to pretend to be irrational at times, if he has to get things to work.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BwuGe3ELy89etNYrf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -18, "extendedScore": null, "score": -9e-06, "legacy": true, "legacyId": "6949", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T10:42:32.743Z", "modifiedAt": null, "url": null, "title": "anchoring for coordination", "slug": "anchoring-for-coordination", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:34.178Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sark", "createdAt": "2010-01-20T20:18:10.889Z", "isAdmin": false, "displayName": "sark"}, "userId": "cJYNhyCitpdzsZqeP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WMGFe3EESA2wZaLyF/anchoring-for-coordination", "pageUrlRelative": "/posts/WMGFe3EESA2wZaLyF/anchoring-for-coordination", "linkUrl": "https://www.lesswrong.com/posts/WMGFe3EESA2wZaLyF/anchoring-for-coordination", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20anchoring%20for%20coordination&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Aanchoring%20for%20coordination%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWMGFe3EESA2wZaLyF%2Fanchoring-for-coordination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=anchoring%20for%20coordination%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWMGFe3EESA2wZaLyF%2Fanchoring-for-coordination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWMGFe3EESA2wZaLyF%2Fanchoring-for-coordination", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 634, "htmlBody": "<p>Reading Schelling's the Strategy of Conflict, a useful social purpose for anchoring occurred to me.\n<p>First some background.</p>\n<p>You and your husband/wife lose each other in the mall. The two of you have not before this agreed on a place to meet in case you lose each other. Still, there is a good chance both of you would decide to meet up at some salient/prominent place, say the main information desk. This is coordination without communication and with aligned interests.</p>\n<p>You and your partner/rival are independently given the choice of \"Heads\" or \"Tails\". Neither knows the choice of the other. If both of you choose \"Heads\" you'll get $1 and your opponent $3. If both of you choose \"Tails\", you'll get $3 and your opponent $1. Otherwise neither of you gets anything. Most pairs would coordinate on \"Heads\" (again because of convention/salience), with the Tails player not insisting on Tails because she has no way to coordinate (arrange for compensation, say) with the Heads player on this. This is coordination without communication and with some conflict of interest. But not <em>total </em>conflict, as they would rather coordinate than get no payment at all.</p>\n<p>Schelling then goes on to consider explicit bargaining situations where there is of course actual communication between the parties deciding on a mutually acceptable outcome. But he notes that even here, \"focal points\" seem to exert a huge influence. Furthermore, these focal points are often quite partial towards the interests of a certain party. Yet often, the 'losing' party still accepts this less than stellar bargaining outcome. For example, a nation conceding some territory because the only prominent landmark permitting a stable division was some river partial to the interests of the other nation.</p>\n<p>He then proceeds to show how explicit bargaining is not so different from the Heads/Tails coordination game. In a bargaining situation, both sides would rather reach agreement than none at all. And there is a range of possible points of agreement, where the 'losing' party would rather concede than forfeit any agreement. But how to decide among these points of potential agreement? A stable point of agreement for an outcome of the bargaining would be one in which neither expects the other to make further concessions. But a party decides if they would concede based on their expectations of the other party's likelihood of conceding. And so it goes back and forth. Hence, Schelling argues, even in explicit bargaining, focal points play an important role in coordinating expectations, and in ensuring that an agreement is reached, to the mutual (if lopsided) benefit of both parties.</p>\n<p>This is where anchoring comes in. The proposal is that, sure, by letting yourself be influenced by a subpar anchor, you are forgoing a much better bargaining outcome for yourself. But this is better than no agreement at all! If you accepted a price from a merchant who proposed high price to set an anchor, it was only because this was a price you were willing to accept before you started bargaining. And if instead the lowest price the merchant would allow was too high, you would simply have rejected the transaction, and perhaps found a better offer from his competitors.</p>\n<p>Anchoring is of course, not limited to such explicit bargaining situations. But then so is the principle of 'focal points'! In many situations throughout life, there are situations where participants share some interests and diverge on others, and where bargaining is not entirely explicit. To coordinate on these at all we require the ability to respond to anchors. Of course, this would only create an incentive to manipulate anchors, and subsequently an incentive to be resistant to such manipulation. But resistance is not total non-susceptibility! If one does not respond to anchors<em> at all</em>, one would be unnecessarily forgoing many mutually beneficial bargaining outcomes, to one's own detriment.</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WMGFe3EESA2wZaLyF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 7.054420734235214e-07, "legacy": true, "legacyId": "6961", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T11:48:48.616Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Proper Use of Humility", "slug": "seq-rerun-the-proper-use-of-humility", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:30.948Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F3EnWH3poQs4mBK3p/seq-rerun-the-proper-use-of-humility", "pageUrlRelative": "/posts/F3EnWH3poQs4mBK3p/seq-rerun-the-proper-use-of-humility", "linkUrl": "https://www.lesswrong.com/posts/F3EnWH3poQs4mBK3p/seq-rerun-the-proper-use-of-humility", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Proper%20Use%20of%20Humility&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Proper%20Use%20of%20Humility%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3EnWH3poQs4mBK3p%2Fseq-rerun-the-proper-use-of-humility%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Proper%20Use%20of%20Humility%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3EnWH3poQs4mBK3p%2Fseq-rerun-the-proper-use-of-humility", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3EnWH3poQs4mBK3p%2Fseq-rerun-the-proper-use-of-humility", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<p>Today's post,<a href=\"/lw/gp/whats_a_bias_again\"></a> <a href=\"/lw/gq/the_proper_use_of_humility/\">The Proper Use of Humility</a> was originally published on 1 December 2006. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>\n<p>There are good and bad kinds of humility. Proper humility is not being selectively underconfident about uncomfortable truths. Proper humility is not the same as social modesty, which can be an excuse for not even trying to be right. Proper scientific humility means not just acknowledging one's uncertainty with words, but taking specific actions to plan for the case that one is wrong.</p>\n</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was</em>&nbsp;&nbsp;<a href=\"/lw/gp/whats_a_bias_again/\">...What's a bias, again?</a><em> and you can use the <a href=\"/r/discussion/tag/sequence_reruns\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F3EnWH3poQs4mBK3p", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 7.054608489410998e-07, "legacy": true, "legacyId": "6962", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jnZbHi873v9vcpGpZ", "GrDqnMjhqoxiqpQPw", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T12:19:36.751Z", "modifiedAt": null, "url": null, "title": "Possible personal implications of the Israeli Hunger-Probation study", "slug": "possible-personal-implications-of-the-israeli-hunger", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:33.199Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "zaph", "createdAt": "2009-03-09T16:48:24.816Z", "isAdmin": false, "displayName": "zaph"}, "userId": "j6gu6vjBnANKCcfsR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7pJQDj5JjSEnuYAzJ/possible-personal-implications-of-the-israeli-hunger", "pageUrlRelative": "/posts/7pJQDj5JjSEnuYAzJ/possible-personal-implications-of-the-israeli-hunger", "linkUrl": "https://www.lesswrong.com/posts/7pJQDj5JjSEnuYAzJ/possible-personal-implications-of-the-israeli-hunger", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Possible%20personal%20implications%20of%20the%20Israeli%20Hunger-Probation%20study&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APossible%20personal%20implications%20of%20the%20Israeli%20Hunger-Probation%20study%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7pJQDj5JjSEnuYAzJ%2Fpossible-personal-implications-of-the-israeli-hunger%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Possible%20personal%20implications%20of%20the%20Israeli%20Hunger-Probation%20study%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7pJQDj5JjSEnuYAzJ%2Fpossible-personal-implications-of-the-israeli-hunger", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7pJQDj5JjSEnuYAzJ%2Fpossible-personal-implications-of-the-israeli-hunger", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 375, "htmlBody": "<p>I'll let <a href=\"/lw/58y/the_bias_you_didnt_expect/\">Psychohistorian</a> provide the set-up, in case the reference is unfamiliar. Anyway, my wife's expecting, and that means many, many tests, ultrasounds, etc. that she ends up going through. She had an ultrasound done yesterday that was a follow-up form one two weeks ago. There was a particular measurement that was \"top normal\" (the doctor's words) that they needed to keep an eye on*. The first ultrasound was done at her OBGYN, the next at the hospital she'll be delivering at.</p>\n<p>It was during the second ultrasound that I noticed the time; it was about 11:35 when the ultrasound tech finished up and called the doctor in. Being-the-probably-over-worried-parent to be that I am, immediately the study jumped into my head. What if the doc's blood sugar is too low? Do doctors make better decisions when they're hungry, because they're more alert, or worse ones, because they're distracted? Was it better that I came in earlier so that the technician was more alert, so that she took better pictures and measurements on the ultrasound?</p>\n<p>Both the doctor and the tech seemed to be very alert and competent, and as the follow up involved a specific measurement, the were very careful of being thorough in checking and rechecking it. The thought about the timing of the visit, though, and meetings with experts in general, is something I've been thinking a lot about since the appointment. I would really like to see a follow-up study in the medical field. In the meantime, I'm trying to consider when the bests times are to schedule appointments.</p>\n<p>All of this is based on what seems to me to be very concrete evidence that people's thinking is affected by their hunger, and that organizational structures don't pay much attention to outcomes related to that. Is this being premature, or overly broad? Are there other factors that could come into play? My main thinking is to stay away from lunchtime and closing time, because those are the two periods where I believe people would be most distracted.</p>\n<p>*\"Top normal\" in this case could also translate to \"low abnormal\", which shows why numbers provide much better means than words in thinking about these things. The baby's fine as of the latest ultrasound, btw (and thanks for asking!)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7pJQDj5JjSEnuYAzJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 7.054695767976127e-07, "legacy": true, "legacyId": "6963", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["L8dB6yoMEWofoeDNt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T13:37:39.166Z", "modifiedAt": null, "url": null, "title": "Sandberg, A. and Bostrom, N. (2011): Machine Intelligence Survey", "slug": "sandberg-a-and-bostrom-n-2011-machine-intelligence-survey", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:22.578Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Pn7w9nNYzkNDv53mm/sandberg-a-and-bostrom-n-2011-machine-intelligence-survey", "pageUrlRelative": "/posts/Pn7w9nNYzkNDv53mm/sandberg-a-and-bostrom-n-2011-machine-intelligence-survey", "linkUrl": "https://www.lesswrong.com/posts/Pn7w9nNYzkNDv53mm/sandberg-a-and-bostrom-n-2011-machine-intelligence-survey", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sandberg%2C%20A.%20and%20Bostrom%2C%20N.%20(2011)%3A%20Machine%20Intelligence%20Survey&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASandberg%2C%20A.%20and%20Bostrom%2C%20N.%20(2011)%3A%20Machine%20Intelligence%20Survey%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPn7w9nNYzkNDv53mm%2Fsandberg-a-and-bostrom-n-2011-machine-intelligence-survey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sandberg%2C%20A.%20and%20Bostrom%2C%20N.%20(2011)%3A%20Machine%20Intelligence%20Survey%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPn7w9nNYzkNDv53mm%2Fsandberg-a-and-bostrom-n-2011-machine-intelligence-survey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPn7w9nNYzkNDv53mm%2Fsandberg-a-and-bostrom-n-2011-machine-intelligence-survey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 174, "htmlBody": "<blockquote>\n<p>As some readers may recall, we had a conference this January about intelligence, and in particular the future of machine intelligence. We did a quick survey among participants about their estimates of when and how human-level machine intelligence would be developed. Now we can announce the results: <a title=\"MI_survey.pdf (application/pdf Object)\" href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0015/21516/MI_survey.pdf\">Sandberg, A. and Bostrom, N. (2011): Machine Intelligence Survey, Technical Report #2011-1, Future of Humanity Institute, Oxford University</a>.</p>\n<p>[...]</p>\n<p>The median estimate of when there will be 50% chance of human level machine intelligence was 2050.</p>\n<p>People estimated 10% chance of AI in 2028, and 90% chance in 2150.</p>\n<p>[...]</p>\n<p>All in all, a small study of a self selected group, so it doesn't prove anything in particular. But it fits in with earlier studies like <a href=\"http://hplusmagazine.com/2010/02/05/how-long-till-human-level-ai/\">Ben Goertzel, Seth Baum, Ted Goertzel, How Long Till Human-Level AI? </a> and <a href=\"http://www.novamente.net/bruce/?p=54\">Bruce Klein, When will AI surpass human-level intelligence?</a> - people who tend to answer this kind of surveys seem to have a fairly similar mental model.</p>\n</blockquote>\n<p><strong>Link:</strong> <a href=\"http://www.aleph.se/andart/archives/2011/04/when_will_we_get_our_robot_overlords.html\">Machine Intelligence Survey</a> (<a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0015/21516/MI_survey.pdf\">PDF</a>)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Pn7w9nNYzkNDv53mm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 7.054916904875572e-07, "legacy": true, "legacyId": "6964", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T15:26:05.968Z", "modifiedAt": null, "url": null, "title": "The Many Worlds of Hugh Everett", "slug": "the-many-worlds-of-hugh-everett", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:38.806Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "johnclark", "createdAt": "2010-12-11T17:45:15.654Z", "isAdmin": false, "displayName": "johnclark"}, "userId": "kKChFZ54eramyAwve", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Yt8YSQCEbLcfFfEY6/the-many-worlds-of-hugh-everett", "pageUrlRelative": "/posts/Yt8YSQCEbLcfFfEY6/the-many-worlds-of-hugh-everett", "linkUrl": "https://www.lesswrong.com/posts/Yt8YSQCEbLcfFfEY6/the-many-worlds-of-hugh-everett", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Many%20Worlds%20of%20Hugh%20Everett&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Many%20Worlds%20of%20Hugh%20Everett%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYt8YSQCEbLcfFfEY6%2Fthe-many-worlds-of-hugh-everett%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Many%20Worlds%20of%20Hugh%20Everett%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYt8YSQCEbLcfFfEY6%2Fthe-many-worlds-of-hugh-everett", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYt8YSQCEbLcfFfEY6%2Fthe-many-worlds-of-hugh-everett", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1764, "htmlBody": "<p>I've just finished this book and its one of the most enjoyable things I've read in a long time. Being a staple of science fiction and the only interpretation of quantum mechanics to enter the popular imagination it's a little surprising that \"The Many Worlds of Hugh Everett\" by Peter Byrne is the first biography of the originator of that amazing idea. Everett certainly had an interesting life, he was a libertarian and a libertine, became a cold warrior who with his top secret clearance was comfortable with the idea of megadeath, became wealthy by started one of the first successful software companies until alcoholism drove him and his company into the ground. Everett died of heart failure in 1982 at the age of 51, he was legally drunk at the time. He requested that his body be cremated and his ashes thrown into the garbage. And so he was.</p>\n<p>Byrne had an advantage other potential biographers did not, the cooperation of his son Mark, a successful rock musician and composer whose music has been featured in such big budget movies as American Beauty, Hellboy, Yes Man, all three of the Shrek movies and many others. Mark gave Byrne full access to his garage which was full of his father's papers that nobody had looked at in decades.</p>\n<p>Everett was an atheist all his life, after his death Paul Davies, who got 1,000,000 pounds for winning the Templeton religion prize, said that if true Many Worlds destroyed the anthropic argument for the existence of God. Everett would have been delighted. Nevertheless Everett ended up going to Catholic University of America near Washington DC. Although Byrne doesn't tell us exactly what was in it, Everett as a freshman devised a logical proof against the existence of God. Apparently it was good enough that one of his pious professors became very upset and depressed with \"ontological horror\" when he read it. Everett liked the professor and felt so guilty he decided not to use it on a person of faith again. This story is very atypical of the man, most of the time Everett seems to care little for the feelings of others and although quite brilliant wasn't exactly lovable.</p>\n<p>Everett wasn't the only one dissatisfied with the Copenhagen Interpretation which insisted the measuring device had to be outside the wave function, but he was unlike other dissidents such as Bohm or Cramer in that Everett saw no need to add new terms to Schrodinger's Equation and thought the equation meant exactly what it said. The only reason those extra terms were added was to try to rescue the single universe idea, and there was no experimental justification for that. Everett was unique in thinking that quantum mechanics gave a description of nature that was literally true.</p>\n<p>John Wheeler, Everett's thesis adviser, made him cut out about half the stuff in his original 137 page thesis and tone down the language so it didn't sound like he thought all those other universes were equally real when in fact he did. For example, Wheeler didn't like the word \"split\" and was especially uncomfortable with talk of conscious observers splitting, most seriously he made him remove the entire chapter on information and probability which today many consider the best part of the work. His long thesis was not published until 1973, if that version had been published in 1957 instead of the truncated Bowdlerized version things would have been different; plenty of people would still have disagreed but he would not have been ignored for as long as he was.</p>\n<p>Byrne writes of Everett's views: \"the splitting of observers share an identity because they stem from a common ancestor, but they also embark on different fates in different universes. They experience different lifespans, dissimilar events (such as a nuclear war perhaps) and at some point are no longer the same person, even though they share certain memory records.\" Everett says that when a observer splits it is meaningless to ask \"which of the final observers corresponds to the initial one since each possess the total memory of the first\" he says it is as foolish as asking which amoeba is the original after it splits into two. Wheeler made him remove all such talk of amoebas from his published short thesis.</p>\n<p>Byrne says Everett did not think there were just an astronomically large number of other universes but rather an infinite number of them, not only that he thought there were a non-denumerable infinite number of other worlds. This means that the number of them was larger than the infinite set of integers, but Byrne does not make it clear if this means they are as numerous as the number of points on a line, or as numerous as an even larger infinite set like the set of all possible clock faces, or maybe an even larger infinity than that where easy to understand examples of that sort of mega-infinite magnitude are hard to come by. Neill Graham tried to reformulate the theory so you'd only need a countably infinite number of branches and Everett at first liked the idea but later rejected it and concluded you couldn't derive probability by counting universes. Eventually even Graham seems to have agreed and abandoned the idea that the number of universes was so small you could count them.</p>\n<p>Taken as a whole Everett's multiverse, where all things happen, probability is not a useful concept and everything is deterministic. However for observers like us trapped in a single branch of the multiverse, observers who do not have access to the entire wave function and all the information it contains but only a small sliver of it, probability is the best we can do. That probability we see is not part of the thing itself but is just a subjective measure of our ignorance.</p>\n<p>Infinity can cause problems in figuring out probability but Everett said his theory could calculate what the probability any event could be observed in any branch of the multiverse, and it turns out to be the Born Rule (discovered by Max Born, grandfather of Olivia Newton John) which means the probability of finding a particle at a point is the squaring of the amplitude of the Schrodinger Wave function at that point. The Born Rule has been shown experimentally to be true but the Copenhagen Interpretation just postulates it, Everett said he could derive it from his theory it \"emerges naturally as a measure of probability for observers confined to a single branch (like our branch)\". He proved the mathematical consistency of this idea by adding up all the probabilities in all the branches of the event happening and getting exactly 100%. Dieter Zeh said Everett may not have rigorously derived the Born Rule but did justify it and showed it \"as being the only reasonable choice for a probability measure if objective reality is represented by the universal wave function [Schrodinger's wave equation]\". Rigorous proof or not that's more than any other quantum interpretation has managed to do.</p>\n<p>Everett wrote to his friend Max Jammer:</p>\n<blockquote>\n<p>\"None of these physicists had grasped what I consider to be the major accomplishment of the theory- the \"rigorous\" deduction of the probability interpretation of Quantum Mechanics from wave mechanics alone. This deduction is just as \"rigorous\" as any deductions of classical statistical mechanics. [...] What is unique about the choice of measure and why it is forced upon one is that in both cases it is the only measure that satisfies the law of conservation of probability through the equations of motion. Thus logically in both classical statistical mechanics and in quantum mechanics, the only possible statistical statements depend upon the existence of a unique measure which obeys this conservation principle.\"</p>\n</blockquote>\n<p>Nevertheless some complained that Everett did not use enough rigor in his derivation. David Deutsch has helped close that rigor gap. He showed that the number of Everett-worlds after a branching is proportional to the conventional probability density. He then used Game Theory to show that all these are all equally likely to be observed. Everett would likely have been delighted as he used Game Theory extensively in his other life as a cold warrior. Professor Deutsch gave one of the best quotations in the entire book, talking about many worlds as a interpretation of Quantum Mechanics \"is like talking about dinosaurs as an interpretation of the fossil record\".</p>\n<p>Everett was disappointed at the poor reception his doctoral dissertation received and never published anything on quantum mechanics again for the rest of his life; instead he became a Dr. Strangelove type character making computer nuclear war games and doing grim operational research for the pentagon about armageddon. He was one of the first to point out that any defense against intercontinental ballistic missiles would be ineffectual and building an anti-balistic missile system could not be justified except for \"political or psychological grounds\". Byrne makes the case that Everett was the first one to convince high military leaders through mathematics and no nonsense non sentimental reasoning that a nuclear war could not be won, \"after an attack by either superpower on the other, the majority of the attacked population that survived the initial blasts would be sterilized and gradually succumb to leukemia. Livestock would die quickly and survivors would be forced to rely on eating grains potatoes and vegetables. Unfortunately the produce would be seething with radioactive Strontium 90 which seeps into human bone marrow and causes cancer\". Linus Pauling credited Evert by name and quoted from his pessimistic report in his Nobel acceptance speech for receiving the 1962 Nobel Peace prize.</p>\n<p>Despite his knowledge of the horrors of a nuclear war Everett, like most of his fellow cold warrior colleagues in the 50's and 60's, thought the probability of it happening was very high and would probably happen very soon. Byrne speculates in a footnote that Everett may have privately used anthropic reasoning and thought that the fact we live in a world where such a war has not happened (at least not yet) was more confirmation that his Many Worlds idea was right. Incidentally this is one of those rare books where the footnotes are almost as much fun to read as the main text.</p>\n<p>Hugh's daughter Liz Everett killed herself a few years after her father's death, in her suicide note she said \"Funeral requests: I prefer no church stuff. Please burn be and DON'T FILE ME. Please sprinkle me in some nice body of water or the garbage, maybe that way I'll end up in the correct parallel universe to meet up with Daddy\". And so she was.</p>\n<p style=\"padding-left: 30px;\">John K Clark</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb1c9": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Yt8YSQCEbLcfFfEY6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 28, "extendedScore": null, "score": 7.055224222623458e-07, "legacy": true, "legacyId": "6965", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T17:27:31.834Z", "modifiedAt": null, "url": null, "title": "New movie about infinite universe (and thus, multiple selves)", "slug": "new-movie-about-infinite-universe-and-thus-multiple-selves", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.200Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k9hb3Sg2GXEoJMFp5/new-movie-about-infinite-universe-and-thus-multiple-selves", "pageUrlRelative": "/posts/k9hb3Sg2GXEoJMFp5/new-movie-about-infinite-universe-and-thus-multiple-selves", "linkUrl": "https://www.lesswrong.com/posts/k9hb3Sg2GXEoJMFp5/new-movie-about-infinite-universe-and-thus-multiple-selves", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20movie%20about%20infinite%20universe%20(and%20thus%2C%20multiple%20selves)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20movie%20about%20infinite%20universe%20(and%20thus%2C%20multiple%20selves)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk9hb3Sg2GXEoJMFp5%2Fnew-movie-about-infinite-universe-and-thus-multiple-selves%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20movie%20about%20infinite%20universe%20(and%20thus%2C%20multiple%20selves)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk9hb3Sg2GXEoJMFp5%2Fnew-movie-about-infinite-universe-and-thus-multiple-selves", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk9hb3Sg2GXEoJMFp5%2Fnew-movie-about-infinite-universe-and-thus-multiple-selves", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 8, "htmlBody": "<p><em>Another Earth</em>: <a href=\"http://trailers.apple.com/trailers/fox/anotherearth/\">Trailer</a>.</p>\n<p>Thought some might find this interesting.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k9hb3Sg2GXEoJMFp5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.055568363815675e-07, "legacy": true, "legacyId": "6966", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T19:43:07.029Z", "modifiedAt": null, "url": null, "title": "The benefits of madness: A positive account of arationality", "slug": "the-benefits-of-madness-a-positive-account-of-arationality", "viewCount": null, "lastCommentedAt": "2022-05-28T17:31:45.356Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Skatche", "createdAt": "2011-01-01T21:34:33.025Z", "isAdmin": false, "displayName": "Skatche"}, "userId": "sdFHhNSzievXc7TuM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zPJE7MDtL25RpN7Cc/the-benefits-of-madness-a-positive-account-of-arationality", "pageUrlRelative": "/posts/zPJE7MDtL25RpN7Cc/the-benefits-of-madness-a-positive-account-of-arationality", "linkUrl": "https://www.lesswrong.com/posts/zPJE7MDtL25RpN7Cc/the-benefits-of-madness-a-positive-account-of-arationality", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20benefits%20of%20madness%3A%20A%20positive%20account%20of%20arationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20benefits%20of%20madness%3A%20A%20positive%20account%20of%20arationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzPJE7MDtL25RpN7Cc%2Fthe-benefits-of-madness-a-positive-account-of-arationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20benefits%20of%20madness%3A%20A%20positive%20account%20of%20arationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzPJE7MDtL25RpN7Cc%2Fthe-benefits-of-madness-a-positive-account-of-arationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzPJE7MDtL25RpN7Cc%2Fthe-benefits-of-madness-a-positive-account-of-arationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4287, "htmlBody": "<p>This post originated in a <a href=\"/lw/5a9/learned_blankness/3yq7\">comment</a> I posted about a strange and unpleasant experience I had when pushing myself too hard mentally.&nbsp; People seemed interested in hearing about it, so I sat down to write.&nbsp; In the process, however, it became something rather different (and a great deal longer) than what I originally intended.&nbsp; The incident referred to in the above comment was a case of manic focus gone wrong; but the truth is, often in my life it's gone incredibly <em>right</em>.&nbsp; I've gotten myself into some pretty strange headspaces, but through discipline and quick thinking I have often been able to turn them to my advantage and put them to good use.</p>\n<p>Part 1, then, lays out a sort of cognitive history, focusing on the more extreme states I've been in.&nbsp; Part 2 continues the narrative; this is where I began to learn to ride them out and make them work for me.&nbsp; Part 3 is the incident in question: where I overstepped myself and suffered the consequences.</p>\n<p>Some of you, however, may want to skip ahead to part 4 (unless you find my autobiographical writings interesting as a case study).&nbsp; There, I've written a proposal for a series of posts about how to effectively use the full spectrum of somatic and cognitive states to one's advantage.&nbsp; I have vacillated for a long time about this, for reasons that will be discussed below, but I decided that if I was already laying this much on the line, I might as well take it a step further.&nbsp; Read if you will; and if you're interested, please say so.</p>\n<p><a id=\"more\"></a></p>\n<p><strong>Part 1: My cognitive background</strong></p>\n<p>Let's start with full disclosure: there is madness in my family.&nbsp; My father was an alcoholic; it was clear to all of us that he also had some other psychological issues, but I never fully learned the details.&nbsp; My sister has been variously diagnosed with depression, bipolar, borderline personality disorder, etc, and has a breakdown about three or four times a year.&nbsp; My brother is also bipolar.&nbsp; He's had two manic episodes so far; he became psychotic during the first one, and both times he's been hospitalized.&nbsp; And then there's me: the sane, dependable one.</p>\n<p>That's what I thought, anyway, until my brother had his first episode and I started to look back on my own history.&nbsp; I'd always regarded myself as rather unusual, certainly, but basically stable.&nbsp; But seeing full-blown psychosis for the first time, and within my own family at that, gave new definition and clarity to some of the experiences I had had.&nbsp; My first episode happened when I was in my senior year of high school.&nbsp; I had been getting into New Age for about six months, reading rather credulously the work of one Dr. Joshua David Stone, author of the Ascension Manual and a number of other books inspired primarily by theosophy.&nbsp; I had not thought much about spirituality since renouncing God at the age of twelve, yet a vague unease had led me to begin seeking.&nbsp; Once I got started, I just ate it up; yet the vague unease persisted.&nbsp; I did my best to believe and to perform the meditative exercises, and for the most part I did, but it just wasn't sitting quite right.</p>\n<p>During winter break of that year, I began reading Zen and the Art of Motorcycle Maintenance, by Robert Pirsig.&nbsp; Now, here was something new: Pirsig rejected the analytic method as the sole arbiter of truth, yet he was also clearly uncomfortable with holism and spirituality.&nbsp; In fact, he seemed uncomfortable with all his ideas: they had come to him during a period of degenerating mental illness, culminating in a nervous breakdown and subsequent electroshock therapy.&nbsp; Yet rather than dismiss these ideas, he seemed determined to confront them and grapple with them, to sift for genuine insights among the delusions.&nbsp; Even more interesting was his rhetorical style: rather than simply stating his ideas, as is typical in a philosophical treatise, he would present problems first - present them as problems, really convince the reader that these were questions worth thinking about - and then move on to something else, only proposing solutions several pages later.&nbsp; This forced me to really think, for the first time in what seemed like ages.&nbsp; It was exciting; I couldn't put the book down.</p>\n<p>And this is where the trouble started: I really couldn't put the book down.&nbsp; It was as though the mental stimulation afforded by ZAMM had pushed me over the lip of an energy barrier, and I was now in an incredible downhill rush.&nbsp; My thoughts raced, day and night, about the nature of reality.&nbsp; New Age was the first thing to go: I could hardly believe my own unthinking credulity, and I summarily rejected what Dr. Stone had taught me.&nbsp; I also, however, rejected everything else I had thought I knew, eventually concluding that I wasn't sure if I existed; and then on further examination, unable to find any fundamental ground of reality, I departed from Descartes and concluded that even I did not exist, that all was illusion.</p>\n<p>I began to withdraw, although I felt I was surging with mental energy.&nbsp; For the next few months, I spent most of my time in my room, either staring at nothing and pondering or else writing frantic screeds about philosophical matters.&nbsp; Eventually one of my few remaining social contacts managed to get a grudging confession out of me of my own existence, but I wasn't out of the woods yet.&nbsp; The following months brought paranoia, existential anxiety, delusions of grandeur.&nbsp; It was at its worst during the summer: I began to feel that I was trapped in reality, in some sense, and that there were beings outside the universe - previous escapees - who were sending me telepathic messages in an effort to help me escape as well.&nbsp; I even had one brief moment of hallucination, once: waiting on my bicycle at an intersection, the traffic light shimmered silvery-blue, like an arc of liquid electricity creeping across the surface, and then returned to normal.</p>\n<p>Well, if I had told my family about this, I might have ended up medicated; but I put on a straight face, and I kept my grades up despite the inclination to up and head for the hills, so no one ever really noticed.&nbsp; I think this is why I had never considered this a mental disorder: there was a part of my mind that always kept me in check, making sure to perform all necessary maintenance operations while I lost my shit.&nbsp; Next thing I knew I was in university, doing remarkably well; the sudden change of scenery and the newfound freedom of living in a major city, as well as increased social contact with a variety of new people, seemed to stabilize me.&nbsp; I still maintained an interest in spirituality and the occult, but I had learned my lesson: I regarded everything I read as only a hypothetical, perhaps something to be tested but never to be strongly affirmed.</p>\n<p>And then, just as suddenly as it had come, my energy departed.&nbsp; After a stellar first year, I spent the next several years holed up in my room on my computer, not going to class nor doing much else.&nbsp; Even after I became aware of the problem, I found I could not pull myself out of it, no matter how hard I tried.&nbsp; This all went about as well as you could expect, and I almost got kicked out of school a couple times.</p>\n<p><strong>Part 2: How I learned to stop worrying and use my madness</strong></p>\n<p>My second episode began when my father died, and it never really ended.&nbsp; Our relationship had not been uniformly or even predominantly negative, but it had certainly been complicated, and I felt he held me back in a lot of subtle ways; it was like I was pulling against an elastic tether, and the day he died, it finally snapped.&nbsp; The school term (and my tenancy in the student residence) was just wrapping up at this time, so on a momentary whim I decided to move to another city where some friends of mine lived; within a week I was unpacking in my new room.&nbsp; Said friends were heavily into the occult, particularly the work of Aleister Crowley and assorted characters, who take a (selectively) skeptical approach to occultism, even going so far as to suggest that it is more a tool for self-analysis and self-change than anything else.&nbsp; For the following several months, therefore, I would be inundated with messages of self-improvement and introspective understanding of one's own mind.</p>\n<p>So, possessed with a desperate fervour, I began to practice yoga, meditation and ritual magic, attempting to use them as cognitive levers.&nbsp; At the same time, suddenly deprived of my father's financial support, I struggled to make ends meet, working awful temp labour jobs for minimum wage.&nbsp; At any time I could have packed up and returned to live with my mother, but I dimly perceived a higher presence urging me onward, promising wisdom and power if I could learn self-discipline against difficult odds.&nbsp; During this time, I would occasionally have moments of incredible clarity and expansiveness, overwhelmed by the beauty around me and more strongly aware of invisible presences guiding the events in my life, seemingly benevolent yet somewhat harsh in their methods.&nbsp; Sometimes I would even talk to or argue with myself, addressing darker parts of my psyche as separate entities as described in certain recensions of demonic invocation.</p>\n<p>And yet, this time something was different.&nbsp; This time, I saw exactly how crazy this all was.&nbsp; The solution, then, was simple: I simply did not attach any definite ontological state to what I was experiencing.&nbsp; As long as there was some part of me still grounded in the mundane, refusing to judge these entities as separate intelligences or as aspects of myself or even just as figments of my imagination, I could simply follow them along and evaluate the results.&nbsp; Rather surprisingly, the results were uniformly good: I was learning a great deal about how the world worked as well as my own constitution; the challenges I faced were difficult but surmountable, which boosted my confidence; and my overall life satisfaction dramatically increased.&nbsp; I learned to push through serious discomfort - physical, emotional or mental - if it was beneficial to do so.&nbsp; And I learned how to pay attention to my extremes of mental excitation: how to encourage them, how to use them, and how to keep them in check when necessary.</p>\n<p>Urged on by my visions, I returned to school with new dedication and discipline, which blossomed into a deep and abiding love of mathematics.&nbsp; A year later, it was a vision that compelled me to ride my bicycle from Ontario to Georgia, an incredible and life-changing experience which also introduced me to communal and alternative living as I met people along the way.&nbsp; It was another vision that compelled me to start my own communal house, where I am living happily to this day, and it was yet another vision that caused me to finally sit down and learn physics.&nbsp; And this is only a small selection of the ways in which arational impulses and visionary experiences have improved my life; they've also contributed to the development of my social skills, to my construction of a broad circle of friends and acquaintances, even to my moral development.&nbsp; They've also been highly entertaining: I have something of a penchant for the bizarre and mindbending, after the fashion of Philip K. Dick or David Cronenberg, and it's all the more exciting if it appears to be really happening.</p>\n<p>More interestingly, visionary experiences have often furnished me with new and interesting ideas.&nbsp; In the worst case, these ideas turn out to be totally absurd and useless, and I dismiss them easily, no harm done.&nbsp; In some cases, the ideas are dead ends but for very subtle reasons; in these cases, I often learn a great deal in trying to work them out.&nbsp; But in many cases, the ideas have proven to hold water even after I come down, perhaps after a little revision and formalization.&nbsp; The most recent of these was a game theoretic analysis of the relationship between government and citizen, which may end up as another post.&nbsp; Another time, I had a direct and visceral experience of living in a Tegmark universe, several years before I even heard of the idea - but we'll get to that.</p>\n<p>At any rate, I've benefited a great deal from arational urges verging on madness.&nbsp; But there is one more tale to tell: the time I pushed myself too far off balance and suffered the consequences.</p>\n<p><strong>Part 3: How it turned around and bit me</strong></p>\n<p>This happened a little over two years ago.&nbsp; I had a psychedelic experience (legal highs only, of course) in which it was suggested that I investigate the topology of consciousness.&nbsp; Sounds a little crazy, but as mentioned, I've found a lot of value in the process of wrestling with these kinds of ideas, trying to make them work.&nbsp; Along for the trip was a man I had never met, who would become one of my closest friends.&nbsp; He had studied in some detail biology, physics, scattered mathematics, logic, and a variety of other technical fields.&nbsp; Not knowing what reaction I would get, I started talking to him about my idea.&nbsp; He became excited and began feeding back clever angles I might not have otherwise considered.&nbsp; As the conversation continued we fed off each other, growing more and more animated.&nbsp; Finally I stormed out onto the porch to have a cigarette.&nbsp; My mind was racing; this was the most brilliant idea ever!&nbsp; It was essential that I study this.&nbsp; But how would I support myself?&nbsp; The university was a good bet, but what department would I take it to?&nbsp; Which would be just crazy enough to fund me while I work on something this weird?</p>\n<p>And then all of a sudden something felt terribly wrong.&nbsp; Like metaphysical poison, unbearable dysphoria flowed into my entire being.&nbsp; The strength left my limbs, and I sat down, briefly certain I was going to die.&nbsp; Fortunately I quickly recognized this as an entirely common and much-parodied psychedelic trope, and after confirming that my vital signs were good, I crawled off to the bathroom to lie on the floor until I started to feel better.</p>\n<p>Looking back, I believe what happened was this: although I had gained some experience in effectively managing my more extreme mental states, I was accustomed to doing this in something of a vacuum; I didn't know anyone else who was interested in the things I was interested in.&nbsp; But my new friend acted as an amplifier, and I needed new cognitive tools to recognize the threat and contain myself accordingly.&nbsp; In the meantime, though, I was terribly excited despite the bad trip and determined to begin on the project I had been given.</p>\n<p>I quickly determined that I would need to understand physics better; all I had was Newtonian mechanics supplemented by pop science articles about relativity and quantum physics.&nbsp; So I began to study, with a passion.&nbsp; I bought some textbooks, found a number of physics courses on YouTube - quite a few of them, something like 150-200 hours in total - and began to spend all my free time giving myself a full, if a little sketchy, undergraduate physics education, condensed into about six months.&nbsp; And this was while I was also in university courses.&nbsp; To round it off, I started taking psychedelics on a regular basis.&nbsp; The character of my trips became darker and less euphoric, but they helped me develop richer intuitions for the systems I was learning about, and sometimes suggested new insights.&nbsp; I felt I was making good progress, and so despite feeling that I was stretched a little thin, I pushed further.&nbsp; Meanwhile, I withdrew from everything except school and my project, and the isolation began to take its toll.</p>\n<p>This culminated eventually in my Tegmark vision: I felt I saw the entire mathematical universe, a densely connected fabric of causality with our own universe embedded within it.&nbsp; Deduction, duality, emergence, simulation, and other such operations were seen as directions in this space.&nbsp; I felt there was a kind of knot or defect in the Tegmark space, along the lines of circular causation but vastly more subtle, somehow embedded in the structure of causality itself, and that this was how anything manages to exist in the first place.&nbsp; Needless to say, I threw caution to the wind and redoubled my efforts after this, certain I was approaching a significant discovery.</p>\n<p>And that's when I got swine flu.&nbsp; No joke.</p>\n<p>For three days I was unable to keep anything down but juice and tylenol.&nbsp; My fever was unbearable, and it got so bad at one point that I called 911, worried I might be dying - the one and only time I have ever called them for myself.&nbsp; Worst of all was the delirium: I hallucinated tiny quantum particle interactions, repeated over and over for hours in terrifying slowness and silence.&nbsp; I had visions of plagues sweeping the planet.&nbsp; I realized that this cold, mechanistic empty thing was all there was to reality, and there was not even the benefit of some kind of invisible being revealing this to me; I was just some poor schmuck who had discovered it by accident.</p>\n<p>The fever broke, but for almost a month afterward I was weak and sickly, unable to stand for long without getting dizzy.&nbsp; During this time, I could not bear to think about math or physics or the mind; it triggered a kind of psychic nausea reaction.&nbsp; But the damage had already been done: I felt restless and anxious and desperate even as the physical symptoms abated, and although I was in fact functioning at peak capacity in purely practical matters - driven mainly by a sense of desperation - my social life and my mental wellbeing began to suffer.&nbsp; I started having panic attacks for the first time in my life.&nbsp; I felt like I was being tormented by some demonic influence (figuratively, in this case); life was tolerable at best and harsh and brutal at worst.</p>\n<p>The mental state I had been maintaining, it seems, was a fragile one.&nbsp; It gave me a great deal of energy and dedication, which I was able to use to greatly enrich my understanding of the world, but it relied too heavily on nothing else going wrong in my life.&nbsp; It was like I had been building a tall but flimsy tower on a fault line, and when the earthquake finally hit - in the form of the flu - it all violently collapsed.</p>\n<p>It took a year of  damage control to finally return myself to stability, which takes us close to the present; I remember distinctly a particular day in September when I realized I finally felt completely at ease.&nbsp; In the months since then I have taken great pleasure in pursuing my degree, cultivating a new interest in applied mathematics.&nbsp; The old questions still linger, and I return to them for inspiration, but I take a more relaxed approach to my researches.&nbsp; My friend and I have discussed the feedback loops we get into, and through shared awareness we now keep our oscillations suitably damped.&nbsp; Most importantly, I have learned how to keep myself balanced.&nbsp; I still allow myself to go into ecstatic states, but in short bursts and with frequent breaks.</p>\n<p><strong>Conclusion: A proposal</strong></p>\n<p>I'm told that Bertrand Russell was once asked: \"But haven't you ever had any mystical experiences?\"&nbsp; \"Why, yes,\" he replied, \"I ignored them.\"&nbsp; He had convinced himself, through rigourous argumentation, that there was nothing in the spectrum of supernatural phenomena that stood up to scrutiny; and so when faced with peak experiences, he simply disregarded them as cognitive artefacts and glitches.&nbsp; I'm in no place to disagree with him about the supernatural; I have some finicky ontological and epistemic quibbles with materialism as usually stated, but I regard it as basically correct.&nbsp; I do wonder, though, if he was too extreme in his reaction.</p>\n<p>I won't rehash the usual arguments linking madness and creativity, but I do want to call attention to the link.&nbsp; The consensus on Less Wrong seems to be that spirituality in the experiential sense is a cognitive glitch in and of itself.&nbsp; I suggest, on the contrary, that it is a somewhat glitchy and kludgy tendency nevertheless serving a useful cognitive purpose.&nbsp; I have always been struck by the fact that the revelations and felt presences I have experienced seem just as clever and aware as I am, sometimes even more so.&nbsp; I don't mean to suggest anything supernatural by this; it is more likely that they are personified representations of my own unconscious ability to recognize patterns and solve hard problems.</p>\n<p>The ability to loosen one's associations and build bridges between disparate ideas seems to help us solve problems not amenable to direct, formal computation: to intuit mathematical truths before sitting down to prove them, for example, or to recognize that a pattern seen in one system is reflected in another, totally unrelated system.&nbsp; A state of mental excitation, even to the point of fervour, is also useful for overcoming akrasia, and promotes the quick thinking necessary when you don't have time to sit around and compute.&nbsp; If this is the case, then there is considerable benefit to be had in learning to depart from rationality in a safe and controlled manner.&nbsp; I say safe and controlled because, as we have seen, there are real dangers in overextending oneself; but with proper technique, I believe these dangers can be minimized while still reaping the benefits.</p>\n<p>If Less Wrong is simply about improving our techniques of rationality, then much of our work is already done: the voluminous Sequences encode both the core ideas and many of the consequences of good critical thinking, and we are left quibbling about subtleties of anthropic reasoning and speculating about AI design.&nbsp; If, however, we wish to use every advantage afforded by our mental constitution, then we should be studying ecstasy and passion.&nbsp; In fact, this generalizes to a wide variety of affective states; indeed, there have been some posts mentioning more effective managing of emotions, social skills, and so on, but not many concrete suggestions have been made.&nbsp; This is not surprising: much of the scientific research that has been done on emotions is either about business-as-usual or about treating serious pathologies.</p>\n<p>The truth is, there are in fact techniques out there which seem to work.&nbsp; I'm perhaps an unusual case in that I already had some extreme cognitive states to work with, but these techniques have served me well, and they also seem to have worked well for other friends of mine who have tried them.&nbsp; Nevertheless, I've been reluctant to post them, for one major reason: they're cranky as hell.&nbsp; Many of them come from spiritual, religious or occult sources, and it can be a little tricky to tease apart the techniques from the metaphysical beliefs (the best case, perhaps, is the Buddhist system, which holds (roughly) that the unenlightened mind can't truly understand reality anyway, so you'd best just shut up and meditate).&nbsp; Nevertheless, these traditions have decades or even centuries of experience in inducing altered states of consciousness, and with a good cognitive hazmat suit we can pick out really effective techniques among the more fanciful detritus.</p>\n<p>So, with little to lose, I'm putting this out there: I have a fair bit of experience with this sort of thing, and I can start posting about it if people are interested.&nbsp; I've done my best to filter out the woo-woo from a lot of it, and to get feedback from other people attempting similar techniques, but due to limited data it is sometimes difficult to separate what is actually effective from what is extraneous.&nbsp; So, fair warning: you'd be getting this in a rather rough and inexact form.&nbsp; For this reason, I would encourage everyone to analyze and critique what I post - and, more importantly, to experiment and report back their results.<br /><br />To give you a sense of what I have planned:</p>\n<ul>\n<li>Roadmap of the emotions: a post, or series of posts, attempting to categorize affective states in a more or less natural way, with an eye to neurochemistry.&nbsp; How to recognize particular emotions, how to induce them, how to keep them in check, what they're good for, and when they're not so good.</li>\n<li>Effective use of the body: the benefits of particular kinds of exercise, how to develop muscle memory, how to construct good practice drills.&nbsp; Also some suggestions for what kinds of body awareness rationalists should develop: I believe, for example, that learning a martial tradition is of significant benefit even if you never have to use it.</li>\n<li>Reprogramming the nervous system: recognizing and dealing with deep-seated cognitive blocks, traumas, pathologies, etc.&nbsp; If you're accustomed to being a social outcast from an early age, for example, any interaction with strangers will tend to trigger anxiety and hinder the establishment of rapport.</li>\n<li>How to step outside the rational box without going off the deep end.&nbsp; Essentially, techniques for maintaining a lifeline back to normality so you can explore the further reaches of the psyche in some degree of safety.</li>\n</ul>\n<p>I have some other ideas, but in a more inchoate form, so I'll leave it at that: this, then, is my pitch.&nbsp; I'd rather not clutter the main page with this stuff if it's going to bother people, but at least a few have expressed interest in hearing about it, and so if there's broader support I will proceed.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xHjy88N2uJvGdgzfw": 1, "AiNyf5iwbpc7mehiX": 1, "iP2X4jQNHMWHRNPne": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zPJE7MDtL25RpN7Cc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 139, "baseScore": 127, "extendedScore": null, "score": 0.000233, "legacy": true, "legacyId": "6967", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 127, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This post originated in a <a href=\"/lw/5a9/learned_blankness/3yq7\">comment</a> I posted about a strange and unpleasant experience I had when pushing myself too hard mentally.&nbsp; People seemed interested in hearing about it, so I sat down to write.&nbsp; In the process, however, it became something rather different (and a great deal longer) than what I originally intended.&nbsp; The incident referred to in the above comment was a case of manic focus gone wrong; but the truth is, often in my life it's gone incredibly <em>right</em>.&nbsp; I've gotten myself into some pretty strange headspaces, but through discipline and quick thinking I have often been able to turn them to my advantage and put them to good use.</p>\n<p>Part 1, then, lays out a sort of cognitive history, focusing on the more extreme states I've been in.&nbsp; Part 2 continues the narrative; this is where I began to learn to ride them out and make them work for me.&nbsp; Part 3 is the incident in question: where I overstepped myself and suffered the consequences.</p>\n<p>Some of you, however, may want to skip ahead to part 4 (unless you find my autobiographical writings interesting as a case study).&nbsp; There, I've written a proposal for a series of posts about how to effectively use the full spectrum of somatic and cognitive states to one's advantage.&nbsp; I have vacillated for a long time about this, for reasons that will be discussed below, but I decided that if I was already laying this much on the line, I might as well take it a step further.&nbsp; Read if you will; and if you're interested, please say so.</p>\n<p><a id=\"more\"></a></p>\n<p><strong id=\"Part_1__My_cognitive_background\">Part 1: My cognitive background</strong></p>\n<p>Let's start with full disclosure: there is madness in my family.&nbsp; My father was an alcoholic; it was clear to all of us that he also had some other psychological issues, but I never fully learned the details.&nbsp; My sister has been variously diagnosed with depression, bipolar, borderline personality disorder, etc, and has a breakdown about three or four times a year.&nbsp; My brother is also bipolar.&nbsp; He's had two manic episodes so far; he became psychotic during the first one, and both times he's been hospitalized.&nbsp; And then there's me: the sane, dependable one.</p>\n<p>That's what I thought, anyway, until my brother had his first episode and I started to look back on my own history.&nbsp; I'd always regarded myself as rather unusual, certainly, but basically stable.&nbsp; But seeing full-blown psychosis for the first time, and within my own family at that, gave new definition and clarity to some of the experiences I had had.&nbsp; My first episode happened when I was in my senior year of high school.&nbsp; I had been getting into New Age for about six months, reading rather credulously the work of one Dr. Joshua David Stone, author of the Ascension Manual and a number of other books inspired primarily by theosophy.&nbsp; I had not thought much about spirituality since renouncing God at the age of twelve, yet a vague unease had led me to begin seeking.&nbsp; Once I got started, I just ate it up; yet the vague unease persisted.&nbsp; I did my best to believe and to perform the meditative exercises, and for the most part I did, but it just wasn't sitting quite right.</p>\n<p>During winter break of that year, I began reading Zen and the Art of Motorcycle Maintenance, by Robert Pirsig.&nbsp; Now, here was something new: Pirsig rejected the analytic method as the sole arbiter of truth, yet he was also clearly uncomfortable with holism and spirituality.&nbsp; In fact, he seemed uncomfortable with all his ideas: they had come to him during a period of degenerating mental illness, culminating in a nervous breakdown and subsequent electroshock therapy.&nbsp; Yet rather than dismiss these ideas, he seemed determined to confront them and grapple with them, to sift for genuine insights among the delusions.&nbsp; Even more interesting was his rhetorical style: rather than simply stating his ideas, as is typical in a philosophical treatise, he would present problems first - present them as problems, really convince the reader that these were questions worth thinking about - and then move on to something else, only proposing solutions several pages later.&nbsp; This forced me to really think, for the first time in what seemed like ages.&nbsp; It was exciting; I couldn't put the book down.</p>\n<p>And this is where the trouble started: I really couldn't put the book down.&nbsp; It was as though the mental stimulation afforded by ZAMM had pushed me over the lip of an energy barrier, and I was now in an incredible downhill rush.&nbsp; My thoughts raced, day and night, about the nature of reality.&nbsp; New Age was the first thing to go: I could hardly believe my own unthinking credulity, and I summarily rejected what Dr. Stone had taught me.&nbsp; I also, however, rejected everything else I had thought I knew, eventually concluding that I wasn't sure if I existed; and then on further examination, unable to find any fundamental ground of reality, I departed from Descartes and concluded that even I did not exist, that all was illusion.</p>\n<p>I began to withdraw, although I felt I was surging with mental energy.&nbsp; For the next few months, I spent most of my time in my room, either staring at nothing and pondering or else writing frantic screeds about philosophical matters.&nbsp; Eventually one of my few remaining social contacts managed to get a grudging confession out of me of my own existence, but I wasn't out of the woods yet.&nbsp; The following months brought paranoia, existential anxiety, delusions of grandeur.&nbsp; It was at its worst during the summer: I began to feel that I was trapped in reality, in some sense, and that there were beings outside the universe - previous escapees - who were sending me telepathic messages in an effort to help me escape as well.&nbsp; I even had one brief moment of hallucination, once: waiting on my bicycle at an intersection, the traffic light shimmered silvery-blue, like an arc of liquid electricity creeping across the surface, and then returned to normal.</p>\n<p>Well, if I had told my family about this, I might have ended up medicated; but I put on a straight face, and I kept my grades up despite the inclination to up and head for the hills, so no one ever really noticed.&nbsp; I think this is why I had never considered this a mental disorder: there was a part of my mind that always kept me in check, making sure to perform all necessary maintenance operations while I lost my shit.&nbsp; Next thing I knew I was in university, doing remarkably well; the sudden change of scenery and the newfound freedom of living in a major city, as well as increased social contact with a variety of new people, seemed to stabilize me.&nbsp; I still maintained an interest in spirituality and the occult, but I had learned my lesson: I regarded everything I read as only a hypothetical, perhaps something to be tested but never to be strongly affirmed.</p>\n<p>And then, just as suddenly as it had come, my energy departed.&nbsp; After a stellar first year, I spent the next several years holed up in my room on my computer, not going to class nor doing much else.&nbsp; Even after I became aware of the problem, I found I could not pull myself out of it, no matter how hard I tried.&nbsp; This all went about as well as you could expect, and I almost got kicked out of school a couple times.</p>\n<p><strong id=\"Part_2__How_I_learned_to_stop_worrying_and_use_my_madness\">Part 2: How I learned to stop worrying and use my madness</strong></p>\n<p>My second episode began when my father died, and it never really ended.&nbsp; Our relationship had not been uniformly or even predominantly negative, but it had certainly been complicated, and I felt he held me back in a lot of subtle ways; it was like I was pulling against an elastic tether, and the day he died, it finally snapped.&nbsp; The school term (and my tenancy in the student residence) was just wrapping up at this time, so on a momentary whim I decided to move to another city where some friends of mine lived; within a week I was unpacking in my new room.&nbsp; Said friends were heavily into the occult, particularly the work of Aleister Crowley and assorted characters, who take a (selectively) skeptical approach to occultism, even going so far as to suggest that it is more a tool for self-analysis and self-change than anything else.&nbsp; For the following several months, therefore, I would be inundated with messages of self-improvement and introspective understanding of one's own mind.</p>\n<p>So, possessed with a desperate fervour, I began to practice yoga, meditation and ritual magic, attempting to use them as cognitive levers.&nbsp; At the same time, suddenly deprived of my father's financial support, I struggled to make ends meet, working awful temp labour jobs for minimum wage.&nbsp; At any time I could have packed up and returned to live with my mother, but I dimly perceived a higher presence urging me onward, promising wisdom and power if I could learn self-discipline against difficult odds.&nbsp; During this time, I would occasionally have moments of incredible clarity and expansiveness, overwhelmed by the beauty around me and more strongly aware of invisible presences guiding the events in my life, seemingly benevolent yet somewhat harsh in their methods.&nbsp; Sometimes I would even talk to or argue with myself, addressing darker parts of my psyche as separate entities as described in certain recensions of demonic invocation.</p>\n<p>And yet, this time something was different.&nbsp; This time, I saw exactly how crazy this all was.&nbsp; The solution, then, was simple: I simply did not attach any definite ontological state to what I was experiencing.&nbsp; As long as there was some part of me still grounded in the mundane, refusing to judge these entities as separate intelligences or as aspects of myself or even just as figments of my imagination, I could simply follow them along and evaluate the results.&nbsp; Rather surprisingly, the results were uniformly good: I was learning a great deal about how the world worked as well as my own constitution; the challenges I faced were difficult but surmountable, which boosted my confidence; and my overall life satisfaction dramatically increased.&nbsp; I learned to push through serious discomfort - physical, emotional or mental - if it was beneficial to do so.&nbsp; And I learned how to pay attention to my extremes of mental excitation: how to encourage them, how to use them, and how to keep them in check when necessary.</p>\n<p>Urged on by my visions, I returned to school with new dedication and discipline, which blossomed into a deep and abiding love of mathematics.&nbsp; A year later, it was a vision that compelled me to ride my bicycle from Ontario to Georgia, an incredible and life-changing experience which also introduced me to communal and alternative living as I met people along the way.&nbsp; It was another vision that compelled me to start my own communal house, where I am living happily to this day, and it was yet another vision that caused me to finally sit down and learn physics.&nbsp; And this is only a small selection of the ways in which arational impulses and visionary experiences have improved my life; they've also contributed to the development of my social skills, to my construction of a broad circle of friends and acquaintances, even to my moral development.&nbsp; They've also been highly entertaining: I have something of a penchant for the bizarre and mindbending, after the fashion of Philip K. Dick or David Cronenberg, and it's all the more exciting if it appears to be really happening.</p>\n<p>More interestingly, visionary experiences have often furnished me with new and interesting ideas.&nbsp; In the worst case, these ideas turn out to be totally absurd and useless, and I dismiss them easily, no harm done.&nbsp; In some cases, the ideas are dead ends but for very subtle reasons; in these cases, I often learn a great deal in trying to work them out.&nbsp; But in many cases, the ideas have proven to hold water even after I come down, perhaps after a little revision and formalization.&nbsp; The most recent of these was a game theoretic analysis of the relationship between government and citizen, which may end up as another post.&nbsp; Another time, I had a direct and visceral experience of living in a Tegmark universe, several years before I even heard of the idea - but we'll get to that.</p>\n<p>At any rate, I've benefited a great deal from arational urges verging on madness.&nbsp; But there is one more tale to tell: the time I pushed myself too far off balance and suffered the consequences.</p>\n<p><strong id=\"Part_3__How_it_turned_around_and_bit_me\">Part 3: How it turned around and bit me</strong></p>\n<p>This happened a little over two years ago.&nbsp; I had a psychedelic experience (legal highs only, of course) in which it was suggested that I investigate the topology of consciousness.&nbsp; Sounds a little crazy, but as mentioned, I've found a lot of value in the process of wrestling with these kinds of ideas, trying to make them work.&nbsp; Along for the trip was a man I had never met, who would become one of my closest friends.&nbsp; He had studied in some detail biology, physics, scattered mathematics, logic, and a variety of other technical fields.&nbsp; Not knowing what reaction I would get, I started talking to him about my idea.&nbsp; He became excited and began feeding back clever angles I might not have otherwise considered.&nbsp; As the conversation continued we fed off each other, growing more and more animated.&nbsp; Finally I stormed out onto the porch to have a cigarette.&nbsp; My mind was racing; this was the most brilliant idea ever!&nbsp; It was essential that I study this.&nbsp; But how would I support myself?&nbsp; The university was a good bet, but what department would I take it to?&nbsp; Which would be just crazy enough to fund me while I work on something this weird?</p>\n<p>And then all of a sudden something felt terribly wrong.&nbsp; Like metaphysical poison, unbearable dysphoria flowed into my entire being.&nbsp; The strength left my limbs, and I sat down, briefly certain I was going to die.&nbsp; Fortunately I quickly recognized this as an entirely common and much-parodied psychedelic trope, and after confirming that my vital signs were good, I crawled off to the bathroom to lie on the floor until I started to feel better.</p>\n<p>Looking back, I believe what happened was this: although I had gained some experience in effectively managing my more extreme mental states, I was accustomed to doing this in something of a vacuum; I didn't know anyone else who was interested in the things I was interested in.&nbsp; But my new friend acted as an amplifier, and I needed new cognitive tools to recognize the threat and contain myself accordingly.&nbsp; In the meantime, though, I was terribly excited despite the bad trip and determined to begin on the project I had been given.</p>\n<p>I quickly determined that I would need to understand physics better; all I had was Newtonian mechanics supplemented by pop science articles about relativity and quantum physics.&nbsp; So I began to study, with a passion.&nbsp; I bought some textbooks, found a number of physics courses on YouTube - quite a few of them, something like 150-200 hours in total - and began to spend all my free time giving myself a full, if a little sketchy, undergraduate physics education, condensed into about six months.&nbsp; And this was while I was also in university courses.&nbsp; To round it off, I started taking psychedelics on a regular basis.&nbsp; The character of my trips became darker and less euphoric, but they helped me develop richer intuitions for the systems I was learning about, and sometimes suggested new insights.&nbsp; I felt I was making good progress, and so despite feeling that I was stretched a little thin, I pushed further.&nbsp; Meanwhile, I withdrew from everything except school and my project, and the isolation began to take its toll.</p>\n<p>This culminated eventually in my Tegmark vision: I felt I saw the entire mathematical universe, a densely connected fabric of causality with our own universe embedded within it.&nbsp; Deduction, duality, emergence, simulation, and other such operations were seen as directions in this space.&nbsp; I felt there was a kind of knot or defect in the Tegmark space, along the lines of circular causation but vastly more subtle, somehow embedded in the structure of causality itself, and that this was how anything manages to exist in the first place.&nbsp; Needless to say, I threw caution to the wind and redoubled my efforts after this, certain I was approaching a significant discovery.</p>\n<p>And that's when I got swine flu.&nbsp; No joke.</p>\n<p>For three days I was unable to keep anything down but juice and tylenol.&nbsp; My fever was unbearable, and it got so bad at one point that I called 911, worried I might be dying - the one and only time I have ever called them for myself.&nbsp; Worst of all was the delirium: I hallucinated tiny quantum particle interactions, repeated over and over for hours in terrifying slowness and silence.&nbsp; I had visions of plagues sweeping the planet.&nbsp; I realized that this cold, mechanistic empty thing was all there was to reality, and there was not even the benefit of some kind of invisible being revealing this to me; I was just some poor schmuck who had discovered it by accident.</p>\n<p>The fever broke, but for almost a month afterward I was weak and sickly, unable to stand for long without getting dizzy.&nbsp; During this time, I could not bear to think about math or physics or the mind; it triggered a kind of psychic nausea reaction.&nbsp; But the damage had already been done: I felt restless and anxious and desperate even as the physical symptoms abated, and although I was in fact functioning at peak capacity in purely practical matters - driven mainly by a sense of desperation - my social life and my mental wellbeing began to suffer.&nbsp; I started having panic attacks for the first time in my life.&nbsp; I felt like I was being tormented by some demonic influence (figuratively, in this case); life was tolerable at best and harsh and brutal at worst.</p>\n<p>The mental state I had been maintaining, it seems, was a fragile one.&nbsp; It gave me a great deal of energy and dedication, which I was able to use to greatly enrich my understanding of the world, but it relied too heavily on nothing else going wrong in my life.&nbsp; It was like I had been building a tall but flimsy tower on a fault line, and when the earthquake finally hit - in the form of the flu - it all violently collapsed.</p>\n<p>It took a year of  damage control to finally return myself to stability, which takes us close to the present; I remember distinctly a particular day in September when I realized I finally felt completely at ease.&nbsp; In the months since then I have taken great pleasure in pursuing my degree, cultivating a new interest in applied mathematics.&nbsp; The old questions still linger, and I return to them for inspiration, but I take a more relaxed approach to my researches.&nbsp; My friend and I have discussed the feedback loops we get into, and through shared awareness we now keep our oscillations suitably damped.&nbsp; Most importantly, I have learned how to keep myself balanced.&nbsp; I still allow myself to go into ecstatic states, but in short bursts and with frequent breaks.</p>\n<p><strong id=\"Conclusion__A_proposal\">Conclusion: A proposal</strong></p>\n<p>I'm told that Bertrand Russell was once asked: \"But haven't you ever had any mystical experiences?\"&nbsp; \"Why, yes,\" he replied, \"I ignored them.\"&nbsp; He had convinced himself, through rigourous argumentation, that there was nothing in the spectrum of supernatural phenomena that stood up to scrutiny; and so when faced with peak experiences, he simply disregarded them as cognitive artefacts and glitches.&nbsp; I'm in no place to disagree with him about the supernatural; I have some finicky ontological and epistemic quibbles with materialism as usually stated, but I regard it as basically correct.&nbsp; I do wonder, though, if he was too extreme in his reaction.</p>\n<p>I won't rehash the usual arguments linking madness and creativity, but I do want to call attention to the link.&nbsp; The consensus on Less Wrong seems to be that spirituality in the experiential sense is a cognitive glitch in and of itself.&nbsp; I suggest, on the contrary, that it is a somewhat glitchy and kludgy tendency nevertheless serving a useful cognitive purpose.&nbsp; I have always been struck by the fact that the revelations and felt presences I have experienced seem just as clever and aware as I am, sometimes even more so.&nbsp; I don't mean to suggest anything supernatural by this; it is more likely that they are personified representations of my own unconscious ability to recognize patterns and solve hard problems.</p>\n<p>The ability to loosen one's associations and build bridges between disparate ideas seems to help us solve problems not amenable to direct, formal computation: to intuit mathematical truths before sitting down to prove them, for example, or to recognize that a pattern seen in one system is reflected in another, totally unrelated system.&nbsp; A state of mental excitation, even to the point of fervour, is also useful for overcoming akrasia, and promotes the quick thinking necessary when you don't have time to sit around and compute.&nbsp; If this is the case, then there is considerable benefit to be had in learning to depart from rationality in a safe and controlled manner.&nbsp; I say safe and controlled because, as we have seen, there are real dangers in overextending oneself; but with proper technique, I believe these dangers can be minimized while still reaping the benefits.</p>\n<p>If Less Wrong is simply about improving our techniques of rationality, then much of our work is already done: the voluminous Sequences encode both the core ideas and many of the consequences of good critical thinking, and we are left quibbling about subtleties of anthropic reasoning and speculating about AI design.&nbsp; If, however, we wish to use every advantage afforded by our mental constitution, then we should be studying ecstasy and passion.&nbsp; In fact, this generalizes to a wide variety of affective states; indeed, there have been some posts mentioning more effective managing of emotions, social skills, and so on, but not many concrete suggestions have been made.&nbsp; This is not surprising: much of the scientific research that has been done on emotions is either about business-as-usual or about treating serious pathologies.</p>\n<p>The truth is, there are in fact techniques out there which seem to work.&nbsp; I'm perhaps an unusual case in that I already had some extreme cognitive states to work with, but these techniques have served me well, and they also seem to have worked well for other friends of mine who have tried them.&nbsp; Nevertheless, I've been reluctant to post them, for one major reason: they're cranky as hell.&nbsp; Many of them come from spiritual, religious or occult sources, and it can be a little tricky to tease apart the techniques from the metaphysical beliefs (the best case, perhaps, is the Buddhist system, which holds (roughly) that the unenlightened mind can't truly understand reality anyway, so you'd best just shut up and meditate).&nbsp; Nevertheless, these traditions have decades or even centuries of experience in inducing altered states of consciousness, and with a good cognitive hazmat suit we can pick out really effective techniques among the more fanciful detritus.</p>\n<p>So, with little to lose, I'm putting this out there: I have a fair bit of experience with this sort of thing, and I can start posting about it if people are interested.&nbsp; I've done my best to filter out the woo-woo from a lot of it, and to get feedback from other people attempting similar techniques, but due to limited data it is sometimes difficult to separate what is actually effective from what is extraneous.&nbsp; So, fair warning: you'd be getting this in a rather rough and inexact form.&nbsp; For this reason, I would encourage everyone to analyze and critique what I post - and, more importantly, to experiment and report back their results.<br><br>To give you a sense of what I have planned:</p>\n<ul>\n<li>Roadmap of the emotions: a post, or series of posts, attempting to categorize affective states in a more or less natural way, with an eye to neurochemistry.&nbsp; How to recognize particular emotions, how to induce them, how to keep them in check, what they're good for, and when they're not so good.</li>\n<li>Effective use of the body: the benefits of particular kinds of exercise, how to develop muscle memory, how to construct good practice drills.&nbsp; Also some suggestions for what kinds of body awareness rationalists should develop: I believe, for example, that learning a martial tradition is of significant benefit even if you never have to use it.</li>\n<li>Reprogramming the nervous system: recognizing and dealing with deep-seated cognitive blocks, traumas, pathologies, etc.&nbsp; If you're accustomed to being a social outcast from an early age, for example, any interaction with strangers will tend to trigger anxiety and hinder the establishment of rapport.</li>\n<li>How to step outside the rational box without going off the deep end.&nbsp; Essentially, techniques for maintaining a lifeline back to normality so you can explore the further reaches of the psyche in some degree of safety.</li>\n</ul>\n<p>I have some other ideas, but in a more inchoate form, so I'll leave it at that: this, then, is my pitch.&nbsp; I'd rather not clutter the main page with this stuff if it's going to bother people, but at least a few have expressed interest in hearing about it, and so if there's broader support I will proceed.</p>", "sections": [{"title": "Part 1: My cognitive background", "anchor": "Part_1__My_cognitive_background", "level": 1}, {"title": "Part 2: How I learned to stop worrying and use my madness", "anchor": "Part_2__How_I_learned_to_stop_worrying_and_use_my_madness", "level": 1}, {"title": "Part 3: How it turned around and bit me", "anchor": "Part_3__How_it_turned_around_and_bit_me", "level": 1}, {"title": "Conclusion: A proposal", "anchor": "Conclusion__A_proposal", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "122 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 123, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-22T21:11:48.313Z", "modifiedAt": null, "url": null, "title": "Probability puzzles", "slug": "probability-puzzles", "viewCount": null, "lastCommentedAt": "2019-11-09T16:50:45.441Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "johnclark", "createdAt": "2010-12-11T17:45:15.654Z", "isAdmin": false, "displayName": "johnclark"}, "userId": "kKChFZ54eramyAwve", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ioaLEKnGnXAAGWB9B/probability-puzzles", "pageUrlRelative": "/posts/ioaLEKnGnXAAGWB9B/probability-puzzles", "linkUrl": "https://www.lesswrong.com/posts/ioaLEKnGnXAAGWB9B/probability-puzzles", "postedAtFormatted": "Friday, April 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Probability%20puzzles&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProbability%20puzzles%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FioaLEKnGnXAAGWB9B%2Fprobability-puzzles%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Probability%20puzzles%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FioaLEKnGnXAAGWB9B%2Fprobability-puzzles", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FioaLEKnGnXAAGWB9B%2Fprobability-puzzles", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 332, "htmlBody": "<p>There are 2&nbsp; probability puzzles that I like: <br /><br />1) Suppose I tell you that I have 2 children and one of them is a boy, what is the probability that I have 2 boys?<br /><br />The correct answer is not 1/2 but 1/3. How can that be? Well there are 4 possible combinations, BB,GG,BG and GB but but at least one is a boy so you can get rid of GG. So all that's left is BB,BG and GB; and in only one of those 3 possibilities do I have two boys.<br /><br />2) Now I tell you that I have 2 children and one of them is a boy born on a Tuesday. What is the probability that I have 2 boys?<br /><br />You may think that Tuesday is not useful information in this matter so the answer would be the same as the previous example, but you would be wrong. The correct answer is 13/27. How can that be?<br /><br />Well there are 14 possibilities for EACH kid:<br />B-Mo, B-Tu, B-We, B-Th, B-Fr, B-Sa, B-Su<br />G-Mo, G-Tu, G-We, G-Th, G-Fr, G-Sa, G-Su<br /><br />But I told you the one of my kids (the first or the second) was a boy born on a Tuesday so that narrows down the field of possibilities to: <br /><br />First child: B-Tu, second child: B-Mo, B-Tu, B-We, B-Th, B-Fr, B-Sa, B-Su, G-Mo, G-Tu, G-We, G-Th, G-Fr, G-Sa, G-Su.<br /><br />Second child: B-Tu, first child: B-Mo, B-We, B-Th, B-Fr, B-Sa, B-Su, G-Mo, G-Tu, G-We, G-Th, G-Fr, G-Sa, G-Su.<br /><br />No need to put B-Tu in the second row because it's already accounted for in the first row.<br />So now just count them out, 14+13= 27 possibilities. How many result in 2 boys? Count them out again 7+6=13. So 13 out of 27 possibilities give you 2 boys.<br /><br />&nbsp; John K Clark<br /></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ioaLEKnGnXAAGWB9B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": -12, "extendedScore": null, "score": 7.056204046502117e-07, "legacy": true, "legacyId": "6968", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-23T00:08:48.125Z", "modifiedAt": null, "url": null, "title": "Is Kiryas Joel an Unhappy Place?", "slug": "is-kiryas-joel-an-unhappy-place", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:35.614Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Fy6JoSn4sozvNYaDA/is-kiryas-joel-an-unhappy-place", "pageUrlRelative": "/posts/Fy6JoSn4sozvNYaDA/is-kiryas-joel-an-unhappy-place", "linkUrl": "https://www.lesswrong.com/posts/Fy6JoSn4sozvNYaDA/is-kiryas-joel-an-unhappy-place", "postedAtFormatted": "Saturday, April 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20Kiryas%20Joel%20an%20Unhappy%20Place%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20Kiryas%20Joel%20an%20Unhappy%20Place%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFy6JoSn4sozvNYaDA%2Fis-kiryas-joel-an-unhappy-place%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20Kiryas%20Joel%20an%20Unhappy%20Place%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFy6JoSn4sozvNYaDA%2Fis-kiryas-joel-an-unhappy-place", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFy6JoSn4sozvNYaDA%2Fis-kiryas-joel-an-unhappy-place", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 933, "htmlBody": "<p class=\"articleHeadline\">I was browsing my RSS feed, as one does, and came across a <em>New York Times</em> article, <a href=\"http://www.nytimes.com/2011/04/21/nyregion/kiryas-joel-a-village-with-the-numbers-not-the-image-of-the-poorest-place.html?pagewanted=all\">\"A Village With the Numbers, Not the Image, of the Poorest Place\"</a>, about the <a href=\"http://en.wikipedia.org/wiki/Satmar_%28Hasidic_dynasty%29\">Satmar Hasidic</a> Jews of <a href=\"http://en.wikipedia.org/wiki/Kiryas_Joel,_New_York\">Kiryas Joel </a>(NY).</p>\n<p class=\"articleHeadline\">Their interest lies in their extraordinarily high birthrate &amp; population growth, and their poverty - which are connected. From the article:</p>\n<blockquote>\n<p class=\"articleHeadline\">\"...officially, at least, none of the nation&rsquo;s 3,700 villages, towns or cities with more than 10,000 people has a higher proportion of its population living in poverty than Kiryas Joel, N.Y., a community of mostly garden apartments and town houses 50 miles northwest of New York City in suburban Orange County.</p>\n<p>About 70 percent of the village&rsquo;s 21,000 residents live in households whose income falls below the federal poverty threshold, according to the <a class=\"meta-org\" title=\"More articles about Census Bureau, U.S.\" href=\"http://topics.nytimes.com/top/reference/timestopics/organizations/c/census_bureau/index.html?inline=nyt-org\">Census Bureau</a>. Median family income ($17,929) and per capita income ($4,494) rank lower than any other comparable place in the country. Nearly half of the village&rsquo;s households reported less than $15,000 in annual income. About half of the residents receive food stamps, and one-third receive <a class=\"meta-classifier\" title=\"Recent and archival health news about Medicaid.\" href=\"http://topics.nytimes.com/top/news/health/diseasesconditionsandhealthtopics/medicaid/index.html?inline=nyt-classifier\">Medicaid</a> benefits and rely on federal vouchers to help pay their housing costs.</p>\n<p>Kiryas Joel&rsquo;s unlikely ranking results largely from religious and cultural factors. Ultra-Orthodox Satmar Hasidic Jews predominate in the village; many of them moved there from Williamsburg, Brooklyn, beginning in the 1970s to accommodate a population that was growing geometrically. Women marry young, remain in the village to raise their families and, according to religious strictures, do not use birth control. As a result, the median age (under 12) is the lowest in the country and the household size (nearly six) is the highest. Mothers rarely work outside the home while their children are young. Most residents, raised as Yiddish speakers, do not speak much English. And most men devote themselves to Torah and Talmud studies rather than academic training &mdash; only 39 percent of the residents are high school graduates, and less than 5 percent have a bachelor&rsquo;s degree. Several hundred adults study full time at religious institutions.</p>\n<p>...Because the community typically votes as a bloc, it wields disproportionate political influence, which enables it to meet those challenges creatively. A luxurious 60-bed postnatal maternal care center was built with $10 million in state and federal grants. Mothers can recuperate there for two weeks away from their large families. Rates, which begin at $120 a day, are not covered by Medicaid, although, Mr. Szegedin said, poorer women are typically subsidized by wealthier ones.</p>\n<p>...The village does aggressively pursue economic opportunities. A kosher poultry slaughterhouse, which processes 40,000 chickens a day, is community owned and considered a nonprofit organization. A bakery that produces 800 pounds of matzo daily is owned by one of the village&rsquo;s synagogues.</p>\n<p>Most children attend religious schools, but transportation and textbooks are publicly financed. Several hundred handicapped students are educated by the village&rsquo;s own public school district, which, because virtually all the students are poor and disabled, is eligible for sizable state and federal government grants.</p>\n<p>... Still, poverty is largely invisible in the village. Parking lots are full, but strollers and tricycles seem to outnumber cars. A jeweler shares a storefront with a check-cashing office. To avoid stigmatizing poorer young couples or instilling guilt in parents, the chief rabbi recently decreed that diamond rings were not acceptable as engagement gifts and that one-man bands would suffice at weddings. Many residents who were approached by a reporter said they did not want to talk about their finances.</p>\n<p>...Are as many as 7 in 10 Kiryas Joel residents really poor? &ldquo;It is, in a sense, a statistical anomaly,&rdquo; Professor Helmreich said. &ldquo;They are clearly not wealthy, and they do have a lot of children. They spend whatever discretionary income they have on clothing, food and baby carriages. They don&rsquo;t belong to country clubs or go to movies or go on trips to Aruba.</p>\n<p>...David Jolly, the social services commissioner for Orange County, also said that while the number of people receiving benefits seemed disproportionately high, the number of caseloads &mdash; a family considered as a unit &mdash; was much less aberrant. A family of eight who reports as much as $48,156 in income is still eligible for food stamps, although the threshold for cash assistance ($37,010), which relatively few village residents receive, is lower....&ldquo;You also have no drug-treatment programs, no juvenile delinquency program, we&rsquo;re not clogging the court system with criminal cases, you&rsquo;re not running programs for AIDS or teen pregnancy,&rdquo; he [Mr. Szegedin, the village administrator] said. &ldquo;I haven&rsquo;t run the numbers, but I think it&rsquo;s a wash.&rdquo;</p>\n</blockquote>\n<p>From Wikipedia:</p>\n<blockquote>\n<p>The land for Kiryas Joel was purchased in 1977, and fourteen Satmar families settled there. By 2006, there were over 3,000...In 1990, there were 7,400 people in Kiryas Joel; in 2000, 13,100, nearly doubling the population. In 2005, the population had risen to 18,300, a rate of growth suggesting it will double again in the ten years between 2000 and 2010.</p>\n</blockquote>\n<p>Robin Hanson has argued that uploaded/emulated minds will establish a new <a href=\"http://en.wikipedia.org/wiki/Thomas_Malthus\">Malthusian</a>/Darwinian equilibrium in <a href=\"http://hanson.gmu.edu/uploads.html\">\"IF UPLOADS COME FIRST: The crack of a future dawn\"</a> - an equilibrium in comparison to which our own economy will look like a <a href=\"http://www.overcomingbias.com/2010/06/dreamtime.html\">delusive</a> <a href=\"http://www.overcomingbias.com/2009/09/this-is-the-dream-time.html\">dreamtime</a> of impossibly unfit and libertine behavior. The <a href=\"http://en.wikipedia.org/wiki/Demographic_transition\">demographic transition</a> will <a href=\"http://www.overcomingbias.com/2009/09/future-fertility.html\">not last forever</a>. But despite our own distaste for countless lives living at near-subsistence rather than our own extreme per-capita wealth (see the <a href=\"http://plato.stanford.edu/entries/repugnant-conclusion/\">Repugnant</a> <a href=\"/lw/17h/the_lifespan_dilemma/\">Conclusion</a>), those many lives <a href=\"http://www.overcomingbias.com/2009/09/poor-folks-do-smile.html\">will be happy ones</a> (even <a href=\"http://www.overcomingbias.com/2011/01/lift-up-your-eyes.html\">amidst disaster</a>).</p>\n<p>So. Are the inhabitants of Kiryas Joel unhappy?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 1, "sSNtcEQsqHgN8ZmRF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Fy6JoSn4sozvNYaDA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 28, "extendedScore": null, "score": 7.056702991314952e-07, "legacy": true, "legacyId": "6969", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 188, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9RCoE7jmmvGd5Zsh2"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-23T01:04:16.102Z", "modifiedAt": null, "url": null, "title": "Leaving a line of retreat for theists", "slug": "leaving-a-line-of-retreat-for-theists", "viewCount": null, "lastCommentedAt": "2019-10-15T22:14:10.109Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "oFp6JLn8z9uxgdPp8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JKamCpYa7eG7E6Q3b/leaving-a-line-of-retreat-for-theists", "pageUrlRelative": "/posts/JKamCpYa7eG7E6Q3b/leaving-a-line-of-retreat-for-theists", "linkUrl": "https://www.lesswrong.com/posts/JKamCpYa7eG7E6Q3b/leaving-a-line-of-retreat-for-theists", "postedAtFormatted": "Saturday, April 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Leaving%20a%20line%20of%20retreat%20for%20theists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALeaving%20a%20line%20of%20retreat%20for%20theists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJKamCpYa7eG7E6Q3b%2Fleaving-a-line-of-retreat-for-theists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Leaving%20a%20line%20of%20retreat%20for%20theists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJKamCpYa7eG7E6Q3b%2Fleaving-a-line-of-retreat-for-theists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJKamCpYa7eG7E6Q3b%2Fleaving-a-line-of-retreat-for-theists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 291, "htmlBody": "<p>Eliezer recommends that we leave a <a href=\"/lw/o4/leave_a_line_of_retreat/\">line of retreat</a> when discussing controversial topics, since this prevents scary propositions from clouding our judgment. However, I've noticed recently that there are some topics that are just <em>too</em> scary for people to think about, the existence of God being a primary example. Simply put, people don't want to admit that the universe is <a href=\"/lw/uk/beyond_the_reach_of_god/\">beyond the reach of a caring God</a>, no matter how much evidence there is to the contrary. People especially don't want to hear that they will one day cease to exist, never to be reincarnated or continued in an afterlife. I've found this to be a major stumbling block when having discussions with theists or agnostics--though the people I've talked to are willing to accept that <a href=\"http://en.wikipedia.org/wiki/Bill_gates#Philanthropy\">nonbelievers can lead very moral lives</a>, the thought that \"it's just us\" is the stopsign that prevents the discussion from moving further. Naturally I've explained that it's important to <a href=\"/\">only believe things that are true</a>, but for some people this meme just can't overcome the scariness of a naturalistic universe.</p>\n<p>Have any LessWrongians managed to overcome this obstacle? If so, how? We can generalize this problem somewhat: are there effective techniques for getting people to clearly evaluate the probability of scary or depressing propositions? Explanations with the smallest amount of <a href=\"/lw/kg/expecting_short_inferential_distances/\">inferential distance</a> are preferred--while something like cryonics does answer most of the theistic objections raised above, it's a huge distance away from most people's belief systems. (That said, it's quite possible that the answer to my question might be \"No, there are no effective techniques that have short inferential distances,\" and in the spirit of this post I'm willing to accept that.) I'd also be interested in hearing anecdotes about similar situations if anyone has any.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JKamCpYa7eG7E6Q3b", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 17, "extendedScore": null, "score": 7.056863045532282e-07, "legacy": true, "legacyId": "6970", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3XgYbghWruBMrPTAL", "sYgv4eYH82JEsTD34", "HLqWn5LASfhhArZ7w"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-23T04:12:20.162Z", "modifiedAt": null, "url": null, "title": "Spiritedness and docility", "slug": "spiritedness-and-docility", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:33.597Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gray", "createdAt": "2011-03-01T21:47:09.392Z", "isAdmin": false, "displayName": "Gray"}, "userId": "GowbwHixpEz6dtGg7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6eYCsYnpAgAbt92JF/spiritedness-and-docility", "pageUrlRelative": "/posts/6eYCsYnpAgAbt92JF/spiritedness-and-docility", "linkUrl": "https://www.lesswrong.com/posts/6eYCsYnpAgAbt92JF/spiritedness-and-docility", "postedAtFormatted": "Saturday, April 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Spiritedness%20and%20docility&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpiritedness%20and%20docility%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6eYCsYnpAgAbt92JF%2Fspiritedness-and-docility%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Spiritedness%20and%20docility%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6eYCsYnpAgAbt92JF%2Fspiritedness-and-docility", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6eYCsYnpAgAbt92JF%2Fspiritedness-and-docility", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 661, "htmlBody": "<p>Just a brief inquiry, I've been thinking about myself, and what many people here talk about <em>akrasia</em> and \"not getting crap done\", and one of the vectors that this can be thought of is in terms of what I would call spiritedness versus docility.&nbsp; At least this is how I would describe it, maybe you guys know of a better approach.</p>\n<p>I would call these different ends of a continuum, like hot and cold: the more spirited you are, the less docile; and the more docile you are, the less spirited.&nbsp; I suspect that many of those who come here are often on the docile end of the spectrum, and this has everything to do with the sort of society we live in.&nbsp; A spirited/highly energetic person just doesn't work that well in our kind of society where standing in one place, waiting our turn, reading directions, and so on, are standard staples of life.</p>\n<p>Now being docile <em>sounds</em> bad, but the alternative is a lot of frustration--being irritable, impatient, easily angered and annoyed by those around you; at least, this is the way I see it.&nbsp; But I was thinking in terms of what I would call \"rational spiritedness\", because this is the condition under which I think best.&nbsp; That is, rather than passively waiting for the answers, but actively seeking them.&nbsp; There was a post a little while ago about what was called \"learned blankness\", and I think this is very close to what I call docility.&nbsp; For the spirited person, inquiry is naturally active, physical, and empirical.</p>\n<p>I did an experiment the other day when I was in the park walking, and as I was walking I forced myself to constantly probe the environment around me, trying to discover as much I could.&nbsp; I'm talking about very basic things, the way a naturalist would, like what is the structure of the leaves on the grass (grass grows in bundles).&nbsp; I noticed, and then recalled, that this park was hit by a tornado last year, and I could see which trees are newly planted, and which are still there from the tornado.&nbsp; I even noticed the pattern in the trees, the way the old trees had fewer branches on one side, which indicated in which direction the wind blew in from.&nbsp; There were still some old stakes in the ground which were pointed in the same angle.&nbsp; But the idea wasn't to \"learn about any particular thing\" but to \"learn about whatever I could around me\".</p>\n<p>But the impressive thing is that this \"state of mind\" that I somehow struck caused me to learn things, and even <em>see</em> the world around me in a way I never did before.&nbsp; I guess I'm a natural introvert, and I've walked this park many times before, and never noticed any of these details.&nbsp; My walks are usually spent inside my head, thinking about logical arguments, or what not.&nbsp; It never occurred to me to use my rationality to learn things about the world around me, to become a sort of empirical sleuth (Sherlock Holmes is certainly my inspiration here).</p>\n<p>It's this idea of spiritedness that has caught my attention though, that day when I was walking at the park, I think I managed to become more spirited than I usually am.&nbsp; It helped that I was virtually alone at the park (it's a really small park, and still cold), but this spiritedness caused me to walk off the trail many times just to go look at something from a different angle, or to see something up close, or to count the number of something.&nbsp; This was all pretty easy stuff.&nbsp; There was one other guy there, and I hate to say that I felt a little ashamed at what I was doing everytime I saw him.&nbsp; Seeing another person seems to be an instant return to docility.&nbsp; Maybe this is why the best thinkers work alone.</p>\n<p>Anyway, I thought this was interesting, and shared with the class. :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6eYCsYnpAgAbt92JF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 16, "extendedScore": null, "score": 7.057396268857661e-07, "legacy": true, "legacyId": "6979", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-23T22:48:04.458Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Modesty Argument", "slug": "seq-rerun-the-modesty-argument", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:53.827Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Unnamed", "createdAt": "2009-02-27T06:08:10.900Z", "isAdmin": false, "displayName": "Unnamed"}, "userId": "PdzQ73mN7S4SvRMhu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/irsZZvkouLZgNzcF2/seq-rerun-the-modesty-argument", "pageUrlRelative": "/posts/irsZZvkouLZgNzcF2/seq-rerun-the-modesty-argument", "linkUrl": "https://www.lesswrong.com/posts/irsZZvkouLZgNzcF2/seq-rerun-the-modesty-argument", "postedAtFormatted": "Saturday, April 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Modesty%20Argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Modesty%20Argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FirsZZvkouLZgNzcF2%2Fseq-rerun-the-modesty-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Modesty%20Argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FirsZZvkouLZgNzcF2%2Fseq-rerun-the-modesty-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FirsZZvkouLZgNzcF2%2Fseq-rerun-the-modesty-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 161, "htmlBody": "<p>Today's post, <a href=\"/lw/gr/the_modesty_argument/\">The Modesty Argument</a>, was originally published on December 10, 2006. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Factor in what other people think, but not symmetrically, if they are not epistemic peers. <br /></blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/r/discussion/lw/5de/seq_rerun_the_proper_use_of_humility/\">The Proper Use of Humility</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "irsZZvkouLZgNzcF2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 7.060561161939955e-07, "legacy": true, "legacyId": "6885", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NKECtGX4RZPd7SqYp", "F3EnWH3poQs4mBK3p", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-23T23:10:33.258Z", "modifiedAt": null, "url": null, "title": "Functioning Synapse Created Using Carbon Nanotubes [link]", "slug": "functioning-synapse-created-using-carbon-nanotubes-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:33.807Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dreaded_Anomaly", "createdAt": "2010-12-30T06:38:34.106Z", "isAdmin": false, "displayName": "Dreaded_Anomaly"}, "userId": "sBHF4CXWBLakPFzfu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HLwuYLyxRT4yhuEB4/functioning-synapse-created-using-carbon-nanotubes-link", "pageUrlRelative": "/posts/HLwuYLyxRT4yhuEB4/functioning-synapse-created-using-carbon-nanotubes-link", "linkUrl": "https://www.lesswrong.com/posts/HLwuYLyxRT4yhuEB4/functioning-synapse-created-using-carbon-nanotubes-link", "postedAtFormatted": "Saturday, April 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Functioning%20Synapse%20Created%20Using%20Carbon%20Nanotubes%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFunctioning%20Synapse%20Created%20Using%20Carbon%20Nanotubes%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLwuYLyxRT4yhuEB4%2Ffunctioning-synapse-created-using-carbon-nanotubes-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Functioning%20Synapse%20Created%20Using%20Carbon%20Nanotubes%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLwuYLyxRT4yhuEB4%2Ffunctioning-synapse-created-using-carbon-nanotubes-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLwuYLyxRT4yhuEB4%2Ffunctioning-synapse-created-using-carbon-nanotubes-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p><a href=\"http://www.sciencedaily.com/releases/2011/04/110421151921.htm\">Functioning Synapse Created Using Carbon Nanotubes: Devices Might Be Used in Brain Prostheses or Synthetic Brains (article @ ScienceDaily)</a></p>\n<blockquote>\n<p>Engineering researchers the University of Southern California have made a  significant breakthrough in the use of nanotechnologies for the  construction of a synthetic brain. They have built a carbon nanotube  synapse circuit whose behavior in tests reproduces the function of a  neuron, the building block of the brain.</p>\n</blockquote>\n<p>A very promising development for both human and artificial intelligence research.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HLwuYLyxRT4yhuEB4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 4, "extendedScore": null, "score": 7.06062495424815e-07, "legacy": true, "legacyId": "6997", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T00:42:00.360Z", "modifiedAt": null, "url": null, "title": "Heading Toward: No-Nonsense Metaethics", "slug": "heading-toward-no-nonsense-metaethics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:35.442Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "lukeprog", "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SFnfhJkGsBQk8jakK/heading-toward-no-nonsense-metaethics", "pageUrlRelative": "/posts/SFnfhJkGsBQk8jakK/heading-toward-no-nonsense-metaethics", "linkUrl": "https://www.lesswrong.com/posts/SFnfhJkGsBQk8jakK/heading-toward-no-nonsense-metaethics", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Heading%20Toward%3A%20No-Nonsense%20Metaethics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHeading%20Toward%3A%20No-Nonsense%20Metaethics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFnfhJkGsBQk8jakK%2Fheading-toward-no-nonsense-metaethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Heading%20Toward%3A%20No-Nonsense%20Metaethics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFnfhJkGsBQk8jakK%2Fheading-toward-no-nonsense-metaethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFnfhJkGsBQk8jakK%2Fheading-toward-no-nonsense-metaethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 584, "htmlBody": "<p>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics</a></p><p>A few months ago, I <a href=\"https://www.lesserwrong.com/lw/43v/the_urgent_metaethics_of_friendly_artificial/3gwm\">predicted</a> that we could solve metaethics in 15 years. To most people, that was outrageously optimistic. But I&#x27;ve <a href=\"http://wiki.lesswrong.com/wiki/Belief_update\">updated</a> since then. I think much of metaethics can be solved <em>now</em> (depending on where you draw the boundary around the term &#x27;metaethics&#x27;.) My upcoming sequence &#x27;No-Nonsense Metaethics&#x27; will solve the part that can be solved, and make headway on the parts of metaethics that aren&#x27;t yet solved. Solving the easier problems of metaethics will give us a clear and stable platform from which to solve the <em>hard</em> questions of morality.</p><p>Metaethics has been my target for a while now, but first I had to explain the neuroscience of <a href=\"https://www.lesserwrong.com/lw/4yq/the_neuroscience_of_pleasure/\">pleasure</a> and <a href=\"https://www.lesserwrong.com/lw/4z7/the_neuroscience_of_desire/\">desire</a>, and <a href=\"http://wiki.lesswrong.com/wiki/Intuitions_and_Philosophy\">how to use intuitions for philosophy</a>.</p><p>Luckily, Eliezer laid <em>most</em> of the groundwork when he explained <a href=\"https://www.lesserwrong.com/lw/rb/possibility_and_couldness/\">couldness</a>, <a href=\"https://www.lesserwrong.com/lw/l4/terminal_values_and_instrumental_values/\">terminal and instrumental values</a>, the <a href=\"https://www.lesserwrong.com/lw/l3/thou_art_godshatter/\">complexity</a> of human <a href=\"https://www.lesserwrong.com/lw/ld/the_hidden_complexity_of_wishes/\">desire</a> and <a href=\"https://www.lesserwrong.com/lw/lb/not_for_the_sake_of_happiness_alone/\">happiness</a>, how to <a href=\"https://www.lesserwrong.com/lw/of/dissolving_the_question/\">dissolve philosophical problems</a>, how to <a href=\"https://www.lesserwrong.com/lw/nu/taboo_your_words/\">taboo</a> words and <a href=\"https://www.lesserwrong.com/lw/nv/replace_the_symbol_with_the_substance/\">replace them with their substance</a>, how to <a href=\"https://www.lesserwrong.com/lw/np/disputing_definitions/\">avoid definitional disputes</a>, how to <a href=\"https://www.lesserwrong.com/lw/o0/where_to_draw_the_boundary/\">carve reality at its joints</a> with our words, <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">how an algorithm feels from the inside</a>, the <a href=\"https://www.lesserwrong.com/lw/oi/mind_projection_fallacy/\">mind projection fallacy</a>, how <a href=\"https://www.lesserwrong.com/lw/oj/probability_is_in_the_mind/\">probability is in the mind</a>, <a href=\"https://www.lesserwrong.com/lw/on/reductionism/\">reductionism</a>, <a href=\"https://www.lesserwrong.com/lw/r1/timeless_control/\">determinism</a>, <a href=\"http://wiki.lesswrong.com/wiki/Free_will_(solution)\">free will</a>, <a href=\"http://wiki.lesswrong.com/wiki/Evolutionary_psychology\">evolutionary psychology</a>, <a href=\"https://www.lesserwrong.com/lw/re/grasping_slippery_things/\">how to grasp slippery things</a>, and <a href=\"https://www.lesserwrong.com/lw/rq/what_would_you_do_without_morality/\">what you would do without morality</a>.</p><p>Of course, Eliezer wrote <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">his own metaethics sequence</a>. Eliezer and I seem to have similar views on morality, but I&#x27;ll be approaching the subject from a different angle, I&#x27;ll be phrasing my solution differently, and I&#x27;ll be covering a different spread of topics.</p><p>Why do I think much of metaethics can be solved now? We have enormous resources not available just a few years ago. The neuroscience of <a href=\"https://www.lesserwrong.com/lw/4yq/the_neuroscience_of_pleasure/\">pleasure</a> and <a href=\"https://www.lesserwrong.com/lw/4z7/the_neuroscience_of_desire/\">desire</a> didn&#x27;t exist two decades ago. (Well, we thought dopamine was &#x27;the pleasure chemical&#x27;, but we were <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-The-debate-over-dopamines-role-in-reward-the-case-for-incentive-salience.pdf\">wrong</a>.) Detailed models of reductionistic meta-ethics weren&#x27;t developed until the 1980s and 90s (by <a href=\"http://commonsenseatheism.com/?p=15253\">Peter</a> <a href=\"http://commonsenseatheism.com/?p=15264\">Railton</a> and <a href=\"http://commonsenseatheism.com/?p=15267\">Frank Jackson</a>). Reductionism has been around for a while, but there are few philosophers who relentlessly play <a href=\"https://www.lesserwrong.com/lw/nu/taboo_your_words/\">Rationalist&#x27;s Taboo</a>. Eliezer didn&#x27;t write <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">How an Algorithm Feels from the Inside</a> until 2008.</p><p>Our methods will be familiar ones, already used to dissolve problems ranging from <a href=\"http://wiki.lesswrong.com/wiki/Free_will_(solution)\">free will</a> to <a href=\"https://www.lesserwrong.com/lw/2as/diseased_thinking_dissolving_questions_about/\">disease</a>. We will play Taboo with our terms, reducing philosophical questions into scientific ones. Then we will examine the cognitive algorithms that make it <em>feel</em> like open questions remain.</p><p>Along the way, we will solve or dissolve the traditional problems of metaethics: <a href=\"http://plato.stanford.edu/entries/moral-epistemology/\">moral epistemology</a>, the role of <a href=\"http://plato.stanford.edu/entries/reflective-equilibrium/\">moral intuition</a>, the <a href=\"http://en.wikipedia.org/wiki/Is%E2%80%93ought_problem\">is-ought gap</a>, matters of <a href=\"http://en.wikipedia.org/wiki/Moral_psychology\">moral psychology</a>, the <a href=\"http://en.wikipedia.org/wiki/Open_Question_Argument\">open question argument</a>, <a href=\"http://plato.stanford.edu/entries/moral-realism/\">moral realism</a> vs. <a href=\"http://plato.stanford.edu/entries/moral-anti-realism/\">moral anti-realism</a>, <a href=\"http://plato.stanford.edu/entries/moral-cognitivism/\">moral cognitivism vs. non-cognitivism</a>, and more. </p><p>You might respond, &quot;Sure, Luke, we can do the reduce-to-algorithm thing with free will or disease, but morality is different. Morality is <em>fundamentally normative</em>. You can&#x27;t just dissolve moral questions with Taboo-playing and reductionism and cognitive science.&quot;</p><p>Well, we&#x27;re going to examine the cognitive algorithms that generate <em>that</em> intuition, too.</p><p>And at the end, we will see what this all means for the problem of <a href=\"http://intelligence.org/ourresearch/publications/what-is-friendly-ai.html\">Friendly AI</a>.</p><p>I must note that I didn&#x27;t exactly <em>invent</em> the position I&#x27;ll be defending. After sharing my views on metaethics with many scientifically-minded people in private conversation, many have said something like &quot;Yeah, that&#x27;s basically what I think about metaethics, I&#x27;ve just never thought it through in so much detail and cited so much of the relevant science [e.g. recent work in <a href=\"https://www.lesserwrong.com/lw/4z7/the_neuroscience_of_desire/\">neuroeconomics</a> and the <a href=\"http://wiki.lesswrong.com/wiki/Intuitions_and_Philosophy\">science of intuition</a>].&quot;</p><p>But for convenience I do need to invent a <em>name</em> for my theory of metaethics. I call it <em>pluralistic moral reductionism</em>.</p><p></p><p>Next post: <a href=\"https://www.lesserwrong.com/lw/5eh/what_is_metaethics/\">What is Metaethics?</a></p><p></p><p></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Z8wZZLeLMJ3NSK7kR": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SFnfhJkGsBQk8jakK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 55, "baseScore": 50, "extendedScore": null, "score": 9.5e-05, "legacy": true, "legacyId": "6649", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "bQgRsy23biR52poMf", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "s4Mcg9aLMeRwdW7fh", "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 51, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 59, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zThWT5Zvifo5qYaca", "48DTJkBH58JbBNSFH", "3buXtNiSK8gcRLMSG", "n5ucT5ZbPdhfGNLtP", "cSXZpvqpa9vbGGLtG", "4ARaTpNX62uaL86j6", "synsRtBKDeAFuo7e3", "Mc6QcrsbH5NRXbCRX", "WBdvyyHLdxZSAMmoz", "GKfPL6LQFgB49FEnv", "7X2j8HAkWdmMoS8PE", "d5NyJ2Lf6N22AD9PB", "yA4gF5KrboK2m2Xu7", "ZTRiSNmeGQK8AkdN2", "f6ZLxEWaankRZ2Crv", "tPqQdLCuxanjhoaNs", "YYLmZFEGKsjCKQZut", "HnS6c5Xm9p9sbm4a8", "iGH7FSrdoCXa5AHGs", "895quRDaK6gR2rM82", "s4Mcg9aLMeRwdW7fh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T06:39:44.846Z", "modifiedAt": null, "url": null, "title": ".", "slug": "", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:38.620Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "a7xJQpZ55R6SxFTik", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/796CsBqrpNNtYnHNN/", "pageUrlRelative": "/posts/796CsBqrpNNtYnHNN/", "linkUrl": "https://www.lesswrong.com/posts/796CsBqrpNNtYnHNN/", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F796CsBqrpNNtYnHNN%2F%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F796CsBqrpNNtYnHNN%2F", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F796CsBqrpNNtYnHNN%2F", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "796CsBqrpNNtYnHNN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.06189986132929e-07, "legacy": true, "legacyId": "6999", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T08:10:13.048Z", "modifiedAt": null, "url": null, "title": "Mini-camp on Rationality, Awesomeness, and Existential Risk (May 28 through June 4, 2011)", "slug": "mini-camp-on-rationality-awesomeness-and-existential-risk", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:34.431Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9vBasHrBtCmC6zAzD/mini-camp-on-rationality-awesomeness-and-existential-risk", "pageUrlRelative": "/posts/9vBasHrBtCmC6zAzD/mini-camp-on-rationality-awesomeness-and-existential-risk", "linkUrl": "https://www.lesswrong.com/posts/9vBasHrBtCmC6zAzD/mini-camp-on-rationality-awesomeness-and-existential-risk", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mini-camp%20on%20Rationality%2C%20Awesomeness%2C%20and%20Existential%20Risk%20(May%2028%20through%20June%204%2C%202011)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMini-camp%20on%20Rationality%2C%20Awesomeness%2C%20and%20Existential%20Risk%20(May%2028%20through%20June%204%2C%202011)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9vBasHrBtCmC6zAzD%2Fmini-camp-on-rationality-awesomeness-and-existential-risk%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mini-camp%20on%20Rationality%2C%20Awesomeness%2C%20and%20Existential%20Risk%20(May%2028%20through%20June%204%2C%202011)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9vBasHrBtCmC6zAzD%2Fmini-camp-on-rationality-awesomeness-and-existential-risk", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9vBasHrBtCmC6zAzD%2Fmini-camp-on-rationality-awesomeness-and-existential-risk", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1081, "htmlBody": "<p><em>Meet fellow LW-ers, hone your rationality, and get on a path toward reducing existential risk and becoming more awesome.</em></p>\n<p><em>Who:</em> You and a class full of other aspiring rationalists and world-changers, from around the world.</p>\n<p><em>What:</em> A week-long mini-camp, filled with hands-on activities for applying rationality to your life, your goals, and existential risk reduction. &nbsp;(See details in the FAQ.)</p>\n<p><em style=\"font-style: italic;\">When and where:</em>&nbsp;Saturday May 28 through Saturday June 4, 2011 in&nbsp;Berkeley, California.</p>\n<p><em>Why:</em> Because you&rsquo;re a social primate, and the best way to jump into a new way of thinking, make friends, and accomplish your goals is often to spend time with other primates who are doing just that.&nbsp;</p>\n<p><em><a id=\"more\"></a></em><em style=\"font-style: italic;\">Other reasons:</em></p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>Sing karaoke, develop body language skills, and generally try things, building courage.</li>\n<li>See the San Francisco Bay area.</li>\n<li>Get an inside look at the Singularity Institute.</li>\n</ul>\n<p><em>Instructors:</em></p>\n<p><img style=\"width: 114px; border: 0px initial initial;\" src=\"http://singinst.org/files/anna_salamon2.jpg\" alt=\"Anna Salamon\" />&nbsp;<img style=\"width: 126px;\" src=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Luke-thumbnail.png\" alt=\"\" />&nbsp;<img style=\"width: 100px; border: 0px initial initial;\" src=\"http://profile.ak.fbcdn.net/hprofile-ak-snc4/41401_569_659_n.jpg\" alt=\"Divia Melwani\" />&nbsp;</p>\n<p><a href=\"http://annasalamon.com/\">Anna Salamon</a><span style=\"white-space: pre;\">&nbsp;<span style=\"white-space: pre;\"> <span style=\"white-space: pre;\"> <span style=\"white-space: pre;\"> </span></span></span></span><a href=\"http://tinyurl.com/MyLWposts\">Luke\"prog\"</a> <a href=\"http://commonsenseatheism.com/\">Muehlhauser</a> <span style=\"white-space: pre;\"> </span><a href=\"/user/divia\">Divia Melwani</a></p>\n<p><em>Cost:</em> &nbsp;Room[1], board, and tuition are paid for by the Singularity Institute (see below). &nbsp;Getting here is up to you. &nbsp;(A limited number of scholarships are also available to cover the costs of flights; so if you&rsquo;d love to come but can&rsquo;t afford it, apply anyhow.)</p>\n<p>A week isn&rsquo;t long enough to learn rationality or how to prevent existential risks. &nbsp;It isn&rsquo;t long enough to acquire a cool career or master the skills that will help you succeed. But it is long enough to get on a path toward doing these things.</p>\n<p>So if you&rsquo;ve been wanting the above, now is your moment. &nbsp;Come meet us! See what we can help you do.</p>\n<p><a href=\"https://spreadsheets0.google.com/spreadsheet/viewform?hl=en&amp;formkey=dFlxd1p3Z0R5Y1dKaDNZWjFfWDBqRWc6MQ&amp;ifq\"><strong>Apply now.</strong></a></p>\n<p><strong>Frequently Asked Questions:</strong></p>\n<p><em>1. &nbsp;I&rsquo;m older. &nbsp;Should I still apply?</em></p>\n<p style=\"padding-left: 30px;\">Yes! &nbsp;We&rsquo;d really love a more diverse crowd around here, with a wider set of experiences and skills.</p>\n<p><em>2. &nbsp;I&rsquo;d like to come, but I&rsquo;m not sure you&rsquo;ll accept me. &nbsp;Should I still apply?</em></p>\n<p style=\"padding-left: 30px;\">Absolutely! &nbsp; You can fill out our form in as little 10 minutes. &nbsp;What&rsquo;s the harm?[2]</p>\n<p><em>3. &nbsp;I&rsquo;d like to come, but I can&rsquo;t afford the flights. &nbsp;Should I still apply?</em></p>\n<p style=\"padding-left: 30px;\">Yes. &nbsp;A limited number of flights scholarships will probably be available.</p>\n<p><em>4. &nbsp;Can I come for just part of the time?</em></p>\n<p style=\"padding-left: 30px;\">Yes. If work or other obligations prevent you from coming for the full week, we are open to partial visits. &nbsp;You&rsquo;ll miss out on some of the activities, and some of the sessions will make less sense without the prereqs; but for mini-camp, part of a visit is better than none.</p>\n<p><em>5. &nbsp;What will we do, exactly?</em></p>\n<p style=\"padding-left: 30px; \">We're still working out the details. &nbsp;But our current model:</p>\n<ul>\n<li><strong>Daily schedule:</strong> Every day, you'll get two three-hour course sessions, meals shared with other participants, and shared social activities such as soccer, poker, karaoke, and trips to bay area sites.</li>\n<li><strong>Rationality:</strong>&nbsp;Eight three-hour sessions. &nbsp;You'll develop a map of your rationality strengths and gaps, <a href=\"/lw/25d/too_busy_to_think_about_life/\">write out your goals</a>, practice many specific techniques (e.g. Fermi calculations; applying Bayes' theorem and cognitive biases to daily life; seeing how fungibility can boost your goal achievement), and learn how to continue learning rationality after the program.</li>\n<li><strong>Social effectiveness:</strong>&nbsp;&nbsp;Five three-hour sessions, covering: why social reality is so important for achieving goals rationally; reading and using body language; developing a fashion sense; and developing social courage and success.</li>\n<li><strong>Reducing Existential Risk:</strong>&nbsp;Three three-hour sessions, discussing AI risks, other existential risks, large-scale risk reduction strategies, and what can be done today.</li>\n<li><strong>Individual meetings:</strong>&nbsp;You'll also be able to schedule one-on-one appointments to discuss career paths you may want to take (we can help with statistics on earnings in different professions, and strategy for getting in), how to start a LW meet-up or similar community,&nbsp;and how to get involved in existential risks-reducing research.</li>\n</ul>\n<p><em>6. &nbsp;I&rsquo;m new to all this. &nbsp;Will it make sense?</em></p>\n<p style=\"padding-left: 30px;\">If you&rsquo;ve read at least twenty posts from <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\">the</a> <a href=\"http://wiki.lesswrong.com/wiki/Reductionism_(sequence)\">core</a> <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">sequences</a>, yes it will. &nbsp;If you haven&rsquo;t: why not read them now?</p>\n<p><em>7. &nbsp;I&rsquo;ve already read the Sequences seventeen times, and also I&rsquo;m a self-made billionaire[3] with three PhDs. &nbsp;Will I learn anything new?</em></p>\n<p style=\"padding-left: 30px;\">I hope so. &nbsp;We&rsquo;re covering a good range of material, and we&rsquo;ll be focusing on the fundamentals -- pieces that you get some mileage from knowing a little, and more mileage from knowing more thoroughly, and integrating into all aspects of your thoughts.</p>\n<p style=\"padding-left: 30px;\">We&rsquo;ll also aim for an atmosphere in which everyone is free to make mistakes and to try things, and in which people are receptive to a wide range of skill levels.</p>\n<p><em>8. &nbsp;Why is the Singularity Institute paying for this?</em></p>\n<p style=\"padding-left: 30px;\">We're trying to <a href=\"http://intelligence.org/riskintro/index.html\">reduce existential risk</a> -- to increase the odds that an eventual Singularity is good, from the perspective of humane values. &nbsp;To do this, we need more rational, effective people -- people who can&nbsp;train to do the needed research, who can fund that or other work,&nbsp;and who can otherwise exert influence toward good outcomes.</p>\n<p style=\"padding-left: 30px;\">So, we're hoping you'll come out to the SF Bay Area and spend a week boosting your personal effectiveness, having fun, and growing community. &nbsp;Similar past ventures, notably the&nbsp;<a href=\"http://intelligence.org/aboutus/visitingfellows\">old visiting fellows program</a>, have shown that this can be fruitful; and so, since the full&nbsp;<a href=\"/lw/4wm/rationality_boot_camp/\">rationality boot camp</a>&nbsp;is too long for many, we wanted to offer a shorter version that more people could try.</p>\n<p style=\"padding-left: 30px;\"><a href=\"https://spreadsheets0.google.com/spreadsheet/viewform?hl=en&amp;formkey=dFlxd1p3Z0R5Y1dKaDNZWjFfWDBqRWc6MQ&amp;ifq\"><strong>Apply now.</strong></a></p>\n<hr />\n<p>[1] More exactly, we provide a bed in a shared room at a house rented by SIAI. &nbsp;You can also stay elsewhere in the local area if you prefer.</p>\n<p>[2] Sometimes people say they&rsquo;re &ldquo;afraid of wasting our time&rdquo; by sending in an application. &nbsp;This is ridiculous. &nbsp;If you&rsquo;re interested in us, we&rsquo;re interested in you. &nbsp;Also, it takes just seconds to read someone&rsquo;s form, and many of the highest-value people have been the ones who hesitated to apply.</p>\n<p>[3] Okay, fine, this isn&rsquo;t really a frequently asked question. &nbsp;But seriously, we&rsquo;ll be covering a lot that isn&rsquo;t in the sequences -- and the flesh-and-blood experience of meeting other aspiring rationalists is hard to duplicate.</p>\n<p>&nbsp;</p>\n<p><strong>ETA: Women, especially, please apply! &nbsp;</strong>It's time to make LW a more whole community; rationality applies to any career and life-circumstance, but we need a broad set of people, careers, and life-experiences to create that rationality.</p>\n<p><strong style=\"font-weight: bold;\">ETA: Applications for mini-camp are now closed. &nbsp;Also, everyone who applied to mini-camp should now have heard back as to whether they got in&nbsp;</strong>(except for the few who didn't answer our emails requesting an interview). &nbsp;If you applied but haven't heard back, check your spam filter and then email annasalamon at gmail dot com. &nbsp;Also, if you'd like to be emailed about any future mini-camps we may run, please email&nbsp;annasalamon at gmail dot com. &nbsp;We received 112 applications for just over 20 spots in mini-camp.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DQHWBcKeiLnyh9za9": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9vBasHrBtCmC6zAzD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 52, "extendedScore": null, "score": 0.0005863017106431277, "legacy": true, "legacyId": "6996", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 87, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4psQW7vRwt7PE5Pnj", "s887k4Hcqj28cchYo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T10:21:38.240Z", "modifiedAt": null, "url": null, "title": "Paris Meetup, Saturday April 30th, 2PM", "slug": "paris-meetup-saturday-april-30th-2pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:47.846Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cMNt7LZnKfhSGJn3v/paris-meetup-saturday-april-30th-2pm", "pageUrlRelative": "/posts/cMNt7LZnKfhSGJn3v/paris-meetup-saturday-april-30th-2pm", "linkUrl": "https://www.lesswrong.com/posts/cMNt7LZnKfhSGJn3v/paris-meetup-saturday-april-30th-2pm", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Paris%20Meetup%2C%20Saturday%20April%2030th%2C%202PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AParis%20Meetup%2C%20Saturday%20April%2030th%2C%202PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcMNt7LZnKfhSGJn3v%2Fparis-meetup-saturday-april-30th-2pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Paris%20Meetup%2C%20Saturday%20April%2030th%2C%202PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcMNt7LZnKfhSGJn3v%2Fparis-meetup-saturday-april-30th-2pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcMNt7LZnKfhSGJn3v%2Fparis-meetup-saturday-april-30th-2pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><strong>When</strong>: Saturday, April 30th, 2PM.</p>\n<p><strong>Where</strong>: Au Pt'it Chat, a little Caf&eacute; near <a><span class=\"pp-place-title\"><span>Ch&acirc;telet</span></span></a>, which is <a href=\"http://maps.google.fr/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=paris&amp;aq=&amp;sll=48.860318,2.348306&amp;sspn=0.00186,0.004823&amp;gl=fr&amp;ie=UTF8&amp;hq=&amp;hnear=Paris,+%C3%8Ele-de-France&amp;ll=48.859206,2.347764&amp;spn=0.00084,0.004823&amp;z=18&amp;layer=c&amp;cbll=48.859205,2.347764&amp;panoid=KtpE5z8iB3CwytC7FkmpQA&amp;cbp=11,296.05,,0,12\">here</a>. I'll be there with a LessWrong sign.</p>\n<p>Yvain, cousin_it and Morendil should be there ... and <em>you</em> are welcome too!</p>\n<p>This is a repost, the meetup was <a href=\"/lw/52z/paris_meetup_saturday_april_16th_2pm/\">originally planned</a> the 16th, but that post wasn't promoted and the date changed in the meantime.</p>\n<p>Lurkers and newbies are very welcome!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cMNt7LZnKfhSGJn3v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.062526972427963e-07, "legacy": true, "legacyId": "7000", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["w7HiuFcAzjbfz6zYB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T18:03:07.743Z", "modifiedAt": null, "url": null, "title": "What To Do: Environmentalism vs Friendly AI (John Baez)", "slug": "what-to-do-environmentalism-vs-friendly-ai-john-baez", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:38.818Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YN6SiiGgTJDH8SgrD/what-to-do-environmentalism-vs-friendly-ai-john-baez", "pageUrlRelative": "/posts/YN6SiiGgTJDH8SgrD/what-to-do-environmentalism-vs-friendly-ai-john-baez", "linkUrl": "https://www.lesswrong.com/posts/YN6SiiGgTJDH8SgrD/what-to-do-environmentalism-vs-friendly-ai-john-baez", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20To%20Do%3A%20Environmentalism%20vs%20Friendly%20AI%20(John%20Baez)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20To%20Do%3A%20Environmentalism%20vs%20Friendly%20AI%20(John%20Baez)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYN6SiiGgTJDH8SgrD%2Fwhat-to-do-environmentalism-vs-friendly-ai-john-baez%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20To%20Do%3A%20Environmentalism%20vs%20Friendly%20AI%20(John%20Baez)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYN6SiiGgTJDH8SgrD%2Fwhat-to-do-environmentalism-vs-friendly-ai-john-baez", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYN6SiiGgTJDH8SgrD%2Fwhat-to-do-environmentalism-vs-friendly-ai-john-baez", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 734, "htmlBody": "<blockquote>\n<p>In a <a href=\"http://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/#comment-5403\">comment</a> on my last interview with Yudkowsky, Eric Jordan wrote:</p>\n<p style=\"padding-left: 30px;\">John, it would be great if you could follow up at some point with your thoughts and responses to what Eliezer said <a href=\"http://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/#comments\">here</a>. He&rsquo;s got a pretty firm view that environmentalism would be a waste of your talents, and it&rsquo;s obvious where he&rsquo;d like to see you turn your thoughts instead. I&rsquo;m especially curious to hear what you think of his argument that there are already millions of bright people working for the environment, so your personal contribution wouldn&rsquo;t be as important as it would be in a less crowded field.</p>\n<p>I&rsquo;ve been thinking about this a lot.</p>\n<p>[...]</p>\n<p>This a big question. It&rsquo;s a bit self-indulgent to discuss it publicly&hellip; or maybe not. It is, after all, a question we <em>all</em> face. I&rsquo;ll talk about me, because I&rsquo;m not up to tackling this question in its universal abstract form. But it could be you asking this, too.</p>\n<p>[...]</p>\n<p>I&rsquo;ll admit I&rsquo;d be happy to sit back and let everyone else deal with these problems. But the more I study them, the more that seems untenable&hellip; especially since so many people are doing just that: sitting back and letting everyone else deal with them.</p>\n<p>[...]</p>\n<p>I think so far the Azimuth Project is proceeding in a sufficiently unconventional way that while it may fall flat on its face, it&rsquo;s at least trying something new.</p>\n<p>[...]</p>\n<p>The most visible here is the <a href=\"http://math.ucr.edu/home/baez/networks/networks.html\">network theory</a> project, which is a step towards the kind of math I think we need to understand a wide variety of complex systems.</p>\n<p>[...]</p>\n<p>I don&rsquo;t feel satisfied, though. I&rsquo;m happy enough&mdash;that&rsquo;s never a problem these days&mdash;but once you start trying to do things to help the world, instead of just have fun, it&rsquo;s very tricky to determine the best way to proceed.</p>\n</blockquote>\n<p><strong>Link:</strong> <a href=\"http://johncarlosbaez.wordpress.com/2011/04/24/what-to-do/\">johncarlosbaez.wordpress.com/2011/04/24/what-to-do/</a></p>\n<p>His answer, as far as I can tell, seems to be that his <a href=\"http://www.math.ntnu.no/~stacey/Mathforge/Azimuth/\">Azimuth Project</a> does trump the possibility of working directly on friendly AI or to support it indirectly by making and contributing money.</p>\n<p>It seems that he and other people who understand all the arguments in favor of friendly AI and yet decide to ignore it, or <a href=\"http://hplusmagazine.com/2011/04/15/friendly-ai-a-dangerous-delusion/\">disregard it as unfeasible</a>, are <a href=\"http://measureofdoubt.com/2011/04/20/how-to-spot-a-rationalization/\">rationalizing</a>.</p>\n<p>I myself took a different route, I was rather trying to prove to myself that the whole idea of <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">AI going FOOM</a> is somehow flawed rather than trying to come up with justifications for why it would be better to work on something else.</p>\n<p>I still have some doubts though. Is it really enough to observe that the arguments in favor of AI going FOOM are logically valid? When should one disregard tiny probabilities of vast utilities and wait for empirical evidence? Yet I think that compared to the alternatives the arguments in favor of friendly AI are water-tight.</p>\n<p>The problem why I and other people seem to be reluctant to accept that it is rational to support friendly AI research is that the consequences are unbearable. Robin Hanson recently <a href=\"http://www.overcomingbias.com/2011/04/what-do-i-want-to-know.html\">described the problem</a>:</p>\n<blockquote>\n<p>Reading the novel Lolita while listening to Winston&rsquo;s Summer, thinking a fond friend&rsquo;s companionship, and sitting next to my son, all on a plane traveling home, I realized how vulnerable I am to needing such things. I&rsquo;d like to think that while I enjoy such things, I could take them or leave them. But that&rsquo;s probably not true. I like to think I&rsquo;d give them all up if needed to face and speak important truths, but well, that seems unlikely too. If some opinion of mine seriously threatened to deprive me of key things, my subconscious would probably find a way to see the reasonableness of the other side.</p>\n<p>So if my interests became strongly at stake, and those interests deviated from honesty, I&rsquo;ll likely not be reliable in estimating truth.</p>\n</blockquote>\n<p>I believe that people like me feel that to fully accept the importance of friendly AI research would deprive us of the things we value and <em>need</em>.</p>\n<p>I feel that I wouldn't be able to justify what I value on the grounds of needing such things. It feels like that I could and should overcome everything that isn't either directly contributing to FAI research or that helps me to earn more money that I could contribute.</p>\n<p>Some of us value and need things that consume a lot of time...that's the problem.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"EeSkeTcT4wtW2fWsL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YN6SiiGgTJDH8SgrD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 31, "extendedScore": null, "score": 7.063840227296874e-07, "legacy": true, "legacyId": "7002", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 63, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T18:44:35.928Z", "modifiedAt": null, "url": null, "title": "Get data points on your current utility function via hypotheticals", "slug": "get-data-points-on-your-current-utility-function-via", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:34.939Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yzpRwNw8EJGx2AEQ5/get-data-points-on-your-current-utility-function-via", "pageUrlRelative": "/posts/yzpRwNw8EJGx2AEQ5/get-data-points-on-your-current-utility-function-via", "linkUrl": "https://www.lesswrong.com/posts/yzpRwNw8EJGx2AEQ5/get-data-points-on-your-current-utility-function-via", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Get%20data%20points%20on%20your%20current%20utility%20function%20via%20hypotheticals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGet%20data%20points%20on%20your%20current%20utility%20function%20via%20hypotheticals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyzpRwNw8EJGx2AEQ5%2Fget-data-points-on-your-current-utility-function-via%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Get%20data%20points%20on%20your%20current%20utility%20function%20via%20hypotheticals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyzpRwNw8EJGx2AEQ5%2Fget-data-points-on-your-current-utility-function-via", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyzpRwNw8EJGx2AEQ5%2Fget-data-points-on-your-current-utility-function-via", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<p>I've recently found that my utility function valued personal status and fame a whole lot more than I thought it did -- I previously had thought that it mostly relied on the consequences of my actions for other sentiences, but it turned out I was wrong. Obviously, this is a valuable insight -- I definitely want to know what my current utility function is; from there, I can decide whether I should change my actions or my utility function if the two aren't coordinated.</p>\n<p>I did this by imagining how I would feel if I found out certain things. For example, how would I feel if everyone else was also trying to save the world? The emotional response I had was sort of a hollow feeling in the pit of my stomach, like I was a really mediocre being. This obviously wasn't a result of calculating that the marginal utility of my actions would be a whole lot lower in this hypothetical world (and so I should go do something else); instead, it was the fact that me trying to save the world didn't make me special any more -- I wouldn't stand out, in this sort of world.</p>\n<p>(Epilogue: I decided that I hadn't done a good enough job programming my brain and am attempting to modify my utility function to rely on the world actually getting saved.)</p>\n<p>Discussion: What other hypotheticals are useful?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yzpRwNw8EJGx2AEQ5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 7.063958005044283e-07, "legacy": true, "legacyId": "7003", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T20:09:35.864Z", "modifiedAt": null, "url": null, "title": "Edinburgh LW Meetup Saturday April 30th", "slug": "edinburgh-lw-meetup-saturday-april-30th", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:39.664Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sark", "createdAt": "2010-01-20T20:18:10.889Z", "isAdmin": false, "displayName": "sark"}, "userId": "cJYNhyCitpdzsZqeP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8Em5uo5QdZZdas9gz/edinburgh-lw-meetup-saturday-april-30th", "pageUrlRelative": "/posts/8Em5uo5QdZZdas9gz/edinburgh-lw-meetup-saturday-april-30th", "linkUrl": "https://www.lesswrong.com/posts/8Em5uo5QdZZdas9gz/edinburgh-lw-meetup-saturday-april-30th", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Edinburgh%20LW%20Meetup%20Saturday%20April%2030th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEdinburgh%20LW%20Meetup%20Saturday%20April%2030th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Em5uo5QdZZdas9gz%2Fedinburgh-lw-meetup-saturday-april-30th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Edinburgh%20LW%20Meetup%20Saturday%20April%2030th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Em5uo5QdZZdas9gz%2Fedinburgh-lw-meetup-saturday-april-30th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Em5uo5QdZZdas9gz%2Fedinburgh-lw-meetup-saturday-april-30th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 128, "htmlBody": "<p><a id=\"more\"></a></p>\n<p>The second Edinburgh LW meetup.</p>\n<p>The first one was 2 weeks ago. It was fun. Do join us!</p>\n<p>Date/time: Saturday 30th of April at 2:00pm.</p>\n<p>Place: A pub called the <a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://maps.google.co.uk/maps?channel=cs&amp;ie=UTF8&amp;q=auld+hoose&amp;fb=1&amp;gl=uk&amp;hq=auld+hoose&amp;hnear=Edinburgh&amp;cid=0,0,13163354907392914601&amp;t=h&amp;z=15&amp;iwloc=A\">Auld Hoose</a>. I would be holding a sign with \"Less Wrong\" written on it.</p>\n<p>Rough agenda: We will discuss akrasia. We will state our projects and discuss how we intend to keep track of their progress and how we can stay on track. We will also discuss anything else! Feel free to suggest additional topics so that we can coordinate on some preparation to ensure a smoother more enjoyable discussion.</p>\n<p>Please RSVP here: <a href=\"http://www.facebook.com/event.php?eid=183616241685780\">http://www.facebook.com/event.php?eid=183616241685780</a></p>\n<p>See you there!</p>\n<p>EDIT: I would like to thank the attendees of the first meetup for their very enjoyable company. You made the meetup a success. Now let's do it again!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8Em5uo5QdZZdas9gz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.064199420614039e-07, "legacy": true, "legacyId": "7004", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T20:24:51.205Z", "modifiedAt": null, "url": null, "title": "Being Wrong about Your Own Subjective Experience", "slug": "being-wrong-about-your-own-subjective-experience", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:05.871Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J55XeCNeF7wNwgCj9/being-wrong-about-your-own-subjective-experience", "pageUrlRelative": "/posts/J55XeCNeF7wNwgCj9/being-wrong-about-your-own-subjective-experience", "linkUrl": "https://www.lesswrong.com/posts/J55XeCNeF7wNwgCj9/being-wrong-about-your-own-subjective-experience", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Being%20Wrong%20about%20Your%20Own%20Subjective%20Experience&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeing%20Wrong%20about%20Your%20Own%20Subjective%20Experience%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ55XeCNeF7wNwgCj9%2Fbeing-wrong-about-your-own-subjective-experience%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Being%20Wrong%20about%20Your%20Own%20Subjective%20Experience%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ55XeCNeF7wNwgCj9%2Fbeing-wrong-about-your-own-subjective-experience", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ55XeCNeF7wNwgCj9%2Fbeing-wrong-about-your-own-subjective-experience", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2128, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/David_Hume\">Hume</a> was skeptical of induction and causality. <a href=\"http://en.wikipedia.org/wiki/Ren%C3%A9_Descartes\">Descartes</a> began his philosophy by doubting <em>everything</em>. Both thought we may be in great error about the external world. But neither could bring themselves to seriously doubt the contents of their own subjective conscious experience.</p>\n<p>Philosophers and non-philosophers alike often say: \"I may not know whether that is really a yellow banana before me, but surely I know the character of my <em>visual experience</em>&nbsp;of a yellow banana! I may not know whether I really just dropped a barbell on my toe, but surely I know the subjective character of my <em>pain experience</em>, right?\"</p>\n<p>In this article I hope to persuade you that yes, you <em>can</em>&nbsp;be wrong about the subjective quality of your own conscious experience. In fact, such errors are common.</p>\n<p>&nbsp;</p>\n<h4 style=\"font-size: 14px; color: black; float: none;\">Human echolocation</h4>\n<p>Thomas Nagel famously said that we cannot imagine the subjective experience of bat sonar:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>Bat sonar, though clearly a form of perception, is not similar in its operation to any sense that we possess, and there is no reason to suppose that it is subjectively like anything we can experience or imagine.<sup>1</sup></p>\n</blockquote>\n<p>Hold up a book in front of your face at arm's length, close your eyes, and say something loudly.&nbsp;Can you hear the emptiness of the space in front of you?&nbsp;Close your eyes again, hold the book directly in front of your face, and say the book's name again. Can you now&nbsp;<em>hear</em>&nbsp;that the book is closer?</p>\n<p>I'll bet you can, and thus you may be more bat-like than Nagel seems to think is possible, and more bat-like than you have previously thought. When I discovered this, I realized that not only had I been wrong about my perceptual&nbsp;<em>capabilities</em>, I had also been ignorant of the&nbsp;<em>daily content of my subjective auditory experience</em>.</p>\n<p>Blind people can be <a href=\"http://www.worldaccessfortheblind.org/taxonomy/term/16\">especially good</a> at using echolocation to navigate the world. Just like bats and dolphins and whales (but less accurately), humans can make sounds and then hear how nearby objects reflect and modify those sounds. People with normal vision can also be trained to echolocate to some degree with training, for example detecting the location of walls while blindfolded.<sup>2</sup> After some practice, blindfolded people can use sound to distinguish objects of different shapes and textures (at a rate significantly better than chance).<sup>3</sup></p>\n<p>You can try this yourself. Get a friend to blindfold you and then move their hand to one of four quadrants of space in front of your face. Try hissing or talking loudly and see if you can tell something about where your friend's hand is. Have your friend move their hand to another quadrant, and try again. Do this a few dozen times. I suspect you will find that after a while you'll do better than chance at locating the quadrant your friend's hand is in, and you may be able to tell something about its distance as well. If so, you are echolocating. You are having an <em>auditory</em>&nbsp;experience of the physical location of an object - something you may not have realized that you can do, something you probably <em>have</em>&nbsp;been doing your whole life without much realizing it.</p>\n<p>Alternatively, have a friend blindfold you and place you some unspecified distance from a wall. Step toward the wall a few inches at a time, speaking loudly, and stop when the wall is directly in front of you. Most people find they can do this quite reliably. But of course you can't see or touch the wall, and the wall is making no sound of its own. You are echolocating.</p>\n<p>One final test to prove it to yourself, this one relevant to shape and texture. Close your eyes, repeat some syllable, and have a friend hold one of three objects in front of your face: a book, a wadded-up T-shirt, and a mixing bowl. I think you'll find that you can distinguish between these three silent objects better than chance, and that the book will <em>sound</em>&nbsp;solid, the T-shirt will <em>sound</em>&nbsp;soft, and the mixing bowl will <em>sound</em>&nbsp;hollow. You are echolocating <em>shape</em>&nbsp;and <em>texture</em>. <a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Does a coin look circular?</h4>\n<p>Set a coin on a desk or table three feet in front of you. Is its shape circular or elliptical?</p>\n<p>One popular view is to say that we perceive the coin in two aspects. In one aspect, we perceive the raw sense data from our visual plane, which shows the coin as being elliptical (because one end of it is stretching away from us). In another aspect, we perceive it as circular because our minds have an intuitive physics about the shape permanence of solid objects. Perhaps our minds 'flip' between seeing the coin from the two aspects - a kind of 'Gestalt shift' - just as it flips between seeing a rabbit and a duck in Wittgenstein's famous <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/02/duck-rabbit-big.png\">duck-rabbit drawing</a>.</p>\n<p>Schwitzgebel (2011) reports his own confusion:</p>\n<blockquote>\n<p>What exactly is my sensory experience as I stare at a penny? My first and recurring inclination is to say that the penny looks just plain circular, in a three-dimensional space - not elliptical at all... However, I also find that if I dip my head lower to view the penny from a flatter angle, I begin to see how one might think it looks elliptical. Closing one eye helps too... Am I experiencing the ellipse too? Maybe not. But neither can I say that I noticed any Gestalt shift... Could it be, simply, that my visual experience is disorganized, so that there is no simple relationship between viewing angle and apparent shape...?</p>\n<p>Maybe my terms and concepts are muddled. What is it for something to 'look elliptical'? ...</p>\n<p>Or am I simply a poor introspector? Maybe the fact that my own phenomenology in this case doesn't seem obvious to me reveals my introspective ineptitude... And yet I am not sure I should trust other [people's] introspections either.<sup>4</sup></p>\n</blockquote>\n<p>The character of our subjective experience of shape at varying angles and distances is widely debated by philosophers and psychologists,<sup>4</sup> lending some support to the claim that we are unsure of it.</p>\n<p>&nbsp;</p>\n<h4>What is the character of an imagined scene?</h4>\n<p>Close your eyes and picture the front of your house or apartment building from the street.</p>\n<p>Presumably, you know <em>that</em>&nbsp;you experience an image, and you know some aspects of its content (that it is a house, from a certain angle). But what else do you know? Schwitzgebel questions:</p>\n<blockquote>\n<p>How much of the scene can you vividly visualize at once? Can you keep the image of the chimney vividly in mind at the same time that you vividly imagine your front door, or how does the image of the chimney fade as you begin to think about the door? How much detail does your image have? How stable is it? If you can't visually imagine the entire front of your house in rich detail all at once, what happens to the aspects of the image that are relatively less detailed? If the chimney is still experienced as part of the imagery when your imagemaking energies are focused on the front door, how exactly is it experienced? Does it have determinate shape, determinate color? In general, do the objects in your image have color before you think to assign color to them, or do some of the colors remain indeterminate, at least for a while...? If there is indeterminacy of color, how is that indeterminacy experienced? As gray? Does your visual image have depth in the same way that your sensory experienced does... or is your imagery somehow flatter...? ...Do you experience the image as located somewhere in egocentric space - inside your head, or before your eyes, or in front of your forehead - or does it make no sense to attempt to assign it a position in this way?<sup>5</sup></p>\n</blockquote>\n<p>When questioned in this way, most people quickly become uncertain about the character of their own subjective conscious experience.</p>\n<p>&nbsp;</p>\n<h4>Do you dream in color?</h4>\n<p>Most people, when asked, are fairly confident of their answer. But the answer given (in&nbsp;questionnaires&nbsp;or after awakened during REM sleep) has varied widely throughout history and between persons.<sup>6</sup>&nbsp;Pre-scientific authors tended to assume they dreamed in color, while studies in the first half of the 20th century found very few people who reported dreaming in color. In the 1960s, this consensus was overturned, and recent studies show that today, more than 80% of people report that they dream in color. But there are also certain populations that overwhelming report dreaming in black and white.</p>\n<p>Is there something in our genes or in the air that decides whether or not we dream in color, or are we confused about our own subjective experience?</p>\n<p>Schwitzgebel reviews the arguments back and forth, but none give a clear answer. And unfortunately, there remains much disagreement about the neurology of color experience.<sup>7</sup></p>\n<p>&nbsp;</p>\n<h4>Is experience persistent?</h4>\n<p>Schwitzgebel asks:</p>\n<blockquote>\n<p>Do you have constant tactile experience of your feet in your shoes?... Constant visual experience of the frames of your eyeglasses? ... Is consciousness <em>abundant</em>, the stream of experience bristling with phenomenology in a wide variety of modalities simultaneously (visual, auditory, tactile, olfactory, imagistic, proprioceptive, emotional), or is it <em>sparse</em>, limited to one or a few things at a time?</p>\n<p>Suppose you have driven to work by the same route a thousand times. Today, you are absorbed in remembering an unpleasant interaction with your department head. Traffic is light, no dangerous situation occurs, and you drive habitually. You arrive at your usual parking area and seem to \"wake up\" - \"Ah, I'm at work already!\" - with virtually no memory of having driven there. Did you have visual experience while you were driving? You responded to events on the road, stopped at red lights, and stayed in your lane... But perhaps visual input can influence behavior without the involvement of consciousness.</p>\n</blockquote>\n<p>These are difficult questions, and both experts and laymen disagree as to their answers.<sup>8</sup></p>\n<p>&nbsp;</p>\n<h4>Sound and vision biases</h4>\n<p>Have you noticed that you perceive vertical distance as greater when you are looking down than when you are looking up? Well, you do.<sup>9</sup></p>\n<p>Have you noticed that you perceive changes in 'approaching' sounds as being greater than equivalent changes in 'receding' sounds? Have you noticed that you perceived 'approaching' sounds as occurring more near to you than 'receding' sounds? You do.<sup>10</sup></p>\n<p>&nbsp;</p>\n<h4>Conclusion</h4>\n<p>As many people who practices meditation seriously can tell you, the subjective contents of conscious experience are often surprising and uncertain. We can be wrong about our own subjective conscious experiences. Thus, they cannot serve as a bedrock for certainty and <em><a href=\"/lw/k2/a_priori/\">a priori</a></em>&nbsp;truth. (At least, minimally complex subjective conscious experiences cannot.)</p>\n<p>It seems that all we can do is exercise some <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/\">naturalized epistemology</a>:&nbsp;\"<a href=\"/lw/s0/where_recursive_justification_hits_bottom/\">reflecting</a> on your mind's degree of trustworthiness, using your current mind as opposed to something else.\" Luckily, the brain is <a href=\"/lw/jm/the_lens_that_sees_its_flaws/\">the lens that sees its flaws</a>, as demonstrated by surprising studies in human echolocation, the color of dreams, and more.</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup> Nagel (1974).</small></p>\n<p><small><sup>2</sup> Supa et al. (1944); Ammons et al. (1953); Roseblum et al. (2000).</small></p>\n<p><small><sup>3</sup> Hausfeld et al. (1982); Rosenblum &amp; Robert (2007); Gordon &amp; Rosenblum (2004).</small></p>\n<p><small><sup>4</sup>&nbsp;Schwitzgebel (2011), chapter 2. Note that I also interviewed the author <a href=\"http://commonsenseatheism.com/?p=12152\">here</a>. This post is basically a summary of a few sections of Schwitzgebel's book.</small></p>\n<p><small><sup>5</sup>&nbsp;Schwitzgebel (2011), chapter 3.</small></p>\n<p><small><sup>6</sup>&nbsp;Schwitzgebel (2011) reports that most people he ask about dreaming in color are fairly confident of their answer. Also see his Table 1.1, which summarizes the results of 21 studies on the reported color of dreams, some of which include confidence measures. Chapter 1 contains a summary of historical assumptions about dreaming in color.</small></p>\n<p><small><sup>7</sup>&nbsp;Gegenfurtner &amp; Kiper (2003); Solomon &amp; Lennie (2007); Wade et al. (2008); Conway (2009).</small></p>\n<p><small><sup>8</sup> Schwitzgebel (2011), chapter 6.</small></p>\n<p><small><sup>9</sup> Jackson &amp; Cormack (2008).</small></p>\n<p><small><sup>10</sup> Neuhoff (2001).</small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Ammons, Worchel, &amp; Dallenbach (1953). Facial vision: The perception of obstacles out of doors by blindfolded and blindfolded-deafened subjects. <em>American Journal of Psychology, 66</em>: 519-554.</small></p>\n<p><small>Conway (2009). Color vision, cones, and color-coding in the cortex. <em>Neuroscientist, 15</em>: 274-290.</small></p>\n<p><small>Gegenfurtner &amp; Kiper (2003). Color vision. <em>Annual Review of Neuroscience, 26</em>: 181-206.</small></p>\n<p><small>Gordon &amp; Rosenblum (2004). Perception of sound-obstructing surfaces using body-scaled judgments. <em>Ecological Psychology, 16</em>: 87-113.</small></p>\n<p><small>Hausfeld, Power, Gorta, &amp; Harris (1982). Echo perception of shape and texture by sighted subjects. <em>Perceptual and Motor Skills, 55</em>: 623-632.</small></p>\n<p><small>Jackson &amp; Cormack (2008). Evolved navigation theory and the descent illusion. <em>Evolution and Human Behavior, 29</em>: 299-304.</small></p>\n<p><small>Nagel (1974). <a href=\"http://umbral2.uprrp.edu/files/nagel.pdf\">What is it like to be a bat?</a> <em>Philosophical Review, 83</em>: 435-450.</small></p>\n<p><small>Neuhoff (2001). An adaptive bias in the perception of looming auditory motion. <em>Ecological Psychology, 13</em>: 87-113.</small></p>\n<p><small>Roseblum, Gordon, &amp; Jarquin (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Rosenblum-et-al-Echolocating-distance-by-moving-and-stationary-listeners.pdf\">Echolocating distance by moving and stationary listeners</a>. <em>Ecological Psychology, 12</em>: 181-206.</small></p>\n<p><small>Rosenblum &amp; Robert (2007). Hearing silent shapes: Identifying the shape of a sound-obstructing surface. <em>Ecological Psychology, 19</em>: 351-366.</small></p>\n<p><small>Schwitzgebel (2011). <em><a href=\"http://www.amazon.com/Perplexities-Consciousness-Life-Mind-Philosophical/dp/0262014904/\">Perplexities of Consciousness</a></em>. MIT Press.</small></p>\n<p><small>Solomon &amp; Lennie (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Solomon-Lennie-The-machinery-of-colour-vision.pdf\">The machinery of colour vision</a>. <em>Nature Reviews Neuroscience, 8</em>: 276-286.</small></p>\n<p><small>Supa, Cotzin, &amp; Dallenbach (1944). Facial vision: the perception of obstacles by the blind. <em>ASmerican Journal of Psychology, 62</em>: 133-183.</small></p>\n<p><small>Wade, Augath, Logothetis, &amp; Wandell (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Wade-et-al-fMRI-measurement-of-color-in-macaque-and-human.pdf\">fMRI measurement of color in macaque and human</a>. <em>Journal of Vision, 8(10)</em>: 1-19.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwv9eHi7KGg5KA9oM": 1, "XSryTypw5Hszpa4TS": 9, "5gcpKG2XEAZGj5DEf": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J55XeCNeF7wNwgCj9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 64, "baseScore": 55, "extendedScore": null, "score": 0.000105, "legacy": true, "legacyId": "6998", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 58, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a href=\"http://en.wikipedia.org/wiki/David_Hume\">Hume</a> was skeptical of induction and causality. <a href=\"http://en.wikipedia.org/wiki/Ren%C3%A9_Descartes\">Descartes</a> began his philosophy by doubting <em>everything</em>. Both thought we may be in great error about the external world. But neither could bring themselves to seriously doubt the contents of their own subjective conscious experience.</p>\n<p>Philosophers and non-philosophers alike often say: \"I may not know whether that is really a yellow banana before me, but surely I know the character of my <em>visual experience</em>&nbsp;of a yellow banana! I may not know whether I really just dropped a barbell on my toe, but surely I know the subjective character of my <em>pain experience</em>, right?\"</p>\n<p>In this article I hope to persuade you that yes, you <em>can</em>&nbsp;be wrong about the subjective quality of your own conscious experience. In fact, such errors are common.</p>\n<p>&nbsp;</p>\n<h4 style=\"font-size: 14px; color: black; float: none;\" id=\"Human_echolocation\">Human echolocation</h4>\n<p>Thomas Nagel famously said that we cannot imagine the subjective experience of bat sonar:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>Bat sonar, though clearly a form of perception, is not similar in its operation to any sense that we possess, and there is no reason to suppose that it is subjectively like anything we can experience or imagine.<sup>1</sup></p>\n</blockquote>\n<p>Hold up a book in front of your face at arm's length, close your eyes, and say something loudly.&nbsp;Can you hear the emptiness of the space in front of you?&nbsp;Close your eyes again, hold the book directly in front of your face, and say the book's name again. Can you now&nbsp;<em>hear</em>&nbsp;that the book is closer?</p>\n<p>I'll bet you can, and thus you may be more bat-like than Nagel seems to think is possible, and more bat-like than you have previously thought. When I discovered this, I realized that not only had I been wrong about my perceptual&nbsp;<em>capabilities</em>, I had also been ignorant of the&nbsp;<em>daily content of my subjective auditory experience</em>.</p>\n<p>Blind people can be <a href=\"http://www.worldaccessfortheblind.org/taxonomy/term/16\">especially good</a> at using echolocation to navigate the world. Just like bats and dolphins and whales (but less accurately), humans can make sounds and then hear how nearby objects reflect and modify those sounds. People with normal vision can also be trained to echolocate to some degree with training, for example detecting the location of walls while blindfolded.<sup>2</sup> After some practice, blindfolded people can use sound to distinguish objects of different shapes and textures (at a rate significantly better than chance).<sup>3</sup></p>\n<p>You can try this yourself. Get a friend to blindfold you and then move their hand to one of four quadrants of space in front of your face. Try hissing or talking loudly and see if you can tell something about where your friend's hand is. Have your friend move their hand to another quadrant, and try again. Do this a few dozen times. I suspect you will find that after a while you'll do better than chance at locating the quadrant your friend's hand is in, and you may be able to tell something about its distance as well. If so, you are echolocating. You are having an <em>auditory</em>&nbsp;experience of the physical location of an object - something you may not have realized that you can do, something you probably <em>have</em>&nbsp;been doing your whole life without much realizing it.</p>\n<p>Alternatively, have a friend blindfold you and place you some unspecified distance from a wall. Step toward the wall a few inches at a time, speaking loudly, and stop when the wall is directly in front of you. Most people find they can do this quite reliably. But of course you can't see or touch the wall, and the wall is making no sound of its own. You are echolocating.</p>\n<p>One final test to prove it to yourself, this one relevant to shape and texture. Close your eyes, repeat some syllable, and have a friend hold one of three objects in front of your face: a book, a wadded-up T-shirt, and a mixing bowl. I think you'll find that you can distinguish between these three silent objects better than chance, and that the book will <em>sound</em>&nbsp;solid, the T-shirt will <em>sound</em>&nbsp;soft, and the mixing bowl will <em>sound</em>&nbsp;hollow. You are echolocating <em>shape</em>&nbsp;and <em>texture</em>. <a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Does_a_coin_look_circular_\">Does a coin look circular?</h4>\n<p>Set a coin on a desk or table three feet in front of you. Is its shape circular or elliptical?</p>\n<p>One popular view is to say that we perceive the coin in two aspects. In one aspect, we perceive the raw sense data from our visual plane, which shows the coin as being elliptical (because one end of it is stretching away from us). In another aspect, we perceive it as circular because our minds have an intuitive physics about the shape permanence of solid objects. Perhaps our minds 'flip' between seeing the coin from the two aspects - a kind of 'Gestalt shift' - just as it flips between seeing a rabbit and a duck in Wittgenstein's famous <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/02/duck-rabbit-big.png\">duck-rabbit drawing</a>.</p>\n<p>Schwitzgebel (2011) reports his own confusion:</p>\n<blockquote>\n<p>What exactly is my sensory experience as I stare at a penny? My first and recurring inclination is to say that the penny looks just plain circular, in a three-dimensional space - not elliptical at all... However, I also find that if I dip my head lower to view the penny from a flatter angle, I begin to see how one might think it looks elliptical. Closing one eye helps too... Am I experiencing the ellipse too? Maybe not. But neither can I say that I noticed any Gestalt shift... Could it be, simply, that my visual experience is disorganized, so that there is no simple relationship between viewing angle and apparent shape...?</p>\n<p>Maybe my terms and concepts are muddled. What is it for something to 'look elliptical'? ...</p>\n<p>Or am I simply a poor introspector? Maybe the fact that my own phenomenology in this case doesn't seem obvious to me reveals my introspective ineptitude... And yet I am not sure I should trust other [people's] introspections either.<sup>4</sup></p>\n</blockquote>\n<p>The character of our subjective experience of shape at varying angles and distances is widely debated by philosophers and psychologists,<sup>4</sup> lending some support to the claim that we are unsure of it.</p>\n<p>&nbsp;</p>\n<h4 id=\"What_is_the_character_of_an_imagined_scene_\">What is the character of an imagined scene?</h4>\n<p>Close your eyes and picture the front of your house or apartment building from the street.</p>\n<p>Presumably, you know <em>that</em>&nbsp;you experience an image, and you know some aspects of its content (that it is a house, from a certain angle). But what else do you know? Schwitzgebel questions:</p>\n<blockquote>\n<p>How much of the scene can you vividly visualize at once? Can you keep the image of the chimney vividly in mind at the same time that you vividly imagine your front door, or how does the image of the chimney fade as you begin to think about the door? How much detail does your image have? How stable is it? If you can't visually imagine the entire front of your house in rich detail all at once, what happens to the aspects of the image that are relatively less detailed? If the chimney is still experienced as part of the imagery when your imagemaking energies are focused on the front door, how exactly is it experienced? Does it have determinate shape, determinate color? In general, do the objects in your image have color before you think to assign color to them, or do some of the colors remain indeterminate, at least for a while...? If there is indeterminacy of color, how is that indeterminacy experienced? As gray? Does your visual image have depth in the same way that your sensory experienced does... or is your imagery somehow flatter...? ...Do you experience the image as located somewhere in egocentric space - inside your head, or before your eyes, or in front of your forehead - or does it make no sense to attempt to assign it a position in this way?<sup>5</sup></p>\n</blockquote>\n<p>When questioned in this way, most people quickly become uncertain about the character of their own subjective conscious experience.</p>\n<p>&nbsp;</p>\n<h4 id=\"Do_you_dream_in_color_\">Do you dream in color?</h4>\n<p>Most people, when asked, are fairly confident of their answer. But the answer given (in&nbsp;questionnaires&nbsp;or after awakened during REM sleep) has varied widely throughout history and between persons.<sup>6</sup>&nbsp;Pre-scientific authors tended to assume they dreamed in color, while studies in the first half of the 20th century found very few people who reported dreaming in color. In the 1960s, this consensus was overturned, and recent studies show that today, more than 80% of people report that they dream in color. But there are also certain populations that overwhelming report dreaming in black and white.</p>\n<p>Is there something in our genes or in the air that decides whether or not we dream in color, or are we confused about our own subjective experience?</p>\n<p>Schwitzgebel reviews the arguments back and forth, but none give a clear answer. And unfortunately, there remains much disagreement about the neurology of color experience.<sup>7</sup></p>\n<p>&nbsp;</p>\n<h4 id=\"Is_experience_persistent_\">Is experience persistent?</h4>\n<p>Schwitzgebel asks:</p>\n<blockquote>\n<p>Do you have constant tactile experience of your feet in your shoes?... Constant visual experience of the frames of your eyeglasses? ... Is consciousness <em>abundant</em>, the stream of experience bristling with phenomenology in a wide variety of modalities simultaneously (visual, auditory, tactile, olfactory, imagistic, proprioceptive, emotional), or is it <em>sparse</em>, limited to one or a few things at a time?</p>\n<p>Suppose you have driven to work by the same route a thousand times. Today, you are absorbed in remembering an unpleasant interaction with your department head. Traffic is light, no dangerous situation occurs, and you drive habitually. You arrive at your usual parking area and seem to \"wake up\" - \"Ah, I'm at work already!\" - with virtually no memory of having driven there. Did you have visual experience while you were driving? You responded to events on the road, stopped at red lights, and stayed in your lane... But perhaps visual input can influence behavior without the involvement of consciousness.</p>\n</blockquote>\n<p>These are difficult questions, and both experts and laymen disagree as to their answers.<sup>8</sup></p>\n<p>&nbsp;</p>\n<h4 id=\"Sound_and_vision_biases\">Sound and vision biases</h4>\n<p>Have you noticed that you perceive vertical distance as greater when you are looking down than when you are looking up? Well, you do.<sup>9</sup></p>\n<p>Have you noticed that you perceive changes in 'approaching' sounds as being greater than equivalent changes in 'receding' sounds? Have you noticed that you perceived 'approaching' sounds as occurring more near to you than 'receding' sounds? You do.<sup>10</sup></p>\n<p>&nbsp;</p>\n<h4 id=\"Conclusion\">Conclusion</h4>\n<p>As many people who practices meditation seriously can tell you, the subjective contents of conscious experience are often surprising and uncertain. We can be wrong about our own subjective conscious experiences. Thus, they cannot serve as a bedrock for certainty and <em><a href=\"/lw/k2/a_priori/\">a priori</a></em>&nbsp;truth. (At least, minimally complex subjective conscious experiences cannot.)</p>\n<p>It seems that all we can do is exercise some <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/\">naturalized epistemology</a>:&nbsp;\"<a href=\"/lw/s0/where_recursive_justification_hits_bottom/\">reflecting</a> on your mind's degree of trustworthiness, using your current mind as opposed to something else.\" Luckily, the brain is <a href=\"/lw/jm/the_lens_that_sees_its_flaws/\">the lens that sees its flaws</a>, as demonstrated by surprising studies in human echolocation, the color of dreams, and more.</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup> Nagel (1974).</small></p>\n<p><small><sup>2</sup> Supa et al. (1944); Ammons et al. (1953); Roseblum et al. (2000).</small></p>\n<p><small><sup>3</sup> Hausfeld et al. (1982); Rosenblum &amp; Robert (2007); Gordon &amp; Rosenblum (2004).</small></p>\n<p><small><sup>4</sup>&nbsp;Schwitzgebel (2011), chapter 2. Note that I also interviewed the author <a href=\"http://commonsenseatheism.com/?p=12152\">here</a>. This post is basically a summary of a few sections of Schwitzgebel's book.</small></p>\n<p><small><sup>5</sup>&nbsp;Schwitzgebel (2011), chapter 3.</small></p>\n<p><small><sup>6</sup>&nbsp;Schwitzgebel (2011) reports that most people he ask about dreaming in color are fairly confident of their answer. Also see his Table 1.1, which summarizes the results of 21 studies on the reported color of dreams, some of which include confidence measures. Chapter 1 contains a summary of historical assumptions about dreaming in color.</small></p>\n<p><small><sup>7</sup>&nbsp;Gegenfurtner &amp; Kiper (2003); Solomon &amp; Lennie (2007); Wade et al. (2008); Conway (2009).</small></p>\n<p><small><sup>8</sup> Schwitzgebel (2011), chapter 6.</small></p>\n<p><small><sup>9</sup> Jackson &amp; Cormack (2008).</small></p>\n<p><small><sup>10</sup> Neuhoff (2001).</small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Ammons, Worchel, &amp; Dallenbach (1953). Facial vision: The perception of obstacles out of doors by blindfolded and blindfolded-deafened subjects. <em>American Journal of Psychology, 66</em>: 519-554.</small></p>\n<p><small>Conway (2009). Color vision, cones, and color-coding in the cortex. <em>Neuroscientist, 15</em>: 274-290.</small></p>\n<p><small>Gegenfurtner &amp; Kiper (2003). Color vision. <em>Annual Review of Neuroscience, 26</em>: 181-206.</small></p>\n<p><small>Gordon &amp; Rosenblum (2004). Perception of sound-obstructing surfaces using body-scaled judgments. <em>Ecological Psychology, 16</em>: 87-113.</small></p>\n<p><small>Hausfeld, Power, Gorta, &amp; Harris (1982). Echo perception of shape and texture by sighted subjects. <em>Perceptual and Motor Skills, 55</em>: 623-632.</small></p>\n<p><small>Jackson &amp; Cormack (2008). Evolved navigation theory and the descent illusion. <em>Evolution and Human Behavior, 29</em>: 299-304.</small></p>\n<p><small>Nagel (1974). <a href=\"http://umbral2.uprrp.edu/files/nagel.pdf\">What is it like to be a bat?</a> <em>Philosophical Review, 83</em>: 435-450.</small></p>\n<p><small>Neuhoff (2001). An adaptive bias in the perception of looming auditory motion. <em>Ecological Psychology, 13</em>: 87-113.</small></p>\n<p><small>Roseblum, Gordon, &amp; Jarquin (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Rosenblum-et-al-Echolocating-distance-by-moving-and-stationary-listeners.pdf\">Echolocating distance by moving and stationary listeners</a>. <em>Ecological Psychology, 12</em>: 181-206.</small></p>\n<p><small>Rosenblum &amp; Robert (2007). Hearing silent shapes: Identifying the shape of a sound-obstructing surface. <em>Ecological Psychology, 19</em>: 351-366.</small></p>\n<p><small>Schwitzgebel (2011). <em><a href=\"http://www.amazon.com/Perplexities-Consciousness-Life-Mind-Philosophical/dp/0262014904/\">Perplexities of Consciousness</a></em>. MIT Press.</small></p>\n<p><small>Solomon &amp; Lennie (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Solomon-Lennie-The-machinery-of-colour-vision.pdf\">The machinery of colour vision</a>. <em>Nature Reviews Neuroscience, 8</em>: 276-286.</small></p>\n<p><small>Supa, Cotzin, &amp; Dallenbach (1944). Facial vision: the perception of obstacles by the blind. <em>ASmerican Journal of Psychology, 62</em>: 133-183.</small></p>\n<p><small>Wade, Augath, Logothetis, &amp; Wandell (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Wade-et-al-fMRI-measurement-of-color-in-macaque-and-human.pdf\">fMRI measurement of color in macaque and human</a>. <em>Journal of Vision, 8(10)</em>: 1-19.</small></p>", "sections": [{"title": "Human echolocation", "anchor": "Human_echolocation", "level": 1}, {"title": "Does a coin look circular?", "anchor": "Does_a_coin_look_circular_", "level": 1}, {"title": "What is the character of an imagined scene?", "anchor": "What_is_the_character_of_an_imagined_scene_", "level": 1}, {"title": "Do you dream in color?", "anchor": "Do_you_dream_in_color_", "level": 1}, {"title": "Is experience persistent?", "anchor": "Is_experience_persistent_", "level": 1}, {"title": "Sound and vision biases", "anchor": "Sound_and_vision_biases", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "191 comments"}], "headingsCount": 11}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 191, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qmqLxvtsPzZ2s6mpY", "oTX2LXHqXqYg2u4g6", "C8nEXTcjZb9oauTCW", "46qnWRSR7L2eyNbMA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T21:19:26.081Z", "modifiedAt": null, "url": null, "title": "Are Girl Scout Cookies Deliciously Evil? A Case Study in Evaluating Charities by Yourself", "slug": "are-girl-scout-cookies-deliciously-evil-a-case-study-in", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:40.757Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5swa8chZCtWynuFga/are-girl-scout-cookies-deliciously-evil-a-case-study-in", "pageUrlRelative": "/posts/5swa8chZCtWynuFga/are-girl-scout-cookies-deliciously-evil-a-case-study-in", "linkUrl": "https://www.lesswrong.com/posts/5swa8chZCtWynuFga/are-girl-scout-cookies-deliciously-evil-a-case-study-in", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Are%20Girl%20Scout%20Cookies%20Deliciously%20Evil%3F%20A%20Case%20Study%20in%20Evaluating%20Charities%20by%20Yourself&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAre%20Girl%20Scout%20Cookies%20Deliciously%20Evil%3F%20A%20Case%20Study%20in%20Evaluating%20Charities%20by%20Yourself%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5swa8chZCtWynuFga%2Fare-girl-scout-cookies-deliciously-evil-a-case-study-in%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Are%20Girl%20Scout%20Cookies%20Deliciously%20Evil%3F%20A%20Case%20Study%20in%20Evaluating%20Charities%20by%20Yourself%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5swa8chZCtWynuFga%2Fare-girl-scout-cookies-deliciously-evil-a-case-study-in", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5swa8chZCtWynuFga%2Fare-girl-scout-cookies-deliciously-evil-a-case-study-in", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 152, "htmlBody": "<p>I recently finished up an <a href=\"http://www.gwern.net/Girl%20Scouts%20and%20good%20governance\">essay examining the Girl Scouts, their cookies, and their finances</a> with reference to whether they are inefficient or corrupt.</p>\n<p>What is the relevance to LW? (The essay is aimed at a general audience &amp; assumes no knowledge of LW material, though it links heavily to LW in justifying why one should make predictions - such as about Girl Scout finances - before looking at data.)</p>\n<p>Well, on occasion, people ask questions about SIAI that they could have answered by themselves, such as by looking through SIAI financial filings. This kind of annoys me. This essay serves as a demonstration how one could investigate a charity on one's own, without simply trusting GiveWell's recommendations (good though they surely are).</p>\n<p>Reading SIAI's filings may be a future essay; until then, it is left as an exercise for the reader... (EDIT: One such reading is <a href=\"/user/BrandonReinhart/\">BrandonReinhart</a>'s extremely thorough <a href=\"/lw/5il/siai_an_examination/\">SIAI Fundraising</a> Article; highly recommended.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5swa8chZCtWynuFga", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 24, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "7005", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qqhdj3W3vSfB5E9ss"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T21:26:32.520Z", "modifiedAt": null, "url": null, "title": "Join the Special Relocation Task Force!", "slug": "join-the-special-relocation-task-force", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.592Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qH5pz6a9hLaguLFbh/join-the-special-relocation-task-force", "pageUrlRelative": "/posts/qH5pz6a9hLaguLFbh/join-the-special-relocation-task-force", "linkUrl": "https://www.lesswrong.com/posts/qH5pz6a9hLaguLFbh/join-the-special-relocation-task-force", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Join%20the%20Special%20Relocation%20Task%20Force!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJoin%20the%20Special%20Relocation%20Task%20Force!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqH5pz6a9hLaguLFbh%2Fjoin-the-special-relocation-task-force%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Join%20the%20Special%20Relocation%20Task%20Force!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqH5pz6a9hLaguLFbh%2Fjoin-the-special-relocation-task-force", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqH5pz6a9hLaguLFbh%2Fjoin-the-special-relocation-task-force", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 564, "htmlBody": "<p><strong>(Andrew is&nbsp;a pseudonym because he is a little worried about showing up in an internet search; please respect that and do not use his real name when posting below).</strong></p>\n<p>Andrew is an established and valuable member (<a href=\"/lw/1yq/understanding_your_understanding\">link</a> to highest voted post) of the LessWrong community. Sadly, he is without a tribe; he lives in a relatively small city where he has not found a&nbsp;tribe to belong to despite <a href=\"/lw/50p/reflections_on_rationality_a_year_out/3sv2\">considerable effort</a>. Being part of a tribe would improve Andrew's life considerably. Andrew is not attached to the area and quite willing to leave, doesn't know how to&nbsp;<a href=\"/lw/1aj/let_them_eat_cake_interpersonal_problems_vs_tasks/\">taskify</a>&nbsp;getting himself a tribe.&nbsp;</p>\n<p>Big decisions like moving are often easier and better executed when made with outside input. Therefore, I am putting together a Special Relocation Task Force to aid his efforts.&nbsp;</p>\n<p>Besides helping Andrew, I am also interested in answering the question 'will rationalists be good at this?'. They should be; rationalists should win. If they are not, something is wrong and I want to know about it. This experiment seems like a good way of answering that question.</p>\n<p>Here are some basic facts about Andrew:</p>\n<div>\n<ul>\n<li>He currently works in aerospace</li>\n<li>He has a mechanical engineering degree</li>\n<li>He currently lives in Texas</li>\n<li>He would prefer a job that more fully uses his intellectual skills and pushes him to his limits&nbsp;</li>\n</ul>\n</div>\n<div>The Special Relocation Task Force will consist of 5 or fewer people (including Andrew and myself), and will attempt to help him figure out how to find a tribe that fits him well and figure out how to get him there.&nbsp;Andrew does not expect this help to be handed to him on a silver platter, he expects to be the most involved member of the task force and to do most any hard work involved.&nbsp;</div>\n<div>The Special Relocation Task Force will need to answer questions such as the following:</div>\n<div>\n<ul>\n<li>Should Andrew move?</li>\n<li>If so where?</li>\n<li>How does one go about finding a good job near a satisfactory tribe?&nbsp;</li>\n<li>What kind of job should he get?</li>\n</ul>\n<div>Here is my initial plan for the task force:&nbsp;</div>\n<div><ol>\n<li style=\"margin-left: 15px; \">Select 5 or fewer people (including Andrew and I) for the task force.</li>\n<li style=\"margin-left: 15px; \">Choose how to coordinate task force. Forum+skype, email-list+video chat, etc. ?&nbsp;</li>\n<li style=\"margin-left: 15px; \">Initial meeting<ol>\n<li style=\"margin-left: 15px; \">Discuss the details of Andrews issue</li>\n<li style=\"margin-left: 15px; \">Discuss the contours of the issue (hold off on proposing solutions)</li>\n<li style=\"margin-left: 15px; \">Propose broad directions&nbsp;</li>\n<li style=\"margin-left: 15px; \">Select overall direction(s)</li>\n<li style=\"margin-left: 15px; \">Break up mission into tasks</li>\n<li style=\"margin-left: 15px; \">Assign tasks to people&nbsp;</li>\n</ol></li>\n<li style=\"margin-left: 15px; \">Work on assigned tasks</li>\n<li style=\"margin-left: 15px; \">Meeting<ol>\n<li style=\"margin-left: 15px; \">Share results of tasks</li>\n<li style=\"margin-left: 15px; \">Further taskification&nbsp;</li>\n</ol></li>\n<li style=\"margin-left: 15px; \">Return to step 6 unless done. &nbsp;</li>\n</ol></div>\n</div>\n<div>Now is your chance to help Andrew win!&nbsp;If you would like to volunteer to be on the taskforce, please say so below. &nbsp;If you have relevant experience, mention that. What skills/experience/knowledge is useful? Two things that come to mind are 1) having moved a lot 2) knowing about finding engineering jobs.</div>\n<div>If you have advice but do not want to volunteer that is also welcome.&nbsp;</div>\n<div>If you have questions about Andrew, feel free to ask those as well.</div>\n<div><strong>EDIT:</strong> I tentatively intend to select the task force Tuesday evening (PST).</div>\n<div>I expect participants will find this fun.</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qH5pz6a9hLaguLFbh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 46, "extendedScore": null, "score": 8.6e-05, "legacy": true, "legacyId": "7006", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4gevjbK77NQS6hybY", "AhHhm63zdZSDLmb76"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T21:40:07.061Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] \"I don't know.\"", "slug": "seq-rerun-i-don-t-know", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:34.501Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tkgiPWxn6FJ2MKqPe/seq-rerun-i-don-t-know", "pageUrlRelative": "/posts/tkgiPWxn6FJ2MKqPe/seq-rerun-i-don-t-know", "linkUrl": "https://www.lesswrong.com/posts/tkgiPWxn6FJ2MKqPe/seq-rerun-i-don-t-know", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20%22I%20don't%20know.%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20%22I%20don't%20know.%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtkgiPWxn6FJ2MKqPe%2Fseq-rerun-i-don-t-know%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20%22I%20don't%20know.%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtkgiPWxn6FJ2MKqPe%2Fseq-rerun-i-don-t-know", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtkgiPWxn6FJ2MKqPe%2Fseq-rerun-i-don-t-know", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 173, "htmlBody": "<p>Today's post, <a href=\"/lw/gs/i_dont_know/\">\"I don't know.\"</a> was originally published on 21 December 2006. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>An edited instant messaging conversation regarding the use of the phrase \"I don't know\". \"I don't know\" is a useful phrase if you want to avoid getting in trouble or convey the fact that you don't have access to privileged information.</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/r/discussion/lw/5b9/seq_rerun_the_modesty_argument/\">The Modesty Argument</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em> </em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tkgiPWxn6FJ2MKqPe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.064456532801463e-07, "legacy": true, "legacyId": "7008", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Pm83rA8MTYYeR4Ci4", "irsZZvkouLZgNzcF2", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-24T23:48:49.736Z", "modifiedAt": null, "url": null, "title": "San Francisco Meetup 4/28", "slug": "san-francisco-meetup-4-28", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:36.205Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mass_Driver", "createdAt": "2010-03-30T15:48:06.997Z", "isAdmin": false, "displayName": "Mass_Driver"}, "userId": "62rKjNqA2LCJ6RthR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Lkf66ft3poL8NSQ8y/san-francisco-meetup-4-28", "pageUrlRelative": "/posts/Lkf66ft3poL8NSQ8y/san-francisco-meetup-4-28", "linkUrl": "https://www.lesswrong.com/posts/Lkf66ft3poL8NSQ8y/san-francisco-meetup-4-28", "postedAtFormatted": "Sunday, April 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20San%20Francisco%20Meetup%204%2F28&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASan%20Francisco%20Meetup%204%2F28%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLkf66ft3poL8NSQ8y%2Fsan-francisco-meetup-4-28%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=San%20Francisco%20Meetup%204%2F28%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLkf66ft3poL8NSQ8y%2Fsan-francisco-meetup-4-28", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLkf66ft3poL8NSQ8y%2Fsan-francisco-meetup-4-28", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 385, "htmlBody": "<p><a id=\"more\"></a></p>\n<address>Thursday, April 28th at 7:00 PM</address><address>Green Papaya</address><address>825 Mission Street (4th and Mission)</address><address>San Francisco, CA 94103</address>\n<p>&nbsp;</p>\n<p>Welcome back to the next installment of the newest Bay Area Less Wrong meetup: <strong>San Francisco</strong>! The second meeting of the San Francisco group will be this coming Thursday, April 28th, from 7:00-9:00 at <a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=Green+Papaya,+Mission+Street,+San+Francisco,+CA&amp;aq=0&amp;sll=37.0625,-95.677068&amp;sspn=40.681389,79.013672&amp;ie=UTF8&amp;hq=Green+Papaya,&amp;hnear=Mission+St,+San+Francisco,+California&amp;ll=37.783876,-122.404861&amp;spn=0.019875,0.038581&amp;z=15&amp;iwloc=A\" target=\"_blank\">Green Papaya near 4th and Mission</a>. The theme of the meeting will be \"<strong>What would you like to be awesome at?\" </strong>Everyone will get a chance to talk about something they think they could get awesome at pretty quickly with the right kind of help, and also about something that they'd like to be awesome at but have no idea how to get started on.</p>\n<p>Hopefully this will help us get to know each other a little bit while also starting to plan out the broad strokes of what kinds of things we'll do together at future meet-ups. Once we know what at least some people want to be awesome at, we can brainstorm ways of making that happen together.</p>\n<p>If you have any questions at all about the Meetup, feel free to call me, Jason Green-Lowe, at <a href=\"/tel:%28415%29%20895-0650\" target=\"_blank\">(415) 895-0650</a>, or to e-mail me at <a href=\"mailto:jasongreenlowe@gmail.com\" target=\"_blank\">jasongreenlowe@gmail.com</a>. You can also PM me on the Less Wrong blog at Mass_Driver. If you'd like to help organize this or future meetings, you should definitely get in touch -- help is welcome and probably needed!</p>\n<p>If you've never been to a LessWrong meetup before, this is a good chance to go to your first one! Chances are other people feel awkward too, and we'll all be a little uneasy about the whole thing together. Less Wrong meetups are so new that nobody really knows the right way to run them yet, let alone the right way to participate in them. So, come! Help us figure it out. It doesn't matter if you've read the whole blog, if you're unemployed (I am), or if you've graduated high school -- if you show up and try to be less wrong, we'll be glad you came.</p>\n<p>If you want to stay informed about upcoming events in the Bay Area, join the <a href=\"https://groups.google.com/group/bayarealesswrong\" target=\"_blank\">Bay Area LessWrong Google Group</a>! There are other chapters in Tortuga and Berkeley, and together we aim to throw so many events that the global Less Wrong blog won't have room to post them all.&nbsp;</p>\n<p>See you soon!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Lkf66ft3poL8NSQ8y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 7.064822152271538e-07, "legacy": true, "legacyId": "7009", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T04:00:07.525Z", "modifiedAt": null, "url": null, "title": "New Haven / Southern Connecticut Meetup, Wednesday Apr. 27th 6 PM", "slug": "new-haven-southern-connecticut-meetup-wednesday-apr-27th-6", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:53.119Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alyssavance", "createdAt": "2009-10-07T20:08:31.887Z", "isAdmin": false, "displayName": "alyssavance"}, "userId": "zQSAWAS5tnqtzp55N", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sh2SixuY4ouj3ev7B/new-haven-southern-connecticut-meetup-wednesday-apr-27th-6", "pageUrlRelative": "/posts/sh2SixuY4ouj3ev7B/new-haven-southern-connecticut-meetup-wednesday-apr-27th-6", "linkUrl": "https://www.lesswrong.com/posts/sh2SixuY4ouj3ev7B/new-haven-southern-connecticut-meetup-wednesday-apr-27th-6", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20Haven%20%2F%20Southern%20Connecticut%20Meetup%2C%20Wednesday%20Apr.%2027th%206%20PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20Haven%20%2F%20Southern%20Connecticut%20Meetup%2C%20Wednesday%20Apr.%2027th%206%20PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsh2SixuY4ouj3ev7B%2Fnew-haven-southern-connecticut-meetup-wednesday-apr-27th-6%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20Haven%20%2F%20Southern%20Connecticut%20Meetup%2C%20Wednesday%20Apr.%2027th%206%20PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsh2SixuY4ouj3ev7B%2Fnew-haven-southern-connecticut-meetup-wednesday-apr-27th-6", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsh2SixuY4ouj3ev7B%2Fnew-haven-southern-connecticut-meetup-wednesday-apr-27th-6", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<p><a id=\"more\"></a></p>\n<p>To all Less Wrongians in the <strong>New Haven / Southern Connecticut</strong> area: Come join us for dinner at Yorkside Pizza and Restaurant (<strong>288 York Street</strong>, New Haven CT) on <strong>Wednesday, April 27th</strong> at <strong>6:00 PM</strong>. There is currently no established LW meetup in New Haven, but we are starting one, and me and some of my friends will definitely be there. Contact thomas@humanityplus.org for info. It will be awesome!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sh2SixuY4ouj3ev7B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.065536085229714e-07, "legacy": true, "legacyId": "7017", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T12:43:07.217Z", "modifiedAt": null, "url": null, "title": "Convincing Arguments Aren\u2019t Necessarily Correct \u2013 They\u2019re Merely Convincing", "slug": "convincing-arguments-aren-t-necessarily-correct-they-re", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:35.397Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lionhearted", "createdAt": "2010-07-29T13:30:07.417Z", "isAdmin": false, "displayName": "lionhearted"}, "userId": "tooJeLNxoeccqGEky", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AYEAwCXjsASprupys/convincing-arguments-aren-t-necessarily-correct-they-re", "pageUrlRelative": "/posts/AYEAwCXjsASprupys/convincing-arguments-aren-t-necessarily-correct-they-re", "linkUrl": "https://www.lesswrong.com/posts/AYEAwCXjsASprupys/convincing-arguments-aren-t-necessarily-correct-they-re", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Convincing%20Arguments%20Aren%E2%80%99t%20Necessarily%20Correct%20%E2%80%93%20They%E2%80%99re%20Merely%20Convincing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConvincing%20Arguments%20Aren%E2%80%99t%20Necessarily%20Correct%20%E2%80%93%20They%E2%80%99re%20Merely%20Convincing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYEAwCXjsASprupys%2Fconvincing-arguments-aren-t-necessarily-correct-they-re%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Convincing%20Arguments%20Aren%E2%80%99t%20Necessarily%20Correct%20%E2%80%93%20They%E2%80%99re%20Merely%20Convincing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYEAwCXjsASprupys%2Fconvincing-arguments-aren-t-necessarily-correct-they-re", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYEAwCXjsASprupys%2Fconvincing-arguments-aren-t-necessarily-correct-they-re", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 728, "htmlBody": "<p>I've been studying a lot of finance lately, and it strikes me that it's a field that requires a very high degree of rationality and ability to cut through the noise to get to correct arguments.</p>\n<p>What's nice about investing especially, though, is that it has a very similar utility curve for all players. People have slightly different goals in terms of finance and investing, but generally speaking, people are measuring utility in terms of financial return. There's some differences between time preferences and risk tolerance, but generally speaking, we can sort the winning strategies from the losing ones over time. There's a fairly clear and objective standard for what worked and what didn't, which could make it a very helpful field for the aspiring rationalist to study and learn from.</p>\n<p>I originally wrote this post, \"Convincing Arguments Aren&rsquo;t Necessarily Correct &ndash; They&rsquo;re Merely Convincing\" for my blog, so the tone is more colloquial than you'd normally see on LessWrong, and the audience is slightly different. A friend of mine suggested I post it up here too as it might be interesting to the LW crowd, so here we go -<a id=\"more\"></a></p>\n<hr />\n<p><strong>\"Convincing Arguments Aren&rsquo;t Necessarily Correct &ndash; They&rsquo;re Merely Convincing\"</strong></p>\n<p>Things have been going well lately, and I now have a surplus of cash for the first time in a while. Err, rather, I have both a surplus of cash and some high consistency predictable future income. That&rsquo;s nice! I envy all you salaried people when I think about predictable future income. Having a decent chunk of cash, but no predictable future income means you don&rsquo;t really have a surplus of cash.</p>\n<p>Anyways, I was thinking of what to invest a small bit of money in, and reading some papers and analyses and such. I&rsquo;m reading a mix of finance, investment, politics, diplomacy, and history lately, which makes for a nice mix. It also has me interested in the topic.</p>\n<p>Today, I read a really fantastically convincing argument, enough so that I was immediately ready to go buy a small amount of what the author was advocating.</p>\n<p>Then I stopped myself! Wait, the author isn&rsquo;t necessarily <em>correct</em> &ndash; he&rsquo;s merely <em>convincing</em>.</p>\n<p>I went back through the piece I was reading, which was quite a long piece. I started counting the number of premises the author had, and it went something like this:</p>\n<p>Premise A<br />Premise B<br />Premise C<br />Premise D<br />Premise E<br />Premise F<br />If A, B, C, D, E, F, then G.<br />Premise H<br />Premise I<br />Premise J<br />Premise K<br />If G, H, I, J, K, then L.<br />Therefore, invest in L.</p>\n<p>It was super convincing. But then it dawns on me, convincing doesn&rsquo;t mean correct. For instance, though the author doesn&rsquo;t explicitly state it, two of his premises are that the United States and Chinese economies, political leaderships, objectives, and currencies are going to be doing roughly similar things over the next 20 years to how they&rsquo;re doing now, maybe with a little bit of change but nothing drastic.</p>\n<p>Perhaps that&rsquo;s not true! I don&rsquo;t know much about the current governmental leadership of China, who the next projected/potential leadership is, and their thoughts and objectives. Also, American economic, political, and monetary policy can change <em>fast</em>, and would it really surprise anyone if 2012 or 2016 brought in someone with significantly different monetary views than recently?</p>\n<p>So, two of the author&rsquo;s biggest unstated premises are that China and America will behave roughly how we expect China and America to behave over the next 20 years. And if he&rsquo;s wrong, the entire analysis might fall apart.</p>\n<p>It was a super convincing argument, but there&rsquo;s a problem with <em>any</em> argument that has a lot of premises chained together &ndash; if even one premise is wrong, then the whole conclusion might be faulty.</p>\n<p>Convincing doesn&rsquo;t mean correct &ndash; it just means convincing. Stay skeptical. Keep researching.</p>\n<hr />\n<p>The tone is more colloquial than it would be if I wrote strictly for LW, but I think this distinction is an important one that most people don't pay attention to - convincing arguments aren't necessarily correct. If you're looking into an argument that has real world consequences, you need to thoroughly examine all the premises of the argument to make sure you're working with reality. And even a single flaw in a premise can result in you totally blowing your utility up.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AYEAwCXjsASprupys", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 11, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "7021", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T14:18:53.186Z", "modifiedAt": null, "url": null, "title": "Attempts to work around Goedel's theorem by using randomness", "slug": "attempts-to-work-around-goedel-s-theorem-by-using-randomness", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:38.695Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qvsTmpkWSroJyN6MS/attempts-to-work-around-goedel-s-theorem-by-using-randomness", "pageUrlRelative": "/posts/qvsTmpkWSroJyN6MS/attempts-to-work-around-goedel-s-theorem-by-using-randomness", "linkUrl": "https://www.lesswrong.com/posts/qvsTmpkWSroJyN6MS/attempts-to-work-around-goedel-s-theorem-by-using-randomness", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Attempts%20to%20work%20around%20Goedel's%20theorem%20by%20using%20randomness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAttempts%20to%20work%20around%20Goedel's%20theorem%20by%20using%20randomness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqvsTmpkWSroJyN6MS%2Fattempts-to-work-around-goedel-s-theorem-by-using-randomness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Attempts%20to%20work%20around%20Goedel's%20theorem%20by%20using%20randomness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqvsTmpkWSroJyN6MS%2Fattempts-to-work-around-goedel-s-theorem-by-using-randomness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqvsTmpkWSroJyN6MS%2Fattempts-to-work-around-goedel-s-theorem-by-using-randomness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 159, "htmlBody": "<p>You can't make PA complete by adding new axioms with a deterministic algorithm. But what if you used a randomized algorithm? Richard Lipton wrote a <a href=\"http://rjlipton.wordpress.com/2011/03/30/random-axioms-and-gdel-incompleteness/\">post</a> about this idea: generate a random bitstring S, then add to PA the axiom that the K-complexity of S is high enough. That is probabilistically very likely to be true, but is always unprovable in PA for long enough S. Clearly this gives you a stronger theory, but how much stronger? In particular, is there any hope at all that you can approach completeness in some suitable probabilistic sense?</p>\n<p>Nah, don't get your hopes up. In the comments to Lipton's post, Alexander Shen (amusingly, one of my former schoolteachers) and Harvey Friedman show that most true statements remain unreachable by this procedure. Leonid Levin proved a&nbsp;<a href=\"http://arxiv.org/abs/cs.CC/0203029\">weaker but more general result</a>, roughly saying that randomized algorithms cannot complete PA with positive probability.</p>\n<p>So the idea doesn't seem to work. But it was a very nice try.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qvsTmpkWSroJyN6MS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "7022", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T16:53:23.625Z", "modifiedAt": null, "url": null, "title": "What is Metaethics?", "slug": "what-is-metaethics", "viewCount": null, "lastCommentedAt": "2019-04-25T08:06:37.129Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "lukeprog", "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s4Mcg9aLMeRwdW7fh/what-is-metaethics", "pageUrlRelative": "/posts/s4Mcg9aLMeRwdW7fh/what-is-metaethics", "linkUrl": "https://www.lesswrong.com/posts/s4Mcg9aLMeRwdW7fh/what-is-metaethics", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20is%20Metaethics%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20is%20Metaethics%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs4Mcg9aLMeRwdW7fh%2Fwhat-is-metaethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20is%20Metaethics%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs4Mcg9aLMeRwdW7fh%2Fwhat-is-metaethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs4Mcg9aLMeRwdW7fh%2Fwhat-is-metaethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1551, "htmlBody": "<p>When <a href=\"https://www.lesserwrong.com/lw/54p/heading_toward_nononsense_metaethics/\">I say</a> I think I can solve (some of) metaethics, what exactly is it that I think I can solve?</p><p>First, we must distinguish the study of <em>ethics</em> or <em>morality</em> from the <em>anthropology</em> of moral belief and practice. The first one asks: &quot;What is right?&quot; The second one asks: &quot;What do people think is right?&quot; Of course, one can inform the other, but it&#x27;s important not to confuse the two. One can correctly say that different cultures <em>have</em> different &#x27;morals&#x27; in that they have different moral beliefs and practices, but this may not answer the question of whether or not they are behaving in morally right ways.</p><p>My focus is metaethics, so I&#x27;ll discuss the anthropology of moral belief and practice only when it is relevant for making points about metaethics.</p><p>So what is metaethics? Many people break the field of ethics into three sub-fields: applied ethics, normative ethics, and metaethics.</p><p><strong><a href=\"http://www.iep.utm.edu/ethics/#H3\">Applied ethics</a></strong>: Is abortion morally right? How should we treat animals? What political and economic systems are most moral? What are the moral responsibilities of businesses? How should doctors respond to complex and uncertain situations? When is lying acceptable? What kinds of sex are right or wrong? Is euthanasia acceptable?</p><p><strong><a href=\"http://www.iep.utm.edu/ethics/#H2\">Normative ethics</a></strong>: What moral principles should we use in order to <em>decide</em> how to treat animals, when lying is acceptable, and so on? Is morality decided by what produces the greatest good for the greatest number? Is it decided by a list of unbreakable rules? Is it decided by a list of character virtues? Is it decided by a hypothetical social contract drafted under ideal circumstances?</p><p><strong><a href=\"http://www.iep.utm.edu/ethics/#H1\">Metaethics</a></strong>: What does moral language mean? Do moral facts exist? If so, what are they like, and are they reducible to natural facts? How can we know whether moral judgments are true or false? Is there a connection between making a moral judgment and being motivated to abide by it? Are moral judgments objective or subjective, relative or absolute? Does it make sense to talk about moral progress?</p><p>Others prefer to combine applied ethics and normative ethics so that the breakdown becomes: normative ethics vs. metaethics, or &#x27;first order&#x27; moral questions (normative ethics) vs. &#x27;second order&#x27; questions (metaethics).</p><h1>Mainstream views in metaethics</h1><p>To illustrate how people can give different answers to the questions of metaethics, let me summarize some of the mainstream philosophical positions in metaethics.</p><p><strong>Cognitivism vs. non-cognitivism</strong>: This is a <a href=\"http://plato.stanford.edu/entries/moral-cognitivism/\">debate</a> about what is happening when people engage in moral discourse. When someone says &quot;Murder is wrong,&quot; are they trying to state a fact about murder, that it has the property of <em>being wrong</em>? Or are they merely expressing a negative emotion toward murder, as if they had gasped aloud and said &quot;Murder!&quot; with a disapproving tone?</p><p>Another way of saying this is that cognitivists think moral discourse is &#x27;truth-apt&#x27; - that is, moral statements are the kinds of things that can be true or false. Some cognitivists think that all moral claims are in fact false (<a href=\"http://plato.stanford.edu/entries/moral-anti-realism/#ErrThe\">error theory</a>), just as the atheist thinks that claims about gods are usually meant to be fact-stating but in fact are all false because gods don&#x27;t exist.1 Other cognitivists think that at least some moral claims are true. <em>Naturalism</em> holds that moral judgments are true or false because of natural facts,2 while <em>non-naturalism</em> holds that moral judgments are true or false because of non-natural facts.3 <em>Weak cognitivism</em> holds that moral judgments can be true or false not because they agree with certain (natural or non-natural) opinion-independent facts, but because our considered opinions<em> determine</em> the moral facts.4</p><p>Non-cognitivists, in contrast, tend to think that moral discourse is <em>not</em> truth-apt. Ayer (1936) held that moral sentences express our emotions (&quot;Murder? Yuck!&quot;) about certain actions. This is called <em>emotivism</em> or <em>expressivism</em>. Another theory is <em>prescriptivism</em>, the idea that moral sentences express commands (&quot;Don&#x27;t murder!&quot;).5 Or perhaps moral judgments express our acceptance of certain norms (<em>norm expressivism</em>).6 Or maybe our moral judgments express our dispositions to form sentiments of approval or disapproval (<em>quasi-realism</em>).7</p><p><strong>Moral psychology</strong>: One major debate in moral psychology concerns whether moral judgments require some (defeasible) motivation to adhere to the moral judgment (<em><a href=\"http://en.wikipedia.org/wiki/Internalism_and_externalism#Motivation\">motivational internalism</a></em>), or whether one can make a moral judgment without being motivated to adhere to it (<em>motivational externalism</em>). Another debate concerns whether motivation depends on both beliefs <em>and</em> desires (the <em><a href=\"http://sites.google.com/site/neiladri/Home/HumeanTheoryproofs.pdf?attredirects=0&d=1\">Humean theory of motivation</a></em>), or whether some beliefs are by themselves intrinsically motivating (<em>non-Humean theories of motivation</em>).</p><p>More recently, researchers have run a number of experiments to test the mechanisms by which people make moral judgments. I will list a few of the most surprising and famous results:</p><ul><li>Whether we judge an action as &#x27;intentional&#x27; or not often depends on the judged goodness or badness of the action, not the internal states of the agent.8</li><li>Our moral judgments are significantly affected by whether we are in the presence of freshly baked bread or a low concentration of fart spray that only the subconscious mind can detect.9</li><li>Our moral judgments are greatly affected by pointing magnets at the point in our brain that processes <a href=\"http://en.wikipedia.org/wiki/Theory_of_mind\">theory of mind</a>.10</li><li>People tend to insist that certain things are right or wrong even when a hypothetical situation is constructed such that they admit they can give no reason for their judgment.11</li><li>We use our recently-evolved neocortex to make utilitarian judgments, and deontological judgments tend to come from evolutionarily older parts of our brains.12</li><li>People give harsher moral judgments when they feel clean.13</li></ul><p><strong>Moral epistemology</strong>: Different views on cognitivism vs. non-cognitivism and moral psychology suggest different views of moral epistemology. How can we know moral facts? Non-cognitivists and error theorists think there <em>are</em> no moral facts to be known. Those who believe moral facts answer to non-natural facts tend to think that moral knowledge comes from intuition, which somehow has access to non-natural facts. Moral naturalists tend to think that moral facts can be accessed simply by doing science.</p><h1>Tying it all together</h1><p>I will not be trying very hard to fit my <em>pluralistic moral reductionism</em> into these categories. I&#x27;ll be <a href=\"https://www.lesserwrong.com/lw/nv/replace_the_symbol_with_the_substance/\">arguing about the substance, not the symbols</a>. But it still helps to have a concept of the subject matter by way of such examples.</p><p>Maybe mainstream metaethics will make more sense in flowchart form. Here&#x27;s a flowchart I adapted from Miller (2003). If you don&#x27;t understand the bottom-most branching, read chapter 9 of Miller&#x27;s book or else just don&#x27;t worry about it. (Click through for full size.)</p><p>Next post: <a href=\"https://www.lesserwrong.com/lw/5kn/conceptual_analysis_and_moral_theory/\">Conceptual Analysis and Moral Theory</a></p><p>Previous post: <a href=\"https://www.lesserwrong.com/lw/54p/heading_toward_nononsense_metaethics/\">Heading Toward: No-Nonsense Metaethics</a></p><h2>Notes</h2><p>1 This is not quite correct. The error theorist can hold that a statement like &quot;Murder is not wrong&quot; is true, for he thinks that murder is not wrong <em>or</em> right. Rather, the error theorist claims that all moral statements <em>which presuppose the existence of a moral property</em> are false, because no such moral properties exist. See Joyce (2004). Mackie (1977) is the classic statement of error theory.</p><p>2 Sturgeon (1988); Boyd (1988); Brink (1989); Brandt (1979); Railton (1986); Jackson (1998). I have written introductions to the three major versions of moral naturalism: <a href=\"http://commonsenseatheism.com/?p=15213\">Cornell realism</a>, Railton&#x27;s moral reductionism (<a href=\"http://commonsenseatheism.com/?p=15253\">1</a>, <a href=\"http://commonsenseatheism.com/?p=15264\">2</a>), and Jackson&#x27;s <a href=\"http://commonsenseatheism.com/?p=15267\">moral functionalism</a>.</p><p>3 Moore (1903); McDowell (1998); Wiggins (1987).</p><p>4 For an overview of such theories, see Miller (2003), chapter 7.</p><p>5 See Carnap (1937), p. 23-25; Hare (1952).</p><p>6 Gibbard (1990).</p><p>7 Blackburn (1984).</p><p>8 The <a href=\"http://en.wikipedia.org/wiki/Joshua_Knobe#The_Knobe_Effect\">Knobe Effect</a>. See Knobe (2003).</p><p>9 Schnall et al. (2008); Baron &amp; Thomley (1994).</p><p>10 Young et al. (2010). I interviewed the author of this study <a href=\"http://commonsenseatheism.com/?p=10549\">here</a>.</p><p>11 This is <a href=\"http://awaisaftab.blogspot.com/2011/03/moral-dumbfounding.html\">moral dumfounding</a>. See Haidt (2001).</p><p>12 Greene (2007).</p><p>13 Zhong et al. (2010).</p><p></p><h4>References</h4><p>Baron &amp; Thomley (1994). A Whiff of Reality: Positive Affect as a Potential Mediator of the Effects of Pleasant Fragrances on Task Performance and Helping. <em>Environment and Behavior, 26(6)</em>: 766-784.</p><p>Blackburn (1984). <em><a href=\"http://www.amazon.com/Spreading-Word-Groundings-Philosophy-Language/dp/019824651X/\">Spreading the Word</a></em>. Oxford University Press.</p><p>Brandt (1979). <em><a href=\"http://www.amazon.com/Theory-Good-Right-Richard-Brandt/dp/157392220X/\">A Theory of the Good and the Right</a></em>. Oxford University Press.</p><p>Brink (1989). <em><a href=\"http://www.amazon.com/Realism-Foundations-Cambridge-Studies-Philosophy/dp/0521359376/\">Moral Realism and the Foundations of Ethics</a></em>. Cambridge University Press.</p><p>Boyd (1988). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/09/Boyd-How-to-be-a-moral-realist.pdf\">How to be a Moral Realist</a>. In Sayre-McCord (ed.), <em>Essays in Moral Realism</em> (pp. 181-122). Cornell University Press.</p><p>Carnap (1937). <em><a href=\"http://www.amazon.com/Philosophy-Logical-Syntax-Rudolf-Carnap/dp/0404145183/\">Philosophy and Logical Syntax</a></em>. Kegan Paul, Trench, Trubner &amp; Co.</p><p>Gibbard (1990). <em><a href=\"http://www.amazon.com/Wise-Choices-Apt-Feelings-Normative/dp/0674953789/\">Wise Choices, Apt Feelings</a></em>. Clarendon Press.</p><p>Greene (2007). <a href=\"http://www.fed.cuhk.edu.hk/~lchang/material/Evolutionary/Developmental/Greene-KantSoul.pdf\">The secret joke of Kant&#x27;s soul</a>. In Sinnott-Armstrong (ed.), <em>Moral Psychology, Vol. 3: The Neuroscience of Morality: Emotion, Disease, and Development</em>. MIT Press.</p><p>Haidt (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Haidt-The-emotional-dog-and-its-rational-tail.pdf\">The emotional dog and its rational tail: A social intuitionist approach to moral judgment</a>. <em>Psychological Review, 108</em>: 814-834</p><p>Hare (1952). <em><a href=\"http://www.amazon.com/Language-Morals-Oxford-Paperbacks/dp/0198810776/\">The Language of Morals</a></em>. Oxford University Press.</p><p>Jackson (1998). <em><a href=\"http://www.amazon.com/Metaphysics-Ethics-Defence-Conceptual-Analysis/dp/0198250614/\">From Metaphysics to Ethics</a></em>.  Oxford UniversityPress.</p><p>Joyce (2001). <em><a href=\"http://www.amazon.com/Morality-Cambridge-Studies-Philosophy-English/dp/0521036259/\">The Myth of Morality</a></em>. Cambridge University Press.</p><p>Knobe (2003). <a href=\"https://www.lesserwrong.com/Intentional%20Action%20and%20Side%20Effects%20in%20Ordinary%20Language\">Intentional Action and Side Effects in Ordinary Language</a>. <em>Analysis, 63</em>: 190-193.</p><p>Mackie (1977). <em><a href=\"http://www.amazon.com/Ethics-Inventing-J-L-Mackie/dp/B000FKP9X8/\">Ethics: Inventing Right and Wrong</a></em>. Penguin.</p><p>McDowell (1998). <em><a href=\"http://www.amazon.com/Mind-Value-Reality-John-McDowell/dp/0674007131/\">Mind, Value, and Reality</a></em>. Harvard University Press.</p><p>Miller (2003). <em><a href=\"http://www.amazon.com/Introduction-Contemporary-Metaethics-Alex-Miller/dp/074562345X/\">An Introduction to Contemporary Metaethics</a></em>. Polity.</p><p>Moore (1903). <em><a href=\"http://www.amazon.com/Principia-Ethica-G-Moore/dp/0521448484/\">Principia Ethica</a></em>. Cambridge University Press.</p><p>Schnall, Haidt, Clore, &amp; Jordan (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Schnall-et-al-Disgust-as-embodied-moral-judgment.pdf\">Disgust as embodied moral judgment</a>. <em>Personality and Social Psychology Bulletin, 34(8)</em>: 1096-1109.</p><p>Sturgeon (1988). Moral explanations. In Sayre-McCord (ed.), <em>Essays in Moral Realism</em> (pp. 229-255). Cornell University Press.</p><p>Railton (1986). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Railton-Moral-Realism.pdf\">Moral realism</a>. <em>Philosophical Review, 95</em>: 163-207.</p><p>Wiggins (1987). A sensible subjectivism. In <em>Needs, Values, Truth</em> (pp. 185-214). Blackwell.</p><p>Young, Camprodon, Hauser, Pascual-Leone, &amp; Saxe (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/09/Young-Disruption-of-the-right-temporoparietal-junction-with-transcranial-magnetic-stimulation-reduces-the-role-of-beliefs-in-moral-judgments.pdf\">Disruption of the right temporoparietal junction with transcranial magnetic stimulation reduces the role of beliefs in moral judgments</a>. <em>Proceedings of the National Academy of Sciences, 107</em>: 6753-6758.</p><p>Zhong, Strejcek, &amp; Sivanathan (2010). A clean self can render harsh moral judgment. <em>Journal of Experimental Social Psychology, 46 (5)</em>: 859-862</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s4Mcg9aLMeRwdW7fh", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 43, "extendedScore": null, "score": 8.3e-05, "legacy": true, "legacyId": "7001", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "bQgRsy23biR52poMf", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "2YPbdHgcjt7g5ZaFN", "canonicalPrevPostSlug": "SFnfhJkGsBQk8jakK", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>When <a href=\"https://www.lesserwrong.com/lw/54p/heading_toward_nononsense_metaethics/\">I say</a> I think I can solve (some of) metaethics, what exactly is it that I think I can solve?</p><p>First, we must distinguish the study of <em>ethics</em> or <em>morality</em> from the <em>anthropology</em> of moral belief and practice. The first one asks: \"What is right?\" The second one asks: \"What do people think is right?\" Of course, one can inform the other, but it's important not to confuse the two. One can correctly say that different cultures <em>have</em> different 'morals' in that they have different moral beliefs and practices, but this may not answer the question of whether or not they are behaving in morally right ways.</p><p>My focus is metaethics, so I'll discuss the anthropology of moral belief and practice only when it is relevant for making points about metaethics.</p><p>So what is metaethics? Many people break the field of ethics into three sub-fields: applied ethics, normative ethics, and metaethics.</p><p><strong><a href=\"http://www.iep.utm.edu/ethics/#H3\">Applied ethics</a></strong>: Is abortion morally right? How should we treat animals? What political and economic systems are most moral? What are the moral responsibilities of businesses? How should doctors respond to complex and uncertain situations? When is lying acceptable? What kinds of sex are right or wrong? Is euthanasia acceptable?</p><p><strong><a href=\"http://www.iep.utm.edu/ethics/#H2\">Normative ethics</a></strong>: What moral principles should we use in order to <em>decide</em> how to treat animals, when lying is acceptable, and so on? Is morality decided by what produces the greatest good for the greatest number? Is it decided by a list of unbreakable rules? Is it decided by a list of character virtues? Is it decided by a hypothetical social contract drafted under ideal circumstances?</p><p><strong><a href=\"http://www.iep.utm.edu/ethics/#H1\">Metaethics</a></strong>: What does moral language mean? Do moral facts exist? If so, what are they like, and are they reducible to natural facts? How can we know whether moral judgments are true or false? Is there a connection between making a moral judgment and being motivated to abide by it? Are moral judgments objective or subjective, relative or absolute? Does it make sense to talk about moral progress?</p><p>Others prefer to combine applied ethics and normative ethics so that the breakdown becomes: normative ethics vs. metaethics, or 'first order' moral questions (normative ethics) vs. 'second order' questions (metaethics).</p><h1 id=\"Mainstream_views_in_metaethics\">Mainstream views in metaethics</h1><p>To illustrate how people can give different answers to the questions of metaethics, let me summarize some of the mainstream philosophical positions in metaethics.</p><p><strong>Cognitivism vs. non-cognitivism</strong>: This is a <a href=\"http://plato.stanford.edu/entries/moral-cognitivism/\">debate</a> about what is happening when people engage in moral discourse. When someone says \"Murder is wrong,\" are they trying to state a fact about murder, that it has the property of <em>being wrong</em>? Or are they merely expressing a negative emotion toward murder, as if they had gasped aloud and said \"Murder!\" with a disapproving tone?</p><p>Another way of saying this is that cognitivists think moral discourse is 'truth-apt' - that is, moral statements are the kinds of things that can be true or false. Some cognitivists think that all moral claims are in fact false (<a href=\"http://plato.stanford.edu/entries/moral-anti-realism/#ErrThe\">error theory</a>), just as the atheist thinks that claims about gods are usually meant to be fact-stating but in fact are all false because gods don't exist.1 Other cognitivists think that at least some moral claims are true. <em>Naturalism</em> holds that moral judgments are true or false because of natural facts,2 while <em>non-naturalism</em> holds that moral judgments are true or false because of non-natural facts.3 <em>Weak cognitivism</em> holds that moral judgments can be true or false not because they agree with certain (natural or non-natural) opinion-independent facts, but because our considered opinions<em> determine</em> the moral facts.4</p><p>Non-cognitivists, in contrast, tend to think that moral discourse is <em>not</em> truth-apt. Ayer (1936) held that moral sentences express our emotions (\"Murder? Yuck!\") about certain actions. This is called <em>emotivism</em> or <em>expressivism</em>. Another theory is <em>prescriptivism</em>, the idea that moral sentences express commands (\"Don't murder!\").5 Or perhaps moral judgments express our acceptance of certain norms (<em>norm expressivism</em>).6 Or maybe our moral judgments express our dispositions to form sentiments of approval or disapproval (<em>quasi-realism</em>).7</p><p><strong>Moral psychology</strong>: One major debate in moral psychology concerns whether moral judgments require some (defeasible) motivation to adhere to the moral judgment (<em><a href=\"http://en.wikipedia.org/wiki/Internalism_and_externalism#Motivation\">motivational internalism</a></em>), or whether one can make a moral judgment without being motivated to adhere to it (<em>motivational externalism</em>). Another debate concerns whether motivation depends on both beliefs <em>and</em> desires (the <em><a href=\"http://sites.google.com/site/neiladri/Home/HumeanTheoryproofs.pdf?attredirects=0&amp;d=1\">Humean theory of motivation</a></em>), or whether some beliefs are by themselves intrinsically motivating (<em>non-Humean theories of motivation</em>).</p><p>More recently, researchers have run a number of experiments to test the mechanisms by which people make moral judgments. I will list a few of the most surprising and famous results:</p><ul><li>Whether we judge an action as 'intentional' or not often depends on the judged goodness or badness of the action, not the internal states of the agent.8</li><li>Our moral judgments are significantly affected by whether we are in the presence of freshly baked bread or a low concentration of fart spray that only the subconscious mind can detect.9</li><li>Our moral judgments are greatly affected by pointing magnets at the point in our brain that processes <a href=\"http://en.wikipedia.org/wiki/Theory_of_mind\">theory of mind</a>.10</li><li>People tend to insist that certain things are right or wrong even when a hypothetical situation is constructed such that they admit they can give no reason for their judgment.11</li><li>We use our recently-evolved neocortex to make utilitarian judgments, and deontological judgments tend to come from evolutionarily older parts of our brains.12</li><li>People give harsher moral judgments when they feel clean.13</li></ul><p><strong>Moral epistemology</strong>: Different views on cognitivism vs. non-cognitivism and moral psychology suggest different views of moral epistemology. How can we know moral facts? Non-cognitivists and error theorists think there <em>are</em> no moral facts to be known. Those who believe moral facts answer to non-natural facts tend to think that moral knowledge comes from intuition, which somehow has access to non-natural facts. Moral naturalists tend to think that moral facts can be accessed simply by doing science.</p><h1 id=\"Tying_it_all_together\">Tying it all together</h1><p>I will not be trying very hard to fit my <em>pluralistic moral reductionism</em> into these categories. I'll be <a href=\"https://www.lesserwrong.com/lw/nv/replace_the_symbol_with_the_substance/\">arguing about the substance, not the symbols</a>. But it still helps to have a concept of the subject matter by way of such examples.</p><p>Maybe mainstream metaethics will make more sense in flowchart form. Here's a flowchart I adapted from Miller (2003). If you don't understand the bottom-most branching, read chapter 9 of Miller's book or else just don't worry about it. (Click through for full size.)</p><p>Next post: <a href=\"https://www.lesserwrong.com/lw/5kn/conceptual_analysis_and_moral_theory/\">Conceptual Analysis and Moral Theory</a></p><p>Previous post: <a href=\"https://www.lesserwrong.com/lw/54p/heading_toward_nononsense_metaethics/\">Heading Toward: No-Nonsense Metaethics</a></p><h2 id=\"Notes\">Notes</h2><p>1 This is not quite correct. The error theorist can hold that a statement like \"Murder is not wrong\" is true, for he thinks that murder is not wrong <em>or</em> right. Rather, the error theorist claims that all moral statements <em>which presuppose the existence of a moral property</em> are false, because no such moral properties exist. See Joyce (2004). Mackie (1977) is the classic statement of error theory.</p><p>2 Sturgeon (1988); Boyd (1988); Brink (1989); Brandt (1979); Railton (1986); Jackson (1998). I have written introductions to the three major versions of moral naturalism: <a href=\"http://commonsenseatheism.com/?p=15213\">Cornell realism</a>, Railton's moral reductionism (<a href=\"http://commonsenseatheism.com/?p=15253\">1</a>, <a href=\"http://commonsenseatheism.com/?p=15264\">2</a>), and Jackson's <a href=\"http://commonsenseatheism.com/?p=15267\">moral functionalism</a>.</p><p>3 Moore (1903); McDowell (1998); Wiggins (1987).</p><p>4 For an overview of such theories, see Miller (2003), chapter 7.</p><p>5 See Carnap (1937), p. 23-25; Hare (1952).</p><p>6 Gibbard (1990).</p><p>7 Blackburn (1984).</p><p>8 The <a href=\"http://en.wikipedia.org/wiki/Joshua_Knobe#The_Knobe_Effect\">Knobe Effect</a>. See Knobe (2003).</p><p>9 Schnall et al. (2008); Baron &amp; Thomley (1994).</p><p>10 Young et al. (2010). I interviewed the author of this study <a href=\"http://commonsenseatheism.com/?p=10549\">here</a>.</p><p>11 This is <a href=\"http://awaisaftab.blogspot.com/2011/03/moral-dumbfounding.html\">moral dumfounding</a>. See Haidt (2001).</p><p>12 Greene (2007).</p><p>13 Zhong et al. (2010).</p><p></p><h4 id=\"References\">References</h4><p>Baron &amp; Thomley (1994). A Whiff of Reality: Positive Affect as a Potential Mediator of the Effects of Pleasant Fragrances on Task Performance and Helping. <em>Environment and Behavior, 26(6)</em>: 766-784.</p><p>Blackburn (1984). <em><a href=\"http://www.amazon.com/Spreading-Word-Groundings-Philosophy-Language/dp/019824651X/\">Spreading the Word</a></em>. Oxford University Press.</p><p>Brandt (1979). <em><a href=\"http://www.amazon.com/Theory-Good-Right-Richard-Brandt/dp/157392220X/\">A Theory of the Good and the Right</a></em>. Oxford University Press.</p><p>Brink (1989). <em><a href=\"http://www.amazon.com/Realism-Foundations-Cambridge-Studies-Philosophy/dp/0521359376/\">Moral Realism and the Foundations of Ethics</a></em>. Cambridge University Press.</p><p>Boyd (1988). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/09/Boyd-How-to-be-a-moral-realist.pdf\">How to be a Moral Realist</a>. In Sayre-McCord (ed.), <em>Essays in Moral Realism</em> (pp. 181-122). Cornell University Press.</p><p>Carnap (1937). <em><a href=\"http://www.amazon.com/Philosophy-Logical-Syntax-Rudolf-Carnap/dp/0404145183/\">Philosophy and Logical Syntax</a></em>. Kegan Paul, Trench, Trubner &amp; Co.</p><p>Gibbard (1990). <em><a href=\"http://www.amazon.com/Wise-Choices-Apt-Feelings-Normative/dp/0674953789/\">Wise Choices, Apt Feelings</a></em>. Clarendon Press.</p><p>Greene (2007). <a href=\"http://www.fed.cuhk.edu.hk/~lchang/material/Evolutionary/Developmental/Greene-KantSoul.pdf\">The secret joke of Kant's soul</a>. In Sinnott-Armstrong (ed.), <em>Moral Psychology, Vol. 3: The Neuroscience of Morality: Emotion, Disease, and Development</em>. MIT Press.</p><p>Haidt (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Haidt-The-emotional-dog-and-its-rational-tail.pdf\">The emotional dog and its rational tail: A social intuitionist approach to moral judgment</a>. <em>Psychological Review, 108</em>: 814-834</p><p>Hare (1952). <em><a href=\"http://www.amazon.com/Language-Morals-Oxford-Paperbacks/dp/0198810776/\">The Language of Morals</a></em>. Oxford University Press.</p><p>Jackson (1998). <em><a href=\"http://www.amazon.com/Metaphysics-Ethics-Defence-Conceptual-Analysis/dp/0198250614/\">From Metaphysics to Ethics</a></em>.  Oxford UniversityPress.</p><p>Joyce (2001). <em><a href=\"http://www.amazon.com/Morality-Cambridge-Studies-Philosophy-English/dp/0521036259/\">The Myth of Morality</a></em>. Cambridge University Press.</p><p>Knobe (2003). <a href=\"https://www.lesserwrong.com/Intentional%20Action%20and%20Side%20Effects%20in%20Ordinary%20Language\">Intentional Action and Side Effects in Ordinary Language</a>. <em>Analysis, 63</em>: 190-193.</p><p>Mackie (1977). <em><a href=\"http://www.amazon.com/Ethics-Inventing-J-L-Mackie/dp/B000FKP9X8/\">Ethics: Inventing Right and Wrong</a></em>. Penguin.</p><p>McDowell (1998). <em><a href=\"http://www.amazon.com/Mind-Value-Reality-John-McDowell/dp/0674007131/\">Mind, Value, and Reality</a></em>. Harvard University Press.</p><p>Miller (2003). <em><a href=\"http://www.amazon.com/Introduction-Contemporary-Metaethics-Alex-Miller/dp/074562345X/\">An Introduction to Contemporary Metaethics</a></em>. Polity.</p><p>Moore (1903). <em><a href=\"http://www.amazon.com/Principia-Ethica-G-Moore/dp/0521448484/\">Principia Ethica</a></em>. Cambridge University Press.</p><p>Schnall, Haidt, Clore, &amp; Jordan (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Schnall-et-al-Disgust-as-embodied-moral-judgment.pdf\">Disgust as embodied moral judgment</a>. <em>Personality and Social Psychology Bulletin, 34(8)</em>: 1096-1109.</p><p>Sturgeon (1988). Moral explanations. In Sayre-McCord (ed.), <em>Essays in Moral Realism</em> (pp. 229-255). Cornell University Press.</p><p>Railton (1986). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Railton-Moral-Realism.pdf\">Moral realism</a>. <em>Philosophical Review, 95</em>: 163-207.</p><p>Wiggins (1987). A sensible subjectivism. In <em>Needs, Values, Truth</em> (pp. 185-214). Blackwell.</p><p>Young, Camprodon, Hauser, Pascual-Leone, &amp; Saxe (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/09/Young-Disruption-of-the-right-temporoparietal-junction-with-transcranial-magnetic-stimulation-reduces-the-role-of-beliefs-in-moral-judgments.pdf\">Disruption of the right temporoparietal junction with transcranial magnetic stimulation reduces the role of beliefs in moral judgments</a>. <em>Proceedings of the National Academy of Sciences, 107</em>: 6753-6758.</p><p>Zhong, Strejcek, &amp; Sivanathan (2010). A clean self can render harsh moral judgment. <em>Journal of Experimental Social Psychology, 46 (5)</em>: 859-862</p>", "sections": [{"title": "Mainstream views in metaethics", "anchor": "Mainstream_views_in_metaethics", "level": 1}, {"title": "Tying it all together", "anchor": "Tying_it_all_together", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 2}, {"title": "References", "anchor": "References", "level": 3}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "562 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 563, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SFnfhJkGsBQk8jakK", "GKfPL6LQFgB49FEnv", "2YPbdHgcjt7g5ZaFN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-04-25T16:53:23.625Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T17:15:40.235Z", "modifiedAt": null, "url": null, "title": "Eye Reading Ability", "slug": "eye-reading-ability", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:38.309Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZLQo7QQqt9KAnB6QZ/eye-reading-ability", "pageUrlRelative": "/posts/ZLQo7QQqt9KAnB6QZ/eye-reading-ability", "linkUrl": "https://www.lesswrong.com/posts/ZLQo7QQqt9KAnB6QZ/eye-reading-ability", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Eye%20Reading%20Ability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEye%20Reading%20Ability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZLQo7QQqt9KAnB6QZ%2Feye-reading-ability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Eye%20Reading%20Ability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZLQo7QQqt9KAnB6QZ%2Feye-reading-ability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZLQo7QQqt9KAnB6QZ%2Feye-reading-ability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p>I seem to recall this site having a high population with some sort of Autism Spectrum Disorder, and so you might be interested in an online test of eye-reading ability, which seems to be linked to ASD.</p>\n<p>But once you take it, just read your score and open the test up in a new tab- don't see which eyes you got wrong. Then retake the test, but imitate the photo each time, and then guess.</p>\n<p>Does your score increase? Compare the lists of eyes you got wrong (the benefit of doing this in two tabs). Anything interesting?</p>\n<p><a href=\"http://glennrowe.net/BaronCohen/Faces/EyesTest.aspx\">The test is here.</a></p>\n<p>&nbsp;</p>\n<p>From <a href=\"http://thelastpsychiatrist.com/2011/04/why_do_autistics_score_poorly.html\">The Last Psychiatrist</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZLQo7QQqt9KAnB6QZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.067797069455104e-07, "legacy": true, "legacyId": "7023", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T18:47:17.457Z", "modifiedAt": null, "url": null, "title": "Improving the college experience for students on the autism spectrum", "slug": "improving-the-college-experience-for-students-on-the-autism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:42.585Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "James_Miller", "createdAt": "2009-03-05T17:14:38.674Z", "isAdmin": false, "displayName": "James_Miller"}, "userId": "LzF2X9eB9oS3q4BXG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qNkcNTpuXCE4fYNHj/improving-the-college-experience-for-students-on-the-autism", "pageUrlRelative": "/posts/qNkcNTpuXCE4fYNHj/improving-the-college-experience-for-students-on-the-autism", "linkUrl": "https://www.lesswrong.com/posts/qNkcNTpuXCE4fYNHj/improving-the-college-experience-for-students-on-the-autism", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Improving%20the%20college%20experience%20for%20students%20on%20the%20autism%20spectrum&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AImproving%20the%20college%20experience%20for%20students%20on%20the%20autism%20spectrum%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNkcNTpuXCE4fYNHj%2Fimproving-the-college-experience-for-students-on-the-autism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Improving%20the%20college%20experience%20for%20students%20on%20the%20autism%20spectrum%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNkcNTpuXCE4fYNHj%2Fimproving-the-college-experience-for-students-on-the-autism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNkcNTpuXCE4fYNHj%2Fimproving-the-college-experience-for-students-on-the-autism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<p>Smith College is considering trying to make itself more attractive to smart students on the autism spectrum. &nbsp;I would be grateful for suggestions on how to do this from autistics who read LessWrong. &nbsp;You can write comments here or if you wish to remain anonymous send them to me at Jdmiller@Smith.edu</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qNkcNTpuXCE4fYNHj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 16, "extendedScore": null, "score": 7.06805754218053e-07, "legacy": true, "legacyId": "7026", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T18:56:27.094Z", "modifiedAt": null, "url": null, "title": "Elitist Jerks: A Well-Kept Garden ", "slug": "elitist-jerks-a-well-kept-garden", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.223Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "malthrin", "createdAt": "2011-03-22T15:23:59.536Z", "isAdmin": false, "displayName": "malthrin"}, "userId": "5b5DcLkcYGD9YGRfF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TjWSLrZcvrGio6iyp/elitist-jerks-a-well-kept-garden", "pageUrlRelative": "/posts/TjWSLrZcvrGio6iyp/elitist-jerks-a-well-kept-garden", "linkUrl": "https://www.lesswrong.com/posts/TjWSLrZcvrGio6iyp/elitist-jerks-a-well-kept-garden", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Elitist%20Jerks%3A%20A%20Well-Kept%20Garden%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AElitist%20Jerks%3A%20A%20Well-Kept%20Garden%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTjWSLrZcvrGio6iyp%2Felitist-jerks-a-well-kept-garden%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Elitist%20Jerks%3A%20A%20Well-Kept%20Garden%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTjWSLrZcvrGio6iyp%2Felitist-jerks-a-well-kept-garden", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTjWSLrZcvrGio6iyp%2Felitist-jerks-a-well-kept-garden", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 624, "htmlBody": "<p>In response to: http://lesswrong.com/lw/c1/wellkept_gardens_die_by_pacifism/</p>\n<p>I'm a moderator at Elitist Jerks (http://www.elitistjerks.com), a World of Warcraft discussion forum. Within the WoW community, EJ has always been known for its strict moderation standards. We're exactly the sort of 'well-kept garden' that EY's post is about. You can see the fruit of the mod team's labor here: http://elitistjerks.com/f34/ I'll give some of the site's backstory for non-WoW players, describe the crossroads that we're currently at, and then give some caveats before you generalize too much from our example.</p>\n<p>EJ's initial community came together to discuss WoW's most challenging content, known as \"raids\". In order to optimally outfit our characters for maximum performance in raids, both empirical and theoretical work was necessary: the game's combat mechanics were reverse engineered and detailed models for each character class were created. Within a couple of years, this \"theorycrafting\" work became the forum's primary purpose - refining and updating models as new game patches were released. Throughout the forum's life, high moderation standards have been maintained in order to protect our high signal/noise discussion. Primarily, asking for help is forbidden when the resources to answer your question already exist.</p>\n<p>However, we're starting to wonder if we've performed our task too well.&nbsp;</p>\n<ul>\n<li>Discussion about any aspect of the game that can't be quantified has almost completely died out. Despite having threads explicitly designated for more subjective topics, the overall forum atmosphere is sufficiently hostile/intimidating to non-analytic personalities that those threads don't see much traffic.</li>\n<li>Further refinements in class modeling are so small as to be empirically unverifiable - their impact emerges in lengthy runs of simulated combat, but is washed out by random factors (critical hits, etc) in the 5-10 minutes of a typical raid encounter.</li>\n<li>The community is heavily dependant on a few dozen key contributors who maintain the accepted spreadsheet/simulation models. By encouraging all our visitors to use their tools, we've made these people into single points of failure. When one of them quits the game, it's difficult to find another to take up maintenance on their model, because&nbsp;any programmer would rather write new code than work on old code (http://www.joelonsoftware.com/articles/fog0000000069.html). </li>\n<li>In addition to the previous, some of the class models simply aren't as good/reliable as others. However, due to the average person's inability to shut up and multiply (http://wiki.lesswrong.com/wiki/Shut_up_and_multiply),&nbsp;we don't allow posts questioning model output unless they have a detailed proof of a bug. As a result, the models that should be taken with a grain of salt are treated with just as much credibility as the strongest.</li>\n</ul>\n<p>So here we moderators sit on our porch, having kept our garden tidy for six years now. The questions we're asking are \"Is this the community we meant to create?\" and \"What happens to a community formed to solve a problem once the problem is effectively solved?\"</p>\n<p>Caveats:</p>\n<ul>\n<li>There is a private area of the forums where subjective and off-topic discussions still take place. However, these discussions are invisible to non-paying members. I personally worry that quarantining our fun may be just as dangerous for the health of the community as diluting it. This opinion is not universal among the moderation team.</li>\n<li>WoW is, in the larger scope of things, not that hard a problem. What to do after accomplishing a primary goal is not likely to be a problem for a more broadly-scoped community. Even in WoW, hard problems remain that resist quantification - How do you motivate 25 people to keep battling a dragon that's been killing them for the last 2 hours? How do you identify the recruits that will best fit into an existing group and its culture? How do you balance redundancy and responsibility in leadership?</li>\n</ul>\n<p>&nbsp;</p>\n<p>edit: fixed some link formatting</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"oraLTPkETL5xKmhx3": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TjWSLrZcvrGio6iyp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 36, "extendedScore": null, "score": 7.4e-05, "legacy": true, "legacyId": "7027", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-25T21:05:37.065Z", "modifiedAt": null, "url": null, "title": "Toronto Meetup, April 28", "slug": "toronto-meetup-april-28", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:36.545Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spencer_Sleep", "createdAt": "2011-02-11T08:03:53.049Z", "isAdmin": false, "displayName": "Spencer_Sleep"}, "userId": "xAjAXuvj2czWZix2v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8bAZmaDrrQy9wP4fF/toronto-meetup-april-28", "pageUrlRelative": "/posts/8bAZmaDrrQy9wP4fF/toronto-meetup-april-28", "linkUrl": "https://www.lesswrong.com/posts/8bAZmaDrrQy9wP4fF/toronto-meetup-april-28", "postedAtFormatted": "Monday, April 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Toronto%20Meetup%2C%20April%2028&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToronto%20Meetup%2C%20April%2028%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8bAZmaDrrQy9wP4fF%2Ftoronto-meetup-april-28%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Toronto%20Meetup%2C%20April%2028%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8bAZmaDrrQy9wP4fF%2Ftoronto-meetup-april-28", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8bAZmaDrrQy9wP4fF%2Ftoronto-meetup-april-28", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><strong>When</strong>: Thursday, April 28th, 20:00</p>\n<p><strong>Where</strong>: The Bedford Academy, 36 Prince Arthur Avenue</p>\n<p>Hi everyone,</p>\n<p>The Toronto meetup group is having one of our bi-weekly meetings this Thursday at the Bedford Academy. The reservation is under the name Spencer Sleep. I have requested a table upstairs, as it tends to be much quieter up there.</p>\n<p>Newcomers are, as always, extremely welcome.</p>\n<p>If you want to hear about upcoming LessWrong events in Toronto, or have ideas about how or when those events should be run, join the <a href=\"http://groups.google.com/group/lesswrongtoronto\">Toronto LessWrong Google Group</a>!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8bAZmaDrrQy9wP4fF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 7.068450831495239e-07, "legacy": true, "legacyId": "7028", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-26T01:45:09.234Z", "modifiedAt": null, "url": null, "title": "Consequentialism FAQ", "slug": "consequentialism-faq", "viewCount": null, "lastCommentedAt": "2021-07-14T22:53:43.738Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9oqF382ASmjaGBo7z/consequentialism-faq", "pageUrlRelative": "/posts/9oqF382ASmjaGBo7z/consequentialism-faq", "linkUrl": "https://www.lesswrong.com/posts/9oqF382ASmjaGBo7z/consequentialism-faq", "postedAtFormatted": "Tuesday, April 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Consequentialism%20FAQ&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConsequentialism%20FAQ%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9oqF382ASmjaGBo7z%2Fconsequentialism-faq%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Consequentialism%20FAQ%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9oqF382ASmjaGBo7z%2Fconsequentialism-faq", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9oqF382ASmjaGBo7z%2Fconsequentialism-faq", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p>There are a lot of explanations of consequentialism and utilitarianism out there, but not a lot of persuasive essays trying to convert people. I would like to fill that gap with a pro-consequentialist FAQ. The target audience is people who are intelligent but may not have a strong philosophy background or have thought about this matter too much before (ie it's not intended to solve every single problem or be up to the usual standards of discussion on LW).</p>\n<p>I have a draft up at <a href=\"http://www.raikoth.net/consequentialism.html\">http://www.raikoth.net/consequentialism.html</a> (yes, I have since realized the background is horrible, and changing it is on my list of things to do). Feedback would be appreciated, <em>especially</em> from non-consequentialists and non-philosophers since they're the target audience.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DigEmY3RrF3XL5cwe": 2, "ZTRNmvQGgoYiymYnq": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9oqF382ASmjaGBo7z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 39, "extendedScore": null, "score": 8.3e-05, "legacy": true, "legacyId": "7031", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 124, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-26T03:42:25.538Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] A Fable of Science and Politics", "slug": "seq-rerun-a-fable-of-science-and-politics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:35.974Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jake987722", "createdAt": "2009-11-15T04:00:32.147Z", "isAdmin": false, "displayName": "jake987722"}, "userId": "z2eomSrHzecedEdNt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DsxmA3S6CfXrgj4MY/seq-rerun-a-fable-of-science-and-politics", "pageUrlRelative": "/posts/DsxmA3S6CfXrgj4MY/seq-rerun-a-fable-of-science-and-politics", "linkUrl": "https://www.lesswrong.com/posts/DsxmA3S6CfXrgj4MY/seq-rerun-a-fable-of-science-and-politics", "postedAtFormatted": "Tuesday, April 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20A%20Fable%20of%20Science%20and%20Politics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20A%20Fable%20of%20Science%20and%20Politics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDsxmA3S6CfXrgj4MY%2Fseq-rerun-a-fable-of-science-and-politics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20A%20Fable%20of%20Science%20and%20Politics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDsxmA3S6CfXrgj4MY%2Fseq-rerun-a-fable-of-science-and-politics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDsxmA3S6CfXrgj4MY%2Fseq-rerun-a-fable-of-science-and-politics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 162, "htmlBody": "<p>Today's post, <a href=\"/lw/gt/a_fable_of_science_and_politics/\">A Fable of Science and Politics</a> was originally published on 23 December 2006. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>People respond in different ways to clear evidence they're wrong, not always by updating and moving on.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/r/discussion/lw/5eo/seq_rerun_i_dont_know/\">\"I don't know.\"</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DsxmA3S6CfXrgj4MY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 15, "extendedScore": null, "score": 7.069579244628491e-07, "legacy": true, "legacyId": "7039", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6hfGNLf4Hg5DXqJCF", "tkgiPWxn6FJ2MKqPe", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-26T08:35:22.242Z", "modifiedAt": "2020-05-15T18:39:42.710Z", "url": null, "title": "SIAI Fundraising", "slug": "siai-fundraising", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:27.393Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BrandonReinhart", "createdAt": "2009-03-06T04:00:54.689Z", "isAdmin": false, "displayName": "BrandonReinhart"}, "userId": "ugRLNpaFuDrXntoeK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EWn3cyNMyYct98a6G/siai-fundraising", "pageUrlRelative": "/posts/EWn3cyNMyYct98a6G/siai-fundraising", "linkUrl": "https://www.lesswrong.com/posts/EWn3cyNMyYct98a6G/siai-fundraising", "postedAtFormatted": "Tuesday, April 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SIAI%20Fundraising&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASIAI%20Fundraising%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEWn3cyNMyYct98a6G%2Fsiai-fundraising%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SIAI%20Fundraising%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEWn3cyNMyYct98a6G%2Fsiai-fundraising", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEWn3cyNMyYct98a6G%2Fsiai-fundraising", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1828, "htmlBody": "<p><strong>Please refer to the updated documented here:\u00a0<a href=\"/lw/5il/siai_an_examination/\">http://lesswrong.com/lw/5il/siai_an_examination/</a></strong></p>\n<p><strong>This version is an old draft.</strong></p>\n<p>\u00a0</p>\n<p>NOTE: Analysis here will be updated as people point out errors! I've tried to be accurate, but this is my first time looking at these (somewhat hairy) non-profit tax documents. Errors will be corrected as soon as I know of them! Please double check and criticize this work that it might improve.</p>\n<p>Document History:</p>\n<ul>\n<li>4/25/2011 - Initial post.</li>\n<li>4/25/2011 - Corrected Yudkowsky compensation data.</li>\n<li>4/26/2011 - Added expanded data from 2002 - 2009 in Overview, Revenue, and Expenses</li>\n<li>4/27/2011 - Added expanded data to Officer Compensation &amp; Big Donors</li>\n</ul>\n<p>Todo:</p>\n<ul>\n<li>Create a detailed program services analysis that examines the SIAI's allocation of funds to the Summit, etc.</li>\n<li>Create an index of organizational milestones.</li>\n</ul>\n<p>Disclaimer:</p>\n<ul>\n<li>I am not affiliated with the SIAI.</li>\n<li>I have not donated to the SIAI prior to writing this.</li>\n</ul>\n<p>Acting on <a href=\"/user/gwern/\">gwern</a>'s suggestion in his <a href=\"/r/discussion/lw/5el/are_girl_scout_cookies_deliciously_evil_a_case/\">Girl Scout Cookie</a> analysis, here is a first pass at looking at SIAI funding, suggestions for a funding task-force, etc.</p>\n<p>The SIAI's Form 990's are available at <a href=\"http://www2.guidestar.org/\">GuideStar</a>\u00a0and <a href=\"http://foundationcenter.org/\">Foundation Center</a>. You must register in order to access the files at GuideStar.</p>\n<ul>\n<li><a href=\"http://bit.ly/dZZkc0\">2002</a>\u00a0(Form 990-EZ)</li>\n<li><a href=\"http://bit.ly/eOgI0B\">2003</a>\u00a0(Form 990-EZ)</li>\n<li><a href=\"http://bit.ly/efHrQC\">2004</a>\u00a0(Form 990-EZ)</li>\n<li><a href=\"http://bit.ly/f3Ekvg\">2005</a>\u00a0(Form 990)</li>\n<li><a href=\"http://bit.ly/gRC7SS\">2006</a>\u00a0(Form 990)</li>\n<li><a href=\"http://www.guidestar.org/FinDocuments//2007/582/565/2007-582565917-0487362e-9.pdf\">2007</a> (Form 990)</li>\n<li><a href=\"http://www.guidestar.org/FinDocuments//2008/582/565/2008-582565917-0599169c-Z.pdf\">2008</a> (Form 990-EZ)</li>\n<li><a href=\"http://www.guidestar.org/FinDocuments//2009/582/565/2009-582565917-06b644eb-9.pdf\">2009</a> (Form 990)</li>\n</ul>\n<div>Work is being done in <a href=\"https://spreadsheets.google.com/ccc?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;hl=en&amp;authkey=CMKZ1qQP\">this Google Spreadsheet</a>.</div>\n<h2><strong>Overview</strong></h2>\n<p><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=9&amp;zx=3igypx8vnsj4\" /></p>\n<p><img src=\"http://i51.tinypic.com/sbrio2.jpg\" /><img src=\"http://i51.tinypic.com/2v832tw.jpg\" /></p>\n<div>Notes:</div>\n<div>Sometimes the listed end of year balances didn't match what the spreadsheet calculated:</div>\n<ul>\n<li><strong>Filing Error 1?</strong> - There appears to be a minor typo to the effect of $4.86 in the end of year balance for the 2004 document. <em>This money is accounted for,</em> the results just aren't entered correctly. * Someone else please verify.</li>\n<li><strong>Filing Error 2?</strong> - The 2005 document appears to have accounted for expenses incorrectly, resulting in an excess $70,179.00 reported in the end of the year asset balance. <em>This money is accounted for under 2005 Part III.</em> It is merely not correctly deducted from the year end asset balance. * Someone else please verify.</li>\n<li><strong>Theft? -\u00a0</strong>The organization reported $118,803.00 in theft in 2009 resulting in a year end asset balance lower than expected. <em>The SIAI is currently pursuing legal restitution.</em></li>\n</ul>\n<p>Analysis:</p>\n<ul>\n<li>The SIAI asset sheet grew until 2008 when expenditures outpaced revenue.</li>\n<li>Assets would have resumed growth into 2009, except for theft (see above.)</li>\n<li>Current asset balance is insufficient to sustain a year of operation at existing rate of expenditure. Significant loss of revenue would result in a shrinkage of services. Such a loss of revenue may be unlikely, but a reasonable goal would be to build up a year's reserves.</li>\n</ul>\n<h2><strong>Revenue</strong></h2>\n<div>Revenue is composed of public support, program service (events/conferences held, etc), and investment interest. The \"Other\" category tends to include Amazon.com affiliate income, etc.</div>\n<div><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=10&amp;zx=h2xlqyuyanq0\" /></div>\n<div><span><span><img src=\"http://i51.tinypic.com/othv21.jpg\" /></span></span></div>\n<p>Analysis:</p>\n<ul>\n<li>Income from public support (donations) has grown steadily with a significant regular increase starting in 2006.</li>\n<li>This regular increase is a result of significant new contributions from big donors. \n<ul>\n<li>As an example, public support in 2007 is largely composed of significant contributions from Peter Thiel ($125k), Brian Cartmell ($75k), and Robert F. Zahra Jr ($123k) for $323k total in large scale individual contributions (break down below).</li>\n</ul>\n</li>\n<li>In 2007 the SIAI started receiving income from program services. Currently all \"Program Service\" revenue is from operation of the Singularity Summit.</li>\n<li>The Singularity Summit revenue continues to grow. The Summit is roughly breaking even. If this continues, the Summit will be able to compensate speakers better, improve the quality of proceedings, or net some of the revenue for other goals.</li>\n</ul>\n<h2><strong>Expenses</strong></h2>\n<div>Expenses are composed of grants, benefits, salaries &amp; compensation, contracts, travel, program services, and an other category (mostly administrative costs and usually itemized, check the source data).</div>\n<div>The contracts column in the chart below includes legal and accounting fees. Check the source data.</div>\n<p><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=11&amp;zx=nklfq98rlp68\" /></p>\n<p><img src=\"http://i52.tinypic.com/2zobsll.jpg\" /></p>\n<p>Analysis:</p>\n<ul>\n<li>This chart can use improvement. It's categorized rather clinically. Would be more useful to break down the Contracts and Program categories (this may not be possible from the Form 990s).</li>\n<li>The grants in 2002, 2003, and 2004 were paid to Eliezer Yudkowsky for work \"of unique relevance and value to the Singularity, to Artificial Intelligence, or to Friendly Artificial Intelligence.\"</li>\n<li>Program expenses include operating the Singularity Summit, Visiting Fellows Program, etc.</li>\n<li>The Other category includes lots of administrative costs that are somewhat itemized.</li>\n<li>Overall, expenses have grown at pace with revenue. \n<ul>\n<li>Salaries have steadily declined. (More detail below.)</li>\n<li>Program service expenses have increased, but this is expected as the Singularity Summit has grown and new services like the Visiting Fellows Program have been introduced.</li>\n</ul>\n</li>\n</ul>\n<h2><strong>Big Donors</strong></h2>\n<p><img src=\"https://spreadsheets.google.com/spreadsheet/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=15&amp;zx=letfny3o0gyo\" /></p>\n<p>Analysis</p>\n<ul>\n<li>Contributions in the 2010 column are derived from <a href=\"http://intelligence.org/donors\">http://singinst.org/donors</a>. Contributions of less than $5,000 are excluded for the sake of brevity.</li>\n<li>Contributions in 2003 - 2009 are from official filings. The 2009 Form 990 discloses excess donations for 2006 - 2009. This is not an exhaustive list of contributions, just what could be found in the Form 990s available online.</li>\n<li>The 2006 donation from Peter Thiel is sourced from a discussion with the SIAI.</li>\n<li>Peter Thiel and a few other big donors compose the bulk of the organization's revenue. \n<ul>\n<li>Should any major donor be lost, the SIAI would have to reduce services. It would be good to see a broader base of donations moving forward.</li>\n<li>Note, however, that over the past five years the base of donations HAS been improving. We don't have the 2010 Form 990 yet, but just based on data from MA and SingInst.com things are looking a lot better.</li>\n</ul>\n</li>\n</ul>\n<h2><strong>Officer Compensation</strong></h2>\n<p><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=12&amp;zx=cm4ic657urpj\" /></p>\n<div>Analysis: \n<ul>\n<li>This graph needs further work to reflect the duration of officers' service.</li>\n<li>In 2002 to 2005 Eliezer Yudkowsky received compensation in the form of grants from the SIAI for AI research.</li>\n<li>Starting in 2006 all compensation for key officers is reported as salaried instead of in the form of grants.</li>\n<li>SIAI officer compensation has decreased in recent years.</li>\n<li>Eliezer's base compensation as salary increased 20% in 2008 and then 7.8% in 2009. \n<ul>\n<li>It seems reasonable to compare Eliezer's salary with that of professional software developers. Eliezer would be able to make a fair amount more working in private industry as a software developer.</li>\n</ul>\n</li>\n<li>Both Yudkowsky and Vassar report working 60 hours a work week.</li>\n<li>It isn't indicated how the SIAI conducts performance reviews and salary adjustment evaluations.</li>\n</ul>\n<div><span><strong>Further Editorial Thoughts...</strong></span></div>\n<p>Prior to doing this investigation, I had some expectation that the Singularity Summit was a money losing operation. I had an expectation that Eliezer probably made around $70k (programmer money discounted for being paid by a non-profit). I figured the SIAI had a broader donor base. I was off base on all counts.* I am not currently an SIAI supporter. My findings have greatly increased the probability that I will donate in the future.\u00a0</p>\n<p>Overall, the allocation of funds strikes me as highly efficient. I don't know exactly how much the SIAI is spending on food and fancy tablecloths at the Singularity Summit, but I don't think I care: it's growing and it's nearly breaking even. An attendee can have a very confident expectation that their fee covers their cost to the organization. If you go and contribute you add pure value by your attendance.</p>\n<p>At the same time, the organization has been able to expand services without draining the coffers. A donor can hold a strong expectation that the bulk of their donation will go toward actual work in the form of salaries for working personnel or events like the Visiting Fellows Program.</p>\n<p>Eliezer's compensation is slightly more than I thought. I'm not sure what upper bound I would have balked at or would balk at. I do have some concern about the cost of recruiting additional Research Fellows. The cost of additional RFs has to be weighed against new programs like Visiting Fellows.</p>\n<p>The organization appears to be managing its cash reserves well. It would be good to see the SIAI build up some asset reserves so that it could operate comfortably in years were public support dips or so that it could take advantage of unexpected opportunities.</p>\n<p>The organization has a heavy reliance on major donor support. I would expect the 2010 filing to reveal a broadening of revenue and continued expansion of services, but I do not expect the organization to have become independent of big donor support. Things are much improved from 2006 and without the initial support from Peter Thiel the SIAI would not be able to provide the services it has, but it would still be good to see the SIAI operating capacity be larger than any one donor's annual contribution.\u00a0<strong>It is important for Less Wrong to begin a discussion of broadening SIAI revenue sources.</strong></p>\n<h2><strong>Where to Start?</strong></h2>\n<p>There is low hanging fruit to be found. The SIAI's annual revenue is well within the range of our ability to effect significant impact. These suggestions aren't all equal in their promise, they are just things that come to my mind.</p>\n<ul>\n<li>Grant Writing. I don't know a lot about it. Presumably a Less Wrong task force could investigate likely candidate grants, research proper grant writing methodology, and then apply for the grants. Academic members of Less Wrong who have applied for research grants would already have expertise in this area.</li>\n</ul>\n<ul>\n<li>Software. There are a lot of programmers on Less Wrong. A task force could develop an application and donate the revenue to the SIAI.</li>\n</ul>\n<ul>\n<li>Encouraging Donations. Expanding the base of donations is valuable. The SIAI is heavily dependent on donations from Peter Thiel. A task force could focus on methods of encouraging donations from new supporters big and small.</li>\n</ul>\n<ul>\n<li>Prize Winning. There are prizes out there to be won. A Less Wrong task force could identify a prize and then coordinate a group to work towards winning it.</li>\n</ul>\n<ul>\n<li>Crowd Source Utilization. There are sites devoted to crowd sourced funding for projects. A task force could conceive of a project with the potential to generate more revenue than required to build it. Risk could be reduced through the use of crowd sourcing. Excess revenue donated to the SIAI. (Projects don't have to be software, they could be fabricating an interesting device, piece of art, or music.)</li>\n</ul>\n<ul>\n<li>General Fund Raising Research. There are a lot of charities in the world. Presumably there are documented methods for growing them. A task force could attack this material and identify low hanging fruit or synthesize new techniques.</li>\n</ul>\n<div>I have more specific thoughts, but I want to chew on them a bit.</div>\n<div><br /></div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NrvXXL3iGjjxu5B7d": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EWn3cyNMyYct98a6G", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 60, "baseScore": 78, "extendedScore": null, "score": 0.00016141222282235694, "legacy": true, "legacyId": "7044", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": true, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 59, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<p><strong id=\"Please_refer_to_the_updated_documented_here__http___lesswrong_com_lw_5il_siai_an_examination_\">Please refer to the updated documented here:&nbsp;<a href=\"/lw/5il/siai_an_examination/\">http://lesswrong.com/lw/5il/siai_an_examination/</a></strong></p>\n<p><strong id=\"This_version_is_an_old_draft_\">This version is an old draft.</strong></p>\n<p>&nbsp;</p>\n<p>NOTE: Analysis here will be updated as people point out errors! I've tried to be accurate, but this is my first time looking at these (somewhat hairy) non-profit tax documents. Errors will be corrected as soon as I know of them! Please double check and criticize this work that it might improve.</p>\n<p>Document History:</p>\n<ul>\n<li>4/25/2011 - Initial post.</li>\n<li>4/25/2011 - Corrected Yudkowsky compensation data.</li>\n<li>4/26/2011 - Added expanded data from 2002 - 2009 in Overview, Revenue, and Expenses</li>\n<li>4/27/2011 - Added expanded data to Officer Compensation &amp; Big Donors</li>\n</ul>\n<p>Todo:</p>\n<ul>\n<li>Create a detailed program services analysis that examines the SIAI's allocation of funds to the Summit, etc.</li>\n<li>Create an index of organizational milestones.</li>\n</ul>\n<p>Disclaimer:</p>\n<ul>\n<li>I am not affiliated with the SIAI.</li>\n<li>I have not donated to the SIAI prior to writing this.</li>\n</ul>\n<p>Acting on <a href=\"/user/gwern/\">gwern</a>'s suggestion in his <a href=\"/r/discussion/lw/5el/are_girl_scout_cookies_deliciously_evil_a_case/\">Girl Scout Cookie</a> analysis, here is a first pass at looking at SIAI funding, suggestions for a funding task-force, etc.</p>\n<p>The SIAI's Form 990's are available at <a href=\"http://www2.guidestar.org/\">GuideStar</a>&nbsp;and <a href=\"http://foundationcenter.org/\">Foundation Center</a>. You must register in order to access the files at GuideStar.</p>\n<ul>\n<li><a href=\"http://bit.ly/dZZkc0\">2002</a>&nbsp;(Form 990-EZ)</li>\n<li><a href=\"http://bit.ly/eOgI0B\">2003</a>&nbsp;(Form 990-EZ)</li>\n<li><a href=\"http://bit.ly/efHrQC\">2004</a>&nbsp;(Form 990-EZ)</li>\n<li><a href=\"http://bit.ly/f3Ekvg\">2005</a>&nbsp;(Form 990)</li>\n<li><a href=\"http://bit.ly/gRC7SS\">2006</a>&nbsp;(Form 990)</li>\n<li><a href=\"http://www.guidestar.org/FinDocuments//2007/582/565/2007-582565917-0487362e-9.pdf\">2007</a> (Form 990)</li>\n<li><a href=\"http://www.guidestar.org/FinDocuments//2008/582/565/2008-582565917-0599169c-Z.pdf\">2008</a> (Form 990-EZ)</li>\n<li><a href=\"http://www.guidestar.org/FinDocuments//2009/582/565/2009-582565917-06b644eb-9.pdf\">2009</a> (Form 990)</li>\n</ul>\n<div>Work is being done in <a href=\"https://spreadsheets.google.com/ccc?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;hl=en&amp;authkey=CMKZ1qQP\">this Google Spreadsheet</a>.</div>\n<h2 id=\"Overview\"><strong>Overview</strong></h2>\n<p><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=9&amp;zx=3igypx8vnsj4\"></p>\n<p><img src=\"http://i51.tinypic.com/sbrio2.jpg\"><img src=\"http://i51.tinypic.com/2v832tw.jpg\"></p>\n<div>Notes:</div>\n<div>Sometimes the listed end of year balances didn't match what the spreadsheet calculated:</div>\n<ul>\n<li><strong>Filing Error 1?</strong> - There appears to be a minor typo to the effect of $4.86 in the end of year balance for the 2004 document. <em>This money is accounted for,</em> the results just aren't entered correctly. * Someone else please verify.</li>\n<li><strong>Filing Error 2?</strong> - The 2005 document appears to have accounted for expenses incorrectly, resulting in an excess $70,179.00 reported in the end of the year asset balance. <em>This money is accounted for under 2005 Part III.</em> It is merely not correctly deducted from the year end asset balance. * Someone else please verify.</li>\n<li><strong>Theft? -&nbsp;</strong>The organization reported $118,803.00 in theft in 2009 resulting in a year end asset balance lower than expected. <em>The SIAI is currently pursuing legal restitution.</em></li>\n</ul>\n<p>Analysis:</p>\n<ul>\n<li>The SIAI asset sheet grew until 2008 when expenditures outpaced revenue.</li>\n<li>Assets would have resumed growth into 2009, except for theft (see above.)</li>\n<li>Current asset balance is insufficient to sustain a year of operation at existing rate of expenditure. Significant loss of revenue would result in a shrinkage of services. Such a loss of revenue may be unlikely, but a reasonable goal would be to build up a year's reserves.</li>\n</ul>\n<h2 id=\"Revenue\"><strong>Revenue</strong></h2>\n<div>Revenue is composed of public support, program service (events/conferences held, etc), and investment interest. The \"Other\" category tends to include Amazon.com affiliate income, etc.</div>\n<div><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=10&amp;zx=h2xlqyuyanq0\"></div>\n<div><span><span><img src=\"http://i51.tinypic.com/othv21.jpg\"></span></span></div>\n<p>Analysis:</p>\n<ul>\n<li>Income from public support (donations) has grown steadily with a significant regular increase starting in 2006.</li>\n<li>This regular increase is a result of significant new contributions from big donors. \n<ul>\n<li>As an example, public support in 2007 is largely composed of significant contributions from Peter Thiel ($125k), Brian Cartmell ($75k), and Robert F. Zahra Jr ($123k) for $323k total in large scale individual contributions (break down below).</li>\n</ul>\n</li>\n<li>In 2007 the SIAI started receiving income from program services. Currently all \"Program Service\" revenue is from operation of the Singularity Summit.</li>\n<li>The Singularity Summit revenue continues to grow. The Summit is roughly breaking even. If this continues, the Summit will be able to compensate speakers better, improve the quality of proceedings, or net some of the revenue for other goals.</li>\n</ul>\n<h2 id=\"Expenses\"><strong>Expenses</strong></h2>\n<div>Expenses are composed of grants, benefits, salaries &amp; compensation, contracts, travel, program services, and an other category (mostly administrative costs and usually itemized, check the source data).</div>\n<div>The contracts column in the chart below includes legal and accounting fees. Check the source data.</div>\n<p><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=11&amp;zx=nklfq98rlp68\"></p>\n<p><img src=\"http://i52.tinypic.com/2zobsll.jpg\"></p>\n<p>Analysis:</p>\n<ul>\n<li>This chart can use improvement. It's categorized rather clinically. Would be more useful to break down the Contracts and Program categories (this may not be possible from the Form 990s).</li>\n<li>The grants in 2002, 2003, and 2004 were paid to Eliezer Yudkowsky for work \"of unique relevance and value to the Singularity, to Artificial Intelligence, or to Friendly Artificial Intelligence.\"</li>\n<li>Program expenses include operating the Singularity Summit, Visiting Fellows Program, etc.</li>\n<li>The Other category includes lots of administrative costs that are somewhat itemized.</li>\n<li>Overall, expenses have grown at pace with revenue. \n<ul>\n<li>Salaries have steadily declined. (More detail below.)</li>\n<li>Program service expenses have increased, but this is expected as the Singularity Summit has grown and new services like the Visiting Fellows Program have been introduced.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Big_Donors\"><strong>Big Donors</strong></h2>\n<p><img src=\"https://spreadsheets.google.com/spreadsheet/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=15&amp;zx=letfny3o0gyo\"></p>\n<p>Analysis</p>\n<ul>\n<li>Contributions in the 2010 column are derived from <a href=\"http://intelligence.org/donors\">http://singinst.org/donors</a>. Contributions of less than $5,000 are excluded for the sake of brevity.</li>\n<li>Contributions in 2003 - 2009 are from official filings. The 2009 Form 990 discloses excess donations for 2006 - 2009. This is not an exhaustive list of contributions, just what could be found in the Form 990s available online.</li>\n<li>The 2006 donation from Peter Thiel is sourced from a discussion with the SIAI.</li>\n<li>Peter Thiel and a few other big donors compose the bulk of the organization's revenue. \n<ul>\n<li>Should any major donor be lost, the SIAI would have to reduce services. It would be good to see a broader base of donations moving forward.</li>\n<li>Note, however, that over the past five years the base of donations HAS been improving. We don't have the 2010 Form 990 yet, but just based on data from MA and SingInst.com things are looking a lot better.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Officer_Compensation\"><strong>Officer Compensation</strong></h2>\n<p><img src=\"https://spreadsheets.google.com/oimg?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;oid=12&amp;zx=cm4ic657urpj\"></p>\n<div>Analysis: \n<ul>\n<li>This graph needs further work to reflect the duration of officers' service.</li>\n<li>In 2002 to 2005 Eliezer Yudkowsky received compensation in the form of grants from the SIAI for AI research.</li>\n<li>Starting in 2006 all compensation for key officers is reported as salaried instead of in the form of grants.</li>\n<li>SIAI officer compensation has decreased in recent years.</li>\n<li>Eliezer's base compensation as salary increased 20% in 2008 and then 7.8% in 2009. \n<ul>\n<li>It seems reasonable to compare Eliezer's salary with that of professional software developers. Eliezer would be able to make a fair amount more working in private industry as a software developer.</li>\n</ul>\n</li>\n<li>Both Yudkowsky and Vassar report working 60 hours a work week.</li>\n<li>It isn't indicated how the SIAI conducts performance reviews and salary adjustment evaluations.</li>\n</ul>\n<div><span><strong>Further Editorial Thoughts...</strong></span></div>\n<p>Prior to doing this investigation, I had some expectation that the Singularity Summit was a money losing operation. I had an expectation that Eliezer probably made around $70k (programmer money discounted for being paid by a non-profit). I figured the SIAI had a broader donor base. I was off base on all counts.* I am not currently an SIAI supporter. My findings have greatly increased the probability that I will donate in the future.&nbsp;</p>\n<p>Overall, the allocation of funds strikes me as highly efficient. I don't know exactly how much the SIAI is spending on food and fancy tablecloths at the Singularity Summit, but I don't think I care: it's growing and it's nearly breaking even. An attendee can have a very confident expectation that their fee covers their cost to the organization. If you go and contribute you add pure value by your attendance.</p>\n<p>At the same time, the organization has been able to expand services without draining the coffers. A donor can hold a strong expectation that the bulk of their donation will go toward actual work in the form of salaries for working personnel or events like the Visiting Fellows Program.</p>\n<p>Eliezer's compensation is slightly more than I thought. I'm not sure what upper bound I would have balked at or would balk at. I do have some concern about the cost of recruiting additional Research Fellows. The cost of additional RFs has to be weighed against new programs like Visiting Fellows.</p>\n<p>The organization appears to be managing its cash reserves well. It would be good to see the SIAI build up some asset reserves so that it could operate comfortably in years were public support dips or so that it could take advantage of unexpected opportunities.</p>\n<p>The organization has a heavy reliance on major donor support. I would expect the 2010 filing to reveal a broadening of revenue and continued expansion of services, but I do not expect the organization to have become independent of big donor support. Things are much improved from 2006 and without the initial support from Peter Thiel the SIAI would not be able to provide the services it has, but it would still be good to see the SIAI operating capacity be larger than any one donor's annual contribution.&nbsp;<strong>It is important for Less Wrong to begin a discussion of broadening SIAI revenue sources.</strong></p>\n<h2 id=\"Where_to_Start_\"><strong>Where to Start?</strong></h2>\n<p>There is low hanging fruit to be found. The SIAI's annual revenue is well within the range of our ability to effect significant impact. These suggestions aren't all equal in their promise, they are just things that come to my mind.</p>\n<ul>\n<li>Grant Writing. I don't know a lot about it. Presumably a Less Wrong task force could investigate likely candidate grants, research proper grant writing methodology, and then apply for the grants. Academic members of Less Wrong who have applied for research grants would already have expertise in this area.</li>\n</ul>\n<ul>\n<li>Software. There are a lot of programmers on Less Wrong. A task force could develop an application and donate the revenue to the SIAI.</li>\n</ul>\n<ul>\n<li>Encouraging Donations. Expanding the base of donations is valuable. The SIAI is heavily dependent on donations from Peter Thiel. A task force could focus on methods of encouraging donations from new supporters big and small.</li>\n</ul>\n<ul>\n<li>Prize Winning. There are prizes out there to be won. A Less Wrong task force could identify a prize and then coordinate a group to work towards winning it.</li>\n</ul>\n<ul>\n<li>Crowd Source Utilization. There are sites devoted to crowd sourced funding for projects. A task force could conceive of a project with the potential to generate more revenue than required to build it. Risk could be reduced through the use of crowd sourcing. Excess revenue donated to the SIAI. (Projects don't have to be software, they could be fabricating an interesting device, piece of art, or music.)</li>\n</ul>\n<ul>\n<li>General Fund Raising Research. There are a lot of charities in the world. Presumably there are documented methods for growing them. A task force could attack this material and identify low hanging fruit or synthesize new techniques.</li>\n</ul>\n<div>I have more specific thoughts, but I want to chew on them a bit.</div>\n<div><br></div>\n</div>", "sections": [{"title": "Please refer to the updated documented here:\u00a0http://lesswrong.com/lw/5il/siai_an_examination/", "anchor": "Please_refer_to_the_updated_documented_here__http___lesswrong_com_lw_5il_siai_an_examination_", "level": 2}, {"title": "This version is an old draft.", "anchor": "This_version_is_an_old_draft_", "level": 2}, {"title": "Overview", "anchor": "Overview", "level": 1}, {"title": "Revenue", "anchor": "Revenue", "level": 1}, {"title": "Expenses", "anchor": "Expenses", "level": 1}, {"title": "Big Donors", "anchor": "Big_Donors", "level": 1}, {"title": "Officer Compensation", "anchor": "Officer_Compensation", "level": 1}, {"title": "Where to Start?", "anchor": "Where_to_Start_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "120 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 120, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["qqhdj3W3vSfB5E9ss", "5swa8chZCtWynuFga"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-26T10:53:19.858Z", "modifiedAt": null, "url": null, "title": "Nonmagical Powers", "slug": "nonmagical-powers", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:24.064Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Yt5m8LXCmGKwEt2GA/nonmagical-powers", "pageUrlRelative": "/posts/Yt5m8LXCmGKwEt2GA/nonmagical-powers", "linkUrl": "https://www.lesswrong.com/posts/Yt5m8LXCmGKwEt2GA/nonmagical-powers", "postedAtFormatted": "Tuesday, April 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Nonmagical%20Powers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANonmagical%20Powers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYt5m8LXCmGKwEt2GA%2Fnonmagical-powers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Nonmagical%20Powers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYt5m8LXCmGKwEt2GA%2Fnonmagical-powers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYt5m8LXCmGKwEt2GA%2Fnonmagical-powers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<p>A couple of years ago my workplace was running one of those guess-the-number-of-jellybeans-in-the-jar competitions. I don't even like jellybeans all that much, but nonetheless, I held aloft my nonmagic calculator and said \"by the power of Galton!\" Taking the mean of all the previous guesses, I put that down as my answer. I was out by one bean, and won the jar. I don't think my colleagues have ever been so interested in statistics as they were that afternoon, and I doubt they ever will be again.</p>\n<p>I'm going to admit something a bit silly and embarrassing now: that made me feel like a wizard. Not because of the scope of what I'd done, since it was an utterly trivial piece of arithmetic, but because of the reaction it got. I had drawn on arcane lore unknown to my colleagues, and used it to exercise power over the world.</p>\n<p>Personally, I think something like solid state semiconductor technology is about as impressive a real-world miracle as one could ever want by way of demonstrating the whole Science Works/Rationality Is Systematised Winning/Maths Has Manifold Real-World Applications thing, but for most people it will never have the impact of intentionally winning a jar full of jellybeans.</p>\n<p>So I ask you, LW-readership: what other impressive nonmagical powers do we have, that we can casually demonstrate to everyday people in everyday circumstances?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zv7v2ziqexSn5iS9v": 2, "bJBJLxha2xjL4yZte": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Yt5m8LXCmGKwEt2GA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 51, "extendedScore": null, "score": 0.0005743363696095945, "legacy": true, "legacyId": "7049", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 63, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-26T12:54:31.971Z", "modifiedAt": null, "url": null, "title": "What data generated that thought?", "slug": "what-data-generated-that-thought", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:38.904Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rKNuyxFK85yKtwP6G/what-data-generated-that-thought", "pageUrlRelative": "/posts/rKNuyxFK85yKtwP6G/what-data-generated-that-thought", "linkUrl": "https://www.lesswrong.com/posts/rKNuyxFK85yKtwP6G/what-data-generated-that-thought", "postedAtFormatted": "Tuesday, April 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20data%20generated%20that%20thought%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20data%20generated%20that%20thought%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKNuyxFK85yKtwP6G%2Fwhat-data-generated-that-thought%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20data%20generated%20that%20thought%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKNuyxFK85yKtwP6G%2Fwhat-data-generated-that-thought", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKNuyxFK85yKtwP6G%2Fwhat-data-generated-that-thought", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 600, "htmlBody": "<p>In <a href=\"http://www.amazon.com/Techniques-Selling-Writer-Dwight-Swain/dp/0806111917\">Techniques of the Selling Writer</a>, Dwight W. Swain gives advice on receiving advice:</p>\n<blockquote>\n<p>George Abercroft is an action writer. \"Start with a fight!\" is his motto. And for him, it works.</p>\n<p>But Fred Friggenheimer's witch-cult yarn, as he conceives it, puts heavy emphasis on atmosphere. The fight he tries to stick in like a clove in a ham at the beginning, following George's rule, destroys the mood - and the story.</p>\n<p>Even with your own rules, indeed, you must be careful. Because somehow, subtly, they may not apply to this explicit situation. [...]</p>\n<p>How do you tell whether a rule is good or not, in terms of a specific problem?</p>\n<p>Answer: Find out the reason the rule came into being. What idea or principle stands behind it? [...]</p>\n<p>Take George's rule about starting every story with a fight. It's born of George's markets - men's magazines in which the emphasis is on fast, violent action, with blood on page one an absolute must.</p>\n<p>If Fred only realized that fact, he'd ignore George's rule when he himself writes a mood-geared story.</p>\n</blockquote>\n<p>One way to reduce damage done by <a href=\"/lw/k5/cached_thoughts/\">cached thoughts</a> is to cultivate a habit of asking questions about the origin of the thought. Do you remember where you heard the thought? Did it come from someone practicing <a href=\"/lw/u/the_ethic_of_handwashing_and_community_epistemic/\">good epistemic hygiene</a>, or do they just unthinkingly pass on anything they hear? If somebody offered advice based on their own experiences, <a href=\"/lw/dr/generalizing_from_one_example/\">how representative is their experience</a>? What kinds of experiences have they had that prompted that advice? Are there alternative ways of interpreting those experiences? Or if you're the one offering advice, which you came up with yourself, what situation led you to come up with it? How generalizable is it?<a id=\"more\"></a></p>\n<p>So far I have mostly been framing this as a way to notice flaws in seemingly good advice. But there's also an opposite angle: finding gems in seemingly worthless information.</p>\n<p>All outcomes are correlated with causes; <a href=\"/lw/uw/entangled_truths_contagious_lies/\">most statements</a> are <a href=\"/lw/jl/what_is_evidence/\">evidence</a> of <em>something</em>. Michael Vassar once gave the example of a tribe of people who thought that faeries existed, lived in a nearby forest, and you could see them once you became old enough. It later turned out that the tribe had a hereditary eye disease which caused them to see things from the corners of their eyes once they got old. The tribe's theory of what was going on was wrong, but it was still based on some true data about the real world. A scientifically minded person could have figured out what was going on, by being sufficiently curious about the data that generated that belief.</p>\n<blockquote>\n<p>If you&rsquo;re interested in being on the right side of disputes, you will refute your opponents&rsquo; arguments. But if you&rsquo;re interested in producing truth, you will fix your opponents&rsquo; arguments for them. To win, you must fight not only the creature you encounter; you must fight the most horrible thing that can be constructed from its corpse. -- <a href=\"http://www.acceleratingfuture.com/steven/?p=155\">Black Belt Bayesian</a></p>\n</blockquote>\n<p>Some people tend to stop reading a text whenever they come across blatantly incorrect statements. I mind much less. Yes, the person may be generally mistaken, but they may still have some worthwhile points mixed in. <a href=\"/lw/4x8/folk_theories_can_be_useful_even_when_theyre/\">Folk theories can be useful, even when they're entirely wrong</a>. What you're reading is somebody's interpretation of an event, which provides information about the event even if the interpretation is wrong. Can you come up with a better interpretation?</p>\n<p>Maybe you disagree with something that I've said here? In that case, what data do you think generated this advice? What conclusions would you derive instead?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "ec2WRPdGJiWiYmece": 1, "5f5c37ee1b5cdee568cfb0d6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rKNuyxFK85yKtwP6G", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 42, "extendedScore": null, "score": 7.071148433267347e-07, "legacy": true, "legacyId": "7050", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2MD3NMLBPCqPfnfre", "ZP2om2oWHPhvWP2Q3", "baTWMegR42PAsH9qJ", "wyyfFfaRar2jEdeQK", "6s3xABaXKPdFwA3FS", "yB3ipMYY6kjrr9aR7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-26T19:01:29.850Z", "modifiedAt": null, "url": null, "title": "Xtranormal: Nano and AI Danger", "slug": "xtranormal-nano-and-ai-danger", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.849Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Be6bkRNrhKCR2kSd7/xtranormal-nano-and-ai-danger", "pageUrlRelative": "/posts/Be6bkRNrhKCR2kSd7/xtranormal-nano-and-ai-danger", "linkUrl": "https://www.lesswrong.com/posts/Be6bkRNrhKCR2kSd7/xtranormal-nano-and-ai-danger", "postedAtFormatted": "Tuesday, April 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Xtranormal%3A%20Nano%20and%20AI%20Danger&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AXtranormal%3A%20Nano%20and%20AI%20Danger%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBe6bkRNrhKCR2kSd7%2Fxtranormal-nano-and-ai-danger%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Xtranormal%3A%20Nano%20and%20AI%20Danger%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBe6bkRNrhKCR2kSd7%2Fxtranormal-nano-and-ai-danger", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBe6bkRNrhKCR2kSd7%2Fxtranormal-nano-and-ai-danger", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 12, "htmlBody": "<p><a href=\"http://www.xtranormal.com/watch/6893469/nano-and-ai-danger-bis\">Here</a>. One of those videos generated automatically from a text. <a href=\"/lw/31j/an_xtranormal_intelligence_explosion/\">Also see</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Be6bkRNrhKCR2kSd7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -2, "extendedScore": null, "score": 7.072194061907046e-07, "legacy": true, "legacyId": "7052", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LZnPCrmjTsYAaHpZk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-26T23:52:46.667Z", "modifiedAt": null, "url": null, "title": "Advice needed for Less Wrong Discussion Topic: Learning Mastery", "slug": "advice-needed-for-less-wrong-discussion-topic-learning", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:36.518Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bFLKJoc84yqzurjSw/advice-needed-for-less-wrong-discussion-topic-learning", "pageUrlRelative": "/posts/bFLKJoc84yqzurjSw/advice-needed-for-less-wrong-discussion-topic-learning", "linkUrl": "https://www.lesswrong.com/posts/bFLKJoc84yqzurjSw/advice-needed-for-less-wrong-discussion-topic-learning", "postedAtFormatted": "Tuesday, April 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Advice%20needed%20for%20Less%20Wrong%20Discussion%20Topic%3A%20Learning%20Mastery&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAdvice%20needed%20for%20Less%20Wrong%20Discussion%20Topic%3A%20Learning%20Mastery%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbFLKJoc84yqzurjSw%2Fadvice-needed-for-less-wrong-discussion-topic-learning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Advice%20needed%20for%20Less%20Wrong%20Discussion%20Topic%3A%20Learning%20Mastery%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbFLKJoc84yqzurjSw%2Fadvice-needed-for-less-wrong-discussion-topic-learning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbFLKJoc84yqzurjSw%2Fadvice-needed-for-less-wrong-discussion-topic-learning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<p>Hi everyone,</p>\n<p>I currently head up a Sydney Less Wrong Meetup, which is actually just me and a group of my friends trying to improve our own rationality.</p>\n<p>Several are uni students, so I was thinking of doing powerpoint and initiating some discussion on learning optimization, and exploring what helps us learn and absorb information, and see what devices we can find to help us maximize our learning capability.</p>\n<p>Anyone know any particuarly good articles/websites/concepts that would be good for the meetup?</p>\n<p>All advice is always appreciated.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bFLKJoc84yqzurjSw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.073023129887523e-07, "legacy": true, "legacyId": "7053", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T01:24:59.946Z", "modifiedAt": null, "url": null, "title": "DC Meetup: Sunday May 1st, 1 PM", "slug": "dc-meetup-sunday-may-1st-1-pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:47.126Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SRMkraaA2Gpbjdx5R/dc-meetup-sunday-may-1st-1-pm", "pageUrlRelative": "/posts/SRMkraaA2Gpbjdx5R/dc-meetup-sunday-may-1st-1-pm", "linkUrl": "https://www.lesswrong.com/posts/SRMkraaA2Gpbjdx5R/dc-meetup-sunday-may-1st-1-pm", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20DC%20Meetup%3A%20Sunday%20May%201st%2C%201%20PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADC%20Meetup%3A%20Sunday%20May%201st%2C%201%20PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSRMkraaA2Gpbjdx5R%2Fdc-meetup-sunday-may-1st-1-pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=DC%20Meetup%3A%20Sunday%20May%201st%2C%201%20PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSRMkraaA2Gpbjdx5R%2Fdc-meetup-sunday-may-1st-1-pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSRMkraaA2Gpbjdx5R%2Fdc-meetup-sunday-may-1st-1-pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 160, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><em>Sunday May 1st, 1 PM - 5 PM</em><br /> <em>Chipotle Mexican Grill</em><br /> <em>7600 Old Georgetown Road</em><br /> <em>Bethesda, MD 20814</em></p>\n<p>Hey DC LWers, its about time we started meeting up! (Lurkers welcome)</p>\n<p><strong>Goals:</strong><br /> Basically, get to know each other and establish a regularly meeting (and thoroughly awesome) meetup group. I have a few discussion topics in mind (basic logistics, what we'd like to improve/what our goals are, introductions, etc), but feel free to come with your own.</p>\n<p><strong>Directions:</strong><br /> The Chipotle is near the Bethesda Metro station, just follow <a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Old+Georgetown+Rd&amp;daddr=7600+Old+Georgetown+Rd,+Bethesda,+MD+20814&amp;hl=en&amp;geocode=FVXcUgId66Fn-w%3BFarfUgIdn5tn-ynZQi-7ZMm3iTG95vklOa-npw&amp;mra=me&amp;mrsp=0&amp;sz=18&amp;sll=38.985195,-77.0952&amp;sspn=0.002243,0.003449&amp;ie=UTF8&amp;t=h&amp;z=18\">these</a> directions. Go out of the station and walk down Old Georgetown Road. The Chipotle is next to the waterfall fountain, and outdoor seating area.<br /><br />We will be sitting towards the back of the restaurant (basically, keep going in the direction you've been walking to get to the Chipotle), hopefully in the corner with a wraparound bench. Look for the person with curly red hair, or the LW sign.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SRMkraaA2Gpbjdx5R", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 7.073285654232904e-07, "legacy": true, "legacyId": "7057", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T01:25:43.879Z", "modifiedAt": null, "url": null, "title": "IA first steps (Berkeley, CA) (dead)", "slug": "ia-first-steps-berkeley-ca-dead", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.599Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cayenne", "createdAt": "2010-12-27T22:47:02.994Z", "isAdmin": false, "displayName": "Cayenne"}, "userId": "xXoNkpxZ5i5TfDHK8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uL5qqYggYReDs6szX/ia-first-steps-berkeley-ca-dead", "pageUrlRelative": "/posts/uL5qqYggYReDs6szX/ia-first-steps-berkeley-ca-dead", "linkUrl": "https://www.lesswrong.com/posts/uL5qqYggYReDs6szX/ia-first-steps-berkeley-ca-dead", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20IA%20first%20steps%20(Berkeley%2C%20CA)%20(dead)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIA%20first%20steps%20(Berkeley%2C%20CA)%20(dead)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuL5qqYggYReDs6szX%2Fia-first-steps-berkeley-ca-dead%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=IA%20first%20steps%20(Berkeley%2C%20CA)%20(dead)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuL5qqYggYReDs6szX%2Fia-first-steps-berkeley-ca-dead", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuL5qqYggYReDs6szX%2Fia-first-steps-berkeley-ca-dead", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 135, "htmlBody": "<p>Apologies for wasting your time with this post. &nbsp;Please disregard it.</p>\n<p>&nbsp;</p>\n<p>My temporary plan is to meet together daily at one of the BART stops (Ashby or Berkeley, probably Ashby at first), choose a random set of directions, walk for 30-45 minutes, and then find a place to sit and chat for a while about other activities. &nbsp;Then walk back and split up. &nbsp;Total time may be 2-2.5 hours, 1-1.5 of it spent walking. &nbsp;I'm planning on doing this in the evening to avoid the midday heat, and to be done before it gets dark.</p>\n<p>Anyone that wishes can come along. &nbsp;If you would like to bring ideas for future format or training ideas, please do! &nbsp;Together we can come up with things that enhance us all.</p>\n<p>&nbsp;</p>\n<p>Edit - forgot to add location! &nbsp;Thanks for reminding me, Randaly.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uL5qqYggYReDs6szX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 3, "extendedScore": null, "score": 7.073287738592443e-07, "legacy": true, "legacyId": "7056", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T02:16:11.000Z", "modifiedAt": null, "url": null, "title": "Mapping our maps: types of knowledge", "slug": "mapping-our-maps-types-of-knowledge", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.167Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/98fJd55JCCZHauGaY/mapping-our-maps-types-of-knowledge", "pageUrlRelative": "/posts/98fJd55JCCZHauGaY/mapping-our-maps-types-of-knowledge", "linkUrl": "https://www.lesswrong.com/posts/98fJd55JCCZHauGaY/mapping-our-maps-types-of-knowledge", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mapping%20our%20maps%3A%20types%20of%20knowledge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMapping%20our%20maps%3A%20types%20of%20knowledge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98fJd55JCCZHauGaY%2Fmapping-our-maps-types-of-knowledge%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mapping%20our%20maps%3A%20types%20of%20knowledge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98fJd55JCCZHauGaY%2Fmapping-our-maps-types-of-knowledge", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98fJd55JCCZHauGaY%2Fmapping-our-maps-types-of-knowledge", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1878, "htmlBody": "<p><strong>Related to</strong>:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Map_and_territory\">Map and Territory</a>.</p>\n<p>This post is based on ideas that came to be during my second-year nursing Research Methods class. The fact that I did terribly in this class maybe indicates that I shouldn&rsquo;t be trying to explain it to anyone, but it also has a lot to do with the way I zoned out for most of every class, mulling over the material that would later become this post.</p>\n<p><strong>Types of map: the level of abstraction, or &lsquo;how many steps away from reality&rsquo;?</strong></p>\n<p>Probably in the third or fourth Research Methods class, we learned that any given research proposal could be divided into one of the following four categories:</p>\n<ul>\n<li>Descriptive</li>\n<li>Exploratory</li>\n<li>Explanatory</li>\n<li>Predictive</li>\n</ul>\n<p><a id=\"more\"></a></p>\n<p>I started wondering to what degree <em>knowledge in general</em> could be divided into these categories; whether a map can be, in different people&rsquo;s minds, descriptive or exploratory or explanatory or predictive depending on how well they understand the territory. Following this analogy, descriptive knowledge is a map one step, one level of abstraction, away from the territory. Every observation made is simply echoed in the model. From the Wikipedia page on&nbsp;<a href=\"http://en.wikipedia.org/wiki/Descriptive_research\">descriptive research</a>:</p>\n<blockquote>\n<p>Descriptive research, also known as statistical research, describes data and characteristics about the population or phenomenon being studied. Descriptive research answers the questions who, what, where, when and how... Although the data description is factual, accurate and systematic, the research cannot describe what caused a situation. Thus, descriptive research cannot be used to create a causal relationship, where one variable affects another. In other words, descriptive research can be said to have a low requirement for internal validity.</p>\n</blockquote>\n<p>A descriptive map draws no sweeping conclusions; it just copies data about the world. When I close my eyes and picture my kitchen, the model in my head is descriptive. It says nothing about why my kitchen looks a particular way, or what effects its particulars have in my daily life, or what the kitchens in other people&rsquo;s houses look like. Thinking about my kitchen, I might classify the information I know into chunks; I know that spoons, forks, and knives are all in my cutlery drawer, whereas the kettle, toaster, and microwave are all next to each other in a row on the counter. The system of binomial nomenclature created by Carl Linnaeus is a descriptive map; it doesn&rsquo;t suggest particular avenues of exploration, it doesn&rsquo;t explain the characteristics of the species described, and it doesn&rsquo;t predict anything about new species or unknown properties of existing species. It simply lays out the way things are, the current state of knowledge.</p>\n<p>From the Wikipedia page on&nbsp;<a href=\"http://en.wikipedia.org/wiki/Exploratory_research\">exploratory research</a>:</p>\n<blockquote>\n<p>Exploratory research is a type of research conducted for a problem that has not been clearly defined. Exploratory research helps determine the best research design, data collection method and selection of subjects. It should draw definitive conclusions only with extreme caution. Given its fundamental nature, exploratory research often concludes that a perceived problem does not actually exist.</p>\n</blockquote>\n<p>An exploratory model contains questions. Maybe, in the course of describing my kitchen to my mother, I realize I don&rsquo;t know where my eggbeater is. I&rsquo;ve come to realize that part of my mental map is blank, and when I get home I have a task to do; I&rsquo;m going to look through all of my cupboards and find that stupid eggbeater. Maybe it&rsquo;s in some drawer; maybe I lent it to a friend and forgot. I don&rsquo;t really have any idea, so I&rsquo;m not hazarding a prediction, but I know it&rsquo;s a question that needs answering.</p>\n<p>In qualitative research (the study of subjective phenomena which don&rsquo;t lend themselves to being measured numerically), this stage is called grounded theory; the data is collected before a theory is made. This contradicts the usual scientific method of making a theory and then testing it without modifying the theory to fit the results; however, it&rsquo;s the only method that makes sense when the data is insufficient to even hint at a possible theory. There&rsquo;s no point in theorizing about who stole my eggbeater when for all I know it&rsquo;s in the bottom drawer and there is no thievery involved at all. An exploratory model is two levels of abstraction away from the territory; it contains facts, and also questions about the facts. I would argue that having a lot of exploratory models pretty much defines what we call &ldquo;curiosity&rdquo;.</p>\n<p>Explanatory research is the next step, and so is an explanatory map. If I know that my toaster is next to my microwave and kettle because there is only one wall plug in the whole room, my map contains an explanation. Explanatory models are in some sense easier to learn than purely descriptive or exploratory; if I know about the cause-and-effect of the wall plug, I don&rsquo;t have to create a new node in my memory to remember where my appliances are. Knowing the location of the wall plug contains that information in itself. I could describe my kitchen to someone else and, assuming that they understand cause and effect as well as I do, convey just as much information in fewer words. From the&nbsp;<a href=\"http://www.blurtit.com/q415229.html\">blurtit</a>&nbsp;article on explanatory research (there is no Wikipedia article yet, sadly!):</p>\n<blockquote>\n<p>When we encounter an issue that is already known and have a description of it, we might begin to wonder why things are the way they are. The desire to know \"why,\" to explain, is the purpose of explanatory research... Explanatory research looks for causes and reasons. For example, a descriptive research may discover that 10 percent of the parents abuse their children, whereas the explanatory researcher is more interested in learning why parents abuse their children.</p>\n</blockquote>\n<p>Predictive research is the most advanced, and predictive models are the most useful. It&rsquo;s one thing to explain in hindsight that my kettle, microwave, and toaster are adjacent because of the wall plug; it would be more impressive if my friend, learning that there is only one plug and that I don&rsquo;t own an extension cord or PowerBar, says &ldquo;Wow! So your toaster and microwave and kettle must all be next to each other, then? That&rsquo;ll be nice and easy to find if I come to stay at your place!&rdquo; To give another example, if your mental map of, say, physics is sufficiently complete, you might do well on a test without studying at all. Even if it so happens that you&rsquo;ve never seen a particular kind of problem before, you should be able to answer it from first principles. The more abstract model, four steps away from the territory, contains the smaller, less abstract maps of individual problem types. For example, if a particular problem involved the five equations of kinematics, and you had never seen them before but understood all the concepts involved, with enough time you could derive the equations and solve the problem just as well as a student who simply memorized the formulas and did hundreds of practice questions in order to form a pattern-recognition schema for when to use which equation.</p>\n<p>In a certain sense, the different levels of map are like the shells of a Russian doll; for a given domain of knowledge, predictive contains explanatory, which contains exploratory, which contains descriptive. All four types of map can be incomplete, but you can never tell if a descriptive model is complete; there could always be one more fact to type into your giant look-up table, and how would you know? The useful thing about a predictive map is that its completeness can be measured by measuring the accuracy of its predictions, and by studying the internal consistency (though an internally consistent map might not be the right map for a given territory).</p>\n<p><a href=\"http://tinypic.com?ref=292v22p\" target=\"_blank\"><img src=\"http://i55.tinypic.com/292v22p.jpg\" border=\"0\" alt=\"Image and video hosting by TinyPic\" /></a></p>\n<p>Descriptive maps are useful, of course. (&ldquo;Really? That kind of flower is called a chrysanthemum? I never knew that! Now I know what kind of seeds to ask for at the store!&rdquo;) Exploratory maps lead to curiosity. (&ldquo;It doesn&rsquo;t say on the package how long a chrysanthemum needs to sprout. Maybe I should Google it, or call my aunt, I remember seeing them in her garden.&rdquo;) Explanatory maps bring that click of understanding, the aha feeling that something is completely obvious, and predictive maps take that flash of understanding and add a dollop of real-world practicality.</p>\n<p>What category do your maps belong to?</p>\n<p><strong>Types of territory: levels of reductionism, or &lsquo;what is your map of?&rsquo;</strong></p>\n<p>Some systems lend themselves more easily to being mapped on a predictive level than others. I&rsquo;m tempted to call this quality the&nbsp;<em>determinism</em>&nbsp;of a given domain, but technically speaking the entire universe runs on the same substrate, and it&rsquo;s either deterministic or it isn&rsquo;t. Volatile markets aren't any less deterministic than the earth's orbit around the sun; they just have more moving parts, namely the brains of every human who participates in trade. Some of this complexity is predictable enough on a large scale that it can be modelled with simple equations, but not all of it.</p>\n<p>The equations for microeconomics and the equations of general relativity both accept data as input and produce predictions as output, but they aren&rsquo;t the same kind of map. What is the difference? I would argue that general relativity is significantly more<em>reductionist</em>&nbsp;than microeconomics. It&nbsp;<a href=\"/lw/o0/where_to_draw_the_boundary/\">carves reality at its joints</a>&nbsp;and tries to measure the most fundamental qualities, and by doing so has a much broader scope. General relativity is true for every mass in the universe. Microeconomics is useful on Earth (one planet orbiting one star among all the galaxies), within the timespan that humans have existed, within the historical period that markets have existed, and when there is enough stability to justify its simplifying assumptions. It can be very useful in its scope, far more so than a merely descriptive model of which companies are doing well and would be good picks for investment. Predicting the market by discovering the ultimate laws of physics, programming them into a supercomputer, inputting the current state of the universe, and running the simulation wouldn&rsquo;t be exactly cost-effective or worth the benefits gained.</p>\n<p><a href=\"http://tinypic.com?ref=300ec5e\" target=\"_blank\"><img src=\"http://i54.tinypic.com/300ec5e.jpg\" border=\"0\" alt=\"Image and video hosting by TinyPic\" /></a>&nbsp;</p>\n<p>&nbsp;</p>\n<p>The diagram shows a spectrum of different maps on two axes, level of reductionism and level of abstraction. General relativity is assumed to be a map in Einstein&rsquo;s head; my own map of it is explanatory at best, and thus not as high in the vertical dimension. For the periodic table example, I refer to the way I understood it in seventh grade; it was presented simply as a classification, a look-up table for answering problems like &lsquo;is potassium a metal or a non-metal?&rsquo; The map for &lsquo;periodic table&rsquo; in my head now is at most explanatory, though during my high school chemistry years it was predictive to a degree; I knew the equations that governed, for example acid-base reactions, and I could give numerical answers. Grocery lists are the ultimate in primitive maps, neither carving reality at its joints nor inviting curiosity, explanation or prediction.</p>\n<p>Where do your maps fit on this graphic?</p>\n<p><strong>Connectivity</strong></p>\n<p>No matter how non-reductionist a theory becomes, how specific it is, it is presumably about phenomena in our universe. I can&rsquo;t predict microeconomics from the True Theory of physics, not without a supercomputer that runs faster than the universe itself, but I can connect it, chemistry to evolution to neuroscience and evo-psych. My maps aren&rsquo;t very connected. How connected are yours?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "98fJd55JCCZHauGaY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "7061", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Related to</strong>:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Map_and_territory\">Map and Territory</a>.</p>\n<p>This post is based on ideas that came to be during my second-year nursing Research Methods class. The fact that I did terribly in this class maybe indicates that I shouldn\u2019t be trying to explain it to anyone, but it also has a lot to do with the way I zoned out for most of every class, mulling over the material that would later become this post.</p>\n<p><strong id=\"Types_of_map__the_level_of_abstraction__or__how_many_steps_away_from_reality__\">Types of map: the level of abstraction, or \u2018how many steps away from reality\u2019?</strong></p>\n<p>Probably in the third or fourth Research Methods class, we learned that any given research proposal could be divided into one of the following four categories:</p>\n<ul>\n<li>Descriptive</li>\n<li>Exploratory</li>\n<li>Explanatory</li>\n<li>Predictive</li>\n</ul>\n<p><a id=\"more\"></a></p>\n<p>I started wondering to what degree <em>knowledge in general</em> could be divided into these categories; whether a map can be, in different people\u2019s minds, descriptive or exploratory or explanatory or predictive depending on how well they understand the territory. Following this analogy, descriptive knowledge is a map one step, one level of abstraction, away from the territory. Every observation made is simply echoed in the model. From the Wikipedia page on&nbsp;<a href=\"http://en.wikipedia.org/wiki/Descriptive_research\">descriptive research</a>:</p>\n<blockquote>\n<p>Descriptive research, also known as statistical research, describes data and characteristics about the population or phenomenon being studied. Descriptive research answers the questions who, what, where, when and how... Although the data description is factual, accurate and systematic, the research cannot describe what caused a situation. Thus, descriptive research cannot be used to create a causal relationship, where one variable affects another. In other words, descriptive research can be said to have a low requirement for internal validity.</p>\n</blockquote>\n<p>A descriptive map draws no sweeping conclusions; it just copies data about the world. When I close my eyes and picture my kitchen, the model in my head is descriptive. It says nothing about why my kitchen looks a particular way, or what effects its particulars have in my daily life, or what the kitchens in other people\u2019s houses look like. Thinking about my kitchen, I might classify the information I know into chunks; I know that spoons, forks, and knives are all in my cutlery drawer, whereas the kettle, toaster, and microwave are all next to each other in a row on the counter. The system of binomial nomenclature created by Carl Linnaeus is a descriptive map; it doesn\u2019t suggest particular avenues of exploration, it doesn\u2019t explain the characteristics of the species described, and it doesn\u2019t predict anything about new species or unknown properties of existing species. It simply lays out the way things are, the current state of knowledge.</p>\n<p>From the Wikipedia page on&nbsp;<a href=\"http://en.wikipedia.org/wiki/Exploratory_research\">exploratory research</a>:</p>\n<blockquote>\n<p>Exploratory research is a type of research conducted for a problem that has not been clearly defined. Exploratory research helps determine the best research design, data collection method and selection of subjects. It should draw definitive conclusions only with extreme caution. Given its fundamental nature, exploratory research often concludes that a perceived problem does not actually exist.</p>\n</blockquote>\n<p>An exploratory model contains questions. Maybe, in the course of describing my kitchen to my mother, I realize I don\u2019t know where my eggbeater is. I\u2019ve come to realize that part of my mental map is blank, and when I get home I have a task to do; I\u2019m going to look through all of my cupboards and find that stupid eggbeater. Maybe it\u2019s in some drawer; maybe I lent it to a friend and forgot. I don\u2019t really have any idea, so I\u2019m not hazarding a prediction, but I know it\u2019s a question that needs answering.</p>\n<p>In qualitative research (the study of subjective phenomena which don\u2019t lend themselves to being measured numerically), this stage is called grounded theory; the data is collected before a theory is made. This contradicts the usual scientific method of making a theory and then testing it without modifying the theory to fit the results; however, it\u2019s the only method that makes sense when the data is insufficient to even hint at a possible theory. There\u2019s no point in theorizing about who stole my eggbeater when for all I know it\u2019s in the bottom drawer and there is no thievery involved at all. An exploratory model is two levels of abstraction away from the territory; it contains facts, and also questions about the facts. I would argue that having a lot of exploratory models pretty much defines what we call \u201ccuriosity\u201d.</p>\n<p>Explanatory research is the next step, and so is an explanatory map. If I know that my toaster is next to my microwave and kettle because there is only one wall plug in the whole room, my map contains an explanation. Explanatory models are in some sense easier to learn than purely descriptive or exploratory; if I know about the cause-and-effect of the wall plug, I don\u2019t have to create a new node in my memory to remember where my appliances are. Knowing the location of the wall plug contains that information in itself. I could describe my kitchen to someone else and, assuming that they understand cause and effect as well as I do, convey just as much information in fewer words. From the&nbsp;<a href=\"http://www.blurtit.com/q415229.html\">blurtit</a>&nbsp;article on explanatory research (there is no Wikipedia article yet, sadly!):</p>\n<blockquote>\n<p>When we encounter an issue that is already known and have a description of it, we might begin to wonder why things are the way they are. The desire to know \"why,\" to explain, is the purpose of explanatory research... Explanatory research looks for causes and reasons. For example, a descriptive research may discover that 10 percent of the parents abuse their children, whereas the explanatory researcher is more interested in learning why parents abuse their children.</p>\n</blockquote>\n<p>Predictive research is the most advanced, and predictive models are the most useful. It\u2019s one thing to explain in hindsight that my kettle, microwave, and toaster are adjacent because of the wall plug; it would be more impressive if my friend, learning that there is only one plug and that I don\u2019t own an extension cord or PowerBar, says \u201cWow! So your toaster and microwave and kettle must all be next to each other, then? That\u2019ll be nice and easy to find if I come to stay at your place!\u201d To give another example, if your mental map of, say, physics is sufficiently complete, you might do well on a test without studying at all. Even if it so happens that you\u2019ve never seen a particular kind of problem before, you should be able to answer it from first principles. The more abstract model, four steps away from the territory, contains the smaller, less abstract maps of individual problem types. For example, if a particular problem involved the five equations of kinematics, and you had never seen them before but understood all the concepts involved, with enough time you could derive the equations and solve the problem just as well as a student who simply memorized the formulas and did hundreds of practice questions in order to form a pattern-recognition schema for when to use which equation.</p>\n<p>In a certain sense, the different levels of map are like the shells of a Russian doll; for a given domain of knowledge, predictive contains explanatory, which contains exploratory, which contains descriptive. All four types of map can be incomplete, but you can never tell if a descriptive model is complete; there could always be one more fact to type into your giant look-up table, and how would you know? The useful thing about a predictive map is that its completeness can be measured by measuring the accuracy of its predictions, and by studying the internal consistency (though an internally consistent map might not be the right map for a given territory).</p>\n<p><a href=\"http://tinypic.com?ref=292v22p\" target=\"_blank\"><img src=\"http://i55.tinypic.com/292v22p.jpg\" border=\"0\" alt=\"Image and video hosting by TinyPic\"></a></p>\n<p>Descriptive maps are useful, of course. (\u201cReally? That kind of flower is called a chrysanthemum? I never knew that! Now I know what kind of seeds to ask for at the store!\u201d) Exploratory maps lead to curiosity. (\u201cIt doesn\u2019t say on the package how long a chrysanthemum needs to sprout. Maybe I should Google it, or call my aunt, I remember seeing them in her garden.\u201d) Explanatory maps bring that click of understanding, the aha feeling that something is completely obvious, and predictive maps take that flash of understanding and add a dollop of real-world practicality.</p>\n<p>What category do your maps belong to?</p>\n<p><strong id=\"Types_of_territory__levels_of_reductionism__or__what_is_your_map_of__\">Types of territory: levels of reductionism, or \u2018what is your map of?\u2019</strong></p>\n<p>Some systems lend themselves more easily to being mapped on a predictive level than others. I\u2019m tempted to call this quality the&nbsp;<em>determinism</em>&nbsp;of a given domain, but technically speaking the entire universe runs on the same substrate, and it\u2019s either deterministic or it isn\u2019t. Volatile markets aren't any less deterministic than the earth's orbit around the sun; they just have more moving parts, namely the brains of every human who participates in trade. Some of this complexity is predictable enough on a large scale that it can be modelled with simple equations, but not all of it.</p>\n<p>The equations for microeconomics and the equations of general relativity both accept data as input and produce predictions as output, but they aren\u2019t the same kind of map. What is the difference? I would argue that general relativity is significantly more<em>reductionist</em>&nbsp;than microeconomics. It&nbsp;<a href=\"/lw/o0/where_to_draw_the_boundary/\">carves reality at its joints</a>&nbsp;and tries to measure the most fundamental qualities, and by doing so has a much broader scope. General relativity is true for every mass in the universe. Microeconomics is useful on Earth (one planet orbiting one star among all the galaxies), within the timespan that humans have existed, within the historical period that markets have existed, and when there is enough stability to justify its simplifying assumptions. It can be very useful in its scope, far more so than a merely descriptive model of which companies are doing well and would be good picks for investment. Predicting the market by discovering the ultimate laws of physics, programming them into a supercomputer, inputting the current state of the universe, and running the simulation wouldn\u2019t be exactly cost-effective or worth the benefits gained.</p>\n<p><a href=\"http://tinypic.com?ref=300ec5e\" target=\"_blank\"><img src=\"http://i54.tinypic.com/300ec5e.jpg\" border=\"0\" alt=\"Image and video hosting by TinyPic\"></a>&nbsp;</p>\n<p>&nbsp;</p>\n<p>The diagram shows a spectrum of different maps on two axes, level of reductionism and level of abstraction. General relativity is assumed to be a map in Einstein\u2019s head; my own map of it is explanatory at best, and thus not as high in the vertical dimension. For the periodic table example, I refer to the way I understood it in seventh grade; it was presented simply as a classification, a look-up table for answering problems like \u2018is potassium a metal or a non-metal?\u2019 The map for \u2018periodic table\u2019 in my head now is at most explanatory, though during my high school chemistry years it was predictive to a degree; I knew the equations that governed, for example acid-base reactions, and I could give numerical answers. Grocery lists are the ultimate in primitive maps, neither carving reality at its joints nor inviting curiosity, explanation or prediction.</p>\n<p>Where do your maps fit on this graphic?</p>\n<p><strong id=\"Connectivity\">Connectivity</strong></p>\n<p>No matter how non-reductionist a theory becomes, how specific it is, it is presumably about phenomena in our universe. I can\u2019t predict microeconomics from the True Theory of physics, not without a supercomputer that runs faster than the universe itself, but I can connect it, chemistry to evolution to neuroscience and evo-psych. My maps aren\u2019t very connected. How connected are yours?</p>", "sections": [{"title": "Types of map: the level of abstraction, or \u2018how many steps away from reality\u2019?", "anchor": "Types_of_map__the_level_of_abstraction__or__how_many_steps_away_from_reality__", "level": 1}, {"title": "Types of territory: levels of reductionism, or \u2018what is your map of?\u2019", "anchor": "Types_of_territory__levels_of_reductionism__or__what_is_your_map_of__", "level": 1}, {"title": "Connectivity", "anchor": "Connectivity", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "13 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d5NyJ2Lf6N22AD9PB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T03:06:13.819Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Some Claims Are Just Too Extraordinary", "slug": "seq-rerun-some-claims-are-just-too-extraordinary", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:25.852Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jake987722", "createdAt": "2009-11-15T04:00:32.147Z", "isAdmin": false, "displayName": "jake987722"}, "userId": "z2eomSrHzecedEdNt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/khSZgFcEM6Hg3KCDv/seq-rerun-some-claims-are-just-too-extraordinary", "pageUrlRelative": "/posts/khSZgFcEM6Hg3KCDv/seq-rerun-some-claims-are-just-too-extraordinary", "linkUrl": "https://www.lesswrong.com/posts/khSZgFcEM6Hg3KCDv/seq-rerun-some-claims-are-just-too-extraordinary", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Some%20Claims%20Are%20Just%20Too%20Extraordinary&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Some%20Claims%20Are%20Just%20Too%20Extraordinary%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkhSZgFcEM6Hg3KCDv%2Fseq-rerun-some-claims-are-just-too-extraordinary%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Some%20Claims%20Are%20Just%20Too%20Extraordinary%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkhSZgFcEM6Hg3KCDv%2Fseq-rerun-some-claims-are-just-too-extraordinary", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkhSZgFcEM6Hg3KCDv%2Fseq-rerun-some-claims-are-just-too-extraordinary", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p>Today's post, <a href=\"/lw/gu/some_claims_are_just_too_extraordinary/\">Some Claims Are Just Too Extraordinary</a> was originally published on 20 January 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Publications in peer-reviewed scientific journals are more worthy of trust than what you detect with your own ears and eyes.</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/r/discussion/lw/5fj/seq_rerun_a_fable_of_science_and_politics/\">A Fable of Science and Politics</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em> </em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "khSZgFcEM6Hg3KCDv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 7.073573845861436e-07, "legacy": true, "legacyId": "7065", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fXbRhjz3yEF9DLJfE", "DsxmA3S6CfXrgj4MY", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T04:25:05.478Z", "modifiedAt": null, "url": null, "title": "Explanation found for the Pioneer anomaly ", "slug": "explanation-found-for-the-pioneer-anomaly", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.686Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "arundelo", "createdAt": "2009-03-01T18:19:40.865Z", "isAdmin": false, "displayName": "arundelo"}, "userId": "nC4NpcrnXPWe4P3td", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bm6fm3mP2Ez73k89Z/explanation-found-for-the-pioneer-anomaly", "pageUrlRelative": "/posts/bm6fm3mP2Ez73k89Z/explanation-found-for-the-pioneer-anomaly", "linkUrl": "https://www.lesswrong.com/posts/bm6fm3mP2Ez73k89Z/explanation-found-for-the-pioneer-anomaly", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Explanation%20found%20for%20the%20Pioneer%20anomaly%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExplanation%20found%20for%20the%20Pioneer%20anomaly%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbm6fm3mP2Ez73k89Z%2Fexplanation-found-for-the-pioneer-anomaly%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Explanation%20found%20for%20the%20Pioneer%20anomaly%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbm6fm3mP2Ez73k89Z%2Fexplanation-found-for-the-pioneer-anomaly", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbm6fm3mP2Ez73k89Z%2Fexplanation-found-for-the-pioneer-anomaly", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 157, "htmlBody": "<p><a href=\"http://arxiv.org/abs/1103.5222\">Paper here</a>. <a href=\"http://www.technologyreview.com/blog/arxiv/26589/\">Lay summary here</a>. Some bits from the latter:</p>\n<blockquote>\n<p>The problem is this. The Pioneer 10 and 11 spacecraft were launched towards Jupiter and Saturn in the early 1970s. After their respective flybys, they continued on escape trajectories out of the Solar System, both decelerating under the force of the Sun's gravity. But careful measuremenrs show that the spacecraft are slowing faster than they ought to, as if being pulled by an extra unseen force towards the Sun.</p>\n</blockquote>\n<blockquote>\n<p>Spacecraft engineers' first thought was that heat emitted by the spacecraft could cause exactly this kind of deceleration. But when they examined the way heat was produced on the craft, by on board plutonium, and how this must have been emitted, they were unable to make the numbers add up.</p>\n</blockquote>\n<blockquote>\n<p>Now Frederico Francisco at the Instituto de Plasmas e Fusao Nuclear in Lisbon Portugal, and a few pals, say they've worked out where the thermal calculations went wrong.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bm6fm3mP2Ez73k89Z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 14, "extendedScore": null, "score": 7.073798367491208e-07, "legacy": true, "legacyId": "7067", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T08:46:16.731Z", "modifiedAt": null, "url": null, "title": "Is there an optimal function for belief calibration over time?", "slug": "is-there-an-optimal-function-for-belief-calibration-over", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.458Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YoWCGyC3Zay4HrxgM/is-there-an-optimal-function-for-belief-calibration-over", "pageUrlRelative": "/posts/YoWCGyC3Zay4HrxgM/is-there-an-optimal-function-for-belief-calibration-over", "linkUrl": "https://www.lesswrong.com/posts/YoWCGyC3Zay4HrxgM/is-there-an-optimal-function-for-belief-calibration-over", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20there%20an%20optimal%20function%20for%20belief%20calibration%20over%20time%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20there%20an%20optimal%20function%20for%20belief%20calibration%20over%20time%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYoWCGyC3Zay4HrxgM%2Fis-there-an-optimal-function-for-belief-calibration-over%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20there%20an%20optimal%20function%20for%20belief%20calibration%20over%20time%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYoWCGyC3Zay4HrxgM%2Fis-there-an-optimal-function-for-belief-calibration-over", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYoWCGyC3Zay4HrxgM%2Fis-there-an-optimal-function-for-belief-calibration-over", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<p>You can, say, measure a belief on a scale from -1 to 1, where 0 is correct belief.</p>\n<p>Then you could try calibrating the belief. Thing is, that sometimes you can calibrate it by monotonically decreasing it. Or you could monotonically decrease the absolute value of it. Or you could even make the calibration function oscillate between -1 and 1. Sometimes, more incorrect beliefs might even be desirable, since they may give you additional information about the landscape (this is where you can have a case where D1(t) &gt; D2(t) and D1(t+1) &lt; D2(t+1) ).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YoWCGyC3Zay4HrxgM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -6, "extendedScore": null, "score": 7.0745420730755e-07, "legacy": true, "legacyId": "7070", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T13:59:32.012Z", "modifiedAt": null, "url": null, "title": "Entropy and social groups", "slug": "entropy-and-social-groups", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:17.133Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nTkaBxKty8MPAjoCJ/entropy-and-social-groups", "pageUrlRelative": "/posts/nTkaBxKty8MPAjoCJ/entropy-and-social-groups", "linkUrl": "https://www.lesswrong.com/posts/nTkaBxKty8MPAjoCJ/entropy-and-social-groups", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Entropy%20and%20social%20groups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEntropy%20and%20social%20groups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnTkaBxKty8MPAjoCJ%2Fentropy-and-social-groups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Entropy%20and%20social%20groups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnTkaBxKty8MPAjoCJ%2Fentropy-and-social-groups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnTkaBxKty8MPAjoCJ%2Fentropy-and-social-groups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 235, "htmlBody": "<p>I suggest that there are default patterns for social groups, and they could be viewed as high entropy-- what you'd expect without knowing more than that there was a social group of a certain size, possibly with some modifications for tech level and status.</p>\n<p>For example, I think that authoritarianism is the default for government-- \"we're in charge because we're in charge, and it would be dangerous for anyone who tries to change that\". Totalitarianism is lower entropy-- it's surprising for the people in charge to have an ideology which requires them to make drastic changes.</p>\n<p>The recent <a href=\"/r/discussion/lw/5f7/elitist_jerks_a_wellkept_garden/\">Elitist Jerks: A Well-kept Garden</a> describes an effort to fight one sort of entropy (the repetition of the same questions and answers) which resulted in another sort of entropy (an excessively stable and eventually fragile core group).</p>\n<p><a href=\"/lw/5c0/epistle_to_the_new_york_less_wrongians\">Maintaining fun</a> is another challenge in the keeping things alive category. Pleasant is relatively easy. Fun (which I'd say requires novelty) is harder, and I'm interested in comments on what it takes to keep the fun going.</p>\n<p>There's a theory that life exists as chaos on the border between order and randomness-- I find this plausible, and it's a different angle for looking at the Friendliness problem. How can a system be built which continues to permit (or even encourage) interesting sorts of change, without permitting change so drastic that we as we are now wouldn't recognize the outcome as still related to us?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nTkaBxKty8MPAjoCJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 8, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "7072", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TjWSLrZcvrGio6iyp", "jP583FwKepjiWbeoQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T16:41:02.296Z", "modifiedAt": null, "url": null, "title": "Avoiding Factual Muggings", "slug": "avoiding-factual-muggings", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.482Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KenChen", "createdAt": "2011-02-16T18:02:23.420Z", "isAdmin": false, "displayName": "KenChen"}, "userId": "Tay9Y5o7ehACBHeqc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8vEmWQK3MHmy8iiLF/avoiding-factual-muggings", "pageUrlRelative": "/posts/8vEmWQK3MHmy8iiLF/avoiding-factual-muggings", "linkUrl": "https://www.lesswrong.com/posts/8vEmWQK3MHmy8iiLF/avoiding-factual-muggings", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Avoiding%20Factual%20Muggings&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAvoiding%20Factual%20Muggings%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8vEmWQK3MHmy8iiLF%2Favoiding-factual-muggings%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Avoiding%20Factual%20Muggings%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8vEmWQK3MHmy8iiLF%2Favoiding-factual-muggings", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8vEmWQK3MHmy8iiLF%2Favoiding-factual-muggings", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 188, "htmlBody": "<p>When people talk about self-defense, they tend to concentrate on how to physically defend yourself. But the best way to avoid getting hurt is to avoid being attacked in the first place. Here are some suggestions:</p>\n<ul>\n<li>Appear to be alert -- don't listen to music, don't use your phone, and keep moving. If you go so far as to run or jog to your destination, you will be a very unappealing target.</li>\n<li>Stay in well-lit areas at night. In a place with low traffic, it may be better to walk in the middle of the road.</li>\n<li>Appear to be armed. Concealed weapons don't help -- they are only useful once you have already been selected as a target. Visible and obvious weapons such as guns and knives are usually too much trouble to be worth it. Ordinary objects that can be used as weapons, such as baseball bats and hammers may be best, as they act a deterrent without the hassle that traditional weapons bring.</li>\n</ul>\n<p>What are some other easy measures that people can take to make themselves less of a likely target?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8vEmWQK3MHmy8iiLF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 3, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "7073", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T18:19:51.186Z", "modifiedAt": null, "url": null, "title": "What would you do with a solution to 3-SAT?", "slug": "what-would-you-do-with-a-solution-to-3-sat", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:47.203Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qz6Q2sRfj3ruYdsS9/what-would-you-do-with-a-solution-to-3-sat", "pageUrlRelative": "/posts/qz6Q2sRfj3ruYdsS9/what-would-you-do-with-a-solution-to-3-sat", "linkUrl": "https://www.lesswrong.com/posts/qz6Q2sRfj3ruYdsS9/what-would-you-do-with-a-solution-to-3-sat", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20would%20you%20do%20with%20a%20solution%20to%203-SAT%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20would%20you%20do%20with%20a%20solution%20to%203-SAT%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqz6Q2sRfj3ruYdsS9%2Fwhat-would-you-do-with-a-solution-to-3-sat%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20would%20you%20do%20with%20a%20solution%20to%203-SAT%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqz6Q2sRfj3ruYdsS9%2Fwhat-would-you-do-with-a-solution-to-3-sat", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqz6Q2sRfj3ruYdsS9%2Fwhat-would-you-do-with-a-solution-to-3-sat", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<p>Many experts suspect that there is no polynomial-time solution to the so-called NP-complete problems, though no-one has yet been able to rigorously prove this and there remains the possibility that a polynomial-time algorithm will one day emerge. However unlikely this is, today I would like to invite LW to play a game I played with with some colleagues called what-would-you-do-with-a-polynomial-time-solution-to-3SAT? 3SAT&nbsp;is, of course, one of the most famous of the NP-complete problems&nbsp;and a solution to 3SAT would also constitute a solution to *all* the problems in NP. This includes lots of fun planning problems (e.g. travelling salesman) as well as the problem of performing exact inference in (general) Bayesian networks. What's the most fun you could have?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qz6Q2sRfj3ruYdsS9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 4, "extendedScore": null, "score": 7.076172927739244e-07, "legacy": true, "legacyId": "7075", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 80, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T19:01:24.288Z", "modifiedAt": null, "url": null, "title": "96 Bad Links in the Sequences [fixed]", "slug": "96-bad-links-in-the-sequences-fixed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:00.828Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Louie", "createdAt": "2010-05-10T21:41:14.619Z", "isAdmin": false, "displayName": "Louie"}, "userId": "JPwZspDjBcfwwuy7W", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pxAyccJoFqGakWM6e/96-bad-links-in-the-sequences-fixed", "pageUrlRelative": "/posts/pxAyccJoFqGakWM6e/96-bad-links-in-the-sequences-fixed", "linkUrl": "https://www.lesswrong.com/posts/pxAyccJoFqGakWM6e/96-bad-links-in-the-sequences-fixed", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%2096%20Bad%20Links%20in%20the%20Sequences%20%5Bfixed%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A96%20Bad%20Links%20in%20the%20Sequences%20%5Bfixed%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpxAyccJoFqGakWM6e%2F96-bad-links-in-the-sequences-fixed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=96%20Bad%20Links%20in%20the%20Sequences%20%5Bfixed%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpxAyccJoFqGakWM6e%2F96-bad-links-in-the-sequences-fixed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpxAyccJoFqGakWM6e%2F96-bad-links-in-the-sequences-fixed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 28, "htmlBody": "<p><strong>Follow-up to:</strong> <a href=\"/lw/555/96_bad_links_in_the_sequences/\">96 Bad Links in the Sequences</a></p>\n<p>&nbsp;</p>\n<p>Just to let everyone know:</p>\n<p>I followed up on <a href=\"/lw/555/96_bad_links_in_the_sequences/3wsj\">my promise</a> to fix all the broken links Alexandros found in the Sequences.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pxAyccJoFqGakWM6e", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 82, "baseScore": 97, "extendedScore": null, "score": 0.000183, "legacy": true, "legacyId": "7076", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-05-11T18:21:44.332Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": true, "hideFrontpageComments": false, "maxBaseScore": 97, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5wLDhMCn2p3mMnC6g"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-27T23:59:54.062Z", "modifiedAt": null, "url": null, "title": "Melbourne Meetup: Friday 6th May, 6pm", "slug": "melbourne-meetup-friday-6th-may-6pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.124Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iFNwmX5mBYQaXk7X7/melbourne-meetup-friday-6th-may-6pm", "pageUrlRelative": "/posts/iFNwmX5mBYQaXk7X7/melbourne-meetup-friday-6th-may-6pm", "linkUrl": "https://www.lesswrong.com/posts/iFNwmX5mBYQaXk7X7/melbourne-meetup-friday-6th-may-6pm", "postedAtFormatted": "Wednesday, April 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Melbourne%20Meetup%3A%20Friday%206th%20May%2C%206pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMelbourne%20Meetup%3A%20Friday%206th%20May%2C%206pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiFNwmX5mBYQaXk7X7%2Fmelbourne-meetup-friday-6th-may-6pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Melbourne%20Meetup%3A%20Friday%206th%20May%2C%206pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiFNwmX5mBYQaXk7X7%2Fmelbourne-meetup-friday-6th-may-6pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiFNwmX5mBYQaXk7X7%2Fmelbourne-meetup-friday-6th-may-6pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 100, "htmlBody": "<p><a id=\"more\"></a> <strong>When:</strong> Friday 6th May, 18:00<br /><strong>Where:</strong> TrikeApps office, lvl 2, 55 Walsh St, West Melbourne 3003 (http://trikeapps.com/contact)</p>\n<p><strong>Directions:</strong><br />Enter the somewhat unfriendly&nbsp;building, climb the stairs to the top (2 floors), and turn left.<br />No wheelchair access (sorry - if you need help there and dignity and safety are not important to you I'm sure we can help you get to the top; if they are important then please speak up - we can at least move the next one to a more accessible venue).</p>\n<p><strong>Discussion:</strong></p>\n<ul>\n<li>\n<p style=\"display: inline !important;\"><a href=\"http://groups.google.com/group/melbourne-less-wrong\">http://groups.google.com/group/melbourne-less-wrong</a>&nbsp;(join to see this list)</p>\n</li>\n<li>\n<p style=\"display: inline !important;\"><a href=\"http://www.google.com/moderator/#16/e=6a317\">http://www.google.com/moderator/#16/e=6a317</a></p>\n</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iFNwmX5mBYQaXk7X7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 7.077144610984483e-07, "legacy": true, "legacyId": "7077", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T01:31:29.739Z", "modifiedAt": null, "url": null, "title": "Less Wrong Meetup section", "slug": "less-wrong-meetup-section", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.381Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rfEfNMTs3siA5wjKd/less-wrong-meetup-section", "pageUrlRelative": "/posts/rfEfNMTs3siA5wjKd/less-wrong-meetup-section", "linkUrl": "https://www.lesswrong.com/posts/rfEfNMTs3siA5wjKd/less-wrong-meetup-section", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20Meetup%20section&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20Meetup%20section%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrfEfNMTs3siA5wjKd%2Fless-wrong-meetup-section%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20Meetup%20section%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrfEfNMTs3siA5wjKd%2Fless-wrong-meetup-section", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrfEfNMTs3siA5wjKd%2Fless-wrong-meetup-section", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>Is there any reason this doesn't exist yet?</p>\r\n<p>Just wondering. Wasn't sure where else to ask. Would be great if we could get a part of the website dedicated to this.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rfEfNMTs3siA5wjKd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 7.077405620081989e-07, "legacy": true, "legacyId": "7078", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T03:30:17.047Z", "modifiedAt": null, "url": null, "title": "First Triangle LW Meetup 5/4 7pm (Raleigh/Durham/Chapel Hill) [Repost]", "slug": "first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:50.026Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bAgaqjj23QcTW6bfo/first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill", "pageUrlRelative": "/posts/bAgaqjj23QcTW6bfo/first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill", "linkUrl": "https://www.lesswrong.com/posts/bAgaqjj23QcTW6bfo/first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20First%20Triangle%20LW%20Meetup%205%2F4%207pm%20(Raleigh%2FDurham%2FChapel%20Hill)%20%5BRepost%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFirst%20Triangle%20LW%20Meetup%205%2F4%207pm%20(Raleigh%2FDurham%2FChapel%20Hill)%20%5BRepost%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbAgaqjj23QcTW6bfo%2Ffirst-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=First%20Triangle%20LW%20Meetup%205%2F4%207pm%20(Raleigh%2FDurham%2FChapel%20Hill)%20%5BRepost%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbAgaqjj23QcTW6bfo%2Ffirst-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbAgaqjj23QcTW6bfo%2Ffirst-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 199, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><span style=\"font-style: italic;\">Note: This announcement was previously posted <a href=\"/lw/595/first_triangle_lw_meetup_54_7pm/\">here</a>&nbsp;but was not promoted at the time. &nbsp;I assume this was either because the date was too far out or there was no summary break. Please let me know if I should delete that post or ask for people to downvote it to balance karma or if there is some other reason it or this post was not promoted.</span></p>\n<address><br /></address>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">When: Wednesday, May 4th at 7:00 pm</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Where:&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline; \" href=\"http://maps.google.com/maps?ie=UTF8&amp;q=morrisville+outlet+mall&amp;fb=1&amp;gl=us&amp;hq=outlet+mall&amp;hnear=Morrisville,+NC&amp;cid=0,0,14550008319969595142&amp;ll=35.861544,-78.819855&amp;spn=0.008521,0.016512&amp;z=17\">Morrisville Outlet Mall Food Court</a>;&nbsp;&nbsp;I'll be wearing a Lego evolution shirt and may or may not have a LW sign.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \"><a style=\"color: #6a8a6b; text-decoration: underline; \" href=\"https://docs.google.com/document/d/1mePaq-mH-4LGG8oFhM3pti9I2eM86_Yrxm1MrlqdTJc/edit?hl=en\">This Google doc</a>&nbsp;contains some preliminary notes as well as my phone number. &nbsp;I imagine this meeting will consist of introductions and some meta stuff about future meetups. &nbsp;We have seven people that can attend, including the number three LW poster, Alicorn. &nbsp;Hopefully there are even more LWers in the area,&nbsp;or at least rationalists that we can reach out to; it certainly seems&nbsp;like&nbsp;there should be, being the \"Research Triangle\" and all. And feel free to join us if you're not officially inside the Triangle, of course. &nbsp;If there are a bunch of people in Greensboro or Charlotte, we can probably move the venue further West.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Hope to see you there!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bAgaqjj23QcTW6bfo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 7.077744145838789e-07, "legacy": true, "legacyId": "7088", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Z6baaAwf3QihNxAju"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T05:29:30.494Z", "modifiedAt": null, "url": null, "title": "HELP! I want to do good", "slug": "help-i-want-to-do-good", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:35.767Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Giles", "createdAt": "2011-02-11T02:30:16.999Z", "isAdmin": false, "displayName": "Giles"}, "userId": "H347ba3KZMP8XoDt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qJCPpLXmS9rYemjy7/help-i-want-to-do-good", "pageUrlRelative": "/posts/qJCPpLXmS9rYemjy7/help-i-want-to-do-good", "linkUrl": "https://www.lesswrong.com/posts/qJCPpLXmS9rYemjy7/help-i-want-to-do-good", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20HELP!%20I%20want%20to%20do%20good&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHELP!%20I%20want%20to%20do%20good%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqJCPpLXmS9rYemjy7%2Fhelp-i-want-to-do-good%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=HELP!%20I%20want%20to%20do%20good%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqJCPpLXmS9rYemjy7%2Fhelp-i-want-to-do-good", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqJCPpLXmS9rYemjy7%2Fhelp-i-want-to-do-good", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 927, "htmlBody": "<p>There are people out there who want to do good in the world, but don't know how.</p>\n<p>Maybe you are one of them.</p>\n<p>Maybe you kind of feel that you should be into the \"saving the world\" stuff but aren't quite sure if it's for you. You'd have to be some kind of saint, right? That doesn't sound like you.</p>\n<p>Maybe you really do feel it's you, but don't know where to start. You've read <a href=\"/lw/373/how_to_save_the_world/\">the \"How to Save the World\" guide</a> and your reaction is, ok, I <em>get it</em>, now where do I start? A plan that starts \"first, change your entire life\" somehow doesn't sound like a very good plan.</p>\n<p>All the guides on how to save the world, all the advice, all the <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">essays on why cooperation is so hard</a>, everything I've read so far, has missed one fundamental point.</p>\n<p>If I could put it into words, it would be this:</p>\n<p><strong><em>AAAAAAAAAAAGGGHH WTF CRAP WHERE DO I START EEK BLURFBL</em></strong></p>\n<p>If that's your reaction then you're half way there. That's what you get when you finally grasp how much pointless pain, misery, risk, death there is in the world; just how <em>much</em> good could be done if everyone would get their act together; just <em>how little anyone seems to care</em>.</p>\n<p>If you're still reading, then maybe this is you. A little bit.</p>\n<p>And I want to help you.</p>\n<p>How will I help you? That's the easy part. I'll start a community of aspiring rationalist do-gooders. If I can, I'll start it right here in the comments section of this post. If anything about this post speaks to you, let me know. At this point I just want to know whether there's <em>anybody out there</em>.</p>\n<p>And what then? I'll listen to people's opinions, feelings and concerns. I'll post about my worldview and invite people to criticize, attack, tear it apart. Because it's not my worldview I care about. I care about making the world better. I have <a href=\"/lw/nb/something_to_protect/\">something to protect</a>.</p>\n<p>The posts will mainly be about what I don't see enough of on Less Wrong. About reconciling being rational with being <em>human</em>. Posts that encourage <em>doing</em> rather than thinking. I've had enough ideas that I can commit to writing 20 discussion posts over a reasonable timescale, although some might be quite short - just single ideas.</p>\n<p>Someone mentioned there should be a \"saving the world wiki\". That sounds like a great idea and I'm sure that setting one up would be well within my power if someone else doesn't get around to it first.</p>\n<p>But how I intend to help you is not the important part. The important part is <em>why</em>.</p>\n<p>To answer that I'll need to take a couple of steps back.</p>\n<p>Since basically forever, I've had vague, guilt-motivated feelings that I ought to be good. I ought to work towards making the world the place I wished it would be. I knew that others appeared to do good for greedy or selfish reasons; I wasn't like that. I wasn't going to do it for personal gain.</p>\n<p>If everyone did their bit, then things would be great. So I wanted to do my bit.</p>\n<p>I wanted to privately, secretively, give a hell of a lot of money to a good charity. So that I would be doing good and that I would know I wasn't doing it for status or glory.</p>\n<p>I started small. I gave small amounts to some big-name charities, charities I could be fairly sure would be doing <em>something</em> right. That went on for about a year, with not much given in total - I was still building up confidence.</p>\n<p>And then I heard about GiveWell. And I stopped giving. Entirely.</p>\n<p>WHY??? I can't really give a reason. But something just didn't seem right to me. People who talked about GiveWell also tended to mention that the best policy was to give <em>only</em> to the charity listed at the top. And that didn't seem right either. I couldn't argue with the maths, but it went against what I'd been doing up until that point and something about that didn't seem right.</p>\n<p>Also, I hadn't heard of GiveWell or any of the charities they listed. How could I trust any of them? And yet how could I give to anyone <em>else</em> if these charities were so much more effective? Big akrasia time.</p>\n<p>It took a while to sink in. But when it did, I realised that my life so far had mostly been a waste of time. I'd earned some money, but I had no real goals or ambitions. And yet, why should I care if my life so far had been wasted? What I had done in the past was irrelevant to what I intended to do in the future. I knew what my goal was now and from that a whole lot became clear.</p>\n<p>One thing mattered most of all. If I was to be truly virtuous, altruistic, world-changing then I shouldn't deny myself status or make financial sacrifices. I should be <em>completely indifferent</em> to those things. And from that the plan became clear: the best way to save the world would be to <em>persuade other people to do it for me</em>. I'm still not entirely sure why they're not already doing it, but I will use the <a href=\"/lw/dr/generalizing_from_one_example/\">typical mind prior</a> and assume that for some at least, it's for the same reasons as me. They're confused. And that to carry out my plan I won't need to manipulate anyone into carrying out my wishes, but simply help them carry out their own.</p>\n<p>I could say a lot more and I will, but for now I just want to know. Who will be my ally?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qJCPpLXmS9rYemjy7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 22, "extendedScore": null, "score": 3.8e-05, "legacy": true, "legacyId": "7090", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TrmMcujGZt5JAtMGg", "7FzD7pNm9X68Gp5ZC", "SGR4GxFK7KmW7ckCB", "baTWMegR42PAsH9qJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T08:46:58.803Z", "modifiedAt": null, "url": null, "title": "What are the leftover questions of metaethics?", "slug": "what-are-the-leftover-questions-of-metaethics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:40.253Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NyxXkw5NutHDZ6exG/what-are-the-leftover-questions-of-metaethics", "pageUrlRelative": "/posts/NyxXkw5NutHDZ6exG/what-are-the-leftover-questions-of-metaethics", "linkUrl": "https://www.lesswrong.com/posts/NyxXkw5NutHDZ6exG/what-are-the-leftover-questions-of-metaethics", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20the%20leftover%20questions%20of%20metaethics%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20the%20leftover%20questions%20of%20metaethics%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNyxXkw5NutHDZ6exG%2Fwhat-are-the-leftover-questions-of-metaethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20the%20leftover%20questions%20of%20metaethics%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNyxXkw5NutHDZ6exG%2Fwhat-are-the-leftover-questions-of-metaethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNyxXkw5NutHDZ6exG%2Fwhat-are-the-leftover-questions-of-metaethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<p>lukeprog gave a list of metaethics questions <a href=\"/lw/5eh/what_is_metaethics/\">here</a>:</p>\n<blockquote>\n<p>What does moral language mean? Do moral facts exist? If so, what are they like, and are they reducible to natural facts? How can we know whether moral judgments are true or false? Is there a connection between making a moral judgment and being motivated to abide by it? Are moral judgments objective or subjective, relative or absolute? Does it make sense to talk about moral progress?</p>\n</blockquote>\n<p>Most of these questions make no sense to me. I imagine that the moral intuitions in my brain come from a special black box within it, a \"morality core\" whose outputs I cannot easily change. (Explaining how my \"morality core\" ended up a certain way is a task for evo psych, not philosophy.) Or I can be more enlightened and adopt Nesov's idea that the \"morality core\" doesn't exist as a unified device, only as an umbrella name for all the diverse \"reasons for action\" that my brain can fire. Either perspective can be implemented as a computer program pretty easily, so I don't feel there's any philosophical mystery left over. All we have is factual questions about how people's \"morality cores\" vary in time and from person to person, how compelling their voices are, finding patterns in their outputs, etc. Can someone explain what problem metaethics is supposed to solve?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Z8wZZLeLMJ3NSK7kR": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NyxXkw5NutHDZ6exG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 30, "extendedScore": null, "score": 7.07864681386529e-07, "legacy": true, "legacyId": "7095", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["s4Mcg9aLMeRwdW7fh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T09:26:04.851Z", "modifiedAt": null, "url": null, "title": "Reminder: London meetup, Sunday 2pm, near Holborn", "slug": "reminder-london-meetup-sunday-2pm-near-holborn", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:39.433Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6zhgiDHdiNycGSAby/reminder-london-meetup-sunday-2pm-near-holborn", "pageUrlRelative": "/posts/6zhgiDHdiNycGSAby/reminder-london-meetup-sunday-2pm-near-holborn", "linkUrl": "https://www.lesswrong.com/posts/6zhgiDHdiNycGSAby/reminder-london-meetup-sunday-2pm-near-holborn", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reminder%3A%20London%20meetup%2C%20Sunday%202pm%2C%20near%20Holborn&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReminder%3A%20London%20meetup%2C%20Sunday%202pm%2C%20near%20Holborn%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6zhgiDHdiNycGSAby%2Freminder-london-meetup-sunday-2pm-near-holborn%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reminder%3A%20London%20meetup%2C%20Sunday%202pm%2C%20near%20Holborn%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6zhgiDHdiNycGSAby%2Freminder-london-meetup-sunday-2pm-near-holborn", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6zhgiDHdiNycGSAby%2Freminder-london-meetup-sunday-2pm-near-holborn", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<p><a id=\"more\"></a>Reminder: London meetup on Sunday May 1 at 14:00 at the&nbsp;<a href=\"http://maps.google.co.uk/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=shakespeare's+head&amp;sll=51.42559,-0.130394&amp;sspn=0.011854,0.020943&amp;ie=UTF8&amp;hq=shakespeare's+head&amp;hnear=&amp;layer=c&amp;cbll=51.516734,-0.119933&amp;panoid=kXPwAeowAo9LzJJA34agOw&amp;cbp=11,76.42,,1,-1.06&amp;ll=51.516728,-0.124025&amp;spn=0.005622,0.022488&amp;z=16\">Shakespeares Head</a>&nbsp;(<a href=\"http://www.jdwetherspoon.co.uk/home/pubs/shakespeares-head\">official page</a>) on Kingsway near Holborn Tube station. Note that there's more than one pub in London with that name, so make sure you get the right one. &nbsp;As always, we'll have a big picture of a paperclip on the table so you can find us; I <a href=\"http://pics.babysimon.co.uk/index.py/photos/3902?tag=Paul\">look like this</a>. &nbsp;Hope to see lots of you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6zhgiDHdiNycGSAby", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.078758274838641e-07, "legacy": true, "legacyId": "7096", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T16:41:50.161Z", "modifiedAt": null, "url": null, "title": "Assumption of positive rationality", "slug": "assumption-of-positive-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:38.997Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zm6RDiAvnhnwGPcyn/assumption-of-positive-rationality", "pageUrlRelative": "/posts/Zm6RDiAvnhnwGPcyn/assumption-of-positive-rationality", "linkUrl": "https://www.lesswrong.com/posts/Zm6RDiAvnhnwGPcyn/assumption-of-positive-rationality", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Assumption%20of%20positive%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAssumption%20of%20positive%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZm6RDiAvnhnwGPcyn%2Fassumption-of-positive-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Assumption%20of%20positive%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZm6RDiAvnhnwGPcyn%2Fassumption-of-positive-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZm6RDiAvnhnwGPcyn%2Fassumption-of-positive-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 521, "htmlBody": "<p>Let's pretend for the sake of simplicity that all belief-holding entities are either rational or irrational. Rational entities have beliefs that correlate well with reality, and update their beliefs with evidence properly. Irrational entities have beliefs that do not correlate with reality at all, and update their beliefs randomly. Now suppose Bob wants to know what the probability that he is rational is. He estimates that someone with a thought process that seems like his does from the inside is 70% likely to be rational and 30% likely to be irrational. Unfortunately, this does not help much. If Bob is irrational, then his estimate is useless. If Bob is rational, then, after updating on the fact that a randomly selected Bob-like entity is rational, the we can estimate that the probability of another randomly selected Bob-like entity being rational is higher than 70% (exact value depending on the uncertainty regarding what percentage of Bob-like entities are rational). But Bob doesn't care whether a randomly selected Bob-like entity is rational; he wants to know whether he is rational. And conditional on Bob's attempts to figure it out being effective, the probability of that is 1 by definition. Conditional on Bob being irrational, he cannot give meaningful estimates of the probability of much of anything. Thus, even if we ignore the difficulty of coming up with a prior, if Bob tries to evaluate evidence regarding whether or not he is rational, he ends up with:<br />P(evidence given Bob is rational) = x (he can figure it out)<br />P(evidence given Bob is irrational) = ?<br />I am not aware of any good ways to do Bayesian reasoning with question marks. It seems that Bob cannot meaningfully estimate the probability that he is rational. However, in a decision theoretic sense, this is not really an issue for him, because Bob cannot be an effective decision agent if his beliefs about how to achieve his objectives are uncorrelated with reality, so he has no expected utility invested in the possibility that he is irrational. All he needs are probabilities conditional on him being rational, and that's what he has.<br /><br />This does not seem to extend well to further increases in rationality. If you act on the assumption that you are immune to some common cognitive bias, you will just fail at life. However, I can think of one real-life application of this principle: the possibility that you are a Boltzmann brain. A Boltzmann brain would have no particular reason to have correct beliefs or good algorithms for evaluating evidence. When people talk about the probability that they are a Boltzmann brain, they often mention things like the fact that our sensory input is way more well-organized that it should be for almost all Boltzmann brains, but if you are a Boltzmann brain, then how are you supposed to know how well-organized your visual field should be? Is there any meaningful way someone can talk about the probability of em being a Boltzmann brain, or does ey just express all other probabilities as conditional on em not being a Boltzmann brain?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zm6RDiAvnhnwGPcyn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.080000661293127e-07, "legacy": true, "legacyId": "7099", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T19:42:15.164Z", "modifiedAt": null, "url": null, "title": "So You've Changed Your Mind", "slug": "so-you-ve-changed-your-mind", "viewCount": null, "lastCommentedAt": "2019-07-13T20:05:45.616Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spurlock", "createdAt": "2010-03-24T17:13:19.572Z", "isAdmin": false, "displayName": "Spurlock"}, "userId": "mK7rKWbkuoDsm3aQb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W2ZymNJFWbirwctxo/so-you-ve-changed-your-mind", "pageUrlRelative": "/posts/W2ZymNJFWbirwctxo/so-you-ve-changed-your-mind", "linkUrl": "https://www.lesswrong.com/posts/W2ZymNJFWbirwctxo/so-you-ve-changed-your-mind", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20So%20You've%20Changed%20Your%20Mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASo%20You've%20Changed%20Your%20Mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW2ZymNJFWbirwctxo%2Fso-you-ve-changed-your-mind%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=So%20You've%20Changed%20Your%20Mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW2ZymNJFWbirwctxo%2Fso-you-ve-changed-your-mind", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW2ZymNJFWbirwctxo%2Fso-you-ve-changed-your-mind", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1168, "htmlBody": "<p>Related to: <a href=\"/lw/gw/politics_is_the_mindkiller/\">Politics is the mind-killer</a>, <a href=\"/lw/uw/entangled_truths_contagious_lies/\">Entangled Truths, Contagious Lies</a>, <a href=\"/lw/i9/the_importance_of_saying_oops/\">The Importance of Saying \"Oops\"</a>, <a href=\"/lw/o4/leave_a_line_of_retreat/\">Leave a Line of Retreat</a>, <a href=\"/lw/id/you_can_face_reality/\">You Can Face Reality</a></p>\n<p><em>This is something I wrote, sort of in brain-dump mode, in the process of trying to organize my thoughts for a song I'm working on. I don't think it covers any new ground for this community, but I was somewhat taken with the way it turned out and figured I'd go ahead and post it for LW's enjoyment.</em></p>\n<p>&nbsp;</p>\n<p>So you've changed your mind. Given up your sacred belief, the one that defined so much of <em>who you are</em> for so long.</p>\n<p>You are probably feeling pretty scared right now.</p>\n<p>Your life <em>revolved</em> around this. There is not a single aspect of your life that will not feel the effects of this momentous tumult. Right now though, you're still in shock. You know that later, little by little, as you lie awake in bed or stare at your desk at work, the idea will creep its way through the web of your mind. It will touch each and every idea, and change it, and move on. And that changed idea will change other ideas, and <em>those ideas</em> will change as well. Who are you as a <em>person</em> if not the person who holds that idea? For as this new notion gradually but violently makes its way through your skull, will it not upset everything that you know, everything that you do, everything that you <em>are</em>? Will you not then be another person?</p>\n<p>The thought is terrifying. <em>What person</em> will you be?</p>\n<p><a id=\"more\"></a></p>\n<p>Will you be like the jackasses that you argued against for so long? Yes, they were right all along, but damn they were <em>infuriating</em>. Is that your lot now? Another loud-mouth, uncompromising, thick-skulled, pushy, self-righteous snob who lives for the thrill of making everyone else feel ignorant? Dear God. Is <em>that</em> your fate? Perhaps in just a few days? You're reminded of the film character who has just been bitten by a zombie: Knowing the disgusting, horrific, inhuman <em>beast</em> he is now doomed to become, he says good-bye to The Girl, politely leaves the room, and wraps his mouth around both barrels of his shotgun.</p>\n<p>Is that it then? Better dead than Red? But surely this is nonsense. For starters, you know damn well that you just don't have the, well... courage? resolve? commitment? hopelessness? inclination? lack-of-perspective? impulsiveness? Whatever it is that separates those who could actually, really and truly, <em>do</em> such a thing, from... you. But really now. If this isn't \"game over\"... then why not? Hasn't this been your <em>reason</em> for Everything? Doesn't that make Everything, QED, a lost cause now? Difficult to see why it wouldn't.</p>\n<p>And yet... there is the <em>feeling</em> that it doesn't. You <em>don't</em> want to throw it all away. You don't know why, and part of you condemns your fickleness, but throwing it all away just doesn't feel as right as it sounds.</p>\n<p>Well, perhaps it's not right. Really, when you take a second to actually <em>think</em> of reasons to go on... where to begin? You still love your spouse, and you still want to see your kids grow up... why cut your time with them short? You still take pride in your job, most days. You still like the taste of pizza, which is actually sounding <em>really good</em> right about now. Hell, you still have another season and a half of <em>Doctor Who</em> to get through. Perhaps you've lost your \"purpose\", for the time being, but you've still got <em>reasons</em>.</p>\n<p>Maybe that idea wasn't as far-reaching as you told yourself it was. Even now, in the immediate aftermath, you can see that it must not have been your <em>real</em> reason for getting out of bed in the morning. Because you know that tomorrow morning, despite everything, you're going to get out of bed. Maybe the world <em>will</em> seem new and scary, but honestly, how long could you possibly just <em>sit in bed</em>? Even if you didn't have to pee.</p>\n<p>Maybe you told yourself that it was your reason for loving your parents, for going to work, for learning and socializing and creating and <em>breathing</em>... but then, maybe you weren't being totally honest with yourself. Because here you are, and while you might be feeling a little overwhelmed right now... you know that you <em>still want to do</em> those things. So then... maybe that wasn't your true motivation all along, like you always said it was. Well, fine. You're already cleaning out ideas, might as well clean out the related, faulty, meta-ideas too.</p>\n<p>And slowly, <em>hesitantly</em>, your fear starts to dissipate. You feel a curious sense of clarity. You <em>don't</em> have to become a zombie. Because in this brave new world, zombies are still obnoxious and intolerable. You still can't stand just how infuriating they are. And really <em>that</em> was the reason you were so disgusted at the thought of becoming one of them. Your ideas about what it means to be on \"their side\"... those were just poisoned meta-ideas too. Just like the lies about your \"purpose for living\", they were just one more road block you set up to block your own escape route. Preemptive self-sabotage. My, were you ever <em>committed</em>.</p>\n<p>For a moment, you are confused. You've just realized that perhaps a lot of your ideas are poisonous slave-ideas like this one. You've realized that perhaps you'll be overturning even more ideas that you feared. And yet, you are comforted. How could this realization possibly be <em>comforting</em>?... And then you see it: it's because you realize that that more of these ideas you give up, the easier it will be to let the <em>core idea</em> go.</p>\n<p>Come to think of it, most of your <em>real ideas</em> will be <em>fine</em>. There's no reason to expect that you'll have to overturn your notions about the blueness of the sky, the four-ness of two plus two, the wrongness of murder, the rightness of compassion, the awesomeness of <em>London Calling</em>&nbsp;or the awfulness of <em>Bridezillas</em>. The only beliefs that you'll have to overturn are the ones that were <em>holding you back anyway</em>. The ones that either grew out of a <em>mistake</em>, or were planted just to <em>protect that mistake</em>.</p>\n<p>Your <em>commitment</em> to that mistake has filled your mind with <em>junk</em>. In fact, a lot of that junk would still be junk even if the idea had been <em>right</em>. Perhaps the commitment itself hurt you more than the idea... Perhaps there's a lesson to be learned there... but there will be plenty of time later to ponder that.</p>\n<p>Either way, you suddenly find yourself feeling a lot more optimistic about the house cleaning that's coming up over the next few days. Of course you're going to change: you've been given a real chance to <em>improve yourself</em>. Might as well wring every last precious drop out of it. And if \"purpose\" is still something you find yourself needing... well, you'll find a better one. For the time being, as long as there is something you care about, anything at all, there will be something that needs doing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mQbxDKHxPcKKRG4mb": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W2ZymNJFWbirwctxo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 78, "baseScore": 78, "extendedScore": null, "score": 0.000165, "legacy": true, "legacyId": "7100", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 62, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9weLK2AJ9JEt2Tt8f", "wyyfFfaRar2jEdeQK", "wCqfCLs8z5Qw4GbKS", "3XgYbghWruBMrPTAL", "HYWhKXRsMAyvRKRYz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-28T20:26:29.071Z", "modifiedAt": null, "url": null, "title": "Meditation, insight, and rationality. (Part 1 of 3)", "slug": "meditation-insight-and-rationality-part-1-of-3", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:08.260Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DavidM", "createdAt": "2011-04-25T18:36:53.508Z", "isAdmin": false, "displayName": "DavidM"}, "userId": "rMmh9neuZsXGc6ywN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QqSNFcGSZdnARx56E/meditation-insight-and-rationality-part-1-of-3", "pageUrlRelative": "/posts/QqSNFcGSZdnARx56E/meditation-insight-and-rationality-part-1-of-3", "linkUrl": "https://www.lesswrong.com/posts/QqSNFcGSZdnARx56E/meditation-insight-and-rationality-part-1-of-3", "postedAtFormatted": "Thursday, April 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meditation%2C%20insight%2C%20and%20rationality.%20(Part%201%20of%203)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeditation%2C%20insight%2C%20and%20rationality.%20(Part%201%20of%203)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQqSNFcGSZdnARx56E%2Fmeditation-insight-and-rationality-part-1-of-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meditation%2C%20insight%2C%20and%20rationality.%20(Part%201%20of%203)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQqSNFcGSZdnARx56E%2Fmeditation-insight-and-rationality-part-1-of-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQqSNFcGSZdnARx56E%2Fmeditation-insight-and-rationality-part-1-of-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5005, "htmlBody": "<p>For millennia, the practice of meditation has been deeply intertwined with many of the world's major and minor religious and spiritual traditions, as a technique aimed as everything from developing magical powers to communing with gods and demons. By contrast, during the last few decades in the West, enthusiasts have promoted meditation (along with a variety of its secularized offshoots) as a good way to cultivate relaxation, creativity, and psychological self-improvement in the context of our hurried and stressful lives. Because of this variegated cultural history, it's no surprise that many people see it as either as an exercise that leads to irrationality and madness, or as a harmless but questionably-effective pop science fad---sometimes both at once!</p>\n<p>Set against this backdrop, small and somewhat private groups with an interest in meditation have long gathered together in secret to discuss and learn. Not satisfied with the popular dogmas, they got down to figuring out, as best they could, whether meditation <em>really</em> leads to anything that could be called \"enlightenment\": by experimenting on themselves, comparing notes with others, seeing where it led them, and seeing whether it would repeatably lead others to the same point. Because their subject is taboo, they have labored in the shadows for a very long time; but the modern mass-adoption of the internet has allowed what they know to reach a widening audience. And while they fought for years to discover these things, you now have the opportunity to hear about them merely for the cost of your internet connection---for some of you that may be a blessing, but guard your minds so that it isn't also a <a href=\"/lw/p0/to_spread_science_keep_it_secret/\">curse</a>.</p>\n<p><a id=\"more\"></a></p>\n<p>Before I begin, there are three caveats:</p>\n<p>1) The perspective I'm going to present is one most closely associated with Buddhism, and you may be inclined to ask \"Is this a good description of what Buddhists believe?\" or \"Is this what Buddhism is <em>really</em> about?\" or even shout \"This doesn't sound like Buddhism to me!\"&nbsp; The relation between this material and Buddhism is an interesting topic (and I'll discuss that in Part 2), but for now, I make no claims whatsoever. This material draws enormous inspiration from particular strains of Buddhism, and one may argue that it is a highly plausible interpretation of what Buddhism is 'really about,' but in the end it stands or falls by itself.</p>\n<p>2) What is declassified on the internet is still taboo in many communities. If you walk into your local dharma group / meditation center / Buddhist sangha or what-have-you and start asking about enlightenment or talking concretely about your own meditation experiences and what you think they mean, you may not get the response you'd expect. Having warned you, my conscience will remain clear...even so, don't be a jerk, and please recognize that not everyone who appears to be interested in meditation wants to hear about these things.</p>\n<p>3) What follows is the best attempt at writing this information up in a way that I think suits the LW community. No one besides me is to blame for any shortcomings it has.</p>\n<p>&nbsp;</p>\n<p><strong>Why meditate?</strong></p>\n<p>You may take up or have taken up meditation for all kinds of reasons. It may help you to relax, it may help you to think clearly, and it may even help you to fit in with your New-Agey friends and the alternative lifestyle crowd. But one of the best reasons to start meditating is so that you can <em>stop being deluded</em>.</p>\n<p>Delusions come in many kinds, and the right medicine for one may be ineffectual for another. Some things called delusions are merely misinformation, and melt away in the light of evidence. Other types of delusions stem from mental illness and can be vanquished by therapy or medication. The common practices of rationalists are well-suited to eliminating delusions that spring from cognitive biases. The sane human mind is generally quite good at representing and then talking about these cases: you can call yourself out on these types of delusions, or failing that, someone else will call you out. If you disagree with their assessment, you at least can expect to understand what's at stake in the disagreement.</p>\n<p>But there is another way to be deluded, in which you <em>can't</em> easily understand what it means to be deluded in that way. For the purpose of crafting a simple metaphor, think of beliefs, thoughts, various cognitive representations, etc. as tangible objects in the factory that is your mind, and think of the various cognitive transformations that your mind is capable of as industrial processes that take these objects as inputs and produce others as outputs. So, via one process, these objects can be looked at, via another their properties can be manipulated, or further objects can be generated as a function of the properties of the inputs; ultimately, all objects are either put to further use in-house as inputs to other processes, or marketed to consumers (= behaviors in the external world) at some point. Most processes are simple, but others are sophisticated (second-order) and can assess the ways that different inputs and outputs make the factory's gears grind differently, and adjust operations to compensate. If the outputs are built to spec, all's well; malformed outputs are either rejected on the market or gum up the works when used in-house, depending on what they are and what they're supposed to do.</p>\n<p>There are lots of simple ways that factories can run badly: the processes are obsolete, there aren't enough doo-dads available when the machinery requires doo-dads to run, or someone puts sprockets in the chute clearly marked \"COGS ONLY\". But there are also systematic ways that production can be inefficient.</p>\n<p>Suppose that some processes take objects and project their image, via a lens, onto a photosensitive site that controls the specifications of whatever that process outputs. If the lens is sufficiently good, there's no problem. If the lens has severe aberrations...well, it depends. Some processes may not be sensitive to the distortions that the lens imposes, so there is no practical effect. Other processes will output different objects than they otherwise would have due to the lens' distortion. Those malformed objects may be destined for the market, where consumers may or may not be sensitive to the malformation, or they may be inputs to other processes which are not sensitive to the malformation. But for those processes that ARE sensitive to it...if THEIR malformed outputs feed into processes that are also sensitive to it...and THEIR outputs do as well...there's a potential for some serious industrial mishaps.</p>\n<p>How would you, the factory owner, assess whether such a problem exists? Perhaps there's a camera that feeds into a CCTV display in the main office, and you could have it point at the objects being generated, inspect them, and make an assessment. If you see that the objects are not built to spec, you can inspect the machinery, and, finding the junky lenses, replace them. Sounds good...unless...the camera was built in-house with a lens that also produces a distorted image. That's a more complicated problem.</p>\n<p>If the camera's image looks distorted on the screen, you can always stop the production lines and take a look with your own two eyes, bypassing the camera and its problems.</p>\n<p>Unfortunately, there is no homunculus perched on a chair somewhere in your brain, waiting to spring into action. In our metaphor, the camera's image is input for a second-order process, perhaps a rudimentary AI meant to regulate overall production, cobbled together by some sloppy but effective evolutionary process outside the factory. How likely is it for the AI to consider the possibility of a distorted camera lens? Suppose it's so unsophisticated that it does not even understand that the camera's output is a representation of anything, but assumes the output is direct access to the thing-in-itself? (Imagine that it does not even know that there is a camera, and is built in such a way that it receives the camera's output with the tag \"WHAT's GOING ON AT COORDINATES X,Y,Z\" and nothing else.) If it has no primitive concept of data <em>representing</em> something, and the process by which it receives data from the camera is completely opaque to it, then it may be quite oblivious to the fact that there even is a problem. Even if it responds to natural language, you can type \"MACHINES X AND Y ARE MALFUNCTIONING AND THE CAMERA BY WHICH YOU OBSERVE THEM IS MISLEADING YOU!!!!!1\" on the terminal all day with no guarantee of making headway.</p>\n<p>To fix the problem, the AI needs to be adaptive enough to find a way to conceptualize it in the first place, and, depending on the idiosyncrasies of the evolutionary process that built it and on&nbsp; the degree to which that process selects for AIs that happen to be good at factory control rather than something else, the ways by which it might recognize that there is a problem so that it forms the relevant concepts to deal with it could well be limited.</p>\n<p>Welcome to the human condition.</p>\n<p>&nbsp;</p>\n<p><strong>Building new concepts</strong>.</p>\n<p>Here's a stylized story about how the the AI might manage to figure out that some of the machines it watches over, along&nbsp; with the cameras by which it watches, have lenses that produce distorted images, and these images are leading to production problems.</p>\n<p>Suppose there are multiple cameras it receives data from, and the AI, for whatever reason (perhaps an unintended consequence of something else it's doing) directs them both towards the same machine. Lo and behold, two sources of information tagged \"WHAT'S GOING ON AT COORDINATES X,Y,Z\" are not identical! How strange. Perhaps from this and some adaptive inference it figures out that what representation is and that these data merely represent what's going on at coordinates X,Y,Z. If the camera lenses are only moderately distorting, the AI may point one camera at the other, match the image it sees to an image of a camera in its database, and by doing so, manage to peek into the black box that produces the data by which it monitors the factory. And perhaps now it has an inkling of an idea that, since production has been slower and more problematic than expected, that means <em>something is wrong</em>, despite the fact that all the data it has access to do not allow it to pinpoint any particular problem: because, as it now knows, the data could be inaccurate.</p>\n<p>From here, there are various ways that the AI could discover that something is wrong with the camera lenses. If the distortions aren't uniform over the image the lens produces, it could rotate one camera, un-rotate the output, and see that this is not equivalent to the previous output from an un-rotated camera. Or, knowing the layout and dimensions of the factory, it could aim both cameras at the same location, transform the data from one camera&nbsp; so that in theory it would match the data from the other (given the known positions of the cameras as well as the machines on the factory floor being looked at), and yet find that they did not match. Now it can infer that at least one representation is inaccurate.</p>\n<p>Since the factory makes lenses in-house, to test the hypothesis that one of the cameras' lenses is faulty, the AI could replace one camera's lens with a different one (of unknown quality), and depending on how clever it is and how much it knows about optics, try to work out what the lens aberrations at issue here are. If the malfunctioning machines are the ones that produce lenses, there may be multiple rounds of producing lenses with different kinds or degrees of aberrations, inserting them in the cameras, inspecting the machines, modifying the machines, building new lenses based on the modifications....successively getting closer to the point where it has enough data from the various distorted images it's collected to have managed to produce a lens of sufficiently high quality to</p>\n<ul>\n<li>Accurately observe the previous defective camera lenses,</li>\n<li>Reflect on how those lenses led to faulty information about the machines and their outputs,</li>\n<li>Accurately observe the malformed outputs of the machines,</li>\n<li>Accurately observe the defective lenses inside of the machines,</li>\n<li>Discover the details by which the defective lenses are leading to malformed outputs,</li>\n<li>Deduce a lens design that will not lead to malformed outputs, and</li>\n<li>Build and install such lenses.</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>What's wrong with your mind.</strong></p>\n<p>Understanding that it's an oversimplification, the preceding metaphor is a very good one for describing how human minds works by default with respect to what meditation is good for. Some cognitive processes within the mind have defects that yield distorted outputs. And the second-order processes that evaluate how the first-order processes work are themselves defective, yielding more distorted outputs. All these distorted outputs are fed back into various cognitive processes, where they muck up effective operation in all kinds of ways.</p>\n<p>If I tell you about the defects in your own mind, it is unlikely that you will understand (<em>really</em> understand) what I mean. The first-order processes may be messed up and I could describe that to you, but when you attempt to introspect on their status, the image of those processes that you see is itself distorted. Further, you may not have even developed a concept by which you could understand what the distortion is, or even <em>what it would be like</em> for the outputs of your first- and second-order cognitive processes to be distorted or not distorted in the way I mean. So we would be talking past each other.</p>\n<p>This post was inspired by <a href=\"/lw/5dj/the_benefits_of_madness_a_positive_account_of/\">Skatche's</a>. He writes, parenthetically,</p>\n<p style=\"padding-left: 30px;\">\"[...in] the Buddhist system...the unenlightened mind can't truly understand reality anyway, so you'd best just shut up and meditate.\"</p>\n<p>This is a common impression people have. It's also more or less true. Not because&nbsp; enlightenment is some wild, indescribable altered state of consciousness which people mistake for a glimpse&nbsp; into 'reality,' but because the unenlightened mind probably can't even begin to conceptualize the problem, and definitely doesn't have the tools with which to understand it with sufficient clarity. 8-year-olds typically can't grok higher mathematics, not because mathematicians are tripping balls, but because 8-year-old minds don't have the tools to grasp what mathematicians talk about, and don't have the concepts to understand what it is that there's not grasping. <em>C'est la vie</em>.</p>\n<p>I'm sure you want to hear what the big deal is anyway, so here you go. Your first-order cognitive processes that take experiences as objects are malfunctioning, and output bizarre things such as 'attachment,' 'craving,' and 'hatred.' The second-order cognitive process that monitors them is malfunctioning, and can't see what is so bizarre about those outputs (\"aren't these built to spec?\"). The same process, when monitoring experiences, outputs bizarre things such as 'Self' (and many variations on it). When it takes itself as an object to see its own inner workings, no output is produced, and a function call to the rational inference module asking what process outputted 'Self' yields a variety of confabulated answers (typically 'the senses' or 'rational deduction,' and claimed to be built to spec). When high-level cognitive processes take 'Self' as an object, the outputs are more bizarre objects: for example, 'existential angst,' 'Cartesian dualism,' and so on. From then on, the lives of these malformed objects are variegated: 'existential angst' as an input for the poetry generation process yields a product roundly rejected by consumers, 'attachment' and 'existential angst' as inputs for the life-goal planning process yields questionable long-term plans, and 'Cartesian dualism' as an input into the philosophy of mind process causes a blue screen of death.</p>\n<p>All this happens without you batting an eye, and yet if you reflect in a very general and nonspecific way on whether all these malformed objects are helping or hurting your functioning, and helping or hurting your everyday behavior, you may be able to see that, at least in some ways, they're gumming up the works. But can you see what's wrong with them? Aren't they built to spec? Don't you need them in order to lead a normal life?</p>\n<p>You may be quick to say that you have a perfectly good meaning in mind when you say 'Self.' Either 'Self' is a matter of definition and can be defined innocuously, or better yet, describes the behavior of biological systems in a useful and accurate way---<a href=\"/lw/o0/where_to_draw_the_boundary/\">carving reality at the joints</a>. So it is not a delusion, and anyone who says otherwise is...well...deluded.</p>\n<p>Well, bull. You have at least <em>two</em> concepts, Self and Self*. What you are describing, what carves reality at the joints, is Self*, an output of the rational thought process. Because your lens distorts, Self and Self* look indistinguishable to you. When you make a function call to ask what process outputs [Self or Self*, since they look the same to you], the answer you invariably get is 'rational thought.' \"See,\" you think, \"no delusion!\" as you happily feed Self into the processes that generate attachment, craving, hatred, existential angst, etc. etc. from it, <em>even when</em> <em>Self* is not an input that would produce those outputs.</em></p>\n<p>The rationally-derived concept Self2 that you use doesn't and <em>couldn't</em> play the role in your mental machinery that it seems to. When you were young, before you were mature enough to form the concept Self*, you had attachment, craving, and so on. Today, you still do. How likely is it that Self* is responsible for those things right now? When you feel, deep down in your bones, that <em>you</em> want something--sex, drugs, money, status, friendship, happiness, anything--what is the 'you' who appears to want it? Self*? Knowing what you know about human minds, human development and comparative neurophysiology, is the 'you' who appears to want it the kind of thing that is likely to be the output of a rational process?</p>\n<p>Think about it. See if you can begin to form a new concept that better captures what could be going on in your mind.</p>\n<p>This metaphor is just illustrative. If it doesn't make sense to you on some level, I know of no argument that will be able to change that. If, for example, you have the intuitive feeling that you are a homunculus experiencing the output of your brain and yet rationally know that that's not true, the tension between the two may be a starting point for you. Or if you've had experiences where your sense of self was altered in radical ways, you may be able to see that there's more to the way you normally conceive of the world in relation to you than first meets the eye.</p>\n<p>But it isn't irrational for this not to make sense. If it doesn't make sense, you simply haven't built the right concepts and tools yet to allow it to make sense. Being ill-equipped is not a matter of irrationality. It's a simple problem that you can solve if you're motivated to.</p>\n<p>Whichever case best describes you, I claim you can build the concepts and tools you need to understand this through meditation. If you're interested, you can do the experiment yourself, and see what happens.</p>\n<p>&nbsp;</p>\n<p><strong>How meditation works.</strong></p>\n<p>Meditation, at least meditation for the goal I've described, can be thought of as a series of attentional and perceptual exercises. Experience has shown that directing your attention and perception in particular ways will help you to begin to see the ways in which your cognitive machinery is distorted. As in the metaphor, you eventually need to build new lenses in order to get a handle on what's going on, but luckily, you don't need to know their specs or retrofit your cognitive machinery; if you do the exercises, neuroplasticity will handle those parts for you.</p>\n<p>EDITED FOR CLARITY: There are a range of \"attentional and perceptual exercises\" (= meditation styles) that are effective, but it important to note that not all are especially effective,&nbsp; and more importantly, a couple tend to work <em>really well</em> compared to the rest. Common kinds of meditation instructions, such as \"relax, follow your breath, and cultivate equanimity towards whatever thoughts arise without getting involved with them\", are unfortunately not the kinds of instructions that have an especially good track record among typical meditators. At least with respect to attaining the kind of insight under discussion. Such instructions do seem to work very well for helping people to be relaxed and less overemotional, though. More details in Part 2.</p>\n<p>Experience shows that doing the exercises will cause your mind to generate various new lenses with different aberrations (there are various ways to categorize how many different types), and as your mental processes adapt to the output that these aberrations engender, you gain more and more data with which you can piece together the ways in which these distorted outputs have misled you. When you have enough data, your mind is able to produce a lens that it <em>strictly less distorting</em> than everything that came before. Retrofitting everything with this new type of lens makes your life better, and it makes the exercises easier. As you continue the exercises and cycle through new lenses, eventually your mind is able to repeat the feat, and make a lens that is strictly less distorting than in the previous case. On and on.</p>\n<p>The first time you generate and use a lens that is strictly less distorting, you are partially enlightened.</p>\n<p>When you have generated and installed a lens that does not distort in ways that lead to attachment, you are fully enlightened.</p>\n<p>These results do not depend on any effort to maintain, and they are not altered states of consciousness. The goal of this type of meditation is not to produce any particular mental state, but to fix your cognitive machinery. When it's fixed, it's fixed. Experience has shown that no maintenance is required.</p>\n<p>Unlike what popular mythology says, this process need not take a lifetime, or half of a lifetime, and definitely doesn't require that you live on a mountaintop in the Himalayas. Bearing in mind that individual variation exists, contemporary methods can yield deep and powerful cognitive upgrades along these lines within a few years. Many people are able to reach what is considered to be the first partial stage of enlightenment within <em>months</em>, in the context of a dedicated and regular practice during their daily life, and this is not considered especially atypical.</p>\n<p>&nbsp;</p>\n<p><strong>Benefits.</strong></p>\n<p>The reasons you might pursue this kind of mental upgrade are individual---just as in every other case. I don't have THE REASON that this is important for you to do. But here are a selection that you as an individual might find compelling.</p>\n<ul>\n<li>Be happier; function better.</li>\n</ul>\n<p>When you begin to cut off the automatic generation of attachment, craving, hatred, etc., those things get used less as inputs to other mental processes: your life will likely become a more fun, more carefree, and more worthwhile experience. As you begin to cut off the generation of the concept Self by second-order processes, it gets used less as inputs to higher-level cognitive processes: you will think more clearly about existential issues of all kinds.</p>\n<ul>\n<li>Know what your goals would be if you were more insightful.</li>\n</ul>\n<p>It's easy to think about what you want, and build a plan for your life around what you think you want. But your ability to know what you want is curtailed by the fact that you have delusions about what 'you' means. If you begin to get rid of the delusions by beginning to cut off the flow of Self into various processes, you will be in a better position to decide on how to live your life. Imagine you could get a&nbsp; pre-Friendly AI glimpse into CEV; might that change your current goals? What would a glimpse of your own, private extrapolated volition be worth to you? What would you do to get such a glimpse?</p>\n<ul>\n<li>Be more rational.</li>\n</ul>\n<p>As you do the attentional and perceptual exercises involved in meditation, you develop a less and less distorted view of your own mental processes. This eventually allows you to fix any processes that are systematically malfunctioning due to the want of non-distorting components. But as a side effect, it also lets you see an enormous selection of what's going on in your mind: lots of things that you might not have previously noticed, or that you would have previously called '\"subconscious,\" may become effortlessly clear to you.</p>\n<p>Suppose you are biased against non-degreed people, and one day, a high school dropout tells you something that you currently disbelieve. If the thought \"he doesn't know anything, he has no education!\" arose in your mind, you might not normally even notice it, or you might delusively attribute the thought to 'you' and then be invested in acting according to it and defending it (since it's 'yours,' or since 'you' thought it). As your mental processes snap into focus, it's much easier to see the thought, and regard it as 'a thought' rather than 'my thought' or 'my belief' or 'mental content I generated'. When your mind can't sweep it under the carpet and yet you have no special attachment to it, it is easy to face it explicitly and decide how to work with it. If you already have the motivation, accounting for and dealing with your own cognitive biases is likely to become much simpler and easier than before.</p>\n<ul>\n<li>Understand the origin of delusive intuitions.</li>\n</ul>\n<p>One example. Many people have the intuition that they have free will, i.e. that they are homunculi controlling their bodies and minds in a way that is outside the normal laws of physics. Even those of us who know better may still have that feeling. Meditation can ultimately eliminate that feeling. Undercutting the intuition and seeing where that leaves the rational case for free will, from a first-person perspective, may be very informative for understanding other cases in which your intuitions are misleading you by corrupting your rational thought.</p>\n<ul>\n<li>Understand the limits of your own conceptual apparatus.</li>\n</ul>\n<p>The space of potential minds is huge; the space of human-like minds is a tiny subset of it. You may believe that your human mind cannot really conceive of what other potential minds would be like if they were sufficiently different, but do you <em>know</em> that in your bones? The result of meditation is a mind that is well within the space of human-like minds...but you will not be able to imagine what having that kind of mind is like until you have it. That puts potential alien minds and AIs, or rather, your ability to imagine them with any sort of accuracy, into perspective.</p>\n<p>&nbsp;</p>\n<p><strong>Risks.</strong></p>\n<p>It is extremely important to realize that the process of replacing the lenses of your mental processes can lead to intense mental turmoil, potentially severe enough that it impacts your ability to function effectively for weeks, months, or even years. This does not happen to everyone, and it need not be severe when it does happen, but you should consider the degree to which you're committed to this <em>before you start</em>. I would recommend not starting at all unless you are willing to see it through and not give up just because it seems to have made things temporarily suck: experience has shown that giving up while things suck is a great way to make things suck for a <em>long</em> time. (And experience has shown that commitment helps to avoid this problem.)</p>\n<p>It is also important to realize that this is an experiment in self-transformation. Past a certain point, there is no going back, and no undo button. As a matter of informed consent, you need to know that the style of meditation that leads to the goal I've described can and will change the functioning of your brain, permanently. Lots of people have found these changes worthwhile. That doesn't mean there's no need to think about what you're about to do before you do it.</p>\n<p>More information forthcoming in Part 2. (Perhaps next week.)</p>\n<p>&nbsp;</p>\n<p><strong>Addendum.</strong></p>\n<p>I have made all kinds of claims in this post, some of which may be seen as wild, reckless, unfounded, unargued-for, and so on. Certainly I'm not doing very much hedging and qualification. The really remarkable thing that communities interested in this kind of human development have discovered is that people who work at meditation long enough will reliably and regularly say the same kinds of things, in the same order; and people who have stumbled onto the exercises that lead to this kind of development <em>outside of these communities</em> will also, reliably and regularly, say the same kinds of things (although some translation between cultural frameworks may have to go on first). Further. I have not known anyone to suffer from a deficit in rationality or in the ability to observe and assess themselves by practicing meditation in the way that leads to this kind of development. So my working hypothesis is:</p>\n<ul>\n<li>Certain styles of meditation lead to <em>bona fide</em> insight, and there is a consensus on what that insight is among people who meditate in those styles; anyone with the same cultural background (e.g. contemporary Westerners) who takes up meditation is likely to experience that insight and describe it a way that is broadly similar to everyone else's description, whether or not they are primed to do so by the discourse of the communities of which they are members.</li>\n</ul>\n<p>I hope that exposing readers of Less Wrong to this information will help me to confirm or deny this hypothesis. More importantly, I'm also sharing the information that I am because I hope that learning about it will ultimately help people to benefit personally from it, as I have.</p>\n<p>Also, please note that my metaphor of a factory is just a metaphor, intended to be intuitive and helpful, not intended to be anything like a precise and thorough description of how minds work or how meditation changes how minds work.</p>\n<p>Finally, this was written as a blog post, not a final draft of a formal article. Criticisms related to tone and style are especially welcomed. And apologies in for the length of the piece, as well as any formatting issues it has (I have little experience with effective formatting for blogs.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AiNyf5iwbpc7mehiX": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QqSNFcGSZdnARx56E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 68, "baseScore": 58, "extendedScore": null, "score": 0.000111, "legacy": true, "legacyId": "7101", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 58, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>For millennia, the practice of meditation has been deeply intertwined with many of the world's major and minor religious and spiritual traditions, as a technique aimed as everything from developing magical powers to communing with gods and demons. By contrast, during the last few decades in the West, enthusiasts have promoted meditation (along with a variety of its secularized offshoots) as a good way to cultivate relaxation, creativity, and psychological self-improvement in the context of our hurried and stressful lives. Because of this variegated cultural history, it's no surprise that many people see it as either as an exercise that leads to irrationality and madness, or as a harmless but questionably-effective pop science fad---sometimes both at once!</p>\n<p>Set against this backdrop, small and somewhat private groups with an interest in meditation have long gathered together in secret to discuss and learn. Not satisfied with the popular dogmas, they got down to figuring out, as best they could, whether meditation <em>really</em> leads to anything that could be called \"enlightenment\": by experimenting on themselves, comparing notes with others, seeing where it led them, and seeing whether it would repeatably lead others to the same point. Because their subject is taboo, they have labored in the shadows for a very long time; but the modern mass-adoption of the internet has allowed what they know to reach a widening audience. And while they fought for years to discover these things, you now have the opportunity to hear about them merely for the cost of your internet connection---for some of you that may be a blessing, but guard your minds so that it isn't also a <a href=\"/lw/p0/to_spread_science_keep_it_secret/\">curse</a>.</p>\n<p><a id=\"more\"></a></p>\n<p>Before I begin, there are three caveats:</p>\n<p>1) The perspective I'm going to present is one most closely associated with Buddhism, and you may be inclined to ask \"Is this a good description of what Buddhists believe?\" or \"Is this what Buddhism is <em>really</em> about?\" or even shout \"This doesn't sound like Buddhism to me!\"&nbsp; The relation between this material and Buddhism is an interesting topic (and I'll discuss that in Part 2), but for now, I make no claims whatsoever. This material draws enormous inspiration from particular strains of Buddhism, and one may argue that it is a highly plausible interpretation of what Buddhism is 'really about,' but in the end it stands or falls by itself.</p>\n<p>2) What is declassified on the internet is still taboo in many communities. If you walk into your local dharma group / meditation center / Buddhist sangha or what-have-you and start asking about enlightenment or talking concretely about your own meditation experiences and what you think they mean, you may not get the response you'd expect. Having warned you, my conscience will remain clear...even so, don't be a jerk, and please recognize that not everyone who appears to be interested in meditation wants to hear about these things.</p>\n<p>3) What follows is the best attempt at writing this information up in a way that I think suits the LW community. No one besides me is to blame for any shortcomings it has.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Why_meditate_\">Why meditate?</strong></p>\n<p>You may take up or have taken up meditation for all kinds of reasons. It may help you to relax, it may help you to think clearly, and it may even help you to fit in with your New-Agey friends and the alternative lifestyle crowd. But one of the best reasons to start meditating is so that you can <em>stop being deluded</em>.</p>\n<p>Delusions come in many kinds, and the right medicine for one may be ineffectual for another. Some things called delusions are merely misinformation, and melt away in the light of evidence. Other types of delusions stem from mental illness and can be vanquished by therapy or medication. The common practices of rationalists are well-suited to eliminating delusions that spring from cognitive biases. The sane human mind is generally quite good at representing and then talking about these cases: you can call yourself out on these types of delusions, or failing that, someone else will call you out. If you disagree with their assessment, you at least can expect to understand what's at stake in the disagreement.</p>\n<p>But there is another way to be deluded, in which you <em>can't</em> easily understand what it means to be deluded in that way. For the purpose of crafting a simple metaphor, think of beliefs, thoughts, various cognitive representations, etc. as tangible objects in the factory that is your mind, and think of the various cognitive transformations that your mind is capable of as industrial processes that take these objects as inputs and produce others as outputs. So, via one process, these objects can be looked at, via another their properties can be manipulated, or further objects can be generated as a function of the properties of the inputs; ultimately, all objects are either put to further use in-house as inputs to other processes, or marketed to consumers (= behaviors in the external world) at some point. Most processes are simple, but others are sophisticated (second-order) and can assess the ways that different inputs and outputs make the factory's gears grind differently, and adjust operations to compensate. If the outputs are built to spec, all's well; malformed outputs are either rejected on the market or gum up the works when used in-house, depending on what they are and what they're supposed to do.</p>\n<p>There are lots of simple ways that factories can run badly: the processes are obsolete, there aren't enough doo-dads available when the machinery requires doo-dads to run, or someone puts sprockets in the chute clearly marked \"COGS ONLY\". But there are also systematic ways that production can be inefficient.</p>\n<p>Suppose that some processes take objects and project their image, via a lens, onto a photosensitive site that controls the specifications of whatever that process outputs. If the lens is sufficiently good, there's no problem. If the lens has severe aberrations...well, it depends. Some processes may not be sensitive to the distortions that the lens imposes, so there is no practical effect. Other processes will output different objects than they otherwise would have due to the lens' distortion. Those malformed objects may be destined for the market, where consumers may or may not be sensitive to the malformation, or they may be inputs to other processes which are not sensitive to the malformation. But for those processes that ARE sensitive to it...if THEIR malformed outputs feed into processes that are also sensitive to it...and THEIR outputs do as well...there's a potential for some serious industrial mishaps.</p>\n<p>How would you, the factory owner, assess whether such a problem exists? Perhaps there's a camera that feeds into a CCTV display in the main office, and you could have it point at the objects being generated, inspect them, and make an assessment. If you see that the objects are not built to spec, you can inspect the machinery, and, finding the junky lenses, replace them. Sounds good...unless...the camera was built in-house with a lens that also produces a distorted image. That's a more complicated problem.</p>\n<p>If the camera's image looks distorted on the screen, you can always stop the production lines and take a look with your own two eyes, bypassing the camera and its problems.</p>\n<p>Unfortunately, there is no homunculus perched on a chair somewhere in your brain, waiting to spring into action. In our metaphor, the camera's image is input for a second-order process, perhaps a rudimentary AI meant to regulate overall production, cobbled together by some sloppy but effective evolutionary process outside the factory. How likely is it for the AI to consider the possibility of a distorted camera lens? Suppose it's so unsophisticated that it does not even understand that the camera's output is a representation of anything, but assumes the output is direct access to the thing-in-itself? (Imagine that it does not even know that there is a camera, and is built in such a way that it receives the camera's output with the tag \"WHAT's GOING ON AT COORDINATES X,Y,Z\" and nothing else.) If it has no primitive concept of data <em>representing</em> something, and the process by which it receives data from the camera is completely opaque to it, then it may be quite oblivious to the fact that there even is a problem. Even if it responds to natural language, you can type \"MACHINES X AND Y ARE MALFUNCTIONING AND THE CAMERA BY WHICH YOU OBSERVE THEM IS MISLEADING YOU!!!!!1\" on the terminal all day with no guarantee of making headway.</p>\n<p>To fix the problem, the AI needs to be adaptive enough to find a way to conceptualize it in the first place, and, depending on the idiosyncrasies of the evolutionary process that built it and on&nbsp; the degree to which that process selects for AIs that happen to be good at factory control rather than something else, the ways by which it might recognize that there is a problem so that it forms the relevant concepts to deal with it could well be limited.</p>\n<p>Welcome to the human condition.</p>\n<p>&nbsp;</p>\n<p><strong>Building new concepts</strong>.</p>\n<p>Here's a stylized story about how the the AI might manage to figure out that some of the machines it watches over, along&nbsp; with the cameras by which it watches, have lenses that produce distorted images, and these images are leading to production problems.</p>\n<p>Suppose there are multiple cameras it receives data from, and the AI, for whatever reason (perhaps an unintended consequence of something else it's doing) directs them both towards the same machine. Lo and behold, two sources of information tagged \"WHAT'S GOING ON AT COORDINATES X,Y,Z\" are not identical! How strange. Perhaps from this and some adaptive inference it figures out that what representation is and that these data merely represent what's going on at coordinates X,Y,Z. If the camera lenses are only moderately distorting, the AI may point one camera at the other, match the image it sees to an image of a camera in its database, and by doing so, manage to peek into the black box that produces the data by which it monitors the factory. And perhaps now it has an inkling of an idea that, since production has been slower and more problematic than expected, that means <em>something is wrong</em>, despite the fact that all the data it has access to do not allow it to pinpoint any particular problem: because, as it now knows, the data could be inaccurate.</p>\n<p>From here, there are various ways that the AI could discover that something is wrong with the camera lenses. If the distortions aren't uniform over the image the lens produces, it could rotate one camera, un-rotate the output, and see that this is not equivalent to the previous output from an un-rotated camera. Or, knowing the layout and dimensions of the factory, it could aim both cameras at the same location, transform the data from one camera&nbsp; so that in theory it would match the data from the other (given the known positions of the cameras as well as the machines on the factory floor being looked at), and yet find that they did not match. Now it can infer that at least one representation is inaccurate.</p>\n<p>Since the factory makes lenses in-house, to test the hypothesis that one of the cameras' lenses is faulty, the AI could replace one camera's lens with a different one (of unknown quality), and depending on how clever it is and how much it knows about optics, try to work out what the lens aberrations at issue here are. If the malfunctioning machines are the ones that produce lenses, there may be multiple rounds of producing lenses with different kinds or degrees of aberrations, inserting them in the cameras, inspecting the machines, modifying the machines, building new lenses based on the modifications....successively getting closer to the point where it has enough data from the various distorted images it's collected to have managed to produce a lens of sufficiently high quality to</p>\n<ul>\n<li>Accurately observe the previous defective camera lenses,</li>\n<li>Reflect on how those lenses led to faulty information about the machines and their outputs,</li>\n<li>Accurately observe the malformed outputs of the machines,</li>\n<li>Accurately observe the defective lenses inside of the machines,</li>\n<li>Discover the details by which the defective lenses are leading to malformed outputs,</li>\n<li>Deduce a lens design that will not lead to malformed outputs, and</li>\n<li>Build and install such lenses.</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong id=\"What_s_wrong_with_your_mind_\">What's wrong with your mind.</strong></p>\n<p>Understanding that it's an oversimplification, the preceding metaphor is a very good one for describing how human minds works by default with respect to what meditation is good for. Some cognitive processes within the mind have defects that yield distorted outputs. And the second-order processes that evaluate how the first-order processes work are themselves defective, yielding more distorted outputs. All these distorted outputs are fed back into various cognitive processes, where they muck up effective operation in all kinds of ways.</p>\n<p>If I tell you about the defects in your own mind, it is unlikely that you will understand (<em>really</em> understand) what I mean. The first-order processes may be messed up and I could describe that to you, but when you attempt to introspect on their status, the image of those processes that you see is itself distorted. Further, you may not have even developed a concept by which you could understand what the distortion is, or even <em>what it would be like</em> for the outputs of your first- and second-order cognitive processes to be distorted or not distorted in the way I mean. So we would be talking past each other.</p>\n<p>This post was inspired by <a href=\"/lw/5dj/the_benefits_of_madness_a_positive_account_of/\">Skatche's</a>. He writes, parenthetically,</p>\n<p style=\"padding-left: 30px;\">\"[...in] the Buddhist system...the unenlightened mind can't truly understand reality anyway, so you'd best just shut up and meditate.\"</p>\n<p>This is a common impression people have. It's also more or less true. Not because&nbsp; enlightenment is some wild, indescribable altered state of consciousness which people mistake for a glimpse&nbsp; into 'reality,' but because the unenlightened mind probably can't even begin to conceptualize the problem, and definitely doesn't have the tools with which to understand it with sufficient clarity. 8-year-olds typically can't grok higher mathematics, not because mathematicians are tripping balls, but because 8-year-old minds don't have the tools to grasp what mathematicians talk about, and don't have the concepts to understand what it is that there's not grasping. <em>C'est la vie</em>.</p>\n<p>I'm sure you want to hear what the big deal is anyway, so here you go. Your first-order cognitive processes that take experiences as objects are malfunctioning, and output bizarre things such as 'attachment,' 'craving,' and 'hatred.' The second-order cognitive process that monitors them is malfunctioning, and can't see what is so bizarre about those outputs (\"aren't these built to spec?\"). The same process, when monitoring experiences, outputs bizarre things such as 'Self' (and many variations on it). When it takes itself as an object to see its own inner workings, no output is produced, and a function call to the rational inference module asking what process outputted 'Self' yields a variety of confabulated answers (typically 'the senses' or 'rational deduction,' and claimed to be built to spec). When high-level cognitive processes take 'Self' as an object, the outputs are more bizarre objects: for example, 'existential angst,' 'Cartesian dualism,' and so on. From then on, the lives of these malformed objects are variegated: 'existential angst' as an input for the poetry generation process yields a product roundly rejected by consumers, 'attachment' and 'existential angst' as inputs for the life-goal planning process yields questionable long-term plans, and 'Cartesian dualism' as an input into the philosophy of mind process causes a blue screen of death.</p>\n<p>All this happens without you batting an eye, and yet if you reflect in a very general and nonspecific way on whether all these malformed objects are helping or hurting your functioning, and helping or hurting your everyday behavior, you may be able to see that, at least in some ways, they're gumming up the works. But can you see what's wrong with them? Aren't they built to spec? Don't you need them in order to lead a normal life?</p>\n<p>You may be quick to say that you have a perfectly good meaning in mind when you say 'Self.' Either 'Self' is a matter of definition and can be defined innocuously, or better yet, describes the behavior of biological systems in a useful and accurate way---<a href=\"/lw/o0/where_to_draw_the_boundary/\">carving reality at the joints</a>. So it is not a delusion, and anyone who says otherwise is...well...deluded.</p>\n<p>Well, bull. You have at least <em>two</em> concepts, Self and Self*. What you are describing, what carves reality at the joints, is Self*, an output of the rational thought process. Because your lens distorts, Self and Self* look indistinguishable to you. When you make a function call to ask what process outputs [Self or Self*, since they look the same to you], the answer you invariably get is 'rational thought.' \"See,\" you think, \"no delusion!\" as you happily feed Self into the processes that generate attachment, craving, hatred, existential angst, etc. etc. from it, <em>even when</em> <em>Self* is not an input that would produce those outputs.</em></p>\n<p>The rationally-derived concept Self2 that you use doesn't and <em>couldn't</em> play the role in your mental machinery that it seems to. When you were young, before you were mature enough to form the concept Self*, you had attachment, craving, and so on. Today, you still do. How likely is it that Self* is responsible for those things right now? When you feel, deep down in your bones, that <em>you</em> want something--sex, drugs, money, status, friendship, happiness, anything--what is the 'you' who appears to want it? Self*? Knowing what you know about human minds, human development and comparative neurophysiology, is the 'you' who appears to want it the kind of thing that is likely to be the output of a rational process?</p>\n<p>Think about it. See if you can begin to form a new concept that better captures what could be going on in your mind.</p>\n<p>This metaphor is just illustrative. If it doesn't make sense to you on some level, I know of no argument that will be able to change that. If, for example, you have the intuitive feeling that you are a homunculus experiencing the output of your brain and yet rationally know that that's not true, the tension between the two may be a starting point for you. Or if you've had experiences where your sense of self was altered in radical ways, you may be able to see that there's more to the way you normally conceive of the world in relation to you than first meets the eye.</p>\n<p>But it isn't irrational for this not to make sense. If it doesn't make sense, you simply haven't built the right concepts and tools yet to allow it to make sense. Being ill-equipped is not a matter of irrationality. It's a simple problem that you can solve if you're motivated to.</p>\n<p>Whichever case best describes you, I claim you can build the concepts and tools you need to understand this through meditation. If you're interested, you can do the experiment yourself, and see what happens.</p>\n<p>&nbsp;</p>\n<p><strong id=\"How_meditation_works_\">How meditation works.</strong></p>\n<p>Meditation, at least meditation for the goal I've described, can be thought of as a series of attentional and perceptual exercises. Experience has shown that directing your attention and perception in particular ways will help you to begin to see the ways in which your cognitive machinery is distorted. As in the metaphor, you eventually need to build new lenses in order to get a handle on what's going on, but luckily, you don't need to know their specs or retrofit your cognitive machinery; if you do the exercises, neuroplasticity will handle those parts for you.</p>\n<p>EDITED FOR CLARITY: There are a range of \"attentional and perceptual exercises\" (= meditation styles) that are effective, but it important to note that not all are especially effective,&nbsp; and more importantly, a couple tend to work <em>really well</em> compared to the rest. Common kinds of meditation instructions, such as \"relax, follow your breath, and cultivate equanimity towards whatever thoughts arise without getting involved with them\", are unfortunately not the kinds of instructions that have an especially good track record among typical meditators. At least with respect to attaining the kind of insight under discussion. Such instructions do seem to work very well for helping people to be relaxed and less overemotional, though. More details in Part 2.</p>\n<p>Experience shows that doing the exercises will cause your mind to generate various new lenses with different aberrations (there are various ways to categorize how many different types), and as your mental processes adapt to the output that these aberrations engender, you gain more and more data with which you can piece together the ways in which these distorted outputs have misled you. When you have enough data, your mind is able to produce a lens that it <em>strictly less distorting</em> than everything that came before. Retrofitting everything with this new type of lens makes your life better, and it makes the exercises easier. As you continue the exercises and cycle through new lenses, eventually your mind is able to repeat the feat, and make a lens that is strictly less distorting than in the previous case. On and on.</p>\n<p>The first time you generate and use a lens that is strictly less distorting, you are partially enlightened.</p>\n<p>When you have generated and installed a lens that does not distort in ways that lead to attachment, you are fully enlightened.</p>\n<p>These results do not depend on any effort to maintain, and they are not altered states of consciousness. The goal of this type of meditation is not to produce any particular mental state, but to fix your cognitive machinery. When it's fixed, it's fixed. Experience has shown that no maintenance is required.</p>\n<p>Unlike what popular mythology says, this process need not take a lifetime, or half of a lifetime, and definitely doesn't require that you live on a mountaintop in the Himalayas. Bearing in mind that individual variation exists, contemporary methods can yield deep and powerful cognitive upgrades along these lines within a few years. Many people are able to reach what is considered to be the first partial stage of enlightenment within <em>months</em>, in the context of a dedicated and regular practice during their daily life, and this is not considered especially atypical.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Benefits_\">Benefits.</strong></p>\n<p>The reasons you might pursue this kind of mental upgrade are individual---just as in every other case. I don't have THE REASON that this is important for you to do. But here are a selection that you as an individual might find compelling.</p>\n<ul>\n<li>Be happier; function better.</li>\n</ul>\n<p>When you begin to cut off the automatic generation of attachment, craving, hatred, etc., those things get used less as inputs to other mental processes: your life will likely become a more fun, more carefree, and more worthwhile experience. As you begin to cut off the generation of the concept Self by second-order processes, it gets used less as inputs to higher-level cognitive processes: you will think more clearly about existential issues of all kinds.</p>\n<ul>\n<li>Know what your goals would be if you were more insightful.</li>\n</ul>\n<p>It's easy to think about what you want, and build a plan for your life around what you think you want. But your ability to know what you want is curtailed by the fact that you have delusions about what 'you' means. If you begin to get rid of the delusions by beginning to cut off the flow of Self into various processes, you will be in a better position to decide on how to live your life. Imagine you could get a&nbsp; pre-Friendly AI glimpse into CEV; might that change your current goals? What would a glimpse of your own, private extrapolated volition be worth to you? What would you do to get such a glimpse?</p>\n<ul>\n<li>Be more rational.</li>\n</ul>\n<p>As you do the attentional and perceptual exercises involved in meditation, you develop a less and less distorted view of your own mental processes. This eventually allows you to fix any processes that are systematically malfunctioning due to the want of non-distorting components. But as a side effect, it also lets you see an enormous selection of what's going on in your mind: lots of things that you might not have previously noticed, or that you would have previously called '\"subconscious,\" may become effortlessly clear to you.</p>\n<p>Suppose you are biased against non-degreed people, and one day, a high school dropout tells you something that you currently disbelieve. If the thought \"he doesn't know anything, he has no education!\" arose in your mind, you might not normally even notice it, or you might delusively attribute the thought to 'you' and then be invested in acting according to it and defending it (since it's 'yours,' or since 'you' thought it). As your mental processes snap into focus, it's much easier to see the thought, and regard it as 'a thought' rather than 'my thought' or 'my belief' or 'mental content I generated'. When your mind can't sweep it under the carpet and yet you have no special attachment to it, it is easy to face it explicitly and decide how to work with it. If you already have the motivation, accounting for and dealing with your own cognitive biases is likely to become much simpler and easier than before.</p>\n<ul>\n<li>Understand the origin of delusive intuitions.</li>\n</ul>\n<p>One example. Many people have the intuition that they have free will, i.e. that they are homunculi controlling their bodies and minds in a way that is outside the normal laws of physics. Even those of us who know better may still have that feeling. Meditation can ultimately eliminate that feeling. Undercutting the intuition and seeing where that leaves the rational case for free will, from a first-person perspective, may be very informative for understanding other cases in which your intuitions are misleading you by corrupting your rational thought.</p>\n<ul>\n<li>Understand the limits of your own conceptual apparatus.</li>\n</ul>\n<p>The space of potential minds is huge; the space of human-like minds is a tiny subset of it. You may believe that your human mind cannot really conceive of what other potential minds would be like if they were sufficiently different, but do you <em>know</em> that in your bones? The result of meditation is a mind that is well within the space of human-like minds...but you will not be able to imagine what having that kind of mind is like until you have it. That puts potential alien minds and AIs, or rather, your ability to imagine them with any sort of accuracy, into perspective.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Risks_\">Risks.</strong></p>\n<p>It is extremely important to realize that the process of replacing the lenses of your mental processes can lead to intense mental turmoil, potentially severe enough that it impacts your ability to function effectively for weeks, months, or even years. This does not happen to everyone, and it need not be severe when it does happen, but you should consider the degree to which you're committed to this <em>before you start</em>. I would recommend not starting at all unless you are willing to see it through and not give up just because it seems to have made things temporarily suck: experience has shown that giving up while things suck is a great way to make things suck for a <em>long</em> time. (And experience has shown that commitment helps to avoid this problem.)</p>\n<p>It is also important to realize that this is an experiment in self-transformation. Past a certain point, there is no going back, and no undo button. As a matter of informed consent, you need to know that the style of meditation that leads to the goal I've described can and will change the functioning of your brain, permanently. Lots of people have found these changes worthwhile. That doesn't mean there's no need to think about what you're about to do before you do it.</p>\n<p>More information forthcoming in Part 2. (Perhaps next week.)</p>\n<p>&nbsp;</p>\n<p><strong id=\"Addendum_\">Addendum.</strong></p>\n<p>I have made all kinds of claims in this post, some of which may be seen as wild, reckless, unfounded, unargued-for, and so on. Certainly I'm not doing very much hedging and qualification. The really remarkable thing that communities interested in this kind of human development have discovered is that people who work at meditation long enough will reliably and regularly say the same kinds of things, in the same order; and people who have stumbled onto the exercises that lead to this kind of development <em>outside of these communities</em> will also, reliably and regularly, say the same kinds of things (although some translation between cultural frameworks may have to go on first). Further. I have not known anyone to suffer from a deficit in rationality or in the ability to observe and assess themselves by practicing meditation in the way that leads to this kind of development. So my working hypothesis is:</p>\n<ul>\n<li>Certain styles of meditation lead to <em>bona fide</em> insight, and there is a consensus on what that insight is among people who meditate in those styles; anyone with the same cultural background (e.g. contemporary Westerners) who takes up meditation is likely to experience that insight and describe it a way that is broadly similar to everyone else's description, whether or not they are primed to do so by the discourse of the communities of which they are members.</li>\n</ul>\n<p>I hope that exposing readers of Less Wrong to this information will help me to confirm or deny this hypothesis. More importantly, I'm also sharing the information that I am because I hope that learning about it will ultimately help people to benefit personally from it, as I have.</p>\n<p>Also, please note that my metaphor of a factory is just a metaphor, intended to be intuitive and helpful, not intended to be anything like a precise and thorough description of how minds work or how meditation changes how minds work.</p>\n<p>Finally, this was written as a blog post, not a final draft of a formal article. Criticisms related to tone and style are especially welcomed. And apologies in for the length of the piece, as well as any formatting issues it has (I have little experience with effective formatting for blogs.)</p>", "sections": [{"title": "Why meditate?", "anchor": "Why_meditate_", "level": 1}, {"title": "What's wrong with your mind.", "anchor": "What_s_wrong_with_your_mind_", "level": 1}, {"title": "How meditation works.", "anchor": "How_meditation_works_", "level": 1}, {"title": "Benefits.", "anchor": "Benefits_", "level": 1}, {"title": "Risks.", "anchor": "Risks_", "level": 1}, {"title": "Addendum.", "anchor": "Addendum_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "123 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 123, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3diLhMELXxM8rFHJj", "zPJE7MDtL25RpN7Cc", "d5NyJ2Lf6N22AD9PB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-29T01:04:38.551Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Outside the Laboratory", "slug": "seq-rerun-outside-the-laboratory", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:38.223Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DfEBucFwdAfRzNCbB/seq-rerun-outside-the-laboratory", "pageUrlRelative": "/posts/DfEBucFwdAfRzNCbB/seq-rerun-outside-the-laboratory", "linkUrl": "https://www.lesswrong.com/posts/DfEBucFwdAfRzNCbB/seq-rerun-outside-the-laboratory", "postedAtFormatted": "Friday, April 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Outside%20the%20Laboratory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Outside%20the%20Laboratory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfEBucFwdAfRzNCbB%2Fseq-rerun-outside-the-laboratory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Outside%20the%20Laboratory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfEBucFwdAfRzNCbB%2Fseq-rerun-outside-the-laboratory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfEBucFwdAfRzNCbB%2Fseq-rerun-outside-the-laboratory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<p>Today's post, <a href=\"/lw/gv/outside_the_laboratory/\">Outside the Laboratory</a> was originally published on 21 January 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Written regarding the proverb \"Outside the laboratory, scientists are no wiser than anyone else.\" The case is made that if this proverb is in fact true, that's quite worrisome because it implies that scientists are blindly following scientific rituals without understanding why. In particular, it is argued that if a scientist is religious, they probably don't understand the foundations of science very well.</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/gu/some_claims_are_just_too_extraordinary/\">Some Claims Are Just Too Extraordinary</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DfEBucFwdAfRzNCbB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.08143469853974e-07, "legacy": true, "legacyId": "7102", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["N2pENnTPB75sfc9kb", "fXbRhjz3yEF9DLJfE", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-29T01:48:23.091Z", "modifiedAt": null, "url": null, "title": "Extremely Important Cell Phone Feature Missing", "slug": "extremely-important-cell-phone-feature-missing", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:52.948Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aqBtDtv3gTRGZxjkp/extremely-important-cell-phone-feature-missing", "pageUrlRelative": "/posts/aqBtDtv3gTRGZxjkp/extremely-important-cell-phone-feature-missing", "linkUrl": "https://www.lesswrong.com/posts/aqBtDtv3gTRGZxjkp/extremely-important-cell-phone-feature-missing", "postedAtFormatted": "Friday, April 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Extremely%20Important%20Cell%20Phone%20Feature%20Missing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExtremely%20Important%20Cell%20Phone%20Feature%20Missing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaqBtDtv3gTRGZxjkp%2Fextremely-important-cell-phone-feature-missing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Extremely%20Important%20Cell%20Phone%20Feature%20Missing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaqBtDtv3gTRGZxjkp%2Fextremely-important-cell-phone-feature-missing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaqBtDtv3gTRGZxjkp%2Fextremely-important-cell-phone-feature-missing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 291, "htmlBody": "<p>Regular cell phones are so useful and have become so cheap that they have quickly become nearly a human universal. Smartphones are steadily getting cheaper and more common, and will soon be universal, even in very poor areas. The features present in this generation of phones will have major effects on the course of future events, just as the features of previous generations did. For example, the inclusion of cameras in cell phones has made many crimes and abuses of power harder to get away with. But there is a feature missing, an <em>extremely important</em> feature.</p>\n<p>Consumer cell phones cannot send messages to satellites, not even emergency text messages, not even in a disaster area which major powers have decided to point all their antennas at, not even if you're willing to spend your whole battery on transmit power.</p>\n<p><em>This is unacceptable</em>. This is the difference between life and death in a wide variety of disaster scenarios, some of which are definitely going to happen. This is the difference between rescuers following GPS coordinates, and rescuers searching blindly. This is the difference between rescuers that leave immediately and rescuers that wait for a missing person report. <em>This could be the difference between a genocide going unreported, and being deterred</em>. Sending short messages from cell phones to satellites is technically feasible, although will require of coordination between cell phone makers and satellite owners and it may require launching new hardware into orbit. I do not believe that it would increase the cost of the phones themselves by much. This should work worldwide, and it should also be part of the United States FCC's Enhanced 911 requirements.</p>\n<p>Many lives depend on this getting done. This affects existential risk. Who has the connections to make it happen?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aqBtDtv3gTRGZxjkp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 1, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "7103", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-29T06:39:05.661Z", "modifiedAt": null, "url": null, "title": "Harry Sue and The Methods of Rationality", "slug": "harry-sue-and-the-methods-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:42.696Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tiiba", "createdAt": "2009-02-27T06:55:57.544Z", "isAdmin": false, "displayName": "Tiiba"}, "userId": "FngsS7fwH2r3ikxTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Nz2CoXy5R4ePpB5Q3/harry-sue-and-the-methods-of-rationality", "pageUrlRelative": "/posts/Nz2CoXy5R4ePpB5Q3/harry-sue-and-the-methods-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/Nz2CoXy5R4ePpB5Q3/harry-sue-and-the-methods-of-rationality", "postedAtFormatted": "Friday, April 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harry%20Sue%20and%20The%20Methods%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarry%20Sue%20and%20The%20Methods%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNz2CoXy5R4ePpB5Q3%2Fharry-sue-and-the-methods-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harry%20Sue%20and%20The%20Methods%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNz2CoXy5R4ePpB5Q3%2Fharry-sue-and-the-methods-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNz2CoXy5R4ePpB5Q3%2Fharry-sue-and-the-methods-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 286, "htmlBody": "<p>I've been hearing about this fic for a long time, and I've been somewhat suspicious of it. I knew that Eliezer is a pretty good writer, but that his attempts to graft Bayes onto his characters are invariably rather inorganic. On top of that, OOC is irritating to me even when I expect it.</p>\r\n<p>Nothing, however, prepared me for this. I just got done reading chapter 6. Up to this point, Harry's greatest sin was dumping a Less Wrong post onto poor Minerva every ten minutes. And she understood everything, including pop culture references (when in the books, most wizards don't comprehend rubber ducks).</p>\r\n<p>Now, in this chapter, Harry thought he heard a strange note in the prof's voice, decided in a split second that she's trying to destroy his parents, and informed her of this suspicion in the form of a hissy fit. Then he started blackmailing her, and finished by implying that she's a nearsighted idiot, but it's alright, most people are. And he started calling her McGonnagal, then switched to Minerva, and is now planning on Minny for the future. I expected her to snap at some point and beat him to a pulp with the first heavy object that presents itself.</p>\r\n<p>I read the reviews pertaining to that chapter. They all proclaimed it to be a masterpiece, the standard by which all other fiction should be measured. To me, it was what people call \"epic fail\". I cannot find any other way to describe my reaction. Calling it terrible just doesn't have that drop of vitriol that I think is necessary.</p>\r\n<p>But this is Eliezer Yudkowsky. I KNOW he can write. I KNOW that he can detect and neutralize a Black Hole Sue. And yet...</p>\r\n<p>Does he?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Nz2CoXy5R4ePpB5Q3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 49, "baseScore": -10, "extendedScore": null, "score": -1.5e-05, "legacy": true, "legacyId": "7110", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-29T16:39:39.385Z", "modifiedAt": null, "url": null, "title": "What do you mean by \"wrong\", in the moral sense?", "slug": "what-do-you-mean-by-wrong-in-the-moral-sense", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "zaph", "createdAt": "2009-03-09T16:48:24.816Z", "isAdmin": false, "displayName": "zaph"}, "userId": "j6gu6vjBnANKCcfsR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N2HfF2gwC7XJ2LztX/what-do-you-mean-by-wrong-in-the-moral-sense", "pageUrlRelative": "/posts/N2HfF2gwC7XJ2LztX/what-do-you-mean-by-wrong-in-the-moral-sense", "linkUrl": "https://www.lesswrong.com/posts/N2HfF2gwC7XJ2LztX/what-do-you-mean-by-wrong-in-the-moral-sense", "postedAtFormatted": "Friday, April 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20do%20you%20mean%20by%20%22wrong%22%2C%20in%20the%20moral%20sense%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20do%20you%20mean%20by%20%22wrong%22%2C%20in%20the%20moral%20sense%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN2HfF2gwC7XJ2LztX%2Fwhat-do-you-mean-by-wrong-in-the-moral-sense%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20do%20you%20mean%20by%20%22wrong%22%2C%20in%20the%20moral%20sense%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN2HfF2gwC7XJ2LztX%2Fwhat-do-you-mean-by-wrong-in-the-moral-sense", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN2HfF2gwC7XJ2LztX%2Fwhat-do-you-mean-by-wrong-in-the-moral-sense", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 176, "htmlBody": "<p>I've been reading through the recent discussions on morality here, and I wanted to ask about how people are using the word \"wrong\". Something I've read here (I don't recall the specific post or comment) discussed how someone could be rationally wrong, say thinking 2+2=5, and that's equivalent to being morally wrong, say committing an unprovoked violent act. Now, I won't pretend that I don't agree with both statements, but the word \"wrong\" to me is referring to different things in my mind. In the first case, it means the answer, assuming base 10, etc., is incorrect. Whether or not math has some platonic reality outside of people's minds, or is a construction we have, in that system, the answer isn't correct, given all the other points that are assumed to be true. When it comes to the wrongness of a violent act, however, it's completely different. I think it's wrong to inflict pain for no reason. I don't have a list of axioms of why that's the case, and I don't think I need one.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N2HfF2gwC7XJ2LztX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "7114", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-29T21:26:52.662Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Politics is the Mind-Killer", "slug": "seq-rerun-politics-is-the-mind-killer", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:25.866Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/shomaNHiik6jonZSF/seq-rerun-politics-is-the-mind-killer", "pageUrlRelative": "/posts/shomaNHiik6jonZSF/seq-rerun-politics-is-the-mind-killer", "linkUrl": "https://www.lesswrong.com/posts/shomaNHiik6jonZSF/seq-rerun-politics-is-the-mind-killer", "postedAtFormatted": "Friday, April 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Politics%20is%20the%20Mind-Killer&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Politics%20is%20the%20Mind-Killer%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshomaNHiik6jonZSF%2Fseq-rerun-politics-is-the-mind-killer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Politics%20is%20the%20Mind-Killer%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshomaNHiik6jonZSF%2Fseq-rerun-politics-is-the-mind-killer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshomaNHiik6jonZSF%2Fseq-rerun-politics-is-the-mind-killer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 277, "htmlBody": "<p>Today's post, <a href=\"/lw/gw/politics_is_the_mindkiller/\">Politics is the Mind-Killer</a> was originally published on 18 February 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>People act funny when they talk about politics. In the ancestral environment, being on the wrong side might get you killed, and being on the correct side might get you sex, food or let you kill your hated rival. If you must talk about politics (for the purposes of teaching rationality) use examples from the distant past. Politics is an extension of war by other means. Arguments are soldiers. Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back - providing aid and comfort to the enemy. If your topic legitimately relates to attempts to ban evolution in school curricula, then go ahead and talk about it - but don't blame it explicitly on the whole Republican Party (Democratic/Liberal/Conservative/Nationalist).</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/gv/outside_the_laboratory/\">Outside the Laboratory</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "shomaNHiik6jonZSF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.084922734789443e-07, "legacy": true, "legacyId": "7116", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9weLK2AJ9JEt2Tt8f", "N2pENnTPB75sfc9kb", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-29T21:34:01.049Z", "modifiedAt": null, "url": null, "title": "How hard do we really want to sell cryonics?", "slug": "how-hard-do-we-really-want-to-sell-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:56.988Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Strange7", "createdAt": "2010-02-12T08:30:10.267Z", "isAdmin": false, "displayName": "Strange7"}, "userId": "hKxerxxgheQZCxHsR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6vPwdQFgKzyJa2q9c/how-hard-do-we-really-want-to-sell-cryonics", "pageUrlRelative": "/posts/6vPwdQFgKzyJa2q9c/how-hard-do-we-really-want-to-sell-cryonics", "linkUrl": "https://www.lesswrong.com/posts/6vPwdQFgKzyJa2q9c/how-hard-do-we-really-want-to-sell-cryonics", "postedAtFormatted": "Friday, April 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20hard%20do%20we%20really%20want%20to%20sell%20cryonics%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20hard%20do%20we%20really%20want%20to%20sell%20cryonics%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vPwdQFgKzyJa2q9c%2Fhow-hard-do-we-really-want-to-sell-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20hard%20do%20we%20really%20want%20to%20sell%20cryonics%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vPwdQFgKzyJa2q9c%2Fhow-hard-do-we-really-want-to-sell-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vPwdQFgKzyJa2q9c%2Fhow-hard-do-we-really-want-to-sell-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 181, "htmlBody": "<p>For a lot of serious charitable causes, people expend tremendous resources on 'raising awareness' which probably, on net, accomplishes little or nothing for the cause it nominally supports. For cryonics, though, the technology already exists, the target audience can pay for it themselves, the main obstacle is genuine ignorance and perverse fear-of-death countermeasures.</p>\n<p>The second problem seems intractable, but in the long term we can just let the blind idiot god fix it.</p>\n<p>For the first, have any of the organizations involved considered saving up for, say, a superbowl ad? Or even just some youtube videos. I am imagining it set up as a conversation between two people in, say, an office. The skeptic brings up some plausible-sounding objection (sticking to the saner stuff), which is illustrated by cartoons with the continuing conversation as voiceover.</p>\n<p>See, I talked to a relative of mine, who I respect very highly, on easter. She's planning to get cremated. Mentioned some technical objections which I know have been resolved, but which I couldn't adequately explain on the spot, and didn't know where to point her for the source.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6vPwdQFgKzyJa2q9c", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 10, "extendedScore": null, "score": 7.084943119090656e-07, "legacy": true, "legacyId": "7117", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-29T23:37:19.797Z", "modifiedAt": null, "url": null, "title": "An inflection point for probability estimates of the AI takeoff?", "slug": "an-inflection-point-for-probability-estimates-of-the-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:34.942Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Prismattic", "createdAt": "2010-12-25T22:57:35.560Z", "isAdmin": false, "displayName": "Prismattic"}, "userId": "S374FemeqCtr35dEk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cPfZA6Bz9JEjPrC6B/an-inflection-point-for-probability-estimates-of-the-ai", "pageUrlRelative": "/posts/cPfZA6Bz9JEjPrC6B/an-inflection-point-for-probability-estimates-of-the-ai", "linkUrl": "https://www.lesswrong.com/posts/cPfZA6Bz9JEjPrC6B/an-inflection-point-for-probability-estimates-of-the-ai", "postedAtFormatted": "Friday, April 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20inflection%20point%20for%20probability%20estimates%20of%20the%20AI%20takeoff%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20inflection%20point%20for%20probability%20estimates%20of%20the%20AI%20takeoff%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcPfZA6Bz9JEjPrC6B%2Fan-inflection-point-for-probability-estimates-of-the-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20inflection%20point%20for%20probability%20estimates%20of%20the%20AI%20takeoff%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcPfZA6Bz9JEjPrC6B%2Fan-inflection-point-for-probability-estimates-of-the-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcPfZA6Bz9JEjPrC6B%2Fan-inflection-point-for-probability-estimates-of-the-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<p>Suppose that your current &nbsp;estimate for possibility of an AI takeoff coming in the next 10 years is some probability x. &nbsp;As technology is constantly becoming more sophisticated, presumably your probability estimate 10 years from now will be some y &gt; x. &nbsp;And 10 years after that, it will be z &gt; y. &nbsp;My question is, does there come a point in the future where, assuming that an AI takeoff has not yet happened <em>in spite of</em>&nbsp;much advanced technology, you begin to revise your estimate <em>downward </em>with each passing year? &nbsp;If so, how many decades (centuries) from now would you expect the inflection point in your estimate?&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cPfZA6Bz9JEjPrC6B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 20, "extendedScore": null, "score": 7.085295200997703e-07, "legacy": true, "legacyId": "7118", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-30T04:18:27.772Z", "modifiedAt": null, "url": null, "title": "Question: How many people have tried to optimize rationality outreach?", "slug": "question-how-many-people-have-tried-to-optimize-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:56.076Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zRjAy7mfCksf64RBG/question-how-many-people-have-tried-to-optimize-rationality", "pageUrlRelative": "/posts/zRjAy7mfCksf64RBG/question-how-many-people-have-tried-to-optimize-rationality", "linkUrl": "https://www.lesswrong.com/posts/zRjAy7mfCksf64RBG/question-how-many-people-have-tried-to-optimize-rationality", "postedAtFormatted": "Saturday, April 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Question%3A%20How%20many%20people%20have%20tried%20to%20optimize%20rationality%20outreach%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuestion%3A%20How%20many%20people%20have%20tried%20to%20optimize%20rationality%20outreach%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzRjAy7mfCksf64RBG%2Fquestion-how-many-people-have-tried-to-optimize-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Question%3A%20How%20many%20people%20have%20tried%20to%20optimize%20rationality%20outreach%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzRjAy7mfCksf64RBG%2Fquestion-how-many-people-have-tried-to-optimize-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzRjAy7mfCksf64RBG%2Fquestion-how-many-people-have-tried-to-optimize-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 52, "htmlBody": "<p>There's been some talk about rationality outreach recently. And not so recently. I was just wondering:</p>\n<p>Who has actually tried to optimize for rationality outreach?</p>\n<p>I think Jasen did it to form the NYC group. That went <a href=\"/lw/4ul/less_wrong_nyc_case_study_of_a_successful/\">well</a>.<br /><br />Are there any other cases/attempts that you know of? How did they go?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zRjAy7mfCksf64RBG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.086098007778363e-07, "legacy": true, "legacyId": "7121", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CsKboswS3z5iaiutC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-30T20:31:22.620Z", "modifiedAt": null, "url": null, "title": "Cryonics Promotional Video Contest -- 10 BTC Prize", "slug": "cryonics-promotional-video-contest-10-btc-prize", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:23.813Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lsparrish", "createdAt": "2010-06-30T19:05:11.515Z", "isAdmin": false, "displayName": "lsparrish"}, "userId": "xgc8giekPig6tYf2X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ojpjGWrBNSSFYiYG8/cryonics-promotional-video-contest-10-btc-prize", "pageUrlRelative": "/posts/ojpjGWrBNSSFYiYG8/cryonics-promotional-video-contest-10-btc-prize", "linkUrl": "https://www.lesswrong.com/posts/ojpjGWrBNSSFYiYG8/cryonics-promotional-video-contest-10-btc-prize", "postedAtFormatted": "Saturday, April 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%20Promotional%20Video%20Contest%20--%2010%20BTC%20Prize&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%20Promotional%20Video%20Contest%20--%2010%20BTC%20Prize%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FojpjGWrBNSSFYiYG8%2Fcryonics-promotional-video-contest-10-btc-prize%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%20Promotional%20Video%20Contest%20--%2010%20BTC%20Prize%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FojpjGWrBNSSFYiYG8%2Fcryonics-promotional-video-contest-10-btc-prize", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FojpjGWrBNSSFYiYG8%2Fcryonics-promotional-video-contest-10-btc-prize", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 551, "htmlBody": "<p>There was recently a <a href=\"/r/discussion/lw/5hp/how_hard_do_we_really_want_to_sell_cryonics\">proposal</a> that we should create YouTube commercials for cryonics. This is an area where the cryonics community is sorely lacking fresh content, and which in my opinion has higher leverage per unit effort relative to other kinds of content, for making the kinds of cultural changes that need to be made for cryonics to gain acceptance.</p>\n<p>One <span class=\"author-g-gmkq289h7qvieu3m\">important strategy t</span>o <a href=\"/lw/3w3/how_to_beat_procrastination/\">beat procrastination</a>, <span class=\"author-g-gmkq289h7qvieu3m\">is to turn ideas into concrete action <em>quickly</em> rather than <a href=\"http://sivers.org/zipit\">talking</a> about them for too long. Another is to raise the amount of positive feedback a person expects to receive. <a href=\"/r/discussion/lw/35o/100_for_the_best_article_on_efficient_charity/\">Prizes</a> have been used successfully in the past for the promotion of creative efforts with considerable success, and I have long thought that this would work for cryonics promotions as well. It's time for a simple empirical test.<br /></span></p>\n<p>To get things started, I am offering the nominal sum of <strong>10 <a href=\"/lw/4mc/singularity_institute_now_accepts_donations_via/\">bitcoins</a></strong><sup>1</sup> as a prize to whoever creates the the most \"liked\" promotional or educational video for cryonics on YouTube for the month of May, 2011. If anyone wishes to contribute to the prize and thus increase its size, send bitcoins here: <strong>&lt;removed&gt;</strong></p>\n<p><em>All funds sent to the above address will be transferred to the address of the person whose YouTube video promoting cryonics receives the most \"likes\" on YouTube during the month of May. Donors who let me know that they have donated will be given credit for donating below.<br /></em></p>\n<ul>\n<li><strong>Start date: May 1, 2011 at 12:00 AM GMT. </strong>Entry video cannot have been released on <a href=\"http://www.youtube.com/\">YouTube</a> sooner than this.</li>\n<li><strong>End date: </strong><strong>June 1, 2011 at 12:00 AM GMT.</strong> This is when the votes (likes) will be tallied and the prize awarded.</li>\n<li>Video must <strong>promote cryonics</strong> and/or <strong>answer common questions about cryonics</strong>.</li>\n<li>Multiple submissions per person are allowed and encouraged, as are collaborations<sup>2</sup>.</li>\n<li>Xtranormal videos, slide shows, stick figure cartoons, voice-overs, and anything else that can go in a YouTube video are acceptable.</li>\n<li>Winner must have or obtain a <strong>bitcoin address</strong><sup>3</sup>, and must let us know what it is along with a link to their video (which must be posted to YouTube) in the comments section of this post.</li>\n<li>In the event that there are multiple videos with substantially similar numbers of likes (to within 1% of the top number) at midnight of June first, they will all be treated as co-winners and receive equal shares of the prize.</li>\n</ul>\n<p>Anyone who wants to donate to non-winning entries that they liked is welcome to do so as well (the bitcoin address of each entry will be visible below).</p>\n<p>Let the games begin!</p>\n<hr />\n<ol>\n<li>These are a digital commodity that I thought would make a more fun and interesting prize than dollars, and seem to have a positive reputation on LW so far. It is also easy for me to keep track of. Market value was about $4 per bitcoin as of April 31.</li>\n<li>One bitcoin address per video please. Teams are responsible for divvying up the prize money among members.</li>\n<li>The simple way is to create an account on <a href=\"https://www.mybitcoin.com/\">MyBitcoin</a>. You can also install the Bitcoin <a href=\"http://www.bitcoin.org/\">client</a>.</li>\n</ol> \n<hr />\n<p>Current prize fund (to be updated): <strong><span class=\"strong\">14.75 BTC</span></strong> (103.29 USD @ 7.003)</p>\n<p>Donors known so far:</p>\n<ul>\n<li>drethelin</li>\n<li>Pavitra</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ojpjGWrBNSSFYiYG8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 20, "extendedScore": null, "score": 7.088877518471393e-07, "legacy": true, "legacyId": "7126", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6vPwdQFgKzyJa2q9c", "RWo4LwFzpHNQCTcYt", "4amcyxad5bnBR9Afm", "jLAw6dPGZCRnpNgxM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-30T21:04:56.019Z", "modifiedAt": null, "url": null, "title": "Phoenix Less Wrong Meetup- Saturday, 5-7-11, 5pm", "slug": "phoenix-less-wrong-meetup-saturday-5-7-11-5pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.379Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Danny_Hintze", "createdAt": "2010-12-04T23:01:40.826Z", "isAdmin": false, "displayName": "Danny_Hintze"}, "userId": "2fHm6t2WFDMPShg5b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/secqWCtdaeLXCwprW/phoenix-less-wrong-meetup-saturday-5-7-11-5pm", "pageUrlRelative": "/posts/secqWCtdaeLXCwprW/phoenix-less-wrong-meetup-saturday-5-7-11-5pm", "linkUrl": "https://www.lesswrong.com/posts/secqWCtdaeLXCwprW/phoenix-less-wrong-meetup-saturday-5-7-11-5pm", "postedAtFormatted": "Saturday, April 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Phoenix%20Less%20Wrong%20Meetup-%20Saturday%2C%205-7-11%2C%205pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhoenix%20Less%20Wrong%20Meetup-%20Saturday%2C%205-7-11%2C%205pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsecqWCtdaeLXCwprW%2Fphoenix-less-wrong-meetup-saturday-5-7-11-5pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Phoenix%20Less%20Wrong%20Meetup-%20Saturday%2C%205-7-11%2C%205pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsecqWCtdaeLXCwprW%2Fphoenix-less-wrong-meetup-saturday-5-7-11-5pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsecqWCtdaeLXCwprW%2Fphoenix-less-wrong-meetup-saturday-5-7-11-5pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p><a id=\"more\"></a>We're excited to have a second Phoenix meetup. As always, absolutely anyone is welcome. This time we'd like to change the location to the Barrett Honors College Dining Hall at ASU (It's extremely nice and has excellent food). I'll be there from 5 to 7 on Saturday and have a copy of Godel, Escher, Bach on the table.&nbsp;</p>\n<p>The address is&nbsp;698-798 Apache Blvd E, Tempe, AZ, and&nbsp;<a title=\"here\" href=\"http://maps.google.com/maps?hl=en&amp;sugexp=ldymls&amp;xhr=t&amp;cp=4&amp;qe=YmFycg&amp;qesig=pWPtqlamH8X5P4pKsKG47w&amp;pkc=AFgZ2tkKdTURUtCFvtYlSxwxPvX_5e-TKjnfeHvbI4qmASYsBgFaxmctl29qMwS_EOxbzGVfB2i6bR8MmejPryWF6zMj5HEkew&amp;bav=on.2,or.r_gc.r_pw.&amp;um=1&amp;ie=UTF-8&amp;q=barrett+honors+college&amp;fb=1&amp;gl=us&amp;hq=barrett+honors+college&amp;hnear=Tempe,+AZ&amp;cid=0,0,3636504416240652798&amp;ei=I3S8TZLcHpOksQOSh_nYBQ&amp;sa=X&amp;oi=local_result&amp;ct=image&amp;resnum=2&amp;sqi=2&amp;ved=0CCkQnwIwAQ\">here</a>&nbsp;it is on a map. The parking garage on Lemon is probably ideal, Barrett is south of that.&nbsp;</p>\n<p>My phone number is 602-501-9420, feel free to call or text me.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "secqWCtdaeLXCwprW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.08897202727595e-07, "legacy": true, "legacyId": "7097", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-30T22:15:06.002Z", "modifiedAt": null, "url": null, "title": "META: application for adminship on the wiki", "slug": "meta-application-for-adminship-on-the-wiki", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:09.138Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/c2q3nMwem3dnG7Bso/meta-application-for-adminship-on-the-wiki", "pageUrlRelative": "/posts/c2q3nMwem3dnG7Bso/meta-application-for-adminship-on-the-wiki", "linkUrl": "https://www.lesswrong.com/posts/c2q3nMwem3dnG7Bso/meta-application-for-adminship-on-the-wiki", "postedAtFormatted": "Saturday, April 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20META%3A%20application%20for%20adminship%20on%20the%20wiki&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMETA%3A%20application%20for%20adminship%20on%20the%20wiki%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc2q3nMwem3dnG7Bso%2Fmeta-application-for-adminship-on-the-wiki%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=META%3A%20application%20for%20adminship%20on%20the%20wiki%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc2q3nMwem3dnG7Bso%2Fmeta-application-for-adminship-on-the-wiki", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc2q3nMwem3dnG7Bso%2Fmeta-application-for-adminship-on-the-wiki", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 228, "htmlBody": "<p>So, as people have probably noticed, there's fairly regular vandalism on the LW wiki which has been taking a while to address and which regular users have been trying to cope with by moving and blanking pages. This is a little silly - it doesn't resolve the problem and just generates more noise in the RSS feed for Recent Changes (to which I've long subscribed).</p>\n<p>We need more administrators.</p>\n<p>I suggest <a href=\"http://wiki.lesswrong.com/wiki/User:Gwern\">myself</a>. I'm a longtime LWer with high karma, so I can't be <em>too</em> crazy. More to the point, I currently <a href=\"http://haskell.org/haskellwiki/index.php?title=Special:Log&amp;type=&amp;user=Gwern&amp;page=&amp;pattern=&amp;limit=500&amp;offset=0\">handle vandalism</a> as an administrator on the <a href=\"http://haskell.org/haskellwiki/Haskell\">Haskell wiki</a> and have done so ~July 2010; I was formerly an administrator on the English Wikipedia (where I have been a <a href=\"http://www.gwern.net/Wikipedia%20resume\">contributor</a> since ~2005); nor have I abused access that has been given to me elsewhere (eg. my shell account on http://community.haskell.org, the commit bit on the <a href=\"http://predictionbook.com/\">PredictionBook.com</a> repo, etc.). In general, I think of myself as a wiki-savvy and trustworthy guy.</p>\n<p>Administrators are created by bureaucrats; there are currently <a href=\"http://wiki.lesswrong.com/mediawiki/index.php?title=Special:ListUsers&amp;group=bureaucrat\">3</a>. Rather than simply message Yudkowsky or Matt of Trike, I thought I'd make my request public along the line of Wikipedia's <a href=\"http://en.wikipedia.org/wiki/Wikipedia:Requests_for_adminship\">Requests for Adminship</a>.</p>\n<p>If people object, please leave comments; if there are any other users who would like to be admins (<a href=\"http://wiki.lesswrong.com/wiki/User:David_Gerard\">David Gerard</a> comes to mind as someone I know from Wikipedia and would trust as a LW wiki admin), likewise.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "c2q3nMwem3dnG7Bso", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 31, "extendedScore": null, "score": 7.089173957661824e-07, "legacy": true, "legacyId": "7127", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-01T00:54:55.746Z", "modifiedAt": null, "url": null, "title": "Mitigating Social Awkwardness", "slug": "mitigating-social-awkwardness", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.352Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cayenne", "createdAt": "2010-12-27T22:47:02.994Z", "isAdmin": false, "displayName": "Cayenne"}, "userId": "xXoNkpxZ5i5TfDHK8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BjCryxyRraforL2GD/mitigating-social-awkwardness", "pageUrlRelative": "/posts/BjCryxyRraforL2GD/mitigating-social-awkwardness", "linkUrl": "https://www.lesswrong.com/posts/BjCryxyRraforL2GD/mitigating-social-awkwardness", "postedAtFormatted": "Sunday, May 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mitigating%20Social%20Awkwardness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMitigating%20Social%20Awkwardness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBjCryxyRraforL2GD%2Fmitigating-social-awkwardness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mitigating%20Social%20Awkwardness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBjCryxyRraforL2GD%2Fmitigating-social-awkwardness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBjCryxyRraforL2GD%2Fmitigating-social-awkwardness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 774, "htmlBody": "<p>Edit - many apologies to anyone that feels that this discussion was a waste of time. &nbsp;</p>\n<p>&nbsp;</p>\n<p>I just ran across an article (<a href=\"http://techno-anthropology.blogspot.com/2011/04/rough-guide-to-social-skills-for.html\">http://techno-anthropology.blogspot.com/2011/04/rough-guide-to-social-skills-for.html</a>) on Hacker News that gives the barest minimum of a guide for social interaction. Unfortunately this isn't the high-quality advice you need to really handle social situations, though it will help with a few of the worst problems.</p>\n<p>A few other rules that will help:</p>\n<ul>\n<li>Don't intrude on a conversation no matter how stupid or incorrect the arguments on either side are. No matter how you try, you will have turned your attempt to help into an intrusion into their social territory, and they will respond aggressively.</li>\n<li> Don't assume that being smart is the same thing as social authority; seeing that people are going the wrong way and telling them won't work. This is really social territory again, you're trying to take leadership. </li>\n<li> Don't assume that people equate brilliance and desirability. Don't even assume that people can tell that you're brilliant after talking to you for a while. Even if they do, they may not value brilliance. </li>\n<li> Learn to listen to people. Conversations have a natural pause inserted between concepts that is an opportunity for the other person to respond. Do not talk over anyone, instead wait for that pause. Try to stay on the same topic as the previous speaker, or a related topic. Avoid jumping back more than one previous topic without explicitly saying something like \"I had a few more questions about &lt;topic&gt;,\" unless they do it first in the same conversation. </li>\n<li> To have a conversation with someone, ask them about their interests and when you find one that doesn't bore you talk about that. Try very hard not to talk about yourself unless they specifically ask first, and try to focus on what they have to say instead of what you have to say. If you are successful, they will give you opportunities to talk about your insights naturally. Avoid direct challenges; if you disagree then ask a question that exposes a hole, or say \"it seems to me that ...\" </li>\n<li> Conversations share a volume, and speaking at the same volume as someone else is a signal to them that you are part of their conversation. </li>\n<li>Avoid completing other people's words or sentences for them to speed up the conversation.</li>\n<li>If people don't laugh at your joke, don't explain it. Just continue the conversation. Don't be afraid to smile to show you find it funny, but always wait for someone else to laugh at your joke before you join in.</li>\n<li>To become friends with someone, you <em>must</em> have common interests and you must focus on those interests while you're with them. Do not assume that just because someone shares one of your interests that they will share others.</li>\n<li>Most people are not <em>broken</em>, though they are subject to biases. If someone comes to a different conclusion than you do, it probably is not 'stupidity' so much as you seeing a benefit or cost that they do not, or you valuing the benefit or cost differently. This can go both ways; sometimes even someone very shortsighted can have a flash of insight. The only way to know for sure is to ask them about it.</li>\n</ul>\n<p>On the physical side:</p>\n<ul>\n<li>If you have not showered or bathed <em>with soap</em> in the last 24 hours <em>and</em> used deodorant, people will notice. If they do, they will almost never tell you. The same holds true for possible bad breath. The same holds true for clothing: avoid using a shirt two days in a row, change underwear and socks daily, while pants might be able to be reused for up to 5 days if they are not dirty.</li>\n<li>Do not approach within arm's reach (fingertips ourstretched) without them facing you. This is the approximate 'personal space' boundary. As soon as they back up even slightly, stop; you've gotten too close to them. If you find someone constantly edging away from you, adjust that distance upwards.</li>\n<li>If there is no space large enough to accommodate you around the person you wish to talk to, then wait for one or more people to leave first. When calculating this space, assume that each person is as big as their personal space, even if those spaces seem to be overlapping.</li>\n</ul>\n<p>This is a long list, and it isn't even close to complete.</p>\n<p>I'm linking to&nbsp;http://lesswrong.com/lw/372/defecting_by_accident_a_flaw_common_to_analytical/ at the suggestion of David Gerard. &nbsp;It has a lot of deeper discussion into why this is worth knowing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BjCryxyRraforL2GD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 36, "extendedScore": null, "score": 6.3e-05, "legacy": true, "legacyId": "7128", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 162, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-01T06:33:52.080Z", "modifiedAt": null, "url": null, "title": "[Altruist Support] How to determine your utility function", "slug": "altruist-support-how-to-determine-your-utility-function", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:47.543Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Giles", "createdAt": "2011-02-11T02:30:16.999Z", "isAdmin": false, "displayName": "Giles"}, "userId": "H347ba3KZMP8XoDt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FdFa5KYs6CXnFWxq2/altruist-support-how-to-determine-your-utility-function", "pageUrlRelative": "/posts/FdFa5KYs6CXnFWxq2/altruist-support-how-to-determine-your-utility-function", "linkUrl": "https://www.lesswrong.com/posts/FdFa5KYs6CXnFWxq2/altruist-support-how-to-determine-your-utility-function", "postedAtFormatted": "Sunday, May 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BAltruist%20Support%5D%20How%20to%20determine%20your%20utility%20function&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BAltruist%20Support%5D%20How%20to%20determine%20your%20utility%20function%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFdFa5KYs6CXnFWxq2%2Faltruist-support-how-to-determine-your-utility-function%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BAltruist%20Support%5D%20How%20to%20determine%20your%20utility%20function%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFdFa5KYs6CXnFWxq2%2Faltruist-support-how-to-determine-your-utility-function", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFdFa5KYs6CXnFWxq2%2Faltruist-support-how-to-determine-your-utility-function", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1031, "htmlBody": "<p>Follows on from <a href=\"/r/discussion/lw/5gy/help_i_want_to_do_good/\">HELP! I want to do good.</a></p>\n<p><em>What have I learned since last time? I've learned that people want to see an SIAI donation; I'll do it as soon as PayPal will let me. I've learned that people want more \"how\" and maybe more \"doing\"; I'll write a doing post soon, but I've got this and two other background posts to write first. I've learned that there's a nonzero level of interest in my project. I've learned that there's a diversity of opinions; it suggests if I'm wrong, then I'm at least wrong in an interesting way. I may have learned that signalling low status - to avoid intimidating outsiders - may be less of a good strategy than signalling that I know what I'm talking about. I've learned that I am prone to answering a question other than that which was asked.</em></p>\n<p>Somewhere in the Less Wrong archives there is a deeply shocking, disturbing post. It's called <a href=\"/lw/zv/post_your_utility_function/\">Post Your Utility Function.</a></p>\n<p>It's shocking because basically no-one had any idea. At the time I was still learning but I knew that having a utility function was important - that it was what made everything else make sense. But I didn't know what mine was supposed to be. And neither, apparently, did anyone else.</p>\n<p>Eliezer commented 'in prescriptive terms, how do you \"help\" someone without a utility function?'. This post is an attempt to start to answer this question.</p>\n<p>Firstly, what the utility function is and what it's not. It belongs to the field of <a href=\"/lw/31/what_do_we_mean_by_rationality/\">instrumental rationality</a>, not epistemic rationality; it is not part of the <a href=\"http://wiki.lesswrong.com/wiki/Map_and_territory\">territory</a>. Don't expect it to correspond to something physical.</p>\n<p>Also, it's not supposed to model your <a href=\"http://en.wikipedia.org/wiki/Revealed_preference\">revealed preferences</a> - that is, your current behavior. If it did then it would mean you were <em>already perfectly rational</em>. If you don't feel that's the case then you need to look beyond your revealed preferences, toward what you really <em>want</em>.</p>\n<p>In other words, the <em>wrong</em> way to determine your utility function is to think about what decisions you have made, or feel that you would make, in different situations. In other words, there's a chance, just a chance, that up until now you've been doing it completely wrong. You haven't been getting what you wanted.</p>\n<p>So in order to play the utility game, you need <a href=\"/lw/gq/the_proper_use_of_humility/\">humility</a>. You need to accept that you might not have been getting what you want, and that it might hurt. All those little subgoals, they might just have been getting you nowhere more quickly.</p>\n<p>So only play if you want to.</p>\n<p>The first thing is to understand the&nbsp;<a href=\"/lw/116/the_domain_of_your_utility_function/\">domain of the utility function</a>. It's defined over entire world histories. You consider everything that has happened, and will happen, in your life and in the rest of the world. And out of that pops a number. That's the idea.</p>\n<p>This complexity means that utility functions generally have to be defined somewhat <em>vaguely</em>. (Except if you're trying to build an AI). The complexity will also allow you a lot of flexibility in deciding what you really value.</p>\n<p>The second thing is to think about your <em>preferences</em>. Set up some thought experiments to decide whether you prefer <em>this outcome</em> or <em>that outcome</em>. Don't think about what you'd actually do if put in a situation to decide between them; then you will worry about the social consequences of making the \"unethical\" decision. If you value things other than your own happiness, don't ask which outcome you'd be happier in. Instead just ask, <em>which outcome seems preferable?</em>. Which would you consider good news, and which bad news?</p>\n<p>You can start writing things down if you like. One of the big things you'll need to think about is how much you value <em>self</em> versus <em>everyone else</em>. But this may matter less than you think, for reasons I'll get into later.</p>\n<p>The third thing is to think about <em>preferences between uncertain outcomes</em>. This is somewhat technical, and I'd advise a <a href=\"/lw/n3/circular_altruism/\">shut-up-and-multiply</a> approach. (You can try and go against that if you like, but you have to be careful not to end up in weirdness such as getting different answers if you phrase something as one big decision or as a series of identical little decisions).</p>\n<p>The fourth thing is to ask whether this preference system satisfies the <a href=\"/lw/244/vnm_expected_utility_theory_uses_abuses_and/\">von Neumann-Morgenstern</a> axioms. If it's at all sane, it probably will. (Again, this is somewhat technical).</p>\n<p>The last thing is to ask yourself: if I prefer outcome A over outcome B, do I want to act in such a way that I bring about outcome A? (continue only if the answer here is \"yes\").</p>\n<p>That's it - you now have a shiny new utility function. And I want to help you optimize it. (Though it can grow and develop and change along with yourself; I want this to be a speculative process, not one in which you suddenly commit to an immutable life goal).</p>\n<p>You probably don't feel that anything has changed. You're probably feeling and behaving exactly the same as you did before. But this is something I'll have to leave for a later post. Once you start really <em>feeling</em> that you want to maximize your utility then things will start to happen. You'll have <a href=\"/lw/nb/something_to_protect/\">something to protect.</a></p>\n<p>Oh, you wanted to know my utility function? It goes something like this:</p>\n<p><em>It's the sum of the things I value. Once a person is created, I value that person's life; I also value their happiness, fun and freedom of choice. I assign negative value to that person's disease, pain and sadness. I value concepts such as beauty and awesomeness. I assign a large bonus negative value to the extinction of humanity. I weigh the happiness of myself and those close to me more highly than that of strangers, and this asymmetry is more pronounced when my overall well-being becomes low.</em></p>\n<p>Four points: It's actually going to be a lot more complicated than that. I'm aware that it's not quantitative and no terminology is defined. I'm prepared to change it if someone points out a glaring mistake or problem, or if I just feel like it for some reason. And people should not start criticizing my behavior for not adhering to this, at least not <em>yet</em>. (I have a lot of explaining still to do).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FdFa5KYs6CXnFWxq2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 7.090599736972479e-07, "legacy": true, "legacyId": "7132", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qJCPpLXmS9rYemjy7", "MvwdPfYLX866vazFJ", "RcZCwxFiZzE6X7nsv", "GrDqnMjhqoxiqpQPw", "xgicQnkrdA5FehhnQ", "4ZzefKQwAtMo5yp99", "YCMfQoqqi2o9Tjwoa", "SGR4GxFK7KmW7ckCB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-01T18:28:55.986Z", "modifiedAt": null, "url": null, "title": "Sarah Connor and Existential Risk", "slug": "sarah-connor-and-existential-risk", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.119Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wiresnips", "createdAt": "2009-04-21T17:13:52.023Z", "isAdmin": false, "displayName": "wiresnips"}, "userId": "zhwhEJ2a5DNuzcJNg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PtnxA2wD2avx2sGL5/sarah-connor-and-existential-risk", "pageUrlRelative": "/posts/PtnxA2wD2avx2sGL5/sarah-connor-and-existential-risk", "linkUrl": "https://www.lesswrong.com/posts/PtnxA2wD2avx2sGL5/sarah-connor-and-existential-risk", "postedAtFormatted": "Sunday, May 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sarah%20Connor%20and%20Existential%20Risk&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASarah%20Connor%20and%20Existential%20Risk%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPtnxA2wD2avx2sGL5%2Fsarah-connor-and-existential-risk%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sarah%20Connor%20and%20Existential%20Risk%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPtnxA2wD2avx2sGL5%2Fsarah-connor-and-existential-risk", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPtnxA2wD2avx2sGL5%2Fsarah-connor-and-existential-risk", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p>It's probably easier to build an uncaring AI than a friendly one. So, if we assume that someone, somewhere is trying to build an AI without solving friendliness, that person will probably finish before someone who's trying to build a friendly AI.</p>\n<p>[redacted]</p>\n<p>[redacted]</p>\n<p>further edit:</p>\n<p>Wow, this is getting a rather stronger reaction than I'd anticipated. Clarification: I'm not suggesting practical measures that should be implemented. Jeez. I'm deep in an armchair, thinking about a problem that (for the moment) looks very hypothetical.</p>\n<p>For future reference, how should I have gone about asking this question without seeming like I want to mobilize the Turing Police?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PtnxA2wD2avx2sGL5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": -10, "extendedScore": null, "score": -6e-06, "legacy": true, "legacyId": "7138", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-01T20:30:43.049Z", "modifiedAt": null, "url": null, "title": "What would an Incandescence about FAI look like?", "slug": "what-would-an-incandescence-about-fai-look-like", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:47.467Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "VNKKET", "createdAt": "2010-01-20T17:11:59.102Z", "isAdmin": false, "displayName": "VNKKET"}, "userId": "4SRGhXNjeoGxuDQHj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sPxazKhbY3b2Sf7Hv/what-would-an-incandescence-about-fai-look-like", "pageUrlRelative": "/posts/sPxazKhbY3b2Sf7Hv/what-would-an-incandescence-about-fai-look-like", "linkUrl": "https://www.lesswrong.com/posts/sPxazKhbY3b2Sf7Hv/what-would-an-incandescence-about-fai-look-like", "postedAtFormatted": "Sunday, May 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20would%20an%20Incandescence%20about%20FAI%20look%20like%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20would%20an%20Incandescence%20about%20FAI%20look%20like%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsPxazKhbY3b2Sf7Hv%2Fwhat-would-an-incandescence-about-fai-look-like%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20would%20an%20Incandescence%20about%20FAI%20look%20like%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsPxazKhbY3b2Sf7Hv%2Fwhat-would-an-incandescence-about-fai-look-like", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsPxazKhbY3b2Sf7Hv%2Fwhat-would-an-incandescence-about-fai-look-like", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 121, "htmlBody": "<p><strong>This post spoils Greg Egan's <em>Incandescence</em>.</strong></p>\n<p><em>Incandescence</em> is a success story about some people who notice an existential threat and avoid it using science and engineering.&nbsp; We see them figure out how gravity works, which is more interesting than it might sound, partly because their everyday experiences are full of gravitational effects that we don't notice on Earth.&nbsp; At first they do science out of pure curiosity, but it turns into an urgent collective action problem when they discover that their orbit will lead them towards all sorts of disasters, including falling into a black hole.&nbsp; The solution, it turns out, is to move some dirt around.</p>\n<p>Has anyone considered writing a success story about using Friendly AI to solve an existential threat?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sPxazKhbY3b2Sf7Hv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 2, "extendedScore": null, "score": 7.092993097601064e-07, "legacy": true, "legacyId": "7139", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-01T21:08:42.324Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Just Lose Hope Already", "slug": "seq-rerun-just-lose-hope-already", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:49.923Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Za2JJZYsreTh6JmZR/seq-rerun-just-lose-hope-already", "pageUrlRelative": "/posts/Za2JJZYsreTh6JmZR/seq-rerun-just-lose-hope-already", "linkUrl": "https://www.lesswrong.com/posts/Za2JJZYsreTh6JmZR/seq-rerun-just-lose-hope-already", "postedAtFormatted": "Sunday, May 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Just%20Lose%20Hope%20Already&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Just%20Lose%20Hope%20Already%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZa2JJZYsreTh6JmZR%2Fseq-rerun-just-lose-hope-already%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Just%20Lose%20Hope%20Already%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZa2JJZYsreTh6JmZR%2Fseq-rerun-just-lose-hope-already", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZa2JJZYsreTh6JmZR%2Fseq-rerun-just-lose-hope-already", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 244, "htmlBody": "<p>Today's post, <a href=\"/lw/gx/just_lose_hope_already/\">Just Lose Hope Already</a>, was originally published on 25 February 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Casey Serin owes banks 2.2 million dollars after lying on mortgage applications in order to simultaneously buy 8 different houses in different states. The sad part is that he hasn't given up - hasn't declared bankruptcy, and just attempted to purchase another house. While this behavior seems merely stupid, it recalls Merton and Scholes of Long-Term Capital Management who made 40% profits for three years and then lost it all when they overleveraged. Each profession has rules on how to be successful which makes rationality seem unlikely to help greatly in life. Yet it seems that one of the greater skills is not being stupid, which rationality does help with.</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/gw/politics_is_the_mindkiller/\">Politics is the Mind-Killer</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb137": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Za2JJZYsreTh6JmZR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.093101775517936e-07, "legacy": true, "legacyId": "7140", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["waqC6FihC2ryAZuAq", "9weLK2AJ9JEt2Tt8f", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T00:17:12.817Z", "modifiedAt": null, "url": null, "title": "On Being Okay with the Truth", "slug": "on-being-okay-with-the-truth", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:04.450Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3v24wGePcdSGB3i8a/on-being-okay-with-the-truth", "pageUrlRelative": "/posts/3v24wGePcdSGB3i8a/on-being-okay-with-the-truth", "linkUrl": "https://www.lesswrong.com/posts/3v24wGePcdSGB3i8a/on-being-okay-with-the-truth", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Being%20Okay%20with%20the%20Truth&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Being%20Okay%20with%20the%20Truth%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3v24wGePcdSGB3i8a%2Fon-being-okay-with-the-truth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Being%20Okay%20with%20the%20Truth%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3v24wGePcdSGB3i8a%2Fon-being-okay-with-the-truth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3v24wGePcdSGB3i8a%2Fon-being-okay-with-the-truth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 663, "htmlBody": "<p>On January 11, 2007, I timidly <a href=\"http://commonsenseatheism.com/?p=12\">whispered</a> to myself: \"There is no God.\"</p>\n<p>And with that, all my Christian dreams and hopes and purposes and moral systems came crashing down.</p>\n<p>I wrote a defiant email to the host of an <a href=\"http://www.atheist-experience.com/\">atheist radio show</a> I'd been listening to:</p>\n<blockquote>\n<p>I was coming from a lifetime high of surrendering&hellip; my life to Jesus, releasing myself from all cares and worries, and filling myself and others with love. Then I began an investigation of the historical Jesus&hellip; and since then I&rsquo;ve been absolutely miserable. I do not think I am strong enough to be an atheist. Or brave enough. I have a broken leg, and my life is much better with a crutch&hellip; I&rsquo;m going to seek genuine experience with God, to commune with God, and to reinforce my faith. I am going to avoid solid atheist arguments, because they are too compelling and cause for despair. I do not WANT to live in an empty, cold, ultimately purposeless universe in which I am worthless and inherently alone.</p>\n</blockquote>\n<p>I was&nbsp;<em>not</em>&nbsp;okay with the truth. I had been taught that meaning and morality and hope depended on God. If God didn't exist, then life was meaningless.</p>\n<p>My tongue felt like cardboard for a week.</p>\n<p>But when I pulled my head out of the sand, I noticed that millions of people were living lives of incredible meaning and morality and hope without gods. The only thing I had 'lost' was a lie, anyway.</p>\n<p>This <a href=\"http://wiki.lesswrong.com/wiki/Crisis_of_faith\">crisis</a> taught me a lesson: that I could <em>be okay with the truth</em>.</p>\n<p>When I realized that <a href=\"http://wiki.lesswrong.com/wiki/Free_will_(solution)\">I am not an Unmoved Mover</a> of my own actions, I was not much disturbed. I realized that 'moral responsibility' still mattered, because people still had reasons to condemn, praise, punish, and reward certain actions in others. And I realized that I could still deliberate about which actions were likely to achieve my goals, and that this deliberation would affect my actions. Apples didn't stop falling from trees when Einstein's equations replaced Newton's, and humans didn't stop making conscious choices that have consequences when we discovered that we are fully part of nature.</p>\n<p>I didn't freak out when I gave up moral absolutism, either. I had learned to be okay with the truth. Whatever is meant by 'morality', it remains the case that agents have reasons to praise and condemn certain desires and actions in other agents, and that there are more reasons to praise and condemn some actions than others.</p>\n<p>I've gone through <a href=\"/lw/sk/changing_your_metaethics/\">massive reversals</a> in my metaethics <em>twice</em>&nbsp;now, and guess what? At no time did I spontaneously acquire the urge to rape people. At no time did I stop caring about the impoverished. At no time did I want to steal from the elderly. At no time did people stop having reasons to praise or condemn certain desires and actions of mine, and at no time did I stop having reasons to praise or condemn the desires and actions of others.</p>\n<p>We humans have a tendency to 'freak out' when our model of the world changes drastically. But we get over it.</p>\n<p>The love a mother has for her child does not disappear when we explain the brain processes that instantiate that love. Explaining something <a href=\"/lw/oo/explaining_vs_explaining_away/\">is not</a> explaining it <em>away</em>. Showing that love and happiness and moral properties are made of atoms does not mean they are <em>just</em>&nbsp;atoms. They are <em>also</em> love and happiness and moral properties. Water was still water after we discovered which <em>particular</em>&nbsp;atoms it was made of.</p>\n<p>When you understand this, you need not feel the threat of <a href=\"/lw/sc/existential_angst_factory/\">nihilism</a> as science marches on. Instead, you can jump with excitement as science <em>locates</em>&nbsp;everything we care about in the natural world and tells us how it works. Along the way, you can take <a href=\"/lw/or/joy_in_the_merely_real/\">joy in the<em>&nbsp;</em>merely real</a>.</p>\n<p>Whenever you 'lose' something as a result of getting closer to the truth, you've only lost a lie. <a href=\"/lw/id/you_can_face_reality/\">You can face reality</a>, even the truth about morality.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<blockquote>\n<p>People can stand what is true,<br />for they are already enduring it.</p>\n</blockquote>\n<p>-&nbsp;Eugene Gendlin</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"daguMTessgwBYvN4b": 2, "fxvP6nbd5Pjk5TP8Q": 3, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3v24wGePcdSGB3i8a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 46, "baseScore": 48, "extendedScore": null, "score": 8.9e-05, "legacy": true, "legacyId": "7135", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 48, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 73, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LhP2zGBWR5AdssrdJ", "cphoF8naigLhRf3tu", "8rdoea3g6QGhWQtmx", "x4dG4GhpZH2hgz59x", "HYWhKXRsMAyvRKRYz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T01:04:07.300Z", "modifiedAt": null, "url": null, "title": "Ottawa LW meetup, May 9, 7pm; Bayes study group, May 5, 9pm", "slug": "ottawa-lw-meetup-may-9-7pm-bayes-study-group-may-5-9pm", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YZ4CEfdX7n33Edjrn/ottawa-lw-meetup-may-9-7pm-bayes-study-group-may-5-9pm", "pageUrlRelative": "/posts/YZ4CEfdX7n33Edjrn/ottawa-lw-meetup-may-9-7pm-bayes-study-group-may-5-9pm", "linkUrl": "https://www.lesswrong.com/posts/YZ4CEfdX7n33Edjrn/ottawa-lw-meetup-may-9-7pm-bayes-study-group-may-5-9pm", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ottawa%20LW%20meetup%2C%20May%209%2C%207pm%3B%20Bayes%20study%20group%2C%20May%205%2C%209pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOttawa%20LW%20meetup%2C%20May%209%2C%207pm%3B%20Bayes%20study%20group%2C%20May%205%2C%209pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYZ4CEfdX7n33Edjrn%2Fottawa-lw-meetup-may-9-7pm-bayes-study-group-may-5-9pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ottawa%20LW%20meetup%2C%20May%209%2C%207pm%3B%20Bayes%20study%20group%2C%20May%205%2C%209pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYZ4CEfdX7n33Edjrn%2Fottawa-lw-meetup-may-9-7pm-bayes-study-group-may-5-9pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYZ4CEfdX7n33Edjrn%2Fottawa-lw-meetup-may-9-7pm-bayes-study-group-may-5-9pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 127, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><strong style=\"font-weight: bold; \">Less Wrong meeting:</strong></p>\n<p>Date: Monday May 9, 7:00pm until at least 9:00pm.</p>\n<p>Venue: <a href=\"http://www.foxandfeather.ca/\">Fox and Feather</a>, private room 1 (upstairs behind the pool tables)</p>\n<p><strong style=\"font-weight: bold; \">Bayes study group:&nbsp;</strong>Anyone in the region interested in learning how to do Bayesian statistics is welcome to join us. High school algebra and calculus are the prerequisites for Bayes, but if you don't know them, I'll be happy to teach them to you. We'll be using the statistical package <strong>R</strong> (<a href=\"http://cran.r-project.org/\">http://cran.r-project.org/</a>)&nbsp;as a platform, so bring your laptop if you have one.</p>\n<p>&nbsp;</p>\n<p>Date: Thursday May 5, 9:00pm to 10:00pm.</p>\n<p>Venue: 347 Preston St., cafe seating behind the security desk. (Andrew can't make it out to Will's this week, and Chris has difficulty getting there in general, so we'll stick with the Preston Street venue for this week at least.)</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YZ4CEfdX7n33Edjrn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.093775333693831e-07, "legacy": true, "legacyId": "7142", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T01:38:45.629Z", "modifiedAt": null, "url": null, "title": "Ethics and rationality of suicide", "slug": "ethics-and-rationality-of-suicide-1", "viewCount": null, "lastCommentedAt": "2019-01-10T23:26:44.658Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "anonymous259", "user": {"username": "anonymous259", "createdAt": "2009-03-15T17:10:03.685Z", "isAdmin": false, "displayName": "anonymous259"}, "userId": "pGXq6qkqqbnB7k6Ba", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GfuKGCZQ5soSFMhqE/ethics-and-rationality-of-suicide-1", "pageUrlRelative": "/posts/GfuKGCZQ5soSFMhqE/ethics-and-rationality-of-suicide-1", "linkUrl": "https://www.lesswrong.com/posts/GfuKGCZQ5soSFMhqE/ethics-and-rationality-of-suicide-1", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ethics%20and%20rationality%20of%20suicide&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEthics%20and%20rationality%20of%20suicide%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfuKGCZQ5soSFMhqE%2Fethics-and-rationality-of-suicide-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ethics%20and%20rationality%20of%20suicide%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfuKGCZQ5soSFMhqE%2Fethics-and-rationality-of-suicide-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfuKGCZQ5soSFMhqE%2Fethics-and-rationality-of-suicide-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 637, "htmlBody": "<p>I was saddened to learn of the recent <a href=\"http://www.dailytribune.net/articles/2011/04/22/obituaries/doc4db1ac27e4244699183453.txt\">death</a>&nbsp;by suicide of Chris Capel, known here as <a href=\"/user/pdf23ds\">pdf23ds.</a> I didn't know him personally, but I was an occasional reader of his <a href=\"http://pdf23ds.net/\">blog</a>. In retrospect, I regret not having ever gotten into contact with him. Obviously, I don't know that I could have prevented his death, but, as one with mental-health issues myself, at least I could have made a friend, and been one to him. Now I feel a sense of disappointment that I'll never get that chance.</p>\n<p>Having said that, I must say that I take his arguments <a href=\"http://pdf23ds.net/2009/02/02/commit-suicide/\">here</a>&nbsp;very seriously. I do not consider it to be automatic that every suicide is the \"wrong\" decision. We can all imagine circumstances under which we would prefer to die than live; and given this, we should also be able to imagine that these kinds of circumstances may vary for different people. And if one is already accepting of euthanasia for incurable physical suffering, it should not be that much of a leap to accept it for incurable psychological suffering as well.</p>\n<p>Of course, as Chris acknowledges, this doesn't imply that everyone who is contemplating suicide is actually being rational. People may for instance be severely mistaken about their prospects for improvement, especially while in the midst of acute crisis.(Conceivably, that could even have been his own situation.) Nonetheless, I think many of the usual arguments that people use to show that suicide is \"wrong\" are bad arguments. For example, consider what is probably the most common argument: that committing suicide will inflict pain upon friends and family. It frankly strikes me as absurd (and grotesquely unempathetic) to suppose that someone for whom life is so painful that they would rather die somehow has an obligation to continue enduring it just in order to spare other people the emotion of grief (which they are inevitably going to have to confront at some point anyway, at least until we conquer all death). &nbsp;</p>\n<p>Ironically, society's demonization of suicide and suicidal people has negative consequences even from the standpoint of preventing suicide itself, as Chris <a href=\"http://webcache.googleusercontent.com/search?q=cache:http://pdf23ds.net/2011/03/15/bye/\">points out</a>:&nbsp;</p>\n<blockquote>\n<p>I passionately hate that all of the mental health people are obligated by law to commit me to an asylum if they think I&rsquo;m about to kill myself. They can&rsquo;t be objective. You know, if they could talk to me without such stupid constraints, they might have prevented this very suicide</p>\n</blockquote>\n<p>It seems to me very possible that our society's fervor to prevent suicide may result in denying severely depressed people the compassion they need. This could theoretically be worth it if it prevented enough suicides that turned out to be worth preventing, but cases like Chris's raise doubt about this, in my mind. (From both angles: if Chris's decision was the right one for him, then the system is saving people it shouldn't be saving; if on the other hand it was the wrong decision, then we clearly see how the system failed him.)&nbsp;</p>\n<p>Although I'm inclined to be sympathetic to Chris's view -- perhaps because I haven't always been maximally enthusiastic about my own existence myself -- there are some arguments that do worry me. Such as: if you think of future versions of yourself as separate agents, then suicide is a form of homicide. However, usually suicide is carried out on the belief that the future selves would approve of their nonexistence; and all of our decisions have consequences (often irreversible) for our future selves, so this is a general ethical problem that transcends the specific issue of suicide.</p>\n<p>This post is a place to rationally discuss the ethics and rationality of suicide, as well as our attitudes (on an individual level, and as reflected in our institutions) toward suicidal people and,&nbsp;more generally,&nbsp;those suffering from psychological conditions such as depression.&nbsp;</p>\n<p>I'm sad that Chris won't be able to participate.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"BAhM42jvzuWMzTDxR": 1, "gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GfuKGCZQ5soSFMhqE", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 62, "baseScore": 62, "extendedScore": null, "score": 0.000122, "legacy": true, "legacyId": "7141", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": true, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 62, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 203, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T02:22:17.129Z", "modifiedAt": null, "url": null, "title": "[Altruist Support] LW Go Foom", "slug": "altruist-support-lw-go-foom", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.418Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Giles", "createdAt": "2011-02-11T02:30:16.999Z", "isAdmin": false, "displayName": "Giles"}, "userId": "H347ba3KZMP8XoDt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ByWi9xcc34PbQ7nnR/altruist-support-lw-go-foom", "pageUrlRelative": "/posts/ByWi9xcc34PbQ7nnR/altruist-support-lw-go-foom", "linkUrl": "https://www.lesswrong.com/posts/ByWi9xcc34PbQ7nnR/altruist-support-lw-go-foom", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BAltruist%20Support%5D%20LW%20Go%20Foom&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BAltruist%20Support%5D%20LW%20Go%20Foom%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FByWi9xcc34PbQ7nnR%2Faltruist-support-lw-go-foom%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BAltruist%20Support%5D%20LW%20Go%20Foom%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FByWi9xcc34PbQ7nnR%2Faltruist-support-lw-go-foom", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FByWi9xcc34PbQ7nnR%2Faltruist-support-lw-go-foom", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 690, "htmlBody": "<p><em>In which I worry that the Less Wrong project might <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/GoneHorriblyRight\">go horribly right.</a> This post belongs to my <a href=\"/r/discussion/lw/5gy/help_i_want_to_do_good/\">Altruist Support</a> sequence.<a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/GoneHorriblyRight\"><br /></a></em></p>\n<p>Every project needs a risk assessment.</p>\n<p>There's a feeling, just bubbling under the surface here at Less Wrong, that we're just <em>playing</em> at rationality. It's rationality kindergarten. The problem has been expressed in various ways:</p>\n<ul>\n<li><a href=\"/lw/2c/a_sense_that_more_is_possible/\">not a whole lot of rationality</a></li>\n<li><a href=\"/lw/co/fix_it_and_tell_us_what_you_did/\">rationalist porn for daydreamers</a></li>\n<li><a href=\"/lw/9p/extreme_rationality_its_not_that_great/\">not quite as great as everyone seems to think</a></li>\n<li><a href=\"/lw/2po/selfimprovement_or_shiny_distraction_why_less/\">shiny distraction</a></li>\n<li><a href=\"/lw/34a/goals_for_which_less_wrong_does_and_doesnt_help/\">only good for certain goals</a></li>\n</ul>\n<p>And people are starting to look at fixing it. I'm not worried that their attempts - and mine - will fail. At least we'd have fun and learn something.</p>\n<p>I'm worried that they will succeed.</p>\n<p>What would such a Super Less Wrong community do? Its members would self-improve to the point where they had a good chance of succeeding at most things they put their mind to. They would recruit new rationalists and then optimize that recruitment process, until the community got <em>big</em>. They would develop methods for rapidly generating, classifying and evaluating ideas, so that the only ideas that got tried would be the <em>best that anyone had come up with so far</em>. The group would structure itself so that people's basic social drives - such as their desire for status - worked in the interests of the group rather than against it.</p>\n<p>It would be pretty formidable.</p>\n<p>What would the products of such a community be? There would probably be a self-help book that <em>works</em>. There would be an effective, practical guide to setting up effective communities. There would be an intuitive, practical guide to human behavior. There would be books, seminars and classes on how to <em>really</em> achieve your goals - and only the materials which actually got results would be kept. There would be a bunch of stuff on the Dark Arts too, no doubt. Possibly some AI research.</p>\n<p>That's a whole lot of material that we wouldn't want to get into the hands of the wrong people.</p>\n<p>Dangers include:</p>\n<ul>\n<li>Half-rationalists: people who pick up on enough memes to be really dangerous, but not on enough to realise that what they're doing might be foolish. For example, building an AI without adding the friendliness features.</li>\n<li>Rationalists with bad goals: Someone could rationally set about trying to destroy humanity, just for the <a href=\"http://en.wiktionary.org/wiki/lulz\">lulz</a>.</li>\n<li>Dangerous information discovered: e.g. the rationalist community develops a Theory of Everything that reveals a recipe for a physics disaster (e.g. a cheap way to turn the Earth into a block hole). A non-rationalist decides to exploit this.</li>\n</ul>\n<p>If this is a problem we should take seriously, what are some possible strategies for dealing with it?</p>\n<ol>\n<li>Just go ahead and ignore the issue.</li>\n<li>The Bayesian Conspiracy: only those who can be trusted are allowed access to the secret knowledge.</li>\n<li>The Good Word: mix in rationalist ideas with do-good and stay-safe ideas, to the extent that they can't be easily separated. The idea being that anyone who understands rationality will also understand that it must be used for good.</li>\n<li>Rationality cap: we develop enough rationality to achieve our goals (e.g. friendly AI) but deliberately stop short of developing the ideas <em>too</em> far.</li>\n<li>Play at rationality: create a community which appears rational enough to distract people who are that way inclined, but which does not dramatically increase their personal effectiveness.</li>\n<li>Risk management: accept that each new idea has a potential payoff (in terms of helping us avoid existential threats) and a potential cost (in terms of helping \"bad rationalists\"). Implement the ideas which come out positive.</li>\n</ol>\n<p>In the post title, I have suggested an analogy with <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">AI takeoff</a>. That's not entirely fair; there is probably an upper bound to how effective a community of humans can be, at least until brain implants come along. We're probably talking two orders of magnitude rather than ten. But given that humanity already has technology with slight existential threat implications (nuclear weapons, rudimentary AI research), I would be worried about a movement that aims to make <em>all of humanity more effective at everything they do.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ByWi9xcc34PbQ7nnR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 10, "extendedScore": null, "score": 7.093998996021103e-07, "legacy": true, "legacyId": "7143", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qJCPpLXmS9rYemjy7", "Nu3wa6npK4Ry66vFp", "N75n9scjdvvvMN627", "LgavAYtzFQZKg95WC", "uFYQaGCRwt3wKtyZP", "7dRGYDqA2z6Zt7Q4h"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T02:33:45.352Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes: May 2011", "slug": "rationality-quotes-may-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.847Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5oDLZxexkDMGg6sbA/rationality-quotes-may-2011", "pageUrlRelative": "/posts/5oDLZxexkDMGg6sbA/rationality-quotes-may-2011", "linkUrl": "https://www.lesswrong.com/posts/5oDLZxexkDMGg6sbA/rationality-quotes-may-2011", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%3A%20May%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%3A%20May%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5oDLZxexkDMGg6sbA%2Frationality-quotes-may-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%3A%20May%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5oDLZxexkDMGg6sbA%2Frationality-quotes-may-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5oDLZxexkDMGg6sbA%2Frationality-quotes-may-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 78, "htmlBody": "<p>It looks like, this month, I get to be the one to start the quotes thread.</p>\n<p>&nbsp;</p>\n<ul style=\"margin: 10px 2em; padding: 0px; list-style-type: disc; list-style-position: outside;\">\n<li>Please post all quotes separately, so that they can be voted up/down separately.&nbsp; (If they are strongly related, reply to your own comments.&nbsp; If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5oDLZxexkDMGg6sbA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.09403181889908e-07, "legacy": true, "legacyId": "7144", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 124, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T04:07:46.851Z", "modifiedAt": null, "url": null, "title": "Berkeley LW Meet-Up Saturday May 7", "slug": "berkeley-lw-meet-up-saturday-may-7", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.667Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "LucasSloan", "createdAt": "2009-05-28T05:04:38.345Z", "isAdmin": false, "displayName": "LucasSloan"}, "userId": "ouo6Fqn5kTNY7LvqM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7eDE68gvzg4RLXJbF/berkeley-lw-meet-up-saturday-may-7", "pageUrlRelative": "/posts/7eDE68gvzg4RLXJbF/berkeley-lw-meet-up-saturday-may-7", "linkUrl": "https://www.lesswrong.com/posts/7eDE68gvzg4RLXJbF/berkeley-lw-meet-up-saturday-may-7", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Berkeley%20LW%20Meet-Up%20Saturday%20May%207&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABerkeley%20LW%20Meet-Up%20Saturday%20May%207%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7eDE68gvzg4RLXJbF%2Fberkeley-lw-meet-up-saturday-may-7%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Berkeley%20LW%20Meet-Up%20Saturday%20May%207%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7eDE68gvzg4RLXJbF%2Fberkeley-lw-meet-up-saturday-may-7", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7eDE68gvzg4RLXJbF%2Fberkeley-lw-meet-up-saturday-may-7", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 194, "htmlBody": "<p><a id=\"more\"></a>Hey everyone!&nbsp; It is once again the time of the month when all the LW-folk in the SF Bay Area get together.&nbsp; As usual, we will be meeting at the <a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Downtown+Berkeley+BART&amp;daddr=2128+Oxford+St,+Berkeley,+CA+94704-1311+%28Starbucks%29&amp;geocode=FSzZQQIdbVa2-Ck7jvjKnX6FgDG3LOQ7rN5ZmA%3BFW7bQQIdQl62-CEGuQ_bapaUqCmz2L6SnX6FgDHtCjCMFeuX-A&amp;hl=en&amp;mra=ltm&amp;dirflg=w&amp;sll=37.86999,-122.26696&amp;sspn=0.001931,0.005284&amp;ie=UTF8&amp;ll=37.870225,-122.266577&amp;spn=0.001931,0.005284&amp;z=18\">Oxford Street Starbucks</a> at 7 pm and then moving to the Valley Life Sciences Building on the UC Berkeley Campus.&nbsp; We will make time for people to get take out dinner from restaurants in downtown Berkeley, to be eaten at the VLSB.&nbsp; This is great time to meet the Bay Area Less Wrong community, and I welcome newcomers and, from the old hands, guests.</p>\n<p>If you enjoy LW meetups, and want to go to them more often, there is the weekly meetup in Berkeley, which also meets at the <a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Downtown+Berkeley+BART&amp;daddr=2128+Oxford+St,+Berkeley,+CA+94704-1311+%28Starbucks%29&amp;geocode=FSzZQQIdbVa2-Ck7jvjKnX6FgDG3LOQ7rN5ZmA%3BFW7bQQIdQl62-CEGuQ_bapaUqCmz2L6SnX6FgDHtCjCMFeuX-A&amp;hl=en&amp;mra=ltm&amp;dirflg=w&amp;sll=37.86999,-122.26696&amp;sspn=0.001931,0.005284&amp;ie=UTF8&amp;ll=37.870225,-122.266577&amp;spn=0.001931,0.005284&amp;z=18\">Oxford Street Starbucks</a>, on Wednesdays at 7.&nbsp; This week we will be having a party.&nbsp; To receive regular information about the LW events planned in the Bay Area, please sign up for the <a href=\"http://groups.google.com/group/bayarealesswrong\">Google Group</a>.</p>\n<p>For those in the South Bay, there is a weekly meet up at Tortuga on Thursdays.&nbsp; There is a LW sequences study session from 7 to 7:30, with the meet up starting at 7:30.&nbsp; For more information, please join their <a href=\"http://groups.google.com/group/tortuga-rationalists\">Google Group</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7eDE68gvzg4RLXJbF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.094300885877951e-07, "legacy": true, "legacyId": "7147", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T07:08:30.768Z", "modifiedAt": null, "url": null, "title": "SIAI - An Examination", "slug": "siai-an-examination", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:09.214Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BrandonReinhart", "createdAt": "2009-03-06T04:00:54.689Z", "isAdmin": false, "displayName": "BrandonReinhart"}, "userId": "ugRLNpaFuDrXntoeK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qqhdj3W3vSfB5E9ss/siai-an-examination", "pageUrlRelative": "/posts/qqhdj3W3vSfB5E9ss/siai-an-examination", "linkUrl": "https://www.lesswrong.com/posts/qqhdj3W3vSfB5E9ss/siai-an-examination", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SIAI%20-%20An%20Examination&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASIAI%20-%20An%20Examination%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqqhdj3W3vSfB5E9ss%2Fsiai-an-examination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SIAI%20-%20An%20Examination%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqqhdj3W3vSfB5E9ss%2Fsiai-an-examination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqqhdj3W3vSfB5E9ss%2Fsiai-an-examination", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3913, "htmlBody": "<p><em>12/13/2011 - A 2011 update with data from the 2010 fiscal year is in progress. Should be done by the end of the week or sooner.</em></p>\n<p>&nbsp;</p>\n<p><span style=\"font-size: 16px; font-weight: bold;\">Disclaimer</span></p>\n<ul>\n<li>I am not affiliated with the <a href=\"http://intelligence.org/\">Singularity Institute for Artificial Intelligence</a>.</li>\n<li>I have not donated to the SIAI prior to writing this.</li>\n<li><span class=\"c3\">I made </span><span class=\"c5\"><a href=\"/lw/5ec/minicamp_on_rationality_awesomeness_and/40jo\">this pledge</a></span><span class=\"c3\"> prior to writing this document.</span></li>\n</ul>\n<h2>Notes</h2>\n<ul>\n<li>Images are now hosted on LessWrong.com.</li>\n<li>The 2010 Form 990 data will be available later this month.</li>\n<li>It is not my intent to&nbsp;propagate&nbsp;misinformation. Errors will be corrected as soon as they are identified.</li>\n</ul>\n<h2 class=\"c23 c1\"><span class=\"c13 c11\">Introduction</span></h2>\n<p class=\"c1\"><span class=\"c3\">Acting on </span><span class=\"c5\"><a href=\"/user/gwern/\">gwern</a></span><span class=\"c3\">'s suggestion in his </span><span class=\"c5\"><a href=\"/r/discussion/lw/5el/are_girl_scout_cookies_deliciously_evil_a_case/\">Girl Scout Cookie</a></span><span class=\"c3\"> analysis, I decided to look at SIAI funding. After reading about the Visiting Fellows Program and more recently the <a href=\"/lw/4wm/rationality_boot_camp/\">Rationality Boot Camp</a>, I decided that the SIAI might be something I would want to support. I am concerned with <a href=\"http://wiki.lesswrong.com/wiki/Existential_risk\">existential risk</a> and grapple with the utility implications. I feel that I should do more.</span></p>\n<p class=\"c1\"><span class=\"c3\">I wrote on the mini-boot camp page a pledge that I would donate enough to send someone to rationality mini-boot camp. This seemed to me a small cost for the potential benefit. The SIAI might get better at building rationalists. It might build a rationalist who goes on to solve a problem. Should I donate more? I wasn&rsquo;t sure. I read gwern&rsquo;s article and realized that I could easily get more information to clarify my thinking.</span></p>\n<p class=\"c1\"><span class=\"c3\">So I downloaded the SIAI&rsquo;s Form 990 annual IRS filings and started to write down notes in a spreadsheet. As I gathered data and compared it to my expectations and my goals, my beliefs changed. I now believe that donating to the SIAI is valuable. I cannot hide this belief in my writing. I simply have it.</span></p>\n<p class=\"c1\"><span class=\"c3\">My goal is not to convince you to donate to the SIAI. My goal is to provide you with information necessary for you to determine for yourself whether or not you should donate to the SIAI. Or, if not that, to provide you with some direction so that you can continue your investigation.</span></p>\n<p class=\"c1\"><span class=\"c3\"><a id=\"more\"></a></span></p>\n<p class=\"c1\"><span class=\"c3\">The SIAI's Form 990's are available at </span><span class=\"c5\"><a href=\"http://www2.guidestar.org/\">GuideStar</a></span><span class=\"c3\"> and </span><span class=\"c5\"><a href=\"http://foundationcenter.org/\">Foundation Center</a></span><span class=\"c3\">. You must register in order to access the files at GuideStar.</span></p>\n<ol class=\"c14\">\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/dZZkc0\">2002</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/eOgI0B\">2003</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c1 c6 c12\"><span class=\"c5\"><a href=\"http://bit.ly/efHrQC\">2004</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/f3Ekvg\">2005</a></span><span class=\"c3\"> (Form 990)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/gRC7SS\">2006</a></span><span class=\"c3\"> (Form 990)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://www.guidestar.org/FinDocuments//2007/582/565/2007-582565917-0487362e-9.pdf\">2007</a></span><span class=\"c3\"> (Form 990)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://www.guidestar.org/FinDocuments//2008/582/565/2008-582565917-0599169c-Z.pdf\">2008</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://www.guidestar.org/FinDocuments//2009/582/565/2009-582565917-06b644eb-9.pdf\">2009</a></span><span class=\"c3\"> (Form 990)</span></li>\n</ol>\n<h2><span class=\"c13 c11\">SIAI Financial Overview</span></h2>\n<p><span class=\"c13 c11\">The <a href=\"http://intelligence.org\">Singularity Institute for Artificial Intelligence</a> (SIAI) is a public organization working to reduce <a href=\"http://intelligence.org/files/ReducingRisks.pdf\">existential risk from future technologies</a>, in particular artificial intelligence. \"The Singularity Institute brings rational analysis and rational strategy to the challenges facing humanity as we develop cognitive technologies that will exceed the current upper bounds on human intelligence.\" The SIAI are also the founders of Less Wrong.</span></p>\n<p><img src=\"http://images.lesswrong.com/t3_5il_0.png\" alt=\"\" width=\"591\" height=\"211\" /></p>\n<p><img src=\"http://images.lesswrong.com/t3_5il_1.png?v=a0ef8195b3866f478702a67e2238c3bb\" alt=\"\" width=\"296\" height=\"194\" /><img src=\"http://images.lesswrong.com/t3_5il_2.png?v=27393a444aa0942ee9c2ebb93acc3a5e\" alt=\"\" width=\"296\" height=\"194\" /></p>\n<p class=\"c1\"><span class=\"c3\">The graphs above offer an accurate summary of SIAI financial state since 2002. Sometimes the end of year balances listed in the Form 990 doesn&rsquo;t match what you&rsquo;d get if you did the math by hand. These are noted as discrepancies between the filed year end balance and the expected year end balance or between the filed year start balance and the expected year start balance.</span></p>\n<ol class=\"c14\">\n<li class=\"c12 c1 c6\"><span class=\"c3 c11\"><strong>Filing Error 1</strong></span><span class=\"c3\"> - There appears to be a minor typo to the effect of $4.86 in the end of year balance for the 2004 document. It appears that Part I, Line 18 has been summed incorrectly. $32,445.76 is listed, but the expected result is $32,450.41. The Part II balance sheet calculations which agree with the error so the source of the error is unclear. The start of year balance in 2005 reflects the expected value so this was probably just a typo in 2004. The following year&rsquo;s reported start of year balance does not contain the error.</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c3 c11\"><strong>Filing Error 2</strong></span><span class=\"c3\"> - The 2006 document reports a year start balance of $95,105.00 when the expected year start balance is $165,284.00, a discrepancy of $70,179.00. This amount is close to the estimated Program Service Accomplishments in 2005 Form 990 Part III Line F of $72,000.00. Looks like the service expenses were not included completely in Part II. The money is not missing: future forms show expected values moving forward.</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c3 c11\"><strong>Theft</strong> - </span><span class=\"c3\">The organization reported $118,803.00 in theft in 2009 resulting in a year end asset balance lower than expected. </span><span class=\"c3 c10\">The SIAI is currently pursuing legal restitution.</span></li>\n</ol>\n<p class=\"c1 c6\"><span class=\"c3\">The SIAI has generated a revenue surplus every year except 2008. The 2008 deficit appears to be a cashing out of excess surplus from 2007. Asset growth indicates that the SIAI is good at utilizing the funds it has available, without overspending. The organization is expanding it&rsquo;s menu of services, but not so fast that it risks going broke.</span></p>\n<p class=\"c1 c6\">Nonetheless, current asset balance is insufficient to sustain a year of operation at existing rate of expenditure. Significant loss of revenue from donations would result in a shrinkage of services. Such a loss of revenue may be unlikely, but a reasonable goal for the organization would be to build up a year's reserves.</p>\n<p class=\"c1 c6\"><span style=\"font-size: 15px; font-weight: bold;\">Revenue</span></p>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><span class=\"c3\">Revenue is composed of public support, program service (events/conferences held, etc), and investment interest. The \"Other\" category tends to include Amazon.com affiliate income, etc.</span></p>\n<p class=\"c1 c9\"><img src=\"http://images.lesswrong.com/t3_5il_3.png?v=99acbb583f561c10b2f7f164f073d783\" alt=\"\" width=\"608\" height=\"259\" /></p>\n<p class=\"c1 c6\"><img src=\"http://images.lesswrong.com/t3_5il_4.png?v=7f3586b662dd9967ceeeca02f0b05519\" alt=\"\" width=\"339\" height=\"187\" align=\"left\" /></p>\n<p class=\"c1 c6\"><span class=\"c3\">Income from public support has grown steadily with a notable regular increase starting in 2006. This increase is a result of new contributions from big donors. As an example, public support in 2007 is largely composed of significant contributions from Peter Thiel ($125k), Brian Cartmell ($75k), and Robert F. Zahra Jr ($123k) for $323k total in large scale individual contributions (break down below).</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">In 2007 the SIAI started receiving income from program services. Currently all \"Program Service\" revenue is from operation of the Singularity Summit. In 2010 the summit generated surplus revenue for the SIAI. This is a significant achievement, as it means the organization has created a sustainable service that could fund further services moving forward.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">A specific analysis of the summit is below.</span></p>\n<h2><span style=\"font-size: 15px; font-weight: bold;\">Expenses</span></h2>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><span class=\"c3\">Expenses are composed of grants paid to winners, benefits paid to members, officer compensation, contracts, travel, program services, and an other category.</span></p>\n<p class=\"c1\"><span class=\"c3\">The contracts column in the chart below includes legal and accounting fees. The other column includes administrative fees and other operational costs. I didn&rsquo;t see reason to break the columns down further. In many cases the Form 990s provide more detailed itemization. If you care about how much officers spent on gas or when they bought new computers you might find the answers in the source.</span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_5.png?v=d7dbe8ccc715a746bd237e4aca186d18\" alt=\"\" width=\"602\" height=\"211\" /></p>\n<p class=\"c1\"><span class=\"c3\">I don&rsquo;t have data for 2000 or 2001, but left the rows in the spreadsheet in case it can be filled in later.</span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_6.png?v=40dc2b53beef6b4629617169a5c9fac1\" alt=\"\" width=\"350\" height=\"202\" align=\"left\" /></p>\n<p class=\"c1 c6\"><span class=\"c3\">Program expenses have grown over the years, but not unreasonably. Indeed, officer compensation has declined steadily for several years. The grants in 2002, 2003, and 2004 were paid to Eliezer Yudkowsky for work relevant to Artificial Intelligence.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">The program expenses category includes operating the Singularity Summit, Visiting Fellows Program, etc. Some of the cost of these programs is also included in the other category. For example, the 2007 Singularity Summit is reported as costing $101,577.00 but this total amount is accounted for in multiple sections.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">It appears that 2009 was a more productive year than 2008 and also less expensive. 2009 saw a larger Singularity Summit than in 2008 and also the creation of the Visiting Fellows Program.</span></p>\n<h2><span style=\"font-size: 15px; font-weight: bold;\">Big Donors</span></h2>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_7.png?v=3b5b3af66c23a90359308a68b369f487\" alt=\"\" width=\"592\" height=\"336\" /></p>\n<p class=\"c1 c6\"><span class=\"c3\">This is not an exhaustive list of contributions. The SIAI&rsquo;s 2009 filing details major support donations for several previous years. Contributions in the 2010 column are derived from </span><span class=\"c5\"><a href=\"http://intelligence.org/donors\">http://intelligence.org/donors</a></span><span class=\"c3\">. &nbsp;Known contributions of less than $5,000 are excluded for the sake of brevity. The 2006 donation from Peter Thiel is sourced from a discussion with the SIAI.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Peter Thiel and several other big donors compose the bulk of the organization's revenue. It would be good to see a broader base of donations moving forward. Note, however, that the base of donations has been improving. I don't have the 2010 Form 990 yet, but it appears to be the best year yet in terms of both the quantity of donations and the number of individual donors (based on conversation with SIAI members).</span></p>\n<p class=\"c1 c6\"><span style=\"font-size: 15px; font-weight: bold;\">Officer Compensation</span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_8.png?v=f9fe89c72d0fea7ec1a58f7035d93a9d\" alt=\"\" width=\"594\" height=\"147\" /></p>\n<p class=\"c1 c6\"><img src=\"http://images.lesswrong.com/t3_5il_9.png?v=717b8a6e09d407d0a1e00a283657a54f\" alt=\"\" width=\"333\" height=\"218\" align=\"left\" /></p>\n<p class=\"c1 c6\"><span class=\"c3\">In 2002 to 2005 Eliezer Yudkowsky received compensation in the form of grants from the SIAI for AI research. </span><em><span class=\"c3 c10\">It is noted in the Form 990s that </span><span class=\"c3 c10 c11\"><strong>no public funds </strong></span></em><span class=\"c3 c10\"><em>were used for Eliezer&rsquo;s research grants as he is also an officer.</em> </span><span class=\"c3\">Starting in 2006 all compensation for key officers is reported as salaried instead of in the form of grants.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Compensation spiked in 2006, the same year of greatly increased public support. Nonetheless, officer compensation has decreased steadily despite continued increases in public support. It appears that the SIAI has been managing it&rsquo;s resources carefully in recent years, putting more money into programs than into officer compensation.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Eliezer's base compensation as salary increased 20% in 2008. It seems reasonable to compare Eliezer's salary with that of professional software developers. Eliezer would be able to make a fair amount more working in private industry as a software developer.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Mr. Yudkowsky clarifies: \"The reason my salary shows as $95K in 2009 is that Paychex screwed up and paid my first month of salary for 2010 in the 2009 tax year. My actual salary was, I believe, constant or roughly so through 2008-2010.\" In this case we would expect to see the 2010 Form 990 show a month reduced salary.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Moving forward, the SIAI will have to grapple with the high cost of recruiting top tier programmers and academics to do real work. I believe this is an argument for the SIAI improving its asset sheet. More money in the bank means more of an ability to take advantage of recruitment opportunities if they present themselves.</span></p>\n<h2><span style=\"font-size: 15px; font-weight: bold;\">Singularity Summit</span></h2>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><span class=\"c3\">Founded in 2006 by the SIAI in cooperation with Ray Kurzweil and Peter Thiel, the Singularity Summit focuses on a broad number of topics related to the Singularity and emerging technologies. (1)</span></p>\n<p class=\"c1 c9\"><img src=\"http://images.lesswrong.com/t3_5il_10.png?v=b0861f92f729c043979a7d8d7b9cc1f4\" alt=\"\" width=\"577\" height=\"133\" /></p>\n<p class=\"c1\"><span class=\"c3\">The Singularity Summit was free until 2008 when the SIAI chose to begin charging registration fees and accepting sponsorships. (2)</span></p>\n<p class=\"c1 c9\"><img src=\"http://images.lesswrong.com/t3_5il_11.png?v=b77e680872854187f7fb9985aec738f3\" alt=\"\" align=\"left\" /></p>\n<p class=\"c1\"><span class=\"c3\">Attendee counts are estimates drawn from SIAI Form 990 filings. 2010 is purported to be the largest conference so far. Beyond the core conference attendees, hundreds of thousands of online viewers are reached through recordings of the Summit sessions. (A)</span></p>\n<p class=\"c1\"><span class=\"c3\">The cost of running the summit has increased annually, but revenue from sponsorships and registration have kept pace. The conference may have logistic and administrative costs, but it doesn't really impact the SIAI budget. This makes the conference a valuable blend of outreach and education. If the conference convinces someone to donate or in some way directly support work against existential risks, the benefits are effectively free (or at the very least come at no cost to other programs).</span></p>\n<p class=\"c1\"><span style=\"font-size: 14px; font-weight: bold;\">Is the Singularity Summit successful?</span></p>\n<p class=\"c1\"><span class=\"c3\">It&rsquo;s difficult to evaluate the success of conferences. So many of the benefits are realized downstream of the actual event. Nonetheless, the attendee counts and widening exposure seem to bring immense value for the cost. Several factors contribute to a sense that the conference is a success:</span></p>\n<ul>\n<li>In 2010 the Summit became a positive revenue generating exercise in its own right. With careful stewardship, the Singularity Summit could grow to generate a reliable annual revenue for the SIAI.</li>\n<li>The ability to run an efficient conference is itself valuable. Should it choose to, the SIAI could run other types of conferences or special interest events in the future with a good expectation of success.</li>\n<li>The high visibility of the Summit plants seeds for future fund raising. Conference attendees likely benefit as much or more from networking as they do from the content of the sessions. Networking builds relationships between people able to coordinate to solve problems or fund solutions to problems.</li>\n<li><span class=\"c3\">The Singularity Summit has generated ongoing public interest and media coverage. Notable articles can be found in</span><span class=\"c3\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\"> </a></span><span class=\"c5\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\">Popular Science</a></span><span class=\"c3\"> (3),</span><span class=\"c3\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\"> </a></span><span class=\"c5\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\">Popular Mechanics</a></span><span class=\"c3\"> (4), the</span><span class=\"c5\"><a href=\"http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering\"> Guardian</a></span><span class=\"c3\"> (5), and</span><span class=\"c3\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\"> </a></span><span class=\"c5\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\">TIME Magazine</a></span><span class=\"c3\"> (6). Quality media coverage raises public awareness of Singularity related topics. There is a strong argument that a person with an interest in futurist or existential risk consciousness raising reaches a wide audience by supporting the Singularity Summit.</span></li>\n</ul>\n<p class=\"c1\"><span class=\"c3\">When discussing &ldquo;future shock levels&rdquo; -- gaps in exposure to and understanding of futurist concepts -- Eliezer Yudkowsky wrote, &ldquo;In general, one shock level gets you enthusiasm, two gets you a strong reaction - wild enthusiasm or disbelief, three gets you frightened - not necessarily hostile, but frightened, and four can get you burned at the stake.&rdquo; (7) Most futurists are familiar with this sentiment. Increased public exposure to unfamiliar concepts through the positive media coverage brought about by the Singularity Summit works to improve the legitimacy of those concepts and reduce future shock.</span></p>\n<p class=\"c1 c21\">The result is that hard problems get easier to solve. Experts interested in helping, but afraid of social condemnation, will be more likely to do core research. The curious will be further motivated to break problems down. Vague far-mode thinking about future technologies will, for a few, shift into near-mode thinking about solutions. Public reaction to what would otherwise be shocking concepts will shift away from the extreme. The future becomes more conditioned to accept the real work and real costs of battling existential risk.</p>\n<ul>\n</ul>\n<h2><span class=\"c13 c11\">SIAI Milestones</span></h2>\n<p class=\"c1\">This is not a complete list of SIAI milestones, but covers quite a few of the materials and events that the SIAI has produced over the years.</p>\n<p class=\"c1\"><span class=\"c3\"><strong>2005</strong></span></p>\n<p><span class=\"c3\"> </span></p>\n<ul>\n<li><span class=\"c3\">RF Eliezer Yudkowsky publishes &ldquo;</span><span class=\"c5\"><a href=\"http://yudkowsky.net/rational/technical\">A Technical Explanation of Technical Explanation</a></span><span class=\"c3\">&rdquo;</span></li>\n<li><span class=\"c3\">RF Eliezer Yudkowsky writes chapters for &ldquo;</span><span class=\"c5\"><a href=\"http://www.amazon.com/Global-Catastrophic-Risks-Nick-Bostrom/dp/0198570503/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1304291108&amp;sr=8-1\">Global Catastrophic Risks</a></span><span class=\"c3\">&rdquo;</span></li>\n<li>AI and existential risk presentations at Stanford, Immortality Institute&rsquo;s Life Extension Conference, and the Terasem Foundation.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2006</strong></span></p>\n<ul>\n<li>Fundraising efforts expand significantly.</li>\n<li>SIAI hosts the first Singularity Summit at Stanford.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2007</strong></span></p>\n<ul>\n<li>SIAI hosts the Singularity Summit in San Francisco.</li>\n<li><span class=\"c5\"><a href=\"http://intelligence.org/blog/\">SIAI outreach blog</a></span><span class=\"c3\"> is started.</span></li>\n<li><span class=\"c5\"><a href=\"http://intelligence.org/media/interviews\">SIAI Interview Series</a></span><span class=\"c3\"> is started.</span></li>\n<li><span class=\"c5\"><a href=\"http://www.youtube.com/watch?v=0A9pGhwQbS0\">SIAI introductory video</a></span><span class=\"c3\"> is developed and released.</span></li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2008</strong></span></p>\n<ul>\n<li>SIAI hosts the Singularity Summit in San Jose.</li>\n<li>SIAI Interview Series is expanded.</li>\n<li>SIAI begins its summer intern program.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2009</strong></span></p>\n<p class=\"c1\"><span class=\"c3\"><strong><span style=\"font-weight: normal;\"><span class=\"c3\">Significant detail on 2009 achievements is&nbsp;</span><span class=\"c5\"><a href=\"http://intelligence.org/blog/\">available here</a></span><span class=\"c3\">. More publications are <a href=\"http://intelligence.org/research/\">available here</a>.</span></span></strong></span></p>\n<ul>\n<li>RF Eliezer Yudkowsky completes the rationality&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Sequences\">sequences</a>.</li>\n<li><a href=\"/\">Less Wrong</a> is founded.</li>\n<li>SIAI hosts the Singularity Summit in New York.</li>\n<li>RF Anna Salamon speaks on technological forecasting at the Santa Fe institute.</li>\n<li>SIAI establishes the <a href=\"http://intelligence.org/visiting-fellows/\">Visiting Fellows Program</a>. Graduate and under-graduate students within AI related disciplines develop related talks and papers.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\">Papers and talks from SIAI fellows produced in 2009:</span></p>\n<ol class=\"c14\">\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://intelligence.org/files/ChangingTheFrame.pdf\">&ldquo;Changing the frame of AI futurism: From storytelling to heavy-tailed, high-dimensional probability distributions&rdquo;</a></span><span class=\"c7\">, by Steve Rayhawk, Anna Salamon, Tom McCabe, Rolf Nelson, and Michael Anissimov. (Presented at the European Conference of Computing and Philosophy in July &lsquo;09 (ECAP))</span></li>\n<li class=\"c16 c1\"><span class=\"c7\">&ldquo;Arms Control and Intelligence Explosions&rdquo;, by Carl Shulman (Also presented at ECAP)</span></li>\n<li class=\"c1 c16\"><span class=\"c7\">&ldquo;</span><span class=\"c8\"><a href=\"http://bentham.k2.t.u-tokyo.ac.jp/ap-cap09/openconf/data/papers/28-2.pdf\">Machine Ethics and Superintelligence</a></span><span class=\"c7\">&rdquo;, by Carl Shulman and Henrik Jonsson (Presented at the Asia-Pacific Conference of Computing and Philosophy in October &lsquo;09 (APCAP))</span></li>\n<li class=\"c16 c1\"><span class=\"c7\">&ldquo;</span><span class=\"c8\"><a href=\"http://bentham.k2.t.u-tokyo.ac.jp/ap-cap09/openconf/data/papers/33.pdf\">Which Consequentialism? Machine Ethics and Moral Divergence</a></span><span class=\"c7\">&rdquo;, by Carl Shulman and Nick Tarleton (Also presented at APCAP);</span></li>\n<li class=\"c16 c1\"><span class=\"c7\">&ldquo;Long-term AI forecasting: Building methodologies that work&rdquo;, an invited presentation by Anna Salamon at the Santa Fe Institute conference on forecasting;</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://www.vimeo.com/7318055\">&ldquo;Shaping the Intelligence Explosion&rdquo;</a></span><span class=\"c7\"> and </span><span class=\"c5\"><a href=\"http://www.vimeo.com/7397629\">&ldquo;How much it matters to know what matters: A back of the envelope calculation&rdquo;</a></span><span class=\"c3\">, presentations by Anna Salamon at the Singularity Summit 2009 in October</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://www.vimeo.com/7320152\">&ldquo;Pathways to Beneficial Artificial General Intelligence: Virtual Pets, Robot Children, Artificial Bioscientists, and Beyond&rdquo;</a></span><span class=\"c7\">, a presentation by SIAI Director of Research Ben Goertzel at Singularity Summit 2009;</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://www.vimeo.com/7426357\">&ldquo;Cognitive Biases and Giant Risks&rdquo;</a></span><span class=\"c7\">, &nbsp;a presentation by SIAI Research Fellow Eliezer Yudkowsky at Singularity Summit 2009;</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://arxiv.org/abs/0907.5598\">&ldquo;Convergence of Expected Utility for Universal Artificial Intelligence&rdquo;</a></span><span class=\"c7\">, a paper by Peter de Blanc, an SIAI Visiting Fellow.</span></li>\n</ol>\n<p class=\"c1\"><span class=\"c3\">* Text for this list of papers reproduced from </span><span class=\"c5\"><a href=\"http://intelligence.org/blog/\">here</a></span><span class=\"c3\">.</span></p>\n<p class=\"c1\"><span class=\"c3\">A list of achievements, papers, and talks from 2010 is pending. See also the Singularity Summit content links above.</span></p>\n<p class=\"c1\"><span style=\"font-size: 15px; font-weight: bold;\">Further Editorial Thoughts...</span></p>\n<p class=\"c1\"><span class=\"c3\">Prior to doing this investigation I had some expectation that the SIAI was a money losing operation. I didn&rsquo;t expect the Singularity Summit to be making money. I had an expectation that Eliezer probably made around $70k (programmer money discounted for being paid by a non-profit). I figured the SIAI had a broad donor base of small donations. I was off base on all counts.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I had some expectation that the SIAI was a money losing operation.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">I had weak confidence in this belief, as I don&rsquo;t know a lot about the finances of public organizations. The SIAI appears to be managing its cash reserves well. It would be good to see the SIAI build up some asset reserves so that it could operate comfortably in years where public support dips or so that it could take advantage of unexpected opportunities.</span></p>\n<p class=\"c1\"><span class=\"c3\">Overall, the allocation of funds strikes me as highly efficient.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I didn&rsquo;t expect the Singularity Summit to be making money.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">This was a surprising finding, although I incorrectly conditioned my expectation from experiences working with game industry conferences. I don't know exactly how much the SIAI is spending on food and fancy tablecloths at the Singularity Summit, but I don't think I care: it's growing and showing better results on the revenue chart each year. If you attend the conference and contribute to the event you add pure value. As discussed above, the benefits of the conference appear to be very far in the &ldquo;reducing existential risk&rdquo; category. Losing the Summit would be a blow to ensuring a safe future.</span></p>\n<p class=\"c1\"><span class=\"c3\">I know that the Summit will not itself do the hard work of dissolving and solving problems, or of synthesizing new theories, or of testing those theories, or of implementing solutions. The value of the Summit lies in its ability to raise awareness of the work that needs to be done, to create networks of people to do that work, to lower public shock at the implications of that work, and generate funding for those doing that work.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I had an expectation that Eliezer probably made around $70k.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">Eliezer's compensation is slightly more than I thought. I'm not sure what upper bound I would have balked at or would balk at. I do have some concern about the cost of recruiting additional Research Fellows. The cost of additional RFs has to be weighed against new programs like Visiting Fellows.</span></p>\n<p class=\"c1\"><span class=\"c3\">At the same time, the organization has been able to expand services without draining the coffers. A donor can hold a strong expectation that the bulk of their donation will go toward actual work in the form of salaries for working personnel or events like the Visiting Fellows Program.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I figured the SIAI had a broad donor base of small donations.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">I must have been out to lunch when making this prediction. I figured the SIAI was mostly supported by futurism enthusiasts and small scale rationalists.</span></p>\n<p class=\"c1\"><span class=\"c3\">The organization has a heavy reliance on major donor support. I would expect the 2010 filing to reveal a broadening of revenue, but I do not expect the organization to have become independent of big donor support. Big donor support is a good thing to have, but more long term stability would be provided by a broader base of supporters.</span></p>\n<h2><span class=\"c3 c11\">My suggestions to the SIAI:</span></h2>\n<ul>\n<li>Consider relocating to a cheaper part of the planet. Research Fellows will likely have to accept lower than market average compensation for their work or no compensation at all. Better to live in an area where compensation goes farther.</li>\n<li>Consider increasing savings to allow for a larger safety net and the ability to take advantage of opportunities.</li>\n<li>Consider itemizing program service expenses in more detail. It isn&rsquo;t required, but the transparency makes for better decision making on the part of donors.</li>\n<li>Consider providing more information on what Eliezer and other Research Fellows are working on from time to time. You are building two communities. A community of polymaths who will solve hard problems and a community of supporters who believe in the efforts of the polymaths. The latter are more likely to continue their support if they have insight into the activities of the former.</li>\n</ul>\n<h2><span class=\"c3 c11\">Moving forward:</span></h2>\n<p class=\"c1\"><span class=\"c3\">John Salvatier provided me with good insight into next steps for gaining further clarity into the SIAI&rsquo;s operational goals, methodology, and financial standing.</span></p>\n<ul>\n<li>Contact GiveWell for expert advice on organizational analysis to help clarify good next steps.</li>\n<li><span class=\"c3\">Get more information on current and forthcoming SIAI research projects. Is there active work in the </span><span class=\"c5\"><a href=\"http://intelligence.org/research/researchareas\">research areas</a></span><span class=\"c3\"> the SIAI has identified? Is there a game plan for attacking particular problems in the research space?</span></li>\n<li>Spend some time gathering information from SIAI members on how they would utilize new funds. Are there specific opportunities the SIAI has identified? Where is the organization &ldquo;only limited by a lack of cash&rdquo; -- if they had more funds, what would they immediately pursue?</li>\n<li>Formulate methods of validating the SIAI&rsquo;s execution of goals. It appears that the Summit is an example of efficient execution of the reducing existential risk goal by legitimizing the existential risk and AGI problem space and by building networks among interested individuals. How will donors verify the value of SIAI core research work in coming years?</li>\n</ul>\n<h2><span class=\"c3 c11\">Conclusion</span></h2>\n<p class=\"c1\"><span class=\"c3\">At present, the financial position of the SIAI seems sound. The Singularity Summit stands as a particular success that should be acknowledged. The ability for the organization to reduce officer compensation at the same time it expands programs is also notable.</span></p>\n<p class=\"c1\"><span class=\"c3\">Tax documents can only tell us so much. A deeper picture of the SIAI would work to reveal more of the moving parts within the organization. It would provide a better account of monthly activities and provide a means to measure future success or failure. The question for many supporters will not be &ldquo;should I donate&rdquo; but &ldquo;should I continue to donate?&rdquo; A question that can be answered by increased and ongoing transparency.</span></p>\n<p class=\"c1\"><span class=\"c3\">It is important that those who are concerned with existential risks, AGI, and the safety of future technologies and who choose to donate to the SIAI take a role in shaping a positive future for the organization. Donating in support of AI research is valuable, but donating and also telling others about the donation is far more valuable.</span></p>\n<p class=\"c1\"><span class=\"c3\">Consider the Sequence post </span><span class=\"c5\"><a href=\"/lw/3h/why_our_kind_cant_cooperate/\">&lsquo;Why Our Kind Can&rsquo;t Cooperate.&rsquo;</a></span><span class=\"c3\"> If the SIAI is an organization worth supporting, and given that they are working in a problem space that currently only has strong traction with &ldquo;our kind,&rdquo; then there is a risk of the SIAI failing to reach its maximum potential because donors do not coordinate successfully. If you are a donor, stand up and be counted. Post on Less Wrong and describe why you donated. Let the SIAI post your name. Help other donors see that they aren&rsquo;t acting alone.</span></p>\n<p class=\"c1\"><span class=\"c3\">Similarly, if you are critical of the SIAI think about why and write it up. Create a discussion and dig into the details. The path most likely to increase existential risk is the one where rational thinkers stay silent.</span></p>\n<p class=\"c1\"><span class=\"c3\">The SIAI&rsquo;s current operating budget and donor revenue is very small. It is well within our community&rsquo;s ability to effect change.</span></p>\n<p class=\"c0\">&nbsp;</p>\n<p class=\"c0\">My research has led me to the conclusion I should donate to the SIAI (above my previous pledge in support of rationality boot camp).&nbsp;I already donate to Alcor and am an Alcor member. I have to determine an amount for the SIAI that won't cause wife aggro. Unilateral household financial decisions increase my personal existential risk. :P I will update this document or make a comment post when I know more.</p>\n<p class=\"c0\">&nbsp;</p>\n<p class=\"c0\">&nbsp;</p>\n<p class=\"c0\">References:</p>\n<p class=\"c0\"><a href=\"https://spreadsheets.google.com/ccc?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;hl=en\">My working spreadsheet is here.</a></p>\n<p class=\"c1\"><span class=\"c3\">(1)</span><span class=\"c3\"><a href=\"http://www.singularitysummit.com/\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.singularitysummit.com/\">http://www.singularitysummit.com/</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(2)</span><span class=\"c3\"><a href=\"/lw/ts/singularity_summit_2008/\">&nbsp;</a></span><span class=\"c5\"><a href=\"/lw/ts/singularity_summit_2008/\">http://lesswrong.com/lw/ts/singularity_summit_2008/</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(3)</span><span class=\"c3\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\">http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(4)</span><span class=\"c3\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\">http://www.popularmechanics.com/technology/engineering/robots/4332783</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(5)</span><span class=\"c3\"><a href=\"http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering\">http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(6)</span><span class=\"c3\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\">http://www.time.com/time/health/article/0,8599,2048138-1,00.html</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(7)&nbsp;</span><span class=\"c5\"><a href=\"http://www.sl4.org/shocklevels.html\">http://www.sl4.org/shocklevels.html</a></span></p>\n<p class=\"c0\"><span class=\"c5\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\"></a></span></p>\n<p class=\"c1\"><span class=\"c3\">(A) Summit Content</span></p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>2006 to 2009 <a href=\"http://intelligence.org/singularitysummit\">http://intelligence.org/singularitysummit</a></li>\n<li>2010 - <a href=\"http://www.vimeo.com/album/1519377\">http://www.vimeo.com/album/1519377</a></li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NrvXXL3iGjjxu5B7d": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qqhdj3W3vSfB5E9ss", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 148, "baseScore": 182, "extendedScore": null, "score": 0.00035866025158694145, "legacy": true, "legacyId": "7149", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 143, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>12/13/2011 - A 2011 update with data from the 2010 fiscal year is in progress. Should be done by the end of the week or sooner.</em></p>\n<p>&nbsp;</p>\n<p><span style=\"font-size: 16px; font-weight: bold;\">Disclaimer</span></p>\n<ul>\n<li>I am not affiliated with the <a href=\"http://intelligence.org/\">Singularity Institute for Artificial Intelligence</a>.</li>\n<li>I have not donated to the SIAI prior to writing this.</li>\n<li><span class=\"c3\">I made </span><span class=\"c5\"><a href=\"/lw/5ec/minicamp_on_rationality_awesomeness_and/40jo\">this pledge</a></span><span class=\"c3\"> prior to writing this document.</span></li>\n</ul>\n<h2 id=\"Notes\">Notes</h2>\n<ul>\n<li>Images are now hosted on LessWrong.com.</li>\n<li>The 2010 Form 990 data will be available later this month.</li>\n<li>It is not my intent to&nbsp;propagate&nbsp;misinformation. Errors will be corrected as soon as they are identified.</li>\n</ul>\n<h2 class=\"c23 c1\" id=\"Introduction\"><span class=\"c13 c11\">Introduction</span></h2>\n<p class=\"c1\"><span class=\"c3\">Acting on </span><span class=\"c5\"><a href=\"/user/gwern/\">gwern</a></span><span class=\"c3\">'s suggestion in his </span><span class=\"c5\"><a href=\"/r/discussion/lw/5el/are_girl_scout_cookies_deliciously_evil_a_case/\">Girl Scout Cookie</a></span><span class=\"c3\"> analysis, I decided to look at SIAI funding. After reading about the Visiting Fellows Program and more recently the <a href=\"/lw/4wm/rationality_boot_camp/\">Rationality Boot Camp</a>, I decided that the SIAI might be something I would want to support. I am concerned with <a href=\"http://wiki.lesswrong.com/wiki/Existential_risk\">existential risk</a> and grapple with the utility implications. I feel that I should do more.</span></p>\n<p class=\"c1\"><span class=\"c3\">I wrote on the mini-boot camp page a pledge that I would donate enough to send someone to rationality mini-boot camp. This seemed to me a small cost for the potential benefit. The SIAI might get better at building rationalists. It might build a rationalist who goes on to solve a problem. Should I donate more? I wasn\u2019t sure. I read gwern\u2019s article and realized that I could easily get more information to clarify my thinking.</span></p>\n<p class=\"c1\"><span class=\"c3\">So I downloaded the SIAI\u2019s Form 990 annual IRS filings and started to write down notes in a spreadsheet. As I gathered data and compared it to my expectations and my goals, my beliefs changed. I now believe that donating to the SIAI is valuable. I cannot hide this belief in my writing. I simply have it.</span></p>\n<p class=\"c1\"><span class=\"c3\">My goal is not to convince you to donate to the SIAI. My goal is to provide you with information necessary for you to determine for yourself whether or not you should donate to the SIAI. Or, if not that, to provide you with some direction so that you can continue your investigation.</span></p>\n<p class=\"c1\"><span class=\"c3\"><a id=\"more\"></a></span></p>\n<p class=\"c1\"><span class=\"c3\">The SIAI's Form 990's are available at </span><span class=\"c5\"><a href=\"http://www2.guidestar.org/\">GuideStar</a></span><span class=\"c3\"> and </span><span class=\"c5\"><a href=\"http://foundationcenter.org/\">Foundation Center</a></span><span class=\"c3\">. You must register in order to access the files at GuideStar.</span></p>\n<ol class=\"c14\">\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/dZZkc0\">2002</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/eOgI0B\">2003</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c1 c6 c12\"><span class=\"c5\"><a href=\"http://bit.ly/efHrQC\">2004</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/f3Ekvg\">2005</a></span><span class=\"c3\"> (Form 990)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://bit.ly/gRC7SS\">2006</a></span><span class=\"c3\"> (Form 990)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://www.guidestar.org/FinDocuments//2007/582/565/2007-582565917-0487362e-9.pdf\">2007</a></span><span class=\"c3\"> (Form 990)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://www.guidestar.org/FinDocuments//2008/582/565/2008-582565917-0599169c-Z.pdf\">2008</a></span><span class=\"c3\"> (Form 990-EZ)</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c5\"><a href=\"http://www.guidestar.org/FinDocuments//2009/582/565/2009-582565917-06b644eb-9.pdf\">2009</a></span><span class=\"c3\"> (Form 990)</span></li>\n</ol>\n<h2 id=\"SIAI_Financial_Overview\"><span class=\"c13 c11\">SIAI Financial Overview</span></h2>\n<p><span class=\"c13 c11\">The <a href=\"http://intelligence.org\">Singularity Institute for Artificial Intelligence</a> (SIAI) is a public organization working to reduce <a href=\"http://intelligence.org/files/ReducingRisks.pdf\">existential risk from future technologies</a>, in particular artificial intelligence. \"The Singularity Institute brings rational analysis and rational strategy to the challenges facing humanity as we develop cognitive technologies that will exceed the current upper bounds on human intelligence.\" The SIAI are also the founders of Less Wrong.</span></p>\n<p><img src=\"http://images.lesswrong.com/t3_5il_0.png\" alt=\"\" width=\"591\" height=\"211\"></p>\n<p><img src=\"http://images.lesswrong.com/t3_5il_1.png?v=a0ef8195b3866f478702a67e2238c3bb\" alt=\"\" width=\"296\" height=\"194\"><img src=\"http://images.lesswrong.com/t3_5il_2.png?v=27393a444aa0942ee9c2ebb93acc3a5e\" alt=\"\" width=\"296\" height=\"194\"></p>\n<p class=\"c1\"><span class=\"c3\">The graphs above offer an accurate summary of SIAI financial state since 2002. Sometimes the end of year balances listed in the Form 990 doesn\u2019t match what you\u2019d get if you did the math by hand. These are noted as discrepancies between the filed year end balance and the expected year end balance or between the filed year start balance and the expected year start balance.</span></p>\n<ol class=\"c14\">\n<li class=\"c12 c1 c6\"><span class=\"c3 c11\"><strong>Filing Error 1</strong></span><span class=\"c3\"> - There appears to be a minor typo to the effect of $4.86 in the end of year balance for the 2004 document. It appears that Part I, Line 18 has been summed incorrectly. $32,445.76 is listed, but the expected result is $32,450.41. The Part II balance sheet calculations which agree with the error so the source of the error is unclear. The start of year balance in 2005 reflects the expected value so this was probably just a typo in 2004. The following year\u2019s reported start of year balance does not contain the error.</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c3 c11\"><strong>Filing Error 2</strong></span><span class=\"c3\"> - The 2006 document reports a year start balance of $95,105.00 when the expected year start balance is $165,284.00, a discrepancy of $70,179.00. This amount is close to the estimated Program Service Accomplishments in 2005 Form 990 Part III Line F of $72,000.00. Looks like the service expenses were not included completely in Part II. The money is not missing: future forms show expected values moving forward.</span></li>\n<li class=\"c12 c1 c6\"><span class=\"c3 c11\"><strong>Theft</strong> - </span><span class=\"c3\">The organization reported $118,803.00 in theft in 2009 resulting in a year end asset balance lower than expected. </span><span class=\"c3 c10\">The SIAI is currently pursuing legal restitution.</span></li>\n</ol>\n<p class=\"c1 c6\"><span class=\"c3\">The SIAI has generated a revenue surplus every year except 2008. The 2008 deficit appears to be a cashing out of excess surplus from 2007. Asset growth indicates that the SIAI is good at utilizing the funds it has available, without overspending. The organization is expanding it\u2019s menu of services, but not so fast that it risks going broke.</span></p>\n<p class=\"c1 c6\">Nonetheless, current asset balance is insufficient to sustain a year of operation at existing rate of expenditure. Significant loss of revenue from donations would result in a shrinkage of services. Such a loss of revenue may be unlikely, but a reasonable goal for the organization would be to build up a year's reserves.</p>\n<p class=\"c1 c6\"><span style=\"font-size: 15px; font-weight: bold;\">Revenue</span></p>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><span class=\"c3\">Revenue is composed of public support, program service (events/conferences held, etc), and investment interest. The \"Other\" category tends to include Amazon.com affiliate income, etc.</span></p>\n<p class=\"c1 c9\"><img src=\"http://images.lesswrong.com/t3_5il_3.png?v=99acbb583f561c10b2f7f164f073d783\" alt=\"\" width=\"608\" height=\"259\"></p>\n<p class=\"c1 c6\"><img src=\"http://images.lesswrong.com/t3_5il_4.png?v=7f3586b662dd9967ceeeca02f0b05519\" alt=\"\" width=\"339\" height=\"187\" align=\"left\"></p>\n<p class=\"c1 c6\"><span class=\"c3\">Income from public support has grown steadily with a notable regular increase starting in 2006. This increase is a result of new contributions from big donors. As an example, public support in 2007 is largely composed of significant contributions from Peter Thiel ($125k), Brian Cartmell ($75k), and Robert F. Zahra Jr ($123k) for $323k total in large scale individual contributions (break down below).</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">In 2007 the SIAI started receiving income from program services. Currently all \"Program Service\" revenue is from operation of the Singularity Summit. In 2010 the summit generated surplus revenue for the SIAI. This is a significant achievement, as it means the organization has created a sustainable service that could fund further services moving forward.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">A specific analysis of the summit is below.</span></p>\n<h2 id=\"Expenses\"><span style=\"font-size: 15px; font-weight: bold;\">Expenses</span></h2>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><span class=\"c3\">Expenses are composed of grants paid to winners, benefits paid to members, officer compensation, contracts, travel, program services, and an other category.</span></p>\n<p class=\"c1\"><span class=\"c3\">The contracts column in the chart below includes legal and accounting fees. The other column includes administrative fees and other operational costs. I didn\u2019t see reason to break the columns down further. In many cases the Form 990s provide more detailed itemization. If you care about how much officers spent on gas or when they bought new computers you might find the answers in the source.</span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_5.png?v=d7dbe8ccc715a746bd237e4aca186d18\" alt=\"\" width=\"602\" height=\"211\"></p>\n<p class=\"c1\"><span class=\"c3\">I don\u2019t have data for 2000 or 2001, but left the rows in the spreadsheet in case it can be filled in later.</span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_6.png?v=40dc2b53beef6b4629617169a5c9fac1\" alt=\"\" width=\"350\" height=\"202\" align=\"left\"></p>\n<p class=\"c1 c6\"><span class=\"c3\">Program expenses have grown over the years, but not unreasonably. Indeed, officer compensation has declined steadily for several years. The grants in 2002, 2003, and 2004 were paid to Eliezer Yudkowsky for work relevant to Artificial Intelligence.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">The program expenses category includes operating the Singularity Summit, Visiting Fellows Program, etc. Some of the cost of these programs is also included in the other category. For example, the 2007 Singularity Summit is reported as costing $101,577.00 but this total amount is accounted for in multiple sections.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">It appears that 2009 was a more productive year than 2008 and also less expensive. 2009 saw a larger Singularity Summit than in 2008 and also the creation of the Visiting Fellows Program.</span></p>\n<h2 id=\"Big_Donors\"><span style=\"font-size: 15px; font-weight: bold;\">Big Donors</span></h2>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_7.png?v=3b5b3af66c23a90359308a68b369f487\" alt=\"\" width=\"592\" height=\"336\"></p>\n<p class=\"c1 c6\"><span class=\"c3\">This is not an exhaustive list of contributions. The SIAI\u2019s 2009 filing details major support donations for several previous years. Contributions in the 2010 column are derived from </span><span class=\"c5\"><a href=\"http://intelligence.org/donors\">http://intelligence.org/donors</a></span><span class=\"c3\">. &nbsp;Known contributions of less than $5,000 are excluded for the sake of brevity. The 2006 donation from Peter Thiel is sourced from a discussion with the SIAI.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Peter Thiel and several other big donors compose the bulk of the organization's revenue. It would be good to see a broader base of donations moving forward. Note, however, that the base of donations has been improving. I don't have the 2010 Form 990 yet, but it appears to be the best year yet in terms of both the quantity of donations and the number of individual donors (based on conversation with SIAI members).</span></p>\n<p class=\"c1 c6\"><span style=\"font-size: 15px; font-weight: bold;\">Officer Compensation</span></p>\n<p class=\"c1\"><img src=\"http://images.lesswrong.com/t3_5il_8.png?v=f9fe89c72d0fea7ec1a58f7035d93a9d\" alt=\"\" width=\"594\" height=\"147\"></p>\n<p class=\"c1 c6\"><img src=\"http://images.lesswrong.com/t3_5il_9.png?v=717b8a6e09d407d0a1e00a283657a54f\" alt=\"\" width=\"333\" height=\"218\" align=\"left\"></p>\n<p class=\"c1 c6\"><span class=\"c3\">In 2002 to 2005 Eliezer Yudkowsky received compensation in the form of grants from the SIAI for AI research. </span><em><span class=\"c3 c10\">It is noted in the Form 990s that </span><span class=\"c3 c10 c11\"><strong>no public funds </strong></span></em><span class=\"c3 c10\"><em>were used for Eliezer\u2019s research grants as he is also an officer.</em> </span><span class=\"c3\">Starting in 2006 all compensation for key officers is reported as salaried instead of in the form of grants.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Compensation spiked in 2006, the same year of greatly increased public support. Nonetheless, officer compensation has decreased steadily despite continued increases in public support. It appears that the SIAI has been managing it\u2019s resources carefully in recent years, putting more money into programs than into officer compensation.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Eliezer's base compensation as salary increased 20% in 2008. It seems reasonable to compare Eliezer's salary with that of professional software developers. Eliezer would be able to make a fair amount more working in private industry as a software developer.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Mr. Yudkowsky clarifies: \"The reason my salary shows as $95K in 2009 is that Paychex screwed up and paid my first month of salary for 2010 in the 2009 tax year. My actual salary was, I believe, constant or roughly so through 2008-2010.\" In this case we would expect to see the 2010 Form 990 show a month reduced salary.</span></p>\n<p class=\"c1 c6\"><span class=\"c3\">Moving forward, the SIAI will have to grapple with the high cost of recruiting top tier programmers and academics to do real work. I believe this is an argument for the SIAI improving its asset sheet. More money in the bank means more of an ability to take advantage of recruitment opportunities if they present themselves.</span></p>\n<h2 id=\"Singularity_Summit\"><span style=\"font-size: 15px; font-weight: bold;\">Singularity Summit</span></h2>\n<p class=\"c1 c6\"><span style=\"font-size: 15px;\"><strong></strong></span></p>\n<p class=\"c1\"><span class=\"c3\">Founded in 2006 by the SIAI in cooperation with Ray Kurzweil and Peter Thiel, the Singularity Summit focuses on a broad number of topics related to the Singularity and emerging technologies. (1)</span></p>\n<p class=\"c1 c9\"><img src=\"http://images.lesswrong.com/t3_5il_10.png?v=b0861f92f729c043979a7d8d7b9cc1f4\" alt=\"\" width=\"577\" height=\"133\"></p>\n<p class=\"c1\"><span class=\"c3\">The Singularity Summit was free until 2008 when the SIAI chose to begin charging registration fees and accepting sponsorships. (2)</span></p>\n<p class=\"c1 c9\"><img src=\"http://images.lesswrong.com/t3_5il_11.png?v=b77e680872854187f7fb9985aec738f3\" alt=\"\" align=\"left\"></p>\n<p class=\"c1\"><span class=\"c3\">Attendee counts are estimates drawn from SIAI Form 990 filings. 2010 is purported to be the largest conference so far. Beyond the core conference attendees, hundreds of thousands of online viewers are reached through recordings of the Summit sessions. (A)</span></p>\n<p class=\"c1\"><span class=\"c3\">The cost of running the summit has increased annually, but revenue from sponsorships and registration have kept pace. The conference may have logistic and administrative costs, but it doesn't really impact the SIAI budget. This makes the conference a valuable blend of outreach and education. If the conference convinces someone to donate or in some way directly support work against existential risks, the benefits are effectively free (or at the very least come at no cost to other programs).</span></p>\n<p class=\"c1\"><span style=\"font-size: 14px; font-weight: bold;\">Is the Singularity Summit successful?</span></p>\n<p class=\"c1\"><span class=\"c3\">It\u2019s difficult to evaluate the success of conferences. So many of the benefits are realized downstream of the actual event. Nonetheless, the attendee counts and widening exposure seem to bring immense value for the cost. Several factors contribute to a sense that the conference is a success:</span></p>\n<ul>\n<li>In 2010 the Summit became a positive revenue generating exercise in its own right. With careful stewardship, the Singularity Summit could grow to generate a reliable annual revenue for the SIAI.</li>\n<li>The ability to run an efficient conference is itself valuable. Should it choose to, the SIAI could run other types of conferences or special interest events in the future with a good expectation of success.</li>\n<li>The high visibility of the Summit plants seeds for future fund raising. Conference attendees likely benefit as much or more from networking as they do from the content of the sessions. Networking builds relationships between people able to coordinate to solve problems or fund solutions to problems.</li>\n<li><span class=\"c3\">The Singularity Summit has generated ongoing public interest and media coverage. Notable articles can be found in</span><span class=\"c3\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\"> </a></span><span class=\"c5\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\">Popular Science</a></span><span class=\"c3\"> (3),</span><span class=\"c3\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\"> </a></span><span class=\"c5\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\">Popular Mechanics</a></span><span class=\"c3\"> (4), the</span><span class=\"c5\"><a href=\"http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering\"> Guardian</a></span><span class=\"c3\"> (5), and</span><span class=\"c3\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\"> </a></span><span class=\"c5\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\">TIME Magazine</a></span><span class=\"c3\"> (6). Quality media coverage raises public awareness of Singularity related topics. There is a strong argument that a person with an interest in futurist or existential risk consciousness raising reaches a wide audience by supporting the Singularity Summit.</span></li>\n</ul>\n<p class=\"c1\"><span class=\"c3\">When discussing \u201cfuture shock levels\u201d -- gaps in exposure to and understanding of futurist concepts -- Eliezer Yudkowsky wrote, \u201cIn general, one shock level gets you enthusiasm, two gets you a strong reaction - wild enthusiasm or disbelief, three gets you frightened - not necessarily hostile, but frightened, and four can get you burned at the stake.\u201d (7) Most futurists are familiar with this sentiment. Increased public exposure to unfamiliar concepts through the positive media coverage brought about by the Singularity Summit works to improve the legitimacy of those concepts and reduce future shock.</span></p>\n<p class=\"c1 c21\">The result is that hard problems get easier to solve. Experts interested in helping, but afraid of social condemnation, will be more likely to do core research. The curious will be further motivated to break problems down. Vague far-mode thinking about future technologies will, for a few, shift into near-mode thinking about solutions. Public reaction to what would otherwise be shocking concepts will shift away from the extreme. The future becomes more conditioned to accept the real work and real costs of battling existential risk.</p>\n<ul>\n</ul>\n<h2 id=\"SIAI_Milestones\"><span class=\"c13 c11\">SIAI Milestones</span></h2>\n<p class=\"c1\">This is not a complete list of SIAI milestones, but covers quite a few of the materials and events that the SIAI has produced over the years.</p>\n<p class=\"c1\"><span class=\"c3\"><strong>2005</strong></span></p>\n<p><span class=\"c3\"> </span></p>\n<ul>\n<li><span class=\"c3\">RF Eliezer Yudkowsky publishes \u201c</span><span class=\"c5\"><a href=\"http://yudkowsky.net/rational/technical\">A Technical Explanation of Technical Explanation</a></span><span class=\"c3\">\u201d</span></li>\n<li><span class=\"c3\">RF Eliezer Yudkowsky writes chapters for \u201c</span><span class=\"c5\"><a href=\"http://www.amazon.com/Global-Catastrophic-Risks-Nick-Bostrom/dp/0198570503/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1304291108&amp;sr=8-1\">Global Catastrophic Risks</a></span><span class=\"c3\">\u201d</span></li>\n<li>AI and existential risk presentations at Stanford, Immortality Institute\u2019s Life Extension Conference, and the Terasem Foundation.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2006</strong></span></p>\n<ul>\n<li>Fundraising efforts expand significantly.</li>\n<li>SIAI hosts the first Singularity Summit at Stanford.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2007</strong></span></p>\n<ul>\n<li>SIAI hosts the Singularity Summit in San Francisco.</li>\n<li><span class=\"c5\"><a href=\"http://intelligence.org/blog/\">SIAI outreach blog</a></span><span class=\"c3\"> is started.</span></li>\n<li><span class=\"c5\"><a href=\"http://intelligence.org/media/interviews\">SIAI Interview Series</a></span><span class=\"c3\"> is started.</span></li>\n<li><span class=\"c5\"><a href=\"http://www.youtube.com/watch?v=0A9pGhwQbS0\">SIAI introductory video</a></span><span class=\"c3\"> is developed and released.</span></li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2008</strong></span></p>\n<ul>\n<li>SIAI hosts the Singularity Summit in San Jose.</li>\n<li>SIAI Interview Series is expanded.</li>\n<li>SIAI begins its summer intern program.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\"><strong>2009</strong></span></p>\n<p class=\"c1\"><span class=\"c3\"><strong><span style=\"font-weight: normal;\"><span class=\"c3\">Significant detail on 2009 achievements is&nbsp;</span><span class=\"c5\"><a href=\"http://intelligence.org/blog/\">available here</a></span><span class=\"c3\">. More publications are <a href=\"http://intelligence.org/research/\">available here</a>.</span></span></strong></span></p>\n<ul>\n<li>RF Eliezer Yudkowsky completes the rationality&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Sequences\">sequences</a>.</li>\n<li><a href=\"/\">Less Wrong</a> is founded.</li>\n<li>SIAI hosts the Singularity Summit in New York.</li>\n<li>RF Anna Salamon speaks on technological forecasting at the Santa Fe institute.</li>\n<li>SIAI establishes the <a href=\"http://intelligence.org/visiting-fellows/\">Visiting Fellows Program</a>. Graduate and under-graduate students within AI related disciplines develop related talks and papers.</li>\n</ul>\n<p class=\"c1\"><span class=\"c3\">Papers and talks from SIAI fellows produced in 2009:</span></p>\n<ol class=\"c14\">\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://intelligence.org/files/ChangingTheFrame.pdf\">\u201cChanging the frame of AI futurism: From storytelling to heavy-tailed, high-dimensional probability distributions\u201d</a></span><span class=\"c7\">, by Steve Rayhawk, Anna Salamon, Tom McCabe, Rolf Nelson, and Michael Anissimov. (Presented at the European Conference of Computing and Philosophy in July \u201809 (ECAP))</span></li>\n<li class=\"c16 c1\"><span class=\"c7\">\u201cArms Control and Intelligence Explosions\u201d, by Carl Shulman (Also presented at ECAP)</span></li>\n<li class=\"c1 c16\"><span class=\"c7\">\u201c</span><span class=\"c8\"><a href=\"http://bentham.k2.t.u-tokyo.ac.jp/ap-cap09/openconf/data/papers/28-2.pdf\">Machine Ethics and Superintelligence</a></span><span class=\"c7\">\u201d, by Carl Shulman and Henrik Jonsson (Presented at the Asia-Pacific Conference of Computing and Philosophy in October \u201809 (APCAP))</span></li>\n<li class=\"c16 c1\"><span class=\"c7\">\u201c</span><span class=\"c8\"><a href=\"http://bentham.k2.t.u-tokyo.ac.jp/ap-cap09/openconf/data/papers/33.pdf\">Which Consequentialism? Machine Ethics and Moral Divergence</a></span><span class=\"c7\">\u201d, by Carl Shulman and Nick Tarleton (Also presented at APCAP);</span></li>\n<li class=\"c16 c1\"><span class=\"c7\">\u201cLong-term AI forecasting: Building methodologies that work\u201d, an invited presentation by Anna Salamon at the Santa Fe Institute conference on forecasting;</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://www.vimeo.com/7318055\">\u201cShaping the Intelligence Explosion\u201d</a></span><span class=\"c7\"> and </span><span class=\"c5\"><a href=\"http://www.vimeo.com/7397629\">\u201cHow much it matters to know what matters: A back of the envelope calculation\u201d</a></span><span class=\"c3\">, presentations by Anna Salamon at the Singularity Summit 2009 in October</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://www.vimeo.com/7320152\">\u201cPathways to Beneficial Artificial General Intelligence: Virtual Pets, Robot Children, Artificial Bioscientists, and Beyond\u201d</a></span><span class=\"c7\">, a presentation by SIAI Director of Research Ben Goertzel at Singularity Summit 2009;</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://www.vimeo.com/7426357\">\u201cCognitive Biases and Giant Risks\u201d</a></span><span class=\"c7\">, &nbsp;a presentation by SIAI Research Fellow Eliezer Yudkowsky at Singularity Summit 2009;</span></li>\n<li class=\"c16 c1\"><span class=\"c8\"><a href=\"http://arxiv.org/abs/0907.5598\">\u201cConvergence of Expected Utility for Universal Artificial Intelligence\u201d</a></span><span class=\"c7\">, a paper by Peter de Blanc, an SIAI Visiting Fellow.</span></li>\n</ol>\n<p class=\"c1\"><span class=\"c3\">* Text for this list of papers reproduced from </span><span class=\"c5\"><a href=\"http://intelligence.org/blog/\">here</a></span><span class=\"c3\">.</span></p>\n<p class=\"c1\"><span class=\"c3\">A list of achievements, papers, and talks from 2010 is pending. See also the Singularity Summit content links above.</span></p>\n<p class=\"c1\"><span style=\"font-size: 15px; font-weight: bold;\">Further Editorial Thoughts...</span></p>\n<p class=\"c1\"><span class=\"c3\">Prior to doing this investigation I had some expectation that the SIAI was a money losing operation. I didn\u2019t expect the Singularity Summit to be making money. I had an expectation that Eliezer probably made around $70k (programmer money discounted for being paid by a non-profit). I figured the SIAI had a broad donor base of small donations. I was off base on all counts.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I had some expectation that the SIAI was a money losing operation.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">I had weak confidence in this belief, as I don\u2019t know a lot about the finances of public organizations. The SIAI appears to be managing its cash reserves well. It would be good to see the SIAI build up some asset reserves so that it could operate comfortably in years where public support dips or so that it could take advantage of unexpected opportunities.</span></p>\n<p class=\"c1\"><span class=\"c3\">Overall, the allocation of funds strikes me as highly efficient.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I didn\u2019t expect the Singularity Summit to be making money.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">This was a surprising finding, although I incorrectly conditioned my expectation from experiences working with game industry conferences. I don't know exactly how much the SIAI is spending on food and fancy tablecloths at the Singularity Summit, but I don't think I care: it's growing and showing better results on the revenue chart each year. If you attend the conference and contribute to the event you add pure value. As discussed above, the benefits of the conference appear to be very far in the \u201creducing existential risk\u201d category. Losing the Summit would be a blow to ensuring a safe future.</span></p>\n<p class=\"c1\"><span class=\"c3\">I know that the Summit will not itself do the hard work of dissolving and solving problems, or of synthesizing new theories, or of testing those theories, or of implementing solutions. The value of the Summit lies in its ability to raise awareness of the work that needs to be done, to create networks of people to do that work, to lower public shock at the implications of that work, and generate funding for those doing that work.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I had an expectation that Eliezer probably made around $70k.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">Eliezer's compensation is slightly more than I thought. I'm not sure what upper bound I would have balked at or would balk at. I do have some concern about the cost of recruiting additional Research Fellows. The cost of additional RFs has to be weighed against new programs like Visiting Fellows.</span></p>\n<p class=\"c1\"><span class=\"c3\">At the same time, the organization has been able to expand services without draining the coffers. A donor can hold a strong expectation that the bulk of their donation will go toward actual work in the form of salaries for working personnel or events like the Visiting Fellows Program.</span></p>\n<p class=\"c1\" style=\"padding-left: 30px;\"><span class=\"c3 c10\"><em>I figured the SIAI had a broad donor base of small donations.</em></span></p>\n<p class=\"c1\"><span class=\"c3\">I must have been out to lunch when making this prediction. I figured the SIAI was mostly supported by futurism enthusiasts and small scale rationalists.</span></p>\n<p class=\"c1\"><span class=\"c3\">The organization has a heavy reliance on major donor support. I would expect the 2010 filing to reveal a broadening of revenue, but I do not expect the organization to have become independent of big donor support. Big donor support is a good thing to have, but more long term stability would be provided by a broader base of supporters.</span></p>\n<h2 id=\"My_suggestions_to_the_SIAI_\"><span class=\"c3 c11\">My suggestions to the SIAI:</span></h2>\n<ul>\n<li>Consider relocating to a cheaper part of the planet. Research Fellows will likely have to accept lower than market average compensation for their work or no compensation at all. Better to live in an area where compensation goes farther.</li>\n<li>Consider increasing savings to allow for a larger safety net and the ability to take advantage of opportunities.</li>\n<li>Consider itemizing program service expenses in more detail. It isn\u2019t required, but the transparency makes for better decision making on the part of donors.</li>\n<li>Consider providing more information on what Eliezer and other Research Fellows are working on from time to time. You are building two communities. A community of polymaths who will solve hard problems and a community of supporters who believe in the efforts of the polymaths. The latter are more likely to continue their support if they have insight into the activities of the former.</li>\n</ul>\n<h2 id=\"Moving_forward_\"><span class=\"c3 c11\">Moving forward:</span></h2>\n<p class=\"c1\"><span class=\"c3\">John Salvatier provided me with good insight into next steps for gaining further clarity into the SIAI\u2019s operational goals, methodology, and financial standing.</span></p>\n<ul>\n<li>Contact GiveWell for expert advice on organizational analysis to help clarify good next steps.</li>\n<li><span class=\"c3\">Get more information on current and forthcoming SIAI research projects. Is there active work in the </span><span class=\"c5\"><a href=\"http://intelligence.org/research/researchareas\">research areas</a></span><span class=\"c3\"> the SIAI has identified? Is there a game plan for attacking particular problems in the research space?</span></li>\n<li>Spend some time gathering information from SIAI members on how they would utilize new funds. Are there specific opportunities the SIAI has identified? Where is the organization \u201conly limited by a lack of cash\u201d -- if they had more funds, what would they immediately pursue?</li>\n<li>Formulate methods of validating the SIAI\u2019s execution of goals. It appears that the Summit is an example of efficient execution of the reducing existential risk goal by legitimizing the existential risk and AGI problem space and by building networks among interested individuals. How will donors verify the value of SIAI core research work in coming years?</li>\n</ul>\n<h2 id=\"Conclusion\"><span class=\"c3 c11\">Conclusion</span></h2>\n<p class=\"c1\"><span class=\"c3\">At present, the financial position of the SIAI seems sound. The Singularity Summit stands as a particular success that should be acknowledged. The ability for the organization to reduce officer compensation at the same time it expands programs is also notable.</span></p>\n<p class=\"c1\"><span class=\"c3\">Tax documents can only tell us so much. A deeper picture of the SIAI would work to reveal more of the moving parts within the organization. It would provide a better account of monthly activities and provide a means to measure future success or failure. The question for many supporters will not be \u201cshould I donate\u201d but \u201cshould I continue to donate?\u201d A question that can be answered by increased and ongoing transparency.</span></p>\n<p class=\"c1\"><span class=\"c3\">It is important that those who are concerned with existential risks, AGI, and the safety of future technologies and who choose to donate to the SIAI take a role in shaping a positive future for the organization. Donating in support of AI research is valuable, but donating and also telling others about the donation is far more valuable.</span></p>\n<p class=\"c1\"><span class=\"c3\">Consider the Sequence post </span><span class=\"c5\"><a href=\"/lw/3h/why_our_kind_cant_cooperate/\">\u2018Why Our Kind Can\u2019t Cooperate.\u2019</a></span><span class=\"c3\"> If the SIAI is an organization worth supporting, and given that they are working in a problem space that currently only has strong traction with \u201cour kind,\u201d then there is a risk of the SIAI failing to reach its maximum potential because donors do not coordinate successfully. If you are a donor, stand up and be counted. Post on Less Wrong and describe why you donated. Let the SIAI post your name. Help other donors see that they aren\u2019t acting alone.</span></p>\n<p class=\"c1\"><span class=\"c3\">Similarly, if you are critical of the SIAI think about why and write it up. Create a discussion and dig into the details. The path most likely to increase existential risk is the one where rational thinkers stay silent.</span></p>\n<p class=\"c1\"><span class=\"c3\">The SIAI\u2019s current operating budget and donor revenue is very small. It is well within our community\u2019s ability to effect change.</span></p>\n<p class=\"c0\">&nbsp;</p>\n<p class=\"c0\">My research has led me to the conclusion I should donate to the SIAI (above my previous pledge in support of rationality boot camp).&nbsp;I already donate to Alcor and am an Alcor member. I have to determine an amount for the SIAI that won't cause wife aggro. Unilateral household financial decisions increase my personal existential risk. :P I will update this document or make a comment post when I know more.</p>\n<p class=\"c0\">&nbsp;</p>\n<p class=\"c0\">&nbsp;</p>\n<p class=\"c0\">References:</p>\n<p class=\"c0\"><a href=\"https://spreadsheets.google.com/ccc?key=0Av5A0Qa--iQVdGFrd1JEWks2aWh2eXJfTTJpOFBiYWc&amp;hl=en\">My working spreadsheet is here.</a></p>\n<p class=\"c1\"><span class=\"c3\">(1)</span><span class=\"c3\"><a href=\"http://www.singularitysummit.com/\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.singularitysummit.com/\">http://www.singularitysummit.com/</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(2)</span><span class=\"c3\"><a href=\"/lw/ts/singularity_summit_2008/\">&nbsp;</a></span><span class=\"c5\"><a href=\"/lw/ts/singularity_summit_2008/\">http://lesswrong.com/lw/ts/singularity_summit_2008/</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(3)</span><span class=\"c3\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near\">http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(4)</span><span class=\"c3\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.popularmechanics.com/technology/engineering/robots/4332783\">http://www.popularmechanics.com/technology/engineering/robots/4332783</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(5)</span><span class=\"c3\"><a href=\"http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering\">http://www.guardian.co.uk/technology/2008/nov/06/artificialintelligenceai-engineering</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(6)</span><span class=\"c3\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\">&nbsp;</a></span><span class=\"c5\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\">http://www.time.com/time/health/article/0,8599,2048138-1,00.html</a></span></p>\n<p class=\"c1\"><span class=\"c3\">(7)&nbsp;</span><span class=\"c5\"><a href=\"http://www.sl4.org/shocklevels.html\">http://www.sl4.org/shocklevels.html</a></span></p>\n<p class=\"c0\"><span class=\"c5\"><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\"></a></span></p>\n<p class=\"c1\"><span class=\"c3\">(A) Summit Content</span></p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>2006 to 2009 <a href=\"http://intelligence.org/singularitysummit\">http://intelligence.org/singularitysummit</a></li>\n<li>2010 - <a href=\"http://www.vimeo.com/album/1519377\">http://www.vimeo.com/album/1519377</a></li>\n</ul>\n<p>&nbsp;</p>", "sections": [{"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "SIAI Financial Overview", "anchor": "SIAI_Financial_Overview", "level": 1}, {"title": "Expenses", "anchor": "Expenses", "level": 1}, {"title": "Big Donors", "anchor": "Big_Donors", "level": 1}, {"title": "Singularity Summit", "anchor": "Singularity_Summit", "level": 1}, {"title": "SIAI Milestones", "anchor": "SIAI_Milestones", "level": 1}, {"title": "My suggestions to the SIAI:", "anchor": "My_suggestions_to_the_SIAI_", "level": 1}, {"title": "Moving forward:", "anchor": "Moving_forward_", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "207 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 207, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5swa8chZCtWynuFga", "s887k4Hcqj28cchYo", "7FzD7pNm9X68Gp5ZC", "7snc2aJhiDoppX7dW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T09:13:17.840Z", "modifiedAt": null, "url": null, "title": "The Cognitive Costs to Doing Things", "slug": "the-cognitive-costs-to-doing-things", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:35.243Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lionhearted", "createdAt": "2010-07-29T13:30:07.417Z", "isAdmin": false, "displayName": "lionhearted"}, "userId": "tooJeLNxoeccqGEky", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aNH2yrCsDhiMw5ERX/the-cognitive-costs-to-doing-things", "pageUrlRelative": "/posts/aNH2yrCsDhiMw5ERX/the-cognitive-costs-to-doing-things", "linkUrl": "https://www.lesswrong.com/posts/aNH2yrCsDhiMw5ERX/the-cognitive-costs-to-doing-things", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Cognitive%20Costs%20to%20Doing%20Things&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Cognitive%20Costs%20to%20Doing%20Things%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaNH2yrCsDhiMw5ERX%2Fthe-cognitive-costs-to-doing-things%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Cognitive%20Costs%20to%20Doing%20Things%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaNH2yrCsDhiMw5ERX%2Fthe-cognitive-costs-to-doing-things", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaNH2yrCsDhiMw5ERX%2Fthe-cognitive-costs-to-doing-things", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1113, "htmlBody": "<p>What's the mental burden of trying to do something? What's it <em>cost</em>? What price are you going to pay if you try to do something out in the world.</p>\n<p>I think that by figuring out what the usual costs to doing things are, we can reduce the costs and otherwise structure our lives so that it's easier to reach our goals.</p>\n<p>When I sat down to identify cognitive costs, I found seven. There might be more. Let's get started -</p>\n<p><strong>Activation Energy</strong> - As covered in more detail in <a href=\"http://www.sebastianmarshall.com/activation-costs\">this post</a>, starting an activity seems to take a larger of willpower and other resources than keeping going with it. Required activation energy can be adjusted over time - making something into a routine lowers the activation energy to do it. Things like having poorly defined next steps increases activation energy required to get started. This is a major hurdle for a lot of people in a lot of disciplines - just getting started.</p>\n<p><strong>Opportunity cost</strong> - We're all familiar with general opportunity cost. When you're doing one thing, you're not doing something else. You have limited time. But there also seems to be a cognitive cost to this - a natural second guessing of choices by taking one path and not another. This is the sort of thing covered by Barry Schwartz in his Paradox of Choice work (there's some faulty thought/omissions in PoC, but it's overall valuable). It's also why basically every significant military work ever has said you don't want to put the enemy in a position where their only way out is through you - Sun Tzu argued always leaving a way for the enemy to escape, which splits their focus and options. Hernan Cortes famously burned the boats behind him. When you're doing something, your mind is subtly aware and bothered by the other things you're not doing. This is a significant cost.</p>\n<p><strong>Inertia</strong> - Eliezer Yudkowsky wrote that humans are \"<a href=\"/lw/l0/adaptationexecuters_not_fitnessmaximizers/\">Adaptation-Executers, not Fitness-Maximizers</a>.\" He was speaking in terms of large scale evolution, but this is also true of our day to day affairs. Whatever personal adaptations and routines we've gotten into, we tend to perpetuate. Usually people do not break these routines unless a drastic event happens. Very few people self-scrutinize and do drastic things without an external event happening.</p>\n<p>The difference between activation energy and inertia is that you can want to do something, but be having a hard time getting started - that's activation energy. Whereas inertia suggests you'll keep doing what you've been doing, and largely turn your mind off. Breaking out of inertia takes serious energy and tends to make people uncomfortable. They usually only do it if something else makes them more uncomfortable (or, <em>very</em> rarely, when they get incredibly inspired).</p>\n<p><strong>Ego/willpower depletion</strong> - The <a href=\"http://en.wikipedia.org/wiki/Ego_depletion\">Wikipedia article on ego depletion</a> is pretty good. Basically, a lot of recent research shows that by doing something that takes significant willpower your \"battery\" of willpower gets drained some, and it becomes harder to do other high-will-required tasks. From Wikipedia: \" In an illustrative experiment on ego depletion, participants who controlled themselves by trying not to laugh while watching a comedian did worse on a later task that required self-control compared to participants who did not have to control their laughter while watching the video.\" I'd strongly recommend you do some reading on this topic if you haven't - Roy Baumeister has written some excellent papers on it. The pattern holds pretty firm - when someone resists, say, eating a snack they want, it makes it harder for them to focus and persist doing rote work later.</p>\n<p><strong>Neurosis/fear/etc</strong> - Almost all humans are naturally more risk averse than gain-inclined. This seems to have been selected for evolutionarily. We also tend to become afraid far in excess of what we should for certain kinds of activities - especially ones that risk social embarrassment.</p>\n<p>I never realized how strong these forces were until I tried to break free of them - whenever I got a strong negative reaction from someone to my writing, it made it considerably harder to write pieces that I thought would be popular later. Basic things like writing titles that would make a post spread, or polishing the first paragraph and last sentence - it's like my mind was weighing on the \"con\" side of pro/con that it would generate criticism, and it was... frightening's not quite the right word, but something like that.</p>\n<p>Some tasks can be legitimately said to be \"neurosis-inducing\" - that means, you start getting more neurotic when you ponder and start doing them. Things that are almost guaranteed to generate criticism or risk rejection frequently do this. Anything that risks compromising a person's self image can be neurosis inducing too.</p>\n<p><strong>Altering of hormonal balance</strong> - A far too frequently ignored cost. A lot of activities will change your hormonal balance for the better or worse. Entering into conflict-like situations can and does increase adrenalin and cortisol and other stress hormones. Then you face adrenalin withdrawal and crash later. Of course, we basically <em>are</em> biochemistry, so significant changing of hormonal balance affects a lot of our body - immune system, respiration, digestion, etc. A lot of people are aware of this kind of peripherally, but there hasn't been much discussion about the hormonal-altering costs of a lot of activities.</p>\n<p><strong>Maintenance costs from the idea re-emerging in your thoughts</strong> - Another under-appreciated cognitive cost is maintenance costs in your thoughts from an idea recurring, especially when the full cycle isn't complete. In Getting Things Done, David Allen talks about how \"open loops\" are \"anything that's not where it's supposed to be.\" These re-emerge in our thoughts periodically, often at inopportune times, consuming thought and energy. That's fine if the topic is exceedingly pleasant, but if it's not, it can wear you out. Completing an activity seems to reduce the maintenance cost (though not completely). An example would be not having filled your taxes out yet - it emerges in your thoughts at random times, derailing other thought. And it's usually not pleasant.</p>\n<p>Taking on any project, initiative, business, or change can generate these maintenance costs from thoughts re-emerging.</p>\n<p><strong>Conclusion</strong> I identified these seven as the mental/cognitive costs to trying to do something -</p>\n<p>&nbsp;</p>\n<ol>\n<li>Activation Energy</li>\n<li>Opportunity cost</li>\n<li>Inertia</li>\n<li>Ego/willpower depletion</li>\n<li>Neurosis/fear/etc</li>\n<li>Altering of hormonal balance</li>\n<li>Maintenance costs from the idea re-emerging in your thoughts</li>\n</ol>\n<p>&nbsp;</p>\n<p>I think we can reduce some of these costs by planning our tasks, work lives, social lives, and environment intelligently. Others of them it's good to just be aware of so we know when we start to drag or are having a hard time. Thoughts on other costs, or ways to reduce these are very welcome.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"udPbn9RthmgTtHMiG": 2, "fkABsGCJZ6y9qConW": 2, "5f5c37ee1b5cdee568cfb16a": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aNH2yrCsDhiMw5ERX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 49, "extendedScore": null, "score": 0.000147, "legacy": true, "legacyId": "7151", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XPErvb8m9FapXCjhA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T15:32:13.028Z", "modifiedAt": null, "url": null, "title": "Ames, IA LW meetup Sunday May 8 (First Iowa Meetup!) 2pm", "slug": "ames-ia-lw-meetup-sunday-may-8-first-iowa-meetup-2pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.199Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Matt_Simpson", "createdAt": "2009-03-05T21:06:45.432Z", "isAdmin": false, "displayName": "Matt_Simpson"}, "userId": "v4krJe8Qa4jnhPTmd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hs4hhG6ySw4MrLpQo/ames-ia-lw-meetup-sunday-may-8-first-iowa-meetup-2pm", "pageUrlRelative": "/posts/hs4hhG6ySw4MrLpQo/ames-ia-lw-meetup-sunday-may-8-first-iowa-meetup-2pm", "linkUrl": "https://www.lesswrong.com/posts/hs4hhG6ySw4MrLpQo/ames-ia-lw-meetup-sunday-may-8-first-iowa-meetup-2pm", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ames%2C%20IA%20LW%20meetup%20Sunday%20May%208%20(First%20Iowa%20Meetup!)%202pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAmes%2C%20IA%20LW%20meetup%20Sunday%20May%208%20(First%20Iowa%20Meetup!)%202pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhs4hhG6ySw4MrLpQo%2Fames-ia-lw-meetup-sunday-may-8-first-iowa-meetup-2pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ames%2C%20IA%20LW%20meetup%20Sunday%20May%208%20(First%20Iowa%20Meetup!)%202pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhs4hhG6ySw4MrLpQo%2Fames-ia-lw-meetup-sunday-may-8-first-iowa-meetup-2pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhs4hhG6ySw4MrLpQo%2Fames-ia-lw-meetup-sunday-may-8-first-iowa-meetup-2pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 217, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><strong>Date:</strong> Sunday May 8, 2:00pm until at least 4:00pm.</p>\n<p><strong>Venue:</strong> <a href=\"http://www.cafemiloofames.com/\">Cafe Milo</a>&nbsp;in Ames, IA (~ 1 hour from Des Moines, ~ 3 hours from Iowa City)</p>\n<p>This weekend finals are finally over at Iowa State University, so why not celebrate by holding the first LW meetup in Iowa? Apparently there are a <a href=\"/lw/43s/starting_a_lw_meetup_is_easy/3gbc\">substantial</a> amount of LWers in Ames, given it's small size, so maybe it's time we all came out of the woodwork and met each other. I'll be at Cafe Milo in Ames, IA this Sunday from 2:00pm until at least 4:00pm with a black Sony Vaio laptop, probably of stack of tests that I'm grading while I wait, and a sign that says \"Less Wrong.\" Ames is only about an hour from Des Moines, so anyone from that area or anywhere else nearby should feel free to come as well.&nbsp;I'm willing to talk about anything interesting and rationality related, but let's say the discussion topic is productivity and self improvement more generally for the purpose of having something to fall back on.&nbsp;</p>\n<p>If you're from the area, leave a comment saying whether you're coming or not! If you need to contact me directly for some reason (directions, coming late, etc.) you can call or text my cell: (three one four) four oh one - oh three oh one</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hs4hhG6ySw4MrLpQo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 7.096260051636867e-07, "legacy": true, "legacyId": "7152", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T17:36:56.280Z", "modifiedAt": null, "url": null, "title": "Personals, anyone?", "slug": "personals-anyone", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:02.118Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gray", "createdAt": "2011-03-01T21:47:09.392Z", "isAdmin": false, "displayName": "Gray"}, "userId": "GowbwHixpEz6dtGg7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QzNzEg2SvwfHN8bhe/personals-anyone", "pageUrlRelative": "/posts/QzNzEg2SvwfHN8bhe/personals-anyone", "linkUrl": "https://www.lesswrong.com/posts/QzNzEg2SvwfHN8bhe/personals-anyone", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Personals%2C%20anyone%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APersonals%2C%20anyone%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQzNzEg2SvwfHN8bhe%2Fpersonals-anyone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Personals%2C%20anyone%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQzNzEg2SvwfHN8bhe%2Fpersonals-anyone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQzNzEg2SvwfHN8bhe%2Fpersonals-anyone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 279, "htmlBody": "<p>Meet ups are great and all, but a lot of us live far away from the large masses of LW-participants.&nbsp; I live in the Toledo, Ohio area, and I'm also one of those people who are looking for people who I can relate to.&nbsp; Most people I can't relate to, intellectual conversation makes most people I know uncomfortable.&nbsp; Even people who are intelligent are often too timid to speak their minds (this could be because of the before mentioned people).&nbsp; Nothing against people who are more ordinary than I am, but I have this sense that the people I read here are people I have more in common with than most people I will ever meet by chance.</p>\n<p>I'm not looking for a date (well, I am, but not in this case), just people who I can relate to better than people I will meet by chance.&nbsp; This isn't my personal ad, but I was wondering what would be the best place to put such an ad, to see if there are people in my area who are the kind of people who would read this website?&nbsp; I'm not a transhumanist, but I'm not religious either.&nbsp; I've been an atheist since I was 12.&nbsp; I'm not autistic, but I have ADHD which I've only recently been treated for.&nbsp; This is also the main reason why I never finished college, which probably would have been *the* best way to meet people.&nbsp; So I'm looking for second or third best.</p>\n<p>After reading the recent post about the LW user who committed suicide, I realized that I could lose a lot by not making the effort of trying to reach out and meet people.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QzNzEg2SvwfHN8bhe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 20, "extendedScore": null, "score": 4.8e-05, "legacy": true, "legacyId": "7153", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T18:50:25.517Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] You Are Not Hiring the Top 1%", "slug": "seq-rerun-you-are-not-hiring-the-top-1", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.064Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tNJoKJPXPyeuuD5bX/seq-rerun-you-are-not-hiring-the-top-1", "pageUrlRelative": "/posts/tNJoKJPXPyeuuD5bX/seq-rerun-you-are-not-hiring-the-top-1", "linkUrl": "https://www.lesswrong.com/posts/tNJoKJPXPyeuuD5bX/seq-rerun-you-are-not-hiring-the-top-1", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20You%20Are%20Not%20Hiring%20the%20Top%201%25&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20You%20Are%20Not%20Hiring%20the%20Top%201%25%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtNJoKJPXPyeuuD5bX%2Fseq-rerun-you-are-not-hiring-the-top-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20You%20Are%20Not%20Hiring%20the%20Top%201%25%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtNJoKJPXPyeuuD5bX%2Fseq-rerun-you-are-not-hiring-the-top-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtNJoKJPXPyeuuD5bX%2Fseq-rerun-you-are-not-hiring-the-top-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 231, "htmlBody": "<p>Today's post, <a href=\"/lw/gy/you_are_not_hiring_the_top_1/\">You Are Not Hiring the Top 1%</a>, was originally published on 02 March 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Software companies may see themselves as being very selective about who they hire. Out of 200 applicants, they may hire just one or two. However, that doesn't necessarily mean that they're hiring the top 1%. The programmers who weren't hired are likely to apply for jobs somewhere else. Overall, the worst programmers will apply for many more jobs over the course of their careers than the best. So programmers who are applying for a particular job are not representative of programmers as a whole. This phenomenon probably shows up in other places as well.</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/gx/just_lose_hope_already/\">Just Lose Hope Already</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tNJoKJPXPyeuuD5bX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 7.096827591469197e-07, "legacy": true, "legacyId": "7154", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HCssSWMp7zoJAPtcR", "waqC6FihC2ryAZuAq", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-02T19:21:59.590Z", "modifiedAt": null, "url": null, "title": "How did you actually become more effective?", "slug": "how-did-you-actually-become-more-effective", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:02.025Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "wJvJ7vaBfTkLW2tLp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/76JXq3utbAnjpzYGp/how-did-you-actually-become-more-effective", "pageUrlRelative": "/posts/76JXq3utbAnjpzYGp/how-did-you-actually-become-more-effective", "linkUrl": "https://www.lesswrong.com/posts/76JXq3utbAnjpzYGp/how-did-you-actually-become-more-effective", "postedAtFormatted": "Monday, May 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20did%20you%20actually%20become%20more%20effective%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20did%20you%20actually%20become%20more%20effective%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F76JXq3utbAnjpzYGp%2Fhow-did-you-actually-become-more-effective%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20did%20you%20actually%20become%20more%20effective%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F76JXq3utbAnjpzYGp%2Fhow-did-you-actually-become-more-effective", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F76JXq3utbAnjpzYGp%2Fhow-did-you-actually-become-more-effective", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 455, "htmlBody": "<p>Like many people here, I think a lot about how to become more awesome. I'm fairly optimistic about my chances, because I can clearly remember times in the past when I was less awesome than I am now-- not necessarily less rational, but less productive and with fewer relevant skills.<sup>1</sup></p>\r\n<p>So I've been thinking about what changes I believe have&nbsp;most improved&nbsp;my effectiveness, changes which have caused me to learn many useful things and/or greatly increased my productive capacity. I found the list interesting:</p>\r\n<ul>\r\n<li>Getting into a comfortable, highly supportive relationship: it has tremendously decreased my level of anxiety, improved my motivation to maintain a basic level of functioning, and increased my reserve capacity.</li>\r\n<li>Finding enjoyable,&nbsp;appropriately challenging but&nbsp;low-stress work. Work forces me to get out of the house and interact with other humans, keeps me away from harmful behaviors like playing video games for hours, provides mental stimulation, and boosts my self-worth. Since&nbsp;I work as a math tutor, it's also been great practice at teaching, doing math, and the kind of general personhood skills that fall under the heading of Professionalism.</li>\r\n<li>Attempting very difficult things at which I was highly motivated to succeed (but was not necessarily successful). These are the times when I've learned the most.</li>\r\n<li>Limiting my own access to time-wasters by using LeechBlock and being commited to a schedule(LW is certainly on the list of time-wasters).</li>\r\n</ul>\r\n<p>Things which are notably not on the list:</p>\r\n<ul>\r\n<li>Therapy. If you have found therapy helpful,&nbsp;I'd really appreciate&nbsp;hearing exactly how you&nbsp;used it. It hasn't been worth a damn for me.</li>\r\n<li>ADD meds. (Depression meds were somewhat helpful when I was actually depressed, however.)</li>\r\n<li>Ambitious self-improvement projects undertaken alone, or without major consequences for failure (including but not limited to diets, exercise programs, and extensive programs of independent study<sup>3</sup>).</li>\r\n</ul>\r\n<p>So how have you actually improved your own effectiveness?</p>\r\n<p><sup>1 </sup>Some of these less-awesome past versions&nbsp;of me suffered from clinical depression, but the last time I had a major episode of depression I was able to deal with it much more purposefully than in the past and still accomplish a large percentage of&nbsp;the shit I was supposed to be doing, so I think there has been improvement independent of my state of mental health.</p>\r\n<p><sup>2 </sup>Major consequences for failure seem to be very effective motivators, but since&nbsp;I want to undertake projects that are difficult enough to have a&nbsp;significant chance of failure, I would like these consequences to be highly motivating without being horribly costly, if possible. Ideas?</p>\r\n<p><sup>3 </sup>I have learned a lot from pleasure reading, but I'm not sure how much was actually useful, and since I've been reading for pleasure since&nbsp;I can remember there's no easy before-and-after comparison to make.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "76JXq3utbAnjpzYGp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 7.09691798886316e-07, "legacy": true, "legacyId": "7155", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T01:34:26.807Z", "modifiedAt": null, "url": null, "title": "Proposal: consolidate meetup announcements before promotion", "slug": "proposal-consolidate-meetup-announcements-before-promotion", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.920Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eaKHojBdtsf35937k/proposal-consolidate-meetup-announcements-before-promotion", "pageUrlRelative": "/posts/eaKHojBdtsf35937k/proposal-consolidate-meetup-announcements-before-promotion", "linkUrl": "https://www.lesswrong.com/posts/eaKHojBdtsf35937k/proposal-consolidate-meetup-announcements-before-promotion", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Proposal%3A%20consolidate%20meetup%20announcements%20before%20promotion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProposal%3A%20consolidate%20meetup%20announcements%20before%20promotion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeaKHojBdtsf35937k%2Fproposal-consolidate-meetup-announcements-before-promotion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Proposal%3A%20consolidate%20meetup%20announcements%20before%20promotion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeaKHojBdtsf35937k%2Fproposal-consolidate-meetup-announcements-before-promotion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeaKHojBdtsf35937k%2Fproposal-consolidate-meetup-announcements-before-promotion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 132, "htmlBody": "<p>The Less Wrong feed is getting crowded with meetups rather than substantive posts. Hopefully, this should be fixed in the <a href=\"/lw/5by/official_less_wrong_redesign_call_for_suggestions/\">redesign</a>, but one way to work around it in the meanwhile would be to make top-level posts announcing several meetups at once.</p>\n<p>Folk would post meetups under the 'NEW' category, and each week or even every several days one of the meetup organizers could edit her post to announce all the meetups since the last consolidated post. This would greatly reduce the cluster while still getting meetups in the main feed. On the other hand, it would reduce average warning time before meetups, and the additional activation energy might deter some meetups.</p>\n<p>If you have thoughts on the workability of this scheme, or an adjustment to make it workable, please comment below.</p>\n<p>[HT: Anna Salamon]</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eaKHojBdtsf35937k", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 17, "extendedScore": null, "score": 7.097984696084235e-07, "legacy": true, "legacyId": "7162", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["g96zwWHArQFK8HjNd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T02:39:55.204Z", "modifiedAt": null, "url": null, "title": "DC Meetup: Discussion", "slug": "dc-meetup-discussion-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:51.652Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/96BN5dKQtaQtGqR7v/dc-meetup-discussion-0", "pageUrlRelative": "/posts/96BN5dKQtaQtGqR7v/dc-meetup-discussion-0", "linkUrl": "https://www.lesswrong.com/posts/96BN5dKQtaQtGqR7v/dc-meetup-discussion-0", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20DC%20Meetup%3A%20Discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADC%20Meetup%3A%20Discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F96BN5dKQtaQtGqR7v%2Fdc-meetup-discussion-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=DC%20Meetup%3A%20Discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F96BN5dKQtaQtGqR7v%2Fdc-meetup-discussion-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F96BN5dKQtaQtGqR7v%2Fdc-meetup-discussion-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<p>LessWrong DC has had its first meetup! 13 people showed up, and it was pretty fun.<br /><br />We have a google group <a href=\"http://groups.google.com/group/lesswrong-dc\">here</a>, and will have most of the planning there.<br /><br />However, we haven't met all the LWers in the DC area yet, so that's what this thread is for.<br /><br />We're meeting again on the 15th, but were wondering -- is there anyone in Northern Virginia who would be potentially interested, but didn't come?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "96BN5dKQtaQtGqR7v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.098172240773315e-07, "legacy": true, "legacyId": "7164", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T16:17:46.025Z", "modifiedAt": null, "url": null, "title": "Cryonics-related (links)", "slug": "cryonics-related-links", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:50.286Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yBwG8TksqWHZTD7Ym/cryonics-related-links", "pageUrlRelative": "/posts/yBwG8TksqWHZTD7Ym/cryonics-related-links", "linkUrl": "https://www.lesswrong.com/posts/yBwG8TksqWHZTD7Ym/cryonics-related-links", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics-related%20(links)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics-related%20(links)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyBwG8TksqWHZTD7Ym%2Fcryonics-related-links%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics-related%20(links)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyBwG8TksqWHZTD7Ym%2Fcryonics-related-links", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyBwG8TksqWHZTD7Ym%2Fcryonics-related-links", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 24, "htmlBody": "<p><a href=\"http://www.myfoxboston.com/dpp/news/offbeat/british-baby-girl-brought-back-to-life-after-being-frozen-for-three-days-25-ncx-20110303\">British baby girl brought back to life after being frozen for three days</a><br /><br /> <a href=\"http://www.youtube.com/watch?v=uVAaZVz9pDs\">Mark Roth: Suspended animation is within our grasp</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yBwG8TksqWHZTD7Ym", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 9, "extendedScore": null, "score": 7.100515660751769e-07, "legacy": true, "legacyId": "7170", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T16:48:09.957Z", "modifiedAt": null, "url": null, "title": "Discussion: Pathways for the Aspiring AGI Researcher?", "slug": "discussion-pathways-for-the-aspiring-agi-researcher", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.985Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Zetetic", "createdAt": "2010-08-02T17:08:44.781Z", "isAdmin": false, "displayName": "Zetetic"}, "userId": "BN7fbmHCbiE3zB4yQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XQH69YKcscpEge7kx/discussion-pathways-for-the-aspiring-agi-researcher", "pageUrlRelative": "/posts/XQH69YKcscpEge7kx/discussion-pathways-for-the-aspiring-agi-researcher", "linkUrl": "https://www.lesswrong.com/posts/XQH69YKcscpEge7kx/discussion-pathways-for-the-aspiring-agi-researcher", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Discussion%3A%20Pathways%20for%20the%20Aspiring%20AGI%20Researcher%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADiscussion%3A%20Pathways%20for%20the%20Aspiring%20AGI%20Researcher%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQH69YKcscpEge7kx%2Fdiscussion-pathways-for-the-aspiring-agi-researcher%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Discussion%3A%20Pathways%20for%20the%20Aspiring%20AGI%20Researcher%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQH69YKcscpEge7kx%2Fdiscussion-pathways-for-the-aspiring-agi-researcher", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQH69YKcscpEge7kx%2Fdiscussion-pathways-for-the-aspiring-agi-researcher", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 465, "htmlBody": "<p>Follow up to: <a href=\"/lw/38u/best_career_models_for_doing_research\">Best career models for doing research?</a></p>\n<p>First, I must apologize for the somewhat self-serving post, but as it <em>is</em> in the discussion section I hope that this can be forgiven. Also, I would not be surprised if there are <em>at least</em> <em>a few</em> college age people lurking around with very similar problems/issues, so I expect that this might prove very useful to at least a couple of people here. If this works out, I do hope to eventually put it into the form of a more general top-level post on career advice for those interested in a career in AGI.</p>\n<p>Now, on to the issue:</p>\n<p>It has come to my attention that research opportunities in AGI appear to both be somewhat limited, and somewhat unstructured compared to more well-developed fields that I have looked into. It seems to me that it would be useful to have a discussion here, given the unusual population density of AGI enthusiasts/professionals, about the possible pathways that one might take after the completion of an undergraduate degree. In my case, I have a strong background in mathematics, computer science and philosophy as well as a growing knowledge base in psychology. I've been studying Pearl's work, Timeless Decision Theory, cognitive science, evolutionary and cognitive psychology, Bishop's book on Pattern Recognition and Machine Learning, the link between category theory and cognitive science/AI (which appears to have some promise for building ontologies that can combine concepts and generalize), game theory, probability/statistics, computational complexity and I have been trying to get a few more programming languages under my belt.</p>\n<p>My initial impulse was to go ahead and study for, and then take, all of the relevant GRE subject tests (Mathematics, Psychology and Computer science anyway) and apply to cognitive science and computer science programs with strong AGI groups. I've found that the latter option is more difficult that I had realized, which is somewhat disheartening, as my future planning model does not seem to work in such an underdeveloped field, and there is no easy to find established standard source for finding out which schools/programs to look at. I also realized that the former option does not necessarily conform to my research interestes as much as I would like it to, this being a fairly long term commitment.</p>\n<p>Perhaps I lack the knowledge to successfully evaluate AGI programs; perhaps in the case of this particular area getting a PhD is not the best option; perhaps if I were more knowledgeable or wiser I might be better able to navigate where to go next, but I seem to be at a loss here. So; I come to you, fellow Less Wrongians, in search of guidance. Can any of you help to point me (and hopefully plenty of others) in the right (or at least <em>less wrong</em>) direction?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XQH69YKcscpEge7kx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 7.100602790483328e-07, "legacy": true, "legacyId": "7171", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rNkFLv9tXzq8Lrvrc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T17:57:35.700Z", "modifiedAt": null, "url": null, "title": "Terrorist leaders are not about Terror", "slug": "terrorist-leaders-are-not-about-terror", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:55.699Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ShebEG693ddqHZjdm/terrorist-leaders-are-not-about-terror", "pageUrlRelative": "/posts/ShebEG693ddqHZjdm/terrorist-leaders-are-not-about-terror", "linkUrl": "https://www.lesswrong.com/posts/ShebEG693ddqHZjdm/terrorist-leaders-are-not-about-terror", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Terrorist%20leaders%20are%20not%20about%20Terror&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATerrorist%20leaders%20are%20not%20about%20Terror%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FShebEG693ddqHZjdm%2Fterrorist-leaders-are-not-about-terror%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Terrorist%20leaders%20are%20not%20about%20Terror%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FShebEG693ddqHZjdm%2Fterrorist-leaders-are-not-about-terror", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FShebEG693ddqHZjdm%2Fterrorist-leaders-are-not-about-terror", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 186, "htmlBody": "<p>From <a href=\"http://www.miller-mccune.com/culture-society/academics-doubt-impact-of-bin-laden-death-30791/\">\"Academics Doubt Impact of Osama bin Laden&rsquo;s Death\"</a>:</p>\n<blockquote>\n<p>\"...Fifty-three percent of the terrorist organizations that suffered such  a violent leadership loss fell apart &mdash; which sounds impressive until  you discover that 70 percent of groups who did not deal with an  assassination no longer exist.</p>\n<p>Further crunching of the numbers  revealed that leadership decapitation becomes more counterproductive the  older the group is. The difference in collapse rates (between groups  that did and did not have a leader assassinated) is fairly small among  organizations less than 20 years old but quite large for those more than  20 years in age, and even larger for those that have been around more  than 30 years.</p>\n<p>Assassination of a leader does seem to negatively  impact smaller terrorist groups: The data shows organizations with fewer  than 500 members are more likely to collapse if they suffer such a  leadership loss. But organizations with more than 500 members are  actually more likely to survive after an assassination, making this  strategy &ldquo;highly counterproductive for larger groups,&rdquo; Jordan writes.\"</p>\n</blockquote>\n<p>See also <a href=\"/lw/le/lost_purposes/\">Lost Purposes</a>, <a href=\"/lw/1ws/the_importance_of_goodharts_law/\">The Importance of Goodhart's Law</a>, &amp; <a href=\"/lw/qi/faster_than_science/\">Faster than Science</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ShebEG693ddqHZjdm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 4, "extendedScore": null, "score": 7.100801796446146e-07, "legacy": true, "legacyId": "7172", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sP2Hg6uPwpfp3jZJN", "YtvZxRpZjcFNwJecS", "xTyuQ3cgsPjifr7oj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T18:13:57.618Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Policy Debates Should Not Appear One-Sided", "slug": "seq-rerun-policy-debates-should-not-appear-one-sided", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:49.206Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sSMiq68F9ipHmNeSF/seq-rerun-policy-debates-should-not-appear-one-sided", "pageUrlRelative": "/posts/sSMiq68F9ipHmNeSF/seq-rerun-policy-debates-should-not-appear-one-sided", "linkUrl": "https://www.lesswrong.com/posts/sSMiq68F9ipHmNeSF/seq-rerun-policy-debates-should-not-appear-one-sided", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Policy%20Debates%20Should%20Not%20Appear%20One-Sided&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Policy%20Debates%20Should%20Not%20Appear%20One-Sided%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsSMiq68F9ipHmNeSF%2Fseq-rerun-policy-debates-should-not-appear-one-sided%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Policy%20Debates%20Should%20Not%20Appear%20One-Sided%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsSMiq68F9ipHmNeSF%2Fseq-rerun-policy-debates-should-not-appear-one-sided", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsSMiq68F9ipHmNeSF%2Fseq-rerun-policy-debates-should-not-appear-one-sided", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 238, "htmlBody": "<p>Today's post, <a href=\"/lw/gz/policy_debates_should_not_appear_onesided/\">Policy Debates Should Not Appear One-Sided</a>, was originally published on 03 March 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Robin Hanson proposed a \"banned products shop\" where things that the government ordinarily would ban are sold. Eliezer responded that this would probably cause at least one stupid and innocent person to die. He became surprised when people inferred from this remark that he was against Robin's idea. Policy questions are complex actions with many consequences. Thus they should only rarely appear one-sided to an objective observer. A person's intelligence is largely a product of circumstances they cannot control. Eliezer argues for cost-benefit analysis instead of traditional libertarian ideas of tough-mindedness (people who do stupid things deserve their consequences).</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/gy/you_are_not_hiring_the_top_1/\">You Are Not Hiring the Top 1%</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sSMiq68F9ipHmNeSF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.100848706028994e-07, "legacy": true, "legacyId": "7173", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PeSzc9JTBxhaYRp9b", "HCssSWMp7zoJAPtcR", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T18:37:42.698Z", "modifiedAt": null, "url": null, "title": "[link] Bruce Schneier on Cognitive Biases in Risk Analysis", "slug": "link-bruce-schneier-on-cognitive-biases-in-risk-analysis", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:49.328Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MRNpGhJFR8fw5rrQ8/link-bruce-schneier-on-cognitive-biases-in-risk-analysis", "pageUrlRelative": "/posts/MRNpGhJFR8fw5rrQ8/link-bruce-schneier-on-cognitive-biases-in-risk-analysis", "linkUrl": "https://www.lesswrong.com/posts/MRNpGhJFR8fw5rrQ8/link-bruce-schneier-on-cognitive-biases-in-risk-analysis", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Bruce%20Schneier%20on%20Cognitive%20Biases%20in%20Risk%20Analysis&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Bruce%20Schneier%20on%20Cognitive%20Biases%20in%20Risk%20Analysis%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMRNpGhJFR8fw5rrQ8%2Flink-bruce-schneier-on-cognitive-biases-in-risk-analysis%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Bruce%20Schneier%20on%20Cognitive%20Biases%20in%20Risk%20Analysis%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMRNpGhJFR8fw5rrQ8%2Flink-bruce-schneier-on-cognitive-biases-in-risk-analysis", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMRNpGhJFR8fw5rrQ8%2Flink-bruce-schneier-on-cognitive-biases-in-risk-analysis", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>A very clear-minded introduction to map-vs-territory ideas in the context of risk analysis. Nothing particularly new here, though the specific examples he gives may be of interest to LW readers.</p>\n<p>http://www.ted.com/talks/bruce_schneier.html</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MRNpGhJFR8fw5rrQ8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 14, "extendedScore": null, "score": 7.100916788043217e-07, "legacy": true, "legacyId": "7174", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-03T23:38:27.270Z", "modifiedAt": null, "url": null, "title": "[link] Whole Brain Emulation and the Evolution of Superorganisms", "slug": "link-whole-brain-emulation-and-the-evolution-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:53.761Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bjQroWRe33yQM75Ha/link-whole-brain-emulation-and-the-evolution-of", "pageUrlRelative": "/posts/bjQroWRe33yQM75Ha/link-whole-brain-emulation-and-the-evolution-of", "linkUrl": "https://www.lesswrong.com/posts/bjQroWRe33yQM75Ha/link-whole-brain-emulation-and-the-evolution-of", "postedAtFormatted": "Tuesday, May 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Whole%20Brain%20Emulation%20and%20the%20Evolution%20of%20Superorganisms&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Whole%20Brain%20Emulation%20and%20the%20Evolution%20of%20Superorganisms%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbjQroWRe33yQM75Ha%2Flink-whole-brain-emulation-and-the-evolution-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Whole%20Brain%20Emulation%20and%20the%20Evolution%20of%20Superorganisms%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbjQroWRe33yQM75Ha%2Flink-whole-brain-emulation-and-the-evolution-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbjQroWRe33yQM75Ha%2Flink-whole-brain-emulation-and-the-evolution-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 199, "htmlBody": "<p>Robin Hanson has made <a href=\"http://www.overcomingbias.com/2011/05/em-min-wage-risks-slavery.html\">several</a> <a href=\"http://www.overcomingbias.com/2011/05/super-watch-dilemna.html\">recent</a> <a href=\"http://www.overcomingbias.com/2011/05/ems-all-newly-trained.html\">posts</a> on Overcoming Bias about upload economics. I remain mystified why he doesn't link to or otherwise reference or comment on Carl Shulman's 2010 paper, <a href=\"http://intelligence.org/upload/WBE-superorganisms.pdf\">Whole Brain Emulation and the Evolution of Superorganisms</a>, which mentions many of the same ideas and seems to have taken them to their logical conclusions. I was going to complain again in the comments section over there, but then I noticed that the paper hasn't been posted or discussed here either. So here's the abstract. (See above link for the full paper.)</p>\n<blockquote>\n<p>Many scientists expect the eventual development of intelligent software programs capable of closely emulating human brains, to the point of substituting for human labor in almost every economic niche. As software, such emulations could be cheaply copied, with copies subsequently diverging and interacting with their copy-relatives. This paper examines a set of evolutionary pressures on interaction between related emulations, pressures favoring the emergence of <em>superorganisms</em>, groups of emulations ready to self-sacrifice in service of the superorganism. We argue that the increased capacities and internal coordination of such superorganisms could pose increased risks of overriding human values, but also could facilitate the solution of global coordination problems.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb2ac": 2, "5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bjQroWRe33yQM75Ha", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 25, "extendedScore": null, "score": 7.101778952954543e-07, "legacy": true, "legacyId": "7175", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T01:02:51.744Z", "modifiedAt": null, "url": null, "title": "Pleasure, Desire, and Arguing about Definitions", "slug": "pleasure-desire-and-arguing-about-definitions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.968Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rT3GqMmb8rf5Pf7Af/pleasure-desire-and-arguing-about-definitions", "pageUrlRelative": "/posts/rT3GqMmb8rf5Pf7Af/pleasure-desire-and-arguing-about-definitions", "linkUrl": "https://www.lesswrong.com/posts/rT3GqMmb8rf5Pf7Af/pleasure-desire-and-arguing-about-definitions", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pleasure%2C%20Desire%2C%20and%20Arguing%20about%20Definitions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APleasure%2C%20Desire%2C%20and%20Arguing%20about%20Definitions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrT3GqMmb8rf5Pf7Af%2Fpleasure-desire-and-arguing-about-definitions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pleasure%2C%20Desire%2C%20and%20Arguing%20about%20Definitions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrT3GqMmb8rf5Pf7Af%2Fpleasure-desire-and-arguing-about-definitions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrT3GqMmb8rf5Pf7Af%2Fpleasure-desire-and-arguing-about-definitions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 104, "htmlBody": "<p>This post is a bit of shameless self-promotion, but also a pointer to an example of Yudkowskian philosophy at work that LWers may enjoy, this time concerning philosophical theories of desire.</p>\n<p>Episode 14 of my podcast with Alonzo Fyfe, <em><a href=\"http://commonsenseatheism.com/?p=11626\">Morality in the Real World</a></em>, begins to dissolve some common philosophical debates about the nature of desire by <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">replacing the symbol with the substance</a>, etc. Transcript and links <a href=\"http://commonsenseatheism.com/?p=12273\">here</a>, mp3 <a href=\"http://www.archive.org/download/MoralityInTheRealWorldpodcast/14PleasureDesireAndArguingAboutDefinitions.mp3\">here</a>. The episode can also probably serve as a big hint of where I'm going with <a href=\"http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">my metaethics sequence</a>.</p>\n<p>Warning: Alonzo and I are not voice actors, and my sound engineering cannot compare to that of <a href=\"http://www.radiolab.org/\">Radiolab</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rT3GqMmb8rf5Pf7Af", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 7.102019567364904e-07, "legacy": true, "legacyId": "7177", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["GKfPL6LQFgB49FEnv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T02:21:50.156Z", "modifiedAt": null, "url": null, "title": "Official Less Wrong Redesign: View defaults for new users", "slug": "official-less-wrong-redesign-view-defaults-for-new-users", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.187Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hqyGTtBa2stEyXuM5/official-less-wrong-redesign-view-defaults-for-new-users", "pageUrlRelative": "/posts/hqyGTtBa2stEyXuM5/official-less-wrong-redesign-view-defaults-for-new-users", "linkUrl": "https://www.lesswrong.com/posts/hqyGTtBa2stEyXuM5/official-less-wrong-redesign-view-defaults-for-new-users", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Official%20Less%20Wrong%20Redesign%3A%20View%20defaults%20for%20new%20users&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOfficial%20Less%20Wrong%20Redesign%3A%20View%20defaults%20for%20new%20users%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhqyGTtBa2stEyXuM5%2Fofficial-less-wrong-redesign-view-defaults-for-new-users%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Official%20Less%20Wrong%20Redesign%3A%20View%20defaults%20for%20new%20users%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhqyGTtBa2stEyXuM5%2Fofficial-less-wrong-redesign-view-defaults-for-new-users", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhqyGTtBa2stEyXuM5%2Fofficial-less-wrong-redesign-view-defaults-for-new-users", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 120, "htmlBody": "<p>Following along from <a href=\"/user/louie\">Louie</a>'s <a href=\"/lw/5by/official_less_wrong_redesign_call_for_suggestions/\">post</a> and the discussion around it&hellip;</p>\n<p>How should new visitors to Lesswrong see posts and comments ordered and filtered? (Assume we'll address the <a href=\"/lw/5by/official_less_wrong_redesign_call_for_suggestions/3zb8\">new visitors should be introduced to the site</a> issue.) These will remain settings that are easily changed, but how should they start?</p>\n<p><strong>Current defaults:</strong><br />Promoted posts, ordered by recency is our most prominent post list.<br />Comments are sorted by \"Popular\", which is Top with a very strong ageing of points (so recently voted comments rise to the top of the list, and very high voted comments fairly quickly drop away).</p>\n<p>Options seeded in comments by me below, my karma balance at bottom. Please vote on at least one \"Posts:\" comment and one \"Comments:\" comment.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hqyGTtBa2stEyXuM5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.102247407358797e-07, "legacy": true, "legacyId": "7180", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["g96zwWHArQFK8HjNd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T02:25:26.788Z", "modifiedAt": null, "url": null, "title": "The importance of open-source cryptography for Singleton prevention", "slug": "the-importance-of-open-source-cryptography-for-singleton", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:52.836Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "snarles", "createdAt": "2009-06-01T03:48:38.132Z", "isAdmin": false, "displayName": "snarles"}, "userId": "YsmFaM5MdsDW8GNop", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8tGgNE3NG7vSsAzoJ/the-importance-of-open-source-cryptography-for-singleton", "pageUrlRelative": "/posts/8tGgNE3NG7vSsAzoJ/the-importance-of-open-source-cryptography-for-singleton", "linkUrl": "https://www.lesswrong.com/posts/8tGgNE3NG7vSsAzoJ/the-importance-of-open-source-cryptography-for-singleton", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20importance%20of%20open-source%20cryptography%20for%20Singleton%20prevention&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20importance%20of%20open-source%20cryptography%20for%20Singleton%20prevention%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8tGgNE3NG7vSsAzoJ%2Fthe-importance-of-open-source-cryptography-for-singleton%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20importance%20of%20open-source%20cryptography%20for%20Singleton%20prevention%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8tGgNE3NG7vSsAzoJ%2Fthe-importance-of-open-source-cryptography-for-singleton", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8tGgNE3NG7vSsAzoJ%2Fthe-importance-of-open-source-cryptography-for-singleton", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 426, "htmlBody": "<p>I'm sure most of the readers of lesswrong and overcomingbias would consider a (edit: non-FAI) singleton scenario undesirable.&nbsp; (In a singleton scenario, a single political power or individual rules over most of humanity.)</p>\n<p>Singleton could occur if a group of people developed Artificial General Intelligence with a significant lead over their competitors.&nbsp; The economic advantage from sole possession of AGI technology would allow the controllers of the technology the opportunity to gain a economic or even a political monopoly in a relatively short timescale.</p>\n<p>This particular risk, as Robin Hanson pointed out, is less plausible if the \"race for AGI\" involves many competitors, and no competitor can gain too large of a lead over others.&nbsp; This \"close race\" scenario is more likely if there is an \"open-source\" attitude in the AGI community.&nbsp; Even if private organizations attempt to maintain exclusive control of their own innovations, one might hope that hackers or internal leaks would release essential breakthroughs before the innovators could gain too much of a lead.</p>\n<p>Then, supposing AGI is rapidly acquired by many different powers soon after its development, one can further hope that the existence of multiple organizations with AGI with differing goals would serve to prevent any one power from gaining a monopoly using AGI.</p>\n<p>This post is concerned with what happens <em>afterwards</em>, when AGI technology is more or less publicly available.&nbsp; In this situation, the long-term freedom of humanity is still not guaranteed, because disparities in access to computational power could still allow one power to gain a technological lead over the rest of humanity.&nbsp; Technological leads in the form of conventional warfare technologies are not as likely, and perhaps not even as threatening, as technological leads in the form of breakthroughs in cryptography.</p>\n<p>In this information-dependent post-utopia, any power which manages to take control of the computational structures of a society would gain incredible leverage.&nbsp; Any military power which could augment their conventional forces with the ability to intercept all of their enemies' communications whilst protecting their own would enjoy an incredible tactical advantage.&nbsp; In the post-AGI world, the key risk for singleton is exclusive access to key-cracking technology.</p>\n<p>Therefore, a long-term plan for avoiding singleton includes not only measures to promote \"open-source\" sharing of AGI-relevant technologies, but also \"open-source\" sharing of cryptographic innovations.</p>\n<p>Since any revolutions in cryptography are likely to come from mathematical breakthroughs, a true \"open-source\" policy for cryptography would include measures to make mathematical knowledge available on an unprecedented scale.&nbsp; A first step to carrying out such a plan might include encoding of core mathematical results in an open-source database of formal proofs.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8tGgNE3NG7vSsAzoJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -6, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "7184", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T02:59:47.067Z", "modifiedAt": null, "url": null, "title": "Track Your Happiness", "slug": "track-your-happiness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:35.922Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Matt_Simpson", "createdAt": "2009-03-05T21:06:45.432Z", "isAdmin": false, "displayName": "Matt_Simpson"}, "userId": "v4krJe8Qa4jnhPTmd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iorsRGY63L2vemGP3/track-your-happiness", "pageUrlRelative": "/posts/iorsRGY63L2vemGP3/track-your-happiness", "linkUrl": "https://www.lesswrong.com/posts/iorsRGY63L2vemGP3/track-your-happiness", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Track%20Your%20Happiness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATrack%20Your%20Happiness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiorsRGY63L2vemGP3%2Ftrack-your-happiness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Track%20Your%20Happiness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiorsRGY63L2vemGP3%2Ftrack-your-happiness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiorsRGY63L2vemGP3%2Ftrack-your-happiness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 199, "htmlBody": "<p><a href=\"http://www.trackyourhappiness.org/\">Track your happiness</a> using your iphone:</p>\n<blockquote>\n<p>For thousands of years, people have been trying to understand the causes of happiness. What is it that makes people happy? Yet it wasn&rsquo;t until very recently that science has turned its attention to this issue.</p>\n<p class=\"MsoNoSpacing\">Track Your Happiness.org is a new scientific research project that aims to use modern technology to help answer this age-old question. Using this site in conjunction with your iPhone, you can systematically track your happiness and find out what factors &ndash; for you personally &ndash; are associated with greater happiness. Your responses, along with those from other users of trackyourhappiness.org, will also help us learn more about the causes and correlates of happiness.</p>\n</blockquote>\n<p>Seems like a no-brainer to use this to me, at least if you have an iphone. For those with a droid, according to their <a href=\"http://twitter.com/#!/trackhappiness\">twitter feed</a>:</p>\n<blockquote>\n<p class=\"MsoNoSpacing\">the next item on the roadmap is to make track your happiness available to as many people/phones as possible.</p>\n</blockquote>\n<p class=\"MsoNoSpacing\">Despite being a really cool app for managing your happiness, this is just a great idea for doing research. Now I want to take advantage of the large iphone/droid user base to learn about people in some way. Any ideas?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iorsRGY63L2vemGP3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.102356223336254e-07, "legacy": true, "legacyId": "7185", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T04:27:29.657Z", "modifiedAt": null, "url": null, "title": "A Delayed Epiphany on Motivation", "slug": "a-delayed-epiphany-on-motivation", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:56.880Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "LucasSloan", "createdAt": "2009-05-28T05:04:38.345Z", "isAdmin": false, "displayName": "LucasSloan"}, "userId": "ouo6Fqn5kTNY7LvqM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KEkPnadbH3bHBxWDf/a-delayed-epiphany-on-motivation", "pageUrlRelative": "/posts/KEkPnadbH3bHBxWDf/a-delayed-epiphany-on-motivation", "linkUrl": "https://www.lesswrong.com/posts/KEkPnadbH3bHBxWDf/a-delayed-epiphany-on-motivation", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Delayed%20Epiphany%20on%20Motivation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Delayed%20Epiphany%20on%20Motivation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKEkPnadbH3bHBxWDf%2Fa-delayed-epiphany-on-motivation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Delayed%20Epiphany%20on%20Motivation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKEkPnadbH3bHBxWDf%2Fa-delayed-epiphany-on-motivation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKEkPnadbH3bHBxWDf%2Fa-delayed-epiphany-on-motivation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 239, "htmlBody": "<p>During lunch today, I had a conversation with my mother about the lives of my younger brothers.&nbsp; She mentioned to me that my brother, who is taking an SAT class, found the practice test he took to be extremely boring.&nbsp; I replied that I was sorry for my brother and that I felt very privileged not to find standardized tests boring.&nbsp; I went on to express my sorrow that I do not know how to inculcate in others the sublime joy I take in solving particularly interesting problems.&nbsp; Much later, I decided to spend an hour exercising, something that I very rarely do.&nbsp; It wasn't until about 45 minutes in that I realized the proper implication of what I had said to my mother - I have the natural advantage in test taking, but my brother has the natural advantage in exercise.&nbsp; The obvious solution was to find a way to find a similar sense of sublime joy in exercise, and make myself remember that I can find it in exercise.&nbsp; I played around with a few things I could do while on the treadmill, and found that rolling my head while walking felt <em>awesome</em>.&nbsp; I'm definitely going to do more of that in the future.&nbsp; It took me far too long to realize it, but when ever you wish you could help someone in some way, ask yourself if you could benefit from the same sort of thing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KEkPnadbH3bHBxWDf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 26, "extendedScore": null, "score": 7.102607739378693e-07, "legacy": true, "legacyId": "7188", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T12:49:53.598Z", "modifiedAt": null, "url": null, "title": "CFAI doc in SIAI FAQ", "slug": "cfai-doc-in-siai-faq", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:50.848Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oubKEvJeGp96RMDxt/cfai-doc-in-siai-faq", "pageUrlRelative": "/posts/oubKEvJeGp96RMDxt/cfai-doc-in-siai-faq", "linkUrl": "https://www.lesswrong.com/posts/oubKEvJeGp96RMDxt/cfai-doc-in-siai-faq", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20CFAI%20doc%20in%20SIAI%20FAQ&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACFAI%20doc%20in%20SIAI%20FAQ%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoubKEvJeGp96RMDxt%2Fcfai-doc-in-siai-faq%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=CFAI%20doc%20in%20SIAI%20FAQ%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoubKEvJeGp96RMDxt%2Fcfai-doc-in-siai-faq", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoubKEvJeGp96RMDxt%2Fcfai-doc-in-siai-faq", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<p>I found a link to \"Creating Friendly AI\"&nbsp;<a href=\"http://intelligence.org/upload/CFAI.html\">http://singinst.org/upload/CFAI.html</a>&nbsp;in the SIAI FAQ, which I think was recently updated. The document looks quite dated, and considering the length and the title I wonder why it hasn't been kept up. Is it even worth reading, considering it seems 10 years old?</p>\n<p>BTW, there are many dead links in it, also the 'printable version' link is dead.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oubKEvJeGp96RMDxt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.104048719434934e-07, "legacy": true, "legacyId": "7191", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T12:53:44.275Z", "modifiedAt": null, "url": null, "title": "[Link] Skeptics Stack Exchange", "slug": "link-skeptics-stack-exchange", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:21.033Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wilka", "createdAt": "2009-04-04T02:19:32.249Z", "isAdmin": false, "displayName": "Wilka"}, "userId": "ovpC9BgoTgHsForPa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/StPETfrykwGmBS2W8/link-skeptics-stack-exchange", "pageUrlRelative": "/posts/StPETfrykwGmBS2W8/link-skeptics-stack-exchange", "linkUrl": "https://www.lesswrong.com/posts/StPETfrykwGmBS2W8/link-skeptics-stack-exchange", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Skeptics%20Stack%20Exchange&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Skeptics%20Stack%20Exchange%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FStPETfrykwGmBS2W8%2Flink-skeptics-stack-exchange%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Skeptics%20Stack%20Exchange%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FStPETfrykwGmBS2W8%2Flink-skeptics-stack-exchange", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FStPETfrykwGmBS2W8%2Flink-skeptics-stack-exchange", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<p><a href=\"http://skeptics.stackexchange.com/\">http://skeptics.stackexchange.com/</a></p>\n<blockquote>\"Beta Q&amp;A site for skeptics, rationalists, free thinkers, or anyone who questions woo and pseudoscience. Skeptics is aimed at <strong>applied</strong> skepticism -- researching specific areas of woo or pseudoscience. It is not for philosophical discussions about skepticism.\"</blockquote>\n<p>It seems like it might of interest to folks here.</p>\n<p>For those that don't know, the Stack Exchange sites use a pretty&nbsp;successful&nbsp;Q&amp;A format and (at least the sites I use so far) have a high signal-to-noise ratio. More info on how the Q&amp;A system works is <a href=\"http://stackexchange.com/about\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "StPETfrykwGmBS2W8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 1.1e-05, "legacy": true, "legacyId": "7192", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T15:52:43.415Z", "modifiedAt": null, "url": null, "title": "[LINK, TED video] Kathryn Schulz on Being Wrong", "slug": "link-ted-video-kathryn-schulz-on-being-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:49.615Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bogus", "createdAt": "2009-07-17T17:58:52.405Z", "isAdmin": false, "displayName": "bogus"}, "userId": "ChXHsXmDQFWZH638i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xo2Ru7SM8hEG93Lyr/link-ted-video-kathryn-schulz-on-being-wrong", "pageUrlRelative": "/posts/Xo2Ru7SM8hEG93Lyr/link-ted-video-kathryn-schulz-on-being-wrong", "linkUrl": "https://www.lesswrong.com/posts/Xo2Ru7SM8hEG93Lyr/link-ted-video-kathryn-schulz-on-being-wrong", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%2C%20TED%20video%5D%20Kathryn%20Schulz%20on%20Being%20Wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%2C%20TED%20video%5D%20Kathryn%20Schulz%20on%20Being%20Wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXo2Ru7SM8hEG93Lyr%2Flink-ted-video-kathryn-schulz-on-being-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%2C%20TED%20video%5D%20Kathryn%20Schulz%20on%20Being%20Wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXo2Ru7SM8hEG93Lyr%2Flink-ted-video-kathryn-schulz-on-being-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXo2Ru7SM8hEG93Lyr%2Flink-ted-video-kathryn-schulz-on-being-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 139, "htmlBody": "<p><a title=\"Kathryn Schulz: On being wrong\" href=\"http://www.ted.com/talks/kathryn_schulz_on_being_wrong.html\" target=\"_blank\">http://www.ted.com/talks/kathryn_schulz_on_being_wrong.html</a></p>\n<p>Kathryn Schulz is a self-identified \"Wrongologist\" (in fact, <a href=\"http://twitter.com/#!/wrongologist\">@wrongologist</a> is her user name on Twitter).&nbsp; She has written a popular book (\"<em>Being Wrong: Adventures in the Margin of Error</em>\", <a href=\"http://beingwrongbook.com/\">web site</a>) and also writes the <em>Slate</em> column '<a title=\"The Wrong Stuff\" href=\"http://www.slate.com/blogs/blogs/thewrongstuff/\">The Wrong Stuff</a>'.&nbsp; Her TED talk covers the problem of disagreement, the nature of belief, overconfidence bias and how to actually change your mind.&nbsp; She maintains that most folks actively avoid the unpleasant feeling of \"being wrong\", which is an important point I have not seen before (but see <a href=\"/lw/i9/the_importance_of_saying_oops/\">The Importance of Saying 'Oops'</a> and <a title=\"Crisis of Faith\" href=\"/lw/ur/crisis_of_faith/\">Crisis of Faith</a>).&nbsp; Unfortunately, she does not discuss reasoning about uncertainty, so her arguments against 'the feeling of right' end up seeming rather shallow.</p>\n<p>Discuss her TED talk here. (Her broader work is also obviously on topic.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xo2Ru7SM8hEG93Lyr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 5, "extendedScore": null, "score": 7.104573241147526e-07, "legacy": true, "legacyId": "7193", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wCqfCLs8z5Qw4GbKS", "BcYBfG8KomcpcxkEg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T16:13:07.804Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes: May 2011", "slug": "rationality-quotes-may-2011-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:49.473Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DSimon", "createdAt": "2010-06-14T14:54:23.084Z", "isAdmin": false, "displayName": "DSimon"}, "userId": "KxoDC99KCeBkaWc4G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AjrJ6669cXtzeTTuX/rationality-quotes-may-2011-0", "pageUrlRelative": "/posts/AjrJ6669cXtzeTTuX/rationality-quotes-may-2011-0", "linkUrl": "https://www.lesswrong.com/posts/AjrJ6669cXtzeTTuX/rationality-quotes-may-2011-0", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%3A%20May%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%3A%20May%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAjrJ6669cXtzeTTuX%2Frationality-quotes-may-2011-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%3A%20May%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAjrJ6669cXtzeTTuX%2Frationality-quotes-may-2011-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAjrJ6669cXtzeTTuX%2Frationality-quotes-may-2011-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<p><strong>WARNING WARNING YE HAIRY GODS THIS IS A WARNING:</strong></p>\n<p>This is <strong>not</strong> the proper quotes thread for this month. The correct page is <a href=\"/r/discussion/lw/5ig/rationality_quotes_may_2011/\">here</a>. Sorry about the confusion!</p>\n<p>I will leave this post up for a day or so to let the few people who've already posted here move their quotes over, then I'll delete it.</p>\n<p><a id=\"more\"></a></p>\n<p>Can you has quotes? Yes, you <em>can</em> has quotes!</p>\n<ul>\n<li>Please post all quotes separately, so that they can be voted up/down separately. (If they are strongly related, reply to your own comments. If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AjrJ6669cXtzeTTuX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 3, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "7194", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5oDLZxexkDMGg6sbA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T16:37:30.333Z", "modifiedAt": null, "url": null, "title": "No coinductive datatype of integers", "slug": "no-coinductive-datatype-of-integers", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:06.518Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gzzDoayg9cESFiuXX/no-coinductive-datatype-of-integers", "pageUrlRelative": "/posts/gzzDoayg9cESFiuXX/no-coinductive-datatype-of-integers", "linkUrl": "https://www.lesswrong.com/posts/gzzDoayg9cESFiuXX/no-coinductive-datatype-of-integers", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20No%20coinductive%20datatype%20of%20integers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANo%20coinductive%20datatype%20of%20integers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgzzDoayg9cESFiuXX%2Fno-coinductive-datatype-of-integers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=No%20coinductive%20datatype%20of%20integers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgzzDoayg9cESFiuXX%2Fno-coinductive-datatype-of-integers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgzzDoayg9cESFiuXX%2Fno-coinductive-datatype-of-integers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 248, "htmlBody": "<p>Followup to:&nbsp;<a href=\"/lw/2tk/whats_a_natural_number/\">What's a \"natural number\"?</a></p>\n<p>While thinking about how to make machines understand the concept of \"integers\", I accidentally derived a tiny little math result that I haven't seen before. Not sure if it'll be helpful to anyone, but here goes:</p>\n<p>You're allowed to invent an arbitrary scheme for encoding integers as strings of bits. Whatever encoding you invent, I can give you an infinite input stream of bits that will make your decoder hang and never give a definite answer like \"yes, this is an integer with such-and-such value\" or \"no, this isn't a valid encoding of any integer\".</p>\n<p>To clarify, let's work through an example. Consider an unary encoding: 0 is 0, 1 is 10, 2 is 110, 3 is 1110, etc. In this case, if we feed the decoder an infinite sequence of 1's, it will remain forever undecided as to the integer's value. The result says we can find such pathological inputs for any other encoding system, not just unary.</p>\n<p>The proof is obvious. (If it isn't obvious to you, work it out!) But it seems to strike at the heart of the issue why we can't naively explain to computers what a \"standard integer\" is, what a \"terminating computation\" is, etc. Namely, if you try to define an integer as some observable interface (get first bit, get last bit, get CRC, etc.), then you inevitably invite some \"nonstandard integers\" into your system.</p>\n<p>This idea must be already well-known and have some standard name, any pointers would be welcome!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gzzDoayg9cESFiuXX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 8, "extendedScore": null, "score": 7.104701726579554e-07, "legacy": true, "legacyId": "7195", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 147, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DurJh5k3Br3xFSHpe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T19:08:35.177Z", "modifiedAt": null, "url": null, "title": "Apology for delay and [link] rationality comic", "slug": "apology-for-delay-and-link-rationality-comic", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:51.892Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Skatche", "createdAt": "2011-01-01T21:34:33.025Z", "isAdmin": false, "displayName": "Skatche"}, "userId": "sdFHhNSzievXc7TuM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9bWyRhFe3yRNzB7Nw/apology-for-delay-and-link-rationality-comic", "pageUrlRelative": "/posts/9bWyRhFe3yRNzB7Nw/apology-for-delay-and-link-rationality-comic", "linkUrl": "https://www.lesswrong.com/posts/9bWyRhFe3yRNzB7Nw/apology-for-delay-and-link-rationality-comic", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Apology%20for%20delay%20and%20%5Blink%5D%20rationality%20comic&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApology%20for%20delay%20and%20%5Blink%5D%20rationality%20comic%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9bWyRhFe3yRNzB7Nw%2Fapology-for-delay-and-link-rationality-comic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Apology%20for%20delay%20and%20%5Blink%5D%20rationality%20comic%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9bWyRhFe3yRNzB7Nw%2Fapology-for-delay-and-link-rationality-comic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9bWyRhFe3yRNzB7Nw%2Fapology-for-delay-and-link-rationality-comic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 197, "htmlBody": "<p><a href=\"http://dresdencodak.com/2011/04/19/dark-science-09/\">Link</a>.</p>\n<p>To provide some background: Kimiko, the main character, is moving to Nephilopolis, where all empiricism is strictly regulated by the Department of Inquisition: \"You couldn't so much as make an observation based judgment without a <a href=\"http://dresdencodak.com/2010/11/28/dark-science-06/\">license</a>.\"&nbsp; Since her bag is lost, she has no references, so she was <a href=\"http://dresdencodak.com/2011/02/23/dark-science-08/\">rejected</a> and is attempting to appeal.</p>\n<p>My first reaction was that the Department is acting ridiculous.&nbsp; But on further consideration, given the futuristic setting, it would actually be quite plausible that she's a hologram or an automaton or something of the sort (I do wonder why they don't mention this hypothesis).</p>\n<p>So, discuss!&nbsp; Just how ridiculous are they being?&nbsp; What do you think of this \"credibility score\" idea?&nbsp; Or, if you were to implement such a score, how would it be determined and how would it be administrated?</p>\n<p>&nbsp;</p>\n<p>This comic was also a convenient excuse to offer my apologies for delays getting started on the <a href=\"/lw/5dj/the_benefits_of_madness_a_positive_account_of/\">sequence</a> I posted about.&nbsp; I've been having a really rough time with some house issues, though it looks like the worst of it may blow over in the next day or two.&nbsp; I'm going to cautiously say the first post will be out early- to mid-next week.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9bWyRhFe3yRNzB7Nw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 4, "extendedScore": null, "score": 7.105133830634353e-07, "legacy": true, "legacyId": "7196", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zPJE7MDtL25RpN7Cc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-04T22:38:14.340Z", "modifiedAt": null, "url": null, "title": "Meditation, insight, and rationality. (Part 2 of 3)", "slug": "meditation-insight-and-rationality-part-2-of-3", "viewCount": null, "lastCommentedAt": "2020-03-11T18:36:49.414Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DavidM", "createdAt": "2011-04-25T18:36:53.508Z", "isAdmin": false, "displayName": "DavidM"}, "userId": "rMmh9neuZsXGc6ywN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QjoTFHzvrxQg9A6j3/meditation-insight-and-rationality-part-2-of-3", "pageUrlRelative": "/posts/QjoTFHzvrxQg9A6j3/meditation-insight-and-rationality-part-2-of-3", "linkUrl": "https://www.lesswrong.com/posts/QjoTFHzvrxQg9A6j3/meditation-insight-and-rationality-part-2-of-3", "postedAtFormatted": "Wednesday, May 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meditation%2C%20insight%2C%20and%20rationality.%20(Part%202%20of%203)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeditation%2C%20insight%2C%20and%20rationality.%20(Part%202%20of%203)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQjoTFHzvrxQg9A6j3%2Fmeditation-insight-and-rationality-part-2-of-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meditation%2C%20insight%2C%20and%20rationality.%20(Part%202%20of%203)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQjoTFHzvrxQg9A6j3%2Fmeditation-insight-and-rationality-part-2-of-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQjoTFHzvrxQg9A6j3%2Fmeditation-insight-and-rationality-part-2-of-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 7937, "htmlBody": "<p>This post is the second in a series; you can read the first <a href=\"/lw/5h9/meditation_insight_and_rationality_part_1_of_3/\">here</a>.</p>\n<p>I have already given a brief overview of what the goal of a particular style of meditation is, and why some individuals in this community might find it beneficial to pursue. The basic structure of this article will be as follows: a brief restatement of my major claims, a highly abridged history of meditation in one Buddhist-associated tradition and of models of the path towards enlightenment (from its ancient Buddhist roots to the modern day), and then a short-but-explicit set of instructions which an interested individual can use to see for themselves whether this style of meditation leads to what I have claimed it does.</p>\n<p><a id=\"more\"></a></p>\n<p><strong>My basic claims from Part 1:</strong></p>\n<p>&nbsp;</p>\n<ul>\n<li>The human mind, by default, involves cognitive processes that are fundamentally defective, and which distort one's views about how things are; the result of such processes is a collection of various delusions.</li>\n<li>Due to the distortions these processes cause, neither introspection nor attempts at rational thought / armchair philosophizing reveal them.</li>\n<li>The distortions these processes produce are so severe that, without training, it is unlikely that one will even be able to conceptualize what they are, or <em>what it would mean</em> for the assertion that one's cognitive processes are distorted in this particular way to be true or false.</li>\n<li>Because of this inability to conceptualize the problem, there are no words I can type which will serve to explain it to you (what I would intend to convey with them is a meaning which you cannot entertain; whatever you think I mean is almost certainly not what I mean). The best I can do is say that it has something to do with the way you think about your 'self'.</li>\n<li>Meditation, a series of attentional and perceptual exercises, can lead to the end of these delusions by fixing the processes which generate them. The end of these delusion is called 'enlightenment.' These delusions are ended in steps; the various steps are called 'partial enlightenment.'</li>\n<li>Enlightenment is not an altered state of consciousness and does not require any effort to maintain. Enlightenment is a permanent change in the way one's mind functions.</li>\n<li>These exercises have been studied, practiced, and refined over millennia, though the knowledge so-acquired has not been freely available until recently due to social factors.</li>\n<li>The exercises that most people call 'meditation,' which are typically taught to people in contexts ranging from stress reduction to quasi-religious instruction through Buddhist- and Buddhism-associated groups, have been found not to be very effective for this purpose.</li>\n<li>A rigorous implementation of the exercises that <em>have </em>proved to be effective can reasonably be expected to lead to enlightenment much more quickly than you are likely to expect: years, not decades. [Clarification: There are also individual factors at work here which I don't think anyone really understands yet.]</li>\n<li>As delusions are shed, a person may experience numerous changes in the functioning of their mind, which they are likely to find valuable if their goals include \"being happy\" and \"being more rational.\"</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>A highly abridged history of effective Buddhist-styled meditation, from a contemporary secular perspective.</strong></p>\n<p>The man whom we refer to as the Buddha lived around 500 BCE and taught various forms of meditation to those who were interested in pursuing enlightenment. His followers collected and preserved his teachings, first as an oral tradition, and later in written form. The written collection is formally called the 'sutta pitaka' in Pali; I say 'the suttas' to refer to the teachings in general in the form in which they're currently preserved.</p>\n<p>The suttas describe various ways in which enlightenment is reached. The most common formulation is that a meditator will pass through four altered states of consciousness in sequence (called 'jhanas'), and after having passed through the fourth, they will grasp the truth of things and their delusions will be extinguished. The suttas also contain other formulations, some of which are elaborations of this (e.g. eight altered states of consciousness instead of four), and some of which are not (e.g. people reaching enlightenment through certain kinds of intellectual reflection, directly hearing the Buddha's instructions, certain ways of regarding the content of experience, etc.). The suttas describe four stages of enlightenment (the first three being 'partial enlightenment' and stepping-stones on the way to full enlightenment) but there is much less detail on how they come about in relation to the progression-through-four-jhanas theory.</p>\n<p>Around 400 CE, Buddhaghosa wrote a book called the Visuddhimagga, which is ultimately adopted as the orthodox view that characterizes Theravada Buddhism. (Theravada Buddhism is the form of Buddhism most common in Southeast Asia, and which hews closest to the suttas compared to all other currently-extant forms of Buddhism.) According to the Visuddhimagga, there is an attentional exercise called (roughly) 'concentration,' the application of which leads to the aforementioned altered states of consciousness, and there is an attentional exercise called (roughly) 'discernment,' which is along the lines of what I describe in the next section. In order to reach enlightenment via meditation, one develops and improves the capacity to execute these two exercises, in various manners and with varying amounts of emphasis on one or the other (according to the capabilities and inclinations of the meditator). [Modern scientific research often taxonomizes forms of meditation as 'focused attention' or 'open monitoring', which may or may not be derived from an inaccurate understanding of the Visuddhimagga's instructions regarding 'concentration' and 'discernment'.]</p>\n<p>In the 20th century, a Burmese monk in the Theravada tradition (Mahasi Sayadaw, 1904-1982) is taught, practices, and subsequently popularizes a style of meditation which many people discover to be extremely powerful and effective. In his tradition, the progression-through-four-jhanas theory is reconciled with what the Visuddhimagga says: the path to enlightenment is modeled as a progression through four basic modes of perception, which manifest in varying ways due to personal factors and the extent to which a meditator has developed the capacity for and applies 'concentration'. The four basic modes of perception are further divided into sub-modes (eleven relevant sub-modes in all). Having passed through all the sub-modes serially, one reaches partial enlightenment; repeatedly passing through them all eventually leads to full enlightenment.</p>\n<p>Contemporary practitioners have further refined the previous model of meditation, by further subdividing the sub-modes of perception, and making some astute observations about the ways in which modes and sub-modes present cyclically and the ways in which they can be developed and manifest outside of meditation in everyday life. (More about the latter two claims later in this post, and in Part 3). Some important revisions are made to the model of partial enlightenment with respect to how one makes progress from partial enlightenment towards full enlightenment. Contemporary practitioners are also responsible for producing the viewpoint that leads to this abridgement, in the following sense:</p>\n<ul>\n<li>This abridgment leaves out an enormous amount of information relevant to Buddhism; orthodox Theravada Buddhists who seriously practice meditation would recognize the descriptions I give, but probably say that the descriptions are highly biased towards a particular view of meditation and enlightenment which they do not share, and that I leave out an enormous number of important things (the orthodox religious dogma, first and foremost) which are crucial to a full understanding of what meditation and enlightenment are about. Theravada Buddhists are also likely to disagree amongst themselves about the extent to which Mahasi Sayadaw's writings (or contemporary Burmese Theravada Buddhism in general) are faithful representations of the Visuddhimagga or of the suttas, which only adds to the list of grievances they would have with my abridgement.</li>\n</ul>\n<p>So it goes. I for one am glad that contemporary experience has built the groundwork so that 2500 years of Buddhist tradition can be framed in a way that makes sense outside of a religious context.</p>\n<p>(Non-Theravada Buddhist traditions have been omitted for the sake of simplicity, not because I or contemporary communities have anything against them.)</p>\n<p>There is lots of disagreement about whether the enlightenment I describe is the same as the enlightenment that [the suttas / the Visuddhimagga / etc.] describe, or whether there are other methods that lead to something even better than it. It's an interesting question, but will not be resolved here. The only thing that's important here is that the methods I describe lead to something very useful which you are not likely to ever run into unless you put them into practice. So, listen up.</p>\n<p>&nbsp;</p>\n<p><strong>How to meditate if you want to be enlightened.</strong></p>\n<p>&nbsp;</p>\n<p>What follows is a simplified description of one style of meditation which has been shown to be extremely effective, along with a simplified model of where one is along the path to partial enlightenment, and what to do about it. This style of meditation emphasizes the development of 'discernment' rather than 'concentration,' though both will be developed to some extent. The simplifications are my own, and they draw heavily on my own meditation practice, the experiences and knowledge of others, and \"community knowledge.\"</p>\n<p>A major focus of this method is to develop an acquaintance with what are called 'vibrations.' A meditator practicing in this style will eventually find that their experience is not static, but 'vibrates' or fluxes in a peculiar way over extremely short periods of time (fractions of a second). For an explanation by analogy, imagine a set of speakers playing music without dynamic variation; if a person rapidly turns the volume knob in the pattern off-low-high-low-off, the amplitude of the music will flux over time. Similarly, a meditator practicing in this style finds that the components of experience are not static, but fluctuate rapidly from nonexistent to existent and back again. N.B. This has nothing to do with the fact that the <em>contents </em>of experience are constantly changing. Rather, apparently static objects (e.g. an unchanging white visual field) turn out to be in flux.</p>\n<p>The analogy only goes so far. Unlike music whose volume is being manipulated, recognizing that experience is made of 'vibrations' rather than static objects is not in itself disorienting and does not in itself affect one's ability to keep track of or make sense of or appreciate one's experience. A discussion of why is unimportant, but a person who takes up this style of meditation will discover for themselves the fact that it does not have these effects, and may get some intuitive sense of why. Another dis-analogy is that this fluxing appears to be tied into the mental process of attention, rather than presenting purely as a property of sensory experience.</p>\n<p>The orthodox view is that these vibrations are related to 'impermanence,' according to Buddhism one of the three characteristics of everything that exists. A science-inspired view is that this style of meditation develops one's attention to the point that one can directly observe an artifact of the way that attention is implemented and interacts with sense data and cognitive content in the brain. In context of practicing meditation, the true explanation does not really matter; what matters is that experience has shown that developing the ability to perceive vibrations is an important step towards enlightenment and so you had better do it.</p>\n<p>As an interesting aside, there is a common belief that meditation works by reinforcing ways of thinking and feeling, and their continued reinforcement slowly biases one's everyday experiences towards those ways of thinking and feeling. For example, one might believe that a meditator cultivates pleasant feelings and learns to vanquish unpleasant feelings, and eventually pleasant feelings become more common and unpleasant feelings are easily done away with when they arise. This appears not to describe how meditation aimed at reaching enlightenment works. In the style being described, one will do practices that develop attention and perception, but at the end, when attention and perception have become sufficiently precise and clear, something completely unexpected will dawn upon the meditator...specifically, that they have been laboring under delusions which are caused by the inability to see clearly. Now that they see clearly, they unexpectedly and permanently reap the cognitive and emotional benefits of not being deluded in the ways they were. The practices that develop attention and perception are, by contrast, not especially interesting or useful in themselves. Unlike meditation aimed at generating pleasant experiences, one needs some degree of confidence that the development of attention and perception leads to a good outcome, since their development is unlikely to be valued in itself.</p>\n<p>To recap, there are four basic modes of perception which are of interest in the context of meditation. These modes of perception can manifest in distinct and profound ways during intense meditation, but also can and will manifest during everyday life in subtle and unremarkable ways. Each has typical characteristics related to the width of one's attention, the frequencies of vibrations which present themselves, and the cognitive / emotional content which tends to appear. When you sit down to meditate, you generally begin in the first mode, and slide upwards to the last mode that you have ever reached; continuing to meditate at the \"edge\" of the last mode you have reached allows you to progress to the next mode once you have put in enough effort and allowed your brain time to rewire. In general, once you reach a particular mode of perception, you are able to reach it again with much less effort (it is difficult to regress, especially if you meditate regularly, though it is possible). The stage you are at is determined by the highest mode you can easily reach. Therefore, there are four basic stages before partial enlightenment.</p>\n<p>&nbsp;</p>\n<p><em>Stage one.</em></p>\n<p>This is where you begin if you try to meditate, have never meditated before, and have no 'accidental aptitude' for developing your attention and perception outside of formal meditation, nor have personal factors which predispose you towards having developed your attention and perception without ever having made the explicit effort to. N.B. This means that some people, for whatever reason, will not start here, even without any formal meditation experience.</p>\n<p>Typical qualities of mode one perception: Very narrow attentional width (if you \"tune into\" one sense you \"tune out\" the others\"; if you \"tune into\" part of the content of one sense [e.g. a visual object in front of you] you \"tune out\" all the other content of that sense [e.g. your peripheral vision]), vibrations are subtle, various cognitive and emotional content but nothing very extreme aside from physical unpleasantness.</p>\n<p>Goal: Develop attention sufficiently to focus on an object without one's mind wandering much; learn to distinguish different kinds of experiences; develop the ability to perceive vibrations clearly.</p>\n<p>Basic method: Sit down in a place where there are few distractions, and pick an object to focus one's attention on. The most popular objects are the feeling of breath at the tip of the nostrils / upper lip, and the motion of the abdomen as one breathes in and out. (In this description I'll assume you're using the latter.) Begin by trying to clearly perceive the feeling of the abdomen expanding and contracting; when it expands and you perceive it clearly, attach the label 'in' to that perception, and when it contracts and you perceive that clearly, attach the label 'out' to that perception. As your attention becomes more stable and precise, you can divide the experience up into as many parts as you can discern: for example, 'in'-&gt;'holding'-&gt;'out'-&gt;'holding', or further, 'in-beginning'-&gt;'in-slowing'-&gt;'holding'-&gt;'out-beginning'-&gt;'out-slowing'-&gt;'holding'. The label you use is not important so long as it's simple and makes sense to you. What is important is attending to the perception, and the best way to do this is by attaching a label to the perception every time you notice it clearly. Focus on perceiving every aspect of the movement of your abdomen as precisely as is possible for you, given your current level of attentional and perceptual development,&nbsp; and on keeping your attention as set on the movements of your abdomen as possible given the same. When you get good at this, try to incline your mind towards the attentional / perceptual flux called 'vibrations' in the experience of your abdomen moving. Try to see how, in the experience of attention being fixed on an object, it is continually being set and re-set there. After enough practice, they will make themselves apparent.</p>\n<p>Whenever your attention goes to anything other than your abdomen, attach a label to the accidental object of attention and then go back to your abdomen. If you wonder about how effective the exercise is, believe it's easy, believe it's hard, decide it's pointless, congratulate yourself for how you're doing, etc. etc., label it 'thinking' and go back. If you think about your day, your future plans or responsibilities, etc., etc., also label it 'thinking.' If you visualize what you're going to do after meditation, etc. label it 'imagining.' If you have the desire to move, label it 'restless.' If you form the intention to move, label it 'intending.' If you feel some emotion, label it appropriately: 'happy,' 'sad,' 'enthusiastic,' whatever. If your attention wanders off for a long time, when you regain it and realize that, label the whole daydream or reverie 'wandering' and put your attention back on your abdomen. If you hear a distracting noise, label it 'hearing.' Anytime your attention is not on your abdomen, whatever it's on, recognize that it's not on your abdomen and is instead on that thing, label it, then go back.</p>\n<p>General advice:</p>\n<ul>\n<li>Keeping your attention on your abdomen, or any object, is extremely hard for beginners. Do whatever you can to avoid falling into a slothful state or a daydream. Meditate with your eyes open, meditate standing, drink a lot of caffeine, sit in an uncomfortable position, whatever it takes. 'Try to relax' or 'don't get caught up in your thoughts' is good advice, but for many beginners it is counterproductive because it leads to too much relaxation and not enough sharpness of attention, where attention fails to stay on any object. Try to get caught up in the process of attending and labelling. Relax insofar as it helps you do that. If feeling like you're working hard and making an effort helps you do that, don't relax.</li>\n<li>Many people try to pay attention to their abdomen but actually pay attention to a visual image of their abdomen in their imagination, an abstract image of their breath, or other things along those lines, without recognizing what they're doing. Sensory experiences are one thing, and mental experiences that imitate sensory experiences are another. Distinguish them. If you're not distinguishing them, you're not perceiving them as precisely as possible. (This is hard, but it's good to aim at.) </li>\n<li>If you can observe something, it is an object of experience. Keeping this in mind can be helpful depending on the extent to which the experiences you label seem like they're about 'you' or are 'yours' (e.g. intentions seem more 'yours' than visual imagery) and the extent to which you fail to label experiences because you can't see them as experiences but instead see them as 'stuff I'm doing / thinking about'. Your thoughts and reflections and reactions are <em>bona fide</em> mental objects, no different in this way than instances of seeing or hearing. For the purposes of meditation they ought not to be given any special privileged status. Think about this carefully, and review it from time to time to make sure you haven't forgotten.</li>\n<li>The goal of this exercise is not specifically to feel pleasant. If you don't feel good, that is irrelevant. Your success is measured by whether your attention stays on an object, and then, whether you perceive vibrations.</li>\n<li>The goal of this exercise is not specifically to experience a distinct altered state of consciousness. If your concentration is good then you may. If not, it doesn't matter as long as your attention stays on an object and you perceive vibrations.</li>\n<li>You will probably feel pretty lousy at times, either because your life is making you feel that way or because meditation is making you feel that way. Re-read the previous two points.</li>\n<li>Try not to think about why this works, or to think about anything in particular. Just attend and label. Do it as mechanically and efficiently as possible. Try to let other mental activity fall away due to disinterest.</li>\n<li>Beginning meditators sometimes suffer from what I call 'meditation hangover,' where, once attention is set on an object, it takes their minds some time to revert back to normal functioning once they stop meditating and go about their everyday business, and until that happens they feel sluggish or dissociated. This is a problem, but it goes away in time as the practice makes your mind more flexible. If it's a problem for you, schedule meditation when it won't interfere with whatever you have planned for afterwards.</li>\n<li>If you can't figure out how to label an experience, just pick a generic label and move on. Don't get caught in a loop wondering about what label to affix to something that happened five seconds ago. If you can't decide on a label, go with 'that.' Keep your labeling as immediate as possible.</li>\n<li>If you think you're able to keep your attention on your abdomen for more than a short period of time, you're probably wrong and simply not able to discern all the cognitive and sensory stuff that's distracting you. Despite that, this is probably a sign of doing well.</li>\n<li>Label as fast as you can. </li>\n<li>When you get to the point of being able to perceive vibrations, you are doing well; at that point make observing vibrations in your abdomen the focus of your efforts.</li>\n<li>All else being equal, the more you meditate, the faster your attention and perception will improve. Working up to one or two hours per day, every day, is a good goal.</li>\n<li>If you meditate as if your head is on fire and meditation is the only way to put the fire out, that is probably worth more than doing it half-assed for longer periods.</li>\n<li>Some people worry that this practice reinforces the self of a 'self' watching or observing the contents of experience, even though meditation aims at ending that particular delusion. This is irrelevant. It may reinforce the sense of being the observer of one's experience (who else labels things but 'me,' the observer?), until attention and perception are developed sufficiently that such a sense is undermined. Trust the process. Try to have a measure of confidence in the claim that you are deluded because you can't see clearly, and refining your attention and perception will help even though it may not be clear why or how.</li>\n</ul>\n<p>&nbsp;</p>\n<p><em>Stage two.</em></p>\n<p><br />If you've done the basic method in stage one successfully, you will eventually get here.</p>\n<p>Typical qualities of mode two perception: slightly wider attentional width, vibrations are obvious and often perceived effortlessly, potential for extreme shifts in mood and energy towards the positive end of the spectrum; potential for surprising or detailed spontaneous visualizations or mental imagery, potential for highly physical / sexual / pleasurable sensations, potential for all kinds of egocentric biases (in the everyday sense) concerning one's capabilities, moral worth, etc., potential for 'missionary behavior' concerning meditation because it seems like meditation is so fun, pleasant, effortless, etc. and everyone else would enjoy it if they would only do it, potential for generic [hypo]manic behavior (such as high sex drive, low need for sleep, etc.).</p>\n<p>Goal: Observe vibrations without any special regard to the content of the experience that they comprise; spend enough time observing them that it becomes effortless; try to observe them so precisely that you will be able to see an extremely high number of them per second.</p>\n<p>Basic method: Approximately the same as with stage one, except that meditation is typically much easier and effortless here, many of the admonishments and bits of advice can be put aside. If you can simply attend to any aspect of your experience and perceive vibrations in it, it is sufficient to attend and perceive them. If you get lost or your attention falls off, you can go back to observing your abdomen and labeling things until it recovers. Try to attend fluidly and effortlessly, as if the only thing you would like to do is indifferently observe your experience. Again, let mental activity that isn't concerned with observing vibrations (and possibly with labeling experience) fall away due to disinterest, as much as you can. Try to be indifferent towards the content of your experience (e.g. if you visualize Buddha vibrating at 10hz, pay attention to the fact that the image is vibrating at 10hz and not the fact that the image is Buddha or that you like or dislike the visualization). Observe very precisely and rapidly. Don't feel obligated to stay with your abdomen if you can more easily observe vibrations in some other aspect of your experience. (For example, I find the visual field, on the back of the eyelids or with eyes open, to be very good for this.)</p>\n<p>This stage manifests in a variety of ways that typically mimic hypomania, and in extreme cases can mimic mania with psychotic features. If a lot of crazy stuff presents itself to you and you find it disturbing, remember that it is not atypical for this stage and will eventually go away. If you have intense visualisations or hallucinations, just label it 'seeing.' If you feel like you're going mad, label it 'thinking.' If you feel like meditation is the greatest thing and that you'd like to preach about its benefits, also label it 'thinking.' If you think \"I must be enlightened!\", definitely label it 'thinking,' and feel free to label it 'delusion' also, because you're far from it.</p>\n<p>If this is your first time passing through this mode of perception (which doesn't include people who have without ever having made the explicit effort to meditate), it is likely to alter the way you relate to your own sense of self, and you are likely to find that you have a better intuitive grasp of issues in philosophy of mind due to that alteration. This is likely to be permanent.</p>\n<p>It is highly typical for the end of this stage to involve extremely strong physical rushing sensations (\"energy\") throughout the body. They can be extremely sexual (like the biggest orgasm you've ever had), possibly paradoxically pleasant and unpleasant at the same time, and can somehow distort your sense of self or constitute a very short-lived <em>bona fide </em>altered state of consciousness. When they occur, they can make you feel as if you're losing your identity or your volition as they temporarily take over your experiential world. <em>Observe that they are comprised of vibrations and try to see them as precisely as you can.</em> The number of vibrations you may see may be very high, like 20 or 40 per second, so don't aim too low. If the experience is too extreme to keep your wits, then just submit to it without fighting and without worrying about where your identity or volition will go.</p>\n<p>&nbsp;</p>\n<p><em>Stage three.</em></p>\n<p>&nbsp;</p>\n<p>If you ever get to stage two, it should be easy to get here, because the characteristic mode of perception in stage two is enjoyable and makes you want to keep observing your experience. My advice is only likely to make it happen faster. In stage three, the characteristic mode of perception tends to be unpleasant, so it is possible to get \"stuck\" because you may be inclined not to observe your experience. Read closely, commit what I'm writing to memory, and resolve to keep meditating no matter what.</p>\n<p>Typical qualities of mode three perception: attentional width is very diffuse (as if you can see a lot of your experience at once, but none of it especially clearly), some vibrations are fast while others aren't, vibrations tend to change frequency less often, 'discord' between vibrations in the experiential field, potential for moodiness, low energy, depression, anxiety, feelings of hopelessness, and all kinds of other unpleasantness.</p>\n<p>Goal: Observe vibrations. Attend to a wider swath of your experience than before, even if it feels like your ability to perceive it is clouded or muddled. If you feel terrible, label each and every such feeling. If you ruminate about how terrible you feel, label each and every such instance of thought. Whatever terrible experiences arise, see them as <em>objects of experience</em>, or better yet, as <em>vibrating objects of experience.</em></p>\n<p>Basic method: Like a cross between stage one and stage two. Vibrations should be easy to see, but unlike in mode two, observing them tends to be unpleasant, so some of the advice from stage one needs to be re-read and applied. The new element here is that attention is much wider than usual, so make peace with that (don't try to constrain your attention by focusing on your abdomen and trying to tune things out) and attend to experience in a way that accords with that width. The types of experiences here are different than before, so be sure to see them as clearly as you can.</p>\n<p>General advice:</p>\n<ul>\n<li>Now is a good time to step up your meditation practice, so as to get out of this stage as soon as possible and not have it bleed over onto the rest of your life. Investing as many hours as you have to spare is a good idea.</li>\n<li>Like in stage two, observe vibrations, ignore content. If you have the experience of anxiety, observe that it's vibrating at 7hz, and not that it's anxiety or that it sucks.</li>\n<li>Don't focus on the content of your experience. Don't ruminate on the content of your experience. If you can't help but do so, try to focus on relatively uninteresting experiences. Mode three perception often involves unpleasant body sensations, which are easier not to get caught in the content of than unpleasant thoughts.</li>\n<li>Using the metaphor of the volume knob on speakers being turned in the off-low-high-low-off pattern, Vibrations in mode three perception tend to be indistinct with respect to all but the second half of the pattern: (high)--&gt;low-off. Experiences appear to be constantly fading away. This is why perception seems clouded or muddled. Pay very close attention to this feature of perception.</li>\n<li>Mode three perception often involves new kinds of feelings that warrant labels such as 'dissocated' or 'off-balance' or 'out-of-sync.' Use those labels. However, make sure you are very clear about what precise thing in your experience is getting the label. In other words, make sure you can pinpoint exactly what the experience of feeling dissociated consists in if you're going to use the label. Try to \"face\" the experience instead of throwing a label in its direction and hoping that it hits. Look very closely. You may find that doing so gives you a new understanding of what experiential objects a variety of words concerning negative emotions actually refer to. Re-read the previous point.</li>\n<li>In this stage there may be a tradeoff between speed of observation and precision of observation. Emphasize precision over speed. Re-read the previous two points. Try to be clear on the variety of things your experience contains. (\"Clearly perceiving\" is not the same as \"feeling like one is clearly perceiving.\") Actively use labels for everything (as if you're a beginner in stage one again and don't know what vibrations are) if it helps.</li>\n<li>The more you meditate, the worse you are likely to feel. Feeling worse is a sign of progress. Learn to embrace it.</li>\n<li>If you feel terrible even when you're not meditating, remember that you feel that way because you're in stage three and not because people are aggravating, because you hate your boss, because your significant other isn't a good match for you, and so on. Mode three perception manifests in everyday life in this way. Try not to act on beliefs that involve judgment of other people in relation to you and your life unless you're sure that those judgments are valid. Even if you're sure, try not to act on them anyway, because there's a good chance you're wrong.</li>\n<li>It helps to have someone to talk to if you're really feeling down.</li>\n</ul>\n<p>This stage manifests in a variety of ways that typically mimic mild depression / anxiety, and in extreme cases can mimic depression with psychotic features. If the content of your experience starts getting crazy, the advice for dealing with crazy experiences in stage two applies here. If you visualize grinning skulls eating corpses, label it 'seeing.' If you feel like life is pointless and you can't go on, label it 'thinking.' If you think that this practice will extirpate your sense of self and you won't be able to function without it and will be condemned to a psychiatric ward, label it 'thinking' or 'delusion'. And so on.</p>\n<p>The more into this stage you get, the worse it tends to be, so don't be discouraged if nothing you do appears to be helping.</p>\n<p>Keep in mind that there are lots of individual factors involved and your experience may only be mildly unpleasant. That is not atypical either.</p>\n<p>Also, keep in mind that if you stop meditating altogether at this point, mode three perception (with all its negative content) is likely to become the subtle undercurrent of the rest of your life.<em> That is seriously bad</em>. Please don't do that to yourself. Please resolve, if you get to stage three, that you will keep meditating until you get out of it.</p>\n<p>&nbsp;</p>\n<p><em>Stage four.</em></p>\n<p>&nbsp;</p>\n<p>The contrast between stage three and stage four should be rather big. One typical manifestation of the very beginning of stage four is boredom or a feeling of blandness. So don't expect to immediately feel relieved when you get here, or to think \"this feels so much better than what was happening before!\" Recognize stage four by the fact that you've stopped feeling terrible, and your attention is both wider and clearer than before. It will not necessarily 'feel' like there is a big contrast; simply recognize that there is one.</p>\n<p>Typical qualities of mode four perception: attentional width is such that you can see very large amounts of your experience and it seems rather clear (rather than muddled), vibrations are regular and slowly become synchronized, feelings of boredom and indifference that eventually turn into peace and equanimity, ability to perceive subtle aspects of experience that were previously indiscernible.</p>\n<p>Goal: Observe your experience in a wide, diffuse way. Attend to all the subtle aspects. Don't ignore any aspects of experience just because you've never really reflected on them before or don't know what they are.</p>\n<p>General advice:</p>\n<ul>\n<li>Try to observe as much of your experience at the same time as you can. Don't push beyond what you can do; simply try not to tune things out. Emphasize breadth over speed. Vibrations should be obvious; keep an awareness of them in the background as you focus on breadth.</li>\n<li>'Peaceful' is a feeling. 'Neutral' is a feeling. Label them and any other way you may feel.</li>\n<li>As you get deeper into this stage, it may occur to you that there have always been experiences that you have never properly recognized as mental objects. For example, 'intending,' 'making effort,' or 'willing' may suddenly seem as if they're truly on the same footing as 'seeing' insofar as they are just experiences and not 'yours' or 'generated by you' or 'descriptions of your agency'. This is good. Observe them clearly and label them.</li>\n<li>As you get deeper into this stage, many subtle objects may present themselves for which the appropriate label is not obvious. Often these will ultimately be given labels such as 'spaciousness' or 'nothingness'. Don't worry about what to call them, just make it a point to call them something and see them clearly.</li>\n<li>Deep into this stage, you are likely to have the sense that what you call 'self' is just a mental object which appears to be the observer of experience, but which you are paradoxically observing. You won't resolve the paradox by thinking about it, so just observe that object precisely and label it 'observer.'&nbsp; [N.B. There is actually no mental object 'self' in experience, but the way in which that is true is not one that can be explained to you, and in any case is something for you potentially to discover in the future.]</li>\n<li>Deep into this stage, you may fall into an altered state of consciousness in which your ability to reflect is suppressed. Don't worry about it. Perhaps try to cultivate this altered state by letting up on your efforts while trying to stay minimally attentive to what's going on. This is more likely to be effective when you are currently experiencing signs of being deep into this stage as described in the previous few points.</li>\n</ul>\n<p>After the fireworks of stages two and three, this stage may incline you to think that meditation no longer works, and nothing interesting is really happening. It begins in an unassuming way, but ultimately develops into an experience characterized by enormous attentional width, peace, ease, the effortless ability to see all experiences as objects, and a plethora of subtle objects to observe. At the very end you may temporarily lose the ability to distinguish between your various senses. (This is not synaesthesia, but simply a change that involves objects being seen as 'experience' rather than being categorized by the particular sense they manifest in.) The distinction between the senses may seem arbitrary or artificial. Just keep meditating.</p>\n<p>The rest of your life is likely to benefit from having mode four perception as its subtle undercurrent. Problems may seem less important and typical worries may no longer arise. If you stop meditating here, it is possible to do fine, but it is also possible to eventually regress to stage three (in which case mode three perception becomes the subtle undercurrent), which sucks. So try not to let that happen.</p>\n<p>Partial enlightenment is preceded by the apparent momentary cessation of consciousness, which will happen at the very end of this stage. Some people find it very profound, in that they now have a radically different understanding of 'self' and of their own mind. Other people find it to be a natural evolution of what they already have developed, and so do not find it to usher in an enormous new paradigm. My working hypothesis is that, the more steeped in Buddhist dogma and belief one is, the more likely it is to be seen as natural. (If \"all phenomena are not-self\" has been resonating in your mind for years, understanding what it means is likely to be less shocking.) If you get to this point, write a post on LW and let us know what you think!</p>\n<p>It is sometimes hard to be sure that you have experienced an apparent momentary cessation of consciousness. One 'test' is simply to see whether you suddenly have a different perspective on things. Another 'test' is to consider which of these cases applies to you:</p>\n<ul>\n<li>The unenlightened meditator in stage <em>n </em>will sit down to meditate in mode one perception, and slowly slide to mode <em>n </em>perception, where they will stay.</li>\n<li>The partially enlightened meditator will sit down to meditate in mode two perception, slowly slide to mode four perception, experience an apparent momentary cessation of consciousness, and then return to mode two perception. This can be repeated numerous times. The cycle from mode two to mode four and back to mode two is highly likely to happen even without meditating.</li>\n</ul>\n<p>After partial enlightenment, at first the various modes of perception will present strongly, and the rapid transitions may be somewhat disorienting, but eventually the brain manages to integrate these various modes of perception and they become rather unimportant, and their emotional and cognitive peculiarities taper off. The subtle undercurrent of one's everyday experience may slowly shift to perceptual mode four.</p>\n<p>Enlightenment has no qualities. It is not a feeling of apathy, detachment, a trippy altered state of consciousness, or a constant stream of awesome vibes. Partial enlightenment is partially like enlightenment. Do not expect all your emotions to be gone and everything good to be sucked out of life; do not expect to find an endless fountain of joy inside of you. Actually reaching partial enlightenment may make it extremely clear to you how silly these expectations are; but despite that, people have them, and so I have to say something about them.</p>\n<p>Partial enlightenment is good in itself, but I would not be able to explain why. Review the first post in the series for some of my claims about the incidental benefits of enlightenment, which are easier to explain.</p>\n<p>It helps to know someone who is experienced with respect to this style of meditation and these four stages, but if you have no one to talk to, you can do it by yourself if you have enough commitment and can follow instructions. You will get better advice on how to finesse your way through these various experiences from a person, because they can tailor what they say to your particular experiences and your personality, and because there is immense individual variation in how minds work which needs to be accounted for when giving advice. Also, there is an enormous amount of useful advice which will help many people in meditation, but trying to stuff it all into a blog post would be absurd. Remember that the model and advice in this post is a condensed version of a much larger model and much more exhaustive advice.</p>\n<p>I include one general piece of advice at the end, because I don't know if it's true, but I think it is. That advice is, if there is some aspect of experience which is suddenly especially interesting or strange to you, that aspect of experience is worth focusing on during meditation until it becomes less interesting or strange. For example, if you are in stage one and it appears to you that your intentions are not leading to action in the way you normally expect, that is worth paying attention to; or, if you are in stage four and are fascinated by the perception of 'nothingness,' that is worth paying attention to.</p>\n<p>Getting from partial to full enlightenment is not necessarily harder (though it generally is). Good advice for how to do it is definitely much harder to summarize and can be highly individual. The process is approximately akin to the process that first gets you to partial enlightenment, but not really. If you get to this point and want to go further, you should find someone to talk to about it.</p>\n<p>Don't forget that being partially enlightened is not the same as being fully enlightened. You are still deluded. Assume that you still don't really know what enlightenment is about, even though you may have a much better idea than before. Don't stand on a pulpit and tell people what it's about unless you are extremely confident that you know and that further meditation won't change your mind, taking what I just wrote into consideration.</p>\n<p>If you are psychologically unstable or suffer from mental illness, please read the descriptions of stages two and three carefully, consider the ways in which they might exacerbate the problems you are already dealing with, and make an informed decision about whether to proceed. If you do decide to proceed, make sure your plan includes ways to deal with these stages safely. And get a doctor's approval and supervision before beginning any of this, whether or not you have pre-existing problems, since I'm not a doctor and not a dispenser of medical advice. You follow the technique I describe at your own risk.</p>\n<p><strong>Addendum.</strong></p>\n<p>&nbsp;</p>\n<p>Now you know how to meditate. Secret knowledge has been revealed to you. If you're interested, test it for yourself and see whether what I have written is true. If you have not done these practices and never observed someone else do them and their results, you have minimal evidence with which to judge the truth of my claims. Perhaps one source of evidence for you will be what other LWers say after trying these exercises themselves. Keep in mind that it takes a variable amount of time to reach partial enlightenment, through if you have a committed practice, a year is a good upper bound. If you have been practicing for awhile and not seeing much, <em>get feedback; </em>you may not be following the instructions even though you think you are. One of the benefits of contemporary communities is that openness and feedback about meditation may have reduced the amount of time it takes to make progress, so take advantage of that feature.</p>\n<p>The way that common descriptions of how to meditate go wrong is as follows. Beginners' minds are inclined by default to do everything <em>other</em> than cultivate their attention and perception in a way that leads to results. (If it were otherwise, most people wouldn't be beginners when they start meditating.) Generic instructions such as \"follow your breath and don't get caught up in your thoughts\" lead to beginners' minds doing a wide variety of different things. (Such instructions are not specific enough to constrain what their minds do or guide them towards developing attention and perception in the right way.) Because of the fact that the prevalent culture of groups interested in meditation in the West involves norms of not talking about one's experiences in detail, not talking about enlightenment as a goal, and not criticizing other people's meditation methods, meditators are never given any way to gauge their progress or any means by which they would recognize and correct their own failure to cultivate their attention and perception. Compounding this, many meditation groups are interested in mood and stress alteration rather than enlightenment, and are not aiming at developing their attention and perception, and so many people never hear that that there is something worth cultivating through meditation apart from relaxation and detachment from negative thoughts and feelings. The style of meditation I describe avoids these problems by 1) coming pre-packaged with a model of how to reach enlightenment, 2) focusing on developing the perception of vibrations and then observing them, which has been shown to be a way that gets people to cultivate their minds in the right way, and 3) providing a way to test whether they have (i.e. \"can you perceive vibrations?\")</p>\n<p>I am not claiming that no other style of meditation is effective or is as effective as this one, or that any effective style bears striking similarities to this one. My claim is that this style is highly effective and easy to teach. My <em>personal belief</em> is that it is a member of a family of closely-related meditation styles which are the most effective known styles for teaching contemporary Westerners, but establishing that convincingly requires data to which I don't have access.</p>\n<p>In Part 3 I shall include criticisms and arguments against my claims, reflections on science with respect to their interest in and models of meditation, and some specific things which contemporary communities who study and practice this stuff believe about meditation which would have significant consequences for the practice of clinical psychology and for people's everyday mental health if they were true. And perhaps some other things that I haven't yet thought of. (If there are specific issues anyone would like me to address, please write them in the comment section and I'll see if I can work them in.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AiNyf5iwbpc7mehiX": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QjoTFHzvrxQg9A6j3", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 57, "baseScore": 34, "extendedScore": null, "score": 6.5e-05, "legacy": true, "legacyId": "7183", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This post is the second in a series; you can read the first <a href=\"/lw/5h9/meditation_insight_and_rationality_part_1_of_3/\">here</a>.</p>\n<p>I have already given a brief overview of what the goal of a particular style of meditation is, and why some individuals in this community might find it beneficial to pursue. The basic structure of this article will be as follows: a brief restatement of my major claims, a highly abridged history of meditation in one Buddhist-associated tradition and of models of the path towards enlightenment (from its ancient Buddhist roots to the modern day), and then a short-but-explicit set of instructions which an interested individual can use to see for themselves whether this style of meditation leads to what I have claimed it does.</p>\n<p><a id=\"more\"></a></p>\n<p><strong id=\"My_basic_claims_from_Part_1_\">My basic claims from Part 1:</strong></p>\n<p>&nbsp;</p>\n<ul>\n<li>The human mind, by default, involves cognitive processes that are fundamentally defective, and which distort one's views about how things are; the result of such processes is a collection of various delusions.</li>\n<li>Due to the distortions these processes cause, neither introspection nor attempts at rational thought / armchair philosophizing reveal them.</li>\n<li>The distortions these processes produce are so severe that, without training, it is unlikely that one will even be able to conceptualize what they are, or <em>what it would mean</em> for the assertion that one's cognitive processes are distorted in this particular way to be true or false.</li>\n<li>Because of this inability to conceptualize the problem, there are no words I can type which will serve to explain it to you (what I would intend to convey with them is a meaning which you cannot entertain; whatever you think I mean is almost certainly not what I mean). The best I can do is say that it has something to do with the way you think about your 'self'.</li>\n<li>Meditation, a series of attentional and perceptual exercises, can lead to the end of these delusions by fixing the processes which generate them. The end of these delusion is called 'enlightenment.' These delusions are ended in steps; the various steps are called 'partial enlightenment.'</li>\n<li>Enlightenment is not an altered state of consciousness and does not require any effort to maintain. Enlightenment is a permanent change in the way one's mind functions.</li>\n<li>These exercises have been studied, practiced, and refined over millennia, though the knowledge so-acquired has not been freely available until recently due to social factors.</li>\n<li>The exercises that most people call 'meditation,' which are typically taught to people in contexts ranging from stress reduction to quasi-religious instruction through Buddhist- and Buddhism-associated groups, have been found not to be very effective for this purpose.</li>\n<li>A rigorous implementation of the exercises that <em>have </em>proved to be effective can reasonably be expected to lead to enlightenment much more quickly than you are likely to expect: years, not decades. [Clarification: There are also individual factors at work here which I don't think anyone really understands yet.]</li>\n<li>As delusions are shed, a person may experience numerous changes in the functioning of their mind, which they are likely to find valuable if their goals include \"being happy\" and \"being more rational.\"</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong id=\"A_highly_abridged_history_of_effective_Buddhist_styled_meditation__from_a_contemporary_secular_perspective_\">A highly abridged history of effective Buddhist-styled meditation, from a contemporary secular perspective.</strong></p>\n<p>The man whom we refer to as the Buddha lived around 500 BCE and taught various forms of meditation to those who were interested in pursuing enlightenment. His followers collected and preserved his teachings, first as an oral tradition, and later in written form. The written collection is formally called the 'sutta pitaka' in Pali; I say 'the suttas' to refer to the teachings in general in the form in which they're currently preserved.</p>\n<p>The suttas describe various ways in which enlightenment is reached. The most common formulation is that a meditator will pass through four altered states of consciousness in sequence (called 'jhanas'), and after having passed through the fourth, they will grasp the truth of things and their delusions will be extinguished. The suttas also contain other formulations, some of which are elaborations of this (e.g. eight altered states of consciousness instead of four), and some of which are not (e.g. people reaching enlightenment through certain kinds of intellectual reflection, directly hearing the Buddha's instructions, certain ways of regarding the content of experience, etc.). The suttas describe four stages of enlightenment (the first three being 'partial enlightenment' and stepping-stones on the way to full enlightenment) but there is much less detail on how they come about in relation to the progression-through-four-jhanas theory.</p>\n<p>Around 400 CE, Buddhaghosa wrote a book called the Visuddhimagga, which is ultimately adopted as the orthodox view that characterizes Theravada Buddhism. (Theravada Buddhism is the form of Buddhism most common in Southeast Asia, and which hews closest to the suttas compared to all other currently-extant forms of Buddhism.) According to the Visuddhimagga, there is an attentional exercise called (roughly) 'concentration,' the application of which leads to the aforementioned altered states of consciousness, and there is an attentional exercise called (roughly) 'discernment,' which is along the lines of what I describe in the next section. In order to reach enlightenment via meditation, one develops and improves the capacity to execute these two exercises, in various manners and with varying amounts of emphasis on one or the other (according to the capabilities and inclinations of the meditator). [Modern scientific research often taxonomizes forms of meditation as 'focused attention' or 'open monitoring', which may or may not be derived from an inaccurate understanding of the Visuddhimagga's instructions regarding 'concentration' and 'discernment'.]</p>\n<p>In the 20th century, a Burmese monk in the Theravada tradition (Mahasi Sayadaw, 1904-1982) is taught, practices, and subsequently popularizes a style of meditation which many people discover to be extremely powerful and effective. In his tradition, the progression-through-four-jhanas theory is reconciled with what the Visuddhimagga says: the path to enlightenment is modeled as a progression through four basic modes of perception, which manifest in varying ways due to personal factors and the extent to which a meditator has developed the capacity for and applies 'concentration'. The four basic modes of perception are further divided into sub-modes (eleven relevant sub-modes in all). Having passed through all the sub-modes serially, one reaches partial enlightenment; repeatedly passing through them all eventually leads to full enlightenment.</p>\n<p>Contemporary practitioners have further refined the previous model of meditation, by further subdividing the sub-modes of perception, and making some astute observations about the ways in which modes and sub-modes present cyclically and the ways in which they can be developed and manifest outside of meditation in everyday life. (More about the latter two claims later in this post, and in Part 3). Some important revisions are made to the model of partial enlightenment with respect to how one makes progress from partial enlightenment towards full enlightenment. Contemporary practitioners are also responsible for producing the viewpoint that leads to this abridgement, in the following sense:</p>\n<ul>\n<li>This abridgment leaves out an enormous amount of information relevant to Buddhism; orthodox Theravada Buddhists who seriously practice meditation would recognize the descriptions I give, but probably say that the descriptions are highly biased towards a particular view of meditation and enlightenment which they do not share, and that I leave out an enormous number of important things (the orthodox religious dogma, first and foremost) which are crucial to a full understanding of what meditation and enlightenment are about. Theravada Buddhists are also likely to disagree amongst themselves about the extent to which Mahasi Sayadaw's writings (or contemporary Burmese Theravada Buddhism in general) are faithful representations of the Visuddhimagga or of the suttas, which only adds to the list of grievances they would have with my abridgement.</li>\n</ul>\n<p>So it goes. I for one am glad that contemporary experience has built the groundwork so that 2500 years of Buddhist tradition can be framed in a way that makes sense outside of a religious context.</p>\n<p>(Non-Theravada Buddhist traditions have been omitted for the sake of simplicity, not because I or contemporary communities have anything against them.)</p>\n<p>There is lots of disagreement about whether the enlightenment I describe is the same as the enlightenment that [the suttas / the Visuddhimagga / etc.] describe, or whether there are other methods that lead to something even better than it. It's an interesting question, but will not be resolved here. The only thing that's important here is that the methods I describe lead to something very useful which you are not likely to ever run into unless you put them into practice. So, listen up.</p>\n<p>&nbsp;</p>\n<p><strong id=\"How_to_meditate_if_you_want_to_be_enlightened_\">How to meditate if you want to be enlightened.</strong></p>\n<p>&nbsp;</p>\n<p>What follows is a simplified description of one style of meditation which has been shown to be extremely effective, along with a simplified model of where one is along the path to partial enlightenment, and what to do about it. This style of meditation emphasizes the development of 'discernment' rather than 'concentration,' though both will be developed to some extent. The simplifications are my own, and they draw heavily on my own meditation practice, the experiences and knowledge of others, and \"community knowledge.\"</p>\n<p>A major focus of this method is to develop an acquaintance with what are called 'vibrations.' A meditator practicing in this style will eventually find that their experience is not static, but 'vibrates' or fluxes in a peculiar way over extremely short periods of time (fractions of a second). For an explanation by analogy, imagine a set of speakers playing music without dynamic variation; if a person rapidly turns the volume knob in the pattern off-low-high-low-off, the amplitude of the music will flux over time. Similarly, a meditator practicing in this style finds that the components of experience are not static, but fluctuate rapidly from nonexistent to existent and back again. N.B. This has nothing to do with the fact that the <em>contents </em>of experience are constantly changing. Rather, apparently static objects (e.g. an unchanging white visual field) turn out to be in flux.</p>\n<p>The analogy only goes so far. Unlike music whose volume is being manipulated, recognizing that experience is made of 'vibrations' rather than static objects is not in itself disorienting and does not in itself affect one's ability to keep track of or make sense of or appreciate one's experience. A discussion of why is unimportant, but a person who takes up this style of meditation will discover for themselves the fact that it does not have these effects, and may get some intuitive sense of why. Another dis-analogy is that this fluxing appears to be tied into the mental process of attention, rather than presenting purely as a property of sensory experience.</p>\n<p>The orthodox view is that these vibrations are related to 'impermanence,' according to Buddhism one of the three characteristics of everything that exists. A science-inspired view is that this style of meditation develops one's attention to the point that one can directly observe an artifact of the way that attention is implemented and interacts with sense data and cognitive content in the brain. In context of practicing meditation, the true explanation does not really matter; what matters is that experience has shown that developing the ability to perceive vibrations is an important step towards enlightenment and so you had better do it.</p>\n<p>As an interesting aside, there is a common belief that meditation works by reinforcing ways of thinking and feeling, and their continued reinforcement slowly biases one's everyday experiences towards those ways of thinking and feeling. For example, one might believe that a meditator cultivates pleasant feelings and learns to vanquish unpleasant feelings, and eventually pleasant feelings become more common and unpleasant feelings are easily done away with when they arise. This appears not to describe how meditation aimed at reaching enlightenment works. In the style being described, one will do practices that develop attention and perception, but at the end, when attention and perception have become sufficiently precise and clear, something completely unexpected will dawn upon the meditator...specifically, that they have been laboring under delusions which are caused by the inability to see clearly. Now that they see clearly, they unexpectedly and permanently reap the cognitive and emotional benefits of not being deluded in the ways they were. The practices that develop attention and perception are, by contrast, not especially interesting or useful in themselves. Unlike meditation aimed at generating pleasant experiences, one needs some degree of confidence that the development of attention and perception leads to a good outcome, since their development is unlikely to be valued in itself.</p>\n<p>To recap, there are four basic modes of perception which are of interest in the context of meditation. These modes of perception can manifest in distinct and profound ways during intense meditation, but also can and will manifest during everyday life in subtle and unremarkable ways. Each has typical characteristics related to the width of one's attention, the frequencies of vibrations which present themselves, and the cognitive / emotional content which tends to appear. When you sit down to meditate, you generally begin in the first mode, and slide upwards to the last mode that you have ever reached; continuing to meditate at the \"edge\" of the last mode you have reached allows you to progress to the next mode once you have put in enough effort and allowed your brain time to rewire. In general, once you reach a particular mode of perception, you are able to reach it again with much less effort (it is difficult to regress, especially if you meditate regularly, though it is possible). The stage you are at is determined by the highest mode you can easily reach. Therefore, there are four basic stages before partial enlightenment.</p>\n<p>&nbsp;</p>\n<p><em>Stage one.</em></p>\n<p>This is where you begin if you try to meditate, have never meditated before, and have no 'accidental aptitude' for developing your attention and perception outside of formal meditation, nor have personal factors which predispose you towards having developed your attention and perception without ever having made the explicit effort to. N.B. This means that some people, for whatever reason, will not start here, even without any formal meditation experience.</p>\n<p>Typical qualities of mode one perception: Very narrow attentional width (if you \"tune into\" one sense you \"tune out\" the others\"; if you \"tune into\" part of the content of one sense [e.g. a visual object in front of you] you \"tune out\" all the other content of that sense [e.g. your peripheral vision]), vibrations are subtle, various cognitive and emotional content but nothing very extreme aside from physical unpleasantness.</p>\n<p>Goal: Develop attention sufficiently to focus on an object without one's mind wandering much; learn to distinguish different kinds of experiences; develop the ability to perceive vibrations clearly.</p>\n<p>Basic method: Sit down in a place where there are few distractions, and pick an object to focus one's attention on. The most popular objects are the feeling of breath at the tip of the nostrils / upper lip, and the motion of the abdomen as one breathes in and out. (In this description I'll assume you're using the latter.) Begin by trying to clearly perceive the feeling of the abdomen expanding and contracting; when it expands and you perceive it clearly, attach the label 'in' to that perception, and when it contracts and you perceive that clearly, attach the label 'out' to that perception. As your attention becomes more stable and precise, you can divide the experience up into as many parts as you can discern: for example, 'in'-&gt;'holding'-&gt;'out'-&gt;'holding', or further, 'in-beginning'-&gt;'in-slowing'-&gt;'holding'-&gt;'out-beginning'-&gt;'out-slowing'-&gt;'holding'. The label you use is not important so long as it's simple and makes sense to you. What is important is attending to the perception, and the best way to do this is by attaching a label to the perception every time you notice it clearly. Focus on perceiving every aspect of the movement of your abdomen as precisely as is possible for you, given your current level of attentional and perceptual development,&nbsp; and on keeping your attention as set on the movements of your abdomen as possible given the same. When you get good at this, try to incline your mind towards the attentional / perceptual flux called 'vibrations' in the experience of your abdomen moving. Try to see how, in the experience of attention being fixed on an object, it is continually being set and re-set there. After enough practice, they will make themselves apparent.</p>\n<p>Whenever your attention goes to anything other than your abdomen, attach a label to the accidental object of attention and then go back to your abdomen. If you wonder about how effective the exercise is, believe it's easy, believe it's hard, decide it's pointless, congratulate yourself for how you're doing, etc. etc., label it 'thinking' and go back. If you think about your day, your future plans or responsibilities, etc., etc., also label it 'thinking.' If you visualize what you're going to do after meditation, etc. label it 'imagining.' If you have the desire to move, label it 'restless.' If you form the intention to move, label it 'intending.' If you feel some emotion, label it appropriately: 'happy,' 'sad,' 'enthusiastic,' whatever. If your attention wanders off for a long time, when you regain it and realize that, label the whole daydream or reverie 'wandering' and put your attention back on your abdomen. If you hear a distracting noise, label it 'hearing.' Anytime your attention is not on your abdomen, whatever it's on, recognize that it's not on your abdomen and is instead on that thing, label it, then go back.</p>\n<p>General advice:</p>\n<ul>\n<li>Keeping your attention on your abdomen, or any object, is extremely hard for beginners. Do whatever you can to avoid falling into a slothful state or a daydream. Meditate with your eyes open, meditate standing, drink a lot of caffeine, sit in an uncomfortable position, whatever it takes. 'Try to relax' or 'don't get caught up in your thoughts' is good advice, but for many beginners it is counterproductive because it leads to too much relaxation and not enough sharpness of attention, where attention fails to stay on any object. Try to get caught up in the process of attending and labelling. Relax insofar as it helps you do that. If feeling like you're working hard and making an effort helps you do that, don't relax.</li>\n<li>Many people try to pay attention to their abdomen but actually pay attention to a visual image of their abdomen in their imagination, an abstract image of their breath, or other things along those lines, without recognizing what they're doing. Sensory experiences are one thing, and mental experiences that imitate sensory experiences are another. Distinguish them. If you're not distinguishing them, you're not perceiving them as precisely as possible. (This is hard, but it's good to aim at.) </li>\n<li>If you can observe something, it is an object of experience. Keeping this in mind can be helpful depending on the extent to which the experiences you label seem like they're about 'you' or are 'yours' (e.g. intentions seem more 'yours' than visual imagery) and the extent to which you fail to label experiences because you can't see them as experiences but instead see them as 'stuff I'm doing / thinking about'. Your thoughts and reflections and reactions are <em>bona fide</em> mental objects, no different in this way than instances of seeing or hearing. For the purposes of meditation they ought not to be given any special privileged status. Think about this carefully, and review it from time to time to make sure you haven't forgotten.</li>\n<li>The goal of this exercise is not specifically to feel pleasant. If you don't feel good, that is irrelevant. Your success is measured by whether your attention stays on an object, and then, whether you perceive vibrations.</li>\n<li>The goal of this exercise is not specifically to experience a distinct altered state of consciousness. If your concentration is good then you may. If not, it doesn't matter as long as your attention stays on an object and you perceive vibrations.</li>\n<li>You will probably feel pretty lousy at times, either because your life is making you feel that way or because meditation is making you feel that way. Re-read the previous two points.</li>\n<li>Try not to think about why this works, or to think about anything in particular. Just attend and label. Do it as mechanically and efficiently as possible. Try to let other mental activity fall away due to disinterest.</li>\n<li>Beginning meditators sometimes suffer from what I call 'meditation hangover,' where, once attention is set on an object, it takes their minds some time to revert back to normal functioning once they stop meditating and go about their everyday business, and until that happens they feel sluggish or dissociated. This is a problem, but it goes away in time as the practice makes your mind more flexible. If it's a problem for you, schedule meditation when it won't interfere with whatever you have planned for afterwards.</li>\n<li>If you can't figure out how to label an experience, just pick a generic label and move on. Don't get caught in a loop wondering about what label to affix to something that happened five seconds ago. If you can't decide on a label, go with 'that.' Keep your labeling as immediate as possible.</li>\n<li>If you think you're able to keep your attention on your abdomen for more than a short period of time, you're probably wrong and simply not able to discern all the cognitive and sensory stuff that's distracting you. Despite that, this is probably a sign of doing well.</li>\n<li>Label as fast as you can. </li>\n<li>When you get to the point of being able to perceive vibrations, you are doing well; at that point make observing vibrations in your abdomen the focus of your efforts.</li>\n<li>All else being equal, the more you meditate, the faster your attention and perception will improve. Working up to one or two hours per day, every day, is a good goal.</li>\n<li>If you meditate as if your head is on fire and meditation is the only way to put the fire out, that is probably worth more than doing it half-assed for longer periods.</li>\n<li>Some people worry that this practice reinforces the self of a 'self' watching or observing the contents of experience, even though meditation aims at ending that particular delusion. This is irrelevant. It may reinforce the sense of being the observer of one's experience (who else labels things but 'me,' the observer?), until attention and perception are developed sufficiently that such a sense is undermined. Trust the process. Try to have a measure of confidence in the claim that you are deluded because you can't see clearly, and refining your attention and perception will help even though it may not be clear why or how.</li>\n</ul>\n<p>&nbsp;</p>\n<p><em>Stage two.</em></p>\n<p><br>If you've done the basic method in stage one successfully, you will eventually get here.</p>\n<p>Typical qualities of mode two perception: slightly wider attentional width, vibrations are obvious and often perceived effortlessly, potential for extreme shifts in mood and energy towards the positive end of the spectrum; potential for surprising or detailed spontaneous visualizations or mental imagery, potential for highly physical / sexual / pleasurable sensations, potential for all kinds of egocentric biases (in the everyday sense) concerning one's capabilities, moral worth, etc., potential for 'missionary behavior' concerning meditation because it seems like meditation is so fun, pleasant, effortless, etc. and everyone else would enjoy it if they would only do it, potential for generic [hypo]manic behavior (such as high sex drive, low need for sleep, etc.).</p>\n<p>Goal: Observe vibrations without any special regard to the content of the experience that they comprise; spend enough time observing them that it becomes effortless; try to observe them so precisely that you will be able to see an extremely high number of them per second.</p>\n<p>Basic method: Approximately the same as with stage one, except that meditation is typically much easier and effortless here, many of the admonishments and bits of advice can be put aside. If you can simply attend to any aspect of your experience and perceive vibrations in it, it is sufficient to attend and perceive them. If you get lost or your attention falls off, you can go back to observing your abdomen and labeling things until it recovers. Try to attend fluidly and effortlessly, as if the only thing you would like to do is indifferently observe your experience. Again, let mental activity that isn't concerned with observing vibrations (and possibly with labeling experience) fall away due to disinterest, as much as you can. Try to be indifferent towards the content of your experience (e.g. if you visualize Buddha vibrating at 10hz, pay attention to the fact that the image is vibrating at 10hz and not the fact that the image is Buddha or that you like or dislike the visualization). Observe very precisely and rapidly. Don't feel obligated to stay with your abdomen if you can more easily observe vibrations in some other aspect of your experience. (For example, I find the visual field, on the back of the eyelids or with eyes open, to be very good for this.)</p>\n<p>This stage manifests in a variety of ways that typically mimic hypomania, and in extreme cases can mimic mania with psychotic features. If a lot of crazy stuff presents itself to you and you find it disturbing, remember that it is not atypical for this stage and will eventually go away. If you have intense visualisations or hallucinations, just label it 'seeing.' If you feel like you're going mad, label it 'thinking.' If you feel like meditation is the greatest thing and that you'd like to preach about its benefits, also label it 'thinking.' If you think \"I must be enlightened!\", definitely label it 'thinking,' and feel free to label it 'delusion' also, because you're far from it.</p>\n<p>If this is your first time passing through this mode of perception (which doesn't include people who have without ever having made the explicit effort to meditate), it is likely to alter the way you relate to your own sense of self, and you are likely to find that you have a better intuitive grasp of issues in philosophy of mind due to that alteration. This is likely to be permanent.</p>\n<p>It is highly typical for the end of this stage to involve extremely strong physical rushing sensations (\"energy\") throughout the body. They can be extremely sexual (like the biggest orgasm you've ever had), possibly paradoxically pleasant and unpleasant at the same time, and can somehow distort your sense of self or constitute a very short-lived <em>bona fide </em>altered state of consciousness. When they occur, they can make you feel as if you're losing your identity or your volition as they temporarily take over your experiential world. <em>Observe that they are comprised of vibrations and try to see them as precisely as you can.</em> The number of vibrations you may see may be very high, like 20 or 40 per second, so don't aim too low. If the experience is too extreme to keep your wits, then just submit to it without fighting and without worrying about where your identity or volition will go.</p>\n<p>&nbsp;</p>\n<p><em>Stage three.</em></p>\n<p>&nbsp;</p>\n<p>If you ever get to stage two, it should be easy to get here, because the characteristic mode of perception in stage two is enjoyable and makes you want to keep observing your experience. My advice is only likely to make it happen faster. In stage three, the characteristic mode of perception tends to be unpleasant, so it is possible to get \"stuck\" because you may be inclined not to observe your experience. Read closely, commit what I'm writing to memory, and resolve to keep meditating no matter what.</p>\n<p>Typical qualities of mode three perception: attentional width is very diffuse (as if you can see a lot of your experience at once, but none of it especially clearly), some vibrations are fast while others aren't, vibrations tend to change frequency less often, 'discord' between vibrations in the experiential field, potential for moodiness, low energy, depression, anxiety, feelings of hopelessness, and all kinds of other unpleasantness.</p>\n<p>Goal: Observe vibrations. Attend to a wider swath of your experience than before, even if it feels like your ability to perceive it is clouded or muddled. If you feel terrible, label each and every such feeling. If you ruminate about how terrible you feel, label each and every such instance of thought. Whatever terrible experiences arise, see them as <em>objects of experience</em>, or better yet, as <em>vibrating objects of experience.</em></p>\n<p>Basic method: Like a cross between stage one and stage two. Vibrations should be easy to see, but unlike in mode two, observing them tends to be unpleasant, so some of the advice from stage one needs to be re-read and applied. The new element here is that attention is much wider than usual, so make peace with that (don't try to constrain your attention by focusing on your abdomen and trying to tune things out) and attend to experience in a way that accords with that width. The types of experiences here are different than before, so be sure to see them as clearly as you can.</p>\n<p>General advice:</p>\n<ul>\n<li>Now is a good time to step up your meditation practice, so as to get out of this stage as soon as possible and not have it bleed over onto the rest of your life. Investing as many hours as you have to spare is a good idea.</li>\n<li>Like in stage two, observe vibrations, ignore content. If you have the experience of anxiety, observe that it's vibrating at 7hz, and not that it's anxiety or that it sucks.</li>\n<li>Don't focus on the content of your experience. Don't ruminate on the content of your experience. If you can't help but do so, try to focus on relatively uninteresting experiences. Mode three perception often involves unpleasant body sensations, which are easier not to get caught in the content of than unpleasant thoughts.</li>\n<li>Using the metaphor of the volume knob on speakers being turned in the off-low-high-low-off pattern, Vibrations in mode three perception tend to be indistinct with respect to all but the second half of the pattern: (high)--&gt;low-off. Experiences appear to be constantly fading away. This is why perception seems clouded or muddled. Pay very close attention to this feature of perception.</li>\n<li>Mode three perception often involves new kinds of feelings that warrant labels such as 'dissocated' or 'off-balance' or 'out-of-sync.' Use those labels. However, make sure you are very clear about what precise thing in your experience is getting the label. In other words, make sure you can pinpoint exactly what the experience of feeling dissociated consists in if you're going to use the label. Try to \"face\" the experience instead of throwing a label in its direction and hoping that it hits. Look very closely. You may find that doing so gives you a new understanding of what experiential objects a variety of words concerning negative emotions actually refer to. Re-read the previous point.</li>\n<li>In this stage there may be a tradeoff between speed of observation and precision of observation. Emphasize precision over speed. Re-read the previous two points. Try to be clear on the variety of things your experience contains. (\"Clearly perceiving\" is not the same as \"feeling like one is clearly perceiving.\") Actively use labels for everything (as if you're a beginner in stage one again and don't know what vibrations are) if it helps.</li>\n<li>The more you meditate, the worse you are likely to feel. Feeling worse is a sign of progress. Learn to embrace it.</li>\n<li>If you feel terrible even when you're not meditating, remember that you feel that way because you're in stage three and not because people are aggravating, because you hate your boss, because your significant other isn't a good match for you, and so on. Mode three perception manifests in everyday life in this way. Try not to act on beliefs that involve judgment of other people in relation to you and your life unless you're sure that those judgments are valid. Even if you're sure, try not to act on them anyway, because there's a good chance you're wrong.</li>\n<li>It helps to have someone to talk to if you're really feeling down.</li>\n</ul>\n<p>This stage manifests in a variety of ways that typically mimic mild depression / anxiety, and in extreme cases can mimic depression with psychotic features. If the content of your experience starts getting crazy, the advice for dealing with crazy experiences in stage two applies here. If you visualize grinning skulls eating corpses, label it 'seeing.' If you feel like life is pointless and you can't go on, label it 'thinking.' If you think that this practice will extirpate your sense of self and you won't be able to function without it and will be condemned to a psychiatric ward, label it 'thinking' or 'delusion'. And so on.</p>\n<p>The more into this stage you get, the worse it tends to be, so don't be discouraged if nothing you do appears to be helping.</p>\n<p>Keep in mind that there are lots of individual factors involved and your experience may only be mildly unpleasant. That is not atypical either.</p>\n<p>Also, keep in mind that if you stop meditating altogether at this point, mode three perception (with all its negative content) is likely to become the subtle undercurrent of the rest of your life.<em> That is seriously bad</em>. Please don't do that to yourself. Please resolve, if you get to stage three, that you will keep meditating until you get out of it.</p>\n<p>&nbsp;</p>\n<p><em>Stage four.</em></p>\n<p>&nbsp;</p>\n<p>The contrast between stage three and stage four should be rather big. One typical manifestation of the very beginning of stage four is boredom or a feeling of blandness. So don't expect to immediately feel relieved when you get here, or to think \"this feels so much better than what was happening before!\" Recognize stage four by the fact that you've stopped feeling terrible, and your attention is both wider and clearer than before. It will not necessarily 'feel' like there is a big contrast; simply recognize that there is one.</p>\n<p>Typical qualities of mode four perception: attentional width is such that you can see very large amounts of your experience and it seems rather clear (rather than muddled), vibrations are regular and slowly become synchronized, feelings of boredom and indifference that eventually turn into peace and equanimity, ability to perceive subtle aspects of experience that were previously indiscernible.</p>\n<p>Goal: Observe your experience in a wide, diffuse way. Attend to all the subtle aspects. Don't ignore any aspects of experience just because you've never really reflected on them before or don't know what they are.</p>\n<p>General advice:</p>\n<ul>\n<li>Try to observe as much of your experience at the same time as you can. Don't push beyond what you can do; simply try not to tune things out. Emphasize breadth over speed. Vibrations should be obvious; keep an awareness of them in the background as you focus on breadth.</li>\n<li>'Peaceful' is a feeling. 'Neutral' is a feeling. Label them and any other way you may feel.</li>\n<li>As you get deeper into this stage, it may occur to you that there have always been experiences that you have never properly recognized as mental objects. For example, 'intending,' 'making effort,' or 'willing' may suddenly seem as if they're truly on the same footing as 'seeing' insofar as they are just experiences and not 'yours' or 'generated by you' or 'descriptions of your agency'. This is good. Observe them clearly and label them.</li>\n<li>As you get deeper into this stage, many subtle objects may present themselves for which the appropriate label is not obvious. Often these will ultimately be given labels such as 'spaciousness' or 'nothingness'. Don't worry about what to call them, just make it a point to call them something and see them clearly.</li>\n<li>Deep into this stage, you are likely to have the sense that what you call 'self' is just a mental object which appears to be the observer of experience, but which you are paradoxically observing. You won't resolve the paradox by thinking about it, so just observe that object precisely and label it 'observer.'&nbsp; [N.B. There is actually no mental object 'self' in experience, but the way in which that is true is not one that can be explained to you, and in any case is something for you potentially to discover in the future.]</li>\n<li>Deep into this stage, you may fall into an altered state of consciousness in which your ability to reflect is suppressed. Don't worry about it. Perhaps try to cultivate this altered state by letting up on your efforts while trying to stay minimally attentive to what's going on. This is more likely to be effective when you are currently experiencing signs of being deep into this stage as described in the previous few points.</li>\n</ul>\n<p>After the fireworks of stages two and three, this stage may incline you to think that meditation no longer works, and nothing interesting is really happening. It begins in an unassuming way, but ultimately develops into an experience characterized by enormous attentional width, peace, ease, the effortless ability to see all experiences as objects, and a plethora of subtle objects to observe. At the very end you may temporarily lose the ability to distinguish between your various senses. (This is not synaesthesia, but simply a change that involves objects being seen as 'experience' rather than being categorized by the particular sense they manifest in.) The distinction between the senses may seem arbitrary or artificial. Just keep meditating.</p>\n<p>The rest of your life is likely to benefit from having mode four perception as its subtle undercurrent. Problems may seem less important and typical worries may no longer arise. If you stop meditating here, it is possible to do fine, but it is also possible to eventually regress to stage three (in which case mode three perception becomes the subtle undercurrent), which sucks. So try not to let that happen.</p>\n<p>Partial enlightenment is preceded by the apparent momentary cessation of consciousness, which will happen at the very end of this stage. Some people find it very profound, in that they now have a radically different understanding of 'self' and of their own mind. Other people find it to be a natural evolution of what they already have developed, and so do not find it to usher in an enormous new paradigm. My working hypothesis is that, the more steeped in Buddhist dogma and belief one is, the more likely it is to be seen as natural. (If \"all phenomena are not-self\" has been resonating in your mind for years, understanding what it means is likely to be less shocking.) If you get to this point, write a post on LW and let us know what you think!</p>\n<p>It is sometimes hard to be sure that you have experienced an apparent momentary cessation of consciousness. One 'test' is simply to see whether you suddenly have a different perspective on things. Another 'test' is to consider which of these cases applies to you:</p>\n<ul>\n<li>The unenlightened meditator in stage <em>n </em>will sit down to meditate in mode one perception, and slowly slide to mode <em>n </em>perception, where they will stay.</li>\n<li>The partially enlightened meditator will sit down to meditate in mode two perception, slowly slide to mode four perception, experience an apparent momentary cessation of consciousness, and then return to mode two perception. This can be repeated numerous times. The cycle from mode two to mode four and back to mode two is highly likely to happen even without meditating.</li>\n</ul>\n<p>After partial enlightenment, at first the various modes of perception will present strongly, and the rapid transitions may be somewhat disorienting, but eventually the brain manages to integrate these various modes of perception and they become rather unimportant, and their emotional and cognitive peculiarities taper off. The subtle undercurrent of one's everyday experience may slowly shift to perceptual mode four.</p>\n<p>Enlightenment has no qualities. It is not a feeling of apathy, detachment, a trippy altered state of consciousness, or a constant stream of awesome vibes. Partial enlightenment is partially like enlightenment. Do not expect all your emotions to be gone and everything good to be sucked out of life; do not expect to find an endless fountain of joy inside of you. Actually reaching partial enlightenment may make it extremely clear to you how silly these expectations are; but despite that, people have them, and so I have to say something about them.</p>\n<p>Partial enlightenment is good in itself, but I would not be able to explain why. Review the first post in the series for some of my claims about the incidental benefits of enlightenment, which are easier to explain.</p>\n<p>It helps to know someone who is experienced with respect to this style of meditation and these four stages, but if you have no one to talk to, you can do it by yourself if you have enough commitment and can follow instructions. You will get better advice on how to finesse your way through these various experiences from a person, because they can tailor what they say to your particular experiences and your personality, and because there is immense individual variation in how minds work which needs to be accounted for when giving advice. Also, there is an enormous amount of useful advice which will help many people in meditation, but trying to stuff it all into a blog post would be absurd. Remember that the model and advice in this post is a condensed version of a much larger model and much more exhaustive advice.</p>\n<p>I include one general piece of advice at the end, because I don't know if it's true, but I think it is. That advice is, if there is some aspect of experience which is suddenly especially interesting or strange to you, that aspect of experience is worth focusing on during meditation until it becomes less interesting or strange. For example, if you are in stage one and it appears to you that your intentions are not leading to action in the way you normally expect, that is worth paying attention to; or, if you are in stage four and are fascinated by the perception of 'nothingness,' that is worth paying attention to.</p>\n<p>Getting from partial to full enlightenment is not necessarily harder (though it generally is). Good advice for how to do it is definitely much harder to summarize and can be highly individual. The process is approximately akin to the process that first gets you to partial enlightenment, but not really. If you get to this point and want to go further, you should find someone to talk to about it.</p>\n<p>Don't forget that being partially enlightened is not the same as being fully enlightened. You are still deluded. Assume that you still don't really know what enlightenment is about, even though you may have a much better idea than before. Don't stand on a pulpit and tell people what it's about unless you are extremely confident that you know and that further meditation won't change your mind, taking what I just wrote into consideration.</p>\n<p>If you are psychologically unstable or suffer from mental illness, please read the descriptions of stages two and three carefully, consider the ways in which they might exacerbate the problems you are already dealing with, and make an informed decision about whether to proceed. If you do decide to proceed, make sure your plan includes ways to deal with these stages safely. And get a doctor's approval and supervision before beginning any of this, whether or not you have pre-existing problems, since I'm not a doctor and not a dispenser of medical advice. You follow the technique I describe at your own risk.</p>\n<p><strong id=\"Addendum_\">Addendum.</strong></p>\n<p>&nbsp;</p>\n<p>Now you know how to meditate. Secret knowledge has been revealed to you. If you're interested, test it for yourself and see whether what I have written is true. If you have not done these practices and never observed someone else do them and their results, you have minimal evidence with which to judge the truth of my claims. Perhaps one source of evidence for you will be what other LWers say after trying these exercises themselves. Keep in mind that it takes a variable amount of time to reach partial enlightenment, through if you have a committed practice, a year is a good upper bound. If you have been practicing for awhile and not seeing much, <em>get feedback; </em>you may not be following the instructions even though you think you are. One of the benefits of contemporary communities is that openness and feedback about meditation may have reduced the amount of time it takes to make progress, so take advantage of that feature.</p>\n<p>The way that common descriptions of how to meditate go wrong is as follows. Beginners' minds are inclined by default to do everything <em>other</em> than cultivate their attention and perception in a way that leads to results. (If it were otherwise, most people wouldn't be beginners when they start meditating.) Generic instructions such as \"follow your breath and don't get caught up in your thoughts\" lead to beginners' minds doing a wide variety of different things. (Such instructions are not specific enough to constrain what their minds do or guide them towards developing attention and perception in the right way.) Because of the fact that the prevalent culture of groups interested in meditation in the West involves norms of not talking about one's experiences in detail, not talking about enlightenment as a goal, and not criticizing other people's meditation methods, meditators are never given any way to gauge their progress or any means by which they would recognize and correct their own failure to cultivate their attention and perception. Compounding this, many meditation groups are interested in mood and stress alteration rather than enlightenment, and are not aiming at developing their attention and perception, and so many people never hear that that there is something worth cultivating through meditation apart from relaxation and detachment from negative thoughts and feelings. The style of meditation I describe avoids these problems by 1) coming pre-packaged with a model of how to reach enlightenment, 2) focusing on developing the perception of vibrations and then observing them, which has been shown to be a way that gets people to cultivate their minds in the right way, and 3) providing a way to test whether they have (i.e. \"can you perceive vibrations?\")</p>\n<p>I am not claiming that no other style of meditation is effective or is as effective as this one, or that any effective style bears striking similarities to this one. My claim is that this style is highly effective and easy to teach. My <em>personal belief</em> is that it is a member of a family of closely-related meditation styles which are the most effective known styles for teaching contemporary Westerners, but establishing that convincingly requires data to which I don't have access.</p>\n<p>In Part 3 I shall include criticisms and arguments against my claims, reflections on science with respect to their interest in and models of meditation, and some specific things which contemporary communities who study and practice this stuff believe about meditation which would have significant consequences for the practice of clinical psychology and for people's everyday mental health if they were true. And perhaps some other things that I haven't yet thought of. (If there are specific issues anyone would like me to address, please write them in the comment section and I'll see if I can work them in.)</p>", "sections": [{"title": "My basic claims from Part 1:", "anchor": "My_basic_claims_from_Part_1_", "level": 1}, {"title": "A highly abridged history of effective Buddhist-styled meditation, from a contemporary secular perspective.", "anchor": "A_highly_abridged_history_of_effective_Buddhist_styled_meditation__from_a_contemporary_secular_perspective_", "level": 1}, {"title": "How to meditate if you want to be enlightened.", "anchor": "How_to_meditate_if_you_want_to_be_enlightened_", "level": 1}, {"title": "Addendum.", "anchor": "Addendum_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "190 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 191, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QqSNFcGSZdnARx56E"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-05-04T22:38:14.340Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-05T03:44:41.890Z", "modifiedAt": null, "url": null, "title": "Hollow Adjectives", "slug": "hollow-adjectives", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:25.267Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psychohistorian", "createdAt": "2009-04-05T18:10:22.976Z", "isAdmin": false, "displayName": "Psychohistorian"}, "userId": "mAQgf4N8jv2jTMK5B", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jikQ9oF6FJDHSJxNp/hollow-adjectives", "pageUrlRelative": "/posts/jikQ9oF6FJDHSJxNp/hollow-adjectives", "linkUrl": "https://www.lesswrong.com/posts/jikQ9oF6FJDHSJxNp/hollow-adjectives", "postedAtFormatted": "Thursday, May 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hollow%20Adjectives&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHollow%20Adjectives%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjikQ9oF6FJDHSJxNp%2Fhollow-adjectives%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hollow%20Adjectives%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjikQ9oF6FJDHSJxNp%2Fhollow-adjectives", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjikQ9oF6FJDHSJxNp%2Fhollow-adjectives", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 778, "htmlBody": "<p>[This is a draft intended to be developed into a top-level post - it wouldn't feel wrong to make it such right now, but it wouldn't quite feel right. I am not entirely sure how to end it or if I could generalize better at the end. I kind of like the ending I have, but I'm not sure if the point overall is coherent enough. &nbsp;Thoughts/suggestions/criticism would all be appreciated. ETA: The problem here may be that this is actually a follow up (or a footnote) to another article I've been thinking of about Weasel Words and the art of misleading through langauge; related to my earlier post on <a href=\"/lw/11y/not_technically_lying/\">Not Technically Lying</a>]</p>\n<p>When I was a teenager, I remember hearing a couple of riddles that I thought were neat:</p>\n<p>\"Could God draw a square circle?\"<br />\"Could God create a stone so large that even He could not lift it?\"</p>\n<p>Let me just disclaim that this post has pretty nothing to do with religion. I just think that these are great examples that many people may be familiar with. That said, consider: do either of these problems pose a threat to the existence of an omnipotent God?</p>\n<p>The answer, as will be clear on a full exposition, is a resounding \"No.\" These are terrible, awful, misleading arguments, and the second one illustrates a relatively common trick used to sneak past an audience's intellectual defenses.</p>\n<p>These riddles both fail to provide relevant counterexamples for the exact same reason, even though the second may seem to make more sense. The first is simpler: a square circle is not a thing. In a practical sense, we can put the words next to each other, but there is simply no way to translate the sound \"square circle\" into some kind of expectation or thing in the real world, in the same way one could translate, \"red barn\" or \"white unicorn\" into an expected observation. It is impossible for anything to be both square and circular, so the fact that God cannot do something that cannot be done does not limit His omnipotence. By the same token, God could not create a married bachelor (using the strict definitions of the terms), as a bachelor is an unmarried man. The inability to violate the law of non-contradiction does not appear to be a legitimate refutation of omnipotence. If we taboo, \"square circle,\" there isn't really a meaningful way of describing the thing you are insisting God be able to draw.</p>\n<p>\"A stone so large that God cannot lift it,\" is <em>exactly</em> the same thing as a square circle. It <em>sounds</em> like a problem, since it's showing that God can't create a big enough stone. But an omnipotent being could presumably lift an object of any arbitrary size. Therefore, no stone could ever meet these criteria. If we taboo \"so large that God cannot lift it,\" there is no actual weight you could describe such a stone as having. Presumably, God could lift a stone that weighted 3^^^3 tons, or even 3^^^^^^3 tons. You've created a hollow adjective: a descriptor whose&nbsp;<em>actual</em> meaning makes an argument self-evidently bad, but which is appealing if you don't actually think about it. It's not&nbsp;<a href=\"/lw/11y/not_technically_lying/\">Not Technically Lying</a>, because it isn't <em>untrue</em>, it's <em>meaningless, </em>which makes it harder to detect (though less common).&nbsp;</p>\n<p>This is an extreme example. Usually, hollowness allows a speaker to be vague enough that they sound like they have a point when a clear definition of their terms would disprove this. Offenses in common language are usually a bit less egregious. \"The president hasn't done enough to fix the economy,\" comes to mind as an example. <em>What</em>&nbsp;exactly, should he have done? There has probably never been a president in history whom people would generally agree has done \"enough to fix the economy;\" indeed, most economists would question the power of the president to seriously influence such things. \"Hasn't the president failed to end the recession?\" may be technically true, but it isn't really <em>useful&nbsp;</em>to call someone a failure for not doing something they lack the power to do. This example is merely illustrative; it is often easy to create descriptors that make your conclusion apparently foregone, despite their actual lack of substance.</p>\n<p>Using such slanted terms is among the darker of the Dark Arts. It plays on its audience not by appealing to the irrational vagaries of the human mind; such efforts are, at least, often transparent. Rather, it masquerades as a rational argument, requiring complex nuance to refute. For those who are not disposed to disagree, it can escape the defense mechanisms of even a cautious mind. Understanding this concept can make it far easier to pinpoint the error in some beguiling arguments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jikQ9oF6FJDHSJxNp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 13, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "3643", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PrXR66hQcaJXsgWsa"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-05T06:28:23.386Z", "modifiedAt": null, "url": null, "title": "San Francisco Meetup every Tues 5/10, 7 pm", "slug": "san-francisco-meetup-every-tues-5-10-7-pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.561Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mass_Driver", "createdAt": "2010-03-30T15:48:06.997Z", "isAdmin": false, "displayName": "Mass_Driver"}, "userId": "62rKjNqA2LCJ6RthR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8CkGAaWfGHXGDfS9j/san-francisco-meetup-every-tues-5-10-7-pm", "pageUrlRelative": "/posts/8CkGAaWfGHXGDfS9j/san-francisco-meetup-every-tues-5-10-7-pm", "linkUrl": "https://www.lesswrong.com/posts/8CkGAaWfGHXGDfS9j/san-francisco-meetup-every-tues-5-10-7-pm", "postedAtFormatted": "Thursday, May 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20San%20Francisco%20Meetup%20every%20Tues%205%2F10%2C%207%20pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASan%20Francisco%20Meetup%20every%20Tues%205%2F10%2C%207%20pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8CkGAaWfGHXGDfS9j%2Fsan-francisco-meetup-every-tues-5-10-7-pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=San%20Francisco%20Meetup%20every%20Tues%205%2F10%2C%207%20pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8CkGAaWfGHXGDfS9j%2Fsan-francisco-meetup-every-tues-5-10-7-pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8CkGAaWfGHXGDfS9j%2Fsan-francisco-meetup-every-tues-5-10-7-pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 429, "htmlBody": "<address>Tuesday, May 10th at 7:00 PM</address><address>Green Papaya</address><address>825 Mission Street (4th and Mission)</address><address>San Francisco, CA 94103</address><address><a id=\"more\"></a><br /></address>\n<p>Welcome back to the next installment of the newest Bay Area Less Wrong meetup: <strong>San Francisco</strong>! By popular demand, the third meeting of the San Francisco group will be this coming <span style=\"color: #0000ff;\"><em>Tuesday</em></span>, May 10th, from 7:00-9:00 at <a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=Green+Papaya,+Mission+Street,+San+Francisco,+CA&amp;aq=0&amp;sll=37.0625,-95.677068&amp;sspn=40.681389,79.013672&amp;ie=UTF8&amp;hq=Green+Papaya,&amp;hnear=Mission+St,+San+Francisco,+California&amp;ll=37.783876,-122.404861&amp;spn=0.019875,0.038581&amp;z=15&amp;iwloc=A\" target=\"_blank\">Green Papaya near 4th and Mission</a>. The theme of the meeting will be \"<strong>How do you measure how much <span style=\"color: #ff0000;\">f</span><span style=\"color: #ff9900;\">u</span><span style=\"color: #ff00ff;\">n</span> you're having?\" </strong>Everyone will get a chance to talk about what they do to try to have fun, how well that usually works out for them, and what they might do to try to improve their odds of having lots of fun.</p>\n<p>Hopefully this will help us get to know each other a little bit while also starting to plan out the broad strokes of what kinds of things we'll do together at future meet-ups. Once we know what at least some do for fun (or want to do for fun), we can brainstorm ways of making that happen together.</p>\n<p>If you have any questions at all about the Meetup, feel free to call me, Jason Green-Lowe, at <a href=\"/tel:%28415%29%20895-0650\" target=\"_blank\">(415) 895-0650</a>, or to e-mail me at <a href=\"mailto:jasongreenlowe@gmail.com\" target=\"_blank\">jasongreenlowe@gmail.com</a>. You can also PM me on the Less Wrong blog at Mass_Driver. If you'd like to help organize this or future meetings, you should definitely get in touch -- help is welcome and probably needed!</p>\n<p>If you've never been to a LessWrong meetup before, this is a good chance to go to your first one! Chances are other people feel awkward too, and we'll all be a little uneasy about the whole thing together. Less Wrong meetups are so new that nobody really knows the right way to run them yet, let alone the right way to participate in them. So, come! Help us figure it out. It doesn't matter if you've read the whole blog or even if you've graduated high school -- if you show up and try to be less wrong, we'll be glad you came.</p>\n<p>If you want to stay informed about upcoming events in the Bay Area, join the <a href=\"https://groups.google.com/group/bayarealesswrong\" target=\"_blank\">Bay Area LessWrong Google Group</a>! There are other chapters in Tortuga and Berkeley, and together we aim to throw so many events that the global Less Wrong blog won't have room to post them all.&nbsp;</p>\n<p>Note that the day-of-the-week has been changed from Thursday to Tuesday, so that it is now possible to attend three (3!!) Bay Area LW meetups each week. Meetups will continue <strong>every Tuesday</strong> for at least the next three weeks, and hopefully until the <a href=\"http://en.wikipedia.org/wiki/Technological_singularity\">Singularity</a>.</p>\n<p>See you soon!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8CkGAaWfGHXGDfS9j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.107086390343346e-07, "legacy": true, "legacyId": "7199", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-05T13:55:33.580Z", "modifiedAt": null, "url": null, "title": "Edinburgh LW meetup, Saturday May 7, 2pm", "slug": "edinburgh-lw-meetup-saturday-may-7-2pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.361Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sark", "createdAt": "2010-01-20T20:18:10.889Z", "isAdmin": false, "displayName": "sark"}, "userId": "cJYNhyCitpdzsZqeP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tJ6jvpPFJ5vMBnLsZ/edinburgh-lw-meetup-saturday-may-7-2pm", "pageUrlRelative": "/posts/tJ6jvpPFJ5vMBnLsZ/edinburgh-lw-meetup-saturday-may-7-2pm", "linkUrl": "https://www.lesswrong.com/posts/tJ6jvpPFJ5vMBnLsZ/edinburgh-lw-meetup-saturday-may-7-2pm", "postedAtFormatted": "Thursday, May 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Edinburgh%20LW%20meetup%2C%20Saturday%20May%207%2C%202pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEdinburgh%20LW%20meetup%2C%20Saturday%20May%207%2C%202pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtJ6jvpPFJ5vMBnLsZ%2Fedinburgh-lw-meetup-saturday-may-7-2pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Edinburgh%20LW%20meetup%2C%20Saturday%20May%207%2C%202pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtJ6jvpPFJ5vMBnLsZ%2Fedinburgh-lw-meetup-saturday-may-7-2pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtJ6jvpPFJ5vMBnLsZ%2Fedinburgh-lw-meetup-saturday-may-7-2pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p><a id=\"more\"></a>Place: <a href=\"http://maps.google.co.uk/maps?ie=UTF8&amp;t=h&amp;cid=1874860554950886070\">Delhi Cafe</a> (new place!)</p>\n<p>I will be the guy with the <a href=\"http://www.amazon.co.uk/59-Seconds-Think-little-change/dp/023074429X\">:59 Seconds book</a> by Richard Wiseman.</p>\n<p>Facebook event page:&nbsp;<a href=\"http://www.facebook.com/event.php?eid=208424955846583\">http://www.facebook.com/event.php?eid=208424955846583</a></p>\n<p>But just let this LW meetup post be the 'official' place where you're 'supposed to' confirm your attendance. But just turn up. Anybody's welcome!</p>\n<p>The meetup's weekly now.</p>\n<p>ETA: Oh yes, do prepare some mini-presentation to give at the meetup. 3 people have already committed to doing this, so you won't feel alone :)</p>\n<p>Sorry for such short notice. See you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tJ6jvpPFJ5vMBnLsZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.108370367986452e-07, "legacy": true, "legacyId": "7204", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-05T16:21:15.687Z", "modifiedAt": null, "url": null, "title": "Your Evolved Intuitions", "slug": "your-evolved-intuitions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.893Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WTS4ZbEwvKrcrnaaN/your-evolved-intuitions", "pageUrlRelative": "/posts/WTS4ZbEwvKrcrnaaN/your-evolved-intuitions", "linkUrl": "https://www.lesswrong.com/posts/WTS4ZbEwvKrcrnaaN/your-evolved-intuitions", "postedAtFormatted": "Thursday, May 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Your%20Evolved%20Intuitions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYour%20Evolved%20Intuitions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWTS4ZbEwvKrcrnaaN%2Fyour-evolved-intuitions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Your%20Evolved%20Intuitions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWTS4ZbEwvKrcrnaaN%2Fyour-evolved-intuitions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWTS4ZbEwvKrcrnaaN%2Fyour-evolved-intuitions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2973, "htmlBody": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>We have already examined one source of our intuitions: <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">attribute substitution heuristics</a>. Today we examine a second source of our intuitions: <em>biological evolution</em>.</p>\n<p>&nbsp;</p>\n<h4>Evolutionary psychology</h4>\n<p>Evolutionary psychology<sup>1</sup> has been covered on Less Wrong <a href=\"http://wiki.lesswrong.com/wiki/Evolutionary_psychology\">many times before</a>, but let's review anyway.</p>\n<p>Lions walk on four legs and hunt for food. Skunks defend themselves with a spray. Spiders make webs. Each species is shaped by selection pressures, and is different from that of other species.</p>\n<p>Certain evolved psychological mechanisms in humans are part of what makes us like each other and not like lions, skunks, and spiders.</p>\n<p>These mechanisms evolved to solve specific adaptive problems. It is not an accident that people around the world prefer calorie-rich foods,<sup>2</sup>&nbsp;that women around the world prefer men with resources,<sup>3</sup> that men around the world prefer women with signs of fertility,<sup>4</sup> or that most of us inherently fear snakes and spiders but not cars and electrical outlets.<sup>5</sup></p>\n<p>An an example of evolutionary psychology at work, consider the '<a href=\"/lw/mj/rational_vs_scientific_evpsych/\">hunter-gatherer hypothesis</a>' that men evolved psychological mechanisms to aid in hunting, while women evolved psychological mechanisms to aid in gathering.<sup>6</sup> This hypothesis leads to a list of bold predictions. If the hypothesis is correct, then:</p>\n<ol>\n<li>Men in modern tribal societies should spend a lot of time hunting, and women more time gathering.</li>\n<li>Humans should show a greater tendency toward strong male coalitions than similar species in which males do not hunt much, because strong male coalitions are required to hunt big game.</li>\n<li>Because meat from most game comes in quantities larger than a single hunter can consume, and because hunting success is highly variable (one week may be a success, but perhaps not the next week),&nbsp;humans should exhibit food sharing and reciprocal altruism.</li>\n<li>We should expect to see a sexual division of labor, due to the different traits conducive for hunting vs. gathering.</li>\n<li>Men should exploit status gains to be had from 'showing off' large hunting successes.</li>\n<li>Men should have superior cognitive ability to navigate across large distances and perform 3D mental rotation tasks required for throwing spears and similar hunting acts. Women should have superior cognitive ability with spacial location memory and object arrays.</li>\n</ol>\n<p>And as it turns out, <em>all</em>&nbsp;these predictions are correct.<sup>7</sup>&nbsp;(And no, evolutionary psychologists do <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/DeBruine-Beyond-Just-So-Stories.pdf\">not</a> only offer 'postdictions' or 'just so' stories. Besides, probability theory <a href=\"/lw/5bw/your_evolved_intuitions/4gpz\">does not have separate categories</a> for 'predictions' and 'postdictions'.)</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Kin loyalty</h4>\n<p>Consider the intuition that we have more responsibility for the well-being of our close relatives than for the well-being of distant relatives or strangers. We would <em>expect</em>&nbsp;human evolution to produce exactly such an intuition given&nbsp;<a href=\"http://en.wikipedia.org/wiki/Kin_selection#Hamilton.27s_rule\">Hamilton's rule</a>,&nbsp;which states that the reproductive cost to an agent is less than the genetic relatedness of the recipient to the agent multiplied by the additional reproductive benefit gained by the recipient of the altruistic act.</p>\n<p>That's a mouthful, so instead let me illustrate the consequences of Hamilton's rule:</p>\n<blockquote>\n<p>Imagine that you pass by a river and notice that some of your genetic relatives are drowning in a ferocious current. You could jump in the water to save them, but you would pay with your own life. According to Hamilton's rule, selection will favor decision rules that, on average, result in your jumping into the water to save three of your brothers, but not one. You would be predicted <em>not</em>&nbsp;to sacrifice your own life for just <em>one</em> brother, because that would violate Hamilton's rule. Using the logic of Hamilton's rule, evolved decision rules should lead you to sacrifice your own life for five nieces or nephews, but you would have to save nine first cousins before you would sacrifice your own life.<sup>8</sup></p>\n</blockquote>\n<p>Hamilton's rule has indeed been observed at work in a wide variety of contexts.<sup>9</sup></p>\n<p>My intuition that I am more responsible for the well-being of my brother than my cousin, and more responsible for the well-being of my cousin than a stranger, looks like a good candidate for an evolved intuition.</p>\n<p>&nbsp;</p>\n<h4>Essentialism</h4>\n<p>Uneducated people around the world believe that organisms come in discrete packets, and that each species has an 'essence' that produces its form and abilities. The intuitive appeal of this&nbsp;<em style=\"font-style: italic;\">essentialism</em>&nbsp;often trumps the explicitly learned gradualism of biological evolution. Even someone who has read Richard Dawkins <a href=\"http://proliferationofniches.blogspot.com/2009/10/dawkins-on-essentialism.html\">argue</a>&nbsp;against essentialism might find himself the very next day stuck in essentialist thinking. Why? Many researchers have suggested that an evolved, intuitive 'folk biology' is responsible.<sup>10</sup></p>\n<p>These essentialist intuitions emerge early in life across all cultures we have studied.<sup>11</sup> For example, children may believe that</p>\n<blockquote>\n<p>...if you remove the insides of a dog, it loses its 'essence' and is no longer really a dog anymore - it can't bark or bite. But if you remove its outsides or change its external appearance so that it doesn't look like a dog, children still believe that it has retained its essential 'dogness.'<sup>12</sup></p>\n</blockquote>\n<p>Many researchers think that essentialist intuitions evolved because it's useful for humans to respond to organisms in this way. With essentialist thinking, we can very quickly drop organisms into categories concerning what we can and can't eat, what we can capture, what might capture us, and so on.</p>\n<p>Essentialism has had a <a href=\"http://en.wikipedia.org/wiki/Essentialism\">long-lasting hold</a> on the minds of many philosophers, and greatly influenced their conclusions even after Darwin.</p>\n<p>&nbsp;</p>\n<h4>Heuristics and biases</h4>\n<p>Human reasoning is subject to a&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Bias\">long list of biases</a>. Why did we evolve such faulty thinking processes? Aren't false beliefs bad for survival and reproduction?</p>\n<p>Many researchers suggest that while humans are poor at formal logic and <a href=\"http://yudkowsky.net/rational/bayes\">Bayesian inference</a>, humans display a kind of 'ecological rationality'.<sup>13</sup></p>\n<blockquote>\n<p>Over evolutionary time, the human environment has had certain statistical regularities: Rain often followed thunder, violence sometimes followed angry shouts, sex sometimes followed prolonged eye contact, dangerous bites often followed getting too close to a snake, and so on. These statistical regularities are called <em>ecological structure</em>. Ecological rationality consists of evolved mechanisms containing design features that utilize ecological structure to facilitate adaptive problem solving.</p>\n<p>The shape and form of cognitive mechanisms, in other words, coordinate with the recurring statistical regularities of the ancestral environments in which humans evolved. We fear snakes and not electrical outlets...</p>\n<p>[Moreover], theories of formal logic that are content independent... are exceptionally poor at solving real adaptive problems. The world is full of logically arbitrary relationships: Dung happens to be potentially dangerous to humans, for example, but provides a hospitable home for dung flies. So applying formal logic cannot in principle solve the adaptive problem of avoiding dung. The only thing that can solve it is a content-specific mechanism, one that has been built over evolutionary time to capitalize on the recurring statistical regularities associated with dung as it interacted with our hominid ancestors.<sup>14</sup></p>\n</blockquote>\n<p>&nbsp;</p>\n<h4>Conclusion</h4>\n<p>Our brains may have evolved intuition-generating mechanisms that worked for solving particular adaptive problems in the ancestral environment, but we may not have evolved psychological mechanisms that generate accurate intuitions useful for doing philosophy. For example, it seems <a href=\"http://commonsenseatheism.com/?p=14609\">unlikely</a> that we evolved a mechanism that gives us reliable intuitions about the metaphysical possibility or impossibility of <a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">zombies</a>.</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/59v/intuition_and_unconscious_learning/\">Intuition and Unconscious Learning</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">How You Make Judgments</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup> Recent introductions to the field include: Buss (2011); Workman &amp; Reader (2008); Gaulin &amp; McBurney (2003). It is also worth mentioning one of the major problems with evolutionary psychology. Evolutionary psychologists tend to focus on subjects that are difficult to test because they are <em>uniquely</em>&nbsp;human but also <em>universally</em>&nbsp;human, which is bad for testability (see <a href=\"http://books.google.com/books?id=aC8Baky2qTcC&amp;lpg=PA41&amp;ots=yGKGEik7F_&amp;dq=%22is%20evolutionary%20psychology%20a%20pseudoscience%22&amp;pg=PA41#v=onepage&amp;q&amp;f=false\">here</a>&nbsp;and <a href=\"http://www.rationallyspeakingpodcast.org/show/rs18-evolutionary-psychology.html\">here</a>). For other difficulties, see <a href=\"/lw/2l7/problems_in_evolutionary_psychology/\">Problems in Evolutionary Psychology</a>.</small></p>\n<p><small><sup>2</sup> Birch (1999); Krebs (2009).</small></p>\n<p><small><sup>3</sup> Buss et al. (1990); Buss &amp; Schmitt (1993); Khallad (2005); Gottschall et al. (2003); Gottschall et al. (2004); Kenrick et al. (1990); Gustavsson &amp; Johnsson (2008); Wiederman (1993); Badahdah &amp; Tiemann (2005); Marlowe (2004); Fisman et al. (2006); Asendorpf et al. (2010); Bokek-Cohen et al. (2007); Pettay et al. (2007).</small></p>\n<p><small><sup>4</sup> Signs of fertility that men prefer include youth (Buss 1989a; Kenrick &amp; Keefe 1992; Kenrick et al. 1996), clear and smooth skin (Sugiyama 2005; Singh &amp; Bronstad 1997; Fink &amp; Neave 2005; Fink et al. 2008; Ford &amp; Beach 1951; Symons 1995), facial femininity (Gangestad &amp; Scheyd 2005; Schaefer et al. 2006; Rhodes 2006), long legs (Fielding et al. 2008; Sorokowski &amp; Pawlowski 2008; Bertamini &amp; Bennett 2009; Swami et al. 2006), and a low waist-to-hip ratio (Singh 1993, 2000; Singh &amp; Young 1995; Jasienska et al. 2004; Singh &amp; Randall 2007; Connolly et al 2000; Furnham et al 1997). Even men blind from birth prefer a low waist-to-hip ratio (Karremans et al. 2010). Note that standards for beautiful faces emerge before cultural can have much effect (Langlois et al. 1990) and that standards of beauty are relatively consistent across cultures (Cunningham et al. 1995; Cross &amp; Cross 1971; Jackson 1992; Jones 1996; Thakerar &amp; Iwawaki 1979).</small></p>\n<p><small><sup>5</sup> Buss (2011), pp. 92-94.</small></p>\n<p><small><sup>6</sup> Buss (2011), p. 85.</small></p>\n<p><small><sup>7</sup> Evidence cited by prediction number. 1: Hewlett (1991); Lee (1979). 2: Tooby &amp; DeVore (1987). 3: Trivers (1971). 4: Roskraft et al. (2004); Tooby &amp; DeVore (1987). 5: Hawkes (1991); Wiessner (2002). 6: Silverman &amp; Philips (1998); Silverman et al. (2000); Eals &amp; Silverman (1994); Silverman et al. (2007); New et al. (2007); Silverman &amp; Choi (2005); Lippa et al. (2010).</small></p>\n<p><small><sup>8</sup> Buss (2011), p. 238-239.</small></p>\n<p><small><sup>9</sup>&nbsp;Buss (2011) calls Hamilton's theory of inclusive fitness (expressed in Hamilton's rule) \"the single most important theoretical revision of Darwin's theory of natural selection in the past century\" (p. 239). For a review of some of the evidence that supports Hamilton's rule, see Buss (2011), chapter 8.</small></p>\n<p><small><sup>10</sup> Atran (1998); Berlin (1992); Keil (1995); Medin &amp; Atran (1999).</small></p>\n<p><small><sup>11</sup> Sperber &amp; Hirschfeld (2004).</small></p>\n<p><small><sup>12</sup> Buss (2011), p. 73.</small></p>\n<p><small><sup>13</sup> Tooby &amp; Cosmides (1998). Haselton et al. (2009) say humans are 'adaptively biased,' while Kenrick et al. (2009) say we are 'adaptively rational.'</small></p>\n<p><small><sup>14</sup> Buss (2011), pp. 396-397.</small></p>\n<p><small><span style=\"font-size: 11px;\"><br /></span></small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Asendorpf, Penke, &amp; Back (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Asendorpf-From-dating-to-mating-and-relating-Predictors-of-initial-and-long-term-outcomes-of-speed-dating-in-a-community-sample.pdf\">From dating to mating and relating: Predictors of initial and long-term outcomes of speed dating in a community sample</a>. <em>European Journal of Personality</em>.</small></p>\n<p><small>Atran (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Atran-Folk-biology-and-the-anthropology-of-science.pdf\">Folk biology and the anthropology of science: Cognitive universals and cultural particulars</a>. <em>Behavioral and Brain Sciences, 21</em>: 547-609.</small></p>\n<p><small>Badahdah &amp; Tiemann (2005). Mate selection criteria among Muslims living in America. <em>Evolution and Human Behavior, 26</em>: 432-440.</small></p>\n<p><small>Berlin (1992). <em><a href=\"http://www.amazon.com/Ethnobiological-Classification-Principles-Categorization-Traditional/dp/0691094691/\">Ethnobiological classification</a></em>. Princeton University Press.</small></p>\n<p><small>Bertamini &amp; Bennett (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Bertamini-The-effect-of-leg-length-on-perceived-attractiveness-of-simplified-stimuli.pdf\">The effect of leg length on perceived attractiveness of simplified stimuli</a>. <em>Journal of Social, Evolutionary, and Cultural Psychology, 3</em>: 233-250.</small></p>\n<p><small>Birch (1999). Development of food preferences. <em>Annual Review of Nutricion, 19</em>: 41-62.</small></p>\n<p><small>Bokek-Cohen, Peres, &amp; Kanazawa (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Bokek-Cohen-Rational-choice-and-evolutionary-psychology-as-explanations-for-mate-selectivity.pdf\">Rational choice and evolutionary psychology as explanations for mate selectivity</a>. <em>Journal of Social, Evolutionary, and Cultural Psychology, 2</em>: 42-55.</small></p>\n<p><small>Buss (1989). Sex differences in human mate preferences: Evolutionary hypotheses testing in 37 cultures. <em>Behavioral and Brain Sciences, 12</em>: 1-49.</small></p>\n<p><small>Buss (2011). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-New-Science-Mind/dp/020501562X/\">Evolutionary Psychology: The New Science of Mind</a></em>&nbsp;(4th ed.). Prentice Hall.</small></p>\n<p><small>Buss &amp; Schmitt (1993). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Buss-Sexual-strategies-theory-An-evolutionary-perspective-on-human-mating.pdf\">Sexual strategies theory: An evolutionary perspective on human mating</a>. <em>Psychological Review, 100</em>: 204-232.</small></p>\n<p><small>Buss, Abbott, Angleitner, Asherian, Biaggio, et al. (1990). International preferences in selecting mates: A study of 37 cultures. <em>Journal of Cross-Cultural Psychology, 21</em>: 5-47.</small></p>\n<p><small>Connolly, Mealey, &amp; Slaughter (2000). The development of waist-to-hip ratio preferences. <em>Perspectives in Human Biology, 5</em>: 19-29.</small></p>\n<p><small>Cross &amp; Cross (1971). Age, sex, race, and the perception of facial beauty. <em>Developmental Psychology, 5</em>: 433-439.</small></p>\n<p><small>Cunningham, Roberts, Wu, Barbee, &amp; Druen (1995). \"Their ideas of beauty are, on the whole, the same as ours\": Consistency and variability in the cross-cultural perception of female attractiveness. <em>Journal of Personality and Social Psychology, 68</em>: 261-279.</small></p>\n<p><small>Eals &amp; Silverman (1994). The hunter-gatherer theory of spatial sex differences: Proximate factors mediating the female advantage in recall of object arrays. <em>Ethology and Sociobiology, 15</em>: 95-105.</small></p>\n<p><small>Fielding, Scholling, Adab, Cheng, Lao et al. (2008). Are longer legs associated with enhanced fertility in Chinese women? <em>Evolution and Human Behavior, 29</em>: 434-443.</small></p>\n<p><small>Fink &amp; Neave (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Fink-The-biology-of-facial-beauty.pdf\">The biology of facial beauty</a>. <em>Internal Journal of Cosmetic Science, 27</em>: 317-325.</small></p>\n<p><small>Fink, Matts, Klingenberg, Kuntze, Weege, &amp; Grammar (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Fink-Visual-attention-to-variation-in-female-skin-color-distribution.pdf\">Visual attention to variation in female skin color distribution</a>. <em>Journal of Cosmetic Dermatology, 7</em>: 155-161.</small></p>\n<p><small>Fisman, Iyengar, Kamenica, &amp; Simonson (2006). Gender differences in mate selection: Evidence from a speed dating experiment. <em>The Quarterly Journal of Economics, 121</em>: 673-697.</small></p>\n<p><small>Ford &amp; Beach (1951). <em><a href=\"http://www.amazon.com/Patterns-sexual-behavior-foreword-Dickinson/dp/B0041WVRI2/\">Patterns of Sexual Behavior</a></em>. Harper &amp; Row.</small></p>\n<p><small>Furnham, Tan, &amp; McManus (1997). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Furnham-Waist-to-hip-ratio-and-preferences-for-body-shape-A-replication-and-extension.pdf\">Waist-to-hip ratio and preferences for body shape: A replication and extension</a>. <em>Personality and Individual Differences, 22</em>: 539-549.</small></p>\n<p><small>Gangestad &amp; Scheyd (2005). The evolution of human physical attractiveness. <em>Annual Review of Anthropology, 34</em>: 523-548.</small></p>\n<p><small>Gaulin &amp; McBurney (2003). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-2nd-Steven-Gaulin/dp/0131115294/\">Evolutionary Psychology</a></em>&nbsp;(2nd ed.) Prentice Hall.</small></p>\n<p><small>Gottschall, Berkey, Cawson, Drown, Fleischner, et al. (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gottschall-Patterns-of-characterization-in-folktales-across-geographic-regions-and-levels-of-cultural-complexity.pdf\">Patterns of characterization in folktales across geographic regions and levels of cultural complexity: Literature as a neglected source of quantitative data</a>. <em>Human Nature, 14</em>: 365-382.</small></p>\n<p><small>Gottschall, Martin, Quish, &amp; Rea (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gottschall-Sex-differences-in-mate-choice-criteria-are-reflected-in-folktales-from-around-the-world-and-in-historical-European-literature.pdf\">Sex differences in mate choice criteria are reflected in folktales from around the world and in historical European literature</a>. <em>Evolution and Human Behavior, 25</em>: 102-112.</small></p>\n<p><small>Gustavsson &amp; Johnsson (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gustavvsson-Mixed-support-for-sexual-selection-theories-of-mate-preferences-in-the-Swedish-population.pdf\">Mixed support for sexual selection theories of mate preferences in the Swedish population</a>. <em>Evolutionary Psychology, 6</em>: 454-470.</small></p>\n<p><small>Haselton , Bryant, Wilke, Frederick, Galperin, Franenhuis, &amp; Moore (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Haselton-Adaptive-rationality-an-evolutionary-perspective-on-cognitive-bias.pdf\">Adaptive rationality: An evolutionary perspective on cognitive bias</a>. <em>Social Cognition, 27</em>: 733-763.</small></p>\n<p><small>Hawkes (1991). Showing off: Tests of another hypothesis about men's foraging goals. <em>Ethology and Sociobiology, 11</em>: 29-54.</small></p>\n<p><small>Hewlett (1991). <em><a href=\"http://www.amazon.com/Intimate-Fathers-Nature-Context-Paternal/dp/0472082035/\">Intimate Fathers: The nature and context of Aka pygmy paternal infant care</a></em>. University of Michigan Press.</small></p>\n<p><small>Jackson (1992). <em><a href=\"http://www.amazon.com/Physical-Appearance-Gender-Sociobiological-Sociocultural/dp/0791408248/\">Physical appearance and gender: Sociobiological and sociocultural perspectives</a></em>. State University of New York Press.</small></p>\n<p><small>Jasienska, Ziomkiewicz, Ellison, Lipson, &amp; Thune (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Jasienska-Large-breasts-and-narrow-waists-indicate-high-reproductive-potential-in-women.pdf\">Large breasts and narrow waists indicate high reproductive potential in women</a>. <em>Proceedings of the Royal Society of London, B, 271</em>: 1213-1217.</small></p>\n<p><small>Jones (1996). <em><a href=\"http://www.amazon.com/Physical-Attractiveness-Theory-Sexual-Selection/dp/0915703408/\">Physical attractiveness and the theory of sexual selection</a></em>. University of Michigan Press.</small></p>\n<p><small>Karremans, Frankenhuis, &amp; Arons (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Karremans-Blind-men-prefer-a-low-waist-to-hip-ratio.pdf\">Blind men prefer a low waist-to-hip ratio</a>. <em>Evolution and Human Behavior, 31</em>: 182-186.</small></p>\n<p><small>Keil (1995). The growth of understandings of natural kinds. In Sperber, Premack, &amp; Premack (eds.), <em>Causal cognition</em>. Clarendon Press.</small></p>\n<p><small>Kenrick, Sadalla, Groth, &amp; Trost (1990). Evolution, traits, and the stages of human courtship: Qualifying the parental investment model. <em>Journal of Personality, 58</em>: 97-116.</small></p>\n<p><small>Kenrick, Keefe, Gabrielidis, &amp; Cornelius (1996). Adolescents' age preferences for dating partners: Support for an evolutionary model of life-history strategies. <em>Child Development, 67</em>: 1499-1511.</small></p>\n<p><small>Kenrick, Griskevicius, Sundie, Li, Li, &amp; Neuberg (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Kenrick-Deep-rationality-the-evolutionary-economics-of-decision-making.pdf\">Deep rationality: The evolutionary economics of decision making</a>. <em>Social Cognition, 27</em>: 764-785.</small></p>\n<p><small>Kenrick &amp; Keefe (1992). Age preferences in mates reflect sex differences in reproductive strategies. <em>Behaivoral and Brain Sciences, 15</em>: 75-133.</small></p>\n<p><small>Khallad (2005). Mate selection in Jordan: Effects of sex, socio-economic status, and culture. <em>Journal of Social and Personal Relationships, 22</em>: 155-168.</small></p>\n<p><small>Krebs (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Krebs-The-gourmet-ape-Evolution-and-human-food-preferences.pdf\">The gourmet ape: Evolution and human food preferences</a>. <em>American Journal of Clinical Nutrition, 90</em>: 707S-711S.</small></p>\n<p><small>Langlois, Roggman, &amp; Reiser-Danner (1990). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Langlois-Infants-differential-social-responses-to-attractive-and-unattractive-faces.pdf\">Infants' differential social responses to attractive and unattractive faces</a>. <em>Developmental Psychology, 26</em>: 153-159.</small></p>\n<p><small>Lee (1979). <em><a href=\"http://www.amazon.com/Kung-San-Women-Foraging-Society/dp/0521295610/\">The !Kung San: Men, women, and working in a foraging society</a></em>. Cambridge University Press.</small></p>\n<p><small>Lippa, Collaer, &amp; Peters (2010). Sex differences in mental rotation and line angle judgments are positively associated with gender equality and economic development across 53 nations. <em>Archives of Sexual Behavior, 39</em>: 990-997.</small></p>\n<p><small>Marlowe (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Langlois-Infants-differential-social-responses-to-attractive-and-unattractive-faces.pdf\">Mate preferences among Hadza hunter-gatherers</a>. <em>Human Nature, 4</em>: 365-376.</small></p>\n<p><small>Medin &amp; Atran, eds. (1999). <em><a href=\"http://www.amazon.com/Folkbiology-Bradford-Books-Douglas-Medin/dp/026263192X/\">Folkbiology</a></em>. MIT Press.</small></p>\n<p><small>New, Krasnow, Truxaw, &amp; Gaulin (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/New-Spatial-adaptations-for-plant-foraging-Women-excel-and-calories-count.pdf\">Spatial adaptations for plant foraging: Women excel and calories count</a>. <em>Proceedings of the Royal Society, B, 274</em>: 2679-2684.</small></p>\n<p><small>Pettay, Helle, Jokela, &amp; Lummaa (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Pettay-Natural-selection-on-female-life-history-traits-in-relation-to-socio-economic-class-in-pre-industrial-human-populations.pdf\">Natural selection on female life-history traits in relation to socio-economic class in pre-industrial human populations</a>. <em>Plos ONE</em>, July: 1-9.</small></p>\n<p><small>Rhodes (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Rhodes-The-evolutionary-psychology-of-facial-beauty.pdf\">The evolutionary psychology of facial beauty</a>. <em>Annual Review of Psychology, 57</em>: 199-226.</small></p>\n<p><small>Roskraft, Hagen, Hagen, &amp; Moksnes (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Roskraft-Patterns-of-outdoor-recreation-activities-among-Norwegians-An-evolutionary-approach.pdf\">Patterns of outdoor recreation activities among Norwegians: An evolutionary approach</a>. <em>Ann. Zool. Fennici, 41</em>: 609-618.</small></p>\n<p><small>Schaefer, Fink, Grammar, Mitteroecker, Gunz, &amp; Bookstein (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Schafer-et-al-Female-appearance-Facial-and-bodily-attractiveness-as-shape.pdf\">Female appearance: Facial and bodily attractiveness as shape</a>. <em>Psychology Science, 48</em>: 187-205.</small></p>\n<p><small>Silverman &amp; Philips (1998). The evolutionary psychology of spatial sex differences. In Crawford &amp; Krebs (eds.), <em>Handbook of evolutionary psychology</em>&nbsp;(pp. 595-612). Erlbaum.</small></p>\n<p><small>Silverman &amp; Choi (2005). Locating places. In Buss (ed.), <em>Handbook of evolutionary psychology</em>&nbsp;(pp. 177-199). Wiley.</small></p>\n<p><small>Silverman, Choi, Mackewn, Fisher, Moro, &amp; Olshanksy (2000). Evolved mechanisms underlying wayfinding: Further studies on the hunter-gatherer theory of spatial sex differences. <em>Evolution and Human Behavior, 21</em>: 201-213.</small></p>\n<p><small>Silverman, Choi, &amp; Peters (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Silverman-On-the-universality-of-sex-related-spatial-competencies.pdf\">On the universality of sex-related spatial competencies</a>. <em>Archives of Human Sexuality, 36</em>: 261-268.</small></p>\n<p><small>Singh (1993). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Singh-Adaptive-significance-of-waist-to-hip-ratio-and-female-physical-attractiveness.pdf\">Adaptive significance of waist-to-hip ratio and female physical attractiveness</a>. <em>Journal of Personality and Social Psychology, 65</em>: 293-307.</small></p>\n<p><small>Singh (2000). Waist-to-hip ratio: An indicator of female mate value. <em>International Research Center for Japanese Studies, International Symposium 16</em>: 79-99.</small></p>\n<p><small>Singh &amp; Randall (2007). Beauty is in the eye of the plastic surgeon: Waist-to-hip ratio (WHR) and women's attractiveness. <em>Personality and Individual Differences, 43</em>: 329-340.&nbsp;</small></p>\n<p><small>Singh &amp; Bronstad (1997). Sex differences in the anatomical locations of human body scarification and tattooing as a function of pathogen prevalence. <em>Evolution and Human Behavior, 18</em>: 403-416.</small></p>\n<p><small>Singh &amp; Young (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Singh-Body-weight-waist-to-hip-ratio-breasts-and-hips-Role-in-judgments-of-female-attractiveness-and-desirability-for-relationships.pdf\">Body weight, waist-to-hip ratio, breasts, and hips: Role in judgments of female attractiveness and desirability for relationships</a>. <em>Ethology and Sociobiology, 16</em>: 483-507.</small></p>\n<p><small>Sperber &amp; Hirschfeld (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Sperber-Hirschfeld-The-cognitive-foundations-of-cultural-stability-and-diversity.pdf\">The cognitive foundations of cultural stability and diversity</a>. <em>Trends in Cognitive Science, 8</em>: 40-46.</small></p>\n<p><small>Sorokowski &amp; Pawlowski (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Sorokowski-Adaptive-preferences-for-leg-length-in-a-potential-partner.pdf\">Adaptive preferences for leg length in a potential partner</a>. <em>Evolution and Human Behavior, 29</em>: 86-91.</small></p>\n<p><small>Sugiyama (2005). Physical attractiveness in adaptationist perspective. In Buss (ed.), <em>The handbook of evolutionary psychology</em>&nbsp;(pp. 292-342). Wiley.</small></p>\n<p><small>Swami, Einon, &amp; Furnham (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Swami-The-leg-to-body-ratio-as-a-human-aesthetic-criterion.pdf\">The leg-to-body ratio as a human aesthetic criterion</a>. <em>Body Image, 3</em>: 317-323.</small></p>\n<p><small>Symons (1995). Beauty is in the adaptations of the beholder: The evolutionary psychology of human female sexual attractiveness. In Abramson &amp; Pinkerton (eds.), <em>Sexual nature, sexual culture</em>&nbsp;(pp. 80-118). University of Chicago Press.</small></p>\n<p><small>Thakerar &amp; Iwawaki (1979). Cross-cultural comparisons in interpersonal attraction of females toward males. <em>Journal of Social Psychology, 108</em>: 121-122.</small></p>\n<p><small>Tooby &amp; Cosmides (1998). <em>Ecological rationality and the multimodular mind: Grounding normative theories in adaptive problems</em>. Unpublished manuscript, University of California, Santa Barbara.</small></p>\n<p><small>Tooby &amp; DeVore (1987). The reconstruction of hominid behavioral evolution through strategic modeling. In Kinzey (ed.), <em>The evolution of human behavior</em>&nbsp;(pp. 183-237). State University of New York Press.</small></p>\n<p><small>Trivers (1971). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Trivers-the-evolution-of-reciprocal-altruism.pdf\">The evolution of reciprocal altruism</a>. <em>The Quarterly Review of Biology, 46</em>: 35-57.</small></p>\n<p><small>Wiederman (1993). Evolved gender differences in mate preferences: Evidence from personal advertisements. <em>Ethology and Sociobiology, 14</em>: 331-352.</small></p>\n<p><small>Wiessner (2002). Hunting, healing, and <em>hzaro</em>&nbsp;exchange: A long-term perspective on !Kung large-game hunting. <em>Evolution and Human Behavior, 20</em>: 121-128.</small></p>\n<p><small>Workman &amp; Reader (2008). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-Introduction-Lance-Workman/dp/0521888360/\">Evolutionary Psychology: An Introduction</a></em>&nbsp;(2nd ed.). Cambridge University Press.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nZCb9BSnmXZXSNA2u": 2, "Ng8Gice9KNkncxqcj": 2, "4R8JYu4QF2FqzJxE5": 2, "z95PGFXtPpwakqkTA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WTS4ZbEwvKrcrnaaN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 21, "extendedScore": null, "score": 4.2e-05, "legacy": true, "legacyId": "6908", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "yFvZa9wkv5JoqhM8F", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "intuition-and-unconscious-learning", "canonicalPrevPostSlug": "how-you-make-judgments-the-elephant-and-its-rider", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>We have already examined one source of our intuitions: <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">attribute substitution heuristics</a>. Today we examine a second source of our intuitions: <em>biological evolution</em>.</p>\n<p>&nbsp;</p>\n<h4 id=\"Evolutionary_psychology\">Evolutionary psychology</h4>\n<p>Evolutionary psychology<sup>1</sup> has been covered on Less Wrong <a href=\"http://wiki.lesswrong.com/wiki/Evolutionary_psychology\">many times before</a>, but let's review anyway.</p>\n<p>Lions walk on four legs and hunt for food. Skunks defend themselves with a spray. Spiders make webs. Each species is shaped by selection pressures, and is different from that of other species.</p>\n<p>Certain evolved psychological mechanisms in humans are part of what makes us like each other and not like lions, skunks, and spiders.</p>\n<p>These mechanisms evolved to solve specific adaptive problems. It is not an accident that people around the world prefer calorie-rich foods,<sup>2</sup>&nbsp;that women around the world prefer men with resources,<sup>3</sup> that men around the world prefer women with signs of fertility,<sup>4</sup> or that most of us inherently fear snakes and spiders but not cars and electrical outlets.<sup>5</sup></p>\n<p>An an example of evolutionary psychology at work, consider the '<a href=\"/lw/mj/rational_vs_scientific_evpsych/\">hunter-gatherer hypothesis</a>' that men evolved psychological mechanisms to aid in hunting, while women evolved psychological mechanisms to aid in gathering.<sup>6</sup> This hypothesis leads to a list of bold predictions. If the hypothesis is correct, then:</p>\n<ol>\n<li>Men in modern tribal societies should spend a lot of time hunting, and women more time gathering.</li>\n<li>Humans should show a greater tendency toward strong male coalitions than similar species in which males do not hunt much, because strong male coalitions are required to hunt big game.</li>\n<li>Because meat from most game comes in quantities larger than a single hunter can consume, and because hunting success is highly variable (one week may be a success, but perhaps not the next week),&nbsp;humans should exhibit food sharing and reciprocal altruism.</li>\n<li>We should expect to see a sexual division of labor, due to the different traits conducive for hunting vs. gathering.</li>\n<li>Men should exploit status gains to be had from 'showing off' large hunting successes.</li>\n<li>Men should have superior cognitive ability to navigate across large distances and perform 3D mental rotation tasks required for throwing spears and similar hunting acts. Women should have superior cognitive ability with spacial location memory and object arrays.</li>\n</ol>\n<p>And as it turns out, <em>all</em>&nbsp;these predictions are correct.<sup>7</sup>&nbsp;(And no, evolutionary psychologists do <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/DeBruine-Beyond-Just-So-Stories.pdf\">not</a> only offer 'postdictions' or 'just so' stories. Besides, probability theory <a href=\"/lw/5bw/your_evolved_intuitions/4gpz\">does not have separate categories</a> for 'predictions' and 'postdictions'.)</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Kin_loyalty\">Kin loyalty</h4>\n<p>Consider the intuition that we have more responsibility for the well-being of our close relatives than for the well-being of distant relatives or strangers. We would <em>expect</em>&nbsp;human evolution to produce exactly such an intuition given&nbsp;<a href=\"http://en.wikipedia.org/wiki/Kin_selection#Hamilton.27s_rule\">Hamilton's rule</a>,&nbsp;which states that the reproductive cost to an agent is less than the genetic relatedness of the recipient to the agent multiplied by the additional reproductive benefit gained by the recipient of the altruistic act.</p>\n<p>That's a mouthful, so instead let me illustrate the consequences of Hamilton's rule:</p>\n<blockquote>\n<p>Imagine that you pass by a river and notice that some of your genetic relatives are drowning in a ferocious current. You could jump in the water to save them, but you would pay with your own life. According to Hamilton's rule, selection will favor decision rules that, on average, result in your jumping into the water to save three of your brothers, but not one. You would be predicted <em>not</em>&nbsp;to sacrifice your own life for just <em>one</em> brother, because that would violate Hamilton's rule. Using the logic of Hamilton's rule, evolved decision rules should lead you to sacrifice your own life for five nieces or nephews, but you would have to save nine first cousins before you would sacrifice your own life.<sup>8</sup></p>\n</blockquote>\n<p>Hamilton's rule has indeed been observed at work in a wide variety of contexts.<sup>9</sup></p>\n<p>My intuition that I am more responsible for the well-being of my brother than my cousin, and more responsible for the well-being of my cousin than a stranger, looks like a good candidate for an evolved intuition.</p>\n<p>&nbsp;</p>\n<h4 id=\"Essentialism\">Essentialism</h4>\n<p>Uneducated people around the world believe that organisms come in discrete packets, and that each species has an 'essence' that produces its form and abilities. The intuitive appeal of this&nbsp;<em style=\"font-style: italic;\">essentialism</em>&nbsp;often trumps the explicitly learned gradualism of biological evolution. Even someone who has read Richard Dawkins <a href=\"http://proliferationofniches.blogspot.com/2009/10/dawkins-on-essentialism.html\">argue</a>&nbsp;against essentialism might find himself the very next day stuck in essentialist thinking. Why? Many researchers have suggested that an evolved, intuitive 'folk biology' is responsible.<sup>10</sup></p>\n<p>These essentialist intuitions emerge early in life across all cultures we have studied.<sup>11</sup> For example, children may believe that</p>\n<blockquote>\n<p>...if you remove the insides of a dog, it loses its 'essence' and is no longer really a dog anymore - it can't bark or bite. But if you remove its outsides or change its external appearance so that it doesn't look like a dog, children still believe that it has retained its essential 'dogness.'<sup>12</sup></p>\n</blockquote>\n<p>Many researchers think that essentialist intuitions evolved because it's useful for humans to respond to organisms in this way. With essentialist thinking, we can very quickly drop organisms into categories concerning what we can and can't eat, what we can capture, what might capture us, and so on.</p>\n<p>Essentialism has had a <a href=\"http://en.wikipedia.org/wiki/Essentialism\">long-lasting hold</a> on the minds of many philosophers, and greatly influenced their conclusions even after Darwin.</p>\n<p>&nbsp;</p>\n<h4 id=\"Heuristics_and_biases\">Heuristics and biases</h4>\n<p>Human reasoning is subject to a&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Bias\">long list of biases</a>. Why did we evolve such faulty thinking processes? Aren't false beliefs bad for survival and reproduction?</p>\n<p>Many researchers suggest that while humans are poor at formal logic and <a href=\"http://yudkowsky.net/rational/bayes\">Bayesian inference</a>, humans display a kind of 'ecological rationality'.<sup>13</sup></p>\n<blockquote>\n<p>Over evolutionary time, the human environment has had certain statistical regularities: Rain often followed thunder, violence sometimes followed angry shouts, sex sometimes followed prolonged eye contact, dangerous bites often followed getting too close to a snake, and so on. These statistical regularities are called <em>ecological structure</em>. Ecological rationality consists of evolved mechanisms containing design features that utilize ecological structure to facilitate adaptive problem solving.</p>\n<p>The shape and form of cognitive mechanisms, in other words, coordinate with the recurring statistical regularities of the ancestral environments in which humans evolved. We fear snakes and not electrical outlets...</p>\n<p>[Moreover], theories of formal logic that are content independent... are exceptionally poor at solving real adaptive problems. The world is full of logically arbitrary relationships: Dung happens to be potentially dangerous to humans, for example, but provides a hospitable home for dung flies. So applying formal logic cannot in principle solve the adaptive problem of avoiding dung. The only thing that can solve it is a content-specific mechanism, one that has been built over evolutionary time to capitalize on the recurring statistical regularities associated with dung as it interacted with our hominid ancestors.<sup>14</sup></p>\n</blockquote>\n<p>&nbsp;</p>\n<h4 id=\"Conclusion\">Conclusion</h4>\n<p>Our brains may have evolved intuition-generating mechanisms that worked for solving particular adaptive problems in the ancestral environment, but we may not have evolved psychological mechanisms that generate accurate intuitions useful for doing philosophy. For example, it seems <a href=\"http://commonsenseatheism.com/?p=14609\">unlikely</a> that we evolved a mechanism that gives us reliable intuitions about the metaphysical possibility or impossibility of <a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">zombies</a>.</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/59v/intuition_and_unconscious_learning/\">Intuition and Unconscious Learning</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">How You Make Judgments</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup> Recent introductions to the field include: Buss (2011); Workman &amp; Reader (2008); Gaulin &amp; McBurney (2003). It is also worth mentioning one of the major problems with evolutionary psychology. Evolutionary psychologists tend to focus on subjects that are difficult to test because they are <em>uniquely</em>&nbsp;human but also <em>universally</em>&nbsp;human, which is bad for testability (see <a href=\"http://books.google.com/books?id=aC8Baky2qTcC&amp;lpg=PA41&amp;ots=yGKGEik7F_&amp;dq=%22is%20evolutionary%20psychology%20a%20pseudoscience%22&amp;pg=PA41#v=onepage&amp;q&amp;f=false\">here</a>&nbsp;and <a href=\"http://www.rationallyspeakingpodcast.org/show/rs18-evolutionary-psychology.html\">here</a>). For other difficulties, see <a href=\"/lw/2l7/problems_in_evolutionary_psychology/\">Problems in Evolutionary Psychology</a>.</small></p>\n<p><small><sup>2</sup> Birch (1999); Krebs (2009).</small></p>\n<p><small><sup>3</sup> Buss et al. (1990); Buss &amp; Schmitt (1993); Khallad (2005); Gottschall et al. (2003); Gottschall et al. (2004); Kenrick et al. (1990); Gustavsson &amp; Johnsson (2008); Wiederman (1993); Badahdah &amp; Tiemann (2005); Marlowe (2004); Fisman et al. (2006); Asendorpf et al. (2010); Bokek-Cohen et al. (2007); Pettay et al. (2007).</small></p>\n<p><small><sup>4</sup> Signs of fertility that men prefer include youth (Buss 1989a; Kenrick &amp; Keefe 1992; Kenrick et al. 1996), clear and smooth skin (Sugiyama 2005; Singh &amp; Bronstad 1997; Fink &amp; Neave 2005; Fink et al. 2008; Ford &amp; Beach 1951; Symons 1995), facial femininity (Gangestad &amp; Scheyd 2005; Schaefer et al. 2006; Rhodes 2006), long legs (Fielding et al. 2008; Sorokowski &amp; Pawlowski 2008; Bertamini &amp; Bennett 2009; Swami et al. 2006), and a low waist-to-hip ratio (Singh 1993, 2000; Singh &amp; Young 1995; Jasienska et al. 2004; Singh &amp; Randall 2007; Connolly et al 2000; Furnham et al 1997). Even men blind from birth prefer a low waist-to-hip ratio (Karremans et al. 2010). Note that standards for beautiful faces emerge before cultural can have much effect (Langlois et al. 1990) and that standards of beauty are relatively consistent across cultures (Cunningham et al. 1995; Cross &amp; Cross 1971; Jackson 1992; Jones 1996; Thakerar &amp; Iwawaki 1979).</small></p>\n<p><small><sup>5</sup> Buss (2011), pp. 92-94.</small></p>\n<p><small><sup>6</sup> Buss (2011), p. 85.</small></p>\n<p><small><sup>7</sup> Evidence cited by prediction number. 1: Hewlett (1991); Lee (1979). 2: Tooby &amp; DeVore (1987). 3: Trivers (1971). 4: Roskraft et al. (2004); Tooby &amp; DeVore (1987). 5: Hawkes (1991); Wiessner (2002). 6: Silverman &amp; Philips (1998); Silverman et al. (2000); Eals &amp; Silverman (1994); Silverman et al. (2007); New et al. (2007); Silverman &amp; Choi (2005); Lippa et al. (2010).</small></p>\n<p><small><sup>8</sup> Buss (2011), p. 238-239.</small></p>\n<p><small><sup>9</sup>&nbsp;Buss (2011) calls Hamilton's theory of inclusive fitness (expressed in Hamilton's rule) \"the single most important theoretical revision of Darwin's theory of natural selection in the past century\" (p. 239). For a review of some of the evidence that supports Hamilton's rule, see Buss (2011), chapter 8.</small></p>\n<p><small><sup>10</sup> Atran (1998); Berlin (1992); Keil (1995); Medin &amp; Atran (1999).</small></p>\n<p><small><sup>11</sup> Sperber &amp; Hirschfeld (2004).</small></p>\n<p><small><sup>12</sup> Buss (2011), p. 73.</small></p>\n<p><small><sup>13</sup> Tooby &amp; Cosmides (1998). Haselton et al. (2009) say humans are 'adaptively biased,' while Kenrick et al. (2009) say we are 'adaptively rational.'</small></p>\n<p><small><sup>14</sup> Buss (2011), pp. 396-397.</small></p>\n<p><small><span style=\"font-size: 11px;\"><br></span></small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Asendorpf, Penke, &amp; Back (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Asendorpf-From-dating-to-mating-and-relating-Predictors-of-initial-and-long-term-outcomes-of-speed-dating-in-a-community-sample.pdf\">From dating to mating and relating: Predictors of initial and long-term outcomes of speed dating in a community sample</a>. <em>European Journal of Personality</em>.</small></p>\n<p><small>Atran (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Atran-Folk-biology-and-the-anthropology-of-science.pdf\">Folk biology and the anthropology of science: Cognitive universals and cultural particulars</a>. <em>Behavioral and Brain Sciences, 21</em>: 547-609.</small></p>\n<p><small>Badahdah &amp; Tiemann (2005). Mate selection criteria among Muslims living in America. <em>Evolution and Human Behavior, 26</em>: 432-440.</small></p>\n<p><small>Berlin (1992). <em><a href=\"http://www.amazon.com/Ethnobiological-Classification-Principles-Categorization-Traditional/dp/0691094691/\">Ethnobiological classification</a></em>. Princeton University Press.</small></p>\n<p><small>Bertamini &amp; Bennett (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Bertamini-The-effect-of-leg-length-on-perceived-attractiveness-of-simplified-stimuli.pdf\">The effect of leg length on perceived attractiveness of simplified stimuli</a>. <em>Journal of Social, Evolutionary, and Cultural Psychology, 3</em>: 233-250.</small></p>\n<p><small>Birch (1999). Development of food preferences. <em>Annual Review of Nutricion, 19</em>: 41-62.</small></p>\n<p><small>Bokek-Cohen, Peres, &amp; Kanazawa (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Bokek-Cohen-Rational-choice-and-evolutionary-psychology-as-explanations-for-mate-selectivity.pdf\">Rational choice and evolutionary psychology as explanations for mate selectivity</a>. <em>Journal of Social, Evolutionary, and Cultural Psychology, 2</em>: 42-55.</small></p>\n<p><small>Buss (1989). Sex differences in human mate preferences: Evolutionary hypotheses testing in 37 cultures. <em>Behavioral and Brain Sciences, 12</em>: 1-49.</small></p>\n<p><small>Buss (2011). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-New-Science-Mind/dp/020501562X/\">Evolutionary Psychology: The New Science of Mind</a></em>&nbsp;(4th ed.). Prentice Hall.</small></p>\n<p><small>Buss &amp; Schmitt (1993). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Buss-Sexual-strategies-theory-An-evolutionary-perspective-on-human-mating.pdf\">Sexual strategies theory: An evolutionary perspective on human mating</a>. <em>Psychological Review, 100</em>: 204-232.</small></p>\n<p><small>Buss, Abbott, Angleitner, Asherian, Biaggio, et al. (1990). International preferences in selecting mates: A study of 37 cultures. <em>Journal of Cross-Cultural Psychology, 21</em>: 5-47.</small></p>\n<p><small>Connolly, Mealey, &amp; Slaughter (2000). The development of waist-to-hip ratio preferences. <em>Perspectives in Human Biology, 5</em>: 19-29.</small></p>\n<p><small>Cross &amp; Cross (1971). Age, sex, race, and the perception of facial beauty. <em>Developmental Psychology, 5</em>: 433-439.</small></p>\n<p><small>Cunningham, Roberts, Wu, Barbee, &amp; Druen (1995). \"Their ideas of beauty are, on the whole, the same as ours\": Consistency and variability in the cross-cultural perception of female attractiveness. <em>Journal of Personality and Social Psychology, 68</em>: 261-279.</small></p>\n<p><small>Eals &amp; Silverman (1994). The hunter-gatherer theory of spatial sex differences: Proximate factors mediating the female advantage in recall of object arrays. <em>Ethology and Sociobiology, 15</em>: 95-105.</small></p>\n<p><small>Fielding, Scholling, Adab, Cheng, Lao et al. (2008). Are longer legs associated with enhanced fertility in Chinese women? <em>Evolution and Human Behavior, 29</em>: 434-443.</small></p>\n<p><small>Fink &amp; Neave (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Fink-The-biology-of-facial-beauty.pdf\">The biology of facial beauty</a>. <em>Internal Journal of Cosmetic Science, 27</em>: 317-325.</small></p>\n<p><small>Fink, Matts, Klingenberg, Kuntze, Weege, &amp; Grammar (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Fink-Visual-attention-to-variation-in-female-skin-color-distribution.pdf\">Visual attention to variation in female skin color distribution</a>. <em>Journal of Cosmetic Dermatology, 7</em>: 155-161.</small></p>\n<p><small>Fisman, Iyengar, Kamenica, &amp; Simonson (2006). Gender differences in mate selection: Evidence from a speed dating experiment. <em>The Quarterly Journal of Economics, 121</em>: 673-697.</small></p>\n<p><small>Ford &amp; Beach (1951). <em><a href=\"http://www.amazon.com/Patterns-sexual-behavior-foreword-Dickinson/dp/B0041WVRI2/\">Patterns of Sexual Behavior</a></em>. Harper &amp; Row.</small></p>\n<p><small>Furnham, Tan, &amp; McManus (1997). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Furnham-Waist-to-hip-ratio-and-preferences-for-body-shape-A-replication-and-extension.pdf\">Waist-to-hip ratio and preferences for body shape: A replication and extension</a>. <em>Personality and Individual Differences, 22</em>: 539-549.</small></p>\n<p><small>Gangestad &amp; Scheyd (2005). The evolution of human physical attractiveness. <em>Annual Review of Anthropology, 34</em>: 523-548.</small></p>\n<p><small>Gaulin &amp; McBurney (2003). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-2nd-Steven-Gaulin/dp/0131115294/\">Evolutionary Psychology</a></em>&nbsp;(2nd ed.) Prentice Hall.</small></p>\n<p><small>Gottschall, Berkey, Cawson, Drown, Fleischner, et al. (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gottschall-Patterns-of-characterization-in-folktales-across-geographic-regions-and-levels-of-cultural-complexity.pdf\">Patterns of characterization in folktales across geographic regions and levels of cultural complexity: Literature as a neglected source of quantitative data</a>. <em>Human Nature, 14</em>: 365-382.</small></p>\n<p><small>Gottschall, Martin, Quish, &amp; Rea (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gottschall-Sex-differences-in-mate-choice-criteria-are-reflected-in-folktales-from-around-the-world-and-in-historical-European-literature.pdf\">Sex differences in mate choice criteria are reflected in folktales from around the world and in historical European literature</a>. <em>Evolution and Human Behavior, 25</em>: 102-112.</small></p>\n<p><small>Gustavsson &amp; Johnsson (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gustavvsson-Mixed-support-for-sexual-selection-theories-of-mate-preferences-in-the-Swedish-population.pdf\">Mixed support for sexual selection theories of mate preferences in the Swedish population</a>. <em>Evolutionary Psychology, 6</em>: 454-470.</small></p>\n<p><small>Haselton , Bryant, Wilke, Frederick, Galperin, Franenhuis, &amp; Moore (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Haselton-Adaptive-rationality-an-evolutionary-perspective-on-cognitive-bias.pdf\">Adaptive rationality: An evolutionary perspective on cognitive bias</a>. <em>Social Cognition, 27</em>: 733-763.</small></p>\n<p><small>Hawkes (1991). Showing off: Tests of another hypothesis about men's foraging goals. <em>Ethology and Sociobiology, 11</em>: 29-54.</small></p>\n<p><small>Hewlett (1991). <em><a href=\"http://www.amazon.com/Intimate-Fathers-Nature-Context-Paternal/dp/0472082035/\">Intimate Fathers: The nature and context of Aka pygmy paternal infant care</a></em>. University of Michigan Press.</small></p>\n<p><small>Jackson (1992). <em><a href=\"http://www.amazon.com/Physical-Appearance-Gender-Sociobiological-Sociocultural/dp/0791408248/\">Physical appearance and gender: Sociobiological and sociocultural perspectives</a></em>. State University of New York Press.</small></p>\n<p><small>Jasienska, Ziomkiewicz, Ellison, Lipson, &amp; Thune (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Jasienska-Large-breasts-and-narrow-waists-indicate-high-reproductive-potential-in-women.pdf\">Large breasts and narrow waists indicate high reproductive potential in women</a>. <em>Proceedings of the Royal Society of London, B, 271</em>: 1213-1217.</small></p>\n<p><small>Jones (1996). <em><a href=\"http://www.amazon.com/Physical-Attractiveness-Theory-Sexual-Selection/dp/0915703408/\">Physical attractiveness and the theory of sexual selection</a></em>. University of Michigan Press.</small></p>\n<p><small>Karremans, Frankenhuis, &amp; Arons (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Karremans-Blind-men-prefer-a-low-waist-to-hip-ratio.pdf\">Blind men prefer a low waist-to-hip ratio</a>. <em>Evolution and Human Behavior, 31</em>: 182-186.</small></p>\n<p><small>Keil (1995). The growth of understandings of natural kinds. In Sperber, Premack, &amp; Premack (eds.), <em>Causal cognition</em>. Clarendon Press.</small></p>\n<p><small>Kenrick, Sadalla, Groth, &amp; Trost (1990). Evolution, traits, and the stages of human courtship: Qualifying the parental investment model. <em>Journal of Personality, 58</em>: 97-116.</small></p>\n<p><small>Kenrick, Keefe, Gabrielidis, &amp; Cornelius (1996). Adolescents' age preferences for dating partners: Support for an evolutionary model of life-history strategies. <em>Child Development, 67</em>: 1499-1511.</small></p>\n<p><small>Kenrick, Griskevicius, Sundie, Li, Li, &amp; Neuberg (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Kenrick-Deep-rationality-the-evolutionary-economics-of-decision-making.pdf\">Deep rationality: The evolutionary economics of decision making</a>. <em>Social Cognition, 27</em>: 764-785.</small></p>\n<p><small>Kenrick &amp; Keefe (1992). Age preferences in mates reflect sex differences in reproductive strategies. <em>Behaivoral and Brain Sciences, 15</em>: 75-133.</small></p>\n<p><small>Khallad (2005). Mate selection in Jordan: Effects of sex, socio-economic status, and culture. <em>Journal of Social and Personal Relationships, 22</em>: 155-168.</small></p>\n<p><small>Krebs (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Krebs-The-gourmet-ape-Evolution-and-human-food-preferences.pdf\">The gourmet ape: Evolution and human food preferences</a>. <em>American Journal of Clinical Nutrition, 90</em>: 707S-711S.</small></p>\n<p><small>Langlois, Roggman, &amp; Reiser-Danner (1990). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Langlois-Infants-differential-social-responses-to-attractive-and-unattractive-faces.pdf\">Infants' differential social responses to attractive and unattractive faces</a>. <em>Developmental Psychology, 26</em>: 153-159.</small></p>\n<p><small>Lee (1979). <em><a href=\"http://www.amazon.com/Kung-San-Women-Foraging-Society/dp/0521295610/\">The !Kung San: Men, women, and working in a foraging society</a></em>. Cambridge University Press.</small></p>\n<p><small>Lippa, Collaer, &amp; Peters (2010). Sex differences in mental rotation and line angle judgments are positively associated with gender equality and economic development across 53 nations. <em>Archives of Sexual Behavior, 39</em>: 990-997.</small></p>\n<p><small>Marlowe (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Langlois-Infants-differential-social-responses-to-attractive-and-unattractive-faces.pdf\">Mate preferences among Hadza hunter-gatherers</a>. <em>Human Nature, 4</em>: 365-376.</small></p>\n<p><small>Medin &amp; Atran, eds. (1999). <em><a href=\"http://www.amazon.com/Folkbiology-Bradford-Books-Douglas-Medin/dp/026263192X/\">Folkbiology</a></em>. MIT Press.</small></p>\n<p><small>New, Krasnow, Truxaw, &amp; Gaulin (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/New-Spatial-adaptations-for-plant-foraging-Women-excel-and-calories-count.pdf\">Spatial adaptations for plant foraging: Women excel and calories count</a>. <em>Proceedings of the Royal Society, B, 274</em>: 2679-2684.</small></p>\n<p><small>Pettay, Helle, Jokela, &amp; Lummaa (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Pettay-Natural-selection-on-female-life-history-traits-in-relation-to-socio-economic-class-in-pre-industrial-human-populations.pdf\">Natural selection on female life-history traits in relation to socio-economic class in pre-industrial human populations</a>. <em>Plos ONE</em>, July: 1-9.</small></p>\n<p><small>Rhodes (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Rhodes-The-evolutionary-psychology-of-facial-beauty.pdf\">The evolutionary psychology of facial beauty</a>. <em>Annual Review of Psychology, 57</em>: 199-226.</small></p>\n<p><small>Roskraft, Hagen, Hagen, &amp; Moksnes (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Roskraft-Patterns-of-outdoor-recreation-activities-among-Norwegians-An-evolutionary-approach.pdf\">Patterns of outdoor recreation activities among Norwegians: An evolutionary approach</a>. <em>Ann. Zool. Fennici, 41</em>: 609-618.</small></p>\n<p><small>Schaefer, Fink, Grammar, Mitteroecker, Gunz, &amp; Bookstein (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Schafer-et-al-Female-appearance-Facial-and-bodily-attractiveness-as-shape.pdf\">Female appearance: Facial and bodily attractiveness as shape</a>. <em>Psychology Science, 48</em>: 187-205.</small></p>\n<p><small>Silverman &amp; Philips (1998). The evolutionary psychology of spatial sex differences. In Crawford &amp; Krebs (eds.), <em>Handbook of evolutionary psychology</em>&nbsp;(pp. 595-612). Erlbaum.</small></p>\n<p><small>Silverman &amp; Choi (2005). Locating places. In Buss (ed.), <em>Handbook of evolutionary psychology</em>&nbsp;(pp. 177-199). Wiley.</small></p>\n<p><small>Silverman, Choi, Mackewn, Fisher, Moro, &amp; Olshanksy (2000). Evolved mechanisms underlying wayfinding: Further studies on the hunter-gatherer theory of spatial sex differences. <em>Evolution and Human Behavior, 21</em>: 201-213.</small></p>\n<p><small>Silverman, Choi, &amp; Peters (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Silverman-On-the-universality-of-sex-related-spatial-competencies.pdf\">On the universality of sex-related spatial competencies</a>. <em>Archives of Human Sexuality, 36</em>: 261-268.</small></p>\n<p><small>Singh (1993). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Singh-Adaptive-significance-of-waist-to-hip-ratio-and-female-physical-attractiveness.pdf\">Adaptive significance of waist-to-hip ratio and female physical attractiveness</a>. <em>Journal of Personality and Social Psychology, 65</em>: 293-307.</small></p>\n<p><small>Singh (2000). Waist-to-hip ratio: An indicator of female mate value. <em>International Research Center for Japanese Studies, International Symposium 16</em>: 79-99.</small></p>\n<p><small>Singh &amp; Randall (2007). Beauty is in the eye of the plastic surgeon: Waist-to-hip ratio (WHR) and women's attractiveness. <em>Personality and Individual Differences, 43</em>: 329-340.&nbsp;</small></p>\n<p><small>Singh &amp; Bronstad (1997). Sex differences in the anatomical locations of human body scarification and tattooing as a function of pathogen prevalence. <em>Evolution and Human Behavior, 18</em>: 403-416.</small></p>\n<p><small>Singh &amp; Young (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Singh-Body-weight-waist-to-hip-ratio-breasts-and-hips-Role-in-judgments-of-female-attractiveness-and-desirability-for-relationships.pdf\">Body weight, waist-to-hip ratio, breasts, and hips: Role in judgments of female attractiveness and desirability for relationships</a>. <em>Ethology and Sociobiology, 16</em>: 483-507.</small></p>\n<p><small>Sperber &amp; Hirschfeld (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Sperber-Hirschfeld-The-cognitive-foundations-of-cultural-stability-and-diversity.pdf\">The cognitive foundations of cultural stability and diversity</a>. <em>Trends in Cognitive Science, 8</em>: 40-46.</small></p>\n<p><small>Sorokowski &amp; Pawlowski (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Sorokowski-Adaptive-preferences-for-leg-length-in-a-potential-partner.pdf\">Adaptive preferences for leg length in a potential partner</a>. <em>Evolution and Human Behavior, 29</em>: 86-91.</small></p>\n<p><small>Sugiyama (2005). Physical attractiveness in adaptationist perspective. In Buss (ed.), <em>The handbook of evolutionary psychology</em>&nbsp;(pp. 292-342). Wiley.</small></p>\n<p><small>Swami, Einon, &amp; Furnham (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Swami-The-leg-to-body-ratio-as-a-human-aesthetic-criterion.pdf\">The leg-to-body ratio as a human aesthetic criterion</a>. <em>Body Image, 3</em>: 317-323.</small></p>\n<p><small>Symons (1995). Beauty is in the adaptations of the beholder: The evolutionary psychology of human female sexual attractiveness. In Abramson &amp; Pinkerton (eds.), <em>Sexual nature, sexual culture</em>&nbsp;(pp. 80-118). University of Chicago Press.</small></p>\n<p><small>Thakerar &amp; Iwawaki (1979). Cross-cultural comparisons in interpersonal attraction of females toward males. <em>Journal of Social Psychology, 108</em>: 121-122.</small></p>\n<p><small>Tooby &amp; Cosmides (1998). <em>Ecological rationality and the multimodular mind: Grounding normative theories in adaptive problems</em>. Unpublished manuscript, University of California, Santa Barbara.</small></p>\n<p><small>Tooby &amp; DeVore (1987). The reconstruction of hominid behavioral evolution through strategic modeling. In Kinzey (ed.), <em>The evolution of human behavior</em>&nbsp;(pp. 183-237). State University of New York Press.</small></p>\n<p><small>Trivers (1971). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Trivers-the-evolution-of-reciprocal-altruism.pdf\">The evolution of reciprocal altruism</a>. <em>The Quarterly Review of Biology, 46</em>: 35-57.</small></p>\n<p><small>Wiederman (1993). Evolved gender differences in mate preferences: Evidence from personal advertisements. <em>Ethology and Sociobiology, 14</em>: 331-352.</small></p>\n<p><small>Wiessner (2002). Hunting, healing, and <em>hzaro</em>&nbsp;exchange: A long-term perspective on !Kung large-game hunting. <em>Evolution and Human Behavior, 20</em>: 121-128.</small></p>\n<p><small>Workman &amp; Reader (2008). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-Introduction-Lance-Workman/dp/0521888360/\">Evolutionary Psychology: An Introduction</a></em>&nbsp;(2nd ed.). Cambridge University Press.</small></p>", "sections": [{"title": "Evolutionary psychology", "anchor": "Evolutionary_psychology", "level": 1}, {"title": "Kin loyalty", "anchor": "Kin_loyalty", "level": 1}, {"title": "Essentialism", "anchor": "Essentialism", "level": 1}, {"title": "Heuristics and biases", "anchor": "Heuristics_and_biases", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "106 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 106, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["du395YvCnQXBPSJax", "pL3To6G42AeihNtaN", "6Cc3TWZjAnrNWokWY", "4MpodyRwdYXEeC3jn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-05T16:29:09.944Z", "modifiedAt": null, "url": null, "title": "GiveWell.org interviews SIAI", "slug": "givewell-org-interviews-siai", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.867Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EyFNgmgkB6rZcgNrv/givewell-org-interviews-siai", "pageUrlRelative": "/posts/EyFNgmgkB6rZcgNrv/givewell-org-interviews-siai", "linkUrl": "https://www.lesswrong.com/posts/EyFNgmgkB6rZcgNrv/givewell-org-interviews-siai", "postedAtFormatted": "Thursday, May 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20GiveWell.org%20interviews%20SIAI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGiveWell.org%20interviews%20SIAI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEyFNgmgkB6rZcgNrv%2Fgivewell-org-interviews-siai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=GiveWell.org%20interviews%20SIAI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEyFNgmgkB6rZcgNrv%2Fgivewell-org-interviews-siai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEyFNgmgkB6rZcgNrv%2Fgivewell-org-interviews-siai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 134, "htmlBody": "<p>Holden Karnofsky of <a href=\"http://www.givewell.org/\">GiveWell.org</a> interviewed Jasen Murray of <a href=\"http://intelligence.org/\">SIAI</a> and <a href=\"http://groups.yahoo.com/group/givewell/message/270\">published his notes</a>&nbsp;(Edit: <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/siai-2011-02-III.pdf\">PDF</a>, thanks lukeprog!), with updates from later conversations. Lots of stuff to take an interest in there - thanks to jsalvatier for <a href=\"/lw/5il/siai_an_examination/43dy\">drawing our attention to it</a>. One new bit of information stands out in particular:</p>\n<ul>\n<li>Michael Vassar is working on an idea he calls the \"Persistent Problems Group\" or PPG. The idea is to assemble a blue-ribbon panel of recognizable experts to make sense of the academic literature on very applicable, popular, but poorly understood topics such as diet/nutrition. This would have obvious benefits for helping people understand what the literature has and hasn't established on important topics; it would also be a demonstration that there is such a thing as \"skill at making sense of the world.\"</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NrvXXL3iGjjxu5B7d": 1, "xEZwTHPd5AWpgQx9w": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EyFNgmgkB6rZcgNrv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 38, "extendedScore": null, "score": 7.10881151831846e-07, "legacy": true, "legacyId": "7205", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T00:03:33.422Z", "modifiedAt": null, "url": null, "title": "Helsinki meetup on May 13, special guest star Patri Friedman (patrissimo)", "slug": "helsinki-meetup-on-may-13-special-guest-star-patri-friedman", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.046Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JM5Z7H9WPXuPnhL55/helsinki-meetup-on-may-13-special-guest-star-patri-friedman", "pageUrlRelative": "/posts/JM5Z7H9WPXuPnhL55/helsinki-meetup-on-may-13-special-guest-star-patri-friedman", "linkUrl": "https://www.lesswrong.com/posts/JM5Z7H9WPXuPnhL55/helsinki-meetup-on-may-13-special-guest-star-patri-friedman", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Helsinki%20meetup%20on%20May%2013%2C%20special%20guest%20star%20Patri%20Friedman%20(patrissimo)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelsinki%20meetup%20on%20May%2013%2C%20special%20guest%20star%20Patri%20Friedman%20(patrissimo)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJM5Z7H9WPXuPnhL55%2Fhelsinki-meetup-on-may-13-special-guest-star-patri-friedman%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Helsinki%20meetup%20on%20May%2013%2C%20special%20guest%20star%20Patri%20Friedman%20(patrissimo)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJM5Z7H9WPXuPnhL55%2Fhelsinki-meetup-on-may-13-special-guest-star-patri-friedman", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJM5Z7H9WPXuPnhL55%2Fhelsinki-meetup-on-may-13-special-guest-star-patri-friedman", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<p><a id=\"more\"></a></p>\r\n<p><strong>Where:&nbsp;</strong>Caf&eacute; Picnic, Yliopistonkatu 5</p>\r\n<p><strong>When: </strong>Friday May 13th, 3 PM.</p>\r\n<p>Less Wrong poster Patri Friedman (<a href=\"/user/patrissimo\">patrissimo</a>) is coming to Helsinki on the 13th to <a href=\"https://www.facebook.com/event.php?eid=110927132325345\">talk about the Seasteading Institute's work</a>. We're holding a meetup on that day, where he'll be attending.</p>\r\n<p>In all likelyhood, I'll unfortunately be unable to attend myself. However, at least <a href=\"/user/Bongo\">Bongo</a> has promised to attend no matter what, so at least he and Patri will be there.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JM5Z7H9WPXuPnhL55", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "7208", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T03:53:01.128Z", "modifiedAt": null, "url": null, "title": "[Altruist Support] The Plan", "slug": "altruist-support-the-plan", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:30.606Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Giles", "createdAt": "2011-02-11T02:30:16.999Z", "isAdmin": false, "displayName": "Giles"}, "userId": "H347ba3KZMP8XoDt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Aq8sxHhqm8YeT8jQ6/altruist-support-the-plan", "pageUrlRelative": "/posts/Aq8sxHhqm8YeT8jQ6/altruist-support-the-plan", "linkUrl": "https://www.lesswrong.com/posts/Aq8sxHhqm8YeT8jQ6/altruist-support-the-plan", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BAltruist%20Support%5D%20The%20Plan&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BAltruist%20Support%5D%20The%20Plan%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAq8sxHhqm8YeT8jQ6%2Faltruist-support-the-plan%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BAltruist%20Support%5D%20The%20Plan%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAq8sxHhqm8YeT8jQ6%2Faltruist-support-the-plan", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAq8sxHhqm8YeT8jQ6%2Faltruist-support-the-plan", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 786, "htmlBody": "<p>Here's my plan.</p>\n<p>I intend to build a community of <em>aspiring rational leaders</em>. I see three components to this:</p>\n<p><strong>A. Becoming more rational</strong></p>\n<p><img src=\"http://images.lesswrong.com/t3_5kc_0.png\" alt=\"Becoming more rational: bringing together the spheres of self-identity, rationality and the human\" width=\"681\" height=\"311\" /></p>\n<p>I see this as being about bringing together the spheres of self-identity, rationality and the human. The human is your physical body and brain; it is the human which actually does things, and if the human isn't on board nothing will happen. Instrumental rationality is the art of achieving your goals; it should be a familiar concept to Less Wrong readers. And self-identity, among other things, is about having those goals in the first place.</p>\n<p>The spheres will never align entirely, and it is important to recognise that we are only <em>aspiring</em> rationalists, and to recognize and work around our weaknesses when they can't be easily fixed.</p>\n<p>You don't have to lead other people to be a rational leader; you might only be leading yourself. But there's no reason to be afraid of it. I see true rationalists as making good leaders.</p>\n<p><strong>B. People stuff</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_1.png\" alt=\"People stuff: interacting with people\" width=\"223\" height=\"213\" /><br /></strong></p>\n<p>In order to achieve your goals, it is likely you will need to interact with other people; to lead them, influence them, cooperate with them. You will also need to influence <em>yourself</em>; learn how to <a href=\"/lw/2dg/applying_behavioral_psychology_on_myself/\">make yourself more effective</a>. You may even need to go beyond basic individual interaction and deal with the issue of <em>why people are the way they are.</em></p>\n<p>This is something I believe may be a problem in the LW community: Not doing the <a href=\"http://www.fanfiction.net/s/5782108/24/Harry_Potter_and_the_Methods_of_Rationality\">people stuff.</a></p>\n<p><strong>C. Doing good</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_2.png\" alt=\"Doing Good\" width=\"252\" height=\"400\" /><br /></strong></p>\n<p>To give us a common goal, I want to find people who are interested in doing good. It doesn't have to be your only goal, and your definition of doing good doesn't have to be exactly the same as mine or anyone else's. It'll still be enough that we should co-operate.</p>\n<p>If I could find such people, and if we could train ourselves and each other into being really effective, what would I see this organization doing?</p>\n<p><strong>1. Welcome</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_3.png\" alt=\"Welcoming people into the community\" width=\"316\" height=\"295\" /><br /></strong></p>\n<p>I would see us reaching out to altruistic individuals and organizations; finding people who are confused, who need help or who are still looking for the right approach. The idea is not to turn them all into rationalists, but rather to use our own rational skills to help and guide them. I would see this as our public face: the Altruist Support Network.</p>\n<p><strong>2. Think</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_4.png\" alt=\"Some brains thinking\" width=\"263\" height=\"277\" /><br /></strong></p>\n<p>Making a real positive difference in the world is <em>hard</em>. Even if you're motivated to do it, the infrastructure just isn't there to enable it. So we're going to need a lot of ideas, and ways to evaluate them. I feel certain that there are levers we can pull; small changes we can make that will have huge impacts, and that we can use rationality to help us find them. But I'll need your help.</p>\n<p><strong>3. Research</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_5.png\" alt=\"Research: a person with a book\" width=\"356\" height=\"243\" /><br /></strong></p>\n<p>Some of the thinking has been done for us: there are papers and books already written, there are communities already out there. We need to find them - we need to create a good map of the rational-doing-good landscape. And then we need to push the boundaries, to create new knowledge.</p>\n<p><strong>4. Fund</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_6.png\" alt=\"Funding: it all ultimately comes down to money\" width=\"192\" height=\"231\" /><br /></strong></p>\n<p>If we have money, we want to <a href=\"/lw/65/money_the_unit_of_caring/\">spend it</a> as wisely as we can: on organizations who share our goals and who have proven themselves to be among the most effective out there. Maybe we can tempt organizations into making changes with the prospect of a donation. And, very likely, we'll need to make money ourselves: to start a business and run it rationally, making a lot of profit and giving it to the causes we support. Such an endeavour sounds very difficult but worthwhile.</p>\n<p><strong>5. Act</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_7.png\" alt=\"Act: a person escapes from the swivel chair of inaction\" width=\"232\" height=\"325\" /><br /></strong></p>\n<p>Sometimes you just need to get out there and do things. Right now I don't know what; but this organization will not be an ivory tower. It exists to serve a purpose - making the world a better place - and we'll do what we need to in order to make that happen.</p>\n<p>I apologize that my previous posts may have seemed a bit directionless. I hope this clears it up a little; I'm planning that my next bunch of posts will be sequence-style, gradually building up the ideas I've been having from foundations that are familiar.</p>\n<p>The main things I want to know:</p>\n<ul>\n<li>Whether people see such an organization working</li>\n<li>Whether they see it as fundamentally different from anything which currently exists</li>\n<li>Whether they would want to be a part of it.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Aq8sxHhqm8YeT8jQ6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 13, "extendedScore": null, "score": 7.110776103914435e-07, "legacy": true, "legacyId": "7212", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Here's my plan.</p>\n<p>I intend to build a community of <em>aspiring rational leaders</em>. I see three components to this:</p>\n<p><strong id=\"A__Becoming_more_rational\">A. Becoming more rational</strong></p>\n<p><img src=\"http://images.lesswrong.com/t3_5kc_0.png\" alt=\"Becoming more rational: bringing together the spheres of self-identity, rationality and the human\" width=\"681\" height=\"311\"></p>\n<p>I see this as being about bringing together the spheres of self-identity, rationality and the human. The human is your physical body and brain; it is the human which actually does things, and if the human isn't on board nothing will happen. Instrumental rationality is the art of achieving your goals; it should be a familiar concept to Less Wrong readers. And self-identity, among other things, is about having those goals in the first place.</p>\n<p>The spheres will never align entirely, and it is important to recognise that we are only <em>aspiring</em> rationalists, and to recognize and work around our weaknesses when they can't be easily fixed.</p>\n<p>You don't have to lead other people to be a rational leader; you might only be leading yourself. But there's no reason to be afraid of it. I see true rationalists as making good leaders.</p>\n<p><strong id=\"B__People_stuff\">B. People stuff</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_1.png\" alt=\"People stuff: interacting with people\" width=\"223\" height=\"213\"><br></strong></p>\n<p>In order to achieve your goals, it is likely you will need to interact with other people; to lead them, influence them, cooperate with them. You will also need to influence <em>yourself</em>; learn how to <a href=\"/lw/2dg/applying_behavioral_psychology_on_myself/\">make yourself more effective</a>. You may even need to go beyond basic individual interaction and deal with the issue of <em>why people are the way they are.</em></p>\n<p>This is something I believe may be a problem in the LW community: Not doing the <a href=\"http://www.fanfiction.net/s/5782108/24/Harry_Potter_and_the_Methods_of_Rationality\">people stuff.</a></p>\n<p><strong id=\"C__Doing_good\">C. Doing good</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_2.png\" alt=\"Doing Good\" width=\"252\" height=\"400\"><br></strong></p>\n<p>To give us a common goal, I want to find people who are interested in doing good. It doesn't have to be your only goal, and your definition of doing good doesn't have to be exactly the same as mine or anyone else's. It'll still be enough that we should co-operate.</p>\n<p>If I could find such people, and if we could train ourselves and each other into being really effective, what would I see this organization doing?</p>\n<p><strong id=\"1__Welcome\">1. Welcome</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_3.png\" alt=\"Welcoming people into the community\" width=\"316\" height=\"295\"><br></strong></p>\n<p>I would see us reaching out to altruistic individuals and organizations; finding people who are confused, who need help or who are still looking for the right approach. The idea is not to turn them all into rationalists, but rather to use our own rational skills to help and guide them. I would see this as our public face: the Altruist Support Network.</p>\n<p><strong id=\"2__Think\">2. Think</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_4.png\" alt=\"Some brains thinking\" width=\"263\" height=\"277\"><br></strong></p>\n<p>Making a real positive difference in the world is <em>hard</em>. Even if you're motivated to do it, the infrastructure just isn't there to enable it. So we're going to need a lot of ideas, and ways to evaluate them. I feel certain that there are levers we can pull; small changes we can make that will have huge impacts, and that we can use rationality to help us find them. But I'll need your help.</p>\n<p><strong id=\"3__Research\">3. Research</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_5.png\" alt=\"Research: a person with a book\" width=\"356\" height=\"243\"><br></strong></p>\n<p>Some of the thinking has been done for us: there are papers and books already written, there are communities already out there. We need to find them - we need to create a good map of the rational-doing-good landscape. And then we need to push the boundaries, to create new knowledge.</p>\n<p><strong id=\"4__Fund\">4. Fund</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_6.png\" alt=\"Funding: it all ultimately comes down to money\" width=\"192\" height=\"231\"><br></strong></p>\n<p>If we have money, we want to <a href=\"/lw/65/money_the_unit_of_caring/\">spend it</a> as wisely as we can: on organizations who share our goals and who have proven themselves to be among the most effective out there. Maybe we can tempt organizations into making changes with the prospect of a donation. And, very likely, we'll need to make money ourselves: to start a business and run it rationally, making a lot of profit and giving it to the causes we support. Such an endeavour sounds very difficult but worthwhile.</p>\n<p><strong id=\"5__Act\">5. Act</strong></p>\n<p><strong><img src=\"http://images.lesswrong.com/t3_5kc_7.png\" alt=\"Act: a person escapes from the swivel chair of inaction\" width=\"232\" height=\"325\"><br></strong></p>\n<p>Sometimes you just need to get out there and do things. Right now I don't know what; but this organization will not be an ivory tower. It exists to serve a purpose - making the world a better place - and we'll do what we need to in order to make that happen.</p>\n<p>I apologize that my previous posts may have seemed a bit directionless. I hope this clears it up a little; I'm planning that my next bunch of posts will be sequence-style, gradually building up the ideas I've been having from foundations that are familiar.</p>\n<p>The main things I want to know:</p>\n<ul>\n<li>Whether people see such an organization working</li>\n<li>Whether they see it as fundamentally different from anything which currently exists</li>\n<li>Whether they would want to be a part of it.</li>\n</ul>", "sections": [{"title": "A. Becoming more rational", "anchor": "A__Becoming_more_rational", "level": 1}, {"title": "B. People stuff", "anchor": "B__People_stuff", "level": 1}, {"title": "C. Doing good", "anchor": "C__Doing_good", "level": 1}, {"title": "1. Welcome", "anchor": "1__Welcome", "level": 1}, {"title": "2. Think", "anchor": "2__Think", "level": 1}, {"title": "3. Research", "anchor": "3__Research", "level": 1}, {"title": "4. Fund", "anchor": "4__Fund", "level": 1}, {"title": "5. Act", "anchor": "5__Act", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "24 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EJuZcWnk8j7eNQPqq", "ZpDnRCeef2CLEFeKM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T03:56:55.132Z", "modifiedAt": null, "url": null, "title": "Leadership and Self Deception, Anatomy of Peace", "slug": "leadership-and-self-deception-anatomy-of-peace", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:27.995Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TimFreeman", "createdAt": "2011-04-12T22:58:16.873Z", "isAdmin": false, "displayName": "TimFreeman"}, "userId": "AAP7Amn8h8BhWCjjC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rK5pbJG3StktPbozu/leadership-and-self-deception-anatomy-of-peace", "pageUrlRelative": "/posts/rK5pbJG3StktPbozu/leadership-and-self-deception-anatomy-of-peace", "linkUrl": "https://www.lesswrong.com/posts/rK5pbJG3StktPbozu/leadership-and-self-deception-anatomy-of-peace", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Leadership%20and%20Self%20Deception%2C%20Anatomy%20of%20Peace&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALeadership%20and%20Self%20Deception%2C%20Anatomy%20of%20Peace%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrK5pbJG3StktPbozu%2Fleadership-and-self-deception-anatomy-of-peace%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Leadership%20and%20Self%20Deception%2C%20Anatomy%20of%20Peace%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrK5pbJG3StktPbozu%2Fleadership-and-self-deception-anatomy-of-peace", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrK5pbJG3StktPbozu%2Fleadership-and-self-deception-anatomy-of-peace", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2071, "htmlBody": "<p>I highly recommend reading Leadership and Self Deception (Henceforth \"L&amp;SD\") by the Arbinger Institute (<a href=\"http://www.amazon.com/Leadership-Self-Deception-Getting-Out/dp/1576751740\">Amazon</a>, <a href=\"http://search.barnesandnoble.com/books/product.aspx?r=1&amp;isbn=9781576755020&amp;cm_mmc=Google%20Product%20Search-_-Q000000630-_-Leadership%20and%20Self%20Deception-_-9781576755020\">Barnes and Noble</a>, <a href=\"http://books.google.com/books?id=tfCBEgKX6DEC&amp;dq=Leadership+and+Self+Deception&amp;printsec=frontcover&amp;source=bn&amp;hl=en&amp;ei=uJJiTLiOF5K8sQOsg7CHCA&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=6&amp;ved=0CDcQ6AEwBQ#v=onepage&amp;q&amp;f=false\">Google Books</a>, <a href=\"http://www.arbinger.com/en/home.html\">Arbinger Institute Home Page</a>). The sequel, Anatomy of Peace, is also good, but this article is based on a reading of L&amp;SD.</p>\n<p>They give a simple model of one cause of some or most everyday subtle neurotic behavior, and have practical suggestions for dealing with it. They present this indirectly, as a first-person narrative from a new executive at a fictional company is being taught this by his managers. The book has its good and bad points, with the good points hugely outweighing the bad. This post contains:</p>\n<ul>\n<li>a summary of what's good and bad about the book, without spoilers; </li>\n<li>a description of the main points of the book, which may or may not prevent people from actually understanding and using that information; </li>\n<li>a list of some unanswered questions I had when I finished reading the book; and </li>\n<li>some additional plausible assertions that, if true, would clarify the answers to those questions. </li>\n</ul>\n<p>A prominent problem with many groups of highly intelligent people is that high intelligence makes it possible to deceive oneself more effectively, so they have pointless social conflict. I hope this model is good enough to help intelligent people identify the tendency to self decieve in social contexts and at least partially compensate for it. <a id=\"more\"></a></p>\n<p>One good point is that, after understanding the material, you can look around you and see the self-deception happening, you can stop doing it yourself somewhat, and you can have ideas about what to do about it when you see it in others.</p>\n<p>Another good point is that the indirect approach seems to be useful. Presenting the material directly doesn't always work. Sometimes a direct presentation leads to people responding from within the self deception without seeing it.</p>\n<p>A bad point is that they don't say why this happens. You'd expect that something many people appear to do instinctively to have some function, rather than to be broken. I think I do understand why, and in the text after the break below I expand slightly upon their model. This added information explains what sort of self-deceptions people tend to adopt, and what sorts of systematic errors people make they're in the self-deceived mode.</p>\n<p>Another bad point is that they don't support their conclusion with research. It seems like the sort of thing that could be supported with research. Perhaps they chose not to cite research because footnotes would interfere with their indirect approach and might make it less effective. They could solve this problem by publishing another book that presents the same material directly and cites psychology research, but they apparently have not done that.</p>\n<p>They are making a statement that seems to be obviously true, once you've understood it. The statement concerns everyday experience, so maybe research is redundant. For example, it is obvious that there were some apples in my refrigerator last night, even though there are no peer-reviewed double-blind research studies published in reputable journals about the apples in my refrigerator. I'd like to see someone do or cite relevant research for the assertions in the book, but maybe we don't have to wait. Caveat emptor.</p>\n<p>The text below presents some of their material directly. I don't have enough experience to know how often it works to get the material directly. I recommend that if you trust me, go read \"Leadership and Self Deception\" now before continuing reading this text. If you don't trust me enough for that, perhaps you should continue reading below and take your chances.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>(Whitespace so people's eyes don't read more than they intend.)</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Here's a brief summary of some of the claims in Leadership and Self Deception. The book fleshes them out and gives lots of examples, but perhaps this bare outline will suffice for this discussion:</p>\n<ul>\n<li>When person X interacts with person Y, X can think of Y's desires as being legitimate, or not. </li>\n<li>X will tend to shift from regarding Y's desires as legitimate to regarding Y's desires as illegitimate when X feels uncomfortable with cooperating with Y's desires. </li>\n<li>If X regards Y's desires as illegitimate, and X interacts with Y, thinks about Y, or talks about Y with other people, X's real purpose will often be to justify some simple statement about the relationship between X and Y. X will generally be deceived about X's true purpose in these interactions. </li>\n<li>If X regards Y's desires as illegitimate, then X's behavior will tend to result in Y regarding X's desires as illegitimate, so the whole thing tends to perpetuate itself. </li>\n</ul>\n<p>For example, imagine a young child (\"X\") who often demands help from his mother (\"Y\") for tasks he could probably do himself. When Y says X should do it himself, X often says \"I can't\" and then offers rationalizations for that statement. Note that X knows he can probably do it, and Y knows he can probably do it. X's intuitive calculation is: if I attempt to do it myself, I might fail, which would decrease my social status, or I might succeed, which leaves my social status unchanged. If I get Mommy to help me, then I'm controlling Mommy's behavior, which increases my social status. I can get Mommy to help me by claiming I can't do it, so I'll try to justify the assertion \"I can't do it\".</p>\n<p>If you don't see this happening a large fraction of the time in both yourself and other people, something is wrong. Either you're denying it because you're operating from inside the self-deception and trying to justify some statement about yourself that conflicts with the main claims, or I'm asserting that it's true because I'm seriously confused. If you think I'm seriously confused, please comment and try to straighten me out.</p>\n<p>It's important to keep in mind that the fix proposed in L&amp;SD is not to carefully analyze people's behavior and root out the self-justification. Instead, L&amp;SD suggests being sure to regard oneself and others as people with legitimate desires.</p>\n<p>In any case, the analysis below assumes that the main claims are true. If you don't believe that, you might as well stop reading now.</p>\n<p>The unanswered questions I had when I finished reading the book were:</p>\n<ul>\n<li>What sorts of simple statements will people try to justify? It's obvious that they all have the same flavor, but it's less obvious what they have in common or why they have that in common. </li>\n<li>Why do people systematically hold these specific false beliefs about their own motivations, even when they're thinking inside their own mind? Wouldn't it be more useful to have true beliefs when thinking in private? </li>\n<li>Why is this self-justification harmful? For example, if someone is at work and trying to justify \"I work effectively for my employer\", why is that a problem? </li>\n</ul>\n<p>I propose the following more detailed model that predicts answers to these questions.</p>\n<p>The likely goals a person X will have when interacting with a person Y fall into a few broad categories:</p>\n<ul>\n<li>X can be trying to cooperate with Y for some shared purpose. X does not benefit from deceiving himself about Y's desires in this case. </li>\n<li>X can be competing with Y. X could be mugging Y, for example. X does not benefit from deceiving himself about Y's desires in this case, either -- X benefits from understanding Y's desires because that helps X to predict Y's behavior and compete more effectively. </li>\n<li>The last option is that X is interacting with Y for the purpose of getting X's peers to have some belief chosen by X. These interactions, and rehearsal for these interactions, is the \"justification\" discussed in L&amp;SD. </li>\n</ul>\n<p>There are several ways X's peers might acquire a belief about X and Y:</p>\n<ul>\n<li>X can convince Y that the belief is true, since Y is one of X's peers. </li>\n<li>X can interact with Y in a way that would convince an onlooker Z that the belief is true. </li>\n<li>X can tell Z about the belief directly. </li>\n<li>After X convinces Z that the belief is true, Z might tell another person W that the belief is true. </li>\n</ul>\n<p>In general, more than one of these will happen.</p>\n<p>There are a few reasonable assertions not present in L&amp;SD that allow us to make more predictions here:</p>\n<ul>\n<li>When choosing the belief B to propagate, X will tend to intuitively choose a belief that will propagate well. X intuitively anticipates that the onlooker Z is not likely to be paying much attention. The belief therefore has to be simple and emotionally compelling enough for Z to attend to it, and it has to appear plausible to Z. </li>\n<li>X will generally choose the belief in order to improve his social status or display his membership in a social group. </li>\n<li>X has to pick some consistent set of beliefs to propagate. X will not benefit from convincing Z that B is true and convincing W that B is false if Z later compares notes with W. </li>\n</ul>\n<p>This gives us answers to the questions listed above:</p>\n<dl> <dt>Q:</dt><dd> What sorts of simple statements will people try to justify? </dd><dt>A:</dt><dd> People will attempt to justify statements that increase their social status, demonstrate their membership in a particular group, or demonstrate fitness. The intended audience of a fitness demonstration may be potential sexual partners, competitors (to discourage them), or people they wish to cooperate with. People will only try to justify statements that are believable by third parties. (For more on beliefs as demonstration of membership in a social group, see http://hanson.gmu.edu/belieflikeclothes.html) </dd><dt>Q:</dt><dd> Why do people systematically hold these specific false beliefs about their own motivations, even when they're thinking inside their own mind? Wouldn't it be more useful to have true beliefs when thinking in private? </dd><dt>A:</dt><dd> Internal dialogue is rehearsal for future social interactions. X will tell himself that B is true so he can consistently advocate B in all social contexts. </dd><dt>Q:</dt><dd> Why is this self-justification harmful? </dd><dt>A:</dt><dd> If X interacts with Y for the purpose of demonstrating a belief B to Z, that's harmful because B can only be demonstrated to Z if B is simple enough to communicate to Z and B is emotionally compelling enough for Z to listen. X has to invent simple and dramatic beliefs to propagate, and the easiest way to propagate beliefs is to believe them and act consistently with them. This holds even when X's beliefs are not the best explanation of X's observations. Furthermore, if X is justifying a belief to others, X only has an incentive to act on that belief when other people are paying attention.\n<p>For example, the difference between X trying to work effectively for his employer and X trying to justify \"I am working effectively for my employer\" is that in the latter case, X will take action to benefit his employer only when those actions can be observed by third parties, those actions are interesting enough for the third parties to remember them, and the actions will be understood by third parties as benefiting his employer.</p>\n</dd><dt>Q:</dt><dd> When is self-justification useful? </dd><dt>A:</dt><dd> In the same circumstances where propagating a simple belief is useful. Some sample beliefs are: \"I pay my taxes\", \"I keep my promises\", \"I am a civilized person\". Politeness and etiquette are almost entirely self-justification, and they are useful in the case where two people are interacting and haven't yet had time to develop a personal relationship.\n<p>Keep in mind that a simple belief is different from a simple plan. A belief is a statement about the present situation in the world that is true or false; a plan is a statement about your future behavior. Simple plans are useful because they can be made into habits. Habits can be useful because habits make it possible to do useful things with expending willpower, and each person has a limited supply of willpower.</p>\n</dd><dt>Q:</dt><dd> Why are people suggestible? </dd><dt>A:</dt><dd> To the extent that people believe things for the purpose of convincing others that the belief is true, it's rational to be suggestible. If X communicates with Y, and Y has belief B, and X knows that Y has belief B, then X knows that B is something that can easily be believed by others and perhaps (not B) is not believable, so it makes sense for X to act consistently with B, and the easiest way to do that is to believe B. </dd></dl>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rK5pbJG3StktPbozu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 15, "extendedScore": null, "score": 7.1107873108087e-07, "legacy": true, "legacyId": "7211", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T06:19:21.259Z", "modifiedAt": null, "url": null, "title": "Climate change: existential risk?", "slug": "climate-change-existential-risk", "viewCount": null, "lastCommentedAt": "2019-05-21T08:11:19.419Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "katydee", "createdAt": "2010-07-09T10:33:52.237Z", "isAdmin": false, "displayName": "katydee"}, "userId": "uHpk5J2f7BPBoiJFX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8qekt2Hn3PFysK6aL/climate-change-existential-risk", "pageUrlRelative": "/posts/8qekt2Hn3PFysK6aL/climate-change-existential-risk", "linkUrl": "https://www.lesswrong.com/posts/8qekt2Hn3PFysK6aL/climate-change-existential-risk", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Climate%20change%3A%20existential%20risk%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AClimate%20change%3A%20existential%20risk%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qekt2Hn3PFysK6aL%2Fclimate-change-existential-risk%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Climate%20change%3A%20existential%20risk%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qekt2Hn3PFysK6aL%2Fclimate-change-existential-risk", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qekt2Hn3PFysK6aL%2Fclimate-change-existential-risk", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 130, "htmlBody": "<p>What does the community here think when it comes to climate change as a potential existential risk? While strategies for combating climate change are fairly straightforward, the seeming lack of political capital behind meaningful climate reform and legislation seems to indicate that the problem is going to get substantially worse before it gets better, and the potential consequences of ignoring this issue look to be <a href=\"http://climateprogress.org/2010/11/29/royal-society-special-issue-4-degrees-world/\">quite severe indeed</a>!</p>\n<p>Should the rationality/x-risks community be spending more effort on evaluating this idea and exploring potential solutions? It certainly seems like a big problem, and the current trajectory is quite worrisome. On the other hand, the issue is a political minefield and could risk entangling the community in political squabbling, potentially jeopardizing its ability to act on other threats. What do you guys think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Rz5jb3cYHTSRmqNnN": 2, "frcrRgCk9PDbEScua": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8qekt2Hn3PFysK6aL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 8, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "7214", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T10:59:57.705Z", "modifiedAt": null, "url": null, "title": "Requesting Advice", "slug": "requesting-advice", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.012Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Carinthium", "createdAt": "2010-11-10T22:28:58.091Z", "isAdmin": false, "displayName": "Carinthium"}, "userId": "DL8CRWfXPCHYqQsv4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GmhpgKj7GshasB7aa/requesting-advice", "pageUrlRelative": "/posts/GmhpgKj7GshasB7aa/requesting-advice", "linkUrl": "https://www.lesswrong.com/posts/GmhpgKj7GshasB7aa/requesting-advice", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Requesting%20Advice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARequesting%20Advice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGmhpgKj7GshasB7aa%2Frequesting-advice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Requesting%20Advice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGmhpgKj7GshasB7aa%2Frequesting-advice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGmhpgKj7GshasB7aa%2Frequesting-advice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<p>I'm somewhat reluctant to talk about my personal life online nowadays, but suffice to say that I've discovered an area of likely self-delusion and I want to prevent myself from backsliding through forgetting what I've learned. Any ways to make sure the knowledge stays in my head?</p>\r\n<p>(And yes, writing&nbsp;this post will likely help- I'm not stupid)&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GmhpgKj7GshasB7aa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 7.112003120095001e-07, "legacy": true, "legacyId": "7219", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T14:13:28.734Z", "modifiedAt": null, "url": null, "title": "Extreme Altruistic Personality Type", "slug": "extreme-altruistic-personality-type", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Wx9GEJAoxpnptHvt7/extreme-altruistic-personality-type", "pageUrlRelative": "/posts/Wx9GEJAoxpnptHvt7/extreme-altruistic-personality-type", "linkUrl": "https://www.lesswrong.com/posts/Wx9GEJAoxpnptHvt7/extreme-altruistic-personality-type", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Extreme%20Altruistic%20Personality%20Type&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExtreme%20Altruistic%20Personality%20Type%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWx9GEJAoxpnptHvt7%2Fextreme-altruistic-personality-type%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Extreme%20Altruistic%20Personality%20Type%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWx9GEJAoxpnptHvt7%2Fextreme-altruistic-personality-type", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWx9GEJAoxpnptHvt7%2Fextreme-altruistic-personality-type", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.science20.com/rogue_neuron/addicted_being_good_psychopathology_heroism-60137</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Wx9GEJAoxpnptHvt7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "7221", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T18:10:45.329Z", "modifiedAt": null, "url": null, "title": "Experiment Idea Thread  - Spring 2011", "slug": "experiment-idea-thread-spring-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:54.969Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psychohistorian", "createdAt": "2009-04-05T18:10:22.976Z", "isAdmin": false, "displayName": "Psychohistorian"}, "userId": "mAQgf4N8jv2jTMK5B", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2WsLgGKEDkoBQ9Q7f/experiment-idea-thread-spring-2011", "pageUrlRelative": "/posts/2WsLgGKEDkoBQ9Q7f/experiment-idea-thread-spring-2011", "linkUrl": "https://www.lesswrong.com/posts/2WsLgGKEDkoBQ9Q7f/experiment-idea-thread-spring-2011", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Experiment%20Idea%20Thread%20%20-%20Spring%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExperiment%20Idea%20Thread%20%20-%20Spring%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2WsLgGKEDkoBQ9Q7f%2Fexperiment-idea-thread-spring-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Experiment%20Idea%20Thread%20%20-%20Spring%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2WsLgGKEDkoBQ9Q7f%2Fexperiment-idea-thread-spring-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2WsLgGKEDkoBQ9Q7f%2Fexperiment-idea-thread-spring-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 331, "htmlBody": "<p>This is an idea that just occurred to me. We have a large community of people who think about scientific problems recreationally, many of whom are in no position to go around investigating them. Hopefully, however, some other community members <em>are</em>&nbsp;in a position to go around investigating them, or know people who are. The idea here is to allow people to propose relatively specific ideas for experiments, which can be upvoted if people think they are wise, and can be commented on and refined by others. Grouping them together in an easily identifiable, organized way in which people can provide approval and suggestions seems like it may actually help advance human knowledge, and with its high sanity waterline and (kind of) diverse group of readers, this community seems like an excellent place to implement this idea.</p>\n<p>These should be relatively practical, with an eye towards providing some aspiring grad student or professor with enough of an idea that they could go implement it. You should explain the general field (physics, AI, evolutionary psychology, economics, psychology, etc.) as well as the question the experiment is designed to investigate, in as much detail as you are reasonably capable of.</p>\n<p>If this is a popular idea, a new thread can be started every time one of these reaches 500 comments, or quarterly, depending on its popularity. I expect this to provide help for people refining their understanding of various sciences, and if it ever gets turned into even a few good experiments, it will prove immensely worthwhile.</p>\n<p>I think it's best to make these distinct from the general discussion thread because they have a very narrow purpose. I'll post an idea or two of my own to get things started. I'd also encourage people to post not only experiment ideas, but criticism and suggestions regarding this thread concept. I'd also suggest that people upvote or downvote this post if they think this is a good or bad idea, to better establish whether future implementations will be worthwhile.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1, "tk4R4LrX88gmFeMmY": 1, "AodfCFefLAuwDyj7Z": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2WsLgGKEDkoBQ9Q7f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 35, "extendedScore": null, "score": 7.113241583679757e-07, "legacy": true, "legacyId": "7225", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T18:17:58.381Z", "modifiedAt": null, "url": null, "title": "Why is my sister related to me only 50%?", "slug": "why-is-my-sister-related-to-me-only-50", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.110Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TimFreeman", "createdAt": "2011-04-12T22:58:16.873Z", "isAdmin": false, "displayName": "TimFreeman"}, "userId": "AAP7Amn8h8BhWCjjC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ocKkSYxwABR6iLpE8/why-is-my-sister-related-to-me-only-50", "pageUrlRelative": "/posts/ocKkSYxwABR6iLpE8/why-is-my-sister-related-to-me-only-50", "linkUrl": "https://www.lesswrong.com/posts/ocKkSYxwABR6iLpE8/why-is-my-sister-related-to-me-only-50", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20is%20my%20sister%20related%20to%20me%20only%2050%25%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20is%20my%20sister%20related%20to%20me%20only%2050%25%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FocKkSYxwABR6iLpE8%2Fwhy-is-my-sister-related-to-me-only-50%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20is%20my%20sister%20related%20to%20me%20only%2050%25%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FocKkSYxwABR6iLpE8%2Fwhy-is-my-sister-related-to-me-only-50", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FocKkSYxwABR6iLpE8%2Fwhy-is-my-sister-related-to-me-only-50", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<p>The standard story when dealing with inclusive fitness in evolutionary arguments is that my sibling's life is worth half of mine and my cousin's life is worth a quarter of mine.</p>\n<p>But I obviously share more than half my genes with my sister because my parents are not unrelated.&nbsp; My parents must share a lot of ancestors enough generations back that nobody has tracked them, since they resemble each other insofar as they both look human.&nbsp; If I take into account that my parents are both human, I should be related to my sister much more than 50%.</p>\n<p>So why do they assume a sibling has half your genes when reasoning about inclusive fitness?</p>\n<p>My wife is Chinese, and both of my parents are of European descent.&nbsp; Should I expect my kids to like each other less than I like my sister, because they are less closely related?&nbsp;</p>\n<p>This is an intellectual question about evolutionary psychology, not an anxious question about my family relationships.&nbsp; We're all doing fine, don't worry.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ocKkSYxwABR6iLpE8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 3, "extendedScore": null, "score": 7.113262336100935e-07, "legacy": true, "legacyId": "7226", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T18:47:19.921Z", "modifiedAt": null, "url": null, "title": "Intuition and Unconscious Learning", "slug": "intuition-and-unconscious-learning", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.725Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6Cc3TWZjAnrNWokWY/intuition-and-unconscious-learning", "pageUrlRelative": "/posts/6Cc3TWZjAnrNWokWY/intuition-and-unconscious-learning", "linkUrl": "https://www.lesswrong.com/posts/6Cc3TWZjAnrNWokWY/intuition-and-unconscious-learning", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Intuition%20and%20Unconscious%20Learning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntuition%20and%20Unconscious%20Learning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Cc3TWZjAnrNWokWY%2Fintuition-and-unconscious-learning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Intuition%20and%20Unconscious%20Learning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Cc3TWZjAnrNWokWY%2Fintuition-and-unconscious-learning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Cc3TWZjAnrNWokWY%2Fintuition-and-unconscious-learning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1478, "htmlBody": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>We have already examined two sources of our intuitions: the <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">attribute substitution heuristics</a>&nbsp;and our <a href=\"/lw/5bw/your_evolved_intuitions/\">evolved psychology</a>. Today we look at a third source of our intuitions: <em>unconscious learning</em>.&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Unconscious learning</h4>\n<p>The 'learning perspective' on intuition is compatible with the heuristics and biases literature and with evolutionary psychology, but adds a deeper understanding of what is going on 'under the hood.' The learning perspective says that many intuitions rely on representations that reflect the entirety of experiences stored in long-term memory. Such intuitions merely reproduce statistical regularities in long-term memory.<sup>1</sup></p>\n<p>An example will help explain:</p>\n<blockquote>\n<p>Assume you run into a man at the 20th anniversary party of your high school class graduation. You immediately sense a feeling of dislike. To avoid getting into a conversation, you signal and shout some words to a couple of old friends sitting at a distant table. While you are walking toward them, you try to remember the man&rsquo;s name, which pops into your mind after some time; and suddenly, you also remember that it was he who always did nasty things to you such as taking your secret letters and showing them to the rest of the class. You applaud the product of your intuition (the immediate feeling) that has helped you to make the right decision (avoiding interaction). Recall of prior experiences was not necessary to make this decision. The decision was solely based on a feeling, which reflected prior knowledge without awareness.<sup>2</sup></p>\n</blockquote>\n<p>Learning perspective theorists would suggest that your feeling of dislike - your intuition that you shouldn't talk to the man - came from something like an (unconscious) regularities analysis of your experiences with that man that were stored in long-term memory, and those experiences turned out to be mostly negative. As such, your intuition can make use of rapid parallel processing to draw on the whole sum of experiences in long-term memory, rather than using a slower, sequential-processing judgment algorithm.</p>\n<p>It is difficult to track the source of any <em>particular</em>&nbsp;intuition (though we can try<sup>3</sup>), but there is evidence to suggest that unconscious learning is a common source of our intuitions.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Stock tickers</h4>\n<p>In a series of experiments,<sup>4</sup> researchers asked subjects to watch a series of advertisements. They warned subjects that a (fictional) stock ticker at the bottom of the screen would be added as a distractor (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Betsch-example-screenshot.png\">screenshot</a>), and that they would be quizzed on the advertisements later. After being quizzed on the advertisements, subjects were surprised by a quiz on their attitudes toward the fictional stocks. Post-experiment interviews confirmed that subjects had not intended to form attitudes toward the stocks.</p>\n<p>Subjects watched 20 to 40 advertisements while the 'distractor' stock ticker displayed 70 to 140 return values for 4 to 8 shares. As the independent variable, researchers varied the return values (and thus their sum, average, frequency, and peaks).</p>\n<p>When given the surprise quiz on their attitudes toward the fictional stocks, researchers found a perfect rank correlation between the subjects' mean evaluation of the shares and the sums of their returns. This was the case even though subjects had no concrete memories of the share returns, and could not remember the sum or average values. Subjects reported they had relied on their 'gut reaction' or 'intuitive feeling.'</p>\n<p>Here, it does not seem that subjects were able to arrive at such accurate intuitions by way of a specific evolved intuition or an attribute substitution heuristic. Instead, they seem to have drawn upon their unconscious learning system without knowing that they were doing so.</p>\n<p>&nbsp;</p>\n<h4>Base rate neglect</h4>\n<p>Consider this problem:</p>\n<blockquote>\n<p>If a test to detect a disease whose prevalence is 1/1000 has a false positive rate of 5%, what is the chance that a person found to have a positive result actually has the disease, assuming you know nothing about the person's symptoms or signs?<sup>5</sup></p>\n</blockquote>\n<p>Among 60 Harvard medical students and staff, almost half judged that the person has the disease with .95 probability, while only 18% got the correct answer: .02. This is an example of <a href=\"http://en.wikipedia.org/wiki/Base_rate_fallacy\">base rate neglect</a>. Subjects based their judgment mostly on the evidence from the test, and ignored the strong evidence from the base rate (1/1000).</p>\n<p>Base rate sensitivity improves when such problems are framed in terms of frequencies rather than probabilities, but even then base rate neglect occurs in about half of subjects.<sup>6</sup></p>\n<p>Subjects further improve their statistical judgments when they are allowed learn the distribution of a variable by their own sampling, and become even more sensitive to base rates.<sup>7</sup></p>\n<p>In a related study,<sup>8</sup>&nbsp;researchers had subjects perform several behaviors many times, and then asked them to estimate behavior frequency. Half of the subjects were asked to make spontaneous judgments, and half were asked to deliberate carefully about their judgments. In the deliberation condition, judgments were biased by the availability heuristic. Judgments from the spontaneous judgment condition were more accurate, and seemed to reflect unconscious recall of the totality of behaviors just performed, stored by unconscious learning.</p>\n<p>&nbsp;</p>\n<h4>Conclusion</h4>\n<p>These and many others studies<sup>9</sup>&nbsp;suggest that sometimes our feelings and intuitive judgments arise from unconscious parallel processing of all (or many) of the experiences relevant to a given judgment stored in our long-term memory.</p>\n<p>Later we'll examine how this understanding of intuition (along with the perspectives from attribute substitution heuristics and evolutionary psychology) gives us some clues about how much trust we should put in our intuitions under particular conditions, and how we can train our intuitions to be more accurate.<sup>10</sup></p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/4vs/when_intuitions_are_useful/\">When Intuitions Are Useful</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/5bw/your_evolved_intuitions/\">Your Evolved Intuitions</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup> Betsch et al. (2004); Betsch &amp; Haberstroh (2005); Betsch (2007); Klein (1999); Hogarth (2001, 2007); Epstein (2007). For an overview of the neuroscience of unconscious learning, see Volz &amp; Cramon (2007). For an overview of the relation between emotion and intuition, see Zeelenberg et al. (2007).</small></p>\n<p><small><sup>2</sup> Betsch (2007), p. 6.</small></p>\n<p><small><sup>3</sup>&nbsp;Hamm (2007).</small></p>\n<p><small><sup>4</sup> Betsch et al. (2001, 2003, 2007).</small></p>\n<p><small><sup>5</sup>&nbsp;Tversky &amp; Kahneman (1982), p. 154.</small></p>\n<p><small><sup>6</sup> Gigerenzer &amp; Hoffrage (1995).</small></p>\n<p><small><sup>7</sup> Betsch et al. (1998); Fiedler et al. (2000).</small></p>\n<p><small><sup>8</sup>&nbsp;Haberstroh et al. (2006).</small></p>\n<p><small><sup>9</sup>&nbsp;Plessner et al. (2007); Raab &amp; Johnson (2007); Gl&ouml;ckner (2007). Also see research on the 'sample size effect': Kaufmann &amp; Betsch (2009).</small></p>\n<p><small><sup>10</sup>&nbsp;Hogarth (2001, 2007); Erev et al. (2007).</small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Betsch (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Betsch-The-nature-of-intuition-and-its-neglect-in-research-on-judgment-and-decision-making.pdf\">The nature of intuition and its neglect in research on judgment and decision making</a>. In Plessner, Betsch, &amp; Betsch (eds.), <em>Intuition in Judgment and Decision Making</em>&nbsp;(pp. 3-22). Psychology Press.</small></p>\n<p><small>Betsch, Plessner, Schwieren, &amp; Gu\u0308tig (2001).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Betsch-et-al-I-like-it-but-I-don&rsquo;t-know-why-A-value-account-approach-to-implicit-attitude-formation.pdf\">I like it but I don&rsquo;t know why: A value-account approach to implicit attitude formation</a>. <em>Personality and Social Psychology Bulletin, 27</em>: 242&ndash;253.</small></p>\n<p><small>Betsch, Hoffmann, Hoffrage, &amp; Plessner (2003).&nbsp;Intuition beyond recognition: When less familiar events are liked more. <em>Experimental Psychology, 50</em>: 49&ndash;54.</small></p>\n<p><small>Betsch, Plessner, &amp; Schallies (2004).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Betsch-et-al-The-value-account-model-of-attitude-formation.pdf\">The value-account model of attitude formation</a>. In Haddock &amp; Miao (eds.),&nbsp;<em style=\"font-style: italic; \">Contemporary perspectives on the psychology of attitudes</em>&nbsp;(pp. 251-274). Psychology Press.</small></p>\n<p><small>Betsch &amp; Haberstroh, eds. (2005).&nbsp;<em style=\"font-style: italic; \"><a href=\"http://www.amazon.com/Routines-Decision-Making-Tilmann-Betsch/dp/0805846131/\">The routines of decision making</a></em>. Psychology Press.</small></p>\n<p><small>Betsch, Kaufmann, Lindow, Plessner, &amp; Hoffmann (2006).&nbsp;Different principles of information integration in implicit and explicit attitude formation. <em>European Journal of Social Psychology, 36</em>: 887&ndash;905.</small></p>\n<p><small>Betsch, Biel, Eddelbu\u0308ttel, &amp; Mock (1998).&nbsp;Natural sampling and base-rate neglect. <em>European Journal of Social Psychology, 28</em>: 269&ndash;273.</small></p>\n<p><small>Epstein (2007).&nbsp;Intuition from the perspective of cognitive-experiential self-theory.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 23-37). Psychology Press.</small></p>\n<p><small>Erav, Shimonowitch, Schurr, &amp; Hertwig (2007). Base rates: How to make the intuitive mind appreciate or neglect them.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 135-148). Psychology Press.</small></p>\n<p><small>Fiedler, Brinkmann, Betsch, &amp; Wild (2000).&nbsp;A sampling approach to biases in conditional probability judgments: Beyond base-rate neglect and statistical format. <em>Journal of Experimental Psychology, General, 129</em>: 399&ndash;418.</small></p>\n<p><small>Gigerenzer &amp; Hoffrage (1995).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gigerenzer-Hoffrage-How-to-improve-Bayesian-reasoning-without-instruction.pdf\">How to improve Bayesian reasoning without instruction: Frequency formats</a>. <em>Psychological Review, 102</em>: 684&ndash;704.</small></p>\n<p><small>Gl&ouml;ckner (2007).&nbsp;Does intuition beat fast and frugal heuristics? A systematic empirical analysis.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 309-326). Psychology Press.</small></p>\n<p><small>Haberstroh, Betsch, &amp; Aarts (2006).&nbsp;When guessing is better than thinking: Multiple bases for frequency judgments. Unpublished manuscript.</small></p>\n<p><small>Hamm (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Hamm-Cue-by-hypothesis-interactions-in-descriptive-modeling-of-unconscious-use-of-multiple-intuitive-judgment-strategies.pdf\">Cue by hypothesis interactions in descriptive modeling of unconscious use of multiple intuitive judgment strategies</a>.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 55-70). Psychology Press.</small></p>\n<p><small>Hogarth (2001). <em><a href=\"http://www.amazon.com/Educating-Intuition-Robin-M-Hogarth/dp/0226348628/\">Educating Intuition</a></em>. University of Chicago Press.</small></p>\n<p><small>Hogarth (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Hogarth-On-the-learning-of-intuition.pdf\">On the learning of intuition</a>.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em>Intuition in Judgment and Decision Making</em>&nbsp;(pp. 91-106). Psychology Press.</small></p>\n<p><small>Klein (1999).&nbsp;<em><a href=\"http://www.amazon.com/Sources-Power-People-Make-Decisions/dp/0262611465/\">Sources of power. How people make decisions</a></em>. MIT press.</small></p>\n<p><small>Kaufmann &amp; Betsch (2009). Origins of the sample-size effect in explicit evaluative judgments. <em>Experimental Psychology, 56</em>: 344-353.</small></p>\n<p><small>Plessner, Betsch, Schallies, &amp; Schwieren (2007).&nbsp;Automatic online formation of implicit attitudes toward politicians as a basis for intuitive voting behavior.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 107-117). Psychology Press.</small></p>\n<p><small>Raab &amp; Johnson (2007).&nbsp;Implicit learning as a means to intuitive decision making in sports.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 119-133). Psychology Press.</small></p>\n<p><small>Tversky &amp; Kahneman (1982).&nbsp;<em><a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/\">Judgment under uncertainty: Heuristics and biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Volz &amp; Cramon (2007). Can neuroscience tell a story about intuition?&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 71-87). Psychology Press.</small></p>\n<p><small>Zeelenberg, Nelissen, &amp; Pieters (2007).&nbsp;Emotion, motivation, and decision making: a feeling-is-for-doing approach.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 173-189). Psychology Press.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"z95PGFXtPpwakqkTA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6Cc3TWZjAnrNWokWY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 44, "extendedScore": null, "score": 8.5e-05, "legacy": true, "legacyId": "6835", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "yFvZa9wkv5JoqhM8F", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "when-intuitions-are-useful", "canonicalPrevPostSlug": "your-evolved-intuitions", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 44, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>We have already examined two sources of our intuitions: the <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">attribute substitution heuristics</a>&nbsp;and our <a href=\"/lw/5bw/your_evolved_intuitions/\">evolved psychology</a>. Today we look at a third source of our intuitions: <em>unconscious learning</em>.&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Unconscious_learning\">Unconscious learning</h4>\n<p>The 'learning perspective' on intuition is compatible with the heuristics and biases literature and with evolutionary psychology, but adds a deeper understanding of what is going on 'under the hood.' The learning perspective says that many intuitions rely on representations that reflect the entirety of experiences stored in long-term memory. Such intuitions merely reproduce statistical regularities in long-term memory.<sup>1</sup></p>\n<p>An example will help explain:</p>\n<blockquote>\n<p>Assume you run into a man at the 20th anniversary party of your high school class graduation. You immediately sense a feeling of dislike. To avoid getting into a conversation, you signal and shout some words to a couple of old friends sitting at a distant table. While you are walking toward them, you try to remember the man\u2019s name, which pops into your mind after some time; and suddenly, you also remember that it was he who always did nasty things to you such as taking your secret letters and showing them to the rest of the class. You applaud the product of your intuition (the immediate feeling) that has helped you to make the right decision (avoiding interaction). Recall of prior experiences was not necessary to make this decision. The decision was solely based on a feeling, which reflected prior knowledge without awareness.<sup>2</sup></p>\n</blockquote>\n<p>Learning perspective theorists would suggest that your feeling of dislike - your intuition that you shouldn't talk to the man - came from something like an (unconscious) regularities analysis of your experiences with that man that were stored in long-term memory, and those experiences turned out to be mostly negative. As such, your intuition can make use of rapid parallel processing to draw on the whole sum of experiences in long-term memory, rather than using a slower, sequential-processing judgment algorithm.</p>\n<p>It is difficult to track the source of any <em>particular</em>&nbsp;intuition (though we can try<sup>3</sup>), but there is evidence to suggest that unconscious learning is a common source of our intuitions.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Stock_tickers\">Stock tickers</h4>\n<p>In a series of experiments,<sup>4</sup> researchers asked subjects to watch a series of advertisements. They warned subjects that a (fictional) stock ticker at the bottom of the screen would be added as a distractor (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Betsch-example-screenshot.png\">screenshot</a>), and that they would be quizzed on the advertisements later. After being quizzed on the advertisements, subjects were surprised by a quiz on their attitudes toward the fictional stocks. Post-experiment interviews confirmed that subjects had not intended to form attitudes toward the stocks.</p>\n<p>Subjects watched 20 to 40 advertisements while the 'distractor' stock ticker displayed 70 to 140 return values for 4 to 8 shares. As the independent variable, researchers varied the return values (and thus their sum, average, frequency, and peaks).</p>\n<p>When given the surprise quiz on their attitudes toward the fictional stocks, researchers found a perfect rank correlation between the subjects' mean evaluation of the shares and the sums of their returns. This was the case even though subjects had no concrete memories of the share returns, and could not remember the sum or average values. Subjects reported they had relied on their 'gut reaction' or 'intuitive feeling.'</p>\n<p>Here, it does not seem that subjects were able to arrive at such accurate intuitions by way of a specific evolved intuition or an attribute substitution heuristic. Instead, they seem to have drawn upon their unconscious learning system without knowing that they were doing so.</p>\n<p>&nbsp;</p>\n<h4 id=\"Base_rate_neglect\">Base rate neglect</h4>\n<p>Consider this problem:</p>\n<blockquote>\n<p>If a test to detect a disease whose prevalence is 1/1000 has a false positive rate of 5%, what is the chance that a person found to have a positive result actually has the disease, assuming you know nothing about the person's symptoms or signs?<sup>5</sup></p>\n</blockquote>\n<p>Among 60 Harvard medical students and staff, almost half judged that the person has the disease with .95 probability, while only 18% got the correct answer: .02. This is an example of <a href=\"http://en.wikipedia.org/wiki/Base_rate_fallacy\">base rate neglect</a>. Subjects based their judgment mostly on the evidence from the test, and ignored the strong evidence from the base rate (1/1000).</p>\n<p>Base rate sensitivity improves when such problems are framed in terms of frequencies rather than probabilities, but even then base rate neglect occurs in about half of subjects.<sup>6</sup></p>\n<p>Subjects further improve their statistical judgments when they are allowed learn the distribution of a variable by their own sampling, and become even more sensitive to base rates.<sup>7</sup></p>\n<p>In a related study,<sup>8</sup>&nbsp;researchers had subjects perform several behaviors many times, and then asked them to estimate behavior frequency. Half of the subjects were asked to make spontaneous judgments, and half were asked to deliberate carefully about their judgments. In the deliberation condition, judgments were biased by the availability heuristic. Judgments from the spontaneous judgment condition were more accurate, and seemed to reflect unconscious recall of the totality of behaviors just performed, stored by unconscious learning.</p>\n<p>&nbsp;</p>\n<h4 id=\"Conclusion\">Conclusion</h4>\n<p>These and many others studies<sup>9</sup>&nbsp;suggest that sometimes our feelings and intuitive judgments arise from unconscious parallel processing of all (or many) of the experiences relevant to a given judgment stored in our long-term memory.</p>\n<p>Later we'll examine how this understanding of intuition (along with the perspectives from attribute substitution heuristics and evolutionary psychology) gives us some clues about how much trust we should put in our intuitions under particular conditions, and how we can train our intuitions to be more accurate.<sup>10</sup></p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/4vs/when_intuitions_are_useful/\">When Intuitions Are Useful</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/5bw/your_evolved_intuitions/\">Your Evolved Intuitions</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup> Betsch et al. (2004); Betsch &amp; Haberstroh (2005); Betsch (2007); Klein (1999); Hogarth (2001, 2007); Epstein (2007). For an overview of the neuroscience of unconscious learning, see Volz &amp; Cramon (2007). For an overview of the relation between emotion and intuition, see Zeelenberg et al. (2007).</small></p>\n<p><small><sup>2</sup> Betsch (2007), p. 6.</small></p>\n<p><small><sup>3</sup>&nbsp;Hamm (2007).</small></p>\n<p><small><sup>4</sup> Betsch et al. (2001, 2003, 2007).</small></p>\n<p><small><sup>5</sup>&nbsp;Tversky &amp; Kahneman (1982), p. 154.</small></p>\n<p><small><sup>6</sup> Gigerenzer &amp; Hoffrage (1995).</small></p>\n<p><small><sup>7</sup> Betsch et al. (1998); Fiedler et al. (2000).</small></p>\n<p><small><sup>8</sup>&nbsp;Haberstroh et al. (2006).</small></p>\n<p><small><sup>9</sup>&nbsp;Plessner et al. (2007); Raab &amp; Johnson (2007); Gl\u00f6ckner (2007). Also see research on the 'sample size effect': Kaufmann &amp; Betsch (2009).</small></p>\n<p><small><sup>10</sup>&nbsp;Hogarth (2001, 2007); Erev et al. (2007).</small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Betsch (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Betsch-The-nature-of-intuition-and-its-neglect-in-research-on-judgment-and-decision-making.pdf\">The nature of intuition and its neglect in research on judgment and decision making</a>. In Plessner, Betsch, &amp; Betsch (eds.), <em>Intuition in Judgment and Decision Making</em>&nbsp;(pp. 3-22). Psychology Press.</small></p>\n<p><small>Betsch, Plessner, Schwieren, &amp; Gu\u0308tig (2001).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Betsch-et-al-I-like-it-but-I-don\u2019t-know-why-A-value-account-approach-to-implicit-attitude-formation.pdf\">I like it but I don\u2019t know why: A value-account approach to implicit attitude formation</a>. <em>Personality and Social Psychology Bulletin, 27</em>: 242\u2013253.</small></p>\n<p><small>Betsch, Hoffmann, Hoffrage, &amp; Plessner (2003).&nbsp;Intuition beyond recognition: When less familiar events are liked more. <em>Experimental Psychology, 50</em>: 49\u201354.</small></p>\n<p><small>Betsch, Plessner, &amp; Schallies (2004).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Betsch-et-al-The-value-account-model-of-attitude-formation.pdf\">The value-account model of attitude formation</a>. In Haddock &amp; Miao (eds.),&nbsp;<em style=\"font-style: italic; \">Contemporary perspectives on the psychology of attitudes</em>&nbsp;(pp. 251-274). Psychology Press.</small></p>\n<p><small>Betsch &amp; Haberstroh, eds. (2005).&nbsp;<em style=\"font-style: italic; \"><a href=\"http://www.amazon.com/Routines-Decision-Making-Tilmann-Betsch/dp/0805846131/\">The routines of decision making</a></em>. Psychology Press.</small></p>\n<p><small>Betsch, Kaufmann, Lindow, Plessner, &amp; Hoffmann (2006).&nbsp;Different principles of information integration in implicit and explicit attitude formation. <em>European Journal of Social Psychology, 36</em>: 887\u2013905.</small></p>\n<p><small>Betsch, Biel, Eddelbu\u0308ttel, &amp; Mock (1998).&nbsp;Natural sampling and base-rate neglect. <em>European Journal of Social Psychology, 28</em>: 269\u2013273.</small></p>\n<p><small>Epstein (2007).&nbsp;Intuition from the perspective of cognitive-experiential self-theory.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 23-37). Psychology Press.</small></p>\n<p><small>Erav, Shimonowitch, Schurr, &amp; Hertwig (2007). Base rates: How to make the intuitive mind appreciate or neglect them.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 135-148). Psychology Press.</small></p>\n<p><small>Fiedler, Brinkmann, Betsch, &amp; Wild (2000).&nbsp;A sampling approach to biases in conditional probability judgments: Beyond base-rate neglect and statistical format. <em>Journal of Experimental Psychology, General, 129</em>: 399\u2013418.</small></p>\n<p><small>Gigerenzer &amp; Hoffrage (1995).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gigerenzer-Hoffrage-How-to-improve-Bayesian-reasoning-without-instruction.pdf\">How to improve Bayesian reasoning without instruction: Frequency formats</a>. <em>Psychological Review, 102</em>: 684\u2013704.</small></p>\n<p><small>Gl\u00f6ckner (2007).&nbsp;Does intuition beat fast and frugal heuristics? A systematic empirical analysis.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 309-326). Psychology Press.</small></p>\n<p><small>Haberstroh, Betsch, &amp; Aarts (2006).&nbsp;When guessing is better than thinking: Multiple bases for frequency judgments. Unpublished manuscript.</small></p>\n<p><small>Hamm (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Hamm-Cue-by-hypothesis-interactions-in-descriptive-modeling-of-unconscious-use-of-multiple-intuitive-judgment-strategies.pdf\">Cue by hypothesis interactions in descriptive modeling of unconscious use of multiple intuitive judgment strategies</a>.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 55-70). Psychology Press.</small></p>\n<p><small>Hogarth (2001). <em><a href=\"http://www.amazon.com/Educating-Intuition-Robin-M-Hogarth/dp/0226348628/\">Educating Intuition</a></em>. University of Chicago Press.</small></p>\n<p><small>Hogarth (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Hogarth-On-the-learning-of-intuition.pdf\">On the learning of intuition</a>.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em>Intuition in Judgment and Decision Making</em>&nbsp;(pp. 91-106). Psychology Press.</small></p>\n<p><small>Klein (1999).&nbsp;<em><a href=\"http://www.amazon.com/Sources-Power-People-Make-Decisions/dp/0262611465/\">Sources of power. How people make decisions</a></em>. MIT press.</small></p>\n<p><small>Kaufmann &amp; Betsch (2009). Origins of the sample-size effect in explicit evaluative judgments. <em>Experimental Psychology, 56</em>: 344-353.</small></p>\n<p><small>Plessner, Betsch, Schallies, &amp; Schwieren (2007).&nbsp;Automatic online formation of implicit attitudes toward politicians as a basis for intuitive voting behavior.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 107-117). Psychology Press.</small></p>\n<p><small>Raab &amp; Johnson (2007).&nbsp;Implicit learning as a means to intuitive decision making in sports.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 119-133). Psychology Press.</small></p>\n<p><small>Tversky &amp; Kahneman (1982).&nbsp;<em><a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/\">Judgment under uncertainty: Heuristics and biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Volz &amp; Cramon (2007). Can neuroscience tell a story about intuition?&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 71-87). Psychology Press.</small></p>\n<p><small>Zeelenberg, Nelissen, &amp; Pieters (2007).&nbsp;Emotion, motivation, and decision making: a feeling-is-for-doing approach.&nbsp;In Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making</em>&nbsp;(pp. 173-189). Psychology Press.</small></p>", "sections": [{"title": "Unconscious learning", "anchor": "Unconscious_learning", "level": 1}, {"title": "Stock tickers", "anchor": "Stock_tickers", "level": 1}, {"title": "Base rate neglect", "anchor": "Base_rate_neglect", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "9 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["du395YvCnQXBPSJax", "WTS4ZbEwvKrcrnaaN", "myLSqHNgi6BumABvE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T20:03:28.747Z", "modifiedAt": null, "url": null, "title": "Add \"Meetups\" to top navigation bar?", "slug": "add-meetups-to-top-navigation-bar", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.264Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "saliency", "createdAt": "2009-10-25T03:59:58.587Z", "isAdmin": false, "displayName": "saliency"}, "userId": "RNx6ydjKM2J3Heae3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/36LFqd8haFj7rEcn2/add-meetups-to-top-navigation-bar", "pageUrlRelative": "/posts/36LFqd8haFj7rEcn2/add-meetups-to-top-navigation-bar", "linkUrl": "https://www.lesswrong.com/posts/36LFqd8haFj7rEcn2/add-meetups-to-top-navigation-bar", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Add%20%22Meetups%22%20to%20top%20navigation%20bar%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAdd%20%22Meetups%22%20to%20top%20navigation%20bar%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F36LFqd8haFj7rEcn2%2Fadd-meetups-to-top-navigation-bar%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Add%20%22Meetups%22%20to%20top%20navigation%20bar%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F36LFqd8haFj7rEcn2%2Fadd-meetups-to-top-navigation-bar", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F36LFqd8haFj7rEcn2%2Fadd-meetups-to-top-navigation-bar", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<p>I think the impulse to promote all meetups was a good idea but now adding to much noise to the \"<a href=\"/\"><strong>PROMOTED</strong></a>\" feed. Of the 10 \"<a href=\"/\"><strong>PROMOTED</strong></a>\" feeds 8 are adverts for meetups.</p>\n<p>I propose adding Meetups to the navigation bar and only adding them to \"<a href=\"/\"><strong>PROMOTED</strong></a>\" when they are especially significant; for example have a special speaker and might draw attention from people who are out of town.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "36LFqd8haFj7rEcn2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 3, "extendedScore": null, "score": 7.113565709047602e-07, "legacy": true, "legacyId": "7227", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T20:47:02.976Z", "modifiedAt": null, "url": null, "title": "Mutable Levels Are Path-Dependent", "slug": "mutable-levels-are-path-dependent", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.768Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3yzFeJc7KeT7qJXrx/mutable-levels-are-path-dependent", "pageUrlRelative": "/posts/3yzFeJc7KeT7qJXrx/mutable-levels-are-path-dependent", "linkUrl": "https://www.lesswrong.com/posts/3yzFeJc7KeT7qJXrx/mutable-levels-are-path-dependent", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mutable%20Levels%20Are%20Path-Dependent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMutable%20Levels%20Are%20Path-Dependent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3yzFeJc7KeT7qJXrx%2Fmutable-levels-are-path-dependent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mutable%20Levels%20Are%20Path-Dependent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3yzFeJc7KeT7qJXrx%2Fmutable-levels-are-path-dependent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3yzFeJc7KeT7qJXrx%2Fmutable-levels-are-path-dependent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 508, "htmlBody": "<p><a href=\"/user/Cyan/\">Cyan</a> and I had a good discussion (several, actually) on our <a href=\"/lw/4vt/trip_from_ottawa_canada_to_nyc_on_weekend_of/\">long recent drive</a>. Among diverse topics, he explained something that lead to a confusion-reducing revelation.</p>\n<p>On meeting Eliezer, Cyan wished to engage him on Measure Theory. Cyan felt that it might be a useful tool for Eliezer's fAI work. The conversation was interesting (I'll leave it to someone more mathematically competent to summarize), but what I remarked on was how it started.</p>\n<p>Cyan began, \"Eliezer, I'd say you're at least 3 levels above me, but I thought I could offer some advice on Measure Theory...\"</p>\n<p>I took this to be (needless) status-lowering behavior, and mentioned this in later conversation. However, it came out that this wasn't so, and there was original thinking behind the number \"3\".</p>\n<p>Cyan's formalization of \"levels\" involved the creation of useful new concepts. Someone a single level above you can create concepts that you can understand, but could not generate on your own.</p>\n<p>Cyan felt that Average Physicists were a level above him, Elite Physicists a level higher, and estimated that Eliezer was a level beyond that. <a href=\"/lw/ua/the_level_above_mine/\">Eliezer's original concept of Levels</a> seems to imply that one's level is biologically determined and immutable, and so a single \"EY-level\" is probably akin to the highest possible \"Cyan-level\". I will therefore refer to Mutable (Cyan-levels) and Immutable (EY-levels) Levels to distinguish the two. The former is the&nbsp;<em>attainment</em>&nbsp;of one's greatest potential, the latter describes this potential.</p>\n<p>I thought that this was a useful way to think about levels and \"leveling up\", but not completely right. I didn't think that levels were generalizable. Alice, Bob, and Cheryl might form a natural chain in which each was one Mutable Level above the previous person in the chain, but this chain could be very different with different players. Alice, Zorba, Xeno, Yudkowsky, and Cheryl could form an equally logical chain with each person being one Mutable Level above the previous person, so it doesn't make sense to refer to someone as X levels above you.</p>\n<p>Cyan and I eventually agreed that this makes more sense, and had the additional benefit providing a useful way to guide seeking out mentors.</p>\n<p>Therefore I make several claims I'd like the group's thoughts on:</p>\n<ol>\n<li>A useful way to think about \"Levels\" is as describing increasing ability to produce concepts of greater explanatory power or insight.</li>\n<li>It is useful to think of someone as a level above you if they can<em> generate</em> novel ideas that you can only <em>understand</em>, but could not have produced from scratch.</li>\n<li>Levels can be usefully thought of as Mutable (if they are amenable to improvement through study or holistic self improvement), or Immutable (if they are biologically - or otherwise - determined and fixed).</li>\n<li>One's maximally attainable Mutable Level is equivalent to one's Immutable Level; the latter describes potential, while the former describes the attainment of that potential.&nbsp;</li>\n<li>Mutable Levels are path dependent; it makes no sense to talk about levels abstractly, only in relation to specific individuals (or specific groups whose members have very similar abilities in the domain of interest).</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3yzFeJc7KeT7qJXrx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 3, "extendedScore": null, "score": 7.113690998549444e-07, "legacy": true, "legacyId": "6677", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oivnz3vuonccDM7r3", "kXSETKZ3X9oidMozA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T21:15:16.085Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Burch's Law", "slug": "seq-rerun-burch-s-law", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:53.287Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3zcmMyozdevq7kEg9/seq-rerun-burch-s-law", "pageUrlRelative": "/posts/3zcmMyozdevq7kEg9/seq-rerun-burch-s-law", "linkUrl": "https://www.lesswrong.com/posts/3zcmMyozdevq7kEg9/seq-rerun-burch-s-law", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Burch's%20Law&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Burch's%20Law%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3zcmMyozdevq7kEg9%2Fseq-rerun-burch-s-law%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Burch's%20Law%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3zcmMyozdevq7kEg9%2Fseq-rerun-burch-s-law", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3zcmMyozdevq7kEg9%2Fseq-rerun-burch-s-law", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 238, "htmlBody": "<p>Today's post, <a href=\"/lw/h0/burchs_law/\">Burch's Law</a>, was originally published on 08 March 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Just because your ethics require an action doesn't mean the universe will exempt you from the consequences. Manufactured cars kill an estimated 1.2 million people per year worldwide. (Roughly 2% of the annual planetary death rate.) Not everyone who dies in an automobile accident is someone who decided to drive a car. The tally of casualties includes pedestrians. It includes minor children who had to be pushed screaming into the car on the way to school. And yet we still manufacture automobiles, because, well, we're in a hurry. The point is that the consequences don't change no matter how good the ethical justification sounds.</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/gz/policy_debates_should_not_appear_onesided/\">Policy Debates Should Not Appear One-Sided</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3zcmMyozdevq7kEg9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.113772144516586e-07, "legacy": true, "legacyId": "7228", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6dSitnwYPg8i8NHn3", "PeSzc9JTBxhaYRp9b", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-06T21:34:48.382Z", "modifiedAt": null, "url": null, "title": "Who are the LW editors?", "slug": "who-are-the-lw-editors", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.220Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "saliency", "createdAt": "2009-10-25T03:59:58.587Z", "isAdmin": false, "displayName": "saliency"}, "userId": "RNx6ydjKM2J3Heae3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iXxSyYLybSvjP7sMX/who-are-the-lw-editors", "pageUrlRelative": "/posts/iXxSyYLybSvjP7sMX/who-are-the-lw-editors", "linkUrl": "https://www.lesswrong.com/posts/iXxSyYLybSvjP7sMX/who-are-the-lw-editors", "postedAtFormatted": "Friday, May 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Who%20are%20the%20LW%20editors%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWho%20are%20the%20LW%20editors%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXxSyYLybSvjP7sMX%2Fwho-are-the-lw-editors%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Who%20are%20the%20LW%20editors%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXxSyYLybSvjP7sMX%2Fwho-are-the-lw-editors", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXxSyYLybSvjP7sMX%2Fwho-are-the-lw-editors", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 12, "htmlBody": "<p>&nbsp;</p>\n<p>Do we have a published list of the users who are editors?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iXxSyYLybSvjP7sMX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 7.113826930653945e-07, "legacy": true, "legacyId": "7229", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T00:06:47.242Z", "modifiedAt": null, "url": null, "title": "What causes people to believe in conspiracy theories?", "slug": "what-causes-people-to-believe-in-conspiracy-theories", "viewCount": null, "lastCommentedAt": "2018-10-14T14:03:29.925Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Servant", "createdAt": "2010-08-28T01:06:07.043Z", "isAdmin": false, "displayName": "Servant"}, "userId": "hKpfDZpbiECWioGmm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KG9xzRiQQm8tYXfkQ/what-causes-people-to-believe-in-conspiracy-theories", "pageUrlRelative": "/posts/KG9xzRiQQm8tYXfkQ/what-causes-people-to-believe-in-conspiracy-theories", "linkUrl": "https://www.lesswrong.com/posts/KG9xzRiQQm8tYXfkQ/what-causes-people-to-believe-in-conspiracy-theories", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20causes%20people%20to%20believe%20in%20conspiracy%20theories%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20causes%20people%20to%20believe%20in%20conspiracy%20theories%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKG9xzRiQQm8tYXfkQ%2Fwhat-causes-people-to-believe-in-conspiracy-theories%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20causes%20people%20to%20believe%20in%20conspiracy%20theories%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKG9xzRiQQm8tYXfkQ%2Fwhat-causes-people-to-believe-in-conspiracy-theories", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKG9xzRiQQm8tYXfkQ%2Fwhat-causes-people-to-believe-in-conspiracy-theories", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 468, "htmlBody": "<p>I'm sorry if this post doesn't seem that high quality, but I do feel this might be the best place to ask. The point of this post is to inspire discussion, hopefully discussion that might be useful for answering certain questions I had.</p>\n<p>On another board, I gathered evidence of the existence of&nbsp;<a href=\"http://www.bay12forums.com/smf/index.php?topic=83773.0\"> \"mainstream\" conspiracy theories</a> with the goal of figuring out why those conspiracy theories are, well, mainstream. Part of the problem is that, because they're mainstream, many people here may believe in them and may even contest the idea that they are even conspiracy theories. I don't really want to get into arguments over if a conspiracy theory is true or not, so just remember \"Politics Is The Mindkiller\".</p>\n<p>1) JFK was assassinated in a conspiracy. (75% of Americans believe this according to <a href=\"http://www.gallup.com/poll/9751/Americans-Kennedy-Assassination-Conspiracy.aspx\">a 2003 Gallup poll</a>.)</p>\n<p>2) Martin Luther King, Jr. was assassinated in a conspiracy. (58% of Americans believe this according to a <a href=\"http://www.pollingreport.com/race.htm\">2008 CNN/Essence poll</a>.)</p>\n<p>3) Bush lied about WMDs. (43% of Americans according to a 2005 Pew Survey, only 41% disagreed with this statement, according to a <a href=\"http://www.pollingreport.com/iraq12.htm\">2005 Pew Survey</a>.)</p>\n<p>4) No <em>international </em>consensus on who did 9/11, with 49% of Mexicans, 66% of Egyptians, 40% of Turks, 52% of Jordanians and 55% of Palestinians naming a suspect other than al-Qaeda. This is from a <a href=\"http://www.worldpublicopinion.org/pipa/articles/international_security_bt/535.php?lb=btis&amp;pnt=535&amp;nid=&amp;id=\">2008 World Public Opinion poll </a>(graph below).</p>\n<p><img src=\"http://www.worldpublicopinion.org/pipa/images/sep08/WPO_911_Sep08_graph.jpg\" alt=\"\" width=\"300\" height=\"480\" /></p>\n<p>It's clear that at least some conspiracy theories are treated as mainstream in at least some polities, but other conspiracy theories, like \"Americans hoaxed the moon landing\" are fringe (only 6% of Americans believe this, according to a 2001 Gallup poll [<a href=\"http://www.gallup.com/poll/1993/Did-Men-Really-Land-Moon.aspx\">link here</a>]). In fact, many bloggers, <a href=\"http://www.overcomingbias.com/2011/04/consider-conspiracies.html\">including the economist Robin Hanson</a>, labor under the idea that <em>all </em>conspiracy theories are fringe and wonder why are these individuals so different from the \"mainstream\". So here's two questions that I would like answered, because these results had been bugging me:</p>\n<p>1) There is some sort of method by which an individual can 'filter' out the false and \"fringe\" conspiracy theory while then selecting a 'true' and \"mainstream\" conspiracy theory to be accepted. What factors play into an individual's decision-making process to determine what conspiracy theories to accept and what to reject?</p>\n<p>2) Is the process of believing in conspiracy theories impacted by some form of rationality? Does Bayesian logic plays a role here as well...do individuals unconsciously rate the likelihood of a conspiracy theory and accept conspiracy theories with a high probability of it occurring (while rejecting conspiracy theories with a low probability of it occurring)?</p>\n<p>Addendum: (I tried to select examples that could generally be agreed to be \"conspiracy  theories\" to avoid arguments over definitions that I'd lose, but I may  have failed in this sort of thing. To reveal bias, I believe that a  conspiracy theory is a hypothesis about a covert plot by more than one  individual.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KG9xzRiQQm8tYXfkQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "7230", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T01:38:39.042Z", "modifiedAt": null, "url": null, "title": "The Power of Agency", "slug": "the-power-of-agency", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.653Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vbcjYg6h3XzuqaaN8/the-power-of-agency", "pageUrlRelative": "/posts/vbcjYg6h3XzuqaaN8/the-power-of-agency", "linkUrl": "https://www.lesswrong.com/posts/vbcjYg6h3XzuqaaN8/the-power-of-agency", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Power%20of%20Agency&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Power%20of%20Agency%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvbcjYg6h3XzuqaaN8%2Fthe-power-of-agency%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Power%20of%20Agency%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvbcjYg6h3XzuqaaN8%2Fthe-power-of-agency", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvbcjYg6h3XzuqaaN8%2Fthe-power-of-agency", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 390, "htmlBody": "<p>You are not a Bayesian <a href=\"http://commonsenseatheism.com/?p=8844\">homunculus</a> whose reasoning is 'corrupted' by cognitive biases.</p>\n<p>You just <em>are</em>&nbsp;cognitive biases.</p>\n<p>You just&nbsp;<em>are </em><a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">attribution substitution heuristics</a>, <a href=\"/lw/5bw/your_evolved_intuitions/\">evolved intuitions</a>, and <a href=\"/lw/59v/intuition_and_unconscious_learning/\">unconscious learning</a>. These make up the '<a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">elephant</a>' of your mind, and atop them rides a tiny 'deliberative thinking' module that only rarely exerts itself, and almost never according to <a href=\"http://yudkowsky.net/rational/bayes\">normatively correct reasoning</a>.</p>\n<p>You do not have the <a href=\"http://www.amazon.com/Lack-Character-Personality-Moral-Behavior/dp/0521608902/\">robust character</a> you think you have, but instead are blown about by <a href=\"/lw/52g/the_good_news_of_situationist_psychology/\">the winds of circumstance</a>.</p>\n<p>You do not have much cognitive access to <a href=\"/lw/4z7/the_neuroscience_of_desire/\">your motivations</a>. You are not Aristotle's 'rational&nbsp;animal.' You are Gazzaniga's <a href=\"http://cwx.prenhall.com/bookbind/pubbooks/morris4/medialib/readings/split.html\"><em>rationalizing</em></a>&nbsp;<a href=\"/lw/ju/rationalization/\">animal</a>. <a href=\"http://en.wikipedia.org/wiki/Neuroscience_of_free_will\">Most of the time</a>, your unconscious makes a decision, and <em>then</em>&nbsp;you become consciously aware of an intention to act, and <em>then</em> your brain invents a rationalization for the motivations behind your actions.</p>\n<p>If an 'agent' is something that makes choices so as to maximize the fulfillment of explicit desires, given explicit beliefs, then few humans are very 'agenty' at all. You may be agenty when you guide a piece of chocolate into your mouth, but you are not very agenty when you navigate the world on a broader scale. On the scale of days or weeks, your actions result from a&nbsp;<a href=\"http://www.amazon.com/Kluge-Haphazard-Evolution-Human-Mind/dp/B002ECETZY/\">kludge</a>&nbsp;of evolved mechanisms that are often function-specific and maladapted to your current environment. You are an&nbsp;<a href=\"/lw/l0/adaptationexecuters_not_fitnessmaximizers/\">adaptation-executor, not a fitness-maximizer</a>.</p>\n<p>Agency is rare but powerful. <a href=\"http://en.wikipedia.org/wiki/Homo_economicus\"><em>Homo economicus</em></a> <a href=\"http://en.wikipedia.org/wiki/Behavioral_economics\">is a myth</a>, but imagine what one of them could do&nbsp;if such a thing existed: a real agent with the power to <em>reliably do things it believed would fulfill its desires</em>. It could change its diet, work out each morning, and maximize its health and physical attractiveness. It could learn and practice body language, fashion, salesmanship, seduction, the laws of money, and domain-specific skills and win in every sphere of life without constant defeat by human hangups. It could learn networking and influence and persuasion and have large-scale effects on societies, cultures, and nations.</p>\n<p>Even a <em>little</em>&nbsp;bit of agenty-ness will have some lasting historical impact. Think of Benjamin Franklin, Teddy Roosevelt, Bill Clinton, or Tim Ferris. Imagine what you&nbsp;could do if you were just a <em>bit</em> more agenty. That's what <a href=\"/lw/4wm/rationality_boot_camp/\">training</a> in instrumental rationality is all about: transcending your kludginess to attain a bit more agenty-ness.</p>\n<p>And, imagine what an agent could do <em>without</em>&nbsp;the limits of human hardware or software. Now <em>that</em> would <em>really</em> be <a href=\"http://intelligence.org/upload/artificial-intelligence-risk.pdf\">something</a>.</p>\n<p><small>(This post was inspired by some conversations with Michael Vassar.)</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZzxvopS4BwLuQy42n": 2, "wBoHTJs9iQzczNtW3": 2, "iP2X4jQNHMWHRNPne": 2, "5f5c37ee1b5cdee568cfb16a": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vbcjYg6h3XzuqaaN8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 87, "baseScore": 96, "extendedScore": null, "score": 0.000177, "legacy": true, "legacyId": "7136", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 96, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["du395YvCnQXBPSJax", "WTS4ZbEwvKrcrnaaN", "6Cc3TWZjAnrNWokWY", "Q5CjE8pRiACqTvhRM", "48DTJkBH58JbBNSFH", "SFZoEBpLo9frSJGkc", "XPErvb8m9FapXCjhA", "s887k4Hcqj28cchYo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T04:51:45.004Z", "modifiedAt": null, "url": null, "title": "The 5-Second Level", "slug": "the-5-second-level", "viewCount": null, "lastCommentedAt": "2022-03-20T18:56:50.361Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JcpzFpPBSmzuksmWM/the-5-second-level", "pageUrlRelative": "/posts/JcpzFpPBSmzuksmWM/the-5-second-level", "linkUrl": "https://www.lesswrong.com/posts/JcpzFpPBSmzuksmWM/the-5-second-level", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%205-Second%20Level&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%205-Second%20Level%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJcpzFpPBSmzuksmWM%2Fthe-5-second-level%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%205-Second%20Level%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJcpzFpPBSmzuksmWM%2Fthe-5-second-level", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJcpzFpPBSmzuksmWM%2Fthe-5-second-level", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2457, "htmlBody": "<!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif] -->\n<p>To develop methods of teaching rationality skills, you need to learn to focus on mental events that occur in 5 seconds or less.&nbsp; Most of what you want to teach is directly on this level; the rest consists of chaining together skills on this level.</p>\n<p>As our first example, let's take the vital rationalist skill, \"Be specific.\"</p>\n<p>Even with people who've had moderate amounts of exposure to Less Wrong, a fair amount of my helping them think effectively often consists of my saying, \"Can you give me a specific example of that?\" or \"Can you be more concrete?\"</p>\n<p>A couple of formative childhood readings that taught me to be specific:</p>\n<blockquote>\n<p>\"What is meant by the word <em>red?</em>\"<br />\"It's a color.\"<br />\"What's a color?\"<br />\"Why, it's a quality things have.\"<br />\"What's a <em>quality?</em>\"<br />\"Say, what are you trying to do, anyway?\"</p>\n<p>You have pushed him into the clouds.&nbsp; If, on the other hand, we habitually go <em>down</em> the abstraction ladder to <em>lower</em> levels of abstraction when we are asked the meaning of a word, we are less likely to get lost in verbal mazes; we will tend to \"have our feet on the ground\" and know what we are talking about.&nbsp; This habit displays itself in an answer such as this:</p>\n<p>\"What is meant by the word <em>red?</em>\"<br />\"Well, the next time you see some cars stopped at an intersection, look at the traffic light facing them.&nbsp; Also, you might go to the fire department and see how their trucks are painted.\"</p>\n<p>-- S. I. Hayakawa, <a href=\"http://books.google.com/books?id=0H1p2sMdyXEC&amp;pg=PA88&amp;lpg=PA88&amp;dq=%22it%27s+a+quality+things+have%22&amp;source=bl&amp;ots=e-xeTes-ey&amp;sig=CRIaG7PXpMZoC6hjqIf7ZqM1tzM&amp;hl=en&amp;ei=KM3ETc7QJZOWsAP56-mmCA&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CBYQ6AEwAA#v=onepage&amp;q=%22it%27s%20a%20quality%20things%20have%22&amp;f=false\"><em>Language in Thought and Action</em></a></p>\n</blockquote>\n<p>and:</p>\n<blockquote>\n<p>\"Beware, demon!\" he intoned hollowly.&nbsp; \"I am not without defenses.\"<br />\"Oh yeah?&nbsp; Name three.\"</p>\n<p>-- Robert Asprin, <em>Another Fine Myth</em></p>\n</blockquote>\n<p>And now, no sooner does someone tell me that they want to \"facilitate communications between managers and employees\" than I say, \"Can you give me a concrete example of how you would do that?\"&nbsp; Hayakawa taught me to distinguish the concrete and the abstract; and from that small passage in Asprin, I picked up the dreadful personal habit of calling people's bluffs, often using the specific phrase, \"Name three.\"</p>\n<p>But the real subject of today's lesson is how to see skills like this on the 5-second level.&nbsp; And now that we have a <em>specific example </em>in hand, we can proceed to try to zoom in on the level of cognitive events that happen in 5 seconds or less.<a id=\"more\"></a></p>\n<p>Over-abstraction happens because it's <em>easy </em>to be abstract.&nbsp; It's <em>easier </em>to say \"red is a color\" than to pause your thoughts for long enough to come up with the example of a stop sign.&nbsp; Abstraction is a path of least resistance, a form of mental laziness.</p>\n<p>So the first thing that needs to happen on a timescale of 5 seconds is <em>perceptual recognition</em> of highly abstract statements unaccompanied by concrete examples, accompanied by an <em>automatic aversion</em>, an ick reaction - this is the trigger which invokes the skill.</p>\n<p>Then, you have <em>actionable stored procedures</em> that associate to the trigger.&nbsp; And \"come up with a concrete example\" is not a 5-second-level skill, not an actionable procedure, it doesn't <a href=\"/lw/1ai/the_first_step_is_to_admit_that_you_have_a_problem/\">transform the problem into a task</a>.&nbsp; An actionable mental procedure that could be learned, stored, and associated with the trigger would be \"Search for a memory that instantiates the abstract statement\", or \"Try to come up with hypothetical examples, and then discard the lousy examples your imagination keeps suggesting, until you finally have a good example that really shows what you were originally trying to say\", or \"Ask why you were making the abstract statement in the first place, and recall the original mental causes of your making that statement to see if they suggest something more concrete.\"</p>\n<p>Or to be more specific on the last mental procedure:&nbsp; Why were you <em>trying </em>to describe redness to someone?&nbsp; Did they just run a red traffic light?</p>\n<p>(And then what kind of exercise can you run someone through, which will get them to distinguish red traffic lights from green traffic lights?&nbsp; What could teach someone to distinguish red from green?)</p>\n<p>When you ask how to teach a rationality skill, don't ask \"How can I teach people to be more specific?\"&nbsp; Ask, \"What sort of exercise will lead people through the part of the skill where they perceptually recognize a statement as overly abstract?\"&nbsp; Ask, \"What exercise teaches people to think about why they made the abstract statement in the first place?\"&nbsp; Ask, \"What exercise could cause people to form, store, and associate with a trigger, a procedure for going through hypothetical examples until a good one or at least adequate one is invented?\"</p>\n<p>Coming up with good ways to teach mental skills requires thinking on the 5-second level, because until you've reached that level of introspective concreteness, that fineness of granularity, you can't recognize the elements you're trying to teach; you can't recognize the patterns of thought you're trying to build inside a mind.</p>\n<p>To come up with a 5-second description of a rationality skill, I would suggest zooming in on a concrete case of a real or hypothetical person who (a) fails in a typical fashion and (b) successfully applies the skill.&nbsp; Break down their <em>internal experience </em>into the smallest granules you can manage:&nbsp; perceptual classifications, contexts that evoke emotions, fleeting choices made too quick for verbal consideration.&nbsp; And then generalize what they're doing while <em>staying on the 5-second level</em>.</p>\n<p>Start with the concrete example of the person who starts to say \"Red is a color\" and cuts themselves off and says \"Red is what that stop sign and that fire engine have in common.\"&nbsp; What did they do on the 5-second level?</p>\n<ol>\n<li>Perceptually recognize a statement they made as overly abstract.</li>\n<li>Feel the need for an accompanying concrete example.</li>\n<li>Be sufficiently averse to the lack of such an example to avoid the path of least resistance where they just let themselves be lazy and abstract.</li>\n<li>Associate to and activate a stored, actionable, procedural skill, e.g:<br />4a.&nbsp; Try to remember a memory which matches that abstract thing you just said.<br />4b.&nbsp; Try to invent a specific hypothetical scenario which matches that abstract thing you just said.<br />4c.&nbsp; Ask why you said the abstract thing in the first place and see if that suggests anything.</li>\n</ol>\n<p><em>and</em></p>\n<ol> </ol> \n<ul>\n<li>Before even 1:&nbsp; They recognize that the notion of \"concrete\" means things like folding chairs, events like a young woman buying a vanilla ice cream, and the number 17, i.e. <em>specific enough to be visualized;</em> and they know \"red is a color\" is <em>not </em>specific enough to be satisfying.&nbsp; They perceptually recognize (this is what Hayakawa was trying to teach) the cardinal directions \"more abstract\" and \"less abstract\" as they apply within the landscape of the mind.</li>\n</ul>\n<ol> </ol>\n<p>If you are thinking on this level of granularity, then you're much more likely to come up with a good method for teaching the skill \"be specific\", because you'll know that whatever exercise you come up with, it ought to cause people's minds to go through events 1-4, and provide examples or feedback to train perception 0.</p>\n<p>Next example of thinking on the 5-second scale:&nbsp; I previously asked some people (especially from the New York LW community) the question \"What makes rationalists fun to be around?\", i.e., why is it that once you try out being in a rationalist community you can't bear the thought of going back?&nbsp; One of the primary qualities cited was \"Being non-judgmental.\"&nbsp; Two different people came up with that exact phrase, but it struck me as being not <em>precisely </em>the right description - rationalists go around judging and estimating and weighing things all the time.&nbsp; (Noticing small discordances in an <em>important </em>description, and reacting by trying to find an exact description, is another one of those 5-second skills.)&nbsp; So I pondered, trying to come up with a <em>more specific image</em> of <em>exactly what it was we weren't doing</em>, i.e. Being Specific, and after further visualization it occurred to me that a better description might be something like this:&nbsp; If you are a fellow member of my rationalist community and you come up with a proposal that I disagree with - like \"We should all practice lying, so that we feel less pressure to believe things that sound good to endorse out loud\" - then I may argue with the proposal on consequentialist grounds.&nbsp; I may <em>judge.</em>&nbsp; But I won't start saying in immense indignation what a terrible person you must be for suggesting it.</p>\n<p>Now I could try to verbally define exactly what it is we don't do, but this would fail to approach the 5-second level, and probably <em>also </em>fail to get at the real quality that's important to rationalist communities.&nbsp; That would merely be another attempt to legislate what people are or aren't allowed to say, and that would make things <em>less </em>fun.&nbsp; There'd be a new accusation to worry about if you said the wrong thing - \"Hey!&nbsp; Good rationalists don't do that!\" followed by a debate that wouldn't be experienced as pleasant for anyone involved.</p>\n<p>In this case I think it's actually <em>easier </em>to define the thing-we-avoid on the 5-second level.&nbsp; Person A says something that Person B disagrees with, and now in Person B's mind there's an option to go in the direction of a certain poisonous pleasure, an opportunity to experience an emotional burst of righteous indignation and a feeling of superiority, a chance to castigate the other person.&nbsp; On the 5-second level, Person B rejects this temptation, and instead invokes the procedure of (a) pausing to reflect and then (b) talking about the consequences of A's proposed policy in a tone that might perhaps be <em>worried </em>(for the way of rationality is not to refuse all emotion) but nonetheless is not filled with <em>righteous outrage and indignation which demands that all others share that indignation or be likewise castigated.</em></p>\n<p>(Which in practice, makes a really huge difference in how much rationalists can relax when they are around fellow rationalists.&nbsp; It's the difference between having to carefully tiptoe through a minefield and being free to run and dance, knowing that even if you make a mistake, it won't socially kill you.&nbsp; You're even allowed to say \"Oops\" and change your mind, if you want to backtrack (but that's a whole 'nother topic of 5-second skills)...)</p>\n<p>The point of <em>5-second-level </em>analysis is that to teach the <em>procedural habit</em>, you don't go into the evolutionary psychology of politics or the game theory of punishing non-punishers (by which the indignant demand that others agree with their indignation), which is unfortunately how I tended to write back when I was writing the original Less Wrong sequences.&nbsp; Rather you try to come up with exercises which, if people go through them, causes them to experience the 5-second events - to feel the temptation to indignation, and to make the choice otherwise, and to associate alternative procedural patterns such as pausing, reflecting, and asking \"What is the evidence?\" or \"What are the consequences?\"</p>\n<p>What <em>would </em>be an exercise which develops that habit?&nbsp; I don't know, although it's worth noting that a lot of traditional rationalists not associated with LW also have this skill, and that it seems fairly learnable by osmosis from watching other people in the community not be indignant.&nbsp; One method that seems worth testing would be to expose people to assertions that seem like obvious temptations to indignation, and get them to talk about evidence or consequences instead.&nbsp; Say, you propose that eating one-month-old human babies ought to be legal, because one-month-old human babies aren't as intelligent as pigs, and we eat pigs.&nbsp; Or you could start talking about feminism, in which case you can say pretty much anything and it's bound to offend someone.&nbsp; (Did that last sentence offend you?&nbsp; <em>Pause and reflect!</em>)&nbsp; The point being, not to persuade anyone of anything, but to get them to introspectively recognize the moment of that choice between indignation and not-indignation, and walk them through an alternative response, so they store and associate that procedural skill.&nbsp; The exercise might fail if the context of a school-exercise meant that the indignation never got started - if the temptation/choice were never experienced.&nbsp; But we could <em>try </em>that teaching method, at any rate.</p>\n<p>(There's this 5-second skill where you respond to mental uncertainty about whether or not something will work, by imagining <em>testing </em>it; and if it looks like you can just go test something, then the thought occurs to you to just go test it.&nbsp; To teach this skill, we might try showing people a list of hypotheses and asking them to <em>quickly </em>say on a scale of 1-10 how easy they look to test, because we're trying to teach people a procedural habit of <em>perceptually </em>considering the testableness of ideas.&nbsp; You wouldn't give people lots of time to think, because then that teaches a procedure of <em>going through complex arguments about testability, </em>which you <em>wouldn't</em> use routinely in real life and would end up associating primarily to a school-context where a defensible verbal argument is expected.)</p>\n<p>I should mention, at this point, that learning to see the 5-second level draws heavily on the introspective skill of visualizing mental events in specific detail, and maintaining that introspective image in your mind's eye for long enough to reflect on it and analyze it.&nbsp; This may take practice, so if you find that you can't do it right away, instinctively react by feeling that you need more practice to get to the lovely reward, instead of instinctively giving up.</p>\n<p>Has everyone learned from these examples a perceptual recognition of what the \"5-second level\" looks like?&nbsp; Of course you have!&nbsp; You've even installed a mental habit that when you or somebody else comes up with a supposedly 5-second-level description, you automatically inspect each part of the description to see if it contains any block units like \"Be specific\" which are actually high-level chunks.</p>\n<p>Now, as your exercise for learning the skill of \"Resolving cognitive events to the 5-second level\", take a rationalist skill you think is important (or pick a random LW post from <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">How To Actually Change Your Mind</a>); come up with a concrete example of that skill being used successfully; decompose that usage to a 5-second-level description of perceptual classifications and emotion-evoking contexts and associative triggers to actionable procedures etcetera; check your description to make sure that each part of it can be visualized as a concrete mental process and that there are no non-actionable abstract chunks; come up with a teaching exercise which seems like it ought to cause those sub-5-second events to occur in people's minds; and then post your analysis and proposed exercise in the comments.&nbsp; Hope to hear from you soon!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5gcpKG2XEAZGj5DEf": 4, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JcpzFpPBSmzuksmWM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 164, "baseScore": 200, "extendedScore": null, "score": 0.000369, "legacy": true, "legacyId": "7235", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 200, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 327, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Pmfk7ruhWaHj9diyv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 20, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T05:28:25.641Z", "modifiedAt": null, "url": null, "title": "Beginning resources for CEV research", "slug": "beginning-resources-for-cev-research", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:20.371Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jN2gbDRJHTtXYSdhY/beginning-resources-for-cev-research", "pageUrlRelative": "/posts/jN2gbDRJHTtXYSdhY/beginning-resources-for-cev-research", "linkUrl": "https://www.lesswrong.com/posts/jN2gbDRJHTtXYSdhY/beginning-resources-for-cev-research", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beginning%20resources%20for%20CEV%20research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeginning%20resources%20for%20CEV%20research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjN2gbDRJHTtXYSdhY%2Fbeginning-resources-for-cev-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beginning%20resources%20for%20CEV%20research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjN2gbDRJHTtXYSdhY%2Fbeginning-resources-for-cev-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjN2gbDRJHTtXYSdhY%2Fbeginning-resources-for-cev-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 521, "htmlBody": "<p>I've been working on <a href=\"http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">metaethics/CEV research</a> for a couple months now (publishing mostly <a href=\"http://wiki.lesswrong.com/wiki/Intuitions_and_Philosophy\">prerequisite</a> <a href=\"/lw/4z7/the_neuroscience_of_desire/\">material</a>) and figured I'd share some of the sources I've been using.</p>\n<p>&nbsp;</p>\n<p><strong>CEV sources</strong>.</p>\n<ul>\n<li>Yudkowsky, <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">Metaethics sequence</a></li>\n<li>Yudkowsky, '<a href=\"http://intelligence.org/upload/CEV.html\">Coherent Extrapolated Volition</a>'</li>\n<li>Tarleton, '<a href=\"http://intelligence.org/upload/coherent-extrapolated-volition.pdf\">Coherent extrapolated volition: A meta-level approach to machine ethics</a>'</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>Motivation</strong>. CEV extrapolates human motivations/desires/values/volition. As such, it will help to understand how human motivation works.</p>\n<ul>\n<li><em>Neuroeconomics</em>&nbsp;studies motivation as a driver of action under uncertainty. Start with <em><a href=\"http://www.amazon.com/Neuroeconomics-Decision-Paul-W-Glimcher/dp/0123741769/\">Neuroeconomics: Decision Making and the Brain</a></em>&nbsp;(2008) and <em><a href=\"http://www.amazon.com/dp/0199744254/\">Foundations of Neuroeconomic Analysis</a></em>&nbsp;(2010), and see my bibliography <a href=\"/lw/4z7/the_neuroscience_of_desire/\">here</a>.</li>\n<li><em>Affective neuroscience</em>&nbsp;studies motivation as an emotion.&nbsp;Start with&nbsp;<em><a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/\">Pleasures of the Brain</a></em>&nbsp;(2009) and my bibliography&nbsp;<a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">here</a>.</li>\n<li><em>Motivation science</em>&nbsp;integrates psychological approaches to studying motivation. Start with <em><a href=\"http://www.amazon.com/Psychology-Goals-Gordon-Moskowitz-PhD/dp/1606230298/\">The Psychology of Goals</a></em>&nbsp;(2009), <em><a href=\"http://www.amazon.com/Oxford-Handbook-Action-Cognition-Neuroscience/dp/0195309987/\">Oxford Handbook of Human Action</a></em>&nbsp;(2008), and&nbsp;<em><a href=\"http://www.amazon.com/Handbook-Motivation-Science-James-Shah/dp/1593855680/\">Handbook of Motivation Science</a></em>&nbsp;(2007).</li>\n</ul>\n<p><br /> <strong>Extrapolation</strong>. Is it plausible to think that some kind of extrapolation of human motivations will converge on a single motivational set? How would extrapolation work, exactly?</p>\n<ul>\n<li><em>Reflective equilibrium</em>. Yudkowsky's proposed extrapolation works analogously to what philosophers call '<a href=\"http://plato.stanford.edu/entries/reflective-equilibrium/\">reflective equilibrium</a>.' The most thorough work here is the&nbsp;<a href=\"http://www.amazon.com/Justice-Justification-Reflective-Equilibrium-Philosophy/dp/052146711X/\">1996 book</a> by Daniels, and there have been <a href=\"http://philpapers.org/browse/reflective-equilibrium\">lots of papers</a>, but this genre is only barely relevant for CEV. Basically, an entirely new literature on volition-extrapolation algorithms needs to be created.</li>\n<li><em>Full-information accounts of value</em>&nbsp;and <em>ideal observer</em>&nbsp;theories.&nbsp;This is what philosophers call theories of value that talk about 'what we would want if we were fully informed, etc.' or 'what a perfectly informed agent would want' like CEV does. There's <a href=\"http://scholar.google.com/scholar?as_q=full+information+accounts&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=value+good&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_sdt=1&amp;as_subj=soc&amp;as_sdtf=&amp;as_sdts=5&amp;hl=en\">some</a> <a href=\"http://en.wikipedia.org/wiki/Ideal_observer_theory\">literature</a> on this, but it's only marginally relevant to CEV. Again, an entirely new literature needs to be written to solve this problem.</li>\n</ul>\n<p><br /> <strong>Metaethics</strong>. Should we use CEV, or something else? What does 'should' mean?</p>\n<ul>\n<li>Yudkowsky, <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">Metaethics sequence</a></li>\n<li><em><a href=\"http://www.amazon.com/Introduction-Contemporary-Metaethics-Alex-Miller/dp/074562345X/\">An Introduction to Contemporary Metaethics</a></em>&nbsp;is a good introduction to mainstream metaethics. Unfortunately, nearly all of mainstream metaethics is horribly misguided, but the book will at least give you a good sense of the questions involved and what some of the wrong answers are. The chapter on moral reductionism is the most profitable.</li>\n<li>Also see '<a href=\"http://bentham.k2.t.u-tokyo.ac.jp/ap-cap09/openconf/data/papers/33.pdf\">Which Consequentialism? Machine ethics and moral divergence</a>.'</li>\n</ul>\n<p><br /> <strong>Building the utility function</strong>. How can a seed AI be built? How can it read what to value?</p>\n<ul>\n<li>Dewey, '<a href=\"http://www.danieldewey.net/dewey-learning-what-to-value.pdf\">Learning What to Value</a>'</li>\n<li>Yudkowsky, '<a href=\"http://intelligence.org/upload/CEV.html\">Coherent Extrapolated Volition</a>'</li>\n<li>Yudkowsky, '<a href=\"http://intelligence.org/upload/artificial-intelligence-risk.pdf\">Artificial Intelligence as a Positive and Negative Factor in Global Risk</a>'</li>\n</ul>\n<p><br /> <strong>Preserving the utility function</strong>. How can the motivations we put into a superintelligence be preserved over time and self-modifcation?</p>\n<ul>\n<li>Yudkowsky, '<a href=\"http://intelligence.org/upload/CEV.html\">Coherent Extrapolated Volition</a>'</li>\n<li>De Blanc, '<a href=\"http://arxiv.org/pdf/1105.3821v1\">Ontological Crises in Artificial Agents' Value Systems</a>'</li>\n<li>Omohundro, '<a href=\"http://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf\">Basic AI Drives</a>' and '<a href=\"http://selfawaresystems.files.wordpress.com/2008/01/nature_of_self_improving_ai.pdf\">The Nature of Self-Improving Artificial Intelligence</a>' (instrumental drives to watch out for, and more)</li>\n</ul>\n<p><br /> <strong>Reflective decision theory</strong>. Current decision theories tell us little about software agents that make decisions to modify their own decision-making mechanisms.</p>\n<ul>\n<li>See the Less Wrong wiki page on <a href=\"http://wiki.lesswrong.com/wiki/Decision_theory\">decision theory</a>.</li>\n<li>Wei Dai's <a href=\"http://wiki.lesswrong.com/wiki/Updateless_decision_theory\">Updateless Decision Theory</a></li>\n<li>Yudkowsky's <a href=\"http://wiki.lesswrong.com/wiki/Timeless_decision_theory\">Timeless Decision Theory</a></li>\n</ul>\n<p><br /> Additional suggestions welcome. I'll try to keep this page up-to-date.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W6QZYSNt5FgWgvbdT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jN2gbDRJHTtXYSdhY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 20, "extendedScore": null, "score": 7.115190554422483e-07, "legacy": true, "legacyId": "7236", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["48DTJkBH58JbBNSFH", "zThWT5Zvifo5qYaca"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T13:14:29.404Z", "modifiedAt": null, "url": null, "title": "Karma Bubble Fix (Greasemonkey script)", "slug": "karma-bubble-fix-greasemonkey-script", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.253Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_Nesov", "createdAt": "2009-02-27T09:55:13.458Z", "isAdmin": false, "displayName": "Vladimir_Nesov"}, "userId": "qf77EiaoMw7tH3GSr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FQRy2yxzTqPBK6Xyx/karma-bubble-fix-greasemonkey-script", "pageUrlRelative": "/posts/FQRy2yxzTqPBK6Xyx/karma-bubble-fix-greasemonkey-script", "linkUrl": "https://www.lesswrong.com/posts/FQRy2yxzTqPBK6Xyx/karma-bubble-fix-greasemonkey-script", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Karma%20Bubble%20Fix%20(Greasemonkey%20script)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKarma%20Bubble%20Fix%20(Greasemonkey%20script)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFQRy2yxzTqPBK6Xyx%2Fkarma-bubble-fix-greasemonkey-script%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Karma%20Bubble%20Fix%20(Greasemonkey%20script)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFQRy2yxzTqPBK6Xyx%2Fkarma-bubble-fix-greasemonkey-script", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFQRy2yxzTqPBK6Xyx%2Fkarma-bubble-fix-greasemonkey-script", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 45, "htmlBody": "<p>I wrote a <a href=\"http://userscripts.org/scripts/show/102429\">greasemonkey script</a> that fixes the problem with Karma bubble that prevents you from seeing the last digits of Karma for big Karma values. You can install it from <a href=\"http://userscripts.org/scripts/show/102429\">userscripts site</a>. You'll need a greasemonkey extension (<a href=\"https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/\">install for Firefox</a>, <a href=\"https://chrome.google.com/webstore/detail/dhdgffkkebhmkfjojejmpbldmpobfkfo\">install for Google Chrome</a>).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FQRy2yxzTqPBK6Xyx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 36, "extendedScore": null, "score": 7.11653148990738e-07, "legacy": true, "legacyId": "7242", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T15:30:09.593Z", "modifiedAt": null, "url": null, "title": "Bias and Naturalism: a Challenge", "slug": "bias-and-naturalism-a-challenge", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BobTheBob", "createdAt": "2011-03-13T16:47:17.414Z", "isAdmin": false, "displayName": "BobTheBob"}, "userId": "sX8EjuGz46HZAJLhm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wnAWZDQxwXaHXhNo9/bias-and-naturalism-a-challenge", "pageUrlRelative": "/posts/wnAWZDQxwXaHXhNo9/bias-and-naturalism-a-challenge", "linkUrl": "https://www.lesswrong.com/posts/wnAWZDQxwXaHXhNo9/bias-and-naturalism-a-challenge", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bias%20and%20Naturalism%3A%20a%20Challenge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABias%20and%20Naturalism%3A%20a%20Challenge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwnAWZDQxwXaHXhNo9%2Fbias-and-naturalism-a-challenge%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bias%20and%20Naturalism%3A%20a%20Challenge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwnAWZDQxwXaHXhNo9%2Fbias-and-naturalism-a-challenge", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwnAWZDQxwXaHXhNo9%2Fbias-and-naturalism-a-challenge", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 665, "htmlBody": "<p>There are two theses which I think many LWers find attractive, but which on the face of it are at odds. This challenge is to find a way to reconcile them. Bluntly and a bit inaccurately:</p>\n<ol>\n<li>You can't trust your untutored native cognitive endowment to make rational (or moral) judgements.</li>\n<li>All knowledge - including of what's rational (moral)- is scientific. To learn what's rational (moral) our only option is to study our native cognitive endowments.</li>\n</ol>\n<p>In more ponderous detail:<br /><br />Point 1) It's taken for granted on LW -and I have no problem with this- that without effort to correct ourselves, humans systematically make irrational judgements. This was always obvious, but research of the last few decades, which this blog usefully advertises, exposes this quite starkly (Kahnemann and Tversky et. al.) I think it's equally likely that the moral judgements of an average unreflective person who has not benefited from any moral education will likely fall short of what someone who has been morally educated would judge (moral education makes us less cruel).<br /><br />Point 2) Some LW contributors subscribe to naturalism. One way of understanding this idea is that all knowledge is scientific knowledge -I mean, knowledge of facts about the measurable, natural world. In particular, whatever there may be to know about what is rational or moral can be known only through empirical investigation -specifically, investigation of the functioning of Homo sapien's cognitive apparatus, and possibly facts about human evolution and ethology.<br /><br />The Problem: Point (1) tells us that study of what people actually think and do will not tell us what's rational or moral. Indeed, if we try to figure out, say, how to judge the probability of a heads on a toss of a fair coin given, say, 5 prior tails, merely studying what untutored <a href=\"http://en.wikipedia.org/wiki/Gambler%27s_fallacy\">people are apt to judge</a> will give us a bum steer.&nbsp; But point (2) seems to tell us that's all we are allowed. How do we augment mere cognitive science with other natural sciences, and without inadvertently simply smuggling in our values in the process, to deduce from naturalistic inquiry what's rational or moral?&nbsp; (The point as it pertains specifically to morality is argued eloquently in <a href=\"(http://www.nybooks.com/articles/archives/2011/may/12/science-right-and-wrong/\">this review</a> (esp section 3)). <br /><br />Here's a fantasy to spell out the idea. Imagine that you had a highly accurate computer model of the human cognitive apparatus, and a sufficiently powerful computer to run a great number (1000's? millions?) of instances simultaneously -and interacting as humans would- and that you could run a history of many 1000's of years of such interacting instances, related and constrained as humans are, by the modelled equivalents of births and deaths and marriages and environments. How could such a model inform the question as to what's rational or moral? Could one know that the system will reach some kind of equilibrium, say, and be justified in believing that this equilibrium state would represent rational and moral interactions?&nbsp; G.E. Moore famously <a href=\"http://plato.stanford.edu/entries/moral-non-naturalism/#NatFal\">argued</a> that one cannot analyse <em>being good</em> purely in naturalistic terms, as it will always be coherent to ask of something possessing the natural properties whether it really is good.<br /><br />And here's another way to formulate what I think is the same point. It's close to an 'analytic' truth that a belief is rational just in case you ought to hold it - 'p is rational' is just short hand for 'you ought to believe p'. But what people in fact believe notriously differs from what we ought to. So,</p>\n<ol>\n<li>How do you identify a properly scientific filter to pull out all and only the rational beliefs from all others? and,</li>\n<li>Assuming you could devise an adequate such filter, how would you give a non-question-begging, properly scientific defence of the proposition that the class of beliefs identified are exactly those which one ought to believe?</li>\n</ol>\n<p>(All this presupposes that beliefs anyway are naturalistically respectable entities -itself a doubtful assumption.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wnAWZDQxwXaHXhNo9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "7125", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T18:00:22.319Z", "modifiedAt": null, "url": null, "title": "Shifting Load to Explicit Reasoning", "slug": "shifting-load-to-explicit-reasoning", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:55.055Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_Nesov", "createdAt": "2009-02-27T09:55:13.458Z", "isAdmin": false, "displayName": "Vladimir_Nesov"}, "userId": "qf77EiaoMw7tH3GSr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oqkPRa3EL9mC72hNC/shifting-load-to-explicit-reasoning", "pageUrlRelative": "/posts/oqkPRa3EL9mC72hNC/shifting-load-to-explicit-reasoning", "linkUrl": "https://www.lesswrong.com/posts/oqkPRa3EL9mC72hNC/shifting-load-to-explicit-reasoning", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Shifting%20Load%20to%20Explicit%20Reasoning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShifting%20Load%20to%20Explicit%20Reasoning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoqkPRa3EL9mC72hNC%2Fshifting-load-to-explicit-reasoning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Shifting%20Load%20to%20Explicit%20Reasoning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoqkPRa3EL9mC72hNC%2Fshifting-load-to-explicit-reasoning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoqkPRa3EL9mC72hNC%2Fshifting-load-to-explicit-reasoning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 454, "htmlBody": "<p><strong>Related to</strong>: <a href=\"/lw/v4/which_parts_are_me/\">Which Parts Are \"Me\"?</a>, <a href=\"/lw/2yp/making_your_explicit_reasoning_trustworthy/\">Making your explicit reasoning trustworthy</a>, <a href=\"/lw/5kz/the_5second_level/\">The 5-Second Level</a>.</p>\n<p>What's damaging about <a href=\"/lw/5kz/the_5second_level\">moralizing</a> that we wish to avoid, what useful purpose does moralizing usually serve, and what allows to avoid the damage while retaining the usefulness? It engages psychological adaptations that promote conflict (by playing on social status), which are unpleasant to experience and can lead to undesirable consequences in the long run (such as feeling systematically uncomfortable interacting with a person, and so not being able to live or work or be friends with them). It serves the purpose of imprinting your values, which you feel to be right, on the people you interact with. Consequentialist elucidation of reasons for approving or disapproving of a given policy (virtue) is an effective persuasion technique if your values are actually right (for the people you try to confer them on), and it doesn't engage the same parts of your brain that make moralizing undesirable.</p>\n<p>What happens here is transfer of responsibility for important tasks from the <a href=\"/lw/v4/which_parts_are_me/\">imperfect machinery</a> that historically used to manage them (with systematic problems in any given context that <em>humans</em> but not <em>evolution</em> can notice), to explicit reasoning.<a id=\"more\"></a></p>\n<p>Taking advantage of this requires including those tasks in the scope of things that can be reasoned about (instead of <a href=\"/lw/5a9/learned_blankness/\">ignoring them</a> as not falling into your area of expertise; for example flinching from reasoning about normative questions or intuition as \"not scientific\", or \"not objective\"), and developing enough understanding to actually do better than the original heuristics (in some cases by not <em>ignoring</em> what they say), making your explicit reasoning <a href=\"/lw/2yp/making_your_explicit_reasoning_trustworthy/\">worth trusting</a>.</p>\n<p>This calls for identifying other examples of problematic modes of reasoning that engage crude psychological adaptations, and developing techniques for doing better (and making sure they are actually better before trusting them). These examples come to mind: rational argument (don't use as arguments things that you expect other person disagrees with, seek a path where every step will be accepted), allocation of responsibility (don't leave it to unvoiced tendencies to do things, discuss effort and motivation explicitly), development of <a href=\"/lw/1xh/living_luminously/\">emotional associations</a> with a given situation/person/thought (take it in your own hands, explicitly train your emotion to be what you prefer it to be, to the extent possible), learning of facts (don't rely on the stupid memory mechanisms which don't understand commands like \"this is really important, remember it\", use <a href=\"http://en.wikipedia.org/wiki/Spaced_repetition\">spaced repetition</a> systems).</p>\n<p>And the list goes on. What other cognitive tools can significantly benefit from transferring them to explicit reasoning?&nbsp;Should there be a list of problems and solutions?&nbsp;Which unsolved problems on such a list are particularly worth working on? Which problems with known solutions should be fixed (in any given person) as soon as possible? How do we better facilitate training?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"QT87jxkk6DXuS8hGA": 9}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oqkPRa3EL9mC72hNC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 25, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "7243", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vjmw8tW6wZAtNJMKo", "m5AH78nscsGjMbBwv", "JcpzFpPBSmzuksmWM", "puhPJimawPuNZ5wAR", "9o3Cjjem7AbmmZfBs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-07T18:36:13.570Z", "modifiedAt": null, "url": null, "title": "[Altruist Support] Fix the SIAI's website (EDIT: or not. I'll do it)", "slug": "altruist-support-fix-the-siai-s-website-edit-or-not-i-ll-do", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:59.737Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Giles", "createdAt": "2011-02-11T02:30:16.999Z", "isAdmin": false, "displayName": "Giles"}, "userId": "H347ba3KZMP8XoDt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Tqhm6jsFqs7ZDwX5H/altruist-support-fix-the-siai-s-website-edit-or-not-i-ll-do", "pageUrlRelative": "/posts/Tqhm6jsFqs7ZDwX5H/altruist-support-fix-the-siai-s-website-edit-or-not-i-ll-do", "linkUrl": "https://www.lesswrong.com/posts/Tqhm6jsFqs7ZDwX5H/altruist-support-fix-the-siai-s-website-edit-or-not-i-ll-do", "postedAtFormatted": "Saturday, May 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BAltruist%20Support%5D%20Fix%20the%20SIAI's%20website%20(EDIT%3A%20or%20not.%20I'll%20do%20it)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BAltruist%20Support%5D%20Fix%20the%20SIAI's%20website%20(EDIT%3A%20or%20not.%20I'll%20do%20it)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqhm6jsFqs7ZDwX5H%2Faltruist-support-fix-the-siai-s-website-edit-or-not-i-ll-do%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BAltruist%20Support%5D%20Fix%20the%20SIAI's%20website%20(EDIT%3A%20or%20not.%20I'll%20do%20it)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqhm6jsFqs7ZDwX5H%2Faltruist-support-fix-the-siai-s-website-edit-or-not-i-ll-do", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqhm6jsFqs7ZDwX5H%2Faltruist-support-fix-the-siai-s-website-edit-or-not-i-ll-do", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 668, "htmlBody": "<p><span style=\"color: #ff0000;\">EDIT: This post no longer reflects my current attitude. I'm now signed up as a volunteer for SIAI and will help them with the website and/or whatever else needs doing. Add a comment or contact me if you're curious as to what my attitude was or why it changed.</span></p>\n<p><em>What I've learnt: People want something more specific</em></p>\n<p><em>What I've also learnt: Not to commit to donating money to an organization without carefully reading their website first</em></p>\n<p>Imagine you are a prospective SIAI donor. You've learnt about AI and its risks, about how hardly anyone takes these risks seriously, about how people are fundamentally not mentally equipped to handle issues of existential risk in a sane way. You've looked around and seen that the SIAI is the only (or one of just a few) organizations that appear to realise this and want to do anything about it.</p>\n<p>So you go to their website. What are you looking for? You're looking for a reason <em>not to give money to them</em>.</p>\n<p><a href=\"http://intelligence.org/overview/whyworktowardthesingularity\">Here's one</a>:</p>\n<blockquote>\n<p>The Singularity Institute exists to carry out the mission of the Singularity-aware &ndash; to accelerate the arrival of the Singularity in order to hasten its human benefits; ...</p>\n</blockquote>\n<p>This seems a somewhat gung-ho attitude which is not consistent with the message on the rest of the site. And this isn't just my misreading or quoting out of context - apparently that page is <em>very </em>out of date and no longer represents the worldview of the more mature, grown up SIAI.</p>\n<p>But people reading the site don't know that. And remember, they're looking for reasons not to give - for reasons to retreat back to their comfort zone where everything's basically OK and the SIAI are just a bunch of weirdos.</p>\n<p>The fact that an organization dedicated to shaping the future of humanity can't keep their website up to date would seem to be one of those reasons.</p>\n<p>So, if you <a href=\"/lw/i4/belief_in_belief/\">really believe</a> the SIAI to be the most effective charity right now, you should help them by offering to fix their website for them - in order to help attract more donors.</p>\n<p>Some possible objections and counter-objections:</p>\n<p><strong>1. If Giles thinks fixing the SIAI's website is so important, he'd already be doing it himself.</strong></p>\n<p>Essentially this boils down to the fact that you probably trust the SIAI a lot more than I do. So for me the community-building effort is the higher priority.</p>\n<p><strong>2. If the website was so important, the SIAI would already have fixed it. Better just to give them money and they'll spend it on fixing the website when it's optimal to do so.</strong></p>\n<p>This assumes that the SIAI behaves in a perfectly rational way. It also ignores the fact that people are going to look at their accounts and try to find evidence that they are actually engaging in saving-the-world type activities. If all they do is \"fix our own website and make ourselves look good\" then no-one's going to take them seriously. By donating your time to improve their website, you keep that activity off the balance sheet.</p>\n<p><strong>3. There are so many more important factors keeping people away from donating to the SIAI. Surely better to address those first?</strong></p>\n<p>Maybe - but they need to be fixed one at a time. And I believe the website to be a single point of failure - even people who are otherwise really keen might be put off by a single strange-sounding sentence appearing on the website.</p>\n<p>Conclusion:</p>\n<p>I don't think the website needs a big overhaul or a massive amount of new information. It just needs a little thought as to people's questions and concerns. Other than the page I mentioned, possible concerns might be:</p>\n<p>- All of the issues that arose in the <a href=\"/lw/5k5/givewellorg_interviews_siai/\">GiveWell interview</a></p>\n<p>- A recognition of the non-strawman criticisms of the SIAI and how they are being addressed</p>\n<p>- An answer to the only-game-in-town question: if we recognise that the SIAI is the only organization seriously addressing these issues but aren't sure of its effectiveness, are we better off giving now or waiting for a more effective organization to come along?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Tqhm6jsFqs7ZDwX5H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 15, "extendedScore": null, "score": 7.117457436238273e-07, "legacy": true, "legacyId": "7244", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><span style=\"color: #ff0000;\">EDIT: This post no longer reflects my current attitude. I'm now signed up as a volunteer for SIAI and will help them with the website and/or whatever else needs doing. Add a comment or contact me if you're curious as to what my attitude was or why it changed.</span></p>\n<p><em>What I've learnt: People want something more specific</em></p>\n<p><em>What I've also learnt: Not to commit to donating money to an organization without carefully reading their website first</em></p>\n<p>Imagine you are a prospective SIAI donor. You've learnt about AI and its risks, about how hardly anyone takes these risks seriously, about how people are fundamentally not mentally equipped to handle issues of existential risk in a sane way. You've looked around and seen that the SIAI is the only (or one of just a few) organizations that appear to realise this and want to do anything about it.</p>\n<p>So you go to their website. What are you looking for? You're looking for a reason <em>not to give money to them</em>.</p>\n<p><a href=\"http://intelligence.org/overview/whyworktowardthesingularity\">Here's one</a>:</p>\n<blockquote>\n<p>The Singularity Institute exists to carry out the mission of the Singularity-aware \u2013 to accelerate the arrival of the Singularity in order to hasten its human benefits; ...</p>\n</blockquote>\n<p>This seems a somewhat gung-ho attitude which is not consistent with the message on the rest of the site. And this isn't just my misreading or quoting out of context - apparently that page is <em>very </em>out of date and no longer represents the worldview of the more mature, grown up SIAI.</p>\n<p>But people reading the site don't know that. And remember, they're looking for reasons not to give - for reasons to retreat back to their comfort zone where everything's basically OK and the SIAI are just a bunch of weirdos.</p>\n<p>The fact that an organization dedicated to shaping the future of humanity can't keep their website up to date would seem to be one of those reasons.</p>\n<p>So, if you <a href=\"/lw/i4/belief_in_belief/\">really believe</a> the SIAI to be the most effective charity right now, you should help them by offering to fix their website for them - in order to help attract more donors.</p>\n<p>Some possible objections and counter-objections:</p>\n<p><strong id=\"1__If_Giles_thinks_fixing_the_SIAI_s_website_is_so_important__he_d_already_be_doing_it_himself_\">1. If Giles thinks fixing the SIAI's website is so important, he'd already be doing it himself.</strong></p>\n<p>Essentially this boils down to the fact that you probably trust the SIAI a lot more than I do. So for me the community-building effort is the higher priority.</p>\n<p><strong id=\"2__If_the_website_was_so_important__the_SIAI_would_already_have_fixed_it__Better_just_to_give_them_money_and_they_ll_spend_it_on_fixing_the_website_when_it_s_optimal_to_do_so_\">2. If the website was so important, the SIAI would already have fixed it. Better just to give them money and they'll spend it on fixing the website when it's optimal to do so.</strong></p>\n<p>This assumes that the SIAI behaves in a perfectly rational way. It also ignores the fact that people are going to look at their accounts and try to find evidence that they are actually engaging in saving-the-world type activities. If all they do is \"fix our own website and make ourselves look good\" then no-one's going to take them seriously. By donating your time to improve their website, you keep that activity off the balance sheet.</p>\n<p><strong id=\"3__There_are_so_many_more_important_factors_keeping_people_away_from_donating_to_the_SIAI__Surely_better_to_address_those_first_\">3. There are so many more important factors keeping people away from donating to the SIAI. Surely better to address those first?</strong></p>\n<p>Maybe - but they need to be fixed one at a time. And I believe the website to be a single point of failure - even people who are otherwise really keen might be put off by a single strange-sounding sentence appearing on the website.</p>\n<p>Conclusion:</p>\n<p>I don't think the website needs a big overhaul or a massive amount of new information. It just needs a little thought as to people's questions and concerns. Other than the page I mentioned, possible concerns might be:</p>\n<p>- All of the issues that arose in the <a href=\"/lw/5k5/givewellorg_interviews_siai/\">GiveWell interview</a></p>\n<p>- A recognition of the non-strawman criticisms of the SIAI and how they are being addressed</p>\n<p>- An answer to the only-game-in-town question: if we recognise that the SIAI is the only organization seriously addressing these issues but aren't sure of its effectiveness, are we better off giving now or waiting for a more effective organization to come along?</p>\n<p>&nbsp;</p>", "sections": [{"title": "1. If Giles thinks fixing the SIAI's website is so important, he'd already be doing it himself.", "anchor": "1__If_Giles_thinks_fixing_the_SIAI_s_website_is_so_important__he_d_already_be_doing_it_himself_", "level": 1}, {"title": "2. If the website was so important, the SIAI would already have fixed it. Better just to give them money and they'll spend it on fixing the website when it's optimal to do so.", "anchor": "2__If_the_website_was_so_important__the_SIAI_would_already_have_fixed_it__Better_just_to_give_them_money_and_they_ll_spend_it_on_fixing_the_website_when_it_s_optimal_to_do_so_", "level": 1}, {"title": "3. There are so many more important factors keeping people away from donating to the SIAI. Surely better to address those first?", "anchor": "3__There_are_so_many_more_important_factors_keeping_people_away_from_donating_to_the_SIAI__Surely_better_to_address_those_first_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "17 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CqyJzDZWvGhhFJ7dY", "EyFNgmgkB6rZcgNrv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T00:11:36.687Z", "modifiedAt": null, "url": null, "title": "Religious Behaviorism", "slug": "religious-behaviorism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:07.259Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mLky3Muhqp8crS8J7/religious-behaviorism", "pageUrlRelative": "/posts/mLky3Muhqp8crS8J7/religious-behaviorism", "linkUrl": "https://www.lesswrong.com/posts/mLky3Muhqp8crS8J7/religious-behaviorism", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Religious%20Behaviorism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReligious%20Behaviorism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmLky3Muhqp8crS8J7%2Freligious-behaviorism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Religious%20Behaviorism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmLky3Muhqp8crS8J7%2Freligious-behaviorism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmLky3Muhqp8crS8J7%2Freligious-behaviorism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1215, "htmlBody": "<p>Willard Quine described, in his article \"Ontological Relativity\" (Journal of Philosophy 65(7):185-212), his doctrine of the <a href=\"http://en.wikipedia.org/wiki/Indeterminacy_of_translation\">indeterminability of translation</a>.&nbsp; Roughly, this says that words are meaningful (a collection of words emitted by an agent can help predict that agent's actions), but don't have meanings (any word taken by itself corresponds to nothing at all; there is no correspondence between the word \"rabbit\" and the <a title=\"Leporidae\" href=\"http://en.wikipedia.org/wiki/Leporidae\">Leporidae</a>).</p>\r\n<p>In Quine's words,</p>\r\n<blockquote>\r\n<p>Seen according to the museum myth, the words and sentences of a language have their determinate meanings. To discover the meanings of the native's words we may have to observe his behavior, but still the meanings of the words are supposed to be determinate in the native's mind, his mental museum, even in cases where behavioral criteria are powerless to discover them for us. When on the other hand we recognize with Dewey that \"meaning. . . is primarily a property of behavior,\" we recognize that there are no meanings, nor likenesses nor distinctions of meaning, beyond what are implicit in people's dispositions to overt behavior. For naturalism the question whether two expressions are alike or unlike in meaning has no determinate answer, known or unknown, except insofar as the answer is settled in principle by people's speech dispositions, known or unknown.</p>\r\n</blockquote>\r\n<p>Quine got my hackles up by using the word \"naturalism\" when he meant \"behaviorism\", implicitly claiming that naturalistic science was synonymous (or would be, if he believed in synonyms) with behaviorism.&nbsp; But I'll try to remain impartial.&nbsp; (Quine's timing was curious; Chomsky had demolished behaviorist linguistics in 1959, nine years before Quine's article.)</p>\r\n<p>Quine's basic idea is insightful.&nbsp; To phrase it in non-behaviorist terms:&nbsp; If all words are defined in terms of other words, how does meaning get into that web of words?&nbsp; Can we unambiguously determine the correct mapping between words and meanings?</p>\r\n<p>Quine's response was to deny that that is an empirical question.&nbsp; He said you should not even talk about meaning; you can only observe behavior.&nbsp; You must remain agnostic about anything inside the head.</p>\r\n<p>But it is an empirical question.&nbsp; With math, plus with some reasonable assumptions, you can prove that you can <a href=\"http://www.google.com/url?sa=t&amp;source=web&amp;cd=6&amp;ved=0CDUQFjAF&amp;url=http%3A%2F%2Flesswrong.com%2Flw%2F1mf%2Fa_lower_bound_for_consciousness%2F&amp;rct=j&amp;q=philgoetz%20site%3Alesswrong.com%20consciousness&amp;ei=ydjFTZCRDonh0QHMpP2iCA&amp;usg=AFQjCNF8Ydhc1uUyDk3TrNvuf2m_YkiQdA&amp;cad=rja\">unambiguously determine the correct mapping</a> even from the outside.&nbsp; In a world where you can tell someone to think of a square, and then use functional magnetic resonance imaging and find a pattern of neurons lit up in a square on his visual cortex, it is difficult to agree with Quine that the word \"square\" has no meaning.</p>\r\n<p>You may protest that I'm thinking there is a homunculus inside the mind looking at that square.&nbsp; After all, Quine already knew that the image of a square would be imprinted in some way on the retina of a person looking at a square.&nbsp; But I am not assuming there is a homunculus inside the brain.&nbsp; I am just observing a <em>re-presentation</em> inside the brain.&nbsp; We can continue the behaviorist philosophy of saying that words are ultimately defined by behavior.&nbsp; But there is no particular reason to stop our analyses when we hit the skull.&nbsp; Behaviors outside the skull are systematically reflected in physical changes inside the skull, and we can investigate them and reason about them.</p>\r\n<p>The more I tried to figure out what Quine meant - sorry, Quine - the more it puzzled me.&nbsp; I'm with him as far as asking whether meanings are ambiguous.&nbsp; But Quine doesn't just say meaning is ambiguous.&nbsp; He says \"there are no meanings... beyond what are implicit in... behavior\".&nbsp; The more I read, the more it seemed Quine was insisting, not that meaning was ambiguous, but that mental states do not exist - or that they are <em>taboo</em>.&nbsp; And this taboo centered on the skull.</p>\r\n<p>That seemed to come from a religious frame.&nbsp; So I stopped trying to think of a rational justification for Quine's position, and starting looking for an emotional one.&nbsp; And I may have found it.<a id=\"more\"></a></p>\r\n<p>Behaviorists claimed that they forbade reasoning about states that were not observable by behaviors.&nbsp; But what they forbade, in practice, was reasoning about states that were <em>inside the skull</em>, whether or not they were observable.&nbsp; They did not say that we did not yet have the technology to study the effects of stimuli on the brain (we <a href=\"http://en.wikipedia.org/wiki/Electroencephalography#History\">did</a>).&nbsp; They said there were no mental objects inside the brain.</p>\r\n<p>This got me wondering what a behaviorist means by a mental object.&nbsp; To me, meaning is something that gets more and more definite the more you know about how brain states correspond to environmental states.&nbsp; \"Ambiguity\" is not a binary predicate; it's&nbsp;the number of possible solutions, or the variance of a probability distribution.&nbsp; But to them, meaning is something that is not approximated or approached, but that you either do or do not apprehend.&nbsp; And, no matter how far back you trace the causal chain, you will never arrive at it.&nbsp; It's pure, possibly atomic... transcendental.</p>\r\n<p>They mean the soul.</p>\r\n<p>Most religious are closely associated with the idea of the immaterial, and more specifically, an immaterial soul that contains a person's essence.&nbsp; Modern re-interpretations of this idea, from Descartes to John Searle, seek to locate the soul within the brain.&nbsp; The soul is a way to protect the human mind, and free will,&nbsp;from reductionism.</p>\r\n<p>Historically, I was taught, behaviorism arose as a response to intuitionism, which took people's thoughts about their thoughts as evidence.&nbsp; It was a methodology designed to rule out errors caused by intuitionism.</p>\r\n<p>But behaviorists went much farther than that.&nbsp; They didn't try to delimit the situations where intuitions were useful, or where one could talk about mental structure or content.&nbsp; They insisted that all talk of mental representations or computations were taboo.&nbsp; They were at odds even with the science that already existed at the time.&nbsp; It was already known, though not with much precision, that damage to particular parts of the brain caused particular mental malfunctions; as did brain diseases with different histopathologies.</p>\r\n<p>So perhaps this original, good methodological idea fell victim to a nearby, stronger attractor:&nbsp; Behaviorism became the flip side of the concept of the soul.&nbsp; You can try to protect the mind from reductionism by encapsulating it in a soul.&nbsp; Or you can protect the mind from reductionism by denying that it exists.&nbsp; (You can talk about my behaviors all you want; just don't look inside my skull.)</p>\r\n<p>I wouldn't say that everyone who called themselves a behaviorist had religious motivations.&nbsp; But perhaps there was a dangerous synergy between his rationalist doctrine, and a parasitic religious one.</p>\r\n<p>But B.F. Skinner, not the earliest but the most well-known evangelist of behaviorism, does not strike me as a religious man.&nbsp; And Skinner denied the existence of free will, which is the opposite of what I expect people trying to protect the mind from scrutiny&nbsp;to say.</p>\r\n<p>So&nbsp;here is an alternative theory:&nbsp; Behaviorists were religious cynics.</p>\r\n<p>A&nbsp;cynic&nbsp;promulgates views that sound sociopathic.&nbsp; Yet a cynic is not a sociopath.&nbsp; Sociopaths are not bitter about failing to find cosmic meaning in the world around them.&nbsp; Cynics are idealists who want too much from their ideals - realists longing for the transcendantal.</p>\r\n<p>Seen through this analogy, behaviorism is a defense of the soul by people who don't really believe it exists; a denial of free will that&nbsp;doesn't solve the tough philosophical problem, but tells people to look away:&nbsp;\"Move along, nothing to see here\".&nbsp; Like religion, it justifies not thinking about threatening philosophical questions.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mLky3Muhqp8crS8J7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -3, "extendedScore": null, "score": 7.118422891524414e-07, "legacy": true, "legacyId": "7245", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T07:00:38.842Z", "modifiedAt": null, "url": null, "title": "[POLL] Slutwalk", "slug": "poll-slutwalk", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.550Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "magfrump", "createdAt": "2009-12-10T20:51:45.065Z", "isAdmin": false, "displayName": "magfrump"}, "userId": "KsYFs5ip5jeiFETJa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/orWpFfj4Wm78BmnAQ/poll-slutwalk", "pageUrlRelative": "/posts/orWpFfj4Wm78BmnAQ/poll-slutwalk", "linkUrl": "https://www.lesswrong.com/posts/orWpFfj4Wm78BmnAQ/poll-slutwalk", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BPOLL%5D%20Slutwalk&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BPOLL%5D%20Slutwalk%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2ForWpFfj4Wm78BmnAQ%2Fpoll-slutwalk%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BPOLL%5D%20Slutwalk%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2ForWpFfj4Wm78BmnAQ%2Fpoll-slutwalk", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2ForWpFfj4Wm78BmnAQ%2Fpoll-slutwalk", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 332, "htmlBody": "<p>I recently heard about the upcoming event (or set of events) Slutwalk. &nbsp;I realize that this is somewhat political and may have some mind-killing effects, but my main interest is in the Less Wrong reaction to the idea. &nbsp;From the wikipedia page[1]:</p>\n<p><span style=\"font-size: 13px; line-height: 19px; font-family: sans-serif;\"><span style=\"font-family: mceinline;\">The \"Toronto Slut Walk\" refers to a protest held on April 3, 2011 in&nbsp;<span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial;\">Toronto</span></span>. Protesters walked from&nbsp;<span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial;\">Queen's Park (Toronto)</span></span>&nbsp;to the&nbsp;<span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial;\">Toronto Police Headquarters</span></span>&nbsp;located on Central Street&nbsp;<sup id=\"cite_ref-0\" class=\"reference\" style=\"line-height: 1em; font-weight: normal; font-style: normal;\"><span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; white-space: nowrap;\">[1]</span></span></sup>. These protesters were dressed in revealing clothing and holding signs in order to reject the belief that female rape victims are \"asking for it\"<sup id=\"cite_ref-1\" class=\"reference\" style=\"line-height: 1em; font-weight: normal; font-style: normal;\"><span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; white-space: nowrap;\">[2]</span></span></sup>. They marched in response to remarks made by a&nbsp;<span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial;\">Toronto</span></span>&nbsp;police officer and judge. Women are also organizing other \"slut walks\" around&nbsp;<span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial;\">Canada</span></span>&nbsp;and the&nbsp;<span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial;\">United States</span></span><sup id=\"cite_ref-2\" class=\"reference\" style=\"line-height: 1em; font-weight: normal; font-style: normal;\"><span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; white-space: nowrap;\">[3]</span></span></sup><sup id=\"cite_ref-3\" class=\"reference\" style=\"line-height: 1em; font-weight: normal; font-style: normal;\"><span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; white-space: nowrap;\">[4]</span></span></sup>, including one scheduled for August 20th, 2011 in&nbsp;<span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial;\">New York City</span></span><sup id=\"cite_ref-4\" class=\"reference\" style=\"line-height: 1em; font-weight: normal; font-style: normal;\"><span style=\"color: #0645ad;\"><span style=\"background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; white-space: nowrap;\">[5]</span></span></sup>.</span></span></p>\n<p>Before continuing to read, please answer the poll below as to how you feel about the idea of the \"Slutwalk.\"</p>\n<p>&nbsp;</p>\n<p>I have many friends who are involved with the Slutwalk and my first impression is that it is a good idea; that framing and terminology, if not a strong part of policy decisions, can have large effects on personal wellbeing. &nbsp;Also that while dressing more modestly may have some effect on sexual assault, having an authority put any onus of a crime on a victim harshly reduces the disincentive for perpetrators.</p>\n<p>On the other hand, I have been known to be clueless before in matters of activism, and I recall that Robin Hanson has made cutting remarks about protest being about attracting mates and making a show of identifying with groups, and this certainly seems like it could fit that description to a T. &nbsp;So I am curious what others' reactions are.</p>\n<p>This is a political issue, and we all know <a href=\"/lw/gw/politics_is_the_mindkiller/\">politics is the mind-killer</a>, so I would mostly like to see what people think of this idea; specifically whether it is controversial, heavily supported, or heavily disapproved of.</p>\n<p>I will attempt to reformat if I can figure out how to work the formatting.</p>\n<p>EDIT: Rephrased poll options and removed references to clusters, at popular request.</p>\n<p>References:</p>\n<p>[1]:&nbsp;<a href=\"http://en.wikipedia.org/wiki/Toronto_Slutwalk\">http://en.wikipedia.org/wiki/Toronto_Slutwalk</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "orWpFfj4Wm78BmnAQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": -18, "extendedScore": null, "score": -2.1e-05, "legacy": true, "legacyId": "7246", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9weLK2AJ9JEt2Tt8f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T08:13:31.325Z", "modifiedAt": null, "url": null, "title": "Book Review: Predictably Irrational by Dan Ariely", "slug": "book-review-predictably-irrational-by-dan-ariely", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.316Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "erratio", "createdAt": "2010-06-29T09:32:42.768Z", "isAdmin": false, "displayName": "erratio"}, "userId": "ty7er2ZYEnPYALnnJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fo5rNAQAJjnDQ5GAk/book-review-predictably-irrational-by-dan-ariely", "pageUrlRelative": "/posts/fo5rNAQAJjnDQ5GAk/book-review-predictably-irrational-by-dan-ariely", "linkUrl": "https://www.lesswrong.com/posts/fo5rNAQAJjnDQ5GAk/book-review-predictably-irrational-by-dan-ariely", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Book%20Review%3A%20Predictably%20Irrational%20by%20Dan%20Ariely&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABook%20Review%3A%20Predictably%20Irrational%20by%20Dan%20Ariely%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffo5rNAQAJjnDQ5GAk%2Fbook-review-predictably-irrational-by-dan-ariely%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Book%20Review%3A%20Predictably%20Irrational%20by%20Dan%20Ariely%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffo5rNAQAJjnDQ5GAk%2Fbook-review-predictably-irrational-by-dan-ariely", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffo5rNAQAJjnDQ5GAk%2Fbook-review-predictably-irrational-by-dan-ariely", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1323, "htmlBody": "<p>I'm ambivalent about recommending this book to LW readers. On the one hand, it's well-written and has lots of interesting anecdotes about Ariely's experiments. He also includes a full reference list at the end of all the papers published based on the studies he describes in the book, which is nice. On the other hand, almost none of the material should be really new to most people here, and a lot of the chapters turned out to be summarisable in a single sentence, indicating a large amount of fluff.</p>\n<p>Anyway, I spent a couple of hours today writing up a quick summary of each chapter, and have included my notes below.</p>\n<h4>Chapter 1 - Everything is relative</h4>\n<p>When presented with multiple options, some of which are similar to each other and some of which are in separate reference classes, people will consistently pick the best option from the set of similar options because they are directly comparable. Similarly, the use of decoy options when offering products will influence their choices - including a ludicrously expensive option makes the others look good by comparison, and when offering three choices in the same reference class the majority of consumers will pick the middle one.</p>\n<h4>Chapter 2 - Supply and demand:</h4>\n<p>Examines the anchoring effect. People asked to list the last two digits of their Social Security number unconsciously used that number as an anchor when bidding for various items later. Black pearls went from worthless to priceless after being displayed next to other high-priced gemstones. When sequentially given 3 different anchoring points, people stuck to the first one presented even if the later ones would have been more beneficial for them. It is also possible to self-anchor, ie. if I buy something expensive despite a previous habit of being cheap, I am now more likely to buy something expensive again because I use my own novel behaviour as an anchor.</p>\n<p><span style=\"font-size: 14px; font-weight: bold;\">Chapter 3 - The power of FREE!</span></p>\n<p>People are irrationally attached to getting free stuff. In one experiment, he set up a table where they had high-quality chocolate for 15c and low-quality for 1c, and most people chose the high-quality ones. But when they decreased each price by 1c, so that it was 14c versus free, most people chose the free ones (and in another experiment they controlled for the inconvenience of getting money out for one but not the other and got the same result). People will also buy more books in order to get free shipping, buy food with zero sugar over food with a negligible amount of sugar, buy the wrong car for their needs because it comes with free oil changes, and so on.</p>\n<p><span style=\"font-size: 14px; font-weight: bold;\">Chapter 4 - The cost of social norms</span></p>\n<p>People don&rsquo;t like comparing social value and market value directly and mixing the two has negative social consequences, as the social norms dissolve permanently as soon as market norms are introduced. People were asked to perform a task either for a low payoff, high payoff, or as a favour. People doing the task as a favour performed around the same level as the high-payoff group. Gifts with explicit monetary values are treated as though they are money, whereas gifts without an explicit value attached are treated as social currency. Ariely suggests that we should try to create more social norms rather than focussing on numerical measures such as money and grades.</p>\n<h4>Chapter 5 - The influence of arousal</h4>\n<p>Students were asked to imagine that they were aroused and answer various questions about his sexual preferences, moral behaviours with respect to sex, and likelihood of engaging unsafe sex as though they were aroused. They were then asked to answer a similar set of questions while actually aroused. The results showed that people are terrible at predicting how their preferences will change under the influence of emotion - they were much more likely to engage in immoral or unsafe behaviour and to find various fetishes exciting while aroused than they had predicted.</p>\n<h4>Chapter 6 - Procrastination and self-control</h4>\n<p>Students in Ariely&rsquo;s classes performed better when given deadlines spaced throughout the term than when the only deadline was the last day of term for all three assignments they had to write. Ariely advises measures such as precommitting to dates with penalties in grades or money for not meeting them, making tasks as simple as possible to reduce confusion-driven procrastination (ie. remove trivial inconveniences), and to blog or otherwise publicise the things you need to do so as to make yourself feel accountable.</p>\n<h4>Chapter 7 - The high price of ownership</h4>\n<p>People systematically overvalue what they own, for example students who won a lottery for tickets to a big basketball game asked for an average of $2400 for their tickets, while students who lost the lottery were willing to offer an average of $175 to buy one. People are highly loss-aversive.</p>\n<h4>Chapter 8 - Why options are distracting</h4>\n<p>People are terrible at dealing with opportunity costs; even when given the expected values for each option available they will still try to experience all options &lsquo;just in case&rsquo;. Conversely, when an opportunity cost isn&rsquo;t obvious, people will often neglect options that they should be paying attention to, eg. parents missing time with their young children because the opportunity of experiencing their childhoods isn&rsquo;t salient enough. Ariely suggests we should drop as many options as we can, because they drain our energy and commitment from the options that we&rsquo;ve decided to pursue. People are also bad at taking into account the consequences of indecision, Ariely recounts a friend who wasted three months trying to decide between two nearly identical digital cameras when he should have just picked one and then taken lots of cool photos during those three months.</p>\n<h4>Chapter 9 - The effect of expectations</h4>\n<p>Peoples expectations affect their perception. eg. people seeing condiments in fancy containers were more likely to enjoy their coffee, people supporting opposite sports teams will have different opinions about contentious plays, and so forth. People&rsquo;s behaviour can be influenced by stereotypes, even when the stereotype isn&rsquo;t directly about them (students primed with words related to old people walked down the hallway slowly compared to the control group) but especially strongly when it is about them (asian women performed better or worse than average on maths tests depended on whether they were reminded of their Asian-ness or female-ness).</p>\n<h4>Chapter 10 - The power of price</h4>\n<p>The placebo effect is influenced by price, such that almost all participants given a fake painkiller supposedly costing $2.50 per pill reported pain relief, while only half the participants reported pain relief from a 10c pill. The effect was particularly strong for people with chronic pain (ie. who cared the most about whether the pills were effective or not)</p>\n<h4>Chapter 11 - The context of our character part I</h4>\n<p>If you provide people with an opportunity to cheat and not get caught, they will, but only up to a certain point. Providing more temptation after that point has no further effect on behaviour. When people are asked to read an honour pledge or the Ten Commandments, they will act more honestly for a short time afterwards even in the absence of visible accountability.</p>\n<h4>Chapter 12 - The context of our character part II</h4>\n<p>When Ariely left Cokes in dorm fridges, they disappeared within 72 hours. When he did the same thing with $1 bills, no one touched them, because people take money more seriously. When monetary rewards in a test were replaced with tokens that were redeemed a few seconds later for cash, students given an opportunity to cheat cheated around twice as much as students given the opportunity to cheat but given their money directly. Lots of further anecdotes about how the further removed the money is from a process, the easier it is to justify dishonesty.</p>\n<h4>Chapter 13 - Beer and free lunches</h4>\n<p>People use public ordering as an opportunity to signal uniqueness or conformity, even if this means ordering a dish or drink that they don&rsquo;t actually want.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4Kcm4etxAJjmeDkHP": 2, "4R8JYu4QF2FqzJxE5": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fo5rNAQAJjnDQ5GAk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 47, "extendedScore": null, "score": 0.000105, "legacy": true, "legacyId": "7247", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I'm ambivalent about recommending this book to LW readers. On the one hand, it's well-written and has lots of interesting anecdotes about Ariely's experiments. He also includes a full reference list at the end of all the papers published based on the studies he describes in the book, which is nice. On the other hand, almost none of the material should be really new to most people here, and a lot of the chapters turned out to be summarisable in a single sentence, indicating a large amount of fluff.</p>\n<p>Anyway, I spent a couple of hours today writing up a quick summary of each chapter, and have included my notes below.</p>\n<h4 id=\"Chapter_1___Everything_is_relative\">Chapter 1 - Everything is relative</h4>\n<p>When presented with multiple options, some of which are similar to each other and some of which are in separate reference classes, people will consistently pick the best option from the set of similar options because they are directly comparable. Similarly, the use of decoy options when offering products will influence their choices - including a ludicrously expensive option makes the others look good by comparison, and when offering three choices in the same reference class the majority of consumers will pick the middle one.</p>\n<h4 id=\"Chapter_2___Supply_and_demand_\">Chapter 2 - Supply and demand:</h4>\n<p>Examines the anchoring effect. People asked to list the last two digits of their Social Security number unconsciously used that number as an anchor when bidding for various items later. Black pearls went from worthless to priceless after being displayed next to other high-priced gemstones. When sequentially given 3 different anchoring points, people stuck to the first one presented even if the later ones would have been more beneficial for them. It is also possible to self-anchor, ie. if I buy something expensive despite a previous habit of being cheap, I am now more likely to buy something expensive again because I use my own novel behaviour as an anchor.</p>\n<p><span style=\"font-size: 14px; font-weight: bold;\">Chapter 3 - The power of FREE!</span></p>\n<p>People are irrationally attached to getting free stuff. In one experiment, he set up a table where they had high-quality chocolate for 15c and low-quality for 1c, and most people chose the high-quality ones. But when they decreased each price by 1c, so that it was 14c versus free, most people chose the free ones (and in another experiment they controlled for the inconvenience of getting money out for one but not the other and got the same result). People will also buy more books in order to get free shipping, buy food with zero sugar over food with a negligible amount of sugar, buy the wrong car for their needs because it comes with free oil changes, and so on.</p>\n<p><span style=\"font-size: 14px; font-weight: bold;\">Chapter 4 - The cost of social norms</span></p>\n<p>People don\u2019t like comparing social value and market value directly and mixing the two has negative social consequences, as the social norms dissolve permanently as soon as market norms are introduced. People were asked to perform a task either for a low payoff, high payoff, or as a favour. People doing the task as a favour performed around the same level as the high-payoff group. Gifts with explicit monetary values are treated as though they are money, whereas gifts without an explicit value attached are treated as social currency. Ariely suggests that we should try to create more social norms rather than focussing on numerical measures such as money and grades.</p>\n<h4 id=\"Chapter_5___The_influence_of_arousal\">Chapter 5 - The influence of arousal</h4>\n<p>Students were asked to imagine that they were aroused and answer various questions about his sexual preferences, moral behaviours with respect to sex, and likelihood of engaging unsafe sex as though they were aroused. They were then asked to answer a similar set of questions while actually aroused. The results showed that people are terrible at predicting how their preferences will change under the influence of emotion - they were much more likely to engage in immoral or unsafe behaviour and to find various fetishes exciting while aroused than they had predicted.</p>\n<h4 id=\"Chapter_6___Procrastination_and_self_control\">Chapter 6 - Procrastination and self-control</h4>\n<p>Students in Ariely\u2019s classes performed better when given deadlines spaced throughout the term than when the only deadline was the last day of term for all three assignments they had to write. Ariely advises measures such as precommitting to dates with penalties in grades or money for not meeting them, making tasks as simple as possible to reduce confusion-driven procrastination (ie. remove trivial inconveniences), and to blog or otherwise publicise the things you need to do so as to make yourself feel accountable.</p>\n<h4 id=\"Chapter_7___The_high_price_of_ownership\">Chapter 7 - The high price of ownership</h4>\n<p>People systematically overvalue what they own, for example students who won a lottery for tickets to a big basketball game asked for an average of $2400 for their tickets, while students who lost the lottery were willing to offer an average of $175 to buy one. People are highly loss-aversive.</p>\n<h4 id=\"Chapter_8___Why_options_are_distracting\">Chapter 8 - Why options are distracting</h4>\n<p>People are terrible at dealing with opportunity costs; even when given the expected values for each option available they will still try to experience all options \u2018just in case\u2019. Conversely, when an opportunity cost isn\u2019t obvious, people will often neglect options that they should be paying attention to, eg. parents missing time with their young children because the opportunity of experiencing their childhoods isn\u2019t salient enough. Ariely suggests we should drop as many options as we can, because they drain our energy and commitment from the options that we\u2019ve decided to pursue. People are also bad at taking into account the consequences of indecision, Ariely recounts a friend who wasted three months trying to decide between two nearly identical digital cameras when he should have just picked one and then taken lots of cool photos during those three months.</p>\n<h4 id=\"Chapter_9___The_effect_of_expectations\">Chapter 9 - The effect of expectations</h4>\n<p>Peoples expectations affect their perception. eg. people seeing condiments in fancy containers were more likely to enjoy their coffee, people supporting opposite sports teams will have different opinions about contentious plays, and so forth. People\u2019s behaviour can be influenced by stereotypes, even when the stereotype isn\u2019t directly about them (students primed with words related to old people walked down the hallway slowly compared to the control group) but especially strongly when it is about them (asian women performed better or worse than average on maths tests depended on whether they were reminded of their Asian-ness or female-ness).</p>\n<h4 id=\"Chapter_10___The_power_of_price\">Chapter 10 - The power of price</h4>\n<p>The placebo effect is influenced by price, such that almost all participants given a fake painkiller supposedly costing $2.50 per pill reported pain relief, while only half the participants reported pain relief from a 10c pill. The effect was particularly strong for people with chronic pain (ie. who cared the most about whether the pills were effective or not)</p>\n<h4 id=\"Chapter_11___The_context_of_our_character_part_I\">Chapter 11 - The context of our character part I</h4>\n<p>If you provide people with an opportunity to cheat and not get caught, they will, but only up to a certain point. Providing more temptation after that point has no further effect on behaviour. When people are asked to read an honour pledge or the Ten Commandments, they will act more honestly for a short time afterwards even in the absence of visible accountability.</p>\n<h4 id=\"Chapter_12___The_context_of_our_character_part_II\">Chapter 12 - The context of our character part II</h4>\n<p>When Ariely left Cokes in dorm fridges, they disappeared within 72 hours. When he did the same thing with $1 bills, no one touched them, because people take money more seriously. When monetary rewards in a test were replaced with tokens that were redeemed a few seconds later for cash, students given an opportunity to cheat cheated around twice as much as students given the opportunity to cheat but given their money directly. Lots of further anecdotes about how the further removed the money is from a process, the easier it is to justify dishonesty.</p>\n<h4 id=\"Chapter_13___Beer_and_free_lunches\">Chapter 13 - Beer and free lunches</h4>\n<p>People use public ordering as an opportunity to signal uniqueness or conformity, even if this means ordering a dish or drink that they don\u2019t actually want.</p>", "sections": [{"title": "Chapter 1 - Everything is relative", "anchor": "Chapter_1___Everything_is_relative", "level": 1}, {"title": "Chapter 2 - Supply and demand:", "anchor": "Chapter_2___Supply_and_demand_", "level": 1}, {"title": "Chapter 5 - The influence of arousal", "anchor": "Chapter_5___The_influence_of_arousal", "level": 1}, {"title": "Chapter 6 - Procrastination and self-control", "anchor": "Chapter_6___Procrastination_and_self_control", "level": 1}, {"title": "Chapter 7 - The high price of ownership", "anchor": "Chapter_7___The_high_price_of_ownership", "level": 1}, {"title": "Chapter 8 - Why options are distracting", "anchor": "Chapter_8___Why_options_are_distracting", "level": 1}, {"title": "Chapter 9 - The effect of expectations", "anchor": "Chapter_9___The_effect_of_expectations", "level": 1}, {"title": "Chapter 10 - The power of price", "anchor": "Chapter_10___The_power_of_price", "level": 1}, {"title": "Chapter 11 - The context of our character part I", "anchor": "Chapter_11___The_context_of_our_character_part_I", "level": 1}, {"title": "Chapter 12 - The context of our character part II", "anchor": "Chapter_12___The_context_of_our_character_part_II", "level": 1}, {"title": "Chapter 13 - Beer and free lunches", "anchor": "Chapter_13___Beer_and_free_lunches", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "9 comments"}], "headingsCount": 13}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T15:22:17.951Z", "modifiedAt": null, "url": null, "title": "Save the Date: DC Meetup May 15th", "slug": "save-the-date-dc-meetup-may-15th", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oAp6KSYDygTuApAqf/save-the-date-dc-meetup-may-15th", "pageUrlRelative": "/posts/oAp6KSYDygTuApAqf/save-the-date-dc-meetup-may-15th", "linkUrl": "https://www.lesswrong.com/posts/oAp6KSYDygTuApAqf/save-the-date-dc-meetup-may-15th", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Save%20the%20Date%3A%20DC%20Meetup%20May%2015th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASave%20the%20Date%3A%20DC%20Meetup%20May%2015th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoAp6KSYDygTuApAqf%2Fsave-the-date-dc-meetup-may-15th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Save%20the%20Date%3A%20DC%20Meetup%20May%2015th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoAp6KSYDygTuApAqf%2Fsave-the-date-dc-meetup-may-15th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoAp6KSYDygTuApAqf%2Fsave-the-date-dc-meetup-may-15th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p>We haven't selected a location yet, but we will meet on May 15th.<br /><br />Join us at&nbsp;lesswrong-dc@googlegroups.com</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oAp6KSYDygTuApAqf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.121045607586636e-07, "legacy": true, "legacyId": "7248", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T15:44:00.291Z", "modifiedAt": null, "url": null, "title": "Death Note, Anonymity, and Information Theory", "slug": "death-note-anonymity-and-information-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:02.047Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zumnfc7jctgocfoe9/death-note-anonymity-and-information-theory", "pageUrlRelative": "/posts/zumnfc7jctgocfoe9/death-note-anonymity-and-information-theory", "linkUrl": "https://www.lesswrong.com/posts/zumnfc7jctgocfoe9/death-note-anonymity-and-information-theory", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Death%20Note%2C%20Anonymity%2C%20and%20Information%20Theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeath%20Note%2C%20Anonymity%2C%20and%20Information%20Theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzumnfc7jctgocfoe9%2Fdeath-note-anonymity-and-information-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Death%20Note%2C%20Anonymity%2C%20and%20Information%20Theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzumnfc7jctgocfoe9%2Fdeath-note-anonymity-and-information-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzumnfc7jctgocfoe9%2Fdeath-note-anonymity-and-information-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 100, "htmlBody": "<p>I don't know if this is a little too afar field for even a Discussion post, but people seemed to enjoy my previous articles (<a href=\"/lw/5el/are_girl_scout_cookies_deliciously_evil_a_case/\">Girl Scouts financial filings</a>, <a href=\"/lw/4or/case_study_console_insurance/\">video game console insurance</a>, <a href=\"/lw/47k/an_abortion_dialogue/\">philosophy of identity/abortion</a>, &amp; <a href=\"/lw/3l2/2011_intrade_fee_changes_or_intrade_considered_no/\">prediction market fees</a>), so...</p>\n<p>I recently wrote up an idea that has been bouncing around my head ever since I watched <em>Death Note</em> years ago - can we quantify Light Yagami's mistakes? Which mistake was the greatest? How could one do better? We can shed some light on the matter by examining DN with... basic information theory.</p>\n<p>Presented for LessWrong's consideration: <a href=\"http://www.gwern.net/Death%20Note%20Anonymity\"><em>Death Note </em>&amp;<em> </em>Anonymity</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"6nS8oYmSMuFMaiowF": 1, "GBpwq8cWvaeRoE9X5": 1, "N5JGtFnhex2DbyPvy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zumnfc7jctgocfoe9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 53, "extendedScore": null, "score": 0.000104, "legacy": true, "legacyId": "7249", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 53, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5swa8chZCtWynuFga", "qykvr25EGcpFcMy6f", "TsRu6iP7DwRRbkHpS", "YhZsCdEi6a6G7sSBD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T17:43:27.892Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Scales of Justice, the Notebook of Rationality", "slug": "seq-rerun-the-scales-of-justice-the-notebook-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.187Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R4B5hzXPh9XyW42cW/seq-rerun-the-scales-of-justice-the-notebook-of-rationality", "pageUrlRelative": "/posts/R4B5hzXPh9XyW42cW/seq-rerun-the-scales-of-justice-the-notebook-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/R4B5hzXPh9XyW42cW/seq-rerun-the-scales-of-justice-the-notebook-of-rationality", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Scales%20of%20Justice%2C%20the%20Notebook%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Scales%20of%20Justice%2C%20the%20Notebook%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4B5hzXPh9XyW42cW%2Fseq-rerun-the-scales-of-justice-the-notebook-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Scales%20of%20Justice%2C%20the%20Notebook%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4B5hzXPh9XyW42cW%2Fseq-rerun-the-scales-of-justice-the-notebook-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4B5hzXPh9XyW42cW%2Fseq-rerun-the-scales-of-justice-the-notebook-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 195, "htmlBody": "<p>Today's post, <a href=\"/lw/h1/the_scales_of_justice_the_notebook_of_rationality/\">The Scales of Justice, the Notebook of Rationality</a>, was originally published on 13 March 2007. Two summaries (taken from the <a href=\"/555555\">LW wiki</a>):</p>\n<blockquote>\n<p>People have an irrational tendency to simplify their assessment of things into how good or bad they are without considering that the things in question may have many distinct and unrelated attributes.</p>\n<p>(alternate summary:)</p>\n<p>In non-binary answer spaces, you can't add up pro and con arguments along one dimension without risk of getting important factual questions wrong.</p>\n</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/h0/burchs_law/\">Burch's Law</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R4B5hzXPh9XyW42cW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 7.12145230766227e-07, "legacy": true, "legacyId": "7250", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XYCEB9roxEBfgjfxs", "6dSitnwYPg8i8NHn3", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T20:04:34.183Z", "modifiedAt": null, "url": null, "title": "Shane Legg's Thesis: Machine Superintelligence, Opinions?", "slug": "shane-legg-s-thesis-machine-superintelligence-opinions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:56.448Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Zetetic", "createdAt": "2010-08-02T17:08:44.781Z", "isAdmin": false, "displayName": "Zetetic"}, "userId": "BN7fbmHCbiE3zB4yQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ys6wGW4WrGASxjrB3/shane-legg-s-thesis-machine-superintelligence-opinions", "pageUrlRelative": "/posts/Ys6wGW4WrGASxjrB3/shane-legg-s-thesis-machine-superintelligence-opinions", "linkUrl": "https://www.lesswrong.com/posts/Ys6wGW4WrGASxjrB3/shane-legg-s-thesis-machine-superintelligence-opinions", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Shane%20Legg's%20Thesis%3A%20Machine%20Superintelligence%2C%20Opinions%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShane%20Legg's%20Thesis%3A%20Machine%20Superintelligence%2C%20Opinions%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYs6wGW4WrGASxjrB3%2Fshane-legg-s-thesis-machine-superintelligence-opinions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Shane%20Legg's%20Thesis%3A%20Machine%20Superintelligence%2C%20Opinions%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYs6wGW4WrGASxjrB3%2Fshane-legg-s-thesis-machine-superintelligence-opinions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYs6wGW4WrGASxjrB3%2Fshane-legg-s-thesis-machine-superintelligence-opinions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<p>I searched the posts but didn't find a great deal of relevant information. Has anyone taken a serious crack at it, preferably someone who would like to share their thoughts? Is the material worthwhile? Are there any dubious portions or any sections one might want to avoid reading (either due to bad ideas or for time saving reasons)? I'm considering investing a chunk of time into investigating Legg's work so any feedback would be much appreciated, and it seems likely that there might be others who would like some perspective on it as well.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ys6wGW4WrGASxjrB3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 16, "extendedScore": null, "score": 7.121858873546502e-07, "legacy": true, "legacyId": "7251", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-08T22:16:23.190Z", "modifiedAt": null, "url": null, "title": "[Reference request] Article by scientist giving lower and upper bounds on the probability of superintelligence", "slug": "reference-request-article-by-scientist-giving-lower-and", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.178Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "multifoliaterose", "createdAt": "2010-06-13T08:56:10.885Z", "isAdmin": false, "displayName": "multifoliaterose"}, "userId": "747HfTZFyfTqGyoPM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FYBWCQbwMXwJm6Jdy/reference-request-article-by-scientist-giving-lower-and", "pageUrlRelative": "/posts/FYBWCQbwMXwJm6Jdy/reference-request-article-by-scientist-giving-lower-and", "linkUrl": "https://www.lesswrong.com/posts/FYBWCQbwMXwJm6Jdy/reference-request-article-by-scientist-giving-lower-and", "postedAtFormatted": "Sunday, May 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BReference%20request%5D%20Article%20by%20scientist%20giving%20lower%20and%20upper%20bounds%20on%20the%20probability%20of%20superintelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BReference%20request%5D%20Article%20by%20scientist%20giving%20lower%20and%20upper%20bounds%20on%20the%20probability%20of%20superintelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFYBWCQbwMXwJm6Jdy%2Freference-request-article-by-scientist-giving-lower-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BReference%20request%5D%20Article%20by%20scientist%20giving%20lower%20and%20upper%20bounds%20on%20the%20probability%20of%20superintelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFYBWCQbwMXwJm6Jdy%2Freference-request-article-by-scientist-giving-lower-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFYBWCQbwMXwJm6Jdy%2Freference-request-article-by-scientist-giving-lower-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>A few months back somebody posted an article by a scientist giving lower and upper bounds on the probability of superintelligence. He broke up the calculation as a Fermi calculation with three parts (EDIT: See LocustBeanGum's answer). Does anybody remember this article and if so can you provide a link?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FYBWCQbwMXwJm6Jdy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 4, "extendedScore": null, "score": 7.122238714829438e-07, "legacy": true, "legacyId": "7252", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T02:50:26.592Z", "modifiedAt": null, "url": null, "title": "Toronto Meetup, May 10th", "slug": "toronto-meetup-may-10th", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.869Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spencer_Sleep", "createdAt": "2011-02-11T08:03:53.049Z", "isAdmin": false, "displayName": "Spencer_Sleep"}, "userId": "xAjAXuvj2czWZix2v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9SJnLQr7A4v2EJJAi/toronto-meetup-may-10th", "pageUrlRelative": "/posts/9SJnLQr7A4v2EJJAi/toronto-meetup-may-10th", "linkUrl": "https://www.lesswrong.com/posts/9SJnLQr7A4v2EJJAi/toronto-meetup-may-10th", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Toronto%20Meetup%2C%20May%2010th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToronto%20Meetup%2C%20May%2010th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9SJnLQr7A4v2EJJAi%2Ftoronto-meetup-may-10th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Toronto%20Meetup%2C%20May%2010th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9SJnLQr7A4v2EJJAi%2Ftoronto-meetup-may-10th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9SJnLQr7A4v2EJJAi%2Ftoronto-meetup-may-10th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 326, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong style=\"font-weight: bold;\"><a id=\"more\"></a>When</strong>: Tuesday, May 10th, 20:00</span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong style=\"font-weight: bold;\">Where</strong>: The Bedford Academy, 36 Prince Arthur Avenue</span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Hi everyone,</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The Toronto meetup group is having one of our bi-weekly meetings this Tuesday at the Bedford Academy. The reservation is under the name Spencer Sleep. I have requested a table upstairs, as it tends to be much quieter up there. &nbsp;</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Regulars take note: This meeting is on Tuesday, not Thursday. &nbsp;This change is because Thursday night is a busy night for bars, so it tends be much louder than Tuesday nights.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Newcomers are, as always, extremely welcome.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The discussion topic for this meeting is <strong>the feasibility of nuclear power. </strong>If that is too abstract for you, then it is&nbsp;<strong><span style=\"font-weight: normal;\"><strong>the feasibility of nuclear power</strong></span></strong><strong>&nbsp;as an energy source when compared to alternatives as they stand today, judged on the basis of economic and environmental effects and logistics (availability of fuel, creation of waste, etc...). </strong>&nbsp;This discussion topic comes from a meeting a few weeks ago where we wanted to try applying rationality to \"solve\" (or at least gain a better understanding of) controversial problems, such as that of nuclear power. &nbsp;Since these are such hot topics, discussions are usually very charged with emotions, and biases run rampant. &nbsp;We wanted to see if we could make headway by approaching it from a rational standpoint. Five minutes into the discussion, we determined that we did not have enough facts and that all we were doing was quoting contradictory numbers at each other. &nbsp;We determined to put it off for another day when we had had time to prepare. &nbsp;That day is today (well, Tuesday).</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19px;\">Note: This discussion topic will probably not take up more than an hour of the meeting, so even if this topic does not&nbsp;particularly&nbsp;interest you please show up anyway, as there will be many other discussions throughout the night.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">If you want to hear about upcoming LessWrong events in Toronto, or have ideas about how or when those events should be run, join the&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://groups.google.com/group/lesswrongtoronto\">Toronto LessWrong Google Group</a>!</p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">See you Tuesday</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9SJnLQr7A4v2EJJAi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 7.123028547335301e-07, "legacy": true, "legacyId": "7254", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T06:01:34.941Z", "modifiedAt": null, "url": null, "title": "But Butter Goes Rancid In The Freezer", "slug": "but-butter-goes-rancid-in-the-freezer", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:56.141Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JenniferRM", "createdAt": "2009-03-06T17:16:50.600Z", "isAdmin": false, "displayName": "JenniferRM"}, "userId": "g8JkZfL8PTqAefpvx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sphhEmp9qHMCqkvkR/but-butter-goes-rancid-in-the-freezer", "pageUrlRelative": "/posts/sphhEmp9qHMCqkvkR/but-butter-goes-rancid-in-the-freezer", "linkUrl": "https://www.lesswrong.com/posts/sphhEmp9qHMCqkvkR/but-butter-goes-rancid-in-the-freezer", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20But%20Butter%20Goes%20Rancid%20In%20The%20Freezer&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABut%20Butter%20Goes%20Rancid%20In%20The%20Freezer%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsphhEmp9qHMCqkvkR%2Fbut-butter-goes-rancid-in-the-freezer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=But%20Butter%20Goes%20Rancid%20In%20The%20Freezer%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsphhEmp9qHMCqkvkR%2Fbut-butter-goes-rancid-in-the-freezer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsphhEmp9qHMCqkvkR%2Fbut-butter-goes-rancid-in-the-freezer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 501, "htmlBody": "<p>I broached the subject of cryonics with a family member today.&nbsp; He offered almost none of the normal objections and I've been happy all day about the way the conversation went.&nbsp; One interesting issue that he raised that I'd like to find an answer for is the question in the title.</p>\n<p>Butter goes rancid after a while at room temperature.&nbsp; It <em>also</em> goes rancid in the fridge and can absorb the other flavors if things aren't well contained inside the refrigerator.&nbsp; Butter <em>also</em> goes rancid if left in a normal freezer, which mostly is designed to bring things very close to the melting point of water around 273 kelvin.</p>\n<p>This suggests that lipid chemistry responds to temperatures in a different way than intuitions mostly educated by other examples of freezing, which is relevant because the brain is mostly made out of fat, with some complicating proteins mixed in.&nbsp; My guess is that developing a \"rancid brain\" isn't likely to be a serious issue when you get down to the 77 kelvin of liquid nitrogen, but its still something I'd like to be able to answer directly and honestly, after really thinking about it in terms of \"safety engineering\".</p>\n<p>One way to answer the direct question about butter might be to just perform the basic experiment with some butter samples at different temperatures (room, fridge, freezer, -80C freezer in a bio lab) and figure out how long butter stored each way takes to go rancid and then do some curve fitting, but that seems like it would take months or maybe even years, and butter doesn't even necessarily answer neurological questions directly.&nbsp; Even if I learned about butter chemistry, there could be open questions about brain chemistry.&nbsp; I've tentatively googled around for 30 minutes but organic chemistry isn't a primary area of expertise and I wasn't sure out to dig up the specialist scientific literature that might answer my question.</p>\n<p>This community seemed like a good place to get help on the subject!</p>\n<p>Here are some <strong>specific questions</strong> I'd love to know the answers to...</p>\n<p>1. What are the precise chemical reactions are that are collectively referred to as rancidity in english, and how to they change at cryogenic temperatures?&nbsp; Does butter stop going rancid in liquid nitrogen?</p>\n<p>2. Are these or similar reactions possible in the brain, given all the cell membranes and mylenation and so on that are primarily made out of fat?</p>\n<p>3. How much personality/memory/mind relevant information might be lost to rancidity, if it happened?&nbsp; If there are brain or neuronal structures that are more likely to go rancid first, would the chemical changes involved in rancidity be likely to change our estimation of the structures \"historical operation\" or not?</p>\n<p>4. The boiling point of oxygen is about 90 kelvin (13 degrees higher than nitrogen's boiling point).&nbsp; If the liquid around a cryo-patient is not changed over time then we might expect the ratio of liquid oxygen to liquid nitrogen to increase over time.&nbsp; Is the presence of the liquid oxygen relevant to rancidty issues or not?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZnHkaTkxukegSrZqE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sphhEmp9qHMCqkvkR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 38, "extendedScore": null, "score": 7.123579502360715e-07, "legacy": true, "legacyId": "7255", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T09:09:47.801Z", "modifiedAt": null, "url": null, "title": "Shanghai Less Wrong Meetup #2 Wednesday May 11th, 7pm", "slug": "shanghai-less-wrong-meetup-2-wednesday-may-11th-7pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:59.382Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Patrick", "createdAt": "2009-02-27T08:09:44.663Z", "isAdmin": false, "displayName": "Patrick"}, "userId": "KC7mjSorWj2XsdL3v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Tty3dNML6RhGwfibm/shanghai-less-wrong-meetup-2-wednesday-may-11th-7pm", "pageUrlRelative": "/posts/Tty3dNML6RhGwfibm/shanghai-less-wrong-meetup-2-wednesday-may-11th-7pm", "linkUrl": "https://www.lesswrong.com/posts/Tty3dNML6RhGwfibm/shanghai-less-wrong-meetup-2-wednesday-may-11th-7pm", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Shanghai%20Less%20Wrong%20Meetup%20%232%20Wednesday%20May%2011th%2C%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShanghai%20Less%20Wrong%20Meetup%20%232%20Wednesday%20May%2011th%2C%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTty3dNML6RhGwfibm%2Fshanghai-less-wrong-meetup-2-wednesday-may-11th-7pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Shanghai%20Less%20Wrong%20Meetup%20%232%20Wednesday%20May%2011th%2C%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTty3dNML6RhGwfibm%2Fshanghai-less-wrong-meetup-2-wednesday-may-11th-7pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTty3dNML6RhGwfibm%2Fshanghai-less-wrong-meetup-2-wednesday-may-11th-7pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p><a id=\"more\"></a>John Teddy has asked me to post the following meetup on Less Wrong:</p>\n<blockquote>\n<p>Shanghai Lesswrong Meeting #2</p>\n<div>Wednesday May 11th, 7pm, XuHui District, Shanghai, China (private residence not listed, please contact John Teddy)</div>\n<div>The first meeting was a success. There are plans to have regular meetings, goal setting, and various topics. Some of the planned topics are porting the mind to software, bayes theorem, cognitive biases, paleo diet, etc. The first meeting was at a public venue. Our next meeting will be at a private residence. Please text or call John Teddy (&nbsp;<a href=\"/user/johntheodore\" target=\"_blank\">http://lesswrong.com/user/johntheodore</a>&nbsp;) at 18621732925 to receive the address.</div>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Tty3dNML6RhGwfibm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.12412209979714e-07, "legacy": true, "legacyId": "7268", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T14:28:36.609Z", "modifiedAt": null, "url": null, "title": "Intelligence vs Friendliness", "slug": "intelligence-vs-friendliness", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:55.453Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "snarles", "createdAt": "2009-06-01T03:48:38.132Z", "isAdmin": false, "displayName": "snarles"}, "userId": "YsmFaM5MdsDW8GNop", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a8fqsA6meBxHm2Rua/intelligence-vs-friendliness", "pageUrlRelative": "/posts/a8fqsA6meBxHm2Rua/intelligence-vs-friendliness", "linkUrl": "https://www.lesswrong.com/posts/a8fqsA6meBxHm2Rua/intelligence-vs-friendliness", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Intelligence%20vs%20Friendliness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntelligence%20vs%20Friendliness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa8fqsA6meBxHm2Rua%2Fintelligence-vs-friendliness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Intelligence%20vs%20Friendliness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa8fqsA6meBxHm2Rua%2Fintelligence-vs-friendliness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa8fqsA6meBxHm2Rua%2Fintelligence-vs-friendliness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 243, "htmlBody": "<p>An agent is composed of two components: a predictive model of the world, and a utility function for evaluating world states</p>\n<p>I would say that the 'intelligence' of an agent corresponds to the sophistication and accuracy of their world model.&nbsp; The 'friendliness' of an agent depends on how closely their utility function aligns with human values.</p>\n<p>What is baffling to me is the vague idea that developing the theory of friendliness has any significant synergy with developing the theory of intelligence.&nbsp; (Such an idea has surfaced in discussions of on the plausibility of SIAI developing friendly AI before unfriendly AI is developed by others.)</p>\n<p>One argument for the latter (and the only one I can think of) is that:</p>\n<p>a) A perfect world model is not possible: one must make the best tradeoff given limited resources</p>\n<p>b) The more relevant a certain feature of the world is to the utility function, the more accurately we want to model it in the world model</p>\n<p>However, for the large part, the world model would differ, in totality, very little between a paperclip maximizer and a friendly AI.&nbsp; While the Friendly AI certainly has to keep track of more things which are irrelevant to the paperclip maximizer, both AIs would have to have world models which have to be able to model human behavior in order for the AIs to be effective, which one would expect would account for the bulk of the complexity of the world model in the first place.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a8fqsA6meBxHm2Rua", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "7278", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T15:14:53.295Z", "modifiedAt": null, "url": null, "title": "Building rationalist communities: lessons from the Latter-day Saints", "slug": "building-rationalist-communities-lessons-from-the-latter-day", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:59.358Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/su7bXsXYpY55vwphc/building-rationalist-communities-lessons-from-the-latter-day", "pageUrlRelative": "/posts/su7bXsXYpY55vwphc/building-rationalist-communities-lessons-from-the-latter-day", "linkUrl": "https://www.lesswrong.com/posts/su7bXsXYpY55vwphc/building-rationalist-communities-lessons-from-the-latter-day", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Building%20rationalist%20communities%3A%20lessons%20from%20the%20Latter-day%20Saints&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABuilding%20rationalist%20communities%3A%20lessons%20from%20the%20Latter-day%20Saints%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsu7bXsXYpY55vwphc%2Fbuilding-rationalist-communities-lessons-from-the-latter-day%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Building%20rationalist%20communities%3A%20lessons%20from%20the%20Latter-day%20Saints%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsu7bXsXYpY55vwphc%2Fbuilding-rationalist-communities-lessons-from-the-latter-day", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsu7bXsXYpY55vwphc%2Fbuilding-rationalist-communities-lessons-from-the-latter-day", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 734, "htmlBody": "<p><!-- /* Font Definitions */ @font-face {font-family:\"Times New Roman\"; panose-1:0 2 2 6 3 5 4 5 2 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:\"Courier New\"; panose-1:0 2 7 3 9 2 2 5 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:Wingdings; panose-1:0 5 2 1 2 1 8 4 8 7; mso-font-charset:2; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:0 0 256 0 -2147483648 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText {margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} span.MsoFootnoteReference {vertical-align:super;} a:link, span.MsoHyperlink {color:blue; text-decoration:underline; text-underline:single;} a:visited, span.MsoHyperlinkFollowed {color:purple; text-decoration:underline; text-underline:single;} table.MsoNormalTable {mso-style-parent:\"\"; font-size:10.0pt; font-family:\"Times New Roman\";} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:1532643161; mso-list-type:hybrid; mso-list-template-ids:-1246472920 243311300 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l0:level1 {mso-level-number-format:bullet; mso-level-text:-; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.25in; font-family:\"Times New Roman\"; mso-font-width:0%;} @list l0:level2 {mso-level-number-format:bullet; mso-level-text:o; mso-level-tab-stop:1.25in; mso-level-number-position:left; margin-left:1.25in; text-indent:-.25in; font-family:\"Courier New\";} @list l0:level3 {mso-level-number-format:bullet; mso-level-text:\uf0a7; mso-level-tab-stop:1.75in; mso-level-number-position:left; margin-left:1.75in; text-indent:-.25in; font-family:Wingdings;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --></p>\n<p class=\"MsoNormal\"><em>Or: How I Learned Everything I Know About Group Organization By Spending Two Years on a Mormon Mission in India.</em></p>\n<p class=\"MsoNormal\">The official name is the Church of Jesus Christ of Latter-day Saints. You may know us as &lsquo;Mormons.&rsquo; We like to call ourselves &lsquo;Latter-day Saints.&rsquo;</p>\n<p class=\"MsoNormal\">If you&rsquo;re a Less Wrongian and trying to organize a rationalist community, you should be interested in the Latter-day Saint organizational model for four reasons:</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>it&rsquo;s a nonprofit, but franchise-based and designed to propagate itself,</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>everyone has a responsibility,</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>no one is paid, and</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>it works.</p>\n<p class=\"MsoNormal\">This is an introductory post. I'm not trying to persuade you to join, but rather that<em></em><span style=\"font-style:normal\"> there&rsquo;s something to learn here.</span></p>\n<p class=\"MsoNormal\">Here, I will give you some basic details about what <span style=\"font-style:normal\">the LDS Church is.<span style=\"mso-spacerun: yes\">&nbsp; </span>In later posts, I will explain more </span>how<em> </em><span style=\"font-style:normal\">it works. A series overview is <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">here</a>.<a id=\"more\"></a></span></p>\n<p class=\"MsoNormal\"><strong><em>A franchise model</em></strong></p>\n<p class=\"MsoNormal\">The Church has about 55,000 missionaries worldwide, all of whom follow the same basic dress code and go about in pairs, basically recruiting people to join the organization. For men, white shirt and &lsquo;conservative&rsquo; tie, suitjacket if it&rsquo;s cold. Clean-shaven. No chewing gum in public.<span style=\"mso-spacerun: yes\">&nbsp; </span>Short hair. <a href=\"http://www.mormonbeliefs.org/wp-content/uploads/2008/06/mormon-elder-missionaries.jpg\">And so forth</a>.</p>\n<p class=\"MsoNormal\">Church buildings are selected from a basic set of designs. Each congregation unit has about 150 people each week at Sunday services. The internal organization is the same for each congregation, albeit with procedures for simplification in smaller units. Everyone has a responsibility, from the congregation head down to the teenage boys who prepare and serve the &lsquo;sacrament.&rsquo;<a style=\"mso-footnote-id:ftn1\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a></p>\n<p class=\"MsoNormal\">And nobody is paid.</p>\n<p class=\"MsoNormal\"><strong><em>Everyone has a responsibility</em></strong></p>\n<p class=\"MsoNormal\">The Church is an organization, but members also comprise a distinct culture. Within the culture, there is an expectation that church members accept a &lsquo;calling&rsquo; or specific unpaid organizational responsibility.</p>\n<p class=\"MsoNormal\">Callings are assigned by the head of the local congregation. You can privately decline, but there is an expectation is to accept the responsibility.</p>\n<p class=\"MsoNormal\">Examples include:</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>visiting specific church member families monthly (&ldquo;home teacher&rdquo;)</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>helping local unemployed church members find jobs</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>teaching a class every week in church</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>presiding over the congregation.</p>\n<p class=\"MsoNormal\">As you see, some roles are more time-intensive than others.</p>\n<p class=\"MsoNormal\">(My current responsibility is to co-chair a committee that organizes weekly social events on Monday nights, to which around 40-50 young single adults come.)</p>\n<p class=\"MsoNormal\">Probably about 70% of church members with a calling fulfill that calling.<a style=\"mso-footnote-id:ftn2\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a></p>\n<p class=\"MsoNormal\"><strong><em>No one is paid</em></strong><span style=\"font-style:normal\"><strong></strong></span></p>\n<p class=\"MsoNormal\">This holds to three decimal places but not to four. The exceptions are:</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>A few people have jobs in church headquarters writing curricula.</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Local members who are paid to organize weekday adult religious education programs. In California, there is about one for every ~15 congregations.</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>A paid &lsquo;General Authority&rsquo; to oversee every ~150 congregations. (One congregation has about 150 attending every Sunday.)</p>\n<p class=\"MsoNormal\">So I would approximate that for every 2000-3000 active church members, of which 1000-1500 are helping to run the church for no salary, there is one paid church worker.</p>\n<p class=\"MsoNormal\"><strong><em>It works</em></strong><span style=\"font-style:normal\"><strong></strong></span></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>The Church of Jesus Christ of Latter-day Saints is the fourth-largest church organization in America.<a style=\"mso-footnote-id:ftn3\" name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It&rsquo;s also around fourth in growth rates, depending on how you measure growth.<a style=\"mso-footnote-id:ftn4\" name=\"_ftnref4\" href=\"#_ftn4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[4]</span></span></a></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It&rsquo;s fairly new, only starting in 1830. It has achieved this growth while receiving the disdain of mainstream Christianity.<a style=\"mso-footnote-id:ftn5\" name=\"_ftnref5\" href=\"#_ftn5\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[5]</span></span></a></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It&rsquo;s basically the only church that doesn't pay local leadership. Google &ldquo;unpaid clergy&rdquo; and you get only Mormon links.</p>\n<p class=\"MsoNormal\">You might be wondering what Less Wrongians possibly have to learn from some&hellip;weird religious organization?</p>\n<p class=\"MsoNormal\">Simply put: <em>because the Church has figured out how to construct an organization and cultural identity that works and spreads without almost anyone being paid. </em></p>\n<p class=\"MsoNormal\">That&rsquo;s what Less Wrong-ians are trying to do, right?</p>\n<p class=\"MsoNormal\">Here is the <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">next part</a>, a series overview.</p>\n<div style=\"mso-element:footnote-list\"><br /> \n<hr size=\"1\" />\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> Sacrament is roughly equivalent to communion; a ritual where bread and water are served individually to each member of the congregation in memory of Christ.</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn2\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a> My estimate. Of course, there is a gradation of effort possible. You can improvise a Sunday lesson on the spot, or carefully prepare it over the preceding week, for example.</p>\n</div>\n<div id=\"ftn3\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn3\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> http://www.adherents.com/rel_USA.html</p>\n</div>\n<div id=\"ftn4\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn4\" name=\"_ftn4\" href=\"#_ftnref4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[4]</span></span></a> I would classify growth as &lsquo;percentage growth rate of a church organization for a fairly large and well-established church.&rsquo; If you have one church and you open three more, you don&rsquo;t count. Data is&nbsp; <a href=\"http://en.wikipedia.org/wiki/Christian_population_growth\">here</a>&nbsp; and&nbsp; <a href=\"http://www.ncccusa.org/news/100204yearbook2010.html\">here </a>. The main faster-growing churches are Assemblies of God, Jehovah&rsquo;s Witnesses, and Seventh-Day Adventists. Catholics are just growing in America because of Hispanic immigration.</p>\n</div>\n<div id=\"ftn5\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn5\" name=\"_ftn5\" href=\"#_ftnref5\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[5]</span></span></a> Latter-day Saints, including church leadership, is sometimes rather unrealistically enthusiastic about the rates of church growth. However, that there is an underlying success is hard to dispute.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "su7bXsXYpY55vwphc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 22, "extendedScore": null, "score": 7.125173417559229e-07, "legacy": true, "legacyId": "7258", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!-- /* Font Definitions */ @font-face {font-family:\"Times New Roman\"; panose-1:0 2 2 6 3 5 4 5 2 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:\"Courier New\"; panose-1:0 2 7 3 9 2 2 5 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:Wingdings; panose-1:0 5 2 1 2 1 8 4 8 7; mso-font-charset:2; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:0 0 256 0 -2147483648 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText {margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} span.MsoFootnoteReference {vertical-align:super;} a:link, span.MsoHyperlink {color:blue; text-decoration:underline; text-underline:single;} a:visited, span.MsoHyperlinkFollowed {color:purple; text-decoration:underline; text-underline:single;} table.MsoNormalTable {mso-style-parent:\"\"; font-size:10.0pt; font-family:\"Times New Roman\";} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:1532643161; mso-list-type:hybrid; mso-list-template-ids:-1246472920 243311300 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l0:level1 {mso-level-number-format:bullet; mso-level-text:-; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.25in; font-family:\"Times New Roman\"; mso-font-width:0%;} @list l0:level2 {mso-level-number-format:bullet; mso-level-text:o; mso-level-tab-stop:1.25in; mso-level-number-position:left; margin-left:1.25in; text-indent:-.25in; font-family:\"Courier New\";} @list l0:level3 {mso-level-number-format:bullet; mso-level-text:\uf0a7; mso-level-tab-stop:1.75in; mso-level-number-position:left; margin-left:1.75in; text-indent:-.25in; font-family:Wingdings;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --></p>\n<p class=\"MsoNormal\"><em>Or: How I Learned Everything I Know About Group Organization By Spending Two Years on a Mormon Mission in India.</em></p>\n<p class=\"MsoNormal\">The official name is the Church of Jesus Christ of Latter-day Saints. You may know us as \u2018Mormons.\u2019 We like to call ourselves \u2018Latter-day Saints.\u2019</p>\n<p class=\"MsoNormal\">If you\u2019re a Less Wrongian and trying to organize a rationalist community, you should be interested in the Latter-day Saint organizational model for four reasons:</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>it\u2019s a nonprofit, but franchise-based and designed to propagate itself,</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>everyone has a responsibility,</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>no one is paid, and</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>it works.</p>\n<p class=\"MsoNormal\">This is an introductory post. I'm not trying to persuade you to join, but rather that<em></em><span style=\"font-style:normal\"> there\u2019s something to learn here.</span></p>\n<p class=\"MsoNormal\">Here, I will give you some basic details about what <span style=\"font-style:normal\">the LDS Church is.<span style=\"mso-spacerun: yes\">&nbsp; </span>In later posts, I will explain more </span>how<em> </em><span style=\"font-style:normal\">it works. A series overview is <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">here</a>.<a id=\"more\"></a></span></p>\n<p class=\"MsoNormal\"><strong id=\"A_franchise_model\"><em>A franchise model</em></strong></p>\n<p class=\"MsoNormal\">The Church has about 55,000 missionaries worldwide, all of whom follow the same basic dress code and go about in pairs, basically recruiting people to join the organization. For men, white shirt and \u2018conservative\u2019 tie, suitjacket if it\u2019s cold. Clean-shaven. No chewing gum in public.<span style=\"mso-spacerun: yes\">&nbsp; </span>Short hair. <a href=\"http://www.mormonbeliefs.org/wp-content/uploads/2008/06/mormon-elder-missionaries.jpg\">And so forth</a>.</p>\n<p class=\"MsoNormal\">Church buildings are selected from a basic set of designs. Each congregation unit has about 150 people each week at Sunday services. The internal organization is the same for each congregation, albeit with procedures for simplification in smaller units. Everyone has a responsibility, from the congregation head down to the teenage boys who prepare and serve the \u2018sacrament.\u2019<a style=\"mso-footnote-id:ftn1\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a></p>\n<p class=\"MsoNormal\">And nobody is paid.</p>\n<p class=\"MsoNormal\"><strong id=\"Everyone_has_a_responsibility\"><em>Everyone has a responsibility</em></strong></p>\n<p class=\"MsoNormal\">The Church is an organization, but members also comprise a distinct culture. Within the culture, there is an expectation that church members accept a \u2018calling\u2019 or specific unpaid organizational responsibility.</p>\n<p class=\"MsoNormal\">Callings are assigned by the head of the local congregation. You can privately decline, but there is an expectation is to accept the responsibility.</p>\n<p class=\"MsoNormal\">Examples include:</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>visiting specific church member families monthly (\u201chome teacher\u201d)</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>helping local unemployed church members find jobs</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>teaching a class every week in church</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>presiding over the congregation.</p>\n<p class=\"MsoNormal\">As you see, some roles are more time-intensive than others.</p>\n<p class=\"MsoNormal\">(My current responsibility is to co-chair a committee that organizes weekly social events on Monday nights, to which around 40-50 young single adults come.)</p>\n<p class=\"MsoNormal\">Probably about 70% of church members with a calling fulfill that calling.<a style=\"mso-footnote-id:ftn2\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a></p>\n<p class=\"MsoNormal\"><strong><em>No one is paid</em></strong><span style=\"font-style:normal\"><strong></strong></span></p>\n<p class=\"MsoNormal\">This holds to three decimal places but not to four. The exceptions are:</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>A few people have jobs in church headquarters writing curricula.</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Local members who are paid to organize weekday adult religious education programs. In California, there is about one for every ~15 congregations.</p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>A paid \u2018General Authority\u2019 to oversee every ~150 congregations. (One congregation has about 150 attending every Sunday.)</p>\n<p class=\"MsoNormal\">So I would approximate that for every 2000-3000 active church members, of which 1000-1500 are helping to run the church for no salary, there is one paid church worker.</p>\n<p class=\"MsoNormal\"><strong><em>It works</em></strong><span style=\"font-style:normal\"><strong></strong></span></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>The Church of Jesus Christ of Latter-day Saints is the fourth-largest church organization in America.<a style=\"mso-footnote-id:ftn3\" name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It\u2019s also around fourth in growth rates, depending on how you measure growth.<a style=\"mso-footnote-id:ftn4\" name=\"_ftnref4\" href=\"#_ftn4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[4]</span></span></a></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It\u2019s fairly new, only starting in 1830. It has achieved this growth while receiving the disdain of mainstream Christianity.<a style=\"mso-footnote-id:ftn5\" name=\"_ftnref5\" href=\"#_ftn5\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[5]</span></span></a></p>\n<p class=\"MsoNormal\" style=\"margin-left:.75in;text-indent:-.25in;mso-list:l0 level1 lfo1; tab-stops:list .75in\"><span style=\"mso-font-width:0%\">-<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It\u2019s basically the only church that doesn't pay local leadership. Google \u201cunpaid clergy\u201d and you get only Mormon links.</p>\n<p class=\"MsoNormal\">You might be wondering what Less Wrongians possibly have to learn from some\u2026weird religious organization?</p>\n<p class=\"MsoNormal\">Simply put: <em>because the Church has figured out how to construct an organization and cultural identity that works and spreads without almost anyone being paid. </em></p>\n<p class=\"MsoNormal\">That\u2019s what Less Wrong-ians are trying to do, right?</p>\n<p class=\"MsoNormal\">Here is the <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">next part</a>, a series overview.</p>\n<div style=\"mso-element:footnote-list\"><br> \n<hr size=\"1\">\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> Sacrament is roughly equivalent to communion; a ritual where bread and water are served individually to each member of the congregation in memory of Christ.</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn2\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a> My estimate. Of course, there is a gradation of effort possible. You can improvise a Sunday lesson on the spot, or carefully prepare it over the preceding week, for example.</p>\n</div>\n<div id=\"ftn3\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn3\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> http://www.adherents.com/rel_USA.html</p>\n</div>\n<div id=\"ftn4\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn4\" name=\"_ftn4\" href=\"#_ftnref4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[4]</span></span></a> I would classify growth as \u2018percentage growth rate of a church organization for a fairly large and well-established church.\u2019 If you have one church and you open three more, you don\u2019t count. Data is&nbsp; <a href=\"http://en.wikipedia.org/wiki/Christian_population_growth\">here</a>&nbsp; and&nbsp; <a href=\"http://www.ncccusa.org/news/100204yearbook2010.html\">here </a>. The main faster-growing churches are Assemblies of God, Jehovah\u2019s Witnesses, and Seventh-Day Adventists. Catholics are just growing in America because of Hispanic immigration.</p>\n</div>\n<div id=\"ftn5\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn5\" name=\"_ftn5\" href=\"#_ftnref5\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[5]</span></span></a> Latter-day Saints, including church leadership, is sometimes rather unrealistically enthusiastic about the rates of church growth. However, that there is an underlying success is hard to dispute.</p>\n</div>\n</div>", "sections": [{"title": "A franchise model", "anchor": "A_franchise_model", "level": 1}, {"title": "Everyone has a responsibility", "anchor": "Everyone_has_a_responsibility", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "72 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 72, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Zasc7RXAEosWLYf8E"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T15:15:34.190Z", "modifiedAt": null, "url": null, "title": "Building rationalist communities: a series overview", "slug": "building-rationalist-communities-a-series-overview", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:31.392Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zasc7RXAEosWLYf8E/building-rationalist-communities-a-series-overview", "pageUrlRelative": "/posts/Zasc7RXAEosWLYf8E/building-rationalist-communities-a-series-overview", "linkUrl": "https://www.lesswrong.com/posts/Zasc7RXAEosWLYf8E/building-rationalist-communities-a-series-overview", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Building%20rationalist%20communities%3A%20a%20series%20overview&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABuilding%20rationalist%20communities%3A%20a%20series%20overview%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZasc7RXAEosWLYf8E%2Fbuilding-rationalist-communities-a-series-overview%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Building%20rationalist%20communities%3A%20a%20series%20overview%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZasc7RXAEosWLYf8E%2Fbuilding-rationalist-communities-a-series-overview", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZasc7RXAEosWLYf8E%2Fbuilding-rationalist-communities-a-series-overview", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 321, "htmlBody": "<p><!-- /* Font Definitions */ @font-face {font-family:\"Times New Roman\"; panose-1:0 2 2 6 3 5 4 5 2 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:\"Courier New\"; panose-1:0 2 7 3 9 2 2 5 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:Wingdings; panose-1:0 5 2 1 2 1 8 4 8 7; mso-font-charset:2; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:0 0 256 0 -2147483648 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} table.MsoNormalTable {mso-style-parent:\"\"; font-size:10.0pt; font-family:\"Times New Roman\";} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:1532643161; mso-list-type:hybrid; mso-list-template-ids:-1246472920 243311300 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l0:level1 {mso-level-number-format:bullet; mso-level-text:-; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.25in; font-family:\"Times New Roman\"; mso-font-width:0%;} @list l0:level2 {mso-level-number-format:bullet; mso-level-text:o; mso-level-tab-stop:1.25in; mso-level-number-position:left; margin-left:1.25in; text-indent:-.25in; font-family:\"Courier New\";} @list l0:level3 {mso-level-number-format:bullet; mso-level-text:\uf0a7; mso-level-tab-stop:1.75in; mso-level-number-position:left; margin-left:1.75in; text-indent:-.25in; font-family:Wingdings;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --></p>\n<p class=\"MsoNormal\">Related to: <a href=\"/lw/5lm/how_to_build_rationalist_communities/\">How to build rationalist communities</a></p>\n<p class=\"MsoNormal\"><em>\"Tell 'em what you're going to tell 'em,\"</em> as it is written:</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.25in;\"><span>-<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Holy Books Don&rsquo;t Implement Themselves</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Marx needed a Lenin. Fermi, Hahn and Meitner needed a Manhattan Project. The Bible needs a Rick Warren.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>EY and the <a href=\"http://wiki.lesswrong.com/wiki/Sequences\">Sequences</a> need:</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.75in; text-indent: -0.25in;\"><span style=\"font-family: Wingdings;\">&sect;<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>a Distiller that generates Rationality Projects.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.75in; text-indent: -0.25in;\"><span style=\"font-family: Wingdings;\">&sect;<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>some Organizers to help people embark on these Projects.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.25in;\"><span>-<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Getting People To Do Stuff</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It doesn&rsquo;t matter what ideas were conveyed in group meeting, the subset that matters is what group members resolved to do</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It doesn&rsquo;t matter what group members resolved to do, the subset that matters is what you, the Organizer, followed up with.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.25in;\"><span>-<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Bhagwat&rsquo;s Law of Commitment</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>The degree to which people identify with the group is directly proportional to the amount of stuff you tell them to do that works.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.25in;\"><span>-<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Head in the Clouds &lt; Making It Rain</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>If someone is unable to articulate how they are going to implement a principle into their day-to-day lives, they are unlikely to implement it.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.25in;\"><span>-<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Herding Cats</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>If you don&rsquo;t let people do something meaningful, they will never be any help.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Feeling needed as a part of a community is a powerful motive to keep coming to meetings.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Know the name and face of every newcomer. Have a good conversation with each. Afterwards, send them an e-mail showing them you are glad they came.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.25in;\"><span>-<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>\"The Four People Who Do Everything\" organization problem</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>When you focus on doing stuff, some fandom members become core members.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Others leave or detach themselves.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>But if you don&rsquo;t have competent core members who organize, the group falls apart or stagnates.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Attrition is the organization-killer. Spending tons of time training new people, only to have your old people leave, is a recipe for frustration and stagnation.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.25in;\"><span>-<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Living Organisms Grow Naturally</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>The idea isn&rsquo;t, &lsquo;how can Less Wrong meetups expand&rsquo;</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.25in; text-indent: -0.25in;\"><span style=\"font-family: &quot;Courier New&quot;;\">o<span style=\"font: 7pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>It&rsquo;s, &lsquo;how can we remove the barriers stopping them?&rsquo;</p>\n<p class=\"MsoNormal\">What are you all most interested in?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7ow6EFpypbH4hzFuz": 1, "izp6eeJJEg9v5zcur": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zasc7RXAEosWLYf8E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 26, "extendedScore": null, "score": 6.3e-05, "legacy": true, "legacyId": "7259", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["su7bXsXYpY55vwphc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T16:20:32.436Z", "modifiedAt": null, "url": null, "title": "[HPMoR] Celebratory Trailer", "slug": "hpmor-celebratory-trailer", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:56.305Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4sET9fSksitS3usY2/hpmor-celebratory-trailer", "pageUrlRelative": "/posts/4sET9fSksitS3usY2/hpmor-celebratory-trailer", "linkUrl": "https://www.lesswrong.com/posts/4sET9fSksitS3usY2/hpmor-celebratory-trailer", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BHPMoR%5D%20Celebratory%20Trailer&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BHPMoR%5D%20Celebratory%20Trailer%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4sET9fSksitS3usY2%2Fhpmor-celebratory-trailer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BHPMoR%5D%20Celebratory%20Trailer%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4sET9fSksitS3usY2%2Fhpmor-celebratory-trailer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4sET9fSksitS3usY2%2Fhpmor-celebratory-trailer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 138, "htmlBody": "<p>Over the weekend the Methods of Rationality audio-book podcast tipped 1000 downloads, and I figured in celebration I'd put a trailer or two out on YouTube. Nothing fancy, just some stills/pics with an audio clip of 30-60 seconds. Thing is, I don't know what would work best for this. So I'm asking any readers of the fanfic - what first really captured your attention when you started reading Methods of Rationality? When did you say \"Ok, that's it, I gotta read all of this now\"? Or, if you're a listener to the podcast, are there any particular points that you thought were cool enough to share widely?</p>\n<p>The restrictions are that it should be somewhere in the 30-60 second range, and that it has to be from the first 6 chapters (since that's all that's been recorded so far).</p>\n<p>Thanks!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4sET9fSksitS3usY2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "7280", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T16:28:43.909Z", "modifiedAt": null, "url": null, "title": "Main site karma requirement for posting broken?", "slug": "main-site-karma-requirement-for-posting-broken", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.351Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AdeleneDawner", "createdAt": "2009-04-28T14:40:00.131Z", "isAdmin": false, "displayName": "AdeleneDawner"}, "userId": "MeSREm4SMRGxeQ8X3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/u3p4o3fzR53wX8bxp/main-site-karma-requirement-for-posting-broken", "pageUrlRelative": "/posts/u3p4o3fzR53wX8bxp/main-site-karma-requirement-for-posting-broken", "linkUrl": "https://www.lesswrong.com/posts/u3p4o3fzR53wX8bxp/main-site-karma-requirement-for-posting-broken", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Main%20site%20karma%20requirement%20for%20posting%20broken%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMain%20site%20karma%20requirement%20for%20posting%20broken%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu3p4o3fzR53wX8bxp%2Fmain-site-karma-requirement-for-posting-broken%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Main%20site%20karma%20requirement%20for%20posting%20broken%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu3p4o3fzR53wX8bxp%2Fmain-site-karma-requirement-for-posting-broken", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu3p4o3fzR53wX8bxp%2Fmain-site-karma-requirement-for-posting-broken", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<p>I just noticed that <a href=\"/user/calcsam\">calcsam</a>, who just posted two top posts in the main section of the site, only has the 100 karma that he has, so far, gained from those posts.</p>\n<p>I don't object to those posts being there, but how did he do that?</p>\n<p>Edit: Question answered; <a href=\"/lw/5m9/main_site_karma_requirement_for_posting_broken/44p7\">Eliezer mucked around with the karma system to make this possible in this specific case.</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "u3p4o3fzR53wX8bxp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.125387778283141e-07, "legacy": true, "legacyId": "7281", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T17:44:24.345Z", "modifiedAt": null, "url": null, "title": "Karma needed to post?", "slug": "karma-needed-to-post", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:55.363Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "saliency", "createdAt": "2009-10-25T03:59:58.587Z", "isAdmin": false, "displayName": "saliency"}, "userId": "RNx6ydjKM2J3Heae3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5mExxwfyHWeEwGCi2/karma-needed-to-post", "pageUrlRelative": "/posts/5mExxwfyHWeEwGCi2/karma-needed-to-post", "linkUrl": "https://www.lesswrong.com/posts/5mExxwfyHWeEwGCi2/karma-needed-to-post", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Karma%20needed%20to%20post%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKarma%20needed%20to%20post%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5mExxwfyHWeEwGCi2%2Fkarma-needed-to-post%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Karma%20needed%20to%20post%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5mExxwfyHWeEwGCi2%2Fkarma-needed-to-post", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5mExxwfyHWeEwGCi2%2Fkarma-needed-to-post", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><a href=\"http://wiki.lesswrong.com/wiki/Karma#What_is_karma.3F\">http://wiki.lesswrong.com/wiki/Karma#What_is_karma.3F</a></p>\n<p>&nbsp;</p>\n<p>My understanding is that it was risen from 20. &nbsp;Is this correct? &nbsp;What is the current number?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5mExxwfyHWeEwGCi2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 3, "extendedScore": null, "score": 7.125606025872999e-07, "legacy": true, "legacyId": "7283", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T17:55:25.123Z", "modifiedAt": null, "url": null, "title": "Chemicals and Electricity", "slug": "chemicals-and-electricity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:55.258Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lionhearted", "createdAt": "2010-07-29T13:30:07.417Z", "isAdmin": false, "displayName": "lionhearted"}, "userId": "tooJeLNxoeccqGEky", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CitdRW9NmTyjm3voL/chemicals-and-electricity", "pageUrlRelative": "/posts/CitdRW9NmTyjm3voL/chemicals-and-electricity", "linkUrl": "https://www.lesswrong.com/posts/CitdRW9NmTyjm3voL/chemicals-and-electricity", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Chemicals%20and%20Electricity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AChemicals%20and%20Electricity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCitdRW9NmTyjm3voL%2Fchemicals-and-electricity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Chemicals%20and%20Electricity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCitdRW9NmTyjm3voL%2Fchemicals-and-electricity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCitdRW9NmTyjm3voL%2Fchemicals-and-electricity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1137, "htmlBody": "<p>I'm doing some work for an old friend of mine.</p>\n<p>His situation is interesting. Not too long ago, he lost his job and got divorced, and otherwise his life got pretty screwed up and off-track.</p>\n<p>He left the United States, took a job below his old skill level for a while, and then stopped that and started a company. Now he's living an exceptional life, and on the verge of making a lot of money.</p>\n<p>I thought that was awesome, and I was quite happy for him. After we'd gotten done going through a lot of numbers, choosing some vendors, designing some systems, and otherwise figuring business out on the phone, we talked personal life. I said, \"Man, I'm so happy for you. So much is going right. Congratulations.\"</p>\n<p>He wasn't excited. He was a little worried.</p>\n<p>He said, \"Sebastian, man... I hope I don't change. I like who I am right now, I hope this doesn't change me.\"</p>\n<p>And you know what?</p>\n<p>His fears are valid. He's going to change.</p>\n<p>Almost guaranteed.<a id=\"more\"></a></p>\n<p>--</p>\n<p>Eliezer cover why power corrupts in the appropriately titled, \"<a href=\"/lw/uu/why_does_power_corrupt/\">Why Does Power Corrupt?</a>\"</p>\n<p>But to understand the nature of this, you have to realize something that's (1) entirely true, (2) potentially unpleasant, (3) not thought about very often, and (4) has the risk of \"not even seeming profound\" when it's said -- despite the importance of it.</p>\n<p>That is:</p>\n<p><strong>You're a bunch of chemicals and electricity.</strong></p>\n<p>Well, that's slightly imprecise. You're actually matter and energy. But give me some slack with terms, because chemicals and electricity are going to get the point across more elegantly.</p>\n<p>There's an illusion that we're in control of our actions, and that all of them are consciously chosen. I do think we have a tremendous amount of control over our lives, moreso than most people realize. But that control comes over relatively long periods of time, not minute-by-minute.</p>\n<p>Minute-by-minute, your thinking and actions are the product of <em>the matter and energy that is you</em> moving around and interacting. Specifically, your biochemicals and electricity in your brain have a <em>huge</em> impact on your thoughts and actions.</p>\n<p>Reading \"<a href=\"http://www.amazon.com/gp/product/0761142908/ref=as_li_ss_tl?ie=UTF8&amp;tag=sebastianmcom-20&amp;linkCode=as2&amp;camp=217145&amp;creative=399349&amp;creativeASIN=0761142908\">Take a Nap, Change Your Life</a>\" by Dr. Sara Mednick really opened up my perspective on this. I read the book while I was researching getting more productivity and creativity out of napping, and I was looking right to her recommendations for better sleep and sleep cycles.</p>\n<p>But she goes into neurochemistry and how the brain works in the book a lot as well. One line that stood out to me is, \"Neurons that fire together become wired together.\"</p>\n<p>The more you think a certain way or do a certain task, the closer the neuron pathways in your brain become wired, and the faster and more reflectively you can do that task - and with <a href=\"http://www.sebastianmarshall.com/the-cognitive-costs-to-doing-things\">less cognitive cost</a>.&nbsp;</p>\n<p>That's good news if you want to learn to play the flute, and bad news if you want to stop eating so many Cheetos.</p>\n<p>Likewise, the mechanism of action for caffeine is that it's an adenosine antagonist. To make a long story really short, adenosine is a neurotransmitter that makes you feel tired. Caffeine molecules are shaped similar to adenosine and get in the way of it, \"blocking\" the adenosine from getting to an adenosine receptor.</p>\n<p>Some other things happen, it's more complicated than that. But basically - caffeine's primary mechanism of action is that it makes you think you're not sleepy by blocking the thing that tells you you're sleepy.</p>\n<p>Testosterone is one of the more famous hormones. A lot of studies suggest a link between aggression and testosterone.</p>\n<p>While I'm a sample size of exactly one, I've found testosterone correlates highly with aggression in myself. It's notable enough that I actually try to change my fitness cycles so that I'm higher testosterone when I'm doing tasks that need aggression, assertiveness, or persistence - things like sales, negotiation, or training in martial arts. I try to lose weight and eat a caloric deficit when more assertiveness wouldn't be especially helpful, and try to eat a caloric surplus and lift weights when it would.</p>\n<p>--</p>\n<p>What the \"chemicals and electricity view of humans\" says, basically, is that your short term thoughts and actions are chemical/electrical reactions. When your inputs change, your chemicals and electricity are modified.</p>\n<p>If you do a task a lot, the neurons wire together and fire easier.</p>\n<p>If you take caffeine, it blocks adenosine receptors and you feel more awake.</p>\n<p>If you increase your testosterone, assertive behaviors might come easier.</p>\n<p>When \"someone changes,\" it's partially a function of their chemicals and electricity changing. Being in a dangerous country and needing to be at high awareness is going to affect your biochemistry, which is going to affect your thoughts and actions. Becoming more wealthy is going to affect your biochemistry, which is going to affect your thoughts and actions.</p>\n<p>You can mediate this to some extent. Changing your interpretation of events definitely changes your potential internal chemical reactions to them. When I hear that the Memphis Grizzlies basketball team defeated the San Antonio Spurs, I feel neutral. But a Spurs fan might feel some malaise and have his happiness and energy promoting biochemicals drop, whereas a Grizzlies fan might be getting crazily excited.</p>\n<p>If you were neutral but moved to San Antonio or Memphis, you might have a different reaction to the event. Things are under your control to some extent, in terms of processing how you want to react to things - but in my opinion, <em>mostly only on longer term time scales</em>. If you'd been devotedly following the Spurs this season, you're going to feel bad when they were eliminated.</p>\n<p>This suggests that you <em>could</em> anticipate changes that would happen, and change your processing to them... but it's probably not easy to do. Absolute power and all...</p>\n<p>My friend's chemistry and electricity is going to change - he's in charge now, which brings its own host of benefits and neuroses with it. He's going to be wealthy, which changes you. He's in a foreign country and a different ethnicity of the people there, so he stands out, and that changes you.</p>\n<p>This isn't all conscious. A lot of it isn't. But the inputs you have into your life affect you. Your hormonal balance and biochemistry and other chemicals and matter are affected by what happens around you, to you, what you ingest, your environment, and what you do. This makes it likely you'll take or not take other kinds of actions, which has a feedback loop in your thoughts - the neurons fire more often, and wire together, making them easier to fire.</p>\n<p>When things around you change, you're going to change. There's an illusion of a great deal of control over our moment by moment thinking. I agree we have a lot of control over our lives, but it's only on a long term scale - and some of the largest gains in control are from controlling the inputs that affect your chemicals and electricity.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CitdRW9NmTyjm3voL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 9, "extendedScore": null, "score": 7.125637788667618e-07, "legacy": true, "legacyId": "7284", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["v8rghtzWCziYuMdJ5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T19:01:14.541Z", "modifiedAt": null, "url": null, "title": "Meetup report: Darwin, Some Rationalists and the Joker [link]", "slug": "meetup-report-darwin-some-rationalists-and-the-joker-link", "viewCount": null, "lastCommentedAt": "2018-04-12T17:00:32.592Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/joDKykeeR2R3WFECZ/meetup-report-darwin-some-rationalists-and-the-joker-link", "pageUrlRelative": "/posts/joDKykeeR2R3WFECZ/meetup-report-darwin-some-rationalists-and-the-joker-link", "linkUrl": "https://www.lesswrong.com/posts/joDKykeeR2R3WFECZ/meetup-report-darwin-some-rationalists-and-the-joker-link", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20report%3A%20Darwin%2C%20Some%20Rationalists%20and%20the%20Joker%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20report%3A%20Darwin%2C%20Some%20Rationalists%20and%20the%20Joker%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoDKykeeR2R3WFECZ%2Fmeetup-report-darwin-some-rationalists-and-the-joker-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20report%3A%20Darwin%2C%20Some%20Rationalists%20and%20the%20Joker%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoDKykeeR2R3WFECZ%2Fmeetup-report-darwin-some-rationalists-and-the-joker-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoDKykeeR2R3WFECZ%2Fmeetup-report-darwin-some-rationalists-and-the-joker-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 279, "htmlBody": "<p>This past weekend the <a href=\"http://groups.google.com/group/less-wrong-ottawa\">Ottawa LessWrong meetup</a> hosted <a href=\"http://www.tempobook.com/about-the-author/\">Venkat Rao</a>, who is on a nomadic journey to promote his (good) <a href=\"http://www.tempobook.com/\">new book</a> and to find enlightenment through deliberate idleness.</p>\n<p>I thought the <a href=\"http://www.tempobook.com/2011/05/08/darwin-some-rationalists-and-the-joker/\">resulting post</a> might be of some interest.</p>\n<p>Here's an excerpt:</p>\n<blockquote>\n<p>For those of you aren&rsquo;t familiar with Less Wrong, it is a community of rationalists associated with the Singularity Institute. I admit I was rather wary and curious at the same time.</p>\n<p>[...]</p>\n<p>I suspect I am in a sort of <a href=\"http://www.ribbonfarm.com/2009/09/17/your-evil-twins-and-how-to-find-them/\">evil-twin</a> relationship with the Less Wrong philosophy of cognition and decision-making. When I said this at the meetup, one of the attendees remarked, &ldquo;&hellip;and you&rsquo;re the evil twin.&rdquo;</p>\n<p>[...]</p>\n<p>To my pleasant surprise though, the meeting was a great deal of fun. I guess I was sort of expecting an inquisition by a panel of Spocks given the views I espouse, but it was mainly a freewheeling open-ended discussion that went down plenty of interesting rabbit holes. Beer, nachos and bad geek jokes flowed freely.</p>\n<p>[...]</p>\n<p>I am now less wary of the lesswrongers than I used to be. They bring a healthy sense of doubt, irony, aesthetics and skepticism to their passion for rationality.</p>\n</blockquote>\n<p>He goes on to say that he'll continue to make fun of LessWrongers, but it says something of Venkat's charming wit that he was able to drop the \"Spock\" and \"faith\" bombs (both of which irk me), and I still like the guy.</p>\n<p>On a related note, it was a great deal of fun having a special guest appearance. If anyone's passing through, please drop a line! I'd recommend either coming in the summer, or bringing your <a href=\"http://www.canadascapital.gc.ca/bins/ncc_web_content_page.asp?cid=16297-16299-10080&amp;bhcp=1&amp;lang=1\">ice skates</a>!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "joDKykeeR2R3WFECZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 22, "extendedScore": null, "score": 3.8e-05, "legacy": true, "legacyId": "7279", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T19:40:04.436Z", "modifiedAt": null, "url": null, "title": "When Intuitions Are Useful", "slug": "when-intuitions-are-useful", "viewCount": null, "lastCommentedAt": "2020-09-02T00:49:39.541Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/myLSqHNgi6BumABvE/when-intuitions-are-useful", "pageUrlRelative": "/posts/myLSqHNgi6BumABvE/when-intuitions-are-useful", "linkUrl": "https://www.lesswrong.com/posts/myLSqHNgi6BumABvE/when-intuitions-are-useful", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20When%20Intuitions%20Are%20Useful&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhen%20Intuitions%20Are%20Useful%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmyLSqHNgi6BumABvE%2Fwhen-intuitions-are-useful%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=When%20Intuitions%20Are%20Useful%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmyLSqHNgi6BumABvE%2Fwhen-intuitions-are-useful", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmyLSqHNgi6BumABvE%2Fwhen-intuitions-are-useful", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3246, "htmlBody": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>In this series, I have examined how intuitions work so that I can clarify how rationalists<sup>1</sup>&nbsp;<em>should</em> and <em>shouldn't</em> use their intuitions<sup>2</sup>&nbsp;when solving philosophical problems. Understanding the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/How_an_algorithm_feels\">cognitive algorithms that generate our intuitions</a>&nbsp;can&nbsp;<a href=\"/lw/of/dissolving_the_question/\">dissolve</a>&nbsp;traditional philosophical problems. As Brian Talbot puts it:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>...where psychological research indicates that certain intuitions are likely to be inaccurate, or that whole categories of intuitions are not good evidence, this will overall benefit philosophy. This has the potential to resolve some problems due to conflicting intuitions, since some of the conflicting intuitions may be shown to be unreliable and not to be taken seriously; it also has the potential to free some domains of philosophy from the burden of having to conform to our intuitions, a burden that has been too heavy to bear in many cases...<sup>3</sup></p>\n</blockquote>\n<p>Knowing how intuitions work can also tell us something about how we can train them to make them render more accurate judgments.<sup>4</sup></p>\n<p>&nbsp;</p>\n<h4><a name=\"problems\"></a>Problems with intuition</h4>\n<p>In <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy#non-quine\">most philosophy</a>, intuitions play the role that observations do in science: they support and undermine various theories.<sup>5</sup> Conceptual analyses are rejected when intuitive counterexamples are presented. Moral theories are rejected when they lead to intuitively revolting results. Theories of mind and language and metaphysics rise and fall depending on how well they can be made to fit our intuitions, even in bizarre science fiction hypothetical scenarios.<sup>6</sup></p>\n<p>But why trust our intuitions? Our intuitions often turn out to contradict each other,<sup>7</sup> or they are contradicted by empirical evidence,<sup>8</sup> or they vary between people and between groups of people.<sup>9</sup> Compared to scientific methods, the philosopher's use of intuitions as his primary tool doesn't seem to have been very productive.<sup>10</sup> Also, we can't calibrate our intuitions, because wherever we <em>have</em>&nbsp;a non-intuition standard against which to calibrate our intuitions, we don't need to use intuition in the first place.<sup>11</sup> Moreover, philosophers have typically known very little about where their intuitions come from, and why they should trust them in the first place!<sup>12</sup></p>\n<p>Defenders of intuitionist philosophy reply that we can't do philosophy without intuitions.<sup>13</sup>&nbsp;Others point out that we have similar worries about the reliability of of sense perception.<sup>14&nbsp;</sup>But these replies do not solve the problem. As Talbot says,<sup>3</sup> these responses \"give us reasons to <em>want</em> to trust intuitions... but no evidence that they are particularly reliable or useful.\"</p>\n<p>The way forward is not to give <em><a href=\"/lw/k2/a_priori/\">a priori</a></em>&nbsp;arguments for or against the use of intuitions. The way forward is to explore what cognitive science can tell us about how our intuitions work (as <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">we've</a> <a href=\"/lw/5bw/your_evolved_intuitions/\">been</a> <a href=\"/lw/59v/intuition_and_unconscious_learning/\">doing</a>) so that we have some idea about when they work and when they don't.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>What is intuition?</h4>\n<p>But first, what <em>is</em>&nbsp;this 'intuition' we're talking about?&nbsp;Definitions of 'intuition' abound.<sup>15</sup></p>\n<p>In 2008, Eliezer wrote a post about&nbsp;<a href=\"/lw/n9/the_intuitions_behind_utilitarianism/\">the 'intuitions' behind utilitarianism</a>. He responded to a critic who used the word 'intuition' in a very broad sense - perhaps meaning&nbsp;<em style=\"font-style: italic;\">all thoughts and seemings.</em>&nbsp;But when we use the word so broadly, then the word is not so useful anymore - like the word 'god' after you've redefined it to mean 'a higher power'. When I talk about 'intuition', I want to talk about intuition in a more specific and useful way (as Eliezer would appreciate<sup>16</sup>).</p>\n<p>But we don't need to argue about definitions. We can use stipulation. We can <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">argue about the substance rather than the symbol</a>.</p>\n<p>For now, let's think of the thing we're investigating as the&nbsp;<em>seeming to be true</em>&nbsp;of some proposition due to an <em>opaque</em> mental process (and not memory or perception). After all, if intuitions were transparent, we could just point to <em>the things that ground them</em> as evidence, and the intuitions themselves would add no weight of their own to our evidence.<sup>3</sup></p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>When intuitions are useful</h4>\n<p>As we are discussing it, an intuition is a judgment that springs from the unconscious. And from where does the unconscious get its judgments? From <a href=\"/lw/5bw/your_evolved_intuitions/\">evolution</a><sup>17</sup> and from <a href=\"/lw/59v/intuition_and_unconscious_learning/\">unconscious learning</a><sup>18</sup> and from&nbsp;<a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">attribute substitution heuristics</a>.<sup>19</sup></p>\n<p>Before considering how these sources of intuitions make them <em>unsuitable</em> for many of their popular uses in philosophy, let's acknowledge how effective intuitions are in <em>some</em> situations.</p>\n<p>Familiarity with recent cognitive science has led many to conclude that \"being more analytic and less intuitive should help you to develop more effective and rewarding solutions.\"<sup>20</sup> But recent investigations have located a few&nbsp;circumstances in which intuitions outperform considered judgments.</p>\n<p>In one study, basketball experts asked to make spontaneous predictions about the outcomes of a basketball tournament made more accurate predictions than those asked to deliberate carefully about their predictions.<sup>21</sup>&nbsp;Other studies on intuition vs. deliberation have found intuition 'winning' on tests of certain kinds of face recognition,<sup>22</sup> route recognition,<sup>23</sup> and voice recognition,<sup>24</sup> while deliberation 'won' on tests of subadditivity probability judgments,<sup>25</sup> raffle-winning probability judgments,<sup>26&nbsp;</sup>quantity estimation,<sup>27</sup> picture recognition,<sup>28</sup> conjunctions and disjunctions,<sup>29</sup> and conditional inferences.<sup>30</sup></p>\n<p>Better-supported is a trend in research which finds that when selecting products to to take home with us, we end up feeling more satisfied with our choice if we made it using intuition rather than a conscious process of weighing pros and cons, costs and benefits.<sup>31</sup></p>\n<p>And if you're trying to avoid collisions or catch a baseball, you're better off acting on your split-second intuition than trying to calculate the physics of moving objects.<sup>32</sup>&nbsp;</p>\n<p>Some authors have suggested other, very specific domains in which intuition may surpass the accuracy of considered judgment,<sup>33&nbsp;</sup>but these claims are not yet well substantiated.</p>\n<p>You may have noticed that the domains in which intuition might excel are not particular relevant to solving philosophical problems. In the next post, we'll begin to examine the ways in which intuitions can lead us astray when doing philosophy.</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/7tz/philosophy_by_humans_1_concepts_dont_work_that_way/\">Concepts Don't Work That Way</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/59v/intuition_and_unconscious_learning/\">Intuitions and Unconscious Learning</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><span style=\"font-size: 11px;\"><sup>1</sup>&nbsp;I use the term 'rationalists' as Less Wrong uses the term, not as the mainstream philosophical community&nbsp;<a href=\"http://en.wikipedia.org/wiki/Rationalism\">uses</a>&nbsp;the term. As Less Wrong uses the term, a 'rationalist' is someone devoted to the craft of refining their rationality by counteracting known cognitive biases and trying to make their beliefs and decisions track with technically correct beliefs and decisions (defined with reference to, for example, Bayes' theorem and decision theory).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>2</sup>&nbsp;In the preface of Plessner et al. (2009), the authors provide a handy list of search terms for those who wish to research the science of intuition on their own: \"unconscious perceptions, 'blindsight,' pattern recognition, instinct, automatic processing, experiential knowing, tacit knowledge, religious experiences, emotional intelligence, nonverbal communication, clinical diagnoses, 'thin slices of behavior,' spontaneous trait inferences, the 'mere exposure' effect, the primacy of affect, 'thinking too much,' priming, feelings as information, implicit attitudes, expertise, creativity, and the 'sixth sense.'\" They recommend the following sources as \"excellent overviews\" for studying these terms and ideas:&nbsp;Bastick (1982); Davis-Floyd &amp; Arvidson (1992); Hogarth (2001); Myers (2002); Wilson (2002).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>3</sup>&nbsp;Talbot (2009).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>4</sup>&nbsp;Hogarth (2001, 2007).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>5</sup>&nbsp;Cummins (1998); Talbot (2009).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>6</sup>&nbsp;Talbot (2009) provides a nice little summary of how intuitions are used in philosophy (I've changed his citations to the original articles in some cases): \"Intuitions about understanding Chinese are used by John Searle to argue against what he calls &ldquo;strong AI&rdquo; (Searle, 1980). In the philosophy of action, intuitions about playing video games are used by Michael Bratman to argue that we can try to do something without intending to do it (Bratman, 1987). Intuitions are used as counter-evidence against compatibilism (Bok, 1998). One of the most famous use of intuitions as counter evidence comes from epistemology: Gettier cases (Gettier, 1963). In metaphysics, intuitions are appealed to to argue for theories of causation (e.g., Lewis, 1973), and against them (by pointing out that they have counter-intuitive consequences, such as transitivity) (Hall, 2000). In ethics, Judith Jarvis Thomson uses intuitions about violinists and carpets to argue for her claim that abortion can be morally acceptable despite having a right to life (Thomson, 1971). Bernard Williams uses intuitions about killing rebels as counter-evidence against utilitarianism (Williams &amp; Smart, 1973). In the philosophy of language, Tyler Burge uses intuitions about &ldquo;arthritis&rdquo; to argue for meaning externalism (Burge, 1979), and Saul Kripke uses intuitions about G&ouml;del to argue against a descriptivist view of names (Kripke, 1972). This list goes on and on.\"</span></p>\n<p><span style=\"font-size: 11px;\"><sup>7</sup>&nbsp;Suppes (1984); Cummins (1998).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>8</sup>&nbsp;Wisniewski (1998);&nbsp;Hastie &amp; Dawes (2009); Gilovich (1991); Kahneman, Slovic, &amp; Tversky (1982); Nisbett &amp; Ross (1980); Stanovich (2009).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>9</sup>&nbsp;Stich (1988);&nbsp;Weinberg, Nichols, &amp; Stich (2001);&nbsp;Swain, Alexander, &amp; Weinberg (2008).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>10</sup>&nbsp;Bishop &amp; Trout (2004); Miller (2000). Talbot (2009) explains: \"Consider the state of philosophy, they say. There is little agreement on most key issues, we have produced few theories that have been very successful or survived criticism, and philosophy has accomplished little of practical significance in the last few hundred years. There is nothing about the subject matter of philosophy that makes these results inevitable; most of us believe that there are answers out there to be found, and at least some philosophical disciplines can produce useful results. This gives us reason to think that we are studying the right stuff but in the wrong way. Some aspects of our methodology &ndash; logic and rigorous thought &ndash; are beyond criticism, and thus, they say, the blame for philosophy&rsquo;s lack of success falls on our use of intuitions.\"</span></p>\n<p><span style=\"font-size: 11px;\"><sup>11</sup>&nbsp;Cummins (1998); Talbot (forthcoming).</span></p>\n<p><span style=\"font-size: 11px;\"><span style=\"font-size: small;\"> </span></span></p>\n<p><small><sup>12</sup>&nbsp;Cummins (1998);&nbsp;Wisniewski (1998).</small></p>\n<p><small><sup>13</sup>&nbsp;Sosa (1998); Bealer (1998); BonJour (1998).</small></p>\n<p><small><sup>14</sup>&nbsp;Sosa (1998); Pust (2000).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>15</sup>&nbsp;Bealer (1996) refers to intuitions as&nbsp;<em style=\"font-style: italic;\">a priori</em>&nbsp;seemings of the sort by which&nbsp;<a href=\"http://en.wikipedia.org/wiki/De_Morgan%27s_Laws\">De Morgan's laws</a>&nbsp;come to seem true to someone - intellectual seemings, not perceptions or imaginative seemings. Sosa (1998) defines 'intuition' as \"noninferential belief due neither to perception nor introspection,\" but sees intuition as focused on abstract propositions: \"At t, S has an intuition that p iff (a) if at t S were merely to understand fully enough the proposition that p (absent relevant perception, introspection, and reasoning), then S would believe that p; (b) at t, S does understand the proposition that p; (c) the proposition that p is an abstract proposition; and (d) at t, S thinks occurrently of the proposition that p (in propria persona, not just by description).\" Williamson (2004) describes intuitions as \"applications of our ordinary capacities for judgment\" and says \"when contemporary analytic philosophers run out of arguments, they appeal to intuition.\" Gopnik &amp; Schwitzgebel (1998) say: \"We will call any judgment an intuitive judgment, or more briefly an intuition, just in case that judgment is not made on the basis of some kind of explicit reasoning process that a person can consciously observe. Intuitions are judgments that grow, rather, out of an underground process... that cannot be directly observed.\" Goldman &amp; Pust (1998) briefly refer to intuitions as \"spontaneous moral judgments.\" Talbot (2009) calls an intuition \"a relatively unreflective reaction that a proposition is true or false.\" Or, more precisely, he says \"an intuition is the seeming to be true (although not necessarily acceptance of or belief in) of some proposition that is not a perceptual seeming, or due to conscious recollection, or due entirely to transparent mental processes.\" Hogarth (2001) says intuitions \"are reached with little apparent effort and typically without conscious awareness. They involve little or no conscious deliberation.\" According to the 'associative learning' view of intuition, intuition draws on the whole stream of past experiences:&nbsp;Betsch et al. (2004);&nbsp;Betsch &amp; Haberstroh (2005). Betsch (2007) offers a definition of intuition from this perspective: \"Intuition is a process of thinking. The input to this process is mostly provided by knowledge stored in long-term memory that has been primarily acquired via associative learning. The input is processed automatically and without conscious awareness. The output of the process is a feeling that can serve as abasis for judgments and decisions.\" Note that the view of intuition from the heuristics and biases perspective (Kahneman &amp; Frederick 2002, 2005) and from the associative learning view are generally not contradictory but rather complementary. Finally, also see surveys of opinion on the nature of intuition, for example Abernathy &amp; Hamm (1995).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>16</sup>&nbsp;In his&nbsp;<a href=\"/lw/n9/the_intuitions_behind_utilitarianism/\">post</a>, Eliezer responds to his critic's broad definition of 'intuition' like this: \"Now 'intuition' is not how I would describe the computations that underlie human morality and distinguish us, as moralists, from an ideal philosopher of perfect emptiness and/or a rock. But I am okay with using the word \"intuition\" as a term of art, bearing in mind that \"intuition\" in this sense is not to be contrasted to reason, but is, rather, the cognitive building block out of which both long verbal arguments and fast perceptual arguments are constructed.\"</span></p>\n<p><small><sup>17</sup> The field of <a href=\"http://en.wikipedia.org/wiki/Evolutionary_psychology\">evolutionary psychology</a> is rich with candidates for evolutionarily adaptive psychological predispositions, some more thoroughly supported by the evidence than others. For an overview, see Buss (2011); Dunbar &amp; Barrett (2007).</small></p>\n<p><small><sup>18</sup>&nbsp;Hogarth (2007); Sloman (1996); Sloman (2002); Evans &amp; Over (1996); Stanovich (2004); Mercier &amp; Sperber (2009); Betsch (2007); Epstein (2007).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>19</sup> Kahneman &amp; Frederick (2002, 2005).</span></p>\n<p><small><sup>20</sup> Kardes (2002), p. 402.</small></p>\n<p><small><sup>21</sup>&nbsp;Halberstadt and Levine (1999). For an overview of similar results, see Plessner &amp; Czenna (2007). For older studies, see Ambady &amp; Rosenthal (1992).</small></p>\n<p><small><sup>22</sup>&nbsp;Clare &amp; Lewandowsky (2004); Fallshore &amp; Schooler (1995); Halbertsadt (2005); Schooler &amp; Engstler-Schooler (1990).</small></p>\n<p><small><sup>23</sup>&nbsp;Fiore &amp; Schooler (2002).</small></p>\n<p><small><sup>24</sup>&nbsp;Perfect et al. (2002).</small></p>\n<p><small><sup>25</sup> Dougherty &amp; Hunter (2003).</small></p>\n<p><small><sup>26</sup> Windschitl &amp; Krizan (2005).</small></p>\n<p><small><sup>27</sup> Gilbert &amp; Rappoport (1975).</small></p>\n<p><small><sup>28</sup> Klimesch (1980); Silverberg &amp; Buchanan (2005).</small></p>\n<p><small><sup>29</sup> Kruglanski &amp; Freund (1983).</small></p>\n<p><small><sup>30</sup> Schroyens et al. (2003).</small></p>\n<p><small><sup>31</sup>&nbsp;Dijksterhuis &amp; van Olden (2005); Dijksterhuis et al. (2006).</small></p>\n<p><small><sup>32</sup> Gigerenzer (2007), ch. 1.</small></p>\n<p><small><sup>33</sup> Gigerenzer (2007); Gladwell (2005).</small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Abernathy &amp; Hamm (1995).&nbsp;<em><a href=\"http://www.amazon.com/Surgical-Intuition-What-How-Get/dp/1560530596/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Surgical intuition: What it is and how to get it</a></em>. Hanley &amp; Belfus.</small></p>\n<p><small>Ambady &amp; Rosenthal (1992). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Ambady-Rosenthal-Thin-Slices-of-Expressive-Behavior-as-Predictors-of-Interpersonal-Consequences-A-Meta-Analysis.pdf\">Thin Slices of Expressive Behavior as Predictors of Interpersonal Consequences: A Meta-Analysis</a>. <em>Psychological Bulletin, 111</em>: 256-274.</small></p>\n<p><small>Bastick (1982). <em><a href=\"http://www.amazon.com/Intuition-How-We-Think-Act/dp/0471279927/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition: How we think and act</a></em>. Wiley.</small></p>\n<p><small>Bealer (1996).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Bealer-A-priori-knowledge-and-the-scope-of-philosophy.pdf\">A priori knowledge and the scope of philosophy</a>.&nbsp;<em style=\"font-style: italic;\">Philosophical Studies, 81(2/3)</em>: 121-142.</small></p>\n<p><small>Bealer (1998). Intuition and the autonomy of philosophy.&nbsp;In De Paul &amp; Ramsey (eds.),&nbsp;<em style=\"font-style: italic; \">Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Betsch (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Betsch-The-nature-of-intuition-and-its-neglect-in-research-on-judgment-and-decision-making.pdf\">The Nature of Intuition and Its Neglect in Research on Judgment and Decision Making</a>. In&nbsp;Plessner, Betsch, &amp; Betsch (eds.), <em>Intuition in Judgment and Decision Making&nbsp;</em>(pp. 3-22). Psychology Press.</small></p>\n<p><small>Betsch &amp; Haberstroh, eds. (2005). <em><a href=\"http://www.amazon.com/Routines-Decision-Making-Tilmann-Betsch/dp/0805846131/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The routines of decision making</a></em>. Lawrence Erlbaum Associates.</small></p>\n<p><small>Betsch, Plessner, &amp; Schallies&nbsp;(2004).&nbsp;The value-account model of attitude formation. In Maio &amp; Haddock (eds.), <em>Contemporary perspectives on the psychology of attitudes</em> (pp. 252&ndash;273). Psychology Press.</small></p>\n<p><small>Bishop &amp; Trout (2004).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/Epistemology-Psychology-Judgment-Michael-Bishop/dp/0195162307/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Epistemology and the Psychology of Human Judgment</a></em>. Oxford University Press.</small></p>\n<p><small>Bok (1998). <em><a href=\"http://www.amazon.com/Freedom-Responsibility-Hilary-Bok/dp/069101566X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Freedom and Responsibility</a></em>. Princeton University Press.</small></p>\n<p><small>BonJour (1998). <em><a href=\"http://www.amazon.com/Defense-Pure-Reason-Rationalist-Justification/dp/0521592364/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">In Defense of Pure Reason</a></em>. Cambridge University Press.</small></p>\n<p><small>Bratman (1987). <em><a href=\"http://www.amazon.com/Intention-Practical-Reason-Michael-Bratman/dp/1575861925/\">Intentions, Plans, and Practical Reason</a></em>. Harvard University Press.</small></p>\n<p><small>Burge (1979). Individualism and the mental. <em>Midwest Studies in Philosophy, 4</em>: 73-121.</small></p>\n<p><small>Buss (2011). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-New-Science-Mind/dp/020501562X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Evolutionary psychology: The new science of mind (4th ed.)</a></em>. Prentice Hall.</small></p>\n<p><small>Clare &amp; Lewandowsky (2004).&nbsp;Verbalizing facial memory: Criterion effects in verbal overshadowing. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition, 30</em>: 739&ndash;755.</small></p>\n<p><small>Cummins (1998). Reflection on reflective equilibrium.&nbsp;In De Paul &amp; Ramsey (eds.),&nbsp;<em style=\"font-style: italic; \">Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Davis-Floyd &amp; Arvidson, eds. (1992). <em><a href=\"http://www.amazon.com/Intuition-Inside-Story-Interdisciplinary-Perspectives/dp/0415915945/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition: the inside story</a></em>. Routledge.</small></p>\n<p><small>Dijksterhuis &amp; van Olden (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Dijksterhuis-On-the-benefits-of-thinking-unconsciously.pdf\">On the benefits of thinking unconsciously: Unconscious&nbsp;thought can increase post-choice satisfaction</a>.&nbsp;<em>Journal of Experimental Social Psychology, 42</em>: 627&ndash;631.</small></p>\n<p><small>Dijksterhuis, Bos, Nordgren, &amp; van Baaren (2006). On making the right choice: The dliberation-without-attention effect. Science, 17: 1005-1007.</small></p>\n<p><small>Dougherty &amp; Hunter (2003).&nbsp;Probability judgment and subadditivity: The role of working memory capacity and constraining retrieval. <em>Memory and Cognition, 31</em>: 968&ndash;982.</small></p>\n<p><small>Dunbar &amp; Barrett, eds. (2007). <em><a href=\"http://www.amazon.com/Oxford-Handbook-Evolutionary-Psychology-Library/dp/0198568304/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford handbook of evolutionary psychology</a></em>. Oxford University Press.</small></p>\n<p><small>Epstein (2007).&nbsp;Intuition From the Perspective of Cognitive-Experiential Self-Theory.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 23-37). Psychology Press.</small></p>\n<p><small>Evans &amp; Over (1996). <em><a href=\"http://www.amazon.com/Rationality-Reasoning-Essays-Cognitive-Psychology/dp/0863774385/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rationality and reasoning</a></em>. Psychology Press.</small></p>\n<p><small>Fallshore &amp; Schooler (1995).&nbsp;Verbal vulnerability of perceptual expertise. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition, 21</em>: 1608&ndash;1623.</small></p>\n<p><small>Fiore &amp; Schooler (2002).&nbsp;How did you get here from there? Verbal overshadowing of spatial mental models. <em>Applied Cognitive Psychology, 16</em>: 897&ndash;909.</small></p>\n<p><small>Gettier (1963). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/01/Gettier-Is-Justified-True-Belief-Knowledge.pdf\">Is justified true belief knowledge?</a> <em>Analysis, 23</em>: 121-123.</small></p>\n<p><small>Gigerenzer (2007). <em><a href=\"http://www.amazon.com/Gut-Feelings-Intelligence-Gerd-Gigerenzer/dp/0143113763/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Gut Feelings: The Intelligence of the Unconscious</a></em>. Penguin.</small></p>\n<p><small>Gilbert &amp; Rappoport (1975).&nbsp;Categories of thought and variations in meaning: A demonstration experiment. <em>Journal of Phenomenological Psychology, 5</em>: 419&ndash;424.</small></p>\n<p><small>Gilovich (1991). <em><a href=\"http://www.amazon.com/How-Know-What-Isnt-Fallibility/dp/0029117062/\">How We Know What Isn't So: The Fallibility of Human Reason in Everyday Life</a></em>. Free Press.</small></p>\n<p><small>Gladwell (2005). <em><a href=\"http://www.amazon.com/Blink-Power-Thinking-Without/dp/0316010669/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Blink: The Power of Thinking Without Thinking</a>. </em>Black Bay Books.</small></p>\n<p><small>Goldman &amp; Pust (1998). Philosophical theory and intuitional evidence. In De Paul &amp; Ramsey (eds.), <em>Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Gopnik &amp; Schwitzgebel (1998). Whose concepts are they anyway? The role of philosophical intuition in empirical psychology. In De Paul &amp; Ramsey (eds.), <em>Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Hall (2000). Causation and the price of transitivity. <em>Journal of Philosophy, 97(4)</em>: 198-222.</small></p>\n<p><small>Halbertsadt (2005).&nbsp;Featural shift in explanation-biased memory for emotional faces. <em>Journal of Personality and Social Psychology, 88</em>: 38&ndash;49.</small></p>\n<p><small>Halberstadt and Levine (1999).&nbsp;Effects of reasons analysis on the accuracy of predicting basketball games. <em>Journal of Applied Social Psychology, 29</em>: 517&ndash;530.</small></p>\n<p><small>Hastie &amp; Dawes (2009).&nbsp;<em><a href=\"http://www.amazon.com/Rational-Choice-Uncertain-World-Psychology/dp/1412959039/\">Rational Choice in an Uncertain World, 2nd edition</a>.</em>&nbsp;Sage.</small></p>\n<p><small>Hogarth (2001). <em><a href=\"http://www.amazon.com/Educating-Intuition-Robin-M-Hogarth/dp/0226348628/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Educating intuition</a></em>. University of Chicago Press.</small></p>\n<p><small>Hogarth (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Hogarth-On-the-learning-of-intuition.pdf\">On the learning of intuition</a>.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 91-105). Psychology Press.</small></p>\n<p><small>Kahneman &amp; Frederick (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-Frederick-Representativeness-revisited.pdf\">Representativeness revisited: Attribute substitution in intuitive judgment</a>. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and biases: The psychology of intuitive judgment</em> (pp. 49-81). Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Frederick (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-A-model-of-heuristic-judgment.pdf\">A model of heuristic judgment</a>. In Holyoak &amp; Morrison (eds.), <em>The Cambridge Handbook of Thinking and Reasoning</em> (pp. 267-294). Cambridge University Press.</small></p>\n<p><small>Kahneman, Slovic, &amp; Tversky (1982).<em style=\"font-style: italic;\">&nbsp;<a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/\">Judgment Under Uncertainty: Heuristics and Biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Kardes (2002).&nbsp;<em><a href=\"http://www.amazon.com/Consumer-Behavior-Managerial-Decision-Making/dp/0130916021/\">Consumer behavior and managerial decision making (2nd ed.)</a></em>. Prentice Hall.</small></p>\n<p><small>Klimesch (1980).&nbsp;The effect of verbalization on memory performance for complex pictures. <em>Zeitschrift fu\u0308r Experimentelle und Angewandte Psychologie, 27</em>: 245&ndash;256.</small></p>\n<p><small>Kripke (1972). <em><a href=\"http://www.amazon.com/Naming-necessity-Saul-Kripke/dp/0631128018/\">Naming and Necessity</a></em>. Harvard University Press.</small></p>\n<p><small>Kruglanski &amp; Freund (1983).&nbsp;The freezing and unfreezing of lay-inferences: Effects on impressional primacy, ethnic stereotyping, and numerical anchoring. <em>Journal of Experimental Social Psychology, 19</em>: 448&ndash;468.</small></p>\n<p><small>Lewis (1973). Causation. <em>The Journal of Philosophy, 70(17)</em>: 556-567.</small></p>\n<p><small>Mercier &amp; Sperber (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Mercier-Sperber-Intuitive-and-reflective-inferences.pdf\">Intuitive and reflective inferences</a>. In Evans &amp; Frankish (eds.), <em>In two minds: Dual processes and beyond</em>. Oxford University Press</small></p>\n<p><small>Miller (2000). Without Intuitions. <em>Metaphilosophy, 31(3)</em>: 231-250.</small></p>\n<p><small>Myers (2002). <em><a href=\"http://www.amazon.com/Intuition-Powers-Perils-Yale-Nota/dp/0300103034/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition: Its powers and perils</a></em>. Yale University Press.</small></p>\n<p><small>Nisbett and Ross (1980).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/Human-Inference-Strategies-Shortcomings-Judgement/dp/0134450736/\">Human Inference: Strategies and Shortcomings of Social Judgment</a></em>. Prentice-Hall.</small></p>\n<p><small>Perfect, Hunt, &amp; Harris (2002).&nbsp;Verbal overshadowing in voice recognition. <em>Applied Cognitive Psychology, 16</em>: 973&ndash;980.</small></p>\n<p><small>Plessner, Betsch, &amp; Betsch, eds. (2007). <em><a href=\"http://www.amazon.com/Intuition-Judgment-Decision-Henning-Plessner/dp/0805857419/\">Intuition in judgment and decision making</a></em>. Psychology Press.</small></p>\n<p><small>Plessner &amp; Czenna (2007). The benefits of intuition.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 251-265). Psychology Press.</small></p>\n<p><small>Pust (2000). <a href=\"http://www.amazon.com/Intuitions-as-Evidence-Studies-Philosophy/dp/0815337639/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuitions as Evidence</a>. Garland.</small></p>\n<p><small>Schooler &amp; Engstler-Schooler (1990).&nbsp;Verbal overshadowing of visual memories: Some things are better left unsaid. <em>Cognitive Psychology, 22</em>: 36&ndash;71</small></p>\n<p><small>Schroyens, Schaeken, &amp; Handley (2003). In search of counter-examples: Deductive rationality in human reasoning. <em>Quarterly Journal of Experimental Psychology: A. Human Experimental Psychology, 56</em>: 1129&ndash;1145.</small></p>\n<p><small>Searle (1980). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Searle-Minds-Brains-and-Programs.pdf\">Minds, brains, and programs</a>. <em>Behavioral and Brain Sciences, 3</em>: 417-424.</small></p>\n<p><small>Silverberg &amp; Buchanan (2005).&nbsp;Verbal mediation and memory for novel figural designs: A dual interference study. <em>Brain and Cognition, 57</em>: 198&ndash;209</small></p>\n<p><small>Sloman (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sloman-The-empirical-case-for-two-systems-of-reasoning.pdf\">The empirical case for two systems of reasoning</a>.&nbsp;<em>Psychological Bulletin, 119</em>: 3-22.</small></p>\n<p><small>Sloman (2002). Two systems of reasoning. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and Biases: The Psychology of Intuitive Judgment</em>. Cambridge University Press.</small></p>\n<p><small>Sosa (1998). Minimal Intuition. In De Paul &amp; Ramsey (eds.), <em>Rethinking Intuition</em>. Rowman and Littlefield.</small></p>\n<p><small>Stanovich (2004). <em><a href=\"http://www.amazon.com/Robots-Rebellion-Finding-Meaning-Darwin/dp/0226771253/\">The robot&rsquo;s rebellion</a></em>. Chicago University Press.</small></p>\n<p><small>Stanovich (2009). <em><a href=\"http://www.amazon.com/How-Think-Straight-About-Psychology/dp/0205685900/\">How to Think Straight About Psychology, 9th edition</a></em>. Allyn &amp; Bacon.</small></p>\n<p><small>Stich (1988).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Stitch-Reflective-Equilibrium-Analytic-Epistemology-and-the-Problem-of-Cognitive-Diversity.pdf\">Reflective equilibrium, analytic epistemology and the problem of cognitive diversity</a>. <em>Synthese, 74(3)</em>: 391-413.</small></p>\n<p><small>Suppes (1984). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Suppes-Conflicting-intuitions-about-causality.pdf\">Conflicting intuitions about causality</a>. <em>Midwest Studies in Philosophy, 9(1)</em>: 151-168.</small></p>\n<p><small>Swain, Alexander, &amp; Weinberg (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Swain-The-instability-of-philosophical-intuitions.pdf\">The instability of philosophical intuitions: Running hot and cold on truetemp</a>. <em>Philosophy and Phenomenological Research, 76:</em> 138&ndash;155.</small></p>\n<p><small>Talbot (2009). <em><a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Talbot-How-to-use-intuitions-in-philosophy.pdf\">How to Use Intuitions in Philosophy</a></em>. Dissertation. University of Southern California.</small></p>\n<p><small>Talbot (forthcoming). The dilemma of calibrating intuitions.</small></p>\n<p><small>Thomson (1971). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Thomson-A-Defense-of-Abortion.pdf\">A defense of abortion</a>. <em>Philosophy and Public Affairs, 1(1)</em>: 47-66.</small></p>\n<p><small>Weinberg, Nichols, &amp; Stich (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Weinberg-Normativity-and-epistemic-intuitions.pdf\">Normativity and epistemic intuitions</a>. Philosophical Topics, 29(1/2): 429-460.</small></p>\n<p><small>Williams &amp; Smart (1973). <em><a href=\"http://www.amazon.com/Utilitarianism-Against-J-C-Smart/dp/052109822X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Utilitarianism: For and Against</a></em>. Cambridge University Press.</small></p>\n<p><small>Williamson (2004).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Williamson-Philosophical-&lsquo;Intuitions&rsquo;-and-Scepticism-about-Judgement.pdf\">Philosophical &lsquo;intuitions&rsquo; and scepticism about judgement</a>. <em>Dialectica, 58(1)</em>: 109-153.</small></p>\n<p><small>Wilson (2002). <em><a href=\"http://www.amazon.com/Strangers-Ourselves-Discovering-Adaptive-Unconscious/dp/0674013824/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Strangers to ourselves: Discovering the adaptive unconscious</a></em>. Harvard University Press.</small></p>\n<p><small>Windschitl &amp; Krizan (2005).&nbsp;Contingent approaches to making likelihood judgments about polychotomous cases: The influence of task factors. <em>Journal of Behavioral Decision Making, 18</em>: 281&ndash;303.</small></p>\n<p><small>Wisniewski (1998). The psychology of intuition.&nbsp;In De Paul &amp; Ramsey (eds.),&nbsp;<em style=\"font-style: italic; \">Rethinking Intuition</em>. Rowan and Littlefield.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"z95PGFXtPpwakqkTA": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "myLSqHNgi6BumABvE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 18, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "6328", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "yFvZa9wkv5JoqhM8F", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "concepts-don-t-work-that-way", "canonicalPrevPostSlug": "intuition-and-unconscious-learning", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>In this series, I have examined how intuitions work so that I can clarify how rationalists<sup>1</sup>&nbsp;<em>should</em> and <em>shouldn't</em> use their intuitions<sup>2</sup>&nbsp;when solving philosophical problems. Understanding the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/How_an_algorithm_feels\">cognitive algorithms that generate our intuitions</a>&nbsp;can&nbsp;<a href=\"/lw/of/dissolving_the_question/\">dissolve</a>&nbsp;traditional philosophical problems. As Brian Talbot puts it:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>...where psychological research indicates that certain intuitions are likely to be inaccurate, or that whole categories of intuitions are not good evidence, this will overall benefit philosophy. This has the potential to resolve some problems due to conflicting intuitions, since some of the conflicting intuitions may be shown to be unreliable and not to be taken seriously; it also has the potential to free some domains of philosophy from the burden of having to conform to our intuitions, a burden that has been too heavy to bear in many cases...<sup>3</sup></p>\n</blockquote>\n<p>Knowing how intuitions work can also tell us something about how we can train them to make them render more accurate judgments.<sup>4</sup></p>\n<p>&nbsp;</p>\n<h4 id=\"Problems_with_intuition\"><a name=\"problems\"></a>Problems with intuition</h4>\n<p>In <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy#non-quine\">most philosophy</a>, intuitions play the role that observations do in science: they support and undermine various theories.<sup>5</sup> Conceptual analyses are rejected when intuitive counterexamples are presented. Moral theories are rejected when they lead to intuitively revolting results. Theories of mind and language and metaphysics rise and fall depending on how well they can be made to fit our intuitions, even in bizarre science fiction hypothetical scenarios.<sup>6</sup></p>\n<p>But why trust our intuitions? Our intuitions often turn out to contradict each other,<sup>7</sup> or they are contradicted by empirical evidence,<sup>8</sup> or they vary between people and between groups of people.<sup>9</sup> Compared to scientific methods, the philosopher's use of intuitions as his primary tool doesn't seem to have been very productive.<sup>10</sup> Also, we can't calibrate our intuitions, because wherever we <em>have</em>&nbsp;a non-intuition standard against which to calibrate our intuitions, we don't need to use intuition in the first place.<sup>11</sup> Moreover, philosophers have typically known very little about where their intuitions come from, and why they should trust them in the first place!<sup>12</sup></p>\n<p>Defenders of intuitionist philosophy reply that we can't do philosophy without intuitions.<sup>13</sup>&nbsp;Others point out that we have similar worries about the reliability of of sense perception.<sup>14&nbsp;</sup>But these replies do not solve the problem. As Talbot says,<sup>3</sup> these responses \"give us reasons to <em>want</em> to trust intuitions... but no evidence that they are particularly reliable or useful.\"</p>\n<p>The way forward is not to give <em><a href=\"/lw/k2/a_priori/\">a priori</a></em>&nbsp;arguments for or against the use of intuitions. The way forward is to explore what cognitive science can tell us about how our intuitions work (as <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">we've</a> <a href=\"/lw/5bw/your_evolved_intuitions/\">been</a> <a href=\"/lw/59v/intuition_and_unconscious_learning/\">doing</a>) so that we have some idea about when they work and when they don't.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"What_is_intuition_\">What is intuition?</h4>\n<p>But first, what <em>is</em>&nbsp;this 'intuition' we're talking about?&nbsp;Definitions of 'intuition' abound.<sup>15</sup></p>\n<p>In 2008, Eliezer wrote a post about&nbsp;<a href=\"/lw/n9/the_intuitions_behind_utilitarianism/\">the 'intuitions' behind utilitarianism</a>. He responded to a critic who used the word 'intuition' in a very broad sense - perhaps meaning&nbsp;<em style=\"font-style: italic;\">all thoughts and seemings.</em>&nbsp;But when we use the word so broadly, then the word is not so useful anymore - like the word 'god' after you've redefined it to mean 'a higher power'. When I talk about 'intuition', I want to talk about intuition in a more specific and useful way (as Eliezer would appreciate<sup>16</sup>).</p>\n<p>But we don't need to argue about definitions. We can use stipulation. We can <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">argue about the substance rather than the symbol</a>.</p>\n<p>For now, let's think of the thing we're investigating as the&nbsp;<em>seeming to be true</em>&nbsp;of some proposition due to an <em>opaque</em> mental process (and not memory or perception). After all, if intuitions were transparent, we could just point to <em>the things that ground them</em> as evidence, and the intuitions themselves would add no weight of their own to our evidence.<sup>3</sup></p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"When_intuitions_are_useful\">When intuitions are useful</h4>\n<p>As we are discussing it, an intuition is a judgment that springs from the unconscious. And from where does the unconscious get its judgments? From <a href=\"/lw/5bw/your_evolved_intuitions/\">evolution</a><sup>17</sup> and from <a href=\"/lw/59v/intuition_and_unconscious_learning/\">unconscious learning</a><sup>18</sup> and from&nbsp;<a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">attribute substitution heuristics</a>.<sup>19</sup></p>\n<p>Before considering how these sources of intuitions make them <em>unsuitable</em> for many of their popular uses in philosophy, let's acknowledge how effective intuitions are in <em>some</em> situations.</p>\n<p>Familiarity with recent cognitive science has led many to conclude that \"being more analytic and less intuitive should help you to develop more effective and rewarding solutions.\"<sup>20</sup> But recent investigations have located a few&nbsp;circumstances in which intuitions outperform considered judgments.</p>\n<p>In one study, basketball experts asked to make spontaneous predictions about the outcomes of a basketball tournament made more accurate predictions than those asked to deliberate carefully about their predictions.<sup>21</sup>&nbsp;Other studies on intuition vs. deliberation have found intuition 'winning' on tests of certain kinds of face recognition,<sup>22</sup> route recognition,<sup>23</sup> and voice recognition,<sup>24</sup> while deliberation 'won' on tests of subadditivity probability judgments,<sup>25</sup> raffle-winning probability judgments,<sup>26&nbsp;</sup>quantity estimation,<sup>27</sup> picture recognition,<sup>28</sup> conjunctions and disjunctions,<sup>29</sup> and conditional inferences.<sup>30</sup></p>\n<p>Better-supported is a trend in research which finds that when selecting products to to take home with us, we end up feeling more satisfied with our choice if we made it using intuition rather than a conscious process of weighing pros and cons, costs and benefits.<sup>31</sup></p>\n<p>And if you're trying to avoid collisions or catch a baseball, you're better off acting on your split-second intuition than trying to calculate the physics of moving objects.<sup>32</sup>&nbsp;</p>\n<p>Some authors have suggested other, very specific domains in which intuition may surpass the accuracy of considered judgment,<sup>33&nbsp;</sup>but these claims are not yet well substantiated.</p>\n<p>You may have noticed that the domains in which intuition might excel are not particular relevant to solving philosophical problems. In the next post, we'll begin to examine the ways in which intuitions can lead us astray when doing philosophy.</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/7tz/philosophy_by_humans_1_concepts_dont_work_that_way/\">Concepts Don't Work That Way</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/59v/intuition_and_unconscious_learning/\">Intuitions and Unconscious Learning</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><span style=\"font-size: 11px;\"><sup>1</sup>&nbsp;I use the term 'rationalists' as Less Wrong uses the term, not as the mainstream philosophical community&nbsp;<a href=\"http://en.wikipedia.org/wiki/Rationalism\">uses</a>&nbsp;the term. As Less Wrong uses the term, a 'rationalist' is someone devoted to the craft of refining their rationality by counteracting known cognitive biases and trying to make their beliefs and decisions track with technically correct beliefs and decisions (defined with reference to, for example, Bayes' theorem and decision theory).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>2</sup>&nbsp;In the preface of Plessner et al. (2009), the authors provide a handy list of search terms for those who wish to research the science of intuition on their own: \"unconscious perceptions, 'blindsight,' pattern recognition, instinct, automatic processing, experiential knowing, tacit knowledge, religious experiences, emotional intelligence, nonverbal communication, clinical diagnoses, 'thin slices of behavior,' spontaneous trait inferences, the 'mere exposure' effect, the primacy of affect, 'thinking too much,' priming, feelings as information, implicit attitudes, expertise, creativity, and the 'sixth sense.'\" They recommend the following sources as \"excellent overviews\" for studying these terms and ideas:&nbsp;Bastick (1982); Davis-Floyd &amp; Arvidson (1992); Hogarth (2001); Myers (2002); Wilson (2002).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>3</sup>&nbsp;Talbot (2009).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>4</sup>&nbsp;Hogarth (2001, 2007).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>5</sup>&nbsp;Cummins (1998); Talbot (2009).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>6</sup>&nbsp;Talbot (2009) provides a nice little summary of how intuitions are used in philosophy (I've changed his citations to the original articles in some cases): \"Intuitions about understanding Chinese are used by John Searle to argue against what he calls \u201cstrong AI\u201d (Searle, 1980). In the philosophy of action, intuitions about playing video games are used by Michael Bratman to argue that we can try to do something without intending to do it (Bratman, 1987). Intuitions are used as counter-evidence against compatibilism (Bok, 1998). One of the most famous use of intuitions as counter evidence comes from epistemology: Gettier cases (Gettier, 1963). In metaphysics, intuitions are appealed to to argue for theories of causation (e.g., Lewis, 1973), and against them (by pointing out that they have counter-intuitive consequences, such as transitivity) (Hall, 2000). In ethics, Judith Jarvis Thomson uses intuitions about violinists and carpets to argue for her claim that abortion can be morally acceptable despite having a right to life (Thomson, 1971). Bernard Williams uses intuitions about killing rebels as counter-evidence against utilitarianism (Williams &amp; Smart, 1973). In the philosophy of language, Tyler Burge uses intuitions about \u201carthritis\u201d to argue for meaning externalism (Burge, 1979), and Saul Kripke uses intuitions about G\u00f6del to argue against a descriptivist view of names (Kripke, 1972). This list goes on and on.\"</span></p>\n<p><span style=\"font-size: 11px;\"><sup>7</sup>&nbsp;Suppes (1984); Cummins (1998).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>8</sup>&nbsp;Wisniewski (1998);&nbsp;Hastie &amp; Dawes (2009); Gilovich (1991); Kahneman, Slovic, &amp; Tversky (1982); Nisbett &amp; Ross (1980); Stanovich (2009).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>9</sup>&nbsp;Stich (1988);&nbsp;Weinberg, Nichols, &amp; Stich (2001);&nbsp;Swain, Alexander, &amp; Weinberg (2008).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>10</sup>&nbsp;Bishop &amp; Trout (2004); Miller (2000). Talbot (2009) explains: \"Consider the state of philosophy, they say. There is little agreement on most key issues, we have produced few theories that have been very successful or survived criticism, and philosophy has accomplished little of practical significance in the last few hundred years. There is nothing about the subject matter of philosophy that makes these results inevitable; most of us believe that there are answers out there to be found, and at least some philosophical disciplines can produce useful results. This gives us reason to think that we are studying the right stuff but in the wrong way. Some aspects of our methodology \u2013 logic and rigorous thought \u2013 are beyond criticism, and thus, they say, the blame for philosophy\u2019s lack of success falls on our use of intuitions.\"</span></p>\n<p><span style=\"font-size: 11px;\"><sup>11</sup>&nbsp;Cummins (1998); Talbot (forthcoming).</span></p>\n<p><span style=\"font-size: 11px;\"><span style=\"font-size: small;\"> </span></span></p>\n<p><small><sup>12</sup>&nbsp;Cummins (1998);&nbsp;Wisniewski (1998).</small></p>\n<p><small><sup>13</sup>&nbsp;Sosa (1998); Bealer (1998); BonJour (1998).</small></p>\n<p><small><sup>14</sup>&nbsp;Sosa (1998); Pust (2000).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>15</sup>&nbsp;Bealer (1996) refers to intuitions as&nbsp;<em style=\"font-style: italic;\">a priori</em>&nbsp;seemings of the sort by which&nbsp;<a href=\"http://en.wikipedia.org/wiki/De_Morgan%27s_Laws\">De Morgan's laws</a>&nbsp;come to seem true to someone - intellectual seemings, not perceptions or imaginative seemings. Sosa (1998) defines 'intuition' as \"noninferential belief due neither to perception nor introspection,\" but sees intuition as focused on abstract propositions: \"At t, S has an intuition that p iff (a) if at t S were merely to understand fully enough the proposition that p (absent relevant perception, introspection, and reasoning), then S would believe that p; (b) at t, S does understand the proposition that p; (c) the proposition that p is an abstract proposition; and (d) at t, S thinks occurrently of the proposition that p (in propria persona, not just by description).\" Williamson (2004) describes intuitions as \"applications of our ordinary capacities for judgment\" and says \"when contemporary analytic philosophers run out of arguments, they appeal to intuition.\" Gopnik &amp; Schwitzgebel (1998) say: \"We will call any judgment an intuitive judgment, or more briefly an intuition, just in case that judgment is not made on the basis of some kind of explicit reasoning process that a person can consciously observe. Intuitions are judgments that grow, rather, out of an underground process... that cannot be directly observed.\" Goldman &amp; Pust (1998) briefly refer to intuitions as \"spontaneous moral judgments.\" Talbot (2009) calls an intuition \"a relatively unreflective reaction that a proposition is true or false.\" Or, more precisely, he says \"an intuition is the seeming to be true (although not necessarily acceptance of or belief in) of some proposition that is not a perceptual seeming, or due to conscious recollection, or due entirely to transparent mental processes.\" Hogarth (2001) says intuitions \"are reached with little apparent effort and typically without conscious awareness. They involve little or no conscious deliberation.\" According to the 'associative learning' view of intuition, intuition draws on the whole stream of past experiences:&nbsp;Betsch et al. (2004);&nbsp;Betsch &amp; Haberstroh (2005). Betsch (2007) offers a definition of intuition from this perspective: \"Intuition is a process of thinking. The input to this process is mostly provided by knowledge stored in long-term memory that has been primarily acquired via associative learning. The input is processed automatically and without conscious awareness. The output of the process is a feeling that can serve as abasis for judgments and decisions.\" Note that the view of intuition from the heuristics and biases perspective (Kahneman &amp; Frederick 2002, 2005) and from the associative learning view are generally not contradictory but rather complementary. Finally, also see surveys of opinion on the nature of intuition, for example Abernathy &amp; Hamm (1995).</span></p>\n<p><span style=\"font-size: 11px;\"><sup>16</sup>&nbsp;In his&nbsp;<a href=\"/lw/n9/the_intuitions_behind_utilitarianism/\">post</a>, Eliezer responds to his critic's broad definition of 'intuition' like this: \"Now 'intuition' is not how I would describe the computations that underlie human morality and distinguish us, as moralists, from an ideal philosopher of perfect emptiness and/or a rock. But I am okay with using the word \"intuition\" as a term of art, bearing in mind that \"intuition\" in this sense is not to be contrasted to reason, but is, rather, the cognitive building block out of which both long verbal arguments and fast perceptual arguments are constructed.\"</span></p>\n<p><small><sup>17</sup> The field of <a href=\"http://en.wikipedia.org/wiki/Evolutionary_psychology\">evolutionary psychology</a> is rich with candidates for evolutionarily adaptive psychological predispositions, some more thoroughly supported by the evidence than others. For an overview, see Buss (2011); Dunbar &amp; Barrett (2007).</small></p>\n<p><small><sup>18</sup>&nbsp;Hogarth (2007); Sloman (1996); Sloman (2002); Evans &amp; Over (1996); Stanovich (2004); Mercier &amp; Sperber (2009); Betsch (2007); Epstein (2007).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>19</sup> Kahneman &amp; Frederick (2002, 2005).</span></p>\n<p><small><sup>20</sup> Kardes (2002), p. 402.</small></p>\n<p><small><sup>21</sup>&nbsp;Halberstadt and Levine (1999). For an overview of similar results, see Plessner &amp; Czenna (2007). For older studies, see Ambady &amp; Rosenthal (1992).</small></p>\n<p><small><sup>22</sup>&nbsp;Clare &amp; Lewandowsky (2004); Fallshore &amp; Schooler (1995); Halbertsadt (2005); Schooler &amp; Engstler-Schooler (1990).</small></p>\n<p><small><sup>23</sup>&nbsp;Fiore &amp; Schooler (2002).</small></p>\n<p><small><sup>24</sup>&nbsp;Perfect et al. (2002).</small></p>\n<p><small><sup>25</sup> Dougherty &amp; Hunter (2003).</small></p>\n<p><small><sup>26</sup> Windschitl &amp; Krizan (2005).</small></p>\n<p><small><sup>27</sup> Gilbert &amp; Rappoport (1975).</small></p>\n<p><small><sup>28</sup> Klimesch (1980); Silverberg &amp; Buchanan (2005).</small></p>\n<p><small><sup>29</sup> Kruglanski &amp; Freund (1983).</small></p>\n<p><small><sup>30</sup> Schroyens et al. (2003).</small></p>\n<p><small><sup>31</sup>&nbsp;Dijksterhuis &amp; van Olden (2005); Dijksterhuis et al. (2006).</small></p>\n<p><small><sup>32</sup> Gigerenzer (2007), ch. 1.</small></p>\n<p><small><sup>33</sup> Gigerenzer (2007); Gladwell (2005).</small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Abernathy &amp; Hamm (1995).&nbsp;<em><a href=\"http://www.amazon.com/Surgical-Intuition-What-How-Get/dp/1560530596/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Surgical intuition: What it is and how to get it</a></em>. Hanley &amp; Belfus.</small></p>\n<p><small>Ambady &amp; Rosenthal (1992). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Ambady-Rosenthal-Thin-Slices-of-Expressive-Behavior-as-Predictors-of-Interpersonal-Consequences-A-Meta-Analysis.pdf\">Thin Slices of Expressive Behavior as Predictors of Interpersonal Consequences: A Meta-Analysis</a>. <em>Psychological Bulletin, 111</em>: 256-274.</small></p>\n<p><small>Bastick (1982). <em><a href=\"http://www.amazon.com/Intuition-How-We-Think-Act/dp/0471279927/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition: How we think and act</a></em>. Wiley.</small></p>\n<p><small>Bealer (1996).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Bealer-A-priori-knowledge-and-the-scope-of-philosophy.pdf\">A priori knowledge and the scope of philosophy</a>.&nbsp;<em style=\"font-style: italic;\">Philosophical Studies, 81(2/3)</em>: 121-142.</small></p>\n<p><small>Bealer (1998). Intuition and the autonomy of philosophy.&nbsp;In De Paul &amp; Ramsey (eds.),&nbsp;<em style=\"font-style: italic; \">Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Betsch (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Betsch-The-nature-of-intuition-and-its-neglect-in-research-on-judgment-and-decision-making.pdf\">The Nature of Intuition and Its Neglect in Research on Judgment and Decision Making</a>. In&nbsp;Plessner, Betsch, &amp; Betsch (eds.), <em>Intuition in Judgment and Decision Making&nbsp;</em>(pp. 3-22). Psychology Press.</small></p>\n<p><small>Betsch &amp; Haberstroh, eds. (2005). <em><a href=\"http://www.amazon.com/Routines-Decision-Making-Tilmann-Betsch/dp/0805846131/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The routines of decision making</a></em>. Lawrence Erlbaum Associates.</small></p>\n<p><small>Betsch, Plessner, &amp; Schallies&nbsp;(2004).&nbsp;The value-account model of attitude formation. In Maio &amp; Haddock (eds.), <em>Contemporary perspectives on the psychology of attitudes</em> (pp. 252\u2013273). Psychology Press.</small></p>\n<p><small>Bishop &amp; Trout (2004).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/Epistemology-Psychology-Judgment-Michael-Bishop/dp/0195162307/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Epistemology and the Psychology of Human Judgment</a></em>. Oxford University Press.</small></p>\n<p><small>Bok (1998). <em><a href=\"http://www.amazon.com/Freedom-Responsibility-Hilary-Bok/dp/069101566X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Freedom and Responsibility</a></em>. Princeton University Press.</small></p>\n<p><small>BonJour (1998). <em><a href=\"http://www.amazon.com/Defense-Pure-Reason-Rationalist-Justification/dp/0521592364/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">In Defense of Pure Reason</a></em>. Cambridge University Press.</small></p>\n<p><small>Bratman (1987). <em><a href=\"http://www.amazon.com/Intention-Practical-Reason-Michael-Bratman/dp/1575861925/\">Intentions, Plans, and Practical Reason</a></em>. Harvard University Press.</small></p>\n<p><small>Burge (1979). Individualism and the mental. <em>Midwest Studies in Philosophy, 4</em>: 73-121.</small></p>\n<p><small>Buss (2011). <em><a href=\"http://www.amazon.com/Evolutionary-Psychology-New-Science-Mind/dp/020501562X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Evolutionary psychology: The new science of mind (4th ed.)</a></em>. Prentice Hall.</small></p>\n<p><small>Clare &amp; Lewandowsky (2004).&nbsp;Verbalizing facial memory: Criterion effects in verbal overshadowing. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition, 30</em>: 739\u2013755.</small></p>\n<p><small>Cummins (1998). Reflection on reflective equilibrium.&nbsp;In De Paul &amp; Ramsey (eds.),&nbsp;<em style=\"font-style: italic; \">Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Davis-Floyd &amp; Arvidson, eds. (1992). <em><a href=\"http://www.amazon.com/Intuition-Inside-Story-Interdisciplinary-Perspectives/dp/0415915945/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition: the inside story</a></em>. Routledge.</small></p>\n<p><small>Dijksterhuis &amp; van Olden (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Dijksterhuis-On-the-benefits-of-thinking-unconsciously.pdf\">On the benefits of thinking unconsciously: Unconscious&nbsp;thought can increase post-choice satisfaction</a>.&nbsp;<em>Journal of Experimental Social Psychology, 42</em>: 627\u2013631.</small></p>\n<p><small>Dijksterhuis, Bos, Nordgren, &amp; van Baaren (2006). On making the right choice: The dliberation-without-attention effect. Science, 17: 1005-1007.</small></p>\n<p><small>Dougherty &amp; Hunter (2003).&nbsp;Probability judgment and subadditivity: The role of working memory capacity and constraining retrieval. <em>Memory and Cognition, 31</em>: 968\u2013982.</small></p>\n<p><small>Dunbar &amp; Barrett, eds. (2007). <em><a href=\"http://www.amazon.com/Oxford-Handbook-Evolutionary-Psychology-Library/dp/0198568304/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford handbook of evolutionary psychology</a></em>. Oxford University Press.</small></p>\n<p><small>Epstein (2007).&nbsp;Intuition From the Perspective of Cognitive-Experiential Self-Theory.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 23-37). Psychology Press.</small></p>\n<p><small>Evans &amp; Over (1996). <em><a href=\"http://www.amazon.com/Rationality-Reasoning-Essays-Cognitive-Psychology/dp/0863774385/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rationality and reasoning</a></em>. Psychology Press.</small></p>\n<p><small>Fallshore &amp; Schooler (1995).&nbsp;Verbal vulnerability of perceptual expertise. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition, 21</em>: 1608\u20131623.</small></p>\n<p><small>Fiore &amp; Schooler (2002).&nbsp;How did you get here from there? Verbal overshadowing of spatial mental models. <em>Applied Cognitive Psychology, 16</em>: 897\u2013909.</small></p>\n<p><small>Gettier (1963). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/01/Gettier-Is-Justified-True-Belief-Knowledge.pdf\">Is justified true belief knowledge?</a> <em>Analysis, 23</em>: 121-123.</small></p>\n<p><small>Gigerenzer (2007). <em><a href=\"http://www.amazon.com/Gut-Feelings-Intelligence-Gerd-Gigerenzer/dp/0143113763/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Gut Feelings: The Intelligence of the Unconscious</a></em>. Penguin.</small></p>\n<p><small>Gilbert &amp; Rappoport (1975).&nbsp;Categories of thought and variations in meaning: A demonstration experiment. <em>Journal of Phenomenological Psychology, 5</em>: 419\u2013424.</small></p>\n<p><small>Gilovich (1991). <em><a href=\"http://www.amazon.com/How-Know-What-Isnt-Fallibility/dp/0029117062/\">How We Know What Isn't So: The Fallibility of Human Reason in Everyday Life</a></em>. Free Press.</small></p>\n<p><small>Gladwell (2005). <em><a href=\"http://www.amazon.com/Blink-Power-Thinking-Without/dp/0316010669/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Blink: The Power of Thinking Without Thinking</a>. </em>Black Bay Books.</small></p>\n<p><small>Goldman &amp; Pust (1998). Philosophical theory and intuitional evidence. In De Paul &amp; Ramsey (eds.), <em>Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Gopnik &amp; Schwitzgebel (1998). Whose concepts are they anyway? The role of philosophical intuition in empirical psychology. In De Paul &amp; Ramsey (eds.), <em>Rethinking Intuition</em>. Rowan and Littlefield.</small></p>\n<p><small>Hall (2000). Causation and the price of transitivity. <em>Journal of Philosophy, 97(4)</em>: 198-222.</small></p>\n<p><small>Halbertsadt (2005).&nbsp;Featural shift in explanation-biased memory for emotional faces. <em>Journal of Personality and Social Psychology, 88</em>: 38\u201349.</small></p>\n<p><small>Halberstadt and Levine (1999).&nbsp;Effects of reasons analysis on the accuracy of predicting basketball games. <em>Journal of Applied Social Psychology, 29</em>: 517\u2013530.</small></p>\n<p><small>Hastie &amp; Dawes (2009).&nbsp;<em><a href=\"http://www.amazon.com/Rational-Choice-Uncertain-World-Psychology/dp/1412959039/\">Rational Choice in an Uncertain World, 2nd edition</a>.</em>&nbsp;Sage.</small></p>\n<p><small>Hogarth (2001). <em><a href=\"http://www.amazon.com/Educating-Intuition-Robin-M-Hogarth/dp/0226348628/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Educating intuition</a></em>. University of Chicago Press.</small></p>\n<p><small>Hogarth (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Hogarth-On-the-learning-of-intuition.pdf\">On the learning of intuition</a>.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 91-105). Psychology Press.</small></p>\n<p><small>Kahneman &amp; Frederick (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-Frederick-Representativeness-revisited.pdf\">Representativeness revisited: Attribute substitution in intuitive judgment</a>. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and biases: The psychology of intuitive judgment</em> (pp. 49-81). Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Frederick (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-A-model-of-heuristic-judgment.pdf\">A model of heuristic judgment</a>. In Holyoak &amp; Morrison (eds.), <em>The Cambridge Handbook of Thinking and Reasoning</em> (pp. 267-294). Cambridge University Press.</small></p>\n<p><small>Kahneman, Slovic, &amp; Tversky (1982).<em style=\"font-style: italic;\">&nbsp;<a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/\">Judgment Under Uncertainty: Heuristics and Biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Kardes (2002).&nbsp;<em><a href=\"http://www.amazon.com/Consumer-Behavior-Managerial-Decision-Making/dp/0130916021/\">Consumer behavior and managerial decision making (2nd ed.)</a></em>. Prentice Hall.</small></p>\n<p><small>Klimesch (1980).&nbsp;The effect of verbalization on memory performance for complex pictures. <em>Zeitschrift fu\u0308r Experimentelle und Angewandte Psychologie, 27</em>: 245\u2013256.</small></p>\n<p><small>Kripke (1972). <em><a href=\"http://www.amazon.com/Naming-necessity-Saul-Kripke/dp/0631128018/\">Naming and Necessity</a></em>. Harvard University Press.</small></p>\n<p><small>Kruglanski &amp; Freund (1983).&nbsp;The freezing and unfreezing of lay-inferences: Effects on impressional primacy, ethnic stereotyping, and numerical anchoring. <em>Journal of Experimental Social Psychology, 19</em>: 448\u2013468.</small></p>\n<p><small>Lewis (1973). Causation. <em>The Journal of Philosophy, 70(17)</em>: 556-567.</small></p>\n<p><small>Mercier &amp; Sperber (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Mercier-Sperber-Intuitive-and-reflective-inferences.pdf\">Intuitive and reflective inferences</a>. In Evans &amp; Frankish (eds.), <em>In two minds: Dual processes and beyond</em>. Oxford University Press</small></p>\n<p><small>Miller (2000). Without Intuitions. <em>Metaphilosophy, 31(3)</em>: 231-250.</small></p>\n<p><small>Myers (2002). <em><a href=\"http://www.amazon.com/Intuition-Powers-Perils-Yale-Nota/dp/0300103034/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition: Its powers and perils</a></em>. Yale University Press.</small></p>\n<p><small>Nisbett and Ross (1980).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/Human-Inference-Strategies-Shortcomings-Judgement/dp/0134450736/\">Human Inference: Strategies and Shortcomings of Social Judgment</a></em>. Prentice-Hall.</small></p>\n<p><small>Perfect, Hunt, &amp; Harris (2002).&nbsp;Verbal overshadowing in voice recognition. <em>Applied Cognitive Psychology, 16</em>: 973\u2013980.</small></p>\n<p><small>Plessner, Betsch, &amp; Betsch, eds. (2007). <em><a href=\"http://www.amazon.com/Intuition-Judgment-Decision-Henning-Plessner/dp/0805857419/\">Intuition in judgment and decision making</a></em>. Psychology Press.</small></p>\n<p><small>Plessner &amp; Czenna (2007). The benefits of intuition.&nbsp;In&nbsp;Plessner, Betsch, &amp; Betsch (eds.),&nbsp;<em style=\"font-style: italic;\">Intuition in Judgment and Decision Making&nbsp;</em>(pp. 251-265). Psychology Press.</small></p>\n<p><small>Pust (2000). <a href=\"http://www.amazon.com/Intuitions-as-Evidence-Studies-Philosophy/dp/0815337639/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuitions as Evidence</a>. Garland.</small></p>\n<p><small>Schooler &amp; Engstler-Schooler (1990).&nbsp;Verbal overshadowing of visual memories: Some things are better left unsaid. <em>Cognitive Psychology, 22</em>: 36\u201371</small></p>\n<p><small>Schroyens, Schaeken, &amp; Handley (2003). In search of counter-examples: Deductive rationality in human reasoning. <em>Quarterly Journal of Experimental Psychology: A. Human Experimental Psychology, 56</em>: 1129\u20131145.</small></p>\n<p><small>Searle (1980). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Searle-Minds-Brains-and-Programs.pdf\">Minds, brains, and programs</a>. <em>Behavioral and Brain Sciences, 3</em>: 417-424.</small></p>\n<p><small>Silverberg &amp; Buchanan (2005).&nbsp;Verbal mediation and memory for novel figural designs: A dual interference study. <em>Brain and Cognition, 57</em>: 198\u2013209</small></p>\n<p><small>Sloman (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sloman-The-empirical-case-for-two-systems-of-reasoning.pdf\">The empirical case for two systems of reasoning</a>.&nbsp;<em>Psychological Bulletin, 119</em>: 3-22.</small></p>\n<p><small>Sloman (2002). Two systems of reasoning. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and Biases: The Psychology of Intuitive Judgment</em>. Cambridge University Press.</small></p>\n<p><small>Sosa (1998). Minimal Intuition. In De Paul &amp; Ramsey (eds.), <em>Rethinking Intuition</em>. Rowman and Littlefield.</small></p>\n<p><small>Stanovich (2004). <em><a href=\"http://www.amazon.com/Robots-Rebellion-Finding-Meaning-Darwin/dp/0226771253/\">The robot\u2019s rebellion</a></em>. Chicago University Press.</small></p>\n<p><small>Stanovich (2009). <em><a href=\"http://www.amazon.com/How-Think-Straight-About-Psychology/dp/0205685900/\">How to Think Straight About Psychology, 9th edition</a></em>. Allyn &amp; Bacon.</small></p>\n<p><small>Stich (1988).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Stitch-Reflective-Equilibrium-Analytic-Epistemology-and-the-Problem-of-Cognitive-Diversity.pdf\">Reflective equilibrium, analytic epistemology and the problem of cognitive diversity</a>. <em>Synthese, 74(3)</em>: 391-413.</small></p>\n<p><small>Suppes (1984). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Suppes-Conflicting-intuitions-about-causality.pdf\">Conflicting intuitions about causality</a>. <em>Midwest Studies in Philosophy, 9(1)</em>: 151-168.</small></p>\n<p><small>Swain, Alexander, &amp; Weinberg (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Swain-The-instability-of-philosophical-intuitions.pdf\">The instability of philosophical intuitions: Running hot and cold on truetemp</a>. <em>Philosophy and Phenomenological Research, 76:</em> 138\u2013155.</small></p>\n<p><small>Talbot (2009). <em><a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Talbot-How-to-use-intuitions-in-philosophy.pdf\">How to Use Intuitions in Philosophy</a></em>. Dissertation. University of Southern California.</small></p>\n<p><small>Talbot (forthcoming). The dilemma of calibrating intuitions.</small></p>\n<p><small>Thomson (1971). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Thomson-A-Defense-of-Abortion.pdf\">A defense of abortion</a>. <em>Philosophy and Public Affairs, 1(1)</em>: 47-66.</small></p>\n<p><small>Weinberg, Nichols, &amp; Stich (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Weinberg-Normativity-and-epistemic-intuitions.pdf\">Normativity and epistemic intuitions</a>. Philosophical Topics, 29(1/2): 429-460.</small></p>\n<p><small>Williams &amp; Smart (1973). <em><a href=\"http://www.amazon.com/Utilitarianism-Against-J-C-Smart/dp/052109822X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Utilitarianism: For and Against</a></em>. Cambridge University Press.</small></p>\n<p><small>Williamson (2004).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Williamson-Philosophical-\u2018Intuitions\u2019-and-Scepticism-about-Judgement.pdf\">Philosophical \u2018intuitions\u2019 and scepticism about judgement</a>. <em>Dialectica, 58(1)</em>: 109-153.</small></p>\n<p><small>Wilson (2002). <em><a href=\"http://www.amazon.com/Strangers-Ourselves-Discovering-Adaptive-Unconscious/dp/0674013824/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Strangers to ourselves: Discovering the adaptive unconscious</a></em>. Harvard University Press.</small></p>\n<p><small>Windschitl &amp; Krizan (2005).&nbsp;Contingent approaches to making likelihood judgments about polychotomous cases: The influence of task factors. <em>Journal of Behavioral Decision Making, 18</em>: 281\u2013303.</small></p>\n<p><small>Wisniewski (1998). The psychology of intuition.&nbsp;In De Paul &amp; Ramsey (eds.),&nbsp;<em style=\"font-style: italic; \">Rethinking Intuition</em>. Rowan and Littlefield.</small></p>", "sections": [{"title": "Problems with intuition", "anchor": "Problems_with_intuition", "level": 1}, {"title": "What is intuition?", "anchor": "What_is_intuition_", "level": 1}, {"title": "When intuitions are useful", "anchor": "When_intuitions_are_useful", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "15 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Mc6QcrsbH5NRXbCRX", "qmqLxvtsPzZ2s6mpY", "du395YvCnQXBPSJax", "WTS4ZbEwvKrcrnaaN", "6Cc3TWZjAnrNWokWY", "r5MSQ83gtbjWRBDWJ", "GKfPL6LQFgB49FEnv", "wHjpCxeDeuFadG3jF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T19:42:02.627Z", "modifiedAt": null, "url": null, "title": "Moderation Wiki Article", "slug": "moderation-wiki-article", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "saliency", "createdAt": "2009-10-25T03:59:58.587Z", "isAdmin": false, "displayName": "saliency"}, "userId": "RNx6ydjKM2J3Heae3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HqNgPi82cxtgN7imN/moderation-wiki-article", "pageUrlRelative": "/posts/HqNgPi82cxtgN7imN/moderation-wiki-article", "linkUrl": "https://www.lesswrong.com/posts/HqNgPi82cxtgN7imN/moderation-wiki-article", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Moderation%20Wiki%20Article&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModeration%20Wiki%20Article%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHqNgPi82cxtgN7imN%2Fmoderation-wiki-article%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Moderation%20Wiki%20Article%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHqNgPi82cxtgN7imN%2Fmoderation-wiki-article", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHqNgPi82cxtgN7imN%2Fmoderation-wiki-article", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p>I have transformed&nbsp;</p>\n<p><a href=\"http://wiki.lesswrong.com/wiki/Site_features\">http://wiki.lesswrong.com/wiki/Site_features</a></p>\n<p>into</p>\n<p><a href=\"http://wiki.lesswrong.com/wiki/Moderation\">http://wiki.lesswrong.com/wiki/Moderation</a></p>\n<p>&nbsp;</p>\n<p>I think \"site features\" is to general of a topic for the content contained in the article.</p>\n<p>In the new wiki article I focus on the topic of all the ways content can be moderated and give the information I have gathered about the&nbsp;process. &nbsp;I took the liberty to simply state that&nbsp;<span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px;\">Eliezer_Yudkowsky is the one who promotes articles to the PROMOTED section. &nbsp;Besides that most is taken from other areas of the site.</span></p>\n<p>&nbsp;</p>\n<p>I'm sure there are factual and formating errors please correct/contribute as needed.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HqNgPi82cxtgN7imN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.125945323477068e-07, "legacy": true, "legacyId": "7285", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-09T22:05:42.156Z", "modifiedAt": null, "url": null, "title": "Scholarship: How to Do It Efficiently", "slug": "scholarship-how-to-do-it-efficiently", "viewCount": null, "lastCommentedAt": "2022-03-02T13:10:02.084Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently", "pageUrlRelative": "/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently", "linkUrl": "https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently", "postedAtFormatted": "Monday, May 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Scholarship%3A%20How%20to%20Do%20It%20Efficiently&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AScholarship%3A%20How%20to%20Do%20It%20Efficiently%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37sHjeisS9uJufi4u%2Fscholarship-how-to-do-it-efficiently%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Scholarship%3A%20How%20to%20Do%20It%20Efficiently%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37sHjeisS9uJufi4u%2Fscholarship-how-to-do-it-efficiently", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37sHjeisS9uJufi4u%2Fscholarship-how-to-do-it-efficiently", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1405, "htmlBody": "<p>Scholarship is <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">an important virtue of rationality</a>, but it can be <a href=\"/lw/4sn/costs_and_benefits_of_scholarship/\">costly</a>. Its major costs are <em>time</em>&nbsp;and <em>effort</em>. Thus, if you can reduce the time and effort required for scholarship - if you can learn to do scholarship <em>more efficiently</em>&nbsp;- then scholarship will be worth your effort more often than it previously was.</p>\n<p>As an autodidact who now consumes <a href=\"/lw/3w3/how_to_beat_procrastination/\">whole</a> <a href=\"/lw/4z7/the_neuroscience_of_desire/\">fields</a> <a href=\"/lw/3gv/statistical_prediction_rules_outperform_expert/\">of</a> <a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">knowledge</a> <a href=\"/lw/59v/intuition_and_unconscious_learning/\">in</a> <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">mere</a> <a href=\"/lw/4su/how_to_be_happy/\">weeks</a>, I've developed efficient habits that allow me to research topics quickly. I'll share my research habits with you now.</p>\n<p>&nbsp;</p>\n<h4>Review articles and textbooks are king</h4>\n<p>My first task is to find scholarly review (or 'survey') articles on my chosen topic from the past five years (the more recent, the better). A good review article provides:</p>\n<ol>\n<li>An overview of the subject matter of the field and the <em>terms</em>&nbsp;being used (for <a href=\"http://scholar.google.com/\">scholarly googling</a> later).</li>\n<li>An overview of the open and solved problems in the field, and which researchers are working on them.</li>\n<li>Pointers to the key studies that give researchers their current understanding of the topic.</li>\n</ol>\n<p>If you can find a recent scholarly edited volume of review articles on the topic, then you've <em>hit the jackpot</em>. (Edited volumes are better than single-author volumes, because when starting out you want to avoid reading only one particular researcher's perspective.) Examples from my own research of <em>just this year</em> include:</p>\n<ul>\n<li>Affective neuroscience: <em><a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Pleasures of the Brain</a></em>&nbsp;(2009)</li>\n<li>Neuroeconomics: <em><a href=\"http://www.amazon.com/Neuroeconomics-Decision-Paul-W-Glimcher/dp/0123741769/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Decision Making and the Brain</a></em>&nbsp;(2008)</li>\n<li>Dual process theories of psychology: <em><a href=\"http://www.amazon.com/Two-Minds-Dual-Processes-Beyond/dp/0199230161/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">In Two Minds</a></em>&nbsp;(2009)</li>\n<li>Intuition and unconscious learning: <em><a href=\"http://www.amazon.com/Intuition-Judgment-Decision-Henning-Plessner/dp/0805857419/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition in Judgment and Decision Making</a></em>&nbsp;(2007)</li>\n<li>Goals: <em><a href=\"http://www.amazon.com/Psychology-Goals-Gordon-Moskowitz-PhD/dp/1606230298/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The Psychology of Goals</a></em>&nbsp;(2009)</li>\n<li>Catastrophic risks: <em><a href=\"http://www.amazon.com/Global-Catastrophic-Risks-Nick-Bostrom/dp/0198570503/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Global Catastrophic Risks</a></em>&nbsp;(2008)</li>\n</ul>\n<p>If the field is large enough, there may exist an edited 'Handbook' on the subject, which is basically just a <em>very large</em>&nbsp;scholarly edited volume of review articles. Examples: <em><a href=\"http://www.amazon.com/Oxford-Handbook-Evolutionary-Psychology-Library/dp/0198568304/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Evolutionary Psychology</a></em>&nbsp;(2007), <em><a href=\"http://www.amazon.com/Oxford-Handbook-Positive-Psychology-Library/dp/0195187245/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Positive Psychology</a></em>&nbsp;(2009), <em><a href=\"http://www.amazon.com/Oxford-Handbook-Philosophy-Neuroscience/dp/0195304780/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Philosophy and Neuroscience</a></em>&nbsp;(2009), <em><a href=\"http://www.amazon.com/Handbook-Developmental-Cognitive-Neuroscience-Charles/dp/0262141043/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Handbook of Developmental Cognitive Neuroscience</a></em>&nbsp;(2008), <em><a href=\"http://www.amazon.com/Oxford-Handbook-Neuroethics-Library-Psychology/dp/0199570701/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Neuroethics</a></em>&nbsp;(2011), <em><a href=\"http://www.amazon.com/gp/product/0805861599/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Handbook of Relationship Intitiation</a></em>&nbsp;(2008),&nbsp;and <em><a href=\"http://www.amazon.com/Handbook-Implicit-Social-Cognition-Applications/dp/1606236733/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Handbook of Implicit Social Cognition</a></em>&nbsp;(2010). For the humanities, see the <a href=\"http://www.amazon.com/s/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Blackwell Companions</a>&nbsp;and <a href=\"http://cco.cambridge.org/collection?id=complete\">Cambridge Companions</a>.</p>\n<p>If your questions are basic enough, a recent entry-level textbook on the subject may be just as good. Textbooks are basically book-length review articles written for undergrads. Textbooks I purchased this year include:</p>\n<ul>\n<li><em><a href=\"http://www.amazon.com/Evolutionary-Psychology-New-Science-Mind/dp/020501562X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Evolutionary Psychology: The New Science of Mind, 4th edition</a></em>&nbsp;(2011)</li>\n<li><em><a href=\"http://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Artificial Intelligence: A Modern Approach, 3rd edition</a></em>&nbsp;(2009)</li>\n<li><em><a href=\"http://www.amazon.com/Psychology-Applied-Modern-Life-Adjustment/dp/1111186634/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Psychology Applied to Modern Life, 10th edition</a></em>&nbsp;(2011)</li>\n<li><em><a href=\"http://www.amazon.com/Psychology-David-G-Myers/dp/1429215976/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Psychology, 9th edition</a> </em>(2009)</li>\n</ul>\n<p>Use <a href=\"http://books.google.com/\">Google Books</a> and Amazon's 'Look Inside' feature to see if the books appear to be of high quality, and likely to answer the questions you have. Also check the textbook recommendations <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">here</a>. You can save money by checking <a href=\"http://gen.lib.rus.ec/\">Library Genesis</a> and <a href=\"http://library.nu/\">library.nu</a> for a PDF copy first, or by buying <a href=\"http://www.bookfinder.com/\">used books</a>, or by buying ebook versions from <a href=\"http://www.amazon.com/kindle-store-ebooks-newspapers-blogs/b?ie=UTF8&amp;node=133141011\">Amazon</a>, <a href=\"http://www.barnesandnoble.com/ebooks/index.asp\">B&amp;N</a>, or <a href=\"http://books.google.com/ebooks\">Google</a>. <a id=\"more\"></a></p>\n<p>Keep in mind that if you take the <a href=\"http://yudkowsky.net/rational/virtues\">virtue of scholarship</a> seriously, you may need to change how you think about the cost of obtaining knowledge. Purchasing the <em>right</em>&nbsp;book can save you <em>dozens</em>&nbsp;of hours of research. Because a huge part of my life these days is devoted to scholarship, a significant portion of my monthly budget is set aside for purchasing knowledge. So far this year I've averaged over $150/mo spent on textbooks and scholarly edited volumes.</p>\n<p>Recent scholarly review articles can also be found on <a href=\"http://scholar.google.com/\">Google scholar</a>. Search for key terms, and review articles will often be listed near the top of the results because review articles are cited widely. For example, result #9 on Google scholar for <a href=\"http://scholar.google.com/scholar?q=procrastination&amp;hl=en&amp;btnG=Search&amp;as_sdt=2001&amp;as_sdtp=on\">procrastination</a> is \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Steel-The-Nature-of-Procrastination.pdf\">The nature of procrastination</a>\" (2007) by Piers Steel, the first half of which is a review article, while the second half is a meta-analysis. Bingo.</p>\n<p>You can also search Amazon for key terms. I recently searched Amazon for 'attention neuroscience.' Result #2 was <a href=\"http://www.amazon.com/Attention-Action-Cognitive-Neuroscience-Behavioural/dp/1841693545/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">a 2004 scholarly edited volume</a> on the subject. A bit old, but not bad for my first search! I found the PDF on <a href=\"http://library.nu/search?q=attention%20in%20action\">library.nu</a>.</p>\n<p>In order to find good review articles, textbooks, and scholarly edited volumes you may first need to figure out what the terminology is. When I wanted to understand the neuroscience of pleasure and desire, it took me a while to figure out that the neuroscience of emotions is called <em>affective neuroscience</em>. After consuming that field, I had learned a lot about pleasure but not much about desire. I then realized that I didn't care about desire <em>as an emotion</em>&nbsp;but instead as <em>a driver of action under uncertainty</em>. That aspect of desire, it turns out, is studied not under the field of affective neuroscience but instead <em>neuroeconomics</em>.</p>\n<p>Similarly, when I was originally looking for 'scientific self-help', I had trouble finding review articles or textbooks on the subject. It took me months to discover that professionals call this the <em>psychology of adjustment</em>. Who would have guessed that? But once I knew the term, I quickly found <a href=\"http://www.amazon.com/Psychology-Applied-Modern-Life-Adjustment/dp/1111186634/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">two</a> <a href=\"http://www.amazon.com/Human-Adjustment--Psych-CD-ROM-Santrock/dp/0073111910/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">textbooks</a> on the subject, which were good starting points for understanding <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">the field</a>.</p>\n<p>Note that not every scholarly edited volume is a volume of <em>review articles</em>. <em><a href=\"http://www.amazon.com/Waves-Philosophy-Action-Jes%C3%BAs-Aguilar/dp/0230230601/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">New Waves in Philosophy of Action</a></em>&nbsp;is a collection of new research articles, not a collection of review articles. It is a poor entry point into the field. Some edited volumes are&nbsp;<em>okay</em>&nbsp;entry points into the field because they are a mix of review articles and original research, for example <em><a href=\"http://www.amazon.com/Machine-Ethics-Michael-Anderson/dp/0521112354/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Machine Ethics</a></em>&nbsp;(2011). But remember that a 'good' edited volume on a subject does not protect you from the entire <em>field</em>&nbsp;being <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">mostly misguided</a>, like machine ethics or <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">mainstream philosophy</a>.</p>\n<p>Also note that if you can't find an edited volume on your subject, one may be just around the corner. In 2007 there was no decent edited volume on neuroeconomics, but there were <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Camerer-Neuroeconomics-how-neuroscience-can-inform-economics.pdf\">three</a> <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sanfey-Neuroeconomics-cross-currents-in-research-on-decision-making.pdf\">review</a> <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Glimcher-Neuroeconomics-the-consilience-of-brain-and-decision.pdf\">articles</a>. Then in 2008,&nbsp;<em><a href=\"http://www.amazon.com/Neuroeconomics-Decision-Paul-W-Glimcher/dp/0123741769/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Decision Making and the Brain</a>&nbsp;</em>was released.</p>\n<p>&nbsp;</p>\n<h4>Going granular</h4>\n<p>Once textbooks and review articles have given you a good overview of the key concepts and terms, open and closed problems, studies and researchers on your chosen topic, it's time to go granular.</p>\n<p>Textbooks and review articles will point you to the articles most directly relevant for answering the questions you have, and the researchers working on the problems you care about. Visit researchers' home pages and check their 'recent publications' lists. Find the papers on <a href=\"http://scholar.google.com/\">Google Scholar</a> and read the abstracts. Make a list of the ones you need to read more closely. You'll be able to download many of them directly from links found on Google Scholar. For others, you'll need to visit a university library's computer lab to download the papers. The university will have subscribed to many of the databases that carry the papers, and university computers will let you past the paywall (but on-campus wifi will not). To get access to a paper you can't get at a nearby university, you can:</p>\n<ol>\n<li>Contact the author via email and request a copy (or a preprint), explaining that you can't get it elsewhere.</li>\n<li>Ask your friends at other universities to check if their university has access to it.</li>\n<li>Look to see if the article has been published in a book that is available at your library or online.</li>\n</ol>\n<p>I've never purchased an article from an online database because the prices are outrageous: $15-$40 for a 20-page article, usually. If I absolutely can't get access to an article, I make a judgement as to how much weight to give the study's conclusions, inferring this from the researcher's history and the abstract and responses to the article I <em>can</em>&nbsp;read and other factors.</p>\n<p>Skim through promising research articles for the information you want, watching for obvious problems in experimental design or quality of argument. This is where your time investment in scholarship can explode, so be conscious of the tradeoffs involved when reading 100 abstracts vs. reading 100 papers.</p>\n<p>You can also try contacting individual researchers. This works best when the subject line of your email is very descriptive, and is obviously about a detail in their recent work. The content of your email should ask a very specific question or two, quoting directly from their paper(s). Researchers are often excited to hear that somebody is actually reading their work closely, though philosophers get more excited than neuroscientists (for example). Neuroscientists are called for comment by the media somewhat regularly. This doesn't happen to philosophers.</p>\n<p>Finally, if you've done all this work already and you're feeling generous, perhaps you could take a little time to write up the results of your research for the rest of us! Or, <a href=\"http://en.wikipedia.org/wiki/Wikipedia:Contributing_to_Wikipedia\">help make Wikipedia better</a>.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 30, "fkABsGCJZ6y9qConW": 13}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "37sHjeisS9uJufi4u", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 157, "baseScore": 199, "extendedScore": null, "score": 0.000367, "legacy": true, "legacyId": "7286", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 199, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Scholarship is <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">an important virtue of rationality</a>, but it can be <a href=\"/lw/4sn/costs_and_benefits_of_scholarship/\">costly</a>. Its major costs are <em>time</em>&nbsp;and <em>effort</em>. Thus, if you can reduce the time and effort required for scholarship - if you can learn to do scholarship <em>more efficiently</em>&nbsp;- then scholarship will be worth your effort more often than it previously was.</p>\n<p>As an autodidact who now consumes <a href=\"/lw/3w3/how_to_beat_procrastination/\">whole</a> <a href=\"/lw/4z7/the_neuroscience_of_desire/\">fields</a> <a href=\"/lw/3gv/statistical_prediction_rules_outperform_expert/\">of</a> <a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">knowledge</a> <a href=\"/lw/59v/intuition_and_unconscious_learning/\">in</a> <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">mere</a> <a href=\"/lw/4su/how_to_be_happy/\">weeks</a>, I've developed efficient habits that allow me to research topics quickly. I'll share my research habits with you now.</p>\n<p>&nbsp;</p>\n<h4 id=\"Review_articles_and_textbooks_are_king\">Review articles and textbooks are king</h4>\n<p>My first task is to find scholarly review (or 'survey') articles on my chosen topic from the past five years (the more recent, the better). A good review article provides:</p>\n<ol>\n<li>An overview of the subject matter of the field and the <em>terms</em>&nbsp;being used (for <a href=\"http://scholar.google.com/\">scholarly googling</a> later).</li>\n<li>An overview of the open and solved problems in the field, and which researchers are working on them.</li>\n<li>Pointers to the key studies that give researchers their current understanding of the topic.</li>\n</ol>\n<p>If you can find a recent scholarly edited volume of review articles on the topic, then you've <em>hit the jackpot</em>. (Edited volumes are better than single-author volumes, because when starting out you want to avoid reading only one particular researcher's perspective.) Examples from my own research of <em>just this year</em> include:</p>\n<ul>\n<li>Affective neuroscience: <em><a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Pleasures of the Brain</a></em>&nbsp;(2009)</li>\n<li>Neuroeconomics: <em><a href=\"http://www.amazon.com/Neuroeconomics-Decision-Paul-W-Glimcher/dp/0123741769/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Decision Making and the Brain</a></em>&nbsp;(2008)</li>\n<li>Dual process theories of psychology: <em><a href=\"http://www.amazon.com/Two-Minds-Dual-Processes-Beyond/dp/0199230161/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">In Two Minds</a></em>&nbsp;(2009)</li>\n<li>Intuition and unconscious learning: <em><a href=\"http://www.amazon.com/Intuition-Judgment-Decision-Henning-Plessner/dp/0805857419/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Intuition in Judgment and Decision Making</a></em>&nbsp;(2007)</li>\n<li>Goals: <em><a href=\"http://www.amazon.com/Psychology-Goals-Gordon-Moskowitz-PhD/dp/1606230298/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The Psychology of Goals</a></em>&nbsp;(2009)</li>\n<li>Catastrophic risks: <em><a href=\"http://www.amazon.com/Global-Catastrophic-Risks-Nick-Bostrom/dp/0198570503/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Global Catastrophic Risks</a></em>&nbsp;(2008)</li>\n</ul>\n<p>If the field is large enough, there may exist an edited 'Handbook' on the subject, which is basically just a <em>very large</em>&nbsp;scholarly edited volume of review articles. Examples: <em><a href=\"http://www.amazon.com/Oxford-Handbook-Evolutionary-Psychology-Library/dp/0198568304/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Evolutionary Psychology</a></em>&nbsp;(2007), <em><a href=\"http://www.amazon.com/Oxford-Handbook-Positive-Psychology-Library/dp/0195187245/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Positive Psychology</a></em>&nbsp;(2009), <em><a href=\"http://www.amazon.com/Oxford-Handbook-Philosophy-Neuroscience/dp/0195304780/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Philosophy and Neuroscience</a></em>&nbsp;(2009), <em><a href=\"http://www.amazon.com/Handbook-Developmental-Cognitive-Neuroscience-Charles/dp/0262141043/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Handbook of Developmental Cognitive Neuroscience</a></em>&nbsp;(2008), <em><a href=\"http://www.amazon.com/Oxford-Handbook-Neuroethics-Library-Psychology/dp/0199570701/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Oxford Handbook of Neuroethics</a></em>&nbsp;(2011), <em><a href=\"http://www.amazon.com/gp/product/0805861599/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Handbook of Relationship Intitiation</a></em>&nbsp;(2008),&nbsp;and <em><a href=\"http://www.amazon.com/Handbook-Implicit-Social-Cognition-Applications/dp/1606236733/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Handbook of Implicit Social Cognition</a></em>&nbsp;(2010). For the humanities, see the <a href=\"http://www.amazon.com/s/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Blackwell Companions</a>&nbsp;and <a href=\"http://cco.cambridge.org/collection?id=complete\">Cambridge Companions</a>.</p>\n<p>If your questions are basic enough, a recent entry-level textbook on the subject may be just as good. Textbooks are basically book-length review articles written for undergrads. Textbooks I purchased this year include:</p>\n<ul>\n<li><em><a href=\"http://www.amazon.com/Evolutionary-Psychology-New-Science-Mind/dp/020501562X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Evolutionary Psychology: The New Science of Mind, 4th edition</a></em>&nbsp;(2011)</li>\n<li><em><a href=\"http://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Artificial Intelligence: A Modern Approach, 3rd edition</a></em>&nbsp;(2009)</li>\n<li><em><a href=\"http://www.amazon.com/Psychology-Applied-Modern-Life-Adjustment/dp/1111186634/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Psychology Applied to Modern Life, 10th edition</a></em>&nbsp;(2011)</li>\n<li><em><a href=\"http://www.amazon.com/Psychology-David-G-Myers/dp/1429215976/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Psychology, 9th edition</a> </em>(2009)</li>\n</ul>\n<p>Use <a href=\"http://books.google.com/\">Google Books</a> and Amazon's 'Look Inside' feature to see if the books appear to be of high quality, and likely to answer the questions you have. Also check the textbook recommendations <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">here</a>. You can save money by checking <a href=\"http://gen.lib.rus.ec/\">Library Genesis</a> and <a href=\"http://library.nu/\">library.nu</a> for a PDF copy first, or by buying <a href=\"http://www.bookfinder.com/\">used books</a>, or by buying ebook versions from <a href=\"http://www.amazon.com/kindle-store-ebooks-newspapers-blogs/b?ie=UTF8&amp;node=133141011\">Amazon</a>, <a href=\"http://www.barnesandnoble.com/ebooks/index.asp\">B&amp;N</a>, or <a href=\"http://books.google.com/ebooks\">Google</a>. <a id=\"more\"></a></p>\n<p>Keep in mind that if you take the <a href=\"http://yudkowsky.net/rational/virtues\">virtue of scholarship</a> seriously, you may need to change how you think about the cost of obtaining knowledge. Purchasing the <em>right</em>&nbsp;book can save you <em>dozens</em>&nbsp;of hours of research. Because a huge part of my life these days is devoted to scholarship, a significant portion of my monthly budget is set aside for purchasing knowledge. So far this year I've averaged over $150/mo spent on textbooks and scholarly edited volumes.</p>\n<p>Recent scholarly review articles can also be found on <a href=\"http://scholar.google.com/\">Google scholar</a>. Search for key terms, and review articles will often be listed near the top of the results because review articles are cited widely. For example, result #9 on Google scholar for <a href=\"http://scholar.google.com/scholar?q=procrastination&amp;hl=en&amp;btnG=Search&amp;as_sdt=2001&amp;as_sdtp=on\">procrastination</a> is \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Steel-The-Nature-of-Procrastination.pdf\">The nature of procrastination</a>\" (2007) by Piers Steel, the first half of which is a review article, while the second half is a meta-analysis. Bingo.</p>\n<p>You can also search Amazon for key terms. I recently searched Amazon for 'attention neuroscience.' Result #2 was <a href=\"http://www.amazon.com/Attention-Action-Cognitive-Neuroscience-Behavioural/dp/1841693545/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">a 2004 scholarly edited volume</a> on the subject. A bit old, but not bad for my first search! I found the PDF on <a href=\"http://library.nu/search?q=attention%20in%20action\">library.nu</a>.</p>\n<p>In order to find good review articles, textbooks, and scholarly edited volumes you may first need to figure out what the terminology is. When I wanted to understand the neuroscience of pleasure and desire, it took me a while to figure out that the neuroscience of emotions is called <em>affective neuroscience</em>. After consuming that field, I had learned a lot about pleasure but not much about desire. I then realized that I didn't care about desire <em>as an emotion</em>&nbsp;but instead as <em>a driver of action under uncertainty</em>. That aspect of desire, it turns out, is studied not under the field of affective neuroscience but instead <em>neuroeconomics</em>.</p>\n<p>Similarly, when I was originally looking for 'scientific self-help', I had trouble finding review articles or textbooks on the subject. It took me months to discover that professionals call this the <em>psychology of adjustment</em>. Who would have guessed that? But once I knew the term, I quickly found <a href=\"http://www.amazon.com/Psychology-Applied-Modern-Life-Adjustment/dp/1111186634/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">two</a> <a href=\"http://www.amazon.com/Human-Adjustment--Psych-CD-ROM-Santrock/dp/0073111910/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">textbooks</a> on the subject, which were good starting points for understanding <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">the field</a>.</p>\n<p>Note that not every scholarly edited volume is a volume of <em>review articles</em>. <em><a href=\"http://www.amazon.com/Waves-Philosophy-Action-Jes%C3%BAs-Aguilar/dp/0230230601/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">New Waves in Philosophy of Action</a></em>&nbsp;is a collection of new research articles, not a collection of review articles. It is a poor entry point into the field. Some edited volumes are&nbsp;<em>okay</em>&nbsp;entry points into the field because they are a mix of review articles and original research, for example <em><a href=\"http://www.amazon.com/Machine-Ethics-Michael-Anderson/dp/0521112354/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Machine Ethics</a></em>&nbsp;(2011). But remember that a 'good' edited volume on a subject does not protect you from the entire <em>field</em>&nbsp;being <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">mostly misguided</a>, like machine ethics or <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">mainstream philosophy</a>.</p>\n<p>Also note that if you can't find an edited volume on your subject, one may be just around the corner. In 2007 there was no decent edited volume on neuroeconomics, but there were <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Camerer-Neuroeconomics-how-neuroscience-can-inform-economics.pdf\">three</a> <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sanfey-Neuroeconomics-cross-currents-in-research-on-decision-making.pdf\">review</a> <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Glimcher-Neuroeconomics-the-consilience-of-brain-and-decision.pdf\">articles</a>. Then in 2008,&nbsp;<em><a href=\"http://www.amazon.com/Neuroeconomics-Decision-Paul-W-Glimcher/dp/0123741769/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Decision Making and the Brain</a>&nbsp;</em>was released.</p>\n<p>&nbsp;</p>\n<h4 id=\"Going_granular\">Going granular</h4>\n<p>Once textbooks and review articles have given you a good overview of the key concepts and terms, open and closed problems, studies and researchers on your chosen topic, it's time to go granular.</p>\n<p>Textbooks and review articles will point you to the articles most directly relevant for answering the questions you have, and the researchers working on the problems you care about. Visit researchers' home pages and check their 'recent publications' lists. Find the papers on <a href=\"http://scholar.google.com/\">Google Scholar</a> and read the abstracts. Make a list of the ones you need to read more closely. You'll be able to download many of them directly from links found on Google Scholar. For others, you'll need to visit a university library's computer lab to download the papers. The university will have subscribed to many of the databases that carry the papers, and university computers will let you past the paywall (but on-campus wifi will not). To get access to a paper you can't get at a nearby university, you can:</p>\n<ol>\n<li>Contact the author via email and request a copy (or a preprint), explaining that you can't get it elsewhere.</li>\n<li>Ask your friends at other universities to check if their university has access to it.</li>\n<li>Look to see if the article has been published in a book that is available at your library or online.</li>\n</ol>\n<p>I've never purchased an article from an online database because the prices are outrageous: $15-$40 for a 20-page article, usually. If I absolutely can't get access to an article, I make a judgement as to how much weight to give the study's conclusions, inferring this from the researcher's history and the abstract and responses to the article I <em>can</em>&nbsp;read and other factors.</p>\n<p>Skim through promising research articles for the information you want, watching for obvious problems in experimental design or quality of argument. This is where your time investment in scholarship can explode, so be conscious of the tradeoffs involved when reading 100 abstracts vs. reading 100 papers.</p>\n<p>You can also try contacting individual researchers. This works best when the subject line of your email is very descriptive, and is obviously about a detail in their recent work. The content of your email should ask a very specific question or two, quoting directly from their paper(s). Researchers are often excited to hear that somebody is actually reading their work closely, though philosophers get more excited than neuroscientists (for example). Neuroscientists are called for comment by the media somewhat regularly. This doesn't happen to philosophers.</p>\n<p>Finally, if you've done all this work already and you're feeling generous, perhaps you could take a little time to write up the results of your research for the rest of us! Or, <a href=\"http://en.wikipedia.org/wiki/Wikipedia:Contributing_to_Wikipedia\">help make Wikipedia better</a>.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Review articles and textbooks are king", "anchor": "Review_articles_and_textbooks_are_king", "level": 1}, {"title": "Going granular", "anchor": "Going_granular", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "146 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 149, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["64FdKLwmea8MCLWkE", "TFbAMgeiCLjdX4Smw", "RWo4LwFzpHNQCTcYt", "48DTJkBH58JbBNSFH", "CKW8c2Bngz9yXibSk", "zThWT5Zvifo5qYaca", "6Cc3TWZjAnrNWokWY", "du395YvCnQXBPSJax", "ZbgCx2ntD5eu8Cno9", "xg3hXCYQPJkwHyik2", "33KewgYhNSxFpbpXg", "fyZBtNB3Ki3fM4a6Y", "FwiPfF8Woe5JrzqEu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 10, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2011-05-09T22:05:42.156Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T02:00:16.735Z", "modifiedAt": null, "url": null, "title": "How should I help us achieve immortality?", "slug": "how-should-i-help-us-achieve-immortality", "viewCount": null, "lastCommentedAt": "2011-11-26T22:22:49.769Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Hul-Gil", "createdAt": "2011-05-02T22:16:10.898Z", "isAdmin": false, "displayName": "Hul-Gil"}, "userId": "a67SuoZfWaXPzjvzy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ktXyc2pGoHxpoaQwH/how-should-i-help-us-achieve-immortality", "pageUrlRelative": "/posts/ktXyc2pGoHxpoaQwH/how-should-i-help-us-achieve-immortality", "linkUrl": "https://www.lesswrong.com/posts/ktXyc2pGoHxpoaQwH/how-should-i-help-us-achieve-immortality", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20should%20I%20help%20us%20achieve%20immortality%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20should%20I%20help%20us%20achieve%20immortality%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FktXyc2pGoHxpoaQwH%2Fhow-should-i-help-us-achieve-immortality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20should%20I%20help%20us%20achieve%20immortality%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FktXyc2pGoHxpoaQwH%2Fhow-should-i-help-us-achieve-immortality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FktXyc2pGoHxpoaQwH%2Fhow-should-i-help-us-achieve-immortality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 358, "htmlBody": "<p>I was immensely glad to find this community, because while I knew intellectually that I was not the only person who felt that rationality was important, death was bad, and technology was our savior, I had never <em>met </em>anyone else who did. I thus determined my career without much input from anything except my own interests; which is not so bad, of course, but I have realized that I might benefit from advice from like-minded people.</p>\n<p>Specifically, I would like to know what LessWrong thinks I should do in order to get into \"immortality research.\" <strong>Edit: </strong>that means \"<span style=\"color: #339966;\">what field should I go into if I want humanity to have extended lifespans as soon as possible?</span>\"</p>\n<p>I feel immortality, or at least life-extension, is one of - if not <em>the</em> - most important thing(s) humanity can accomplish right now. I don't think I am suited to AI work, however. Another obvious option is an MD, but that's not in my temperament either. My major right now is biochemistry, in preparation for a doctorate in either biochemistry itself, or pharmacology.</p>\n<p>I think there's a good chance that advances in this area could contribute to life extension; aging is a biochemical process, right? And certainly drugs will be involved in life extension. But is this the <strong>best</strong> place to apply my efforts? I have considered that biogerontology (http://en.wikipedia.org/wiki/Gerontology) might be better, as it is about aging specifically; but I don't know much about the field - only that Wikipedia says it is new and very few universities offer degrees in it. My final idea is nanotechnology of some kind; I believe nanomachines may be able to repair our bodies. I'm not sure what type of nanotechnology I'd be looking at for this, or if degrees in it are offered.</p>\n<p>Any ideas, suggestions, or comments in general are welcome. I favor the biochemical approach as of now, but only through temperament. As far as I know, AI, biochemical/pharmacological methods, and nanotechnology are all about equally close to giving us immortality. If someone feels one option is better than the others, or has recommended reading on the subject, please share!</p>\n<p>&nbsp;</p>\n<p>Thanks in advance, my new rational friends.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ktXyc2pGoHxpoaQwH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 16, "extendedScore": null, "score": 7.127036443474891e-07, "legacy": true, "legacyId": "7288", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 84, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T05:27:25.332Z", "modifiedAt": null, "url": null, "title": "Schneier talks about The Dishonest Minority [Link]", "slug": "schneier-talks-about-the-dishonest-minority-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.451Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nic_Smith", "createdAt": "2009-10-23T03:32:46.312Z", "isAdmin": false, "displayName": "Nic_Smith"}, "userId": "XP9GcTgRGLBCnf9ih", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Px7JSgnHvykLHpggN/schneier-talks-about-the-dishonest-minority-link", "pageUrlRelative": "/posts/Px7JSgnHvykLHpggN/schneier-talks-about-the-dishonest-minority-link", "linkUrl": "https://www.lesswrong.com/posts/Px7JSgnHvykLHpggN/schneier-talks-about-the-dishonest-minority-link", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Schneier%20talks%20about%20The%20Dishonest%20Minority%20%5BLink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASchneier%20talks%20about%20The%20Dishonest%20Minority%20%5BLink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPx7JSgnHvykLHpggN%2Fschneier-talks-about-the-dishonest-minority-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Schneier%20talks%20about%20The%20Dishonest%20Minority%20%5BLink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPx7JSgnHvykLHpggN%2Fschneier-talks-about-the-dishonest-minority-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPx7JSgnHvykLHpggN%2Fschneier-talks-about-the-dishonest-minority-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<p>Evolution. Morality. Strategy. Security/Cryptography. This hits so many topics of interest, I can't imagine it <em>not</em> being discussed here. Bruce Schneier blogs about his book-in-progress, <a href=\"http://www.schneier.com/blog/archives/2011/05/status_report_t.html\"><em>The Dishonest Minority</em></a>:</p>\n<blockquote>\n<p>Humans evolved along this path.  The basic mechanism can be modeled  simply.  It is in our collective group interest for everyone to  cooperate.  It is in any given individual's short-term self interest not  to cooperate: to defect, in game theory terms.  But if everyone  defects, society falls apart.  To ensure widespread cooperation and  minimal defection, we collectively implement a variety of societal  security systems.</p>\n</blockquote>\n<p>I am somewhat reminded of Robin Hanson's <em><a href=\"http://www.overcomingbias.com/2010/03/homo-hipocritus.html\">Homo Hypocritus</a> </em>writings from the above, although it is not the same. Schneier says that the book is basically a first draft at this point, and might still change quite a bit. Some of the comments focus on whether \"dishonest\" is actually the best term to use for defecting from social norms.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Px7JSgnHvykLHpggN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "7290", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T06:00:42.798Z", "modifiedAt": null, "url": null, "title": "Seeking advice on a moral dilemma", "slug": "seeking-advice-on-a-moral-dilemma", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:59.078Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KuAoHXgA6rjCFBrmF/seeking-advice-on-a-moral-dilemma", "pageUrlRelative": "/posts/KuAoHXgA6rjCFBrmF/seeking-advice-on-a-moral-dilemma", "linkUrl": "https://www.lesswrong.com/posts/KuAoHXgA6rjCFBrmF/seeking-advice-on-a-moral-dilemma", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seeking%20advice%20on%20a%20moral%20dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeeking%20advice%20on%20a%20moral%20dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKuAoHXgA6rjCFBrmF%2Fseeking-advice-on-a-moral-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seeking%20advice%20on%20a%20moral%20dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKuAoHXgA6rjCFBrmF%2Fseeking-advice-on-a-moral-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKuAoHXgA6rjCFBrmF%2Fseeking-advice-on-a-moral-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>I just found 120 Euro (about $172) on the floor in the hallway in a hostel in Berlin. What should I do, and why?</p>\n<p>&nbsp;</p>\n<ul>\n<li>It's not inconceivable that the hostel might just take the money if I turn it in.</li>\n<li>I'll be at this hostel for about two more days.</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KuAoHXgA6rjCFBrmF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 7.12773019398527e-07, "legacy": true, "legacyId": "7291", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T06:15:10.928Z", "modifiedAt": null, "url": null, "title": "[HPMoR] Trailer up", "slug": "hpmor-trailer-up", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.146Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sGDyh49356uP5RT49/hpmor-trailer-up", "pageUrlRelative": "/posts/sGDyh49356uP5RT49/hpmor-trailer-up", "linkUrl": "https://www.lesswrong.com/posts/sGDyh49356uP5RT49/hpmor-trailer-up", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BHPMoR%5D%20Trailer%20up&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BHPMoR%5D%20Trailer%20up%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsGDyh49356uP5RT49%2Fhpmor-trailer-up%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BHPMoR%5D%20Trailer%20up%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsGDyh49356uP5RT49%2Fhpmor-trailer-up", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsGDyh49356uP5RT49%2Fhpmor-trailer-up", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 31, "htmlBody": "<p>Hopefully I'm not spamming the discussion board. Anyway, based on the highest-karma comment from the last post, I've created a trailer for the Harry Potter and the Methods of Rationality podcast.</p>\n<p>Here:&nbsp;<a href=\"http://www.youtube.com/watch?v=sozq1YsGgZ4\">http://www.youtube.com/watch?v=sozq1YsGgZ4</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sGDyh49356uP5RT49", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 15, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "7293", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T07:15:54.207Z", "modifiedAt": null, "url": null, "title": "Holy Books (Or Rationalist Sequences) Don\u2019t Implement Themselves", "slug": "holy-books-or-rationalist-sequences-don-t-implement", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:01.970Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4CW68uEwgWuLfBenZ/holy-books-or-rationalist-sequences-don-t-implement", "pageUrlRelative": "/posts/4CW68uEwgWuLfBenZ/holy-books-or-rationalist-sequences-don-t-implement", "linkUrl": "https://www.lesswrong.com/posts/4CW68uEwgWuLfBenZ/holy-books-or-rationalist-sequences-don-t-implement", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Holy%20Books%20(Or%20Rationalist%20Sequences)%20Don%E2%80%99t%20Implement%20Themselves&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHoly%20Books%20(Or%20Rationalist%20Sequences)%20Don%E2%80%99t%20Implement%20Themselves%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4CW68uEwgWuLfBenZ%2Fholy-books-or-rationalist-sequences-don-t-implement%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Holy%20Books%20(Or%20Rationalist%20Sequences)%20Don%E2%80%99t%20Implement%20Themselves%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4CW68uEwgWuLfBenZ%2Fholy-books-or-rationalist-sequences-don-t-implement", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4CW68uEwgWuLfBenZ%2Fholy-books-or-rationalist-sequences-don-t-implement", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 984, "htmlBody": "<p><!-- /* Font Definitions */ @font-face {font-family:\"Times New Roman\"; panose-1:0 2 2 6 3 5 4 5 2 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:\"Courier New\"; panose-1:0 2 7 3 9 2 2 5 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:Wingdings; panose-1:0 5 2 1 2 1 8 4 8 7; mso-font-charset:2; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:0 0 256 0 -2147483648 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText {margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} span.MsoFootnoteReference {vertical-align:super;} a:link, span.MsoHyperlink {color:blue; text-decoration:underline; text-underline:single;} a:visited, span.MsoHyperlinkFollowed {color:purple; text-decoration:underline; text-underline:single;} table.MsoNormalTable {mso-style-parent:\"\"; font-size:10.0pt; font-family:\"Times New Roman\";} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:1532643161; mso-list-type:hybrid; mso-list-template-ids:-1246472920 243311300 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l0:level1 {mso-level-number-format:bullet; mso-level-text:-; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.25in; font-family:\"Times New Roman\"; mso-font-width:0%;} @list l0:level2 {mso-level-number-format:bullet; mso-level-text:o; mso-level-tab-stop:1.25in; mso-level-number-position:left; margin-left:1.25in; text-indent:-.25in; font-family:\"Courier New\";} @list l0:level3 {mso-level-number-format:bullet; mso-level-text:\uf0a7; mso-level-tab-stop:1.75in; mso-level-number-position:left; margin-left:1.75in; text-indent:-.25in; font-family:Wingdings;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --></p>\n<p class=\"MsoNormal\">Related to: <a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the/\">Lessons from Latter-day Saints</a>, <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">Building Rationalist Communities overview</a></p>\n<p class=\"MsoNormal\"><strong>This is my basic thesis:</strong></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin-left:.5in\">Marx needed a Lenin. Fermi, Hahn and Meitner needed a Manhattan Project. EY and the Sequences need more clearly- and simply-defined rationality skills and methods for improving them.</p>\n</blockquote>\n<p class=\"MsoNormal\">Using <a href=\"/lw/5kz/the_5second_level/\">Eliezer&rsquo;s levels scheme</a>, these are the three descending levels on which belief systems operate: theology, norms, and implementation.</p>\n<p class=\"MsoNormal\">I&rsquo;ll give some examples. Here&rsquo;s a general example, again from the Latter-day Saints:</p>\n<ul>\n<li><em>Theology:</em><span style=\"font-style:normal\"> God knows everything. Your purpose on earth is to become like God<em>;</em></span></li>\n<li><em>Norms:</em><span style=\"font-style:normal\"> You should pursue as much education as possible.</span></li>\n<li><em>Implementation:</em><span style=\"font-style:normal\"> Create and operate a <a href=\"http://en.wikipedia.org/wiki/Brigham_Young_University\">really</a> <a href=\"http://en.wikipedia.org/wiki/Brigham_Young_University%E2%80%93Idaho\">big</a>, <a href=\"http://www.deseretnews.com/article/700106113/BYU-Idaho-will-raise-tuition-next-year-by-3-percent.html\">cheap</a> university system.<a style=\"mso-footnote-id: ftn1\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[1]</span></span></a> </span></li>\n</ul>\n<p class=\"MsoNormal\">Here&rsquo;s one that I often dealt with as a missionary:</p>\n<ul>\n<li><em>Theology:</em><span style=\"font-style:normal\"> God is really good at making decisions. Your purpose on earth is to become like God. </span></li>\n<li><em>Norms:</em><span style=\"font-style:normal\"> You shouldn&rsquo;t take alcohol, tobacco, tea, coffee, or addictive substances. Taking addictive substances impairs your ability to make correct decisions. </span></li>\n<li><em>Implementation:</em><span style=\"font-style:normal\"> We are going to bring you candy every week so that when you&rsquo;re tempted to buy a cigarette, you can eat the strawberry toffee instead. (Or, we are going to stop by your house every day at 8:30pm to give you a boost, because going from 7 cups of coffee a day to 0 is tough.)</span></li>\n</ul>\n<p class=\"MsoNormal\">I did both of these (with different people), and they worked.</p>\n<p class=\"MsoNormal\"><strong>Norms and Implementation</strong></p>\n<p class=\"MsoNormal\">As a missionary for the Church, my basic role was to:</p>\n<ul>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;</span></span>find people who were willing to try something out</li>\n<li>design individualized &ldquo;commitment systems&rdquo; for each person, and</li>\n<li>support them in implementing them.</li>\n</ul>\n<p class=\"MsoNormal\">There&rsquo;s a lifestyle change here.</p>\n<p class=\"MsoNormal\">The &ldquo;basic package,&rdquo; (my terminology), which is a prerequisite to joining the church, includes: a strong focus on strengthening the family, daily family prayer and scripture study, the aforementioned health code, and sex only inside marriage. The glue is weekly church attendance, ensuring membership in a community that shares the same values.</p>\n<p class=\"MsoNormal\">After the &ldquo;basic package,&rdquo; it gets a bit more complex, as there are lots of higher-level elements of this lifestyle. To sample a few in no particular order:</p>\n<ul>\n<li>Loving others. Developing gratitude. Keeping a journal. Following Church leaders. Inviting other people to church. Serving others, especially by accepting responsibilities in church. Pursuing education. Forgiving others.</li>\n<li>Understanding that you have innate self-worth. Not gossiping. Dressing modestly. Being a good parent. Honoring and respecting parents. Keeping a budget. Doing family activities and not shopping on Sunday. Staying out of debt.</li>\n<li>For the doubting, to continue living these habits, until they develop (expected) greater belief through experience.<a style=\"mso-footnote-id: ftn2\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[2]</span></span></a></li>\n</ul>\n<p class=\"MsoNormal\">Obviously these are different than rationalist norms, but my point is that they are fairly comprehensive. Though each topic is fairly regularly discussed in church, it&rsquo;s impossible to implement them into your life all at once. It&rsquo;s easy to seem overwhelmed by the flood of new information. (Sound familiar?)</p>\n<p class=\"MsoNormal\">And that is why we were there, to design mini-programs for each person.<a style=\"mso-footnote-id:ftn3\" name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> We would isolate a couple of specific standards that would be effective for person X, and assist in implementation. If they liked it and wanted more, we helped them implement the &ldquo;basic package&rdquo; lifestyle.</p>\n<p class=\"MsoNormal\"><em>This decision, that they liked it and wanted more, was the single most crucial decision that someone could make. It is directly related to Bhagwat&rsquo;s Law of Commitment: &ldquo;The degree to which people identify with your group is directly proportional to the amount of stuff you tell them to do that works.&rdquo; I will discuss this further on a subsequent post.</em></p>\n<p class=\"MsoNormal\"><strong>Okay, so how does this apply to Less Wrongians?</strong></p>\n<p class=\"MsoNormal\">Less Wrong has its version of a theological framework &ndash; <a href=\"http://wiki.lesswrong.com/wiki/Sequences#Major_Sequences\">the Sequences</a>. They give a comprehensive set of statements about the way the world works, drawn from evolutionary psychology, anthropology, Bayesian statistics, etc.</p>\n<p class=\"MsoNormal\">But rationalism doesn&rsquo;t have a well-defined set of norms/desirable skills to develop. As a result, we Less Wrongians unsurprisingly also lack a well-developed practical system for implementation.</p>\n<p class=\"MsoNormal\">You may cite <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">lukeprog&rsquo;s guide</a>. That&rsquo;s good, but it&rsquo;s only six posts. Less Wrong needs a lot more of it!</p>\n<p class=\"MsoNormal\">Or maybe you&rsquo;ll say that if you read the Sequences carefully, etc, etc. Well, I did. Mysterious Answers to Mysterious Questions is 51 <em>dense </em><span style=\"font-style:normal\">pages in Word, or about 25,000 words. This is an (extremely good) foundational text. It is not a how-to manual.<a style=\"mso-footnote-id:ftn4\" name=\"_ftnref4\" href=\"#_ftn4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[4]</span></span></a> </span></p>\n<p class=\"MsoNormal\">Brevity is key to implementation.</p>\n<p class=\"MsoNormal\">For Latter-day Saints, the basic explanation of <a href=\"http://lds.org/manual/family-guidebook?lang=eng\">family standards</a> is about 6000 words (95% of the important stuff is from page 4 to 15). The <a href=\"http://en.wikipedia.org/wiki/For_the_Strength_of_Youth\">basic guide for teenagers</a> is about 4000 words, and the <a href=\"http://lds.org/manual/branch-guidebook?lang=eng\">basic guide for running a church organization</a> is about 12000 words. And each one is very clear about what to do. (The teenage guide most clearly illustrates this point about brevity.)</p>\n<p class=\"MsoNormal\"><em>The easiest way to begin building a how-to manual is for LW members to post specific, short personal examples of how they applied the principles of rationality in their day-to-day lives. Then they should collect all of the links somewhere, probably on the wiki.</em></p>\n<p class=\"MsoNormal\">If this sounds salesman-y or cheesy to you, or if you're extremely skeptical about religion, I quote a <a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the/44sc\">commenter</a> on my last post. &ldquo;If this works for people that are obviously crazy,\" said <a href=\"/user/Vaniver/\">Vaniver</a>, \"that suggests it'll work for people who are (hopefully obviously) sane.&rdquo;</p>\n<div style=\"mso-element:footnote-list\">\n<hr size=\"1\" />\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> Admittedly, this also supports other norms, such as &lsquo;marry another Latter-day Saint.&rsquo;</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn2\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a>I&rsquo;m not claiming this is perfect. Over the four years since I joined, I've encountered various amounts of ingroup snobbery, use of these standards to judge others, cliquishness, and intolerance towards certain groups, primarily gays. Plus all of the normal human imperfections.</p>\n</div>\n<div id=\"ftn3\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn3\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> In designing and sequencing programs, we generally used a simple cost-benefit standard: how much will this help X vs. how much effort will it cost X?</p>\n</div>\n<div id=\"ftn4\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn4\" name=\"_ftn4\" href=\"#_ftnref4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[4]</span></span></a> By comparison: the Bible is a foundational text of Christianity.&nbsp; <a href=\"http://en.wikipedia.org/wiki/The_Purpose_Driven_Life\">The Purpose-Driven Life</a>&nbsp; is a derivative how-to manual. This is a <a href=\"/lw/fc/you_are_a_brain/\">distillation</a> of the Sequences, which is at least a start.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "7ow6EFpypbH4hzFuz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4CW68uEwgWuLfBenZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 54, "baseScore": 39, "extendedScore": null, "score": 0.000126, "legacy": true, "legacyId": "7303", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!-- /* Font Definitions */ @font-face {font-family:\"Times New Roman\"; panose-1:0 2 2 6 3 5 4 5 2 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:\"Courier New\"; panose-1:0 2 7 3 9 2 2 5 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:Wingdings; panose-1:0 5 2 1 2 1 8 4 8 7; mso-font-charset:2; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:0 0 256 0 -2147483648 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText {margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} span.MsoFootnoteReference {vertical-align:super;} a:link, span.MsoHyperlink {color:blue; text-decoration:underline; text-underline:single;} a:visited, span.MsoHyperlinkFollowed {color:purple; text-decoration:underline; text-underline:single;} table.MsoNormalTable {mso-style-parent:\"\"; font-size:10.0pt; font-family:\"Times New Roman\";} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:1532643161; mso-list-type:hybrid; mso-list-template-ids:-1246472920 243311300 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l0:level1 {mso-level-number-format:bullet; mso-level-text:-; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.25in; font-family:\"Times New Roman\"; mso-font-width:0%;} @list l0:level2 {mso-level-number-format:bullet; mso-level-text:o; mso-level-tab-stop:1.25in; mso-level-number-position:left; margin-left:1.25in; text-indent:-.25in; font-family:\"Courier New\";} @list l0:level3 {mso-level-number-format:bullet; mso-level-text:\uf0a7; mso-level-tab-stop:1.75in; mso-level-number-position:left; margin-left:1.75in; text-indent:-.25in; font-family:Wingdings;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --></p>\n<p class=\"MsoNormal\">Related to: <a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the/\">Lessons from Latter-day Saints</a>, <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">Building Rationalist Communities overview</a></p>\n<p class=\"MsoNormal\"><strong id=\"This_is_my_basic_thesis_\">This is my basic thesis:</strong></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin-left:.5in\">Marx needed a Lenin. Fermi, Hahn and Meitner needed a Manhattan Project. EY and the Sequences need more clearly- and simply-defined rationality skills and methods for improving them.</p>\n</blockquote>\n<p class=\"MsoNormal\">Using <a href=\"/lw/5kz/the_5second_level/\">Eliezer\u2019s levels scheme</a>, these are the three descending levels on which belief systems operate: theology, norms, and implementation.</p>\n<p class=\"MsoNormal\">I\u2019ll give some examples. Here\u2019s a general example, again from the Latter-day Saints:</p>\n<ul>\n<li><em>Theology:</em><span style=\"font-style:normal\"> God knows everything. Your purpose on earth is to become like God<em>;</em></span></li>\n<li><em>Norms:</em><span style=\"font-style:normal\"> You should pursue as much education as possible.</span></li>\n<li><em>Implementation:</em><span style=\"font-style:normal\"> Create and operate a <a href=\"http://en.wikipedia.org/wiki/Brigham_Young_University\">really</a> <a href=\"http://en.wikipedia.org/wiki/Brigham_Young_University%E2%80%93Idaho\">big</a>, <a href=\"http://www.deseretnews.com/article/700106113/BYU-Idaho-will-raise-tuition-next-year-by-3-percent.html\">cheap</a> university system.<a style=\"mso-footnote-id: ftn1\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[1]</span></span></a> </span></li>\n</ul>\n<p class=\"MsoNormal\">Here\u2019s one that I often dealt with as a missionary:</p>\n<ul>\n<li><em>Theology:</em><span style=\"font-style:normal\"> God is really good at making decisions. Your purpose on earth is to become like God. </span></li>\n<li><em>Norms:</em><span style=\"font-style:normal\"> You shouldn\u2019t take alcohol, tobacco, tea, coffee, or addictive substances. Taking addictive substances impairs your ability to make correct decisions. </span></li>\n<li><em>Implementation:</em><span style=\"font-style:normal\"> We are going to bring you candy every week so that when you\u2019re tempted to buy a cigarette, you can eat the strawberry toffee instead. (Or, we are going to stop by your house every day at 8:30pm to give you a boost, because going from 7 cups of coffee a day to 0 is tough.)</span></li>\n</ul>\n<p class=\"MsoNormal\">I did both of these (with different people), and they worked.</p>\n<p class=\"MsoNormal\"><strong id=\"Norms_and_Implementation\">Norms and Implementation</strong></p>\n<p class=\"MsoNormal\">As a missionary for the Church, my basic role was to:</p>\n<ul>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;</span></span>find people who were willing to try something out</li>\n<li>design individualized \u201ccommitment systems\u201d for each person, and</li>\n<li>support them in implementing them.</li>\n</ul>\n<p class=\"MsoNormal\">There\u2019s a lifestyle change here.</p>\n<p class=\"MsoNormal\">The \u201cbasic package,\u201d (my terminology), which is a prerequisite to joining the church, includes: a strong focus on strengthening the family, daily family prayer and scripture study, the aforementioned health code, and sex only inside marriage. The glue is weekly church attendance, ensuring membership in a community that shares the same values.</p>\n<p class=\"MsoNormal\">After the \u201cbasic package,\u201d it gets a bit more complex, as there are lots of higher-level elements of this lifestyle. To sample a few in no particular order:</p>\n<ul>\n<li>Loving others. Developing gratitude. Keeping a journal. Following Church leaders. Inviting other people to church. Serving others, especially by accepting responsibilities in church. Pursuing education. Forgiving others.</li>\n<li>Understanding that you have innate self-worth. Not gossiping. Dressing modestly. Being a good parent. Honoring and respecting parents. Keeping a budget. Doing family activities and not shopping on Sunday. Staying out of debt.</li>\n<li>For the doubting, to continue living these habits, until they develop (expected) greater belief through experience.<a style=\"mso-footnote-id: ftn2\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[2]</span></span></a></li>\n</ul>\n<p class=\"MsoNormal\">Obviously these are different than rationalist norms, but my point is that they are fairly comprehensive. Though each topic is fairly regularly discussed in church, it\u2019s impossible to implement them into your life all at once. It\u2019s easy to seem overwhelmed by the flood of new information. (Sound familiar?)</p>\n<p class=\"MsoNormal\">And that is why we were there, to design mini-programs for each person.<a style=\"mso-footnote-id:ftn3\" name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> We would isolate a couple of specific standards that would be effective for person X, and assist in implementation. If they liked it and wanted more, we helped them implement the \u201cbasic package\u201d lifestyle.</p>\n<p class=\"MsoNormal\"><em>This decision, that they liked it and wanted more, was the single most crucial decision that someone could make. It is directly related to Bhagwat\u2019s Law of Commitment: \u201cThe degree to which people identify with your group is directly proportional to the amount of stuff you tell them to do that works.\u201d I will discuss this further on a subsequent post.</em></p>\n<p class=\"MsoNormal\"><strong id=\"Okay__so_how_does_this_apply_to_Less_Wrongians_\">Okay, so how does this apply to Less Wrongians?</strong></p>\n<p class=\"MsoNormal\">Less Wrong has its version of a theological framework \u2013 <a href=\"http://wiki.lesswrong.com/wiki/Sequences#Major_Sequences\">the Sequences</a>. They give a comprehensive set of statements about the way the world works, drawn from evolutionary psychology, anthropology, Bayesian statistics, etc.</p>\n<p class=\"MsoNormal\">But rationalism doesn\u2019t have a well-defined set of norms/desirable skills to develop. As a result, we Less Wrongians unsurprisingly also lack a well-developed practical system for implementation.</p>\n<p class=\"MsoNormal\">You may cite <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">lukeprog\u2019s guide</a>. That\u2019s good, but it\u2019s only six posts. Less Wrong needs a lot more of it!</p>\n<p class=\"MsoNormal\">Or maybe you\u2019ll say that if you read the Sequences carefully, etc, etc. Well, I did. Mysterious Answers to Mysterious Questions is 51 <em>dense </em><span style=\"font-style:normal\">pages in Word, or about 25,000 words. This is an (extremely good) foundational text. It is not a how-to manual.<a style=\"mso-footnote-id:ftn4\" name=\"_ftnref4\" href=\"#_ftn4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[4]</span></span></a> </span></p>\n<p class=\"MsoNormal\">Brevity is key to implementation.</p>\n<p class=\"MsoNormal\">For Latter-day Saints, the basic explanation of <a href=\"http://lds.org/manual/family-guidebook?lang=eng\">family standards</a> is about 6000 words (95% of the important stuff is from page 4 to 15). The <a href=\"http://en.wikipedia.org/wiki/For_the_Strength_of_Youth\">basic guide for teenagers</a> is about 4000 words, and the <a href=\"http://lds.org/manual/branch-guidebook?lang=eng\">basic guide for running a church organization</a> is about 12000 words. And each one is very clear about what to do. (The teenage guide most clearly illustrates this point about brevity.)</p>\n<p class=\"MsoNormal\"><em>The easiest way to begin building a how-to manual is for LW members to post specific, short personal examples of how they applied the principles of rationality in their day-to-day lives. Then they should collect all of the links somewhere, probably on the wiki.</em></p>\n<p class=\"MsoNormal\">If this sounds salesman-y or cheesy to you, or if you're extremely skeptical about religion, I quote a <a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the/44sc\">commenter</a> on my last post. \u201cIf this works for people that are obviously crazy,\" said <a href=\"/user/Vaniver/\">Vaniver</a>, \"that suggests it'll work for people who are (hopefully obviously) sane.\u201d</p>\n<div style=\"mso-element:footnote-list\">\n<hr size=\"1\">\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> Admittedly, this also supports other norms, such as \u2018marry another Latter-day Saint.\u2019</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn2\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a>I\u2019m not claiming this is perfect. Over the four years since I joined, I've encountered various amounts of ingroup snobbery, use of these standards to judge others, cliquishness, and intolerance towards certain groups, primarily gays. Plus all of the normal human imperfections.</p>\n</div>\n<div id=\"ftn3\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn3\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> In designing and sequencing programs, we generally used a simple cost-benefit standard: how much will this help X vs. how much effort will it cost X?</p>\n</div>\n<div id=\"ftn4\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn4\" name=\"_ftn4\" href=\"#_ftnref4\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[4]</span></span></a> By comparison: the Bible is a foundational text of Christianity.&nbsp; <a href=\"http://en.wikipedia.org/wiki/The_Purpose_Driven_Life\">The Purpose-Driven Life</a>&nbsp; is a derivative how-to manual. This is a <a href=\"/lw/fc/you_are_a_brain/\">distillation</a> of the Sequences, which is at least a start.</p>\n</div>\n</div>", "sections": [{"title": "This is my basic thesis:", "anchor": "This_is_my_basic_thesis_", "level": 1}, {"title": "Norms and Implementation", "anchor": "Norms_and_Implementation", "level": 1}, {"title": "Okay, so how does this apply to Less Wrongians?", "anchor": "Okay__so_how_does_this_apply_to_Less_Wrongians_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "149 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 149, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["su7bXsXYpY55vwphc", "Zasc7RXAEosWLYf8E", "JcpzFpPBSmzuksmWM", "r5H6YCmnn8DMtBtxt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T11:01:34.728Z", "modifiedAt": null, "url": null, "title": "Norms survey (dead)", "slug": "norms-survey-dead", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:55.546Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cayenne", "createdAt": "2010-12-27T22:47:02.994Z", "isAdmin": false, "displayName": "Cayenne"}, "userId": "xXoNkpxZ5i5TfDHK8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rZahdBdQJAuf9HyNp/norms-survey-dead", "pageUrlRelative": "/posts/rZahdBdQJAuf9HyNp/norms-survey-dead", "linkUrl": "https://www.lesswrong.com/posts/rZahdBdQJAuf9HyNp/norms-survey-dead", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Norms%20survey%20(dead)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANorms%20survey%20(dead)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrZahdBdQJAuf9HyNp%2Fnorms-survey-dead%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Norms%20survey%20(dead)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrZahdBdQJAuf9HyNp%2Fnorms-survey-dead", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrZahdBdQJAuf9HyNp%2Fnorms-survey-dead", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>Edit - Barring a major surprise, this post should be regarded as a worthless artifact of my impulse to do things instead of talking about them. &nbsp;I apologize for any time wasted on this, and would recommend ignoring it unless it is for historical purposes. &nbsp;I'll just stick to things I'm less bad at from now on.</p>\n<p>&nbsp;</p>\n<p>This article will be edited as people post and discuss. &nbsp;</p>\n<p>I believe that we need to have a clear, concise statement about the beliefs, practices, and taboos that it is rational to hold, and that we already hold as a group. &nbsp;To be clear, this is not an attempt to make new norms, but an attempt to codify the ones that we already hold and to get a rough estimate of the popularity/importance of each.</p>\n<p><strong>Core Rational</strong> - skills, meta-beliefs, and habits that enhance personal rationality</p>\n<p><strong>Social Rational</strong> - norms that enhance working in groups rationally</p>\n<p><strong>LessWrong Norms</strong> - norms for dealing with Less Wrong specifically</p>\n<p><strong>Common Knowledge</strong> - basic, useful beliefs to build on</p>\n<h2><br /></h2>\n<h2><span style=\"font-size: small; font-weight: normal; \">Please post one phrase at a time and then give your reasoning under it. &nbsp;Once any idea has a common consensus, I'll add it to this article in the appropriate list. &nbsp;</span></h2>\n<p>Edited - Removed the word 'should' as someone has suggested a better phrasing. &nbsp;Edited again - category change, remove extra now-useless examples.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rZahdBdQJAuf9HyNp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 1, "extendedScore": null, "score": 7.128598478704051e-07, "legacy": true, "legacyId": "7307", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 71, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T11:36:36.496Z", "modifiedAt": null, "url": null, "title": "Optimizing Sleep", "slug": "optimizing-sleep", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:35.217Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "LxmsZsaFcsuHYBP8P", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p7CrByygeAqomsJqy/optimizing-sleep", "pageUrlRelative": "/posts/p7CrByygeAqomsJqy/optimizing-sleep", "linkUrl": "https://www.lesswrong.com/posts/p7CrByygeAqomsJqy/optimizing-sleep", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Optimizing%20Sleep&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOptimizing%20Sleep%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7CrByygeAqomsJqy%2Foptimizing-sleep%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Optimizing%20Sleep%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7CrByygeAqomsJqy%2Foptimizing-sleep", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7CrByygeAqomsJqy%2Foptimizing-sleep", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 473, "htmlBody": "<p>I have an atypical sleep schedule. &nbsp;I tend to drift in the hours that I keep (that is, going to sleep later and later each day until a 'reset' is required). &nbsp;I also am willing to sacrifice sleep if something sufficiently interesting or urgent (problem sets, a Neal Stephenson book, a new Less Wrong article about an interesting topic) comes up. &nbsp;While procrastination earlier in the day can also play a part in my staying up late, I've noticed that, left to my own devices, I seem to prefer a day-night inversion. &nbsp;I'm naturally much more active at night than during the day, and will skip a meal or two in order to maintain this schedule. &nbsp;(Note: &nbsp;I realize that day-night sleep inversion can be a sign of a medical illness. &nbsp;For reasons I won't go into here, I don't believe that any of them are applicable.)</p>\n<p>The schedule that I have now is not optimal for a number of reasons:</p>\n<ul>\n<li>Not being able to socialize with very many other people due to not syncing up with their schedules.</li>\n</ul>\n<ul>\n<li>'Drifting' leads to unpredictability in my ability to function at a given time during an upcoming day- which is &nbsp;important for tests and classes.</li>\n</ul>\n<ul>\n<li>Sleeping during the day is more difficult than at night (extra noises, distractions, etc.)</li>\n</ul>\n<p>&nbsp;</p>\n<ul>\n</ul>\n<p>What I'd like to do is figure out how to optimize my sleep schedule. &nbsp;I'd prefer not to just 'invert' it to be a typical sleep schedule, but to either alter the sleep schedule or discover changes that I can make in other parts of my life that will mitigate the downsides. &nbsp;Some things are obvious: microwavable food for when nothing else is available at night is one change that I can make right away and would minimize the damage from skipping meals. &nbsp;The social issues and 'drifting' are more complicated and don't present an obvious solution after a few minutes of reflection. &nbsp;The reason I resist changing back to a regular sleep schedule is that I know that I'm groggy and miserable in the morning and less productive until about noon of that day if forced to operate under a regular sleep schedule.</p>\n<p>Do you have an atypical sleep schedule now, or have you in earlier parts of your life? &nbsp;I would hazard a guess that among the Less Wrong/Rationality/Skeptic/Bayesian community, experimentation in sleep schedule would be higher than in the general population. &nbsp;Have you tried a polyphasic sleep schedule? &nbsp;(I once unsuccessfully did a few years ago in hopes of solving some of the above problems.) &nbsp;If you have experienced these or similar problems, what 'hacks' have you found that mitigate the downsides?</p>\n<p>&nbsp;</p>\n<p>(Note: This is my first discussion post. &nbsp;I apologize in advance if the formatting or content seems a bit askew as a result. &nbsp;Constructive criticism is of course welcome.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p7CrByygeAqomsJqy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 7e-06, "legacy": true, "legacyId": "7308", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T14:42:47.493Z", "modifiedAt": null, "url": null, "title": "What sort of algorithm enjoys music?", "slug": "what-sort-of-algorithm-enjoys-music", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:07.518Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aPqmwoBdquE6u4vZW/what-sort-of-algorithm-enjoys-music", "pageUrlRelative": "/posts/aPqmwoBdquE6u4vZW/what-sort-of-algorithm-enjoys-music", "linkUrl": "https://www.lesswrong.com/posts/aPqmwoBdquE6u4vZW/what-sort-of-algorithm-enjoys-music", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20sort%20of%20algorithm%20enjoys%20music%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20sort%20of%20algorithm%20enjoys%20music%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaPqmwoBdquE6u4vZW%2Fwhat-sort-of-algorithm-enjoys-music%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20sort%20of%20algorithm%20enjoys%20music%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaPqmwoBdquE6u4vZW%2Fwhat-sort-of-algorithm-enjoys-music", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaPqmwoBdquE6u4vZW%2Fwhat-sort-of-algorithm-enjoys-music", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 304, "htmlBody": "<p>Aesthetics is confusing me a bit right now. &nbsp;You &nbsp;might also ask the question \"why?\" with painting or architecture, for example. &nbsp;I am singling out music because I got to thinking about it via how we understand music.</p>\n<p><a href=\"/en.wikipedia.org/wiki/Amusia\">Neurological problems</a> can separately disable pitch/melody recognition, rhythm recognition and emotional reaction to music, and people can lose all of these without losing speech and speech processing. &nbsp;This is odd. &nbsp;Liking music is then some messy neurological process with its own special pathways. &nbsp;And it's probably not all that complicated, from a brain standpoint, just fuzzy and parallel.</p>\n<p>What do we know? &nbsp;We know that we don't generally like contextless musical objects, but instead enjoy relationships between musical objects, especially with some rhythm. &nbsp;And yet we enjoy music \"in the moment,\" (a musical object in the context of the last few measures) without having to listen to a whole piece. &nbsp;We tend to ascribe emotion to music (particularly the stress patterns, which seems vaguely connected to speech), and people can express themselves through music. &nbsp;Music can differ from culture to culture, but we usually like discrete, repeating scales and rhythms that partially repeat.</p>\n<p>One proposal is that we form a vague (consistent with many possibilities) model of what the musician is likely to do next, and enjoy it when the model feels accurate. &nbsp;The emotional content also suggests that \"musical grammar\" model, where different elements of the music communicate things to us and what we enjoy is deciphering the communication and experiencing the communicated emotions. &nbsp;I'd enjoy it if people had more suggestions and possible experiments. &nbsp;Going more abstract, should these proposals generalize well to other sorts of aesthetics, or should we assume that since it's probably all different neurons we shouldn't try too hard? &nbsp;If so, why do we feel like we enjoy aesthetic pursuits in similar ways?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aPqmwoBdquE6u4vZW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "7309", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T15:46:39.135Z", "modifiedAt": null, "url": null, "title": "SL4 META: list closure 2 month followup", "slug": "sl4-meta-list-closure-2-month-followup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:19.972Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7mCusQu7ZXprbYfYc/sl4-meta-list-closure-2-month-followup", "pageUrlRelative": "/posts/7mCusQu7ZXprbYfYc/sl4-meta-list-closure-2-month-followup", "linkUrl": "https://www.lesswrong.com/posts/7mCusQu7ZXprbYfYc/sl4-meta-list-closure-2-month-followup", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SL4%20META%3A%20list%20closure%202%20month%20followup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASL4%20META%3A%20list%20closure%202%20month%20followup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7mCusQu7ZXprbYfYc%2Fsl4-meta-list-closure-2-month-followup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SL4%20META%3A%20list%20closure%202%20month%20followup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7mCusQu7ZXprbYfYc%2Fsl4-meta-list-closure-2-month-followup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7mCusQu7ZXprbYfYc%2Fsl4-meta-list-closure-2-month-followup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<p>This is probably of interest only to the old-timers here. (Ironically, as a cross-post, this is almost by definition spam for LW, since anyone really interested in the topic would already be subscribed to SL4 and would have seen the emails.)</p>\n<p>In 13 March, I finally got around to a long outstanding bit of cleanup: s<a href=\"http://sl4.org/archive/1103/21112.html\">uggesting that</a> the equally long defunct SL4 list be formally closed, things tidied up, and the lights turned out. The suggestion met with a mixed (and muted) reception.</p>\n<p>Last night I followed up with a <a href=\"http://sl4.org/archive/1105/21135.html\">second email</a> comparing SL4 activity to activity on Extropy-chat, LW, OB, and MoR; it won't surprise anyone trying to drink from the firehose here that LW is approximately 3 orders of magnitude more active than SL4 is.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Xw6pxiicjuv6NJWjf": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7mCusQu7ZXprbYfYc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 26, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "7310", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T17:44:38.597Z", "modifiedAt": null, "url": null, "title": "[Link] The Myth of the Three Laws of Robotics", "slug": "link-the-myth-of-the-three-laws-of-robotics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:56.872Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Morendil", "createdAt": "2009-09-21T16:34:39.505Z", "isAdmin": false, "displayName": "Morendil"}, "userId": "aDcxmpDTkqN6vWmRZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/shhHeGgPcJkLEgcrz/link-the-myth-of-the-three-laws-of-robotics", "pageUrlRelative": "/posts/shhHeGgPcJkLEgcrz/link-the-myth-of-the-three-laws-of-robotics", "linkUrl": "https://www.lesswrong.com/posts/shhHeGgPcJkLEgcrz/link-the-myth-of-the-three-laws-of-robotics", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20The%20Myth%20of%20the%20Three%20Laws%20of%20Robotics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20The%20Myth%20of%20the%20Three%20Laws%20of%20Robotics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshhHeGgPcJkLEgcrz%2Flink-the-myth-of-the-three-laws-of-robotics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20The%20Myth%20of%20the%20Three%20Laws%20of%20Robotics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshhHeGgPcJkLEgcrz%2Flink-the-myth-of-the-three-laws-of-robotics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshhHeGgPcJkLEgcrz%2Flink-the-myth-of-the-three-laws-of-robotics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 55, "htmlBody": "<p>At <a href=\"http://singularityhub.com/2011/05/10/the-myth-of-the-three-laws-of-robotics-why-we-cant-control-intelligence/\">SingularityHub</a>. Promising title; disappointing content. Author proceeds by pure perceptual analogy with the Asimovian Three Laws alluded to; argues that the mere possibility of self-modification renders AI uncontrollable - without considering the possibility of fixed points in the goal computation. (\"Do you really think it can be constrained?\" - i.e. argument from limited imagination.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "shhHeGgPcJkLEgcrz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 5, "extendedScore": null, "score": 7.129762001827854e-07, "legacy": true, "legacyId": "7311", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T18:31:46.512Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Blue or Green on Regulation?", "slug": "seq-rerun-blue-or-green-on-regulation", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:31.800Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Gwdu2krNNT8zsGGnX/seq-rerun-blue-or-green-on-regulation", "pageUrlRelative": "/posts/Gwdu2krNNT8zsGGnX/seq-rerun-blue-or-green-on-regulation", "linkUrl": "https://www.lesswrong.com/posts/Gwdu2krNNT8zsGGnX/seq-rerun-blue-or-green-on-regulation", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Blue%20or%20Green%20on%20Regulation%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Blue%20or%20Green%20on%20Regulation%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGwdu2krNNT8zsGGnX%2Fseq-rerun-blue-or-green-on-regulation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Blue%20or%20Green%20on%20Regulation%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGwdu2krNNT8zsGGnX%2Fseq-rerun-blue-or-green-on-regulation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGwdu2krNNT8zsGGnX%2Fseq-rerun-blue-or-green-on-regulation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 344, "htmlBody": "<p>Today's post, <a href=\"/lw/h2/blue_or_green_on_regulation/\">Blue or Green on Regulation?</a>, was originally published on 15 March 2007. A summary (taken from the <a href=\"/555555\">LW wiki</a>):</p>\n<blockquote>\n<p>Both sides are often right in describing the terrible things that will happen if we take the other side's advice; the universe is \"unfair\", terrible things are going to happen regardless of what we do, and it's our job to trade off for the least bad outcome.</p>\n<p>(alternate summary:)</p>\n<p>In a rationalist community, it should not be necessary to talk in the usual circumlocutions when talking about empirical predictions. We should know that people think of arguments as soldiers and recognize the behavior in our selves. When you think about all the truth values around you come to see that much of what the Greens said about the downside of the Blue policy was true - that, left to the mercy of the free market, many people would be crushed by powers far beyond their understanding, nor would they deserve it. And imagine that most of what the Blues said about the downside of the Green policy was also true - that regulators were fallible humans with poor incentives, whacking on delicately balanced forces with a sledgehammer.</p>\n<p>(alternate summary:)</p>\n<p>Burch's law isn't a soldier-argument for regulation; estimating the appropriate level of regulation in each particular case is a superior third option.</p>\n</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/h1/the_scales_of_justice_the_notebook_of_rationality/\">The Scales of Justice, the Notebook of Rationality</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Gwdu2krNNT8zsGGnX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 7.129898079051668e-07, "legacy": true, "legacyId": "7313", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uaPc4NHi5jGXGQKFS", "XYCEB9roxEBfgjfxs", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T20:03:28.999Z", "modifiedAt": null, "url": null, "title": "\"I know I'm biased, but...\"", "slug": "i-know-i-m-biased-but", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.291Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "oFp6JLn8z9uxgdPp8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Wo7EKqAmrNZwkSDXe/i-know-i-m-biased-but", "pageUrlRelative": "/posts/Wo7EKqAmrNZwkSDXe/i-know-i-m-biased-but", "linkUrl": "https://www.lesswrong.com/posts/Wo7EKqAmrNZwkSDXe/i-know-i-m-biased-but", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22I%20know%20I'm%20biased%2C%20but...%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22I%20know%20I'm%20biased%2C%20but...%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWo7EKqAmrNZwkSDXe%2Fi-know-i-m-biased-but%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22I%20know%20I'm%20biased%2C%20but...%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWo7EKqAmrNZwkSDXe%2Fi-know-i-m-biased-but", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWo7EKqAmrNZwkSDXe%2Fi-know-i-m-biased-but", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1014, "htmlBody": "<p><strong>Inspired by:<em> </em></strong><a href=\"/lw/5kz/the_5second_level/\">The 5-Second Level</a>, <a href=\"/lw/he/knowing_about_biases_can_hurt_people/\">Knowing About Biases Can Hurt People</a></p>\n<p>\"I know I'm biased, but...\" and its equivalents seem to be relatively common in casual conversation--I've encountered the phrase in classroom discussions, on Internet message boards, and in political arguments. In most cases, \"I know I'm biased, but...\" is used as a way of feigning humility and deflecting criticism by preemptively responding to accusations of bias. That is, the speaker acknowledges that their argument may be flawed in order to deny their opponent the opportunity point out particular biases. It's a way of signaling to the audience, \"Yes, there are errors in this line of reasoning, but I already know that, so you can't accuse me of being biased.\"</p>\n<p>But as we all know by now, <a href=\"/lw/he/knowing_about_biases_can_hurt_people/\">it's not enough to just acknowledge biases--you have to actually correct the error before you can move on.</a> Admitting that your argument is based on bias does <em>not</em> absolve you of your error, and it doesn't make your argument any truer.</p>\n<p>Therefore, \"I know I'm biased, but\" is a <a href=\"/lw/k5/cached_thoughts/\">cached thought</a> that we would be better off without. But how can we get rid of it? Tabooing the phrase \"I know I'm biased, but...\" is not enough, since your brain will probably end up substituting something similar, such as \"I may be wrong, but...\" instead of making the appropriate correction. Instead, it is necessary to force your brain to consciously think about the bias instead of instinctively rationalizing the biased argument. This is a skill that takes place on the <a href=\"/lw/5kz/the_5second_level/\">5-second level</a>: you have to <em>stop</em> your train of thought mid-sentence and think about the situation more clearly. The following should serve as an anti-pattern for when you notice yourself thinking, \"I know I'm biased, but...\":</p>\n<p>1) <em>Stop.</em> I'm not ready to proceed. If there's a bias in my argument, bulldozing over it is never the correct solution. I need to just cut myself off in mid-sentence and think about this.</p>\n<p>2) <em>Identify the bias.</em> What is this bias that my brain is trying to cover up? Does it have a name? Where have I read about it before? What heuristic am I using that is causing the problem? Do I have any emotional attachment to this argument that might cloud my judgment? How would I feel if this argument was wrong? Where is my information coming from? Did I do a thorough job researching this argument?</p>\n<p>3) <em>Think about potential solutions</em>. What heuristic should I be using instead of the one I <em>am</em> using? Can I substitute a quantitative analysis or Bayesian update instead of jumping to a particular conclusion? Do I need to do more research to determine if this argument is true? What other sources of evidence can I consult?</p>\n<p>4)<em> Re-analyze using a different method</em>. What happens when I use the heuristics I just thought about instead of the ones I originally used? What pieces of evidence <a href=\"/lw/wj/is_that_your_true_rejection/\">really</a> support my argument? What facts would need to be different for it to be false? Can I compare multiple perspectives on this argument?</p>\n<p>5) <em>Re-evaluate the argument.</em> Does the argument still look correct? Does approaching the problem with a different method yield the same results? Have I completely <a href=\"/lw/oo/explaining_vs_explaining_away/\">explained away</a> the bias?</p>\n<p><a href=\"/lw/5kz/the_5second_level/\">An abstract explanation isn't always enough</a>, so here is an example:</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>\"...and that's why,\" Albert concluded, \"the iPhone is absolutely terrible!\"</p>\n<p>\"I know I'm biased,\" Barry replied, \"but iPhone is the best smartphone on the market!\"</p>\n<p><em>Uh-oh</em>, thought Barry. <em>I said that phrase again</em>.<em> Something's not right here</em>. \"Hang on a moment...\"</p>\n<p><em>Why would I think that the iPhone is the best smartphone on the market? How would I feel if it </em>wasn't <em>the best phone? Well, I'd be kind of annoyed that I spent all that money to buy one. I'd feel disappointed because the advertisement made it look really awesome, and I've always told everyone that it was worth the price. Am I rationalizing this? Hmm, maybe I am rationalizing and I just don't want to believe that I made a bad purchase. <br /></em></p>\n<p><em>Ok, so what if it is rationalization? What am I supposed to do now? Didn't I read something on LessWrong about this? This feels like \"<a href=\"/lw/gw/politics_is_the_mindkiller/\">politics is the mind-killer</a>\" territory--I should probably be re-thinking my arguments and checking for bias. <br /></em></p>\n<p><em>But how </em>should <em>I be evaluating the quality of my iPhone? I guess I should ask myself what features I care about--let's pick three. Well, the most important thing to me is service--I make a lot of calls for work and I don't want any of them to be dropped. I want my phone to be durable, too--I'm pretty clumsy and I drop it from time to time. And the phone bill is important too. <br /></em></p>\n<p><em>Alright, let's add all of this up: The iPhone is pretty fragile, I've already cracked the screen slightly. And it does drop calls sometimes--there might be a network with better coverage, I'm not sure. </em><em>And the phone bill--my old phone was definitely a lot cheaper, but it also wasn't a smartphone. I'd have to research other networks' coverage and pricing to be sure. <br /></em></p>\n<p><em>Wow, I might've been wrong about this. That means I wasted a lot of money. </em><em>And it also means that the iPhone probably isn't \"the best\" phone out there. Wait, that's not right--it </em>could<em> be the best, but I don't have the evidence to prove it, so my argument isn't right. I have to gather more evidence.</em></p>\n<p>\"Are you still there?\" Albert frowned in puzzlement. \"You kinda fuzzed out there for a second.\"</p>\n<p>\"Nevermind,\" said Barry. \"What I should have said was, the iPhone doesn't really do all of the things I want it to do. Say, where's the electronics store?\"</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Next time you catch yourself thinking, \"I know I'm biased, but...\", don't let your brain finish the sentence--stop that train of thought and analyze it!</p>\n<p><strong>Edit:</strong> Many commenters have suggested that \"I know I'm biased, but...\" is sometimes used to signal being open to counterarguments. As a result, it is best to double-check what you (or your discussion partners) are really signaling so that you can respond appropriately.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "ZXFpyQWPB5ideFbEG": 1, "Ng8Gice9KNkncxqcj": 1, "qf3kDBak4BQDDw3f2": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Wo7EKqAmrNZwkSDXe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 32, "extendedScore": null, "score": 5.2e-05, "legacy": true, "legacyId": "7314", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JcpzFpPBSmzuksmWM", "AdYdLP2sRqPMoe8fb", "2MD3NMLBPCqPfnfre", "TGux5Fhcd7GmTfNGC", "cphoF8naigLhRf3tu", "9weLK2AJ9JEt2Tt8f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-10T20:49:15.839Z", "modifiedAt": null, "url": null, "title": "SRS advice", "slug": "srs-advice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:57.000Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/z79ApTRh7Jhmis2g8/srs-advice", "pageUrlRelative": "/posts/z79ApTRh7Jhmis2g8/srs-advice", "linkUrl": "https://www.lesswrong.com/posts/z79ApTRh7Jhmis2g8/srs-advice", "postedAtFormatted": "Tuesday, May 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SRS%20advice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASRS%20advice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz79ApTRh7Jhmis2g8%2Fsrs-advice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SRS%20advice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz79ApTRh7Jhmis2g8%2Fsrs-advice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz79ApTRh7Jhmis2g8%2Fsrs-advice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 105, "htmlBody": "<p>I have made some significant progress in organizing myself with org-mode (basically a really well thought out emacs outliner) - consider this a plug :).&nbsp;</p>\n<p>Now I think I am ready to bite the bullet and automate another part of my mental apparatus, memorization. I'd like to hear other people's experiences with SRS - spaced repetition - (negative, too), what software they use, what do they use it for, how much time they spend. I expect these to vary, so stating your reasons is worth an extra upvote (and thanks ahead)</p>\n<p>&nbsp;</p>\n<p><strong>ETA: </strong>When do you decide something is worth memorizing vs. putting it into a searchable database?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"H2q58pKG6xFrv8bPz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "z79ApTRh7Jhmis2g8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 7.130292163678357e-07, "legacy": true, "legacyId": "7315", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-11T12:02:37.204Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes: May 2011", "slug": "rationality-quotes-may-2011-1", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:55.961Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oscar_Cunningham", "createdAt": "2009-09-18T13:28:22.764Z", "isAdmin": false, "displayName": "Oscar_Cunningham"}, "userId": "G2SZuAiaBaNPg9rBt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Lm8MpXRCRnMpG66Tj/rationality-quotes-may-2011-1", "pageUrlRelative": "/posts/Lm8MpXRCRnMpG66Tj/rationality-quotes-may-2011-1", "linkUrl": "https://www.lesswrong.com/posts/Lm8MpXRCRnMpG66Tj/rationality-quotes-may-2011-1", "postedAtFormatted": "Wednesday, May 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%3A%20May%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%3A%20May%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLm8MpXRCRnMpG66Tj%2Frationality-quotes-may-2011-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%3A%20May%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLm8MpXRCRnMpG66Tj%2Frationality-quotes-may-2011-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLm8MpXRCRnMpG66Tj%2Frationality-quotes-may-2011-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<div id=\"entry_t3_53k\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<blockquote>\n<p>I always have a quotation for everything&mdash;it saves original thinking.</p>\n</blockquote>\n<p id=\"firstHeading\" class=\"firstHeading\">-Dorothy L. Sayers</p>\n<p class=\"firstHeading\">&nbsp;</p>\n<p>This is the monthly quotes thread. Share and Enjoy.</p>\n<ul style=\"margin: 10px 2em; padding: 0px; list-style-type: disc; list-style-position: outside;\">\n<li>Please post all quotes separately, so that they can be voted up/down  separately.&nbsp; (If they are strongly related, reply to your own  comments.&nbsp; If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Lm8MpXRCRnMpG66Tj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 1, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "7334", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-11T17:08:12.597Z", "modifiedAt": null, "url": null, "title": "Motivation quotes", "slug": "motivation-quotes", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.048Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "zntneo", "createdAt": "2011-02-25T06:06:34.571Z", "isAdmin": false, "displayName": "zntneo"}, "userId": "AgBNRryLw7RWBT7uh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/D2Xv6Z9Xq2ATg6YL3/motivation-quotes", "pageUrlRelative": "/posts/D2Xv6Z9Xq2ATg6YL3/motivation-quotes", "linkUrl": "https://www.lesswrong.com/posts/D2Xv6Z9Xq2ATg6YL3/motivation-quotes", "postedAtFormatted": "Wednesday, May 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Motivation%20quotes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMotivation%20quotes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD2Xv6Z9Xq2ATg6YL3%2Fmotivation-quotes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Motivation%20quotes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD2Xv6Z9Xq2ATg6YL3%2Fmotivation-quotes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD2Xv6Z9Xq2ATg6YL3%2Fmotivation-quotes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 36, "htmlBody": "<p>I have been looking for rational motivation quotes because most quotes I hear don't seem to be. As an example i see in sports \"pain is weakness leaving the body\" this seems irrational and maybe harmful.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "D2Xv6Z9Xq2ATg6YL3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 2, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "7336", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-11T20:17:02.677Z", "modifiedAt": null, "url": null, "title": "Econ/Game theory question", "slug": "econ-game-theory-question", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:50.845Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psychohistorian", "createdAt": "2009-04-05T18:10:22.976Z", "isAdmin": false, "displayName": "Psychohistorian"}, "userId": "mAQgf4N8jv2jTMK5B", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6C24wYYZgQjLrpnMu/econ-game-theory-question", "pageUrlRelative": "/posts/6C24wYYZgQjLrpnMu/econ-game-theory-question", "linkUrl": "https://www.lesswrong.com/posts/6C24wYYZgQjLrpnMu/econ-game-theory-question", "postedAtFormatted": "Wednesday, May 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Econ%2FGame%20theory%20question&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEcon%2FGame%20theory%20question%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6C24wYYZgQjLrpnMu%2Fecon-game-theory-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Econ%2FGame%20theory%20question%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6C24wYYZgQjLrpnMu%2Fecon-game-theory-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6C24wYYZgQjLrpnMu%2Fecon-game-theory-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 247, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">This puzzled me. I'm pretty sure it's one of those unsolvable questions, but I'd want to know if it's not.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Two members of the species Homo Economus, A and B, live next to each other. A wants to buy an easement (a right to cross B's property, without which he cannot bring anything onto his lot) from B so that he can develop his property. B, under the law, has an absolute right to exclude A, meaning that nothing happens unless B agrees to it. The cost to B of granting this easement is $10 - it's over a fairly remote part of his land and he's not using it for anything else. A values the easement at $500,000, because he's got a sweet spot to build his dream house, if only he could construction equipment and whatnot to it. A and B know each others costs and values. They are \"rational\" and purely self-interested and bargaining costs zero. What's the outcome? I'm guessing it's \"Between $5 and $500k,\" or \"There is no deal unless one can credibly commit to being irrational.\" But I'm really not sure.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">This could be asked as \"In a bilateral monopoly situation where the seller's reservation price is $5 and the buyer's is $500,000, what is the predicted outcome?\" But I figured the concrete example might make it more concrete.&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Now that I've written this, I'm tempted to develop a \"True price fallacy\" and its implications for utilitarian measurement. But that's a separate matter entirely.</p>\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6C24wYYZgQjLrpnMu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 19, "extendedScore": null, "score": 3.6e-05, "legacy": true, "legacyId": "7340", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-12T01:08:20.020Z", "modifiedAt": null, "url": null, "title": "Personal Benefits from Rationality", "slug": "personal-benefits-from-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.710Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Celer", "createdAt": "2011-03-11T14:55:04.704Z", "isAdmin": false, "displayName": "Celer"}, "userId": "mHdDfFjPQrE6p94ud", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gJxiBnGuFLytyvhbe/personal-benefits-from-rationality", "pageUrlRelative": "/posts/gJxiBnGuFLytyvhbe/personal-benefits-from-rationality", "linkUrl": "https://www.lesswrong.com/posts/gJxiBnGuFLytyvhbe/personal-benefits-from-rationality", "postedAtFormatted": "Thursday, May 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Personal%20Benefits%20from%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APersonal%20Benefits%20from%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJxiBnGuFLytyvhbe%2Fpersonal-benefits-from-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Personal%20Benefits%20from%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJxiBnGuFLytyvhbe%2Fpersonal-benefits-from-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJxiBnGuFLytyvhbe%2Fpersonal-benefits-from-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 277, "htmlBody": "<p>I saw <a title=\"Building Rationalist Communities\" href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">this</a> and realised something:</p>\n<p>\"Hey, wait, where have I seen other people talk about specific benefits from Rationality?\"</p>\n<p>And then I realised I hadn't. I look around the site some. Nothing there.</p>\n<p>This is a place to fix that. The idea of this page is to post specific things that you personally have found helpful, that you learned from your studies of Bayescraft. This way we can find some that seem to work for a large number of people, so that when new people start to become interested in Rationality we can \"make it rain\" so that they see the benefits that come with being less wrong.</p>\n<p>For commenters:</p>\n<p>If someone posted something already that also worked for you, mention that. If every tactic is apparently used by only a single person, then it is harder for us as a community to figure out what we should recommend to tyros.&nbsp;</p>\n<p>List of N Things:</p>\n<p>&nbsp;</p>\n<p>Understanding that my high school history class has more to do with real science than does my Chemistry class let me understand how I should be approaching the problem. History lets you look at what happened and say \"Why did this happen\" when you view it the right way.</p>\n<p>Reading up on cognitive neuroscience taught me that I could use the placebo affect on myself. I have missed one day of school due to illness in my life.</p>\n<p>Learning to not propose solutions for a minimum of five minutes, by the clock, has honestly been the most effective thing I have yet learned for personal application at Less Wrong.</p>\n<p>&nbsp;</p>\n<p>May we all share many useful things, for our own benefit and as a place to point tyros towards.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gJxiBnGuFLytyvhbe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 8, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "7342", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Zasc7RXAEosWLYf8E"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-12T03:38:21.206Z", "modifiedAt": null, "url": null, "title": "Designing Rationalist Projects", "slug": "designing-rationalist-projects", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:13.069Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/m38tS7dq8znk5rNjG/designing-rationalist-projects", "pageUrlRelative": "/posts/m38tS7dq8znk5rNjG/designing-rationalist-projects", "linkUrl": "https://www.lesswrong.com/posts/m38tS7dq8znk5rNjG/designing-rationalist-projects", "postedAtFormatted": "Thursday, May 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Designing%20Rationalist%20Projects&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADesigning%20Rationalist%20Projects%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm38tS7dq8znk5rNjG%2Fdesigning-rationalist-projects%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Designing%20Rationalist%20Projects%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm38tS7dq8znk5rNjG%2Fdesigning-rationalist-projects", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm38tS7dq8znk5rNjG%2Fdesigning-rationalist-projects", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1137, "htmlBody": "<p>Related to: <a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the/\">Lessons from Latter-day Saints</a>, <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">Building Rationalist Communities overview</a>, <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/\">Holy Books (Or Rationalist Sequences) Don't Implement Themselves</a></p>\n<p><strong>My thesis:</strong></p>\n<p><!-- /* Font Definitions */ @font-face {font-family:\"Times New Roman\"; panose-1:0 2 2 6 3 5 4 5 2 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:\"Courier New\"; panose-1:0 2 7 3 9 2 2 5 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:Wingdings; panose-1:0 5 2 1 2 1 8 4 8 7; mso-font-charset:2; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:0 0 256 0 -2147483648 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText {margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} span.MsoFootnoteReference {vertical-align:super;} table.MsoNormalTable {mso-style-parent:\"\"; font-size:10.0pt; font-family:\"Times New Roman\";} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:1532643161; mso-list-type:hybrid; mso-list-template-ids:-1246472920 243311300 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l0:level1 {mso-level-number-format:bullet; mso-level-text:-; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.25in; font-family:\"Times New Roman\"; mso-font-width:0%;} @list l0:level2 {mso-level-number-format:bullet; mso-level-text:o; mso-level-tab-stop:1.25in; mso-level-number-position:left; margin-left:1.25in; text-indent:-.25in; font-family:\"Courier New\";} @list l0:level3 {mso-level-number-format:bullet; mso-level-text:\uf0a7; mso-level-tab-stop:1.75in; mso-level-number-position:left; margin-left:1.75in; text-indent:-.25in; font-family:Wingdings;} @list l1 {mso-list-id:1911580563; mso-list-type:hybrid; mso-list-template-ids:1013196958 670996276 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l1:level1 {mso-level-start-at:0; mso-level-number-format:bullet; mso-level-text:\uf0b7; mso-level-tab-stop:42.0pt; mso-level-number-position:left; margin-left:42.0pt; text-indent:-24.0pt; font-family:Symbol; mso-font-width:0%;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --></p>\n<blockquote>\n<p class=\"MsoNormal\">It doesn&rsquo;t matter what ideas are conveyed on Less Wrong, or in LW meetings -- the subset that matters is what group members resolved to do. Discussion of these 'resolves', and people's experience doing them, is useful in creating an expectation that people level up their skills.</p>\n</blockquote>\n<p class=\"MsoNormal\">Intelligent discussion of ideas is always refreshing. But translating that into action is more difficult.</p>\n<p class=\"MsoNormal\">Our learned reflexes are <a href=\"http://wiki.lesswrong.com/wiki/Category:Biases\">deep</a>. They need to be overridden. How? <em>Practice</em><span style=\"font-style:normal\">. </span></p>\n<p class=\"MsoNormal\">One woman I taught in India, we&rsquo;ll call her Girija, was 35 years old, extremely intelligent and really wanted to change her life but had incredibly low levels of self-confidence. Every time we met Girija, we&rsquo;d have a really sharp discussion, followed by her pouring her heart out to us. It was the same every time, and though we enjoyed the visits, and the food she would feed us, she never seemed to be getting anywhere.</p>\n<p class=\"MsoNormal\">If she really wanted to fundamentally change her life, our weekly meetings weren&rsquo;t enough. (Similarly, weekly meetups are a good start, but if you really want to be learning rationality you should be practicing every day.)</p>\n<p class=\"MsoNormal\">We felt that if Girija spent some time every day with her 9 year old daughter and live-in boyfriend, reading the scriptures together, they would be happier. We explained this to her frequently, and she said she would start -- but she never did it.</p>\n<p class=\"MsoNormal\">One week, through cleverly calling Girija and chatting for 10 minutes every day, we got her to do it. After the week was over, we asked her how it went.</p>\n<p class=\"MsoNormal\">&ldquo;You know, it was really good,&rdquo; she said. &ldquo;Sandeep and I have been getting along a lot better this week because we did that.&rdquo;</p>\n<p class=\"MsoNormal\">It was like a light had turned on in her head. Because we followed up, she <em>did it</em><span style=\"font-style:normal\">, and was far more motivated to do more things afterwards.<a style=\"mso-footnote-id:ftn1\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[1]</span></span></a><span style=\"mso-spacerun: yes\">&nbsp; </span></span></p>\n<p class=\"MsoNormal\">Let me give two simple examples of goal, project, and follow-up.<a style=\"mso-footnote-id:ftn2\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[2]</span></span></a></p>\n<ul>\n<li><em>GOAL:</em><span style=\"font-style:normal\"> To become better at noticing <a href=\"http://wiki.lesswrong.com/wiki/Category:Fallacies\">logical fallacies</a> as they are being uttered</span></li>\n<li><em>PROJECT:</em><span style=\"font-style:normal\"> A certain Less Wrong group could watch a designated hour of C-SPAN -- or a soap opera, or a TV show -- and try to note down all the fallacies. </span></li>\n<li><em>FOLLOW-UP:</em><span style=\"font-style:normal\"> Discuss this on a designated thread. Afterwards, compile the arguments and link to the file, so that anyone in the LW community can repeat this on their own and check against your conclusions. Reflect communally at your next LW meeting.</span>&nbsp; </li>\n</ul>\n<ul>\n<li><em>GOAL:</em><span style=\"font-style:normal\"> To get into <a href=\"/lw/nu/taboo_your_words/\">less arguments</a> about definitions.</span></li>\n<li><em>PROJECT:</em><span style=\"font-style:normal\"> &ldquo;Ask, \"Can you give me a specific example of that?\" or \"Can you be more concrete?\" in everyday conversations.&rdquo; Make a challenging goal about how much you will do this &ndash; this is pretty low-hanging fruit.</span></li>\n<li><em>FOLLOW-UP:</em><span style=\"font-style:normal\"> Write instances in your journal. Share examples communally at your next LW meeting. </span></li>\n</ul>\n<p class=\"MsoNormal\">I came up with these in about five minutes. Having spent more time in the community than me, you will all be able to generate more and better possibilities.</p>\n<p class=\"MsoNormal\">Some points about Projects:</p>\n<ul>\n<li><a href=\"/lw/1xh/living_luminously/\">Here</a> <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">are</a> <a href=\"http://yudkowsky.net/rational/virtues\">some</a> <a href=\"http://www.math.utah.edu/~pa/math/polya.html\">ideas</a> <a href=\"http://personalmba.com/49-questions-better-results/\">that</a> <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">can</a> <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">easily</a> <a href=\"http://www.paulgraham.com/identity.html\">be</a> <a href=\"/lw/4e/cached_selves/\">made</a> <a href=\"/user/jschulter/\">into</a> Projects. Thanks <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/44xf\">commenters</a> <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/4558\">on</a> the last post. </li>\n<li>Projects don't have to be group-based, but groups motivate doing stuff. </li>\n<li>Projects should be more short than the above linked posts. The above Goal/Project/Follow-Up kernels are 85 and 57 words, respectively. Brevity is key to implementation.</li>\n<li>There is currently no central database of Rationality Projects or people's experiences trying to implement them. (Correct me if I'm wrong here.)</li>\n<li>Feedback on implementation is essential for improving practices. </li>\n</ul>\n<p class=\"MsoNormal\">Finally, a really 'low-cost' way to make a project and follow up. Right before the conclusion of a Less Wrong group, give everyone a slip of paper and ask them to write down one thing they are going to do differently next week as a result of the discussion. For two minutes (total) at the beginning of the next meeting, let people tell what they did.</p>\n<p class=\"MsoNormal\"><strong>Some notes and warnings:</strong></p>\n<p class=\"MsoNormal\">Doing this in a <em>fraternalistic </em><span style=\"font-style:normal\">manner, not a </span><em>paternalistic</em><span style=\"font-style:normal\"> manner, will be a key to success.<a style=\"mso-footnote-id: ftn3\" name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[3]</span></span></a> Community agreement that We Should Do This is important before launching a Project.</span></p>\n<p class=\"MsoNormal\">Beware of the following tradeoff:</p>\n<ul>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;</span></span>implementing Projects will alienate some people. Even if projects are determined by consensus, there will be some people who don&rsquo;t want to do any Project, and they will feel marginalized and excluded.</li>\n<li>not implementing Projects, people will improve their Rationality skills at a far slower pace. <a name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span>[4]</span></span></a> You will thus run afoul of Bhagwat&rsquo;s Law of Commitment: &ldquo;The degree to which people identify with your group is directly proportional to the amount of stuff you tell them to do that works.\" But ultimately, commitment drives growth. More leadership to organize stuff, more people bringing friends, and so on.</li>\n</ul>\n<p class=\"MsoNormal\">I will discuss this more later, along with possible solutions. Latter-day Saints, with a large emphasis on doing things, have high levels of commitment; however, there are definitely people who would come to church more if they were expected to do less.</p>\n<p class=\"MsoNormal\">Please post any ideas you have for Projects in the comments.</p>\n<div style=\"mso-element:footnote-list\">\n<hr size=\"1\" />\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> Even subtracting the religious element, common goals reduce conflict.</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn2\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a> Here are some keys to following up that I learned. In two years, I probably applied this on about 600 people:</p>\n<ul>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;</span></span>Following up is mere nagging (and equally ineffective) unless the person/group actually wanted to do the task in the first place.</li>\n<li>Congratulating people when they&nbsp; <em>did&nbsp;</em><span style=\"font-style:normal\"> do something was far more important than expressing disappointment when they </span><em>didn&rsquo;t</em><span style=\"font-style:normal\"> do it &ndash; the 80/20 rule applies.</span></li>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\"> </span></span>I often felt afraid to ask someone if they had done what they promised to do, because they probably hadn&rsquo;t, and I didn&rsquo;t know what I should say then.</li>\n<li>But awkwardness is contagious; if you act awkward when talking to someone, the other person will feel awkward too. Be genuinely excited, and they will also reflect this.<span style=\"mso-spacerun: yes\">&nbsp; </span></li>\n<li>It&rsquo;s all about how you ask the question. &ldquo;How did you like reading X?&rdquo; is far better than &ldquo;Did you read X?&rdquo;. Use humor and make the task seem easy to do.</li>\n<li>Don&rsquo;t be self-righteous; actively deprecate yourself if necessary.</li>\n<li>Each person has different ways they like &ndash; and don&rsquo;t like &ndash; being followed-up with.</li>\n</ul>\n</div>\n<div id=\"ftn3\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn3\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> Coming from my experience as a Latter-day Saint missionary, my personal examples are all fairly paternalistic. With tweaks, they can all be made fraternalistic. The sentiment has been&nbsp; <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/4521\">expressed</a>&nbsp; that &ldquo;I don&rsquo;t like people telling me what to do&rdquo;; this will avoid that pitfall.<span style=\"mso-spacerun: yes\">&nbsp;&nbsp; </span></p>\n<p class=\"MsoFootnoteText\"><a name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span>[4]</span></span></a> I say 'far slower' based on my missionary experience. When people were dedicated to specific projects, they seemed to improve a lot faster.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "7ow6EFpypbH4hzFuz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "m38tS7dq8znk5rNjG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 51, "baseScore": 41, "extendedScore": null, "score": 7.135637823754823e-07, "legacy": true, "legacyId": "7345", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Related to: <a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the/\">Lessons from Latter-day Saints</a>, <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">Building Rationalist Communities overview</a>, <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/\">Holy Books (Or Rationalist Sequences) Don't Implement Themselves</a></p>\n<p><strong id=\"My_thesis_\">My thesis:</strong></p>\n<p><!-- /* Font Definitions */ @font-face {font-family:\"Times New Roman\"; panose-1:0 2 2 6 3 5 4 5 2 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:\"Courier New\"; panose-1:0 2 7 3 9 2 2 5 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:50331648 0 0 0 1 0;} @font-face {font-family:Wingdings; panose-1:0 5 2 1 2 1 8 4 8 7; mso-font-charset:2; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:0 0 256 0 -2147483648 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText {margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\";} span.MsoFootnoteReference {vertical-align:super;} table.MsoNormalTable {mso-style-parent:\"\"; font-size:10.0pt; font-family:\"Times New Roman\";} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:1532643161; mso-list-type:hybrid; mso-list-template-ids:-1246472920 243311300 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l0:level1 {mso-level-number-format:bullet; mso-level-text:-; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.25in; font-family:\"Times New Roman\"; mso-font-width:0%;} @list l0:level2 {mso-level-number-format:bullet; mso-level-text:o; mso-level-tab-stop:1.25in; mso-level-number-position:left; margin-left:1.25in; text-indent:-.25in; font-family:\"Courier New\";} @list l0:level3 {mso-level-number-format:bullet; mso-level-text:\uf0a7; mso-level-tab-stop:1.75in; mso-level-number-position:left; margin-left:1.75in; text-indent:-.25in; font-family:Wingdings;} @list l1 {mso-list-id:1911580563; mso-list-type:hybrid; mso-list-template-ids:1013196958 670996276 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;} @list l1:level1 {mso-level-start-at:0; mso-level-number-format:bullet; mso-level-text:\uf0b7; mso-level-tab-stop:42.0pt; mso-level-number-position:left; margin-left:42.0pt; text-indent:-24.0pt; font-family:Symbol; mso-font-width:0%;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --></p>\n<blockquote>\n<p class=\"MsoNormal\">It doesn\u2019t matter what ideas are conveyed on Less Wrong, or in LW meetings -- the subset that matters is what group members resolved to do. Discussion of these 'resolves', and people's experience doing them, is useful in creating an expectation that people level up their skills.</p>\n</blockquote>\n<p class=\"MsoNormal\">Intelligent discussion of ideas is always refreshing. But translating that into action is more difficult.</p>\n<p class=\"MsoNormal\">Our learned reflexes are <a href=\"http://wiki.lesswrong.com/wiki/Category:Biases\">deep</a>. They need to be overridden. How? <em>Practice</em><span style=\"font-style:normal\">. </span></p>\n<p class=\"MsoNormal\">One woman I taught in India, we\u2019ll call her Girija, was 35 years old, extremely intelligent and really wanted to change her life but had incredibly low levels of self-confidence. Every time we met Girija, we\u2019d have a really sharp discussion, followed by her pouring her heart out to us. It was the same every time, and though we enjoyed the visits, and the food she would feed us, she never seemed to be getting anywhere.</p>\n<p class=\"MsoNormal\">If she really wanted to fundamentally change her life, our weekly meetings weren\u2019t enough. (Similarly, weekly meetups are a good start, but if you really want to be learning rationality you should be practicing every day.)</p>\n<p class=\"MsoNormal\">We felt that if Girija spent some time every day with her 9 year old daughter and live-in boyfriend, reading the scriptures together, they would be happier. We explained this to her frequently, and she said she would start -- but she never did it.</p>\n<p class=\"MsoNormal\">One week, through cleverly calling Girija and chatting for 10 minutes every day, we got her to do it. After the week was over, we asked her how it went.</p>\n<p class=\"MsoNormal\">\u201cYou know, it was really good,\u201d she said. \u201cSandeep and I have been getting along a lot better this week because we did that.\u201d</p>\n<p class=\"MsoNormal\">It was like a light had turned on in her head. Because we followed up, she <em>did it</em><span style=\"font-style:normal\">, and was far more motivated to do more things afterwards.<a style=\"mso-footnote-id:ftn1\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[1]</span></span></a><span style=\"mso-spacerun: yes\">&nbsp; </span></span></p>\n<p class=\"MsoNormal\">Let me give two simple examples of goal, project, and follow-up.<a style=\"mso-footnote-id:ftn2\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[2]</span></span></a></p>\n<ul>\n<li><em>GOAL:</em><span style=\"font-style:normal\"> To become better at noticing <a href=\"http://wiki.lesswrong.com/wiki/Category:Fallacies\">logical fallacies</a> as they are being uttered</span></li>\n<li><em>PROJECT:</em><span style=\"font-style:normal\"> A certain Less Wrong group could watch a designated hour of C-SPAN -- or a soap opera, or a TV show -- and try to note down all the fallacies. </span></li>\n<li><em>FOLLOW-UP:</em><span style=\"font-style:normal\"> Discuss this on a designated thread. Afterwards, compile the arguments and link to the file, so that anyone in the LW community can repeat this on their own and check against your conclusions. Reflect communally at your next LW meeting.</span>&nbsp; </li>\n</ul>\n<ul>\n<li><em>GOAL:</em><span style=\"font-style:normal\"> To get into <a href=\"/lw/nu/taboo_your_words/\">less arguments</a> about definitions.</span></li>\n<li><em>PROJECT:</em><span style=\"font-style:normal\"> \u201cAsk, \"Can you give me a specific example of that?\" or \"Can you be more concrete?\" in everyday conversations.\u201d Make a challenging goal about how much you will do this \u2013 this is pretty low-hanging fruit.</span></li>\n<li><em>FOLLOW-UP:</em><span style=\"font-style:normal\"> Write instances in your journal. Share examples communally at your next LW meeting. </span></li>\n</ul>\n<p class=\"MsoNormal\">I came up with these in about five minutes. Having spent more time in the community than me, you will all be able to generate more and better possibilities.</p>\n<p class=\"MsoNormal\">Some points about Projects:</p>\n<ul>\n<li><a href=\"/lw/1xh/living_luminously/\">Here</a> <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">are</a> <a href=\"http://yudkowsky.net/rational/virtues\">some</a> <a href=\"http://www.math.utah.edu/~pa/math/polya.html\">ideas</a> <a href=\"http://personalmba.com/49-questions-better-results/\">that</a> <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">can</a> <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">easily</a> <a href=\"http://www.paulgraham.com/identity.html\">be</a> <a href=\"/lw/4e/cached_selves/\">made</a> <a href=\"/user/jschulter/\">into</a> Projects. Thanks <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/44xf\">commenters</a> <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/4558\">on</a> the last post. </li>\n<li>Projects don't have to be group-based, but groups motivate doing stuff. </li>\n<li>Projects should be more short than the above linked posts. The above Goal/Project/Follow-Up kernels are 85 and 57 words, respectively. Brevity is key to implementation.</li>\n<li>There is currently no central database of Rationality Projects or people's experiences trying to implement them. (Correct me if I'm wrong here.)</li>\n<li>Feedback on implementation is essential for improving practices. </li>\n</ul>\n<p class=\"MsoNormal\">Finally, a really 'low-cost' way to make a project and follow up. Right before the conclusion of a Less Wrong group, give everyone a slip of paper and ask them to write down one thing they are going to do differently next week as a result of the discussion. For two minutes (total) at the beginning of the next meeting, let people tell what they did.</p>\n<p class=\"MsoNormal\"><strong id=\"Some_notes_and_warnings_\">Some notes and warnings:</strong></p>\n<p class=\"MsoNormal\">Doing this in a <em>fraternalistic </em><span style=\"font-style:normal\">manner, not a </span><em>paternalistic</em><span style=\"font-style:normal\"> manner, will be a key to success.<a style=\"mso-footnote-id: ftn3\" name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character:footnote\">[3]</span></span></a> Community agreement that We Should Do This is important before launching a Project.</span></p>\n<p class=\"MsoNormal\">Beware of the following tradeoff:</p>\n<ul>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;</span></span>implementing Projects will alienate some people. Even if projects are determined by consensus, there will be some people who don\u2019t want to do any Project, and they will feel marginalized and excluded.</li>\n<li>not implementing Projects, people will improve their Rationality skills at a far slower pace. <a name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span>[4]</span></span></a> You will thus run afoul of Bhagwat\u2019s Law of Commitment: \u201cThe degree to which people identify with your group is directly proportional to the amount of stuff you tell them to do that works.\" But ultimately, commitment drives growth. More leadership to organize stuff, more people bringing friends, and so on.</li>\n</ul>\n<p class=\"MsoNormal\">I will discuss this more later, along with possible solutions. Latter-day Saints, with a large emphasis on doing things, have high levels of commitment; however, there are definitely people who would come to church more if they were expected to do less.</p>\n<p class=\"MsoNormal\">Please post any ideas you have for Projects in the comments.</p>\n<div style=\"mso-element:footnote-list\">\n<hr size=\"1\">\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> Even subtracting the religious element, common goals reduce conflict.</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element:footnote\">\n<p class=\"MsoNormal\"><a style=\"mso-footnote-id:ftn2\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[2]</span></span></a> Here are some keys to following up that I learned. In two years, I probably applied this on about 600 people:</p>\n<ul>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;</span></span>Following up is mere nagging (and equally ineffective) unless the person/group actually wanted to do the task in the first place.</li>\n<li>Congratulating people when they&nbsp; <em>did&nbsp;</em><span style=\"font-style:normal\"> do something was far more important than expressing disappointment when they </span><em>didn\u2019t</em><span style=\"font-style:normal\"> do it \u2013 the 80/20 rule applies.</span></li>\n<li><span style=\"mso-font-width:0%\"><span style=\"font:7.0pt &quot;Times New Roman&quot;\"> </span></span>I often felt afraid to ask someone if they had done what they promised to do, because they probably hadn\u2019t, and I didn\u2019t know what I should say then.</li>\n<li>But awkwardness is contagious; if you act awkward when talking to someone, the other person will feel awkward too. Be genuinely excited, and they will also reflect this.<span style=\"mso-spacerun: yes\">&nbsp; </span></li>\n<li>It\u2019s all about how you ask the question. \u201cHow did you like reading X?\u201d is far better than \u201cDid you read X?\u201d. Use humor and make the task seem easy to do.</li>\n<li>Don\u2019t be self-righteous; actively deprecate yourself if necessary.</li>\n<li>Each person has different ways they like \u2013 and don\u2019t like \u2013 being followed-up with.</li>\n</ul>\n</div>\n<div id=\"ftn3\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn3\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[3]</span></span></a> Coming from my experience as a Latter-day Saint missionary, my personal examples are all fairly paternalistic. With tweaks, they can all be made fraternalistic. The sentiment has been&nbsp; <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/4521\">expressed</a>&nbsp; that \u201cI don\u2019t like people telling me what to do\u201d; this will avoid that pitfall.<span style=\"mso-spacerun: yes\">&nbsp;&nbsp; </span></p>\n<p class=\"MsoFootnoteText\"><a name=\"_ftnref3\" href=\"#_ftn3\"><span class=\"MsoFootnoteReference\"><span>[4]</span></span></a> I say 'far slower' based on my missionary experience. When people were dedicated to specific projects, they seemed to improve a lot faster.</p>\n</div>\n</div>", "sections": [{"title": "My thesis:", "anchor": "My_thesis_", "level": 1}, {"title": "Some notes and warnings:", "anchor": "Some_notes_and_warnings_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "81 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 81, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["su7bXsXYpY55vwphc", "Zasc7RXAEosWLYf8E", "4CW68uEwgWuLfBenZ", "WBdvyyHLdxZSAMmoz", "9o3Cjjem7AbmmZfBs", "33KewgYhNSxFpbpXg", "FaJaCgqBKphrDzDSj", "BHYBdijDcAKQ6e45Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-12T10:27:09.829Z", "modifiedAt": null, "url": null, "title": "You'll die if you do that", "slug": "you-ll-die-if-you-do-that", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.059Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2PPdPrC7dQDp5oz3T/you-ll-die-if-you-do-that", "pageUrlRelative": "/posts/2PPdPrC7dQDp5oz3T/you-ll-die-if-you-do-that", "linkUrl": "https://www.lesswrong.com/posts/2PPdPrC7dQDp5oz3T/you-ll-die-if-you-do-that", "postedAtFormatted": "Thursday, May 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20You'll%20die%20if%20you%20do%20that&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYou'll%20die%20if%20you%20do%20that%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2PPdPrC7dQDp5oz3T%2Fyou-ll-die-if-you-do-that%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=You'll%20die%20if%20you%20do%20that%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2PPdPrC7dQDp5oz3T%2Fyou-ll-die-if-you-do-that", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2PPdPrC7dQDp5oz3T%2Fyou-ll-die-if-you-do-that", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 347, "htmlBody": "<p>\n<blockquote>\n<p>\"They told me that if I ever turned this flashlight on, I would <em>die!</em> They told me that about <em>everything!</em>&nbsp;I mean, I don't even know why they bothered giving me this stuff if they didn't want me to use it.\"</p>\n<p>-- Wheatley, <em>Portal 2</em></p>\n</blockquote>\n<p>Today I received some shoes in the post, which included a couple of packets of silica gel. I don't think I have ever seen a packet of silica gel that didn't have \"DO NOT EAT\" printed on it, and it's always bemused me. &nbsp;It doesn't look edible, or smell appetising, and isn't even especially harmful to ingest in most circumstances. &nbsp;Chances are that if I ever did want to eat silica gel, I'd probably have a damn good reason, and a lifetime of being told to not eat it is an obstacle to that.</p>\n</p>\n<p>This has started me thinking about all the other things we internalise as serious hazards contrary to reality. &nbsp;As a child, I was told that picking my nose and eating it would have some sort of cumulative toxic effect. &nbsp;This was obviously a lie manufactured by my parents (or maybe their parents) to get me to stop doing it, but a couple of decades later I felt positively scandalised when I read about an Austrian pathologist who claimed the practise was beneficial to the immune system. &nbsp;(Although this is mentioned in the delightful <a href=\"http://en.wikipedia.org/wiki/Nose-picking\">Wikipedia page on nose-picking</a>, the reference links are dead, so I'd actually treat this assertion with caution, but feel free to munch away on your own dried nasal mucus anyway).</p>\n<p>\n<p>Although nose-picking and eating the packaging that shoes come in are pretty trivial examples, I do wonder how many of these prohibitive false dire consequences I'm still labouring under, invisibly making my life more difficult. &nbsp;I also wonder how many full-grown adults still don't accept sweets from strangers.</p>\n<p>Do you have any examples of an authority figure, or a prevailing piece of cultural conditioning, giving warnings of dire outcomes you later discovered to be false, misleading or based on an agenda you were naive to at the time?</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2PPdPrC7dQDp5oz3T", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 22, "extendedScore": null, "score": 7.136819998476781e-07, "legacy": true, "legacyId": "7350", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 74, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-12T14:59:41.657Z", "modifiedAt": null, "url": null, "title": "The elephant in the room, AMA", "slug": "the-elephant-in-the-room-ama", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:28.987Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/E9QGXnFKcNQy4ZiNz/the-elephant-in-the-room-ama", "pageUrlRelative": "/posts/E9QGXnFKcNQy4ZiNz/the-elephant-in-the-room-ama", "linkUrl": "https://www.lesswrong.com/posts/E9QGXnFKcNQy4ZiNz/the-elephant-in-the-room-ama", "postedAtFormatted": "Thursday, May 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20elephant%20in%20the%20room%2C%20AMA&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20elephant%20in%20the%20room%2C%20AMA%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE9QGXnFKcNQy4ZiNz%2Fthe-elephant-in-the-room-ama%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20elephant%20in%20the%20room%2C%20AMA%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE9QGXnFKcNQy4ZiNz%2Fthe-elephant-in-the-room-ama", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE9QGXnFKcNQy4ZiNz%2Fthe-elephant-in-the-room-ama", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 773, "htmlBody": "<p>Hello fellow Less Wrongians!</p>\n<p>Given your comments on <a href=\"/lw/5lm/how_to_build_rationalist_communities/\">my</a> <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">organizing</a> <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/\">communities</a> <a href=\"/lw/5o1/designing_rationalist_projects/\">series</a>, I get the feeling that many of you are wondering why:</p>\n<ul>\n<li>a returned Mormon missionary would even come to Less Wrong in the first place.</li>\n<li>why I find religion plausible at all</li>\n<li>why I would identify with Mormonism in particular (several people have used the word 'cult') </li>\n</ul>\n<p>I'm happy to hold discussions about any of these questions or related ones. However, I haven't responded to many comments on the main series of posts because:</p>\n<ul>\n<li>they could eat up each thread</li>\n<li>the threads aren't supposed to be about Mormonism. They're supposed to be about about making a movement work effectively. But being a missionary is where I got my experience.</li>\n</ul>\n<p>I wanted to created this thread as a center for questions you might have about my faith.<strong> This is not an attempt to preach</strong> -- I would be perfectly happy not having a discussion purely about religion at all. But since there seem to be many comments, well, fire away.</p>\n<p><em>Some basic facts: </em>I am a student at Stanford. I am 22. I converted to Mormonism when I was 19. I used to be atheist/agnostic. I am very much a believer, not just in it for the social perks.</p>\n<p>Well, as it is written, AMA (= Ask Me Anything)</p>\n<p>(Thanks <a href=\"/user/Kevin/\">Kevin</a> for the suggestion.)</p>\n<p><em>Edit: Wow, there are a lot of comments. This has been a helpful chance to clarify my thinking. I hope you have learned something useful -- perhaps using the question is 'Is there anything surprising here that he said?'.</em><br /><em></em></p>\n<p><em>Edit 2: Here are some answers to repeated questions. Again, this really helped me distill and clarify myself and I've enjoyed the discussion. <br /></em></p>\n<p><em><strong>Why do you believe?</strong> </em>It's a combination of</p>\n<ul>\n<li>\"wow<em>, </em>this seems to be a really functional community in producing good people.\"&nbsp;</li>\n<li>\"wow, these doctrines are really amazing.\"<a name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"font-size: 11pt; font-family: Times-Roman;\"><span>[1]</span></span></span></a> </li>\n</ul>\n<ul>\n<li>personal spiritual experiences (experiences-which-I-interpret as spiritual if you prefer) and other positive experiences from doing church things, like emotional growth from going on a mission.</li>\n</ul>\n<p>I would estimate that before this all happened, my odds ratio was about 2000:1, and now it's about 1:10. I would ballpark the odds ratios of each of the above 3 events as ~12.5:1, ~25:1, and ~62.5:1. (I was considering likelihood but didn't think in that precise of terms at the time, so any concretization is open to charges of <em>ex post facto</em>. And these are still ballparks.)</p>\n<p>There are lots of arguments against Mormonism on factual and historical grounds; there are also counterarguments which I feel pretty much balance them out. (The feeling of balancing each other out was contemporaneous.)</p>\n<p><strong>What things could make you consider leaving the faith?</strong></p>\n<ul>\n<li>Undermining any of the above: negative experiences from doing church things, better arguments against Mormonism, the church repudiating the doctrines I love, experiencing it as much less functional, etc. &nbsp; </li>\n</ul>\n<p><strong> Why do you think your conversion story is disappointing to many of us?</strong></p>\n<p>Several possible reasons:</p>\n<ul>\n<li>You might have been looking for a more rationalist narrative.&nbsp;</li>\n<li>Your priors are like (say) 100,000:1 on this. So maybe something I say sounds plausible (1:2). But you're still at 50,000:1 and extremely skeptical.</li>\n<li>It took a lot of experiences and arguments to persuade me; this is just the tip of the iceberg.</li>\n<li>A lot of my conversion was experiential. An analogy would be that I ate a certain fruit which others haven't. We are discussing descriptions of the fruit; the only way to be truly convinced (or unconvinced) would be to taste it.&nbsp; <a name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"font-size: 11pt; font-family: Times-Roman;\"><span>[2]</span></span></span></a></li>\n</ul>\n<div style=\"mso-element:footnote-list\">\n<div>\n<hr size=\"1\" />\n<div id=\"ftn1\">\n<p class=\"MsoFootnoteText\"><a name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span>[1]</span></span></a> Specifically:</p>\n</div>\n</div>\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<ul>\n<li>I felt the doctrines were coherent both with my experience of the world -- for example, how faith is introduced as an experiment and described empirically. </li>\n<li>I felt they offered solutions to central human problems like the feeling of aloneness; the sometimes-destructive yet still necessary nature of guilt. </li>\n<li>Finally, certain doctrines, like the \"weeping God of Mormonism\" or deification, struck me with a reaction which I can only describe as \"it tasted good.\" I felt something like, \"if there is a God, it just makes sense he would be this.</li>\n</ul>\n<div><a name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span>[2]</span></span></a> Difficulty of adequately conveying strong emotional experiences to someone who hasn't had them is general, right? For a parent, try to imagine explaining the feelings you had from holding your infant in your arms the first time. Or someone else, try explaining the strength of arousal feelings to a pre-pubescent who is like \"ew, gross.\" Just because it's really difficult to describe it doesn't mean it didn't happen.</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "7ow6EFpypbH4hzFuz": 1, "YgizoZqa7LEb3LEJn": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "E9QGXnFKcNQy4ZiNz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 48, "baseScore": 30, "extendedScore": null, "score": 6.6e-05, "legacy": true, "legacyId": "7352", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Hello fellow Less Wrongians!</p>\n<p>Given your comments on <a href=\"/lw/5lm/how_to_build_rationalist_communities/\">my</a> <a href=\"/lw/5ln/building_rationalist_communities_a_series_overview/\">organizing</a> <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/\">communities</a> <a href=\"/lw/5o1/designing_rationalist_projects/\">series</a>, I get the feeling that many of you are wondering why:</p>\n<ul>\n<li>a returned Mormon missionary would even come to Less Wrong in the first place.</li>\n<li>why I find religion plausible at all</li>\n<li>why I would identify with Mormonism in particular (several people have used the word 'cult') </li>\n</ul>\n<p>I'm happy to hold discussions about any of these questions or related ones. However, I haven't responded to many comments on the main series of posts because:</p>\n<ul>\n<li>they could eat up each thread</li>\n<li>the threads aren't supposed to be about Mormonism. They're supposed to be about about making a movement work effectively. But being a missionary is where I got my experience.</li>\n</ul>\n<p>I wanted to created this thread as a center for questions you might have about my faith.<strong> This is not an attempt to preach</strong> -- I would be perfectly happy not having a discussion purely about religion at all. But since there seem to be many comments, well, fire away.</p>\n<p><em>Some basic facts: </em>I am a student at Stanford. I am 22. I converted to Mormonism when I was 19. I used to be atheist/agnostic. I am very much a believer, not just in it for the social perks.</p>\n<p>Well, as it is written, AMA (= Ask Me Anything)</p>\n<p>(Thanks <a href=\"/user/Kevin/\">Kevin</a> for the suggestion.)</p>\n<p><em>Edit: Wow, there are a lot of comments. This has been a helpful chance to clarify my thinking. I hope you have learned something useful -- perhaps using the question is 'Is there anything surprising here that he said?'.</em><br><em></em></p>\n<p><em>Edit 2: Here are some answers to repeated questions. Again, this really helped me distill and clarify myself and I've enjoyed the discussion. <br></em></p>\n<p><em><strong>Why do you believe?</strong> </em>It's a combination of</p>\n<ul>\n<li>\"wow<em>, </em>this seems to be a really functional community in producing good people.\"&nbsp;</li>\n<li>\"wow, these doctrines are really amazing.\"<a name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"font-size: 11pt; font-family: Times-Roman;\"><span>[1]</span></span></span></a> </li>\n</ul>\n<ul>\n<li>personal spiritual experiences (experiences-which-I-interpret as spiritual if you prefer) and other positive experiences from doing church things, like emotional growth from going on a mission.</li>\n</ul>\n<p>I would estimate that before this all happened, my odds ratio was about 2000:1, and now it's about 1:10. I would ballpark the odds ratios of each of the above 3 events as ~12.5:1, ~25:1, and ~62.5:1. (I was considering likelihood but didn't think in that precise of terms at the time, so any concretization is open to charges of <em>ex post facto</em>. And these are still ballparks.)</p>\n<p>There are lots of arguments against Mormonism on factual and historical grounds; there are also counterarguments which I feel pretty much balance them out. (The feeling of balancing each other out was contemporaneous.)</p>\n<p><strong id=\"What_things_could_make_you_consider_leaving_the_faith_\">What things could make you consider leaving the faith?</strong></p>\n<ul>\n<li>Undermining any of the above: negative experiences from doing church things, better arguments against Mormonism, the church repudiating the doctrines I love, experiencing it as much less functional, etc. &nbsp; </li>\n</ul>\n<p><strong id=\"Why_do_you_think_your_conversion_story_is_disappointing_to_many_of_us_\"> Why do you think your conversion story is disappointing to many of us?</strong></p>\n<p>Several possible reasons:</p>\n<ul>\n<li>You might have been looking for a more rationalist narrative.&nbsp;</li>\n<li>Your priors are like (say) 100,000:1 on this. So maybe something I say sounds plausible (1:2). But you're still at 50,000:1 and extremely skeptical.</li>\n<li>It took a lot of experiences and arguments to persuade me; this is just the tip of the iceberg.</li>\n<li>A lot of my conversion was experiential. An analogy would be that I ate a certain fruit which others haven't. We are discussing descriptions of the fruit; the only way to be truly convinced (or unconvinced) would be to taste it.&nbsp; <a name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"font-size: 11pt; font-family: Times-Roman;\"><span>[2]</span></span></span></a></li>\n</ul>\n<div style=\"mso-element:footnote-list\">\n<div>\n<hr size=\"1\">\n<div id=\"ftn1\">\n<p class=\"MsoFootnoteText\"><a name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span>[1]</span></span></a> Specifically:</p>\n</div>\n</div>\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<ul>\n<li>I felt the doctrines were coherent both with my experience of the world -- for example, how faith is introduced as an experiment and described empirically. </li>\n<li>I felt they offered solutions to central human problems like the feeling of aloneness; the sometimes-destructive yet still necessary nature of guilt. </li>\n<li>Finally, certain doctrines, like the \"weeping God of Mormonism\" or deification, struck me with a reaction which I can only describe as \"it tasted good.\" I felt something like, \"if there is a God, it just makes sense he would be this.</li>\n</ul>\n<div><a name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span>[2]</span></span></a> Difficulty of adequately conveying strong emotional experiences to someone who hasn't had them is general, right? For a parent, try to imagine explaining the feelings you had from holding your infant in your arms the first time. Or someone else, try explaining the strength of arousal feelings to a pre-pubescent who is like \"ew, gross.\" Just because it's really difficult to describe it doesn't mean it didn't happen.</div>\n</div>\n</div>", "sections": [{"title": "What things could make you consider leaving the faith?", "anchor": "What_things_could_make_you_consider_leaving_the_faith_", "level": 1}, {"title": "Why do you think your conversion story is disappointing to many of us?", "anchor": "Why_do_you_think_your_conversion_story_is_disappointing_to_many_of_us_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "432 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 432, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["su7bXsXYpY55vwphc", "Zasc7RXAEosWLYf8E", "4CW68uEwgWuLfBenZ", "m38tS7dq8znk5rNjG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-12T16:42:12.745Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Superstimuli and the Collapse of Western Civilization", "slug": "seq-rerun-superstimuli-and-the-collapse-of-western", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:02.194Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tyrrell_McAllister", "createdAt": "2009-03-05T19:59:57.157Z", "isAdmin": false, "displayName": "Tyrrell_McAllister"}, "userId": "HSANMQBsHiGrZzwTB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6ynNerF3HAWobehnP/seq-rerun-superstimuli-and-the-collapse-of-western", "pageUrlRelative": "/posts/6ynNerF3HAWobehnP/seq-rerun-superstimuli-and-the-collapse-of-western", "linkUrl": "https://www.lesswrong.com/posts/6ynNerF3HAWobehnP/seq-rerun-superstimuli-and-the-collapse-of-western", "postedAtFormatted": "Thursday, May 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Superstimuli%20and%20the%20Collapse%20of%20Western%20Civilization&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Superstimuli%20and%20the%20Collapse%20of%20Western%20Civilization%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6ynNerF3HAWobehnP%2Fseq-rerun-superstimuli-and-the-collapse-of-western%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Superstimuli%20and%20the%20Collapse%20of%20Western%20Civilization%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6ynNerF3HAWobehnP%2Fseq-rerun-superstimuli-and-the-collapse-of-western", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6ynNerF3HAWobehnP%2Fseq-rerun-superstimuli-and-the-collapse-of-western", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 248, "htmlBody": "<p>Today's post, <a href=\"/lw/h3/superstimuli_and_the_collapse_of_western/\">Superstimuli and the Collapse of Western Civilization</a>, was originally published on 16 March 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>\n<p>As a side effect of evolution, super-stimuli exist, and as a result of economics, are getting and should continue to get worse.</p>\n<p>(alternate summary:)</p>\n<p>At least 3 people have died by playing online games non-stop. How is it that a game is so enticing that after 57 straight hours playing, a person would rather spend the next hour playing the game over sleeping or eating? A candy bar is superstimulus, it corresponds overwhelmingly well to the EEA healthy food characteristics of sugar and fat. If people enjoy these things, the market will respond to provide as much of it as possible, even if other considerations make it undesirable.</p>\n</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/h2/blue_or_green_on_regulation/\">Blue or Green on Regulation?</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6ynNerF3HAWobehnP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "7353", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Jq73GozjsuhdwMLEG", "uaPc4NHi5jGXGQKFS", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T00:19:14.885Z", "modifiedAt": null, "url": null, "title": "Young Cryonicists Conference 2011", "slug": "young-cryonicists-conference-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.271Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alex_Altair", "createdAt": "2010-07-21T18:30:40.806Z", "isAdmin": false, "displayName": "Alex_Altair"}, "userId": "5wu9jG4pm9q6xjZ9R", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RABNzhGkrvav527nF/young-cryonicists-conference-2011", "pageUrlRelative": "/posts/RABNzhGkrvav527nF/young-cryonicists-conference-2011", "linkUrl": "https://www.lesswrong.com/posts/RABNzhGkrvav527nF/young-cryonicists-conference-2011", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Young%20Cryonicists%20Conference%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYoung%20Cryonicists%20Conference%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRABNzhGkrvav527nF%2Fyoung-cryonicists-conference-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Young%20Cryonicists%20Conference%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRABNzhGkrvav527nF%2Fyoung-cryonicists-conference-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRABNzhGkrvav527nF%2Fyoung-cryonicists-conference-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 80, "htmlBody": "<p>Next week I'll be attending the second annual Young Cryonicists conference, which Eliezer attended before writing <a href=\"/lw/1mc/normal_cryonics/\">Normal Cryonics</a>. I expected there to be discussion about it on lesswrong, but there hasn't been, so here it is.</p>\n<ul>\n<li>Who else is going?&nbsp;Is EY going?&nbsp;</li>\n<li>What do you expect to get out of it?</li>\n<li>How can we use it to maximize winning?</li>\n</ul>\n<p>Reference;</p>\n<p><a href=\"http://www.cryonics.org/immortalist/november10/TT2.pdf\">The most official thing I can find about the conference.</a>&nbsp;(PDF)</p>\n<p><a href=\"/lw/1mc/normal_cryonics/\">Normal Cryonics</a>&nbsp;by Eliezer Yudkowsky on Less Wrong</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RABNzhGkrvav527nF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.139227243835762e-07, "legacy": true, "legacyId": "7355", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hiDkhLyN5S2MEjrSE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T02:13:39.781Z", "modifiedAt": null, "url": null, "title": "Rationality Exercise: My Little Pony", "slug": "rationality-exercise-my-little-pony", "viewCount": null, "lastCommentedAt": "2022-01-24T22:11:04.007Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "magfrump", "createdAt": "2009-12-10T20:51:45.065Z", "isAdmin": false, "displayName": "magfrump"}, "userId": "KsYFs5ip5jeiFETJa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9MuxP9bpCR3GJAPDu/rationality-exercise-my-little-pony", "pageUrlRelative": "/posts/9MuxP9bpCR3GJAPDu/rationality-exercise-my-little-pony", "linkUrl": "https://www.lesswrong.com/posts/9MuxP9bpCR3GJAPDu/rationality-exercise-my-little-pony", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Exercise%3A%20My%20Little%20Pony&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Exercise%3A%20My%20Little%20Pony%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9MuxP9bpCR3GJAPDu%2Frationality-exercise-my-little-pony%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Exercise%3A%20My%20Little%20Pony%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9MuxP9bpCR3GJAPDu%2Frationality-exercise-my-little-pony", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9MuxP9bpCR3GJAPDu%2Frationality-exercise-my-little-pony", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 356, "htmlBody": "<p>Recently I started watching My Little Pony: Friendship as Magic on the recommendation of numerous friends.&nbsp; It has been entertaining for the most part, but in episode 15, I hit a problem.</p>\n<p>The main character, Twilight Sparkle, is an avid intellectual, who is constantly reading and learning about the magic of the world.&nbsp; In episode 15, a friend of hers, Pinkie Pie, reveals a strange talent for divination:&nbsp; When something is about to fall, her tail twitches.&nbsp; Various other manifestations also exist, in excruciating detail.</p>\n<p>Twilight Sparkle is very unhappy with this \"unscientific\" state of affairs.&nbsp; She attempts (to my delight) to do Science to Pinkie Pie, however her attempts to do Science are frustratingly foiled; in large part because her experiments ignore the nature of the phenomenon.</p>\n<p>After watching and being frustrated by this episode, I decided that it would be more fun to come up with better experiments that would cut to the core of the issue and really investigate the subject.</p>\n<p>My first idea was, if Pinkie Pie's tail twitches when something falls, place Pinkie Pie in a room.&nbsp; In a room next to her, drop things, and have someone else record her responses and timing.</p>\n<p>Once you can reliably predict and cause tail twitches, try holding her tail still.&nbsp; See if, say, the rest of her body starts shaking, or the thing stops falling.&nbsp; See if the twitches return if she is asleep.&nbsp; See how far away you can make something fall and still get a reaction.</p>\n<p>The list could continue forever!&nbsp; What ideas do you have?&nbsp; You're welcome to seek out and watch the episode, and give experiments that would apply well to Pinkie Pie in particular, or just consider the idea that someone claims that their arm twitches noticeably when something is about to fall, and has used their twitchy arm to accurately predict several falling objects for you, in an uncontrolled setting.&nbsp; How would you Do Science to them (assuming their full cooperation)?</p>\n<p>EDIT: it occurred to me immediately after submitting that \"Experimental design\" would have been a better title beginning that \"Rationality exercise,\" but assuming the RSS issues are unresolved I will not change it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9MuxP9bpCR3GJAPDu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 19, "extendedScore": null, "score": 7.139558362120523e-07, "legacy": true, "legacyId": "7356", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T04:53:11.894Z", "modifiedAt": null, "url": null, "title": "Reference Classes in the Doomsday Argument", "slug": "reference-classes-in-the-doomsday-argument", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.318Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Caerbannog", "createdAt": "2011-04-30T02:54:30.643Z", "isAdmin": false, "displayName": "Caerbannog"}, "userId": "2AHG8DKQeWwxMCvK9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZMDXYGn4Q3x5KdNrW/reference-classes-in-the-doomsday-argument", "pageUrlRelative": "/posts/ZMDXYGn4Q3x5KdNrW/reference-classes-in-the-doomsday-argument", "linkUrl": "https://www.lesswrong.com/posts/ZMDXYGn4Q3x5KdNrW/reference-classes-in-the-doomsday-argument", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reference%20Classes%20in%20the%20Doomsday%20Argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReference%20Classes%20in%20the%20Doomsday%20Argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMDXYGn4Q3x5KdNrW%2Freference-classes-in-the-doomsday-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reference%20Classes%20in%20the%20Doomsday%20Argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMDXYGn4Q3x5KdNrW%2Freference-classes-in-the-doomsday-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMDXYGn4Q3x5KdNrW%2Freference-classes-in-the-doomsday-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1017, "htmlBody": "<p>I've seen the Doomsday Argument discussed here, and I wanted to address some aspects that I have difficulty accepting.<br /><br /><strong>Overview of Doomsday Argument</strong><br /><br />Nick Bostrom <a href=\"http://www.anthropic-principle.com/self-location.html\">introduces</a> the Doomsday Argument (DA) by asking you to imagine a universe of 100 numbered cubicles. You are told that a coin was flipped and one of the following happened:<br /><br />A) 100 people were created and placed individually in cubicles 1-100 (if the coin came up heads)<br />B) 10 people were created and placed individually in cubicles 1-10 (if the coin came up tails)<br /><br />Now, suppose you see that your own cubicle number (n) is 7, then you can deduce the relative likelihood of the above two scenarios by Bayesian reasoning:<br /><br />Suppose that there were 200 such universes starting at the coin flip and in the ideal case there are 100 heads and 100 tails:<br />p(n&lt;=10 | heads) = 10% (or 10 out of 100 such trials)<br />p(n&lt;=10 | tails) = 100% (or 100 out of 100 such trials)<br /><br />Relatively speaking, then, the likelihood that tails came up in this scenario is 100/(10+100) = 0.91 = 91%, even though the prior probability was equal for each outcome.<br /><br />The DA says that based on reasoning similar to the above, it is possible to assign upper and lower bounds to the total number of humans that will ever be born, using birth order in place of the cubicle number.<br /><br />For example (using my own math now), if human birth order is assigned randomly, then you have 95% confidence that your birth is within the middle 95% of all humans who will ever be born (i.e. between 2.5% and 97.5%). You can then calculate with 95% confidence the upper and lower bounds of the number of humans that will ever be born if you assume that your birth order is 100 billionth (this is close to the current consensus of approximately how many humans have ever been born):<br /><br />upper limit: 100 billion / 0.025 = 4 Trillion<br />lower limit: 100 billion / 0.975 = 102.6 Billion<br />therefore p(102.6 Billion &lt; Total Humans ever to be Born &lt; 4 Trillion) = 95%<br /><br />You can choose your desired confidence level and derive the upper and lower bounds accordingly.<br /><br />Alternatively, you can also choose to determine only the upper limit by saying that you have 95% confidence that you are not among the first 5% of humans born:<br /><br />upper limit: 100 billion / 0.05 = 2 Trillion<br />therefore p(Total Humans Born &lt; 2 Trillion) = 95%<br /><br /><strong>Discussion</strong><br /><br />The cubicle part of the argument is well-defined because there is a logical and discrete reference class of objects: A sequentially numbered group of cubicles wherein each item is equally likely (by definition) to be linked to the observer. In applying the DA to human births, you have to choose a reference class that is sequential and distributed such that each position in the sequence is equally likely to contain the observer. In his response to Korb and Oliver, Bostrom <a href=\"http://www.anthropic-principle.com/preprints/ali/alive.html\">admits</a> that:<br /><br /><span style=\"color: #339966;\">\"In my opinion, the problem of the reference class is still unsolved, and it is a serious one for the doomsayer.\"</span><br /><br />If you make the statement \"100 billion humans have been born thus far\" and then base your DA on it, I think you raise some important questions.<br /><br />At what point in our species' history is it appropriate to designate the starting point of \"human birth #1\"? Evolution works gradually, after all, and the concept of species is blurry. Were each of us equally likely to have been born as H. sapiens, H. neanderthalensis, Denisova, H. heidelbergensis, H. erectus, or some earlier form? If not, then why not? If yes, then the total number of births counted would increase dramatically and we still would lack a logical and discrete boundary.<br /><br />Possible responses to the above that I have seen discussed:<br /><br /><span style=\"color: #339966;\"><em>\"My chosen reference class contains only those individuals who would have been capable of understanding the DA in the first place.</em>\"</span><br /><br />Meaning what? That if the DA had been patiently explained to them in their native language at some point in their lives, they would have understood it? You might have been able to explain it to H. erectus if you spent enough time, or maybe not. Maybe H. neanderthalensis is a better candidate. How can you know for sure who would and wouldn't understand? How much education time is allowed? Thirty minutes, 1 day, several years of intensive study? Even then, you still don't have a logical and discrete cutoff to your reference class.<br /><br /><span style=\"color: #339966;\"><em>\"My chosen reference class contains only those individuals who have actually read and understood the DA.</em>\"</span><br /><br />This seems circular; If the DA turns out not to remain a popular idea, the only doom it is predicting is its own. Even if it becomes so popular that almost everyone reads and understands it two centuries from now, then it's still only predicting its own memetic fitness (which may not correlate with the prosperity of humanity as we know it). Is there a useful reason for picking this as a reference class instead of \"People who are Mormons\" or \"People who skateboard\"?<br /><br /><strong>Summary or tl;dr</strong><br /><br />The choice of reference class is a big part of the DA, perhaps the most important part, and it's been hand-waved away or completely ignored in the discussions I have seen. It's all neat and well-behaved when you're talking about sequential cubicles or numbered balls in urns, but without a good way to assign a reference class, I think the argument is weak at best. I would be interested to hear creative ideas for useful and well-bounded reference classes if you have them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZMDXYGn4Q3x5KdNrW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "7357", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T15:51:21.628Z", "modifiedAt": null, "url": null, "title": "Ask LessWrong: Design a degree in Rationality.", "slug": "ask-lesswrong-design-a-degree-in-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:05.336Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qMZLkQn2PqNHEuXZh/ask-lesswrong-design-a-degree-in-rationality", "pageUrlRelative": "/posts/qMZLkQn2PqNHEuXZh/ask-lesswrong-design-a-degree-in-rationality", "linkUrl": "https://www.lesswrong.com/posts/qMZLkQn2PqNHEuXZh/ask-lesswrong-design-a-degree-in-rationality", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ask%20LessWrong%3A%20Design%20a%20degree%20in%20Rationality.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAsk%20LessWrong%3A%20Design%20a%20degree%20in%20Rationality.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMZLkQn2PqNHEuXZh%2Fask-lesswrong-design-a-degree-in-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ask%20LessWrong%3A%20Design%20a%20degree%20in%20Rationality.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMZLkQn2PqNHEuXZh%2Fask-lesswrong-design-a-degree-in-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMZLkQn2PqNHEuXZh%2Fask-lesswrong-design-a-degree-in-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 193, "htmlBody": "<p>You are a tenured professor at a medium-sized public university. The Interdisciplinary Gods have smiled upon you, and you have been handed an operating grant, office space, and broad design powers to create an advanced interdisciplinary degree<sup>1</sup> in \"Rationality\" (you suspect your department head reads LessWrong). Your students will come from a broad range of disciplines, and you cannot assume that they will posses any particular prior knowledge.</p>\n<p>Candidates in your program could take courses in any department, as long as you have personally approved a course as eligible for credits. [ETA] All admitted students will be awarded tuition wavers and living wages. A compelling ROI calculation was a requirement for admission, and all students have demonstrated some impressive real-world accomplishments.</p>\n<p>You thumb through <a href=\"http://ocw.mit.edu/courses/\">your University's course register</a><sup>2</sup>, seeing a long list of courses in a variety of disciplines: Anthropology to Writing and Humanistic Studies. Without some constraints, you think, this degree will be incoherent.</p>\n<p>Which do you include?</p>\n<p><a id=\"more\"></a>[1] To avoid tangential conversation, don't worry about what sort of degree. This could be the course load for a PhD/MBA/MA/etc.</p>\n<p>[2] If it helps you think this through, use the MIT OCW listings to make suggestions. HT: <a href=\"/lw/5on/ask_lesswrong_design_a_degree_in_rationality/45tc\">nerzhin</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qMZLkQn2PqNHEuXZh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 19, "extendedScore": null, "score": 7.141925579028957e-07, "legacy": true, "legacyId": "7367", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T16:14:59.460Z", "modifiedAt": null, "url": null, "title": "List of compartmentalized people (who both win and fail at truth-seeking)", "slug": "list-of-compartmentalized-people-who-both-win-and-fail-at", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:59.986Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NKda72ESqp3DBjgMK/list-of-compartmentalized-people-who-both-win-and-fail-at", "pageUrlRelative": "/posts/NKda72ESqp3DBjgMK/list-of-compartmentalized-people-who-both-win-and-fail-at", "linkUrl": "https://www.lesswrong.com/posts/NKda72ESqp3DBjgMK/list-of-compartmentalized-people-who-both-win-and-fail-at", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20List%20of%20compartmentalized%20people%20(who%20both%20win%20and%20fail%20at%20truth-seeking)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AList%20of%20compartmentalized%20people%20(who%20both%20win%20and%20fail%20at%20truth-seeking)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNKda72ESqp3DBjgMK%2Flist-of-compartmentalized-people-who-both-win-and-fail-at%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=List%20of%20compartmentalized%20people%20(who%20both%20win%20and%20fail%20at%20truth-seeking)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNKda72ESqp3DBjgMK%2Flist-of-compartmentalized-people-who-both-win-and-fail-at", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNKda72ESqp3DBjgMK%2Flist-of-compartmentalized-people-who-both-win-and-fail-at", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 182, "htmlBody": "<p>Following up on an impromptu list XiXiDu made of famous recent scientists &amp; thinkers who also held quite odd beliefs, I've created a <a href=\"http://wiki.lesswrong.com/wiki/Irrationalists\">wiki article with that list &amp; a few other</a> people.</p>\n<p>This Discussion is posted for feedback on a few points:</p>\n<ol>\n<li>Is this a good idea in the first place? I feel vaguely uneasy, like it could be taken as a 'hit list' or a list of inviolable norms.</li>\n<li>What's a better name? 'Irrationalists' is a bad name but the only half-way self-explanatory one I could think of at the moment.</li>\n<li>Who's missing? There are currently only 8 people on the list right now.</li>\n<li>Is it reasonable to limit the list temporally only to people who lived in the 20th century &amp; later, and so had access to all the data and philosophy done then that we take for granted?</li>\n<li>I added in a few 'See Alsos' that I could think of; are there more germane wiki articles? Especially LW articles? (I know Aumann in particular has been discussed occasionally by Eliezer - worth linking directly?)</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NKda72ESqp3DBjgMK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -14, "extendedScore": null, "score": 7.141994009518275e-07, "legacy": true, "legacyId": "7368", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T17:13:19.737Z", "modifiedAt": null, "url": null, "title": "Breaking the Procrastination Equation", "slug": "breaking-the-procrastination-equation", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alex_Altair", "createdAt": "2010-07-21T18:30:40.806Z", "isAdmin": false, "displayName": "Alex_Altair"}, "userId": "5wu9jG4pm9q6xjZ9R", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yGqPGb26X3aSjH4aZ/breaking-the-procrastination-equation", "pageUrlRelative": "/posts/yGqPGb26X3aSjH4aZ/breaking-the-procrastination-equation", "linkUrl": "https://www.lesswrong.com/posts/yGqPGb26X3aSjH4aZ/breaking-the-procrastination-equation", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Breaking%20the%20Procrastination%20Equation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABreaking%20the%20Procrastination%20Equation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyGqPGb26X3aSjH4aZ%2Fbreaking-the-procrastination-equation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Breaking%20the%20Procrastination%20Equation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyGqPGb26X3aSjH4aZ%2Fbreaking-the-procrastination-equation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyGqPGb26X3aSjH4aZ%2Fbreaking-the-procrastination-equation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>Recently, LessWrong user LukeProg wrote an article summarizing the scientific research on procrastination, in <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a>. The result was the Procrastination Equation:</p>\n<p><img src=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/procrastination-equation.png\" alt=\"\" width=\"548\" height=\"99\" /></p>\n<p>This equation quantifies the motivation of people, <em>on average</em>. The rest of the article, and the book that much of it came from, was spent on ways to adjust your situation so that your motivation came out right. This can be helpful, but I think it is important to consider another goal.</p>\n<p style=\"padding-left: 30px;\"><strong>I want to change myself so that I no longer follow the procrastination equation.</strong></p>\n<p>I am confident that there are people in the world that don't follow the procrastination equation.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yGqPGb26X3aSjH4aZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "7370", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RWo4LwFzpHNQCTcYt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T20:49:59.007Z", "modifiedAt": null, "url": null, "title": "Upcoming meet-ups: Buenos Aires, Minneapolis, Ottawa, Edinburgh, Cambridge, London, DC", "slug": "upcoming-meet-ups-buenos-aires-minneapolis-ottawa-edinburgh", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:03.216Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zYjtSZC6spEmEeb4u/upcoming-meet-ups-buenos-aires-minneapolis-ottawa-edinburgh", "pageUrlRelative": "/posts/zYjtSZC6spEmEeb4u/upcoming-meet-ups-buenos-aires-minneapolis-ottawa-edinburgh", "linkUrl": "https://www.lesswrong.com/posts/zYjtSZC6spEmEeb4u/upcoming-meet-ups-buenos-aires-minneapolis-ottawa-edinburgh", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Upcoming%20meet-ups%3A%20Buenos%20Aires%2C%20Minneapolis%2C%20Ottawa%2C%20Edinburgh%2C%20Cambridge%2C%20London%2C%20DC&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUpcoming%20meet-ups%3A%20Buenos%20Aires%2C%20Minneapolis%2C%20Ottawa%2C%20Edinburgh%2C%20Cambridge%2C%20London%2C%20DC%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzYjtSZC6spEmEeb4u%2Fupcoming-meet-ups-buenos-aires-minneapolis-ottawa-edinburgh%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Upcoming%20meet-ups%3A%20Buenos%20Aires%2C%20Minneapolis%2C%20Ottawa%2C%20Edinburgh%2C%20Cambridge%2C%20London%2C%20DC%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzYjtSZC6spEmEeb4u%2Fupcoming-meet-ups-buenos-aires-minneapolis-ottawa-edinburgh", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzYjtSZC6spEmEeb4u%2Fupcoming-meet-ups-buenos-aires-minneapolis-ottawa-edinburgh", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 203, "htmlBody": "<p>There are upcoming Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/lw/5n4/buenos_aires_meetup_saturday_may_14th_3pm/\"><strong>Buenos Aires</strong>: Saturday May 14th, 3pm</a>;</li>\n<li><a href=\"/lw/5nr/minneapolis_meetup_saturday_may_14_300pm/\"><strong>Minneapolis</strong>: Saturday May 14th, 3pm</a>;</li>\n<li><a href=\"/lw/5nx/ottawa_meetup_saturday_may_14_6pm/\"><strong>Ottawa</strong>: Saturday May 14th, 6pm</a>;</li>\n<li><a href=\"/lw/5nu/ediburgh_lw_meetup_sunday_15th_may_2pm/\"><strong>Edinburgh</strong>: Sunday May 15th, 2pm</a>;</li>\n<li><strong><a href=\"/lw/5ko/london_meetup_sunday_20110515_1400_near_london/\">London</a></strong><a href=\"/lw/5ko/london_meetup_sunday_20110515_1400_near_london/\">: Sunday May 15th, 2pm</a>;</li>\n<li><a href=\"/lw/5mf/dc_meetup_sunday_may_15th_330_pm/\"><strong>DC</strong>: Sunday May 15th, 3:30pm</a>;</li>\n<li><a href=\"/r/discussion/lw/5pd/southern_california_meetup_may_21_weekly_irvine/\"><strong>Southern California / Irvine</strong>: Saturday May 21, 2pm</a>;</li>\n<li><a href=\"/r/discussion/lw/5qn/triangle_nc_meetup_may_20th_6pm/\"><strong>Triangle NC:</strong> &nbsp;May 20, 6pm;</a></li>\n<li><a href=\"/r/discussion/lw/5pp/houston_hackerspace_meetup_sunday_may_22_500pm/\"><strong>Houston:</strong> May 22, 5pm;</a></li>\n</ul>\n<p>Cities with regularly scheduled meetups:&nbsp; <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>, <a href=\"/r/discussion/lw/5pd/southern_california_meetup_may_21_weekly_irvine/\">Irvine</a>.</strong></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy/\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p><a id=\"more\"></a>To reduce front page clutter, the new plan&nbsp;is for meetups to be initially posted in the Discussion section, and for me to make a promoted post \"upcoming meetups\" post every Friday that links to every meet-up that has been planned for the next two weeks. [HT: <a href=\"/r/discussion/lw/5iy/proposal_consolidate_meetup_announcements_before\">Carl Shulman</a>.] Please let me know if I omit your meetup.</p>\n<p>Please note that for people to see your meetup announcement, you should post your meetup <em>before </em>the Friday before your meetup!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DQHWBcKeiLnyh9za9": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zYjtSZC6spEmEeb4u", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 44, "extendedScore": null, "score": 7.14279043270106e-07, "legacy": true, "legacyId": "7374", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MtyCh4Y4uTeTmgueG", "k7CAcSRi3KamPtCA4", "5TMcKt3NddaKsTAip", "95PKCPrjsgvRo8FD9", "5jpF2WdwvLCzN4R7r", "kyxPjuszW29NmHcW6", "pAHo9zSFXygp5A5dL", "EALdLAoLng5MRtSRA", "sMM6km5Np42EghAtY", "d28mWBMrFt8nwpXLp", "eaKHojBdtsf35937k"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T20:53:48.623Z", "modifiedAt": null, "url": null, "title": "DC Meetup: Sunday May 15th, 3:30 PM", "slug": "dc-meetup-sunday-may-15th-3-30-pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.963Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kyxPjuszW29NmHcW6/dc-meetup-sunday-may-15th-3-30-pm", "pageUrlRelative": "/posts/kyxPjuszW29NmHcW6/dc-meetup-sunday-may-15th-3-30-pm", "linkUrl": "https://www.lesswrong.com/posts/kyxPjuszW29NmHcW6/dc-meetup-sunday-may-15th-3-30-pm", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20DC%20Meetup%3A%20Sunday%20May%2015th%2C%203%3A30%20PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADC%20Meetup%3A%20Sunday%20May%2015th%2C%203%3A30%20PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkyxPjuszW29NmHcW6%2Fdc-meetup-sunday-may-15th-3-30-pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=DC%20Meetup%3A%20Sunday%20May%2015th%2C%203%3A30%20PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkyxPjuszW29NmHcW6%2Fdc-meetup-sunday-may-15th-3-30-pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkyxPjuszW29NmHcW6%2Fdc-meetup-sunday-may-15th-3-30-pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><em style=\"font-style: italic;\"><a id=\"more\"></a>Sunday May 15th, 3:30 PM - 8:30 PM</em><br /><em style=\"font-style: italic;\">Chipotle Mexican Grill</em><br /><em style=\"font-style: italic;\">7600 Old Georgetown Road</em><br /><em style=\"font-style: italic;\">Bethesda, MD 20814<br /><span style=\"font-style: normal;\"> </span></em></span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-style: italic;\">Hello again! Our first meetup had a great turnout, and we're hoping to get even more this time.</span></p>\n<p><span style=\"font-style: italic;\"><span style=\"font-style: normal;\"> </span> </span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-style: normal;\"><strong style=\"font-weight: bold;\">Goals:</strong><br />Continue getting to know each other and new members, figuring out how to schedule future meetups and pick a more optimal location, and have fun, interesting conversations. Be on the lookout for interesting ideas during the week.</span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-style: normal;\"><strong style=\"font-weight: bold;\">Directions:</strong><br />The Chipotle is near the Bethesda Metro station, just follow&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Old+Georgetown+Rd&amp;daddr=7600+Old+Georgetown+Rd,+Bethesda,+MD+20814&amp;hl=en&amp;geocode=FVXcUgId66Fn-w%3BFarfUgIdn5tn-ynZQi-7ZMm3iTG95vklOa-npw&amp;mra=me&amp;mrsp=0&amp;sz=18&amp;sll=38.985195,-77.0952&amp;sspn=0.002243,0.003449&amp;ie=UTF8&amp;t=h&amp;z=18\">these</a>&nbsp;directions. Go out of the station and walk down Old Georgetown Road. The Chipotle is next to the waterfall fountain, and outdoor seating area.<br /><br />We will be sitting towards the back of the restaurant (basically, keep going in the direction you've been walking to get to the Chipotle), in the corner with a wraparound bench. Look for the person with curly red hair, or the LW sign.<br /><br />See us also at lesswrong-dc@googlegroups.com</span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kyxPjuszW29NmHcW6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "7287", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T20:54:32.138Z", "modifiedAt": null, "url": null, "title": "London meetup, Sunday 2011-05-15 14:00, near London Bridge", "slug": "london-meetup-sunday-2011-05-15-14-00-near-london-bridge", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.999Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5jpF2WdwvLCzN4R7r/london-meetup-sunday-2011-05-15-14-00-near-london-bridge", "pageUrlRelative": "/posts/5jpF2WdwvLCzN4R7r/london-meetup-sunday-2011-05-15-14-00-near-london-bridge", "linkUrl": "https://www.lesswrong.com/posts/5jpF2WdwvLCzN4R7r/london-meetup-sunday-2011-05-15-14-00-near-london-bridge", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20London%20meetup%2C%20Sunday%202011-05-15%2014%3A00%2C%20near%20London%20Bridge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALondon%20meetup%2C%20Sunday%202011-05-15%2014%3A00%2C%20near%20London%20Bridge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jpF2WdwvLCzN4R7r%2Flondon-meetup-sunday-2011-05-15-14-00-near-london-bridge%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=London%20meetup%2C%20Sunday%202011-05-15%2014%3A00%2C%20near%20London%20Bridge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jpF2WdwvLCzN4R7r%2Flondon-meetup-sunday-2011-05-15-14-00-near-london-bridge", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jpF2WdwvLCzN4R7r%2Flondon-meetup-sunday-2011-05-15-14-00-near-london-bridge", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p><a id=\"more\"></a>The meetup on 1 May was another great success, and participants felt we could definitely benefit from meeting up more frequently, so we've schedule another one for next Sunday, 15 May, at 2pm in The George near London Bridge station. This is a change of venue, to mix things up and in case we get nice weather.</p>\n<ul>\n<li>The George Inn, 77 Borough High Street, London, SE1 1NH</li>\n<li><a href=\"http://www.traditionalpubslondon.co.uk/georgesouthwark/index.php\">Official page</a></li>\n<li><a href=\"http://maps.google.co.uk/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=The+George+near+Borough+High+Street,+Camberwell&amp;aq=0&amp;sll=51.42559,-0.130394&amp;sspn=0.011827,0.015771&amp;ie=UTF8&amp;hq=The+George&amp;hnear=Borough+High+St,+Camberwell,+Greater+London,+United+Kingdom&amp;ll=51.504482,-0.090423&amp;spn=0.00593,0.007886&amp;z=17\">Map</a></li>\n<li><a href=\"http://maps.google.co.uk/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=The+George+near+Borough+High+Street,+Camberwell&amp;aq=0&amp;sll=51.42559,-0.130394&amp;sspn=0.011827,0.015771&amp;ie=UTF8&amp;hq=The+George&amp;hnear=Borough+High+St,+Camberwell,+Greater+London,+United+Kingdom&amp;ll=51.504403,-0.090517&amp;spn=0.001483,0.001971&amp;z=19&amp;layer=c&amp;cbll=51.504479,-0.09042&amp;panoid=5uD2wYh_xiLVt1HbVnLZGw&amp;cbp=12,156.09,,0,-7.84\">Street view</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/The_George_Inn,_Southwark\">Wikipedia page</a></li>\n<li><a href=\"http://www.beerintheevening.com/pubs/s/43/434/George/London_Bridge\">beerintheevening</a></li>\n</ul>\n<p>As always, we'll have a big picture of a paperclip on the table so you can find us; I <a href=\"http://pics.babysimon.co.uk/index.py/photos/3902?tag=Paul\">look like this</a>. Hope to see lots of you there. New people always welcome!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5jpF2WdwvLCzN4R7r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.142803617654383e-07, "legacy": true, "legacyId": "7224", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T21:14:11.399Z", "modifiedAt": null, "url": null, "title": "Ediburgh LW Meetup Sunday 15th May, 2pm", "slug": "ediburgh-lw-meetup-sunday-15th-may-2pm", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sark", "createdAt": "2010-01-20T20:18:10.889Z", "isAdmin": false, "displayName": "sark"}, "userId": "cJYNhyCitpdzsZqeP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/95PKCPrjsgvRo8FD9/ediburgh-lw-meetup-sunday-15th-may-2pm", "pageUrlRelative": "/posts/95PKCPrjsgvRo8FD9/ediburgh-lw-meetup-sunday-15th-may-2pm", "linkUrl": "https://www.lesswrong.com/posts/95PKCPrjsgvRo8FD9/ediburgh-lw-meetup-sunday-15th-may-2pm", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ediburgh%20LW%20Meetup%20Sunday%2015th%20May%2C%202pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEdiburgh%20LW%20Meetup%20Sunday%2015th%20May%2C%202pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F95PKCPrjsgvRo8FD9%2Fediburgh-lw-meetup-sunday-15th-may-2pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ediburgh%20LW%20Meetup%20Sunday%2015th%20May%2C%202pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F95PKCPrjsgvRo8FD9%2Fediburgh-lw-meetup-sunday-15th-may-2pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F95PKCPrjsgvRo8FD9%2Fediburgh-lw-meetup-sunday-15th-may-2pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 41, "htmlBody": "<p>Location: Delhi Cafe, 67 Nicolson Street</p>\n<p>Map:&nbsp;<a href=\"http://maps.google.co.uk/maps?ie=UTF8&amp;t=h&amp;cid=1874860554950886070\">http://maps.google.co.uk/maps?ie=UTF8&amp;t=h&amp;cid=1874860554950886070</a></p>\n<p>I will be there with the <a href=\"http://www.amazon.com/Oxford-Book-Aphorisms-John-Gross/dp/0192804561/ref=dp_ob_title_bk\">Oxford Book of Aphorisms</a> (for no particular reason)</p>\n<p><img src=\"http://sitb-images.amazon.com/Qffs+v35lerh9LXX9WM/hvi/TiSbkkpG4VdXWxuDJNnwXPGvfXakdFCycx0aQbHfH3Y2VhVyjWY=\" alt=\"\" width=\"200\" height=\"324\" /></p>\n<p>Also check out: http://www.facebook.com/event.php?eid=161542077233135. Since we touched on Richard Wiseman last week.</p>\n<p>Note: Sunday, not Saturday! (simply because I have an exam on Saturday...)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "95PKCPrjsgvRo8FD9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 7.142860546042991e-07, "legacy": true, "legacyId": "7338", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T21:14:30.252Z", "modifiedAt": null, "url": null, "title": "Ottawa meetup, Saturday May 14 6pm", "slug": "ottawa-meetup-saturday-may-14-6pm", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5TMcKt3NddaKsTAip/ottawa-meetup-saturday-may-14-6pm", "pageUrlRelative": "/posts/5TMcKt3NddaKsTAip/ottawa-meetup-saturday-may-14-6pm", "linkUrl": "https://www.lesswrong.com/posts/5TMcKt3NddaKsTAip/ottawa-meetup-saturday-may-14-6pm", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ottawa%20meetup%2C%20Saturday%20May%2014%206pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOttawa%20meetup%2C%20Saturday%20May%2014%206pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5TMcKt3NddaKsTAip%2Fottawa-meetup-saturday-may-14-6pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ottawa%20meetup%2C%20Saturday%20May%2014%206pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5TMcKt3NddaKsTAip%2Fottawa-meetup-saturday-may-14-6pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5TMcKt3NddaKsTAip%2Fottawa-meetup-saturday-may-14-6pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 121, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"> </span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><em style=\"font-style: italic;\">Saturday May 14th, 18:00 - Late</em></span><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><em style=\"font-style: italic;\"></em></span></p>\n<ol>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><em style=\"font-style: italic;\">Social: My house (Little Italy, Ottawa - PM me for address)</em></span></li>\n<li><em>Games night: Poker @ Casino de Hull</em></li>\n</ol>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-style: normal;\"><strong style=\"font-weight: bold;\">Goals:</strong><br /></span></p>\n<ol>\n<li><span style=\"font-style: normal;\">Continue getting to know each other and new members, continue getting more awesome, and discuss how to implement the various self-improvement/world optimizing schemes that are ongoing.</span></li>\n<li><span style=\"font-style: normal;\">Test your rationality by <a href=\"/lw/4yk/verifying_rationality_via_rationalpokercom/\">playing some poker</a> at the casino (I can drive myself plus four). I'm happy to give a brief tutorial beforehand.<br /></span></li>\n</ol>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-style: normal;\"><strong style=\"font-weight: bold;\">Directions:</strong></span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-style: normal;\">I live near Pub Italia, the Carling O-Train stop, and the corner of Preston &amp; Carling. PM me for my address and/or cell number.</span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">I'll post a more detailed invite to the <a href=\"http://groups.google.com/group/less-wrong-ottawa\">google group</a>.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Come one, come all!</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5TMcKt3NddaKsTAip", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.142861456075334e-07, "legacy": true, "legacyId": "7341", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xjMDAtz5T3Ssz9Y7X"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T21:14:45.113Z", "modifiedAt": null, "url": null, "title": "Minneapolis Meetup: Saturday May 14, 3:00PM", "slug": "minneapolis-meetup-saturday-may-14-3-00pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.555Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JustinShovelain", "createdAt": "2009-06-10T00:56:47.112Z", "isAdmin": false, "displayName": "JustinShovelain"}, "userId": "LEeresErqn3BpWrwG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k7CAcSRi3KamPtCA4/minneapolis-meetup-saturday-may-14-3-00pm", "pageUrlRelative": "/posts/k7CAcSRi3KamPtCA4/minneapolis-meetup-saturday-may-14-3-00pm", "linkUrl": "https://www.lesswrong.com/posts/k7CAcSRi3KamPtCA4/minneapolis-meetup-saturday-may-14-3-00pm", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Minneapolis%20Meetup%3A%20Saturday%20May%2014%2C%203%3A00PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMinneapolis%20Meetup%3A%20Saturday%20May%2014%2C%203%3A00PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk7CAcSRi3KamPtCA4%2Fminneapolis-meetup-saturday-may-14-3-00pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Minneapolis%20Meetup%3A%20Saturday%20May%2014%2C%203%3A00PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk7CAcSRi3KamPtCA4%2Fminneapolis-meetup-saturday-may-14-3-00pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk7CAcSRi3KamPtCA4%2Fminneapolis-meetup-saturday-may-14-3-00pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 148, "htmlBody": "<p><span style=\"font-family: arial, helvetica, sans-serif; font-size: 13px; border-collapse: collapse;\"><a id=\"more\"></a></span></p>\n<address>Saturday May 14th, 3PM</address><address>Starbucks</address><address>Coffman Memorial Union</address><address>300 Washington Avenue SE,</address><address>University of Minnesota, Minneapolis, MN&nbsp;55455</address>\n<p>&nbsp;</p>\n<h3>Goals:</h3>\n<p><span style=\"font-size: 15px; font-weight: bold;\"><span style=\"font-family: Arial, Helvetica, sans-serif; font-weight: normal; font-size: small; line-height: 19px;\">To meet and network with likeminded Minnesotans.</span></span></p>\n<p><span style=\"font-size: 15px; font-weight: bold;\"><span style=\"font-family: Arial, Helvetica, sans-serif; font-weight: normal; font-size: small; line-height: 19px;\">I'll do my best to answer any questions people have about SIAI, rationality, x-risk strategy, and intelligence amplification (I spent about 2 years as a fellow).</span></span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">To better figure out what our personal supergoals are. I'll build and print out a goal system investigation worksheet.&nbsp;</span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><br /></span></p>\n<p><span style=\"font-size: 15px; font-weight: bold;\">Directions:</span></p>\n<p><span style=\"font-family: arial, sans-serif;\"><span style=\"line-height: 15px;\"><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif;\"><span style=\"line-height: normal;\"><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"> </span></span></span></span></span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The Minneapolis meetup&nbsp;will take place this Saturday the 14th at 3:00 PM in Coffman Memorial Union at the University of Minnesota. We'll be meeting inside at Starbucks,&nbsp;next to the northwest entrance to the bookstore, and&nbsp;underneath the northwest entrance to the Union. That entrance is a separate glass-sided structure right next to Washington Avenue, not the multistory brick building, but you can get to Starbucks from either entrance; it's on level 2.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">RSVP and I'll keep an eye out for you.&nbsp;You can contact me at jshovelainsiai@gmail.com.&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k7CAcSRi3KamPtCA4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.14286217334568e-07, "legacy": true, "legacyId": "7335", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T21:15:01.081Z", "modifiedAt": null, "url": null, "title": "Buenos Aires meetup: Saturday, May 14th, 3pm", "slug": "buenos-aires-meetup-saturday-may-14th-3pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.951Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pablo_Stafforini", "createdAt": "2009-03-24T12:56:00.130Z", "isAdmin": false, "displayName": "Pablo"}, "userId": "W7ETRtvRMqYetyQE9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MtyCh4Y4uTeTmgueG/buenos-aires-meetup-saturday-may-14th-3pm", "pageUrlRelative": "/posts/MtyCh4Y4uTeTmgueG/buenos-aires-meetup-saturday-may-14th-3pm", "linkUrl": "https://www.lesswrong.com/posts/MtyCh4Y4uTeTmgueG/buenos-aires-meetup-saturday-may-14th-3pm", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Buenos%20Aires%20meetup%3A%20Saturday%2C%20May%2014th%2C%203pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABuenos%20Aires%20meetup%3A%20Saturday%2C%20May%2014th%2C%203pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtyCh4Y4uTeTmgueG%2Fbuenos-aires-meetup-saturday-may-14th-3pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Buenos%20Aires%20meetup%3A%20Saturday%2C%20May%2014th%2C%203pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtyCh4Y4uTeTmgueG%2Fbuenos-aires-meetup-saturday-may-14th-3pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtyCh4Y4uTeTmgueG%2Fbuenos-aires-meetup-saturday-may-14th-3pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<p><a id=\"more\"></a><strong>When</strong>: Saturday, May 14th, 3pm.</p>\n<p><strong>Where</strong>: <a href=\"http://goo.gl/AwKgD\">Starbucks Coffe, Florida 1</a>,&nbsp;upstairs. &nbsp;(A copy of Greg Egan's book <em>Diaspora </em>will be displayed on our table.)</p>\n<p>This will be the first Buenos Aires LessWrong meetup. &nbsp;Our nominal discussion topic will be <a href=\"http://wiki.lesswrong.com/wiki/Cognitive_biases\">cognitive biases</a>, though we'll keep things flexible so that the conversation can move naturally towards other topics of interest and relevance. &nbsp;If you read and like this blog. and live in BA or just happen to be visiting the city, do join us. &nbsp;It will be a great opportunity to meet like-minded folks in the area.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MtyCh4Y4uTeTmgueG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 7.142862944104896e-07, "legacy": true, "legacyId": "7312", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-13T23:39:45.771Z", "modifiedAt": null, "url": null, "title": "Grigori Perelman refused prize because he knows \"how to control the universe\"", "slug": "grigori-perelman-refused-prize-because-he-knows-how-to", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:35.780Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Hul-Gil", "createdAt": "2011-05-02T22:16:10.898Z", "isAdmin": false, "displayName": "Hul-Gil"}, "userId": "a67SuoZfWaXPzjvzy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v32fvArsBqEss8SHH/grigori-perelman-refused-prize-because-he-knows-how-to", "pageUrlRelative": "/posts/v32fvArsBqEss8SHH/grigori-perelman-refused-prize-because-he-knows-how-to", "linkUrl": "https://www.lesswrong.com/posts/v32fvArsBqEss8SHH/grigori-perelman-refused-prize-because-he-knows-how-to", "postedAtFormatted": "Friday, May 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Grigori%20Perelman%20refused%20prize%20because%20he%20knows%20%22how%20to%20control%20the%20universe%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGrigori%20Perelman%20refused%20prize%20because%20he%20knows%20%22how%20to%20control%20the%20universe%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv32fvArsBqEss8SHH%2Fgrigori-perelman-refused-prize-because-he-knows-how-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Grigori%20Perelman%20refused%20prize%20because%20he%20knows%20%22how%20to%20control%20the%20universe%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv32fvArsBqEss8SHH%2Fgrigori-perelman-refused-prize-because-he-knows-how-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv32fvArsBqEss8SHH%2Fgrigori-perelman-refused-prize-because-he-knows-how-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 263, "htmlBody": "<p>Grigori Perelman was that reclusive Russian mathematician who proved the Poincar&eacute; conjecture, and refused the $1,000,000 prize. He has reportedly said that he refused the reward because he knows \"how to control the universe\" (full quote below; article linked at end).</p>\n<blockquote>\n<p>When asked why he refused from the prize of one million dollars, Perelman responded: \"I know how to control the Universe. Why would I run to get a million, tell me?\"</p>\n</blockquote>\n<p>My immediate thought is that he refers to the fact that understanding of the world means control of the world, to the extent of your understanding and limit of possibility. Thus the saying \"knowledge is power\" (which, oddly, the public doesn't really think seems to apply to science). I also see the point of refusing to communicate with the media, which manifestly does <em>not</em> care about science but rather about celebrity (I'm not guilty! this post is just about his ideas, dammit!). But his other comments - about the \"boundless\", for instance - sound more wild-eyed and vague, so maybe he's thinking of something else.</p>\n<p>Also, what is this nonsense at the end? I think it's probably a misinterpretation by a reporter. Or wild exaggerations by Perelman. Or are we all doomed to be folded?</p>\n<blockquote>\n<p>The scientist has learned some super-knowledge which helps realize creation. Special services need to know whether Perelman and his knowledge may pose a threat to humanity. With his knowledge he can fold the Universe into a spot and then unfold it again. Will mankind survive after this fantastic process? Do we need to control the Universe at all?</p>\n</blockquote>\n<p>http://english.pravda.ru/science/tech/28-04-2011/117727-Grigori_Perelman-0/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v32fvArsBqEss8SHH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 1, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "7376", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-14T00:00:12.341Z", "modifiedAt": null, "url": null, "title": "Free Thought Film Festival: Tampa traditional rationalist gathering this weekend (13-15 May)", "slug": "free-thought-film-festival-tampa-traditional-rationalist", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "khafra", "createdAt": "2009-03-20T14:27:07.210Z", "isAdmin": false, "displayName": "khafra"}, "userId": "TYxB9awGtAt3n4PfL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/i7vYBwJFQ77nuJNuc/free-thought-film-festival-tampa-traditional-rationalist", "pageUrlRelative": "/posts/i7vYBwJFQ77nuJNuc/free-thought-film-festival-tampa-traditional-rationalist", "linkUrl": "https://www.lesswrong.com/posts/i7vYBwJFQ77nuJNuc/free-thought-film-festival-tampa-traditional-rationalist", "postedAtFormatted": "Saturday, May 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Free%20Thought%20Film%20Festival%3A%20Tampa%20traditional%20rationalist%20gathering%20this%20weekend%20(13-15%20May)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFree%20Thought%20Film%20Festival%3A%20Tampa%20traditional%20rationalist%20gathering%20this%20weekend%20(13-15%20May)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi7vYBwJFQ77nuJNuc%2Ffree-thought-film-festival-tampa-traditional-rationalist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Free%20Thought%20Film%20Festival%3A%20Tampa%20traditional%20rationalist%20gathering%20this%20weekend%20(13-15%20May)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi7vYBwJFQ77nuJNuc%2Ffree-thought-film-festival-tampa-traditional-rationalist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi7vYBwJFQ77nuJNuc%2Ffree-thought-film-festival-tampa-traditional-rationalist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 28, "htmlBody": "<p>A bit late, since I'm at the opening ceremonies right now; but <a href=\"http://www.freethoughtfilmfest.org/\">it</a> seems like it could have some potential; and the Tampa Theatre is a great venue.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "i7vYBwJFQ77nuJNuc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.143341438739455e-07, "legacy": true, "legacyId": "7377", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-14T02:50:58.200Z", "modifiedAt": null, "url": null, "title": "Reference Classes in the Doomsday Argument", "slug": "reference-classes-in-the-doomsday-argument-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.959Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Caerbannog", "createdAt": "2011-04-30T02:54:30.643Z", "isAdmin": false, "displayName": "Caerbannog"}, "userId": "2AHG8DKQeWwxMCvK9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ycobo7Ghbx7YH93br/reference-classes-in-the-doomsday-argument-0", "pageUrlRelative": "/posts/ycobo7Ghbx7YH93br/reference-classes-in-the-doomsday-argument-0", "linkUrl": "https://www.lesswrong.com/posts/ycobo7Ghbx7YH93br/reference-classes-in-the-doomsday-argument-0", "postedAtFormatted": "Saturday, May 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reference%20Classes%20in%20the%20Doomsday%20Argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReference%20Classes%20in%20the%20Doomsday%20Argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fycobo7Ghbx7YH93br%2Freference-classes-in-the-doomsday-argument-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reference%20Classes%20in%20the%20Doomsday%20Argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fycobo7Ghbx7YH93br%2Freference-classes-in-the-doomsday-argument-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fycobo7Ghbx7YH93br%2Freference-classes-in-the-doomsday-argument-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p>I accidentally deleted my article titled \"Reference Classes in the Doomsday Argument.\" There were some really thoughtful replies, and I sincerely apologize to everyone who commented. I'm new here and new to web forums in general, and I thought that I was deleting my saved draft. Aargh!</p>\n<p>For those who were involved in the discussion, <a href=\"/r/discussion/lw/5od/reference_classes_in_the_doomsday_argument/\">here</a> is the permalink to the topic.</p>\n<p>Edit: Renamed title to make the discussion easier to find (per nickernst's suggestion).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ycobo7Ghbx7YH93br", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.143836145908659e-07, "legacy": true, "legacyId": "7381", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZMDXYGn4Q3x5KdNrW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-14T05:57:20.502Z", "modifiedAt": null, "url": null, "title": "Victoria BC meet-up Monday May 23rd 5pm", "slug": "victoria-bc-meet-up-monday-may-23rd-5pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.066Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Owen_Richardson", "createdAt": "2011-04-08T22:03:10.482Z", "isAdmin": false, "displayName": "Owen_Richardson"}, "userId": "uR7QxXK65gYZQ4PrL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FTsjQccMpw8HpqKYe/victoria-bc-meet-up-monday-may-23rd-5pm", "pageUrlRelative": "/posts/FTsjQccMpw8HpqKYe/victoria-bc-meet-up-monday-may-23rd-5pm", "linkUrl": "https://www.lesswrong.com/posts/FTsjQccMpw8HpqKYe/victoria-bc-meet-up-monday-may-23rd-5pm", "postedAtFormatted": "Saturday, May 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Victoria%20BC%20meet-up%20Monday%20May%2023rd%205pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVictoria%20BC%20meet-up%20Monday%20May%2023rd%205pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTsjQccMpw8HpqKYe%2Fvictoria-bc-meet-up-monday-may-23rd-5pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Victoria%20BC%20meet-up%20Monday%20May%2023rd%205pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTsjQccMpw8HpqKYe%2Fvictoria-bc-meet-up-monday-may-23rd-5pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTsjQccMpw8HpqKYe%2Fvictoria-bc-meet-up-monday-may-23rd-5pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<p>This little town doesn't seem to have much in the way of a lesswronger presence (search turns up me and one other user who hasn't been active since 2009), but damnit I'm here right now and I may as well give it a try!</p>\n<p>Therefore I'll be at the <a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=yates+starbucks+victoria&amp;aq=&amp;sll=48.425598,-123.360082&amp;sspn=0.003766,0.009581&amp;ie=UTF8&amp;hq=yates+starbucks&amp;hnear=Victoria,+Capital+Regional+District,+British+Columbia,+Canada&amp;ll=48.425926,-123.35947&amp;spn=0.007532,0.019162&amp;z=16&amp;iwloc=A\">Starbucks near the Market on Yates</a> on Monday May 23rd from 5 pm to at least 6 pm.</p>\n<p>I'll be reading a copy of \"Theory of Instruction: Principles and Applications\". Or writing on my laptop I guess. Actually, let's make this easy: Whatever I'm doing, I'll be wearing a black tricorn hat with gold piping and a giant white plume.</p>\n<p>I'll be there anyway, but if any Victorianites out there <em>are</em> reading this, please, <em>please</em> do contact me, especially if you want to come but need a different time and/or location.</p>\n<p>All right, here's hoping to see you there, all my hypothetical Victoria lesswrong homies!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FTsjQccMpw8HpqKYe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "7383", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-14T06:57:05.540Z", "modifiedAt": null, "url": null, "title": "Victoria BC meetup Monday May 23rd 5pm", "slug": "victoria-bc-meetup-monday-may-23rd-5pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.264Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Owen_Richardson", "createdAt": "2011-04-08T22:03:10.482Z", "isAdmin": false, "displayName": "Owen_Richardson"}, "userId": "uR7QxXK65gYZQ4PrL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v6tom6yNm7RHTvaJh/victoria-bc-meetup-monday-may-23rd-5pm", "pageUrlRelative": "/posts/v6tom6yNm7RHTvaJh/victoria-bc-meetup-monday-may-23rd-5pm", "linkUrl": "https://www.lesswrong.com/posts/v6tom6yNm7RHTvaJh/victoria-bc-meetup-monday-may-23rd-5pm", "postedAtFormatted": "Saturday, May 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Victoria%20BC%20meetup%20Monday%20May%2023rd%205pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVictoria%20BC%20meetup%20Monday%20May%2023rd%205pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv6tom6yNm7RHTvaJh%2Fvictoria-bc-meetup-monday-may-23rd-5pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Victoria%20BC%20meetup%20Monday%20May%2023rd%205pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv6tom6yNm7RHTvaJh%2Fvictoria-bc-meetup-monday-may-23rd-5pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv6tom6yNm7RHTvaJh%2Fvictoria-bc-meetup-monday-may-23rd-5pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<p>This little town doesn't seem to have much in the way of a  lesswronger presence (search turns up me and one other user who hasn't  been active since 2009), but damnit I'm here right now and I may as well  give it a try!</p>\n<p>Therefore I'll be at the <a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=yates+starbucks+victoria&amp;aq=&amp;sll=48.425598,-123.360082&amp;sspn=0.003766,0.009581&amp;ie=UTF8&amp;hq=yates+starbucks&amp;hnear=Victoria,+Capital+Regional+District,+British+Columbia,+Canada&amp;ll=48.425926,-123.35947&amp;spn=0.007532,0.019162&amp;z=16&amp;iwloc=A\">Starbucks near the Market on Yates</a> on Monday May 23rd from 5 pm to at least 6 pm.</p>\n<p>I'll  be reading a copy of \"Theory of Instruction: Principles and  Applications\". Or writing on my laptop I guess. Actually, let's make  this easy: Whatever I'm doing, I'll be wearing a black tricorn hat with  gold piping and a giant white plume.</p>\n<p>I'll be there anyway, but if any Victorianites out there <em>are</em> reading this, please, <em>please</em> do contact me, especially if you want to come but need a different time and/or location.</p>\n<p>All right, here's hoping to see you there, all my hypothetical Victoria lesswrong homies!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v6tom6yNm7RHTvaJh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.144549274179511e-07, "legacy": true, "legacyId": "7387", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-14T13:51:11.091Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Useless Medical Disclaimers", "slug": "seq-rerun-useless-medical-disclaimers", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.848Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yk3iTgsFgjG3ZjES5/seq-rerun-useless-medical-disclaimers", "pageUrlRelative": "/posts/yk3iTgsFgjG3ZjES5/seq-rerun-useless-medical-disclaimers", "linkUrl": "https://www.lesswrong.com/posts/yk3iTgsFgjG3ZjES5/seq-rerun-useless-medical-disclaimers", "postedAtFormatted": "Saturday, May 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Useless%20Medical%20Disclaimers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Useless%20Medical%20Disclaimers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyk3iTgsFgjG3ZjES5%2Fseq-rerun-useless-medical-disclaimers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Useless%20Medical%20Disclaimers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyk3iTgsFgjG3ZjES5%2Fseq-rerun-useless-medical-disclaimers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyk3iTgsFgjG3ZjES5%2Fseq-rerun-useless-medical-disclaimers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 259, "htmlBody": "<p>Today's post, <a href=\"/lw/h4/useless_medical_disclaimers/\">Useless Medical Disclaimers</a> was originally published on March 19, 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Medical disclaimers without probabilities are hard to use, and if probabilities aren't there because some people can't handle having there, maybe we ought to tax those people. <br /><br /> (alternate summary:) <br /><br /> Eliezer complains about a disclaimer he had to sign before getting toe surgery because it didn't give numerical probabilities for the possible negative outcomes it described. He guesses this is because of people afflicted with \"innumeracy\" who would over-interpret small numbers. He proposes a tax wherein folks are asked if they are innumerate and asked to pay in proportion to their innumeracy. This tax is revealed in the comments to be a state-sponsored lottery.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/5o9/seq_rerun_superstimuli_and_the_collapse_of/\">Superstimuli and the Collapse of Western Civilization</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yk3iTgsFgjG3ZjES5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.145749373190658e-07, "legacy": true, "legacyId": "7390", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CJfSYYdsn9LQdaoPP", "6ynNerF3HAWobehnP", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-14T15:32:55.978Z", "modifiedAt": null, "url": null, "title": "Analysis of transistion costs for changing habits", "slug": "analysis-of-transistion-costs-for-changing-habits", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.353Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GjwwezvkLZhh5BDC5/analysis-of-transistion-costs-for-changing-habits", "pageUrlRelative": "/posts/GjwwezvkLZhh5BDC5/analysis-of-transistion-costs-for-changing-habits", "linkUrl": "https://www.lesswrong.com/posts/GjwwezvkLZhh5BDC5/analysis-of-transistion-costs-for-changing-habits", "postedAtFormatted": "Saturday, May 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Analysis%20of%20transistion%20costs%20for%20changing%20habits&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnalysis%20of%20transistion%20costs%20for%20changing%20habits%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGjwwezvkLZhh5BDC5%2Fanalysis-of-transistion-costs-for-changing-habits%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Analysis%20of%20transistion%20costs%20for%20changing%20habits%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGjwwezvkLZhh5BDC5%2Fanalysis-of-transistion-costs-for-changing-habits", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGjwwezvkLZhh5BDC5%2Fanalysis-of-transistion-costs-for-changing-habits", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 38, "htmlBody": "<p>http://logicalwholesomehealth.blogspot.com/2011/05/how-easy-is-it-to-change-your-diet-or.html#comment-form</p>\n<p>The article is from the angle of not blaming people who haven't made changes you think should be easy, but it also looks like a good way of allowing yourself appropriate slack for the process of making changes.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GjwwezvkLZhh5BDC5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.14604430821569e-07, "legacy": true, "legacyId": "7391", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-14T16:55:28.275Z", "modifiedAt": null, "url": null, "title": "Southern California Meetup May 21, Weekly Irvine Meetups on Wednesdays", "slug": "southern-california-meetup-may-21-weekly-irvine-meetups-on", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:01.360Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pAHo9zSFXygp5A5dL/southern-california-meetup-may-21-weekly-irvine-meetups-on", "pageUrlRelative": "/posts/pAHo9zSFXygp5A5dL/southern-california-meetup-may-21-weekly-irvine-meetups-on", "linkUrl": "https://www.lesswrong.com/posts/pAHo9zSFXygp5A5dL/southern-california-meetup-may-21-weekly-irvine-meetups-on", "postedAtFormatted": "Saturday, May 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Southern%20California%20Meetup%20May%2021%2C%20Weekly%20Irvine%20Meetups%20on%20Wednesdays&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASouthern%20California%20Meetup%20May%2021%2C%20Weekly%20Irvine%20Meetups%20on%20Wednesdays%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAHo9zSFXygp5A5dL%2Fsouthern-california-meetup-may-21-weekly-irvine-meetups-on%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Southern%20California%20Meetup%20May%2021%2C%20Weekly%20Irvine%20Meetups%20on%20Wednesdays%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAHo9zSFXygp5A5dL%2Fsouthern-california-meetup-may-21-weekly-irvine-meetups-on", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAHo9zSFXygp5A5dL%2Fsouthern-california-meetup-may-21-weekly-irvine-meetups-on", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<p>Southern California is about to have a lot more meetups. To get the ramp up started, there will be a meet up at <a title=\"Map\" href=\"http://maps.google.com/maps?hl=en&amp;ie=UTF8&amp;q=18542+Macarthur+Blvd+Irvine+CA,+92612+ihop&amp;fb=1&amp;gl=us&amp;hq=ihop&amp;hnear=18542+MacArthur+Blvd,+Irvine,+CA+92612&amp;cid=0,0,16042522294109526569&amp;ei=uLa8TOG7MoWCsQO1nM2TDw&amp;ved=0CBYQnwIwAA&amp;ll=33.679247,-117.859418&amp;spn=0.009285,0.021136&amp;t=h&amp;z=16&amp;iwloc=A\" target=\"_blank\">this IHOP</a> across the street from John Wayne Airport in Irvine, on Saturday May 21 from 2:00 to 8:00. We will likely be at the upstairs table, but just tell them you are with the Less Wrong meetup and they will point you in the right direction. This should become a monthly meetup, hopefully one of several monthly meetups held on different weekends of the month in different cities in Southern California.</p>\n<p>We are also starting weekly meetups in Irvine. These will be Wednesday evenings from 6:00 to 8:00, starting May 18, at the <a title=\"Map\" href=\"http://maps.google.com/maps?q=33.650526,-117.838927&amp;num=1&amp;t=h&amp;sll=33.650288,-117.838666&amp;sspn=0.001684,0.002363&amp;ie=UTF8&amp;ll=33.650398,-117.838631&amp;spn=0.001634,0.002497&amp;z=19\" target=\"_blank\">outdoor food court</a> near the UCI Campus, at Campus and Bridge. Look for me with sign showing a diagram of a <a href=\"/lw/nn/neural_categories/\">naive neural classifier of bleggs and rubes</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pAHo9zSFXygp5A5dL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.146283575818069e-07, "legacy": true, "legacyId": "7393", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yFDKvfN6D87Tf5J9f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T00:44:18.347Z", "modifiedAt": null, "url": null, "title": "People who want to save the world", "slug": "people-who-want-to-save-the-world", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:01.417Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Giles", "createdAt": "2011-02-11T02:30:16.999Z", "isAdmin": false, "displayName": "Giles"}, "userId": "H347ba3KZMP8XoDt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/omSbgTBa5HDqPdjHY/people-who-want-to-save-the-world", "pageUrlRelative": "/posts/omSbgTBa5HDqPdjHY/people-who-want-to-save-the-world", "linkUrl": "https://www.lesswrong.com/posts/omSbgTBa5HDqPdjHY/people-who-want-to-save-the-world", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20People%20who%20want%20to%20save%20the%20world&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APeople%20who%20want%20to%20save%20the%20world%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FomSbgTBa5HDqPdjHY%2Fpeople-who-want-to-save-the-world%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=People%20who%20want%20to%20save%20the%20world%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FomSbgTBa5HDqPdjHY%2Fpeople-who-want-to-save-the-world", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FomSbgTBa5HDqPdjHY%2Fpeople-who-want-to-save-the-world", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 201, "htmlBody": "<p>atucker <a href=\"/lw/46r/rationality_for_other_people/\">wants to save the world</a>.<br /> ciphergoth <a href=\"/lw/ee/the_mindkiller/\">wants to save the world</a>.<br /> Dorikka <a href=\"/lw/5ej/get_data_points_on_your_current_utility_function/\">wants to save the world</a>.<br /> Eliezer_Yudkowsky <a href=\"/lw/hx/one_life_against_the_world/\">wants to save the world</a>.<br /> I want to save the world.<br /> Kaj_Sotala <a href=\"/lw/38u/best_career_models_for_doing_research/\">wants to save the world</a>.<br /> lincolnquirk <a href=\"/lw/b9/welcome_to_less_wrong/3u9v\">wants to save the world</a>.<br /> Louie <a href=\"/lw/373/how_to_save_the_world/\">wants to save the world</a>.<br /> paulfchristiano <a href=\"/lw/541/details_of_taskforces_or_cooperate_now/\">wants to save the world</a>.<br /> Psy-Kosh <a href=\"/lw/1ab/dying_outside/15mo\">wants to save the world</a>.</p>\n<p>Clearly the list I've given is incomplete. I imagine most members of the Singularity Institute belong here; otherwise their motives are pretty baffling. But equally clearly, the list will not include everyone.</p>\n<p>What's my point? My point is that these people should be cooperating. But we can't cooperate unless we know who we are. If you feel your name belongs on this list then add a top-level comment to this thread, and feel free to add any information about what this means to you personally or what plans you have. Or it's enough just to say, \"I want to save the world\".</p>\n<p>This time, no-one's signing up for anything. I'm just doing this to let you know that you're not alone. But maybe some of us can find somewhere to talk that's a little quieter.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Rz5jb3cYHTSRmqNnN": 1, "xexCWMyds6QLWognu": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "omSbgTBa5HDqPdjHY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 5, "extendedScore": null, "score": 1.1e-05, "legacy": true, "legacyId": "7382", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 247, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kYDzd777ScKzbsTst", "yfxp4Y6YETjjtChFh", "yzpRwNw8EJGx2AEQ5", "xiHy3kFni8nsxfdcP", "rNkFLv9tXzq8Lrvrc", "TrmMcujGZt5JAtMGg", "2ypea6pY9NbxK8Mav"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T01:32:29.525Z", "modifiedAt": null, "url": null, "title": "Talk about your research", "slug": "talk-about-your-research", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:08.471Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "snarles", "createdAt": "2009-06-01T03:48:38.132Z", "isAdmin": false, "displayName": "snarles"}, "userId": "YsmFaM5MdsDW8GNop", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RD88BfBf75Y8ToRiM/talk-about-your-research", "pageUrlRelative": "/posts/RD88BfBf75Y8ToRiM/talk-about-your-research", "linkUrl": "https://www.lesswrong.com/posts/RD88BfBf75Y8ToRiM/talk-about-your-research", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Talk%20about%20your%20research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATalk%20about%20your%20research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRD88BfBf75Y8ToRiM%2Ftalk-about-your-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Talk%20about%20your%20research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRD88BfBf75Y8ToRiM%2Ftalk-about-your-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRD88BfBf75Y8ToRiM%2Ftalk-about-your-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 24, "htmlBody": "<p>There must be quite a few undergrad/graduate/post-doc/???-level researchers on LessWrong.&nbsp; I'm interested in hearing about your work.&nbsp; I'll post about myself in the comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RD88BfBf75Y8ToRiM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 20, "extendedScore": null, "score": 7.147782674851083e-07, "legacy": true, "legacyId": "7394", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T03:34:40.718Z", "modifiedAt": null, "url": null, "title": "What we're losing", "slug": "what-we-re-losing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:59.869Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jCSLbQvWz8j4Mwcar/what-we-re-losing", "pageUrlRelative": "/posts/jCSLbQvWz8j4Mwcar/what-we-re-losing", "linkUrl": "https://www.lesswrong.com/posts/jCSLbQvWz8j4Mwcar/what-we-re-losing", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20we're%20losing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20we're%20losing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjCSLbQvWz8j4Mwcar%2Fwhat-we-re-losing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20we're%20losing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjCSLbQvWz8j4Mwcar%2Fwhat-we-re-losing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjCSLbQvWz8j4Mwcar%2Fwhat-we-re-losing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 246, "htmlBody": "<p>More and more, LessWrong's posts are meta-rationality posts, about how to be rational, how to avoid akrasia, in general, without any specific application.&nbsp; This is probably the intended purpose of the site.&nbsp; But they're starting to bore me.</p>\n<p>What drew me to LessWrong is that it's a place where I can put rationality into practice, discussing specific questions of philosophy, value, and possible futures, with the goal of finding a good path through the Singularity.&nbsp; Many of these topics have no other place where rational discussion of them is possible, online or off.&nbsp; Such applied topics have almost all moved to Discussion now, and may be declining in frequency.</p>\n<p>This isn't entirely new.&nbsp; Applied discussions have always suffered bad karma on LW (statistically; please do not respond with anecdotal data).&nbsp; I thought this was because people downvote a post if they find anything in it that they disagree with.&nbsp; But perhaps a lot of people would rather talk about rationality than use it.</p>\n<p>Does anyone else have this perception?&nbsp; Or am I just becoming a LW old geezer?</p>\n<p>At the same time, LW is taking off in terms of meetups and number of posts.&nbsp; Is it finding its true self?&nbsp; Does the discussion of rationality techniques have a larger market than debates over Sleeping Beauty (I'm even beginning to miss those!)&nbsp; Is the old concern with values, artificial intelligence, and the Singularity something for LW to grow out of?</p>\n<p>(ADDED: Some rationality posts are good.&nbsp; I am also a lukeprog fan.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jCSLbQvWz8j4Mwcar", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 62, "baseScore": 72, "extendedScore": null, "score": 0.00015777175726796244, "legacy": true, "legacyId": "7395", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 57, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 79, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T07:48:06.108Z", "modifiedAt": null, "url": null, "title": "Rationalists don't care about the future", "slug": "rationalists-don-t-care-about-the-future", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:07.005Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/d5q6vKrLopC36zttS/rationalists-don-t-care-about-the-future", "pageUrlRelative": "/posts/d5q6vKrLopC36zttS/rationalists-don-t-care-about-the-future", "linkUrl": "https://www.lesswrong.com/posts/d5q6vKrLopC36zttS/rationalists-don-t-care-about-the-future", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalists%20don't%20care%20about%20the%20future&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalists%20don't%20care%20about%20the%20future%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd5q6vKrLopC36zttS%2Frationalists-don-t-care-about-the-future%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalists%20don't%20care%20about%20the%20future%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd5q6vKrLopC36zttS%2Frationalists-don-t-care-about-the-future", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd5q6vKrLopC36zttS%2Frationalists-don-t-care-about-the-future", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1671, "htmlBody": "<p>Related to <a href=\"/lw/108/exterminating_life_is_rational/\">Exterminating life is rational</a>.</p>\n<p>ADDED: Standard assumptions about utility maximization and time-discounting imply that we shouldn't care about the future.&nbsp; I will lay out the problem in the hopes that someone can find a convincing way around it.&nbsp; This is the sort of problem we should think about carefully, rather than grasping for the nearest apparent solution.&nbsp; (In particular, the solutions \"If you think you care about the future, then you care about the future\", and, \"So don't use exponential time-discounting,\" are easily-grasped, but vacuous; see bullet points at end.)</p>\n<p>The math is a tedious proof that exponential time discounting trumps geometric expansion into space.&nbsp; If you already understand that, you can skip ahead to the end.&nbsp; I have fixed the point raised by Dreaded_Anomaly.&nbsp; It doesn't change my conclusion.</p>\n<p>Suppose that we have Planck technology such that we can utilize all our local resources optimally to maximize our utility, nearly instantaneously.</p>\n<p>Suppose that we colonize the universe at light speed, starting from the center of our galaxy (we aren't in the center of our galaxy; but it makes the computations easier, and our assumptions more conservative, since starting from the center is more favorable to worrying about the future, as it lets us grab lots of utility quickly near our starting point).<a id=\"more\"></a></p>\n<p>Suppose our galaxy is a disc, so we can consider it two-dimensional.&nbsp; (The number of star systems expanded into per unit time is well-modeled in 2D, because the galaxy's thickness is small compared to its diameter.)</p>\n<p>The Milky Way is approx. 100,000 light-years in diameter, with perhaps 100 billion stars.&nbsp; These stars are denser at its center.&nbsp; Suppose density changes linearly (which <a href=\"http://en.wikipedia.org/wiki/Milky_Way#Size\">Wikipedia</a> says is roughly true), from x stars/sq. light year at its center, to 0 at 50K light-years out, so that the density at radius <em>r</em> light-years is x(50,000-r).&nbsp; We then have that the integral over r = 0 to 50K of 2&pi;rx(50000-r)dr = 100 billion, 2&pi;x(50000&int;rdr - &int;r<sup>2</sup>dr) = 100 billion, x = 100 billion / 2&pi;(50000&int;rdr - &int;r<sup>2</sup>dr) = 100 billion / &pi;[(50000r<sup>2</sup> - 2r<sup>3</sup>/3) from r=0 to 50K = &pi;(50000(50000)<sup>2</sup> - 2(50000)<sup>3</sup>/3) = 50000<sup>3</sup>&pi;(1 - 2/3)] = 100 billion / 130900 billion = .0007639.</p>\n<p>We expand from the center at light speed, so our radius at time t (in years) is t light-years.&nbsp; The additional area enclosed in time dt is 2&pi;tdt, which contains 2&pi;tx(50000-t)dt stars.</p>\n<p>Suppose that we are optimized from the start, so that expected utility at time t is proportional to number of stars consumed at time t.&nbsp; Suppose, in a fit of wild optimism, that our resource usage is always sustainable.&nbsp; (A better model would be that we completely burn out resources as we go, so utility at time t is simply proportional to the ring of colonization at time t.&nbsp; This would result in worrying a <em>lot</em> less about the future.)&nbsp; Total utility at time t is 2&pi;x&int;t(50000-t)dt from 0 to t = 2&pi;x(50000t<sup>2</sup>/2 - t<sup>3</sup>/3) &asymp;120t<sup>2</sup> - .0016t<sup>3</sup>.</p>\n<p>Our time discounting for utility is related to that we find empirically today, encoded in our rate of return on investment, which roughly doubles every ten years.&nbsp; Suppose that, with our Planck technology, subjective time is Y Planck-tech years = 1 Earth year, so our time discounting says that utility x at time t is worth utility x/2<sup>.1Y</sup> at time t+1.&nbsp; Thus, the utility that we, at time 0, assign to time t, with time discounting, is (120t<sup>2</sup> - .0016t<sup>3</sup>) / 2<sup>.1Yt</sup>.&nbsp; The total utility we assign to all time from now to infinity is the integral, from t=0 to infinity, of (120t<sup>2</sup> - .0016t<sup>3</sup>) / 2<sup>.1Yt</sup>.</p>\n<p>Look at that exponential, and you see where this is going.</p>\n<p>Let's be optimistic again, and drop the .0016t<sup>3</sup>, even though including it would make us worry less about the future. &lt;CORRECTION DUE TO Dreaded_Anomaly&gt; Rewrite 2<sup>.1Yt</sup> as (2<sup>.1Y</sup>)<sup>t</sup> = e<sup>at</sup>, a = .1Yln2.&nbsp; Integrate by parts to see &int;t<sup>2</sup>e<sup>-at</sup>dt = -e<sup>-at</sup>(t<sup>2</sup>/a + 2t/a<sup>2</sup> + 2/a<sup>3</sup>).&nbsp; Then &int;120t<sup>2</sup>/2<sup>.1Yt</sup>dt = 120&int;t<sup>2</sup>e<sup>-at</sup>dt = -120e<sup>-at</sup>(t<sup>2</sup>/a + 2t/a<sup>2</sup> + 2/a<sup>3</sup>) from t=0 to infinity.&lt;/CORRECTION DUE TO Dreaded_Anomaly&gt;</p>\n<p>For Y = 1 (no change in subjective time), t=0 to infinity, this is about 6006. For comparison, the integral from t=0 to 10 years is about 5805.&nbsp; Everything after the first 10 years accounts for 3.3% of total utility over all time, as viewed by us in the present.&nbsp; For Y = 100, the first 10 years account for all but 1.95 x 10<sup>-27</sup> of the total utility.</p>\n<p>What all this math shows is that, even making all our assumptions so as to unreasonably favor getting future utility quickly and having larger amounts of utility as time goes on, time discounting plus the speed of light plus the Planck limit means the future does not matter to utility maximizers.&nbsp; The exponential loss due to time-discounting always wins out over the geometric gains due to expansion through space.&nbsp; (Any space.&nbsp; Even supposing we lived in a higher-dimensional space would probably not change the results significantly.)</p>\n<p>Here are some ways of making the future matter:</p>\n<ul>\n<li>Assume that subjective time will change gradually, so that each year of real time brings in more utility than the last.</li>\n<li>Assume that the effectiveness at utilizing resources to maximize utility increases over time.</li>\n<li>ADDED, hat tip to Carl Shulman: Suppose some loophole in physics that lets us expand exponentially, whether through space, additional universes, or downward in size.</li>\n<li>ADDED: Suppose that knowledge can be gained forever at a rate that lets us increase our utility per star exponentially forever.</li>\n</ul>\n<p>The first two don't work:</p>\n<ul>\n<li>Both these processes run up against the Planck limit pretty soon.</li>\n<li>However far the colonization has gone when we run up against the Planck limit, the situation at that point will be worse (from the perspective of wanting to care about the future) than starting from Earth, since the rate of gain per year in utility divided by total utility is smaller the further out you go from the galactic core.</li>\n</ul>\n<p>So it seems that, if we maximize expected total utility with time discounting, we need not even consider expansion beyond our planet.&nbsp; Even the inevitable extinction of all life in the Universe from being restricted to one planet scarcely matters in any rational utility calculation.</p>\n<p>Among other things, this means we might not want to turn the Universe over to a rational expected-utility maximizer.</p>\n<p>I know that many of you will reflexively vote this down because you don't <em>like</em> it.&nbsp; Don't do that.&nbsp; Do the math.</p>\n<p>ADDED: This post makes it sound like not caring about the future is a bad thing.&nbsp; Caring about the future is also problematic, because the utility of the distant future then overwhelms any considerations about the present.&nbsp; For example, while a FAI that doesn't care about the future might neglect expansion into space, it won't kill 90% of the people on earth because they pose a threat during this precarious transition period.</p>\n<p>ADDED: Downvoting this is saying, \"This is not a problem\".&nbsp; And yet, most of those giving their reasons for downvoting have no arguments against the math.</p>\n<ul>\n<li>If you do the math, and you find you don't like the outcome, that does not prove that your time-discounting is not exponential.&nbsp; There are strong reasons for believing that time-discounting is exponential; whereas having a <em>feeling</em> that you hypothetically care about the future is not especially strong evidence that your utility function is shaped in a way that makes you care about the future, or that you will in fact act as if you cared about the future.&nbsp; There are many examples where people's reactions to described scenarios do not match utility computations!&nbsp; You are reading LessWrong; you should be able to come up with a half-dozen off the top of your head.&nbsp; When your gut instincts disagree with your utility computations, it is usually evidence that you are being irrational, not proof that your utility computations are wrong.</li>\n<li>I am fully aware that saying \"we might not want to turn the Universe over to a rational expected-utility maximizer\" shows I am defying my utility calculations.&nbsp; I am not a fully-rational expectation maximizer.&nbsp; My actions do not constitute a mathematical proof; even less, my claims in the abstract about what my actions would be.&nbsp; Everybody <em>thinks</em> they care about the future; yet few act as if they do.</li>\n<li>The consequences are large enough that it is not wise to say, \"We can dispense with this issue by changing our time-discounting function\".&nbsp; It is possible that exponential time-discounting is right, and caring about the future is right, and that there is some subtle third factor that we have not thought of that works around this.&nbsp; We should spend some time looking for this answer, rather than trying to dismiss the problem as quickly as possible.</li>\n<li>Even if you conclude that this proves that we must be careful to design an AI that does not use exponential time-discounting, downvoting this topic is a way of saying, \"It's okay to ignore or forget this fact even though this may lead to the destruction of all life in the universe.\"&nbsp; Because the default assumption is that time-discounting is exponential.&nbsp; If you conclude, \"Okay, we need to not use an exponential function in order to not kill ourselves\", you should upvote this topic for leading you to that important conclusion.</li>\n<li>Saying, \"Sure, a rational being might let all life in the Universe die out; but I'm going to try to bury this discussion and ignore the problem because the way you wrote it sounds whiny\" is... suboptimal.</li>\n<li>I care about whether this topic is voted up or down because I care (or at least think I care) about the fate of the Universe.&nbsp; Each down-vote is an action that makes it more likely that we will destroy all life in the Universe, and it is legitimate and right for me to argue against it.&nbsp; If you'd like to give me a karma hit because I'm an ass, consider voting down <a href=\"/r/discussion/lw/5l9/religious_behaviorism/\">Religious Behaviourism</a> instead.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "d5q6vKrLopC36zttS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 8, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "7396", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 148, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LkCeA4wu8iLmetb28", "mLky3Muhqp8crS8J7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T12:41:00.881Z", "modifiedAt": null, "url": null, "title": "Liars for Jesus", "slug": "liars-for-jesus", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:06.934Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmy", "createdAt": "2009-02-28T00:36:34.416Z", "isAdmin": false, "displayName": "Swimmy"}, "userId": "pNdunthLRqh3unTry", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3Qcyy5NWrhDcHi3bu/liars-for-jesus", "pageUrlRelative": "/posts/3Qcyy5NWrhDcHi3bu/liars-for-jesus", "linkUrl": "https://www.lesswrong.com/posts/3Qcyy5NWrhDcHi3bu/liars-for-jesus", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Liars%20for%20Jesus&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALiars%20for%20Jesus%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Qcyy5NWrhDcHi3bu%2Fliars-for-jesus%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Liars%20for%20Jesus%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Qcyy5NWrhDcHi3bu%2Fliars-for-jesus", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Qcyy5NWrhDcHi3bu%2Fliars-for-jesus", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 128, "htmlBody": "<p>This should be of interest to a few members of this forum: Chris Rodda has made her book, Liars for Jesus, <a href=\"http://www.liarsforjesus.com/downloads/LFJ_FINAL.pdf\">available for free online</a> (pdf). The book is a debunking of modern revisionist histories written by authors like David Barton and Gary DeMar. Topics range from the obvious (no, Jefferson was not an evangelical Christian) to the less obvious (no, the Northwest Ordinance was not widely used to encourage religious teaching in public schools). It's a useful resource for those who, like me, are not well-educated in history. It also works as a case study of confirmation bias: chapter after chapter shows that the evidence for many of the revisionist claims is based on passages taken out of both literary and historical context, thus ignoring relevant counterevidence.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3Qcyy5NWrhDcHi3bu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 2, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "7397", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T13:04:39.613Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Archimedes's Chronophone", "slug": "seq-rerun-archimedes-s-chronophone", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:01.759Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pAFpKFjwWhjt4rPhT/seq-rerun-archimedes-s-chronophone", "pageUrlRelative": "/posts/pAFpKFjwWhjt4rPhT/seq-rerun-archimedes-s-chronophone", "linkUrl": "https://www.lesswrong.com/posts/pAFpKFjwWhjt4rPhT/seq-rerun-archimedes-s-chronophone", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Archimedes's%20Chronophone&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Archimedes's%20Chronophone%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAFpKFjwWhjt4rPhT%2Fseq-rerun-archimedes-s-chronophone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Archimedes's%20Chronophone%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAFpKFjwWhjt4rPhT%2Fseq-rerun-archimedes-s-chronophone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAFpKFjwWhjt4rPhT%2Fseq-rerun-archimedes-s-chronophone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 212, "htmlBody": "<p>Today's post, <a href=\"/lw/h5/archimedess_chronophone/\">Archimedes's Chronophone</a> was originally published on March 23, 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Imagine that Archimedes of Syracuse invented a device that allows you to talk to him. Imagine the possibilities for improving history! Unfortunately, the device will not literally transmit your words - it transmits cognitive strategies. If you advise giving women the vote, it comes out as advising finding a wise tyrant, the Greek ideal of political discourse. Under such restrictions, what do you say to Archimedes? In other words, how can you communicate general thinking patterns which will lead to right answers, as opposed to cached content?</blockquote>\n<p><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/5pa/seq_rerun_useless_medical_disclaimers/\">Useless Medical Disclaimers</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pAFpKFjwWhjt4rPhT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 7.149790483553074e-07, "legacy": true, "legacyId": "7398", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cKrgy7hLdszkse2pq", "yk3iTgsFgjG3ZjES5", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T19:27:50.929Z", "modifiedAt": null, "url": null, "title": "Recovering Insufferable Genius (working title)", "slug": "recovering-insufferable-genius-working-title", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.959Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raw_Power", "createdAt": "2010-09-10T23:59:43.621Z", "isAdmin": false, "displayName": "Raw_Power"}, "userId": "kwSqcED9qTanFyNWG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9FmkWWG9u9AYtKCiS/recovering-insufferable-genius-working-title", "pageUrlRelative": "/posts/9FmkWWG9u9AYtKCiS/recovering-insufferable-genius-working-title", "linkUrl": "https://www.lesswrong.com/posts/9FmkWWG9u9AYtKCiS/recovering-insufferable-genius-working-title", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recovering%20Insufferable%20Genius%20(working%20title)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecovering%20Insufferable%20Genius%20(working%20title)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9FmkWWG9u9AYtKCiS%2Frecovering-insufferable-genius-working-title%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recovering%20Insufferable%20Genius%20(working%20title)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9FmkWWG9u9AYtKCiS%2Frecovering-insufferable-genius-working-title", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9FmkWWG9u9AYtKCiS%2Frecovering-insufferable-genius-working-title", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 744, "htmlBody": "<p>So, I was on TV Tropes creating an article, and I thought maybe you guys could help me add fictional as well as notable Real Life examples to the trope. Here's a copy of <a title=\"the original stub\" href=\"http://tvtropes.org/pmwiki/discussion.php?id=kfz9vamok5wmmepkcyh8h8qh\">the description</a>:</p>\n<p style=\"padding-left: 30px;\">Some kids who are more intelligent than other kids the same age might grow up <a class=\"urllink\" href=\"http://tvtropes.org/pmwiki/discussion.php?id=puzpnmcsfooq1sfzo5sdzqg3\">acting their intellectual age</a>, forsaking interaction with other children their age which they deem to be boring and unfulfilling, if not <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IntelligenceEqualsIsolation\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IntelligenceEqualsIsolation\">outright painful</a> or worse. This can be especially bad if they make a habit of <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/TheSnarkKnight\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/TheSnarkKnight\">pointing out to other kids what they think they are doing wrong</a>, <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ElephantsChild\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ElephantsChild\">asking uncomfortable questions</a>, or <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InsufferableGenius\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InsufferableGenius\">acting smug and superior.</a> Instead, they prefer the company of books which can either efficiently and consistenty entertain them either by allowing them to <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/Escapism\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/Escapism\">escape the dreary world they think they live in</a> or by actually answering their questions, or that of adults who can actually teach them stuff and provide an interesting feedback.</p>\n<p style=\"padding-left: 30px;\">When those kids grow up they might end up being very disappointed by those adult figures they used to respect enough to discuss stuff with. If they have outgrown the <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InsufferableGenius\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InsufferableGenius\">Insufferable Genius</a> phase they might go through a backlash face where they undertake <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ManChild\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ManChild\">Man Child</a> activities as they rediscover (oftentimes with the aid of scientific material) how to interact with the vast majority of mankind <em>as well as</em> their peers[[hottip:*:these characters tend to be as different from each other as they are from the mainstream, connecting through each other through common interests, often of a geeky nature, or through work]]. Having no practice, no natural social skills, they can still become fascinated with societal behavior, and actively strive to learn a lot about them, in a quest to feel <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IJustWantToBeNormal\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IJustWantToBeNormal\">\"together\" with everyone else</a> and <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IJustWantToBeLoved\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IJustWantToBeLoved\">to be loved and appreciated</a> for who they are. Cognitive Sciences are a very favoured way for them to understand <em>how</em> people behave in ways that don't seem to make any sense, and learn some humility on the way. Evolutionary Psychology helps them understand that there is a perfectly good reason these systematic errors were hardwired into the human brain. Pick Up Arts are they way they try to apply that knowledge to succeed in their romantic lives, or at least to understand exactly why they don't and others do. There's also other fields of psychology and sociology, political sciences, economics, graphology, neurolinguistic programming, body language.., However, it's all book knowledge, and these characters are usually poor at application, at least until the get more practice done. And there are rather big holes in their knowledge.<a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InnocentlyInsensitive\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InnocentlyInsensitive\">They might genuinely not realize how rude they can be</a>. However, given that they tend to have few friends and that it often took them much effort to <em>acquire</em> said friends, <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/AFriendInNeed\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/AFriendInNeed\">you can expect them to be fiercely loyal and supportive to them</a>, Characters who achieve success in their journey might become <a class=\"createlink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/AGentlemanAndAScholar\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/AGentlemanAndAScholar\">A Gentleman/Lady And A Scholar</a>. Examples:</p>\n<ul style=\"padding-left: 30px;\">\n<li>Amy Farrah Fowler from <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/TheBigBangTheory\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/TheBigBangTheory\">The Big Bang Theory</a> is this trope incarnate, and is an interesting foil to <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InsufferableGenius\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/InsufferableGenius\">Insufferable Genius</a> <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/AmbiguouslyAutistic\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/AmbiguouslyAutistic\">Ambiguously Autistic</a> <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/JerkAss\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/JerkAss\">Jerk Ass</a> <a class=\"createlink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/SheldonCooper\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/SheldonCooper\">Sheldon Cooper</a> who despises all of the rest of humanity and wants no part of it, yet always wants to assume roles of leadership and be obeyed and followed by all those unworthy people. Many other characters in the series struggle with this. </li>\n<li><a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/PrometheanTheCreated\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/PrometheanTheCreated\">Promethean The Created</a>'s <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IJustWantToBeHuman\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/IJustWantToBeHuman\">Pilgrinage</a> shares some themes with this trope, to the point one might wonder if it isn't a metaphor. </li>\n<li><a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/GeniusTheTransgression\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/GeniusTheTransgression\">Genius The Transgression</a>'s main, overarching theme can be said to be that this trope is doomed to a <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ForegoneConclusion\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ForegoneConclusion\">Foregone Conclusion</a> of complete and utter failure sooner or later, and the bitterness that resutls from this. </li>\n<li>The <a class=\"twikilink\" title=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/LessWrong\" href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/LessWrong\">Less Wrong</a> blog seems to have this as part of its interests. <a class=\"urllink\" href=\"/lw/4su/how_to_be_happy\">It even provides an answer to \"How To Be Happy\", based on a number of scientific studies</a>. </li>\n</ul>\n<p>&nbsp;</p>\n<p>I mentioned this place by name because I got the impression many guys here do fit this trope to an extent. As such, I'm sure you'd have paid more attention than others to fictional embodiments of the trope. I also think it'd be interesting fodder for discussion. I apologize in advance if the article is inadvertently offensive: I tend to be Innocently Insensitive myself, and would gladly welcome help to improve on this article's accuracy and range.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9FmkWWG9u9AYtKCiS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 6, "extendedScore": null, "score": 7.150902448218369e-07, "legacy": true, "legacyId": "7399", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZbgCx2ntD5eu8Cno9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-15T21:31:46.969Z", "modifiedAt": null, "url": null, "title": "Group of Latter Day Roleplayers", "slug": "group-of-latter-day-roleplayers", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.251Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FvKmcH2M92wmweeGE/group-of-latter-day-roleplayers", "pageUrlRelative": "/posts/FvKmcH2M92wmweeGE/group-of-latter-day-roleplayers", "linkUrl": "https://www.lesswrong.com/posts/FvKmcH2M92wmweeGE/group-of-latter-day-roleplayers", "postedAtFormatted": "Sunday, May 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20of%20Latter%20Day%20Roleplayers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20of%20Latter%20Day%20Roleplayers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFvKmcH2M92wmweeGE%2Fgroup-of-latter-day-roleplayers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20of%20Latter%20Day%20Roleplayers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFvKmcH2M92wmweeGE%2Fgroup-of-latter-day-roleplayers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFvKmcH2M92wmweeGE%2Fgroup-of-latter-day-roleplayers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<p>The <a href=\"http://en.wikipedia.org/wiki/Society_for_Creative_Anachronism\">Society for Creative Anachronism</a>&nbsp;started as a backyard graduation party for a medieval studies student&nbsp;and grew to 32,000 members as of 2008. Does anyone have any insight into how that happened? Of particular interest would be any intersection&nbsp;between&nbsp;the SCA's mode of growth and the usual modes of growth of religions (keeping in mind that not every intersection would be worth incorporating into a strategy for raising the sanity waterline by spreading LW-style ideas and approaches).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FvKmcH2M92wmweeGE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 7.15126215430398e-07, "legacy": true, "legacyId": "7400", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T00:37:51.786Z", "modifiedAt": null, "url": null, "title": "Coercion is far", "slug": "coercion-is-far", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:03.411Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "saliency", "createdAt": "2009-10-25T03:59:58.587Z", "isAdmin": false, "displayName": "saliency"}, "userId": "RNx6ydjKM2J3Heae3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EcbQ4HMr84JnwEHfM/coercion-is-far", "pageUrlRelative": "/posts/EcbQ4HMr84JnwEHfM/coercion-is-far", "linkUrl": "https://www.lesswrong.com/posts/EcbQ4HMr84JnwEHfM/coercion-is-far", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Coercion%20is%20far&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACoercion%20is%20far%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEcbQ4HMr84JnwEHfM%2Fcoercion-is-far%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Coercion%20is%20far%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEcbQ4HMr84JnwEHfM%2Fcoercion-is-far", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEcbQ4HMr84JnwEHfM%2Fcoercion-is-far", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 144, "htmlBody": "<p>I was in the subway about a month ago when saw an advert for a new show The Bourgeoisie. &nbsp;While waiting for my train I thought about the families patriarch and the control he probably exerted over family members. &nbsp;I imagined the clich&eacute; of the daughter forced into a marriage for political advantage. &nbsp;I thought about the sacrifice for the greater good of the family that she would be coerced into making and thought how it is easier to force others to sacrifice then to sacrifice yourself. &nbsp;I thought that coercion may be one of the mechanisms that have enabled humans to engage and execute long term plans. &nbsp;If the immediate short-term costs are what most often repress long-term action then those not saddled with the short-term costs of their long-term actions will be prone to engage in more long-term action. &nbsp;<strong>Coercion is far.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EcbQ4HMr84JnwEHfM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -9, "extendedScore": null, "score": 7.151802294097859e-07, "legacy": true, "legacyId": "7401", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T00:58:33.790Z", "modifiedAt": null, "url": null, "title": "Probability updating question - 99.9999% chance of tails, heads on first flip", "slug": "probability-updating-question-99-9999-chance-of-tails-heads", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.995Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nuckingfutz", "createdAt": "2011-02-01T01:42:19.997Z", "isAdmin": false, "displayName": "nuckingfutz"}, "userId": "Syn8dZowAHPL68psE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J8gTcrhTLN5pbvJ8S/probability-updating-question-99-9999-chance-of-tails-heads", "pageUrlRelative": "/posts/J8gTcrhTLN5pbvJ8S/probability-updating-question-99-9999-chance-of-tails-heads", "linkUrl": "https://www.lesswrong.com/posts/J8gTcrhTLN5pbvJ8S/probability-updating-question-99-9999-chance-of-tails-heads", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Probability%20updating%20question%20-%2099.9999%25%20chance%20of%20tails%2C%20heads%20on%20first%20flip&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProbability%20updating%20question%20-%2099.9999%25%20chance%20of%20tails%2C%20heads%20on%20first%20flip%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ8gTcrhTLN5pbvJ8S%2Fprobability-updating-question-99-9999-chance-of-tails-heads%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Probability%20updating%20question%20-%2099.9999%25%20chance%20of%20tails%2C%20heads%20on%20first%20flip%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ8gTcrhTLN5pbvJ8S%2Fprobability-updating-question-99-9999-chance-of-tails-heads", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ8gTcrhTLN5pbvJ8S%2Fprobability-updating-question-99-9999-chance-of-tails-heads", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 127, "htmlBody": "<p>This isn't intended as a full&nbsp;discussion, I'm just a little fuzzy on how a&nbsp;Bayesian&nbsp;update or any other kind of probability update would work in this situation.</p>\n<p>You have a coin with a 99.9999% chance of coming up tails, and a 100% chance of coming up either tails or heads.</p>\n<p>You've deduced these odds by studying the weight of the coin. You are 99% confident of your results. You have not yet flipped it.</p>\n<p>You have no other information before flipping the coin.</p>\n<p>You flip the coin once. It comes up heads.</p>\n<p>How would you update your probability estimates?</p>\n<p>&nbsp;</p>\n<p>(this isn't a homework assignment; rather I was discussing with someone how strong the anthropic principle is. Unfortunately my mathematic abilities can't quite comprehend how to assemble this into any form I can work with.)</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J8gTcrhTLN5pbvJ8S", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.151862385063468e-07, "legacy": true, "legacyId": "7402", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T04:23:39.390Z", "modifiedAt": null, "url": null, "title": "Houston Hackerspace Meetup: Sunday May 22, 5:00PM", "slug": "houston-hackerspace-meetup-sunday-may-22-5-00pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:08.490Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cog", "createdAt": "2011-04-25T04:58:53.803Z", "isAdmin": false, "displayName": "Cog"}, "userId": "xkp87vCZ56dp2tWnN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sMM6km5Np42EghAtY/houston-hackerspace-meetup-sunday-may-22-5-00pm", "pageUrlRelative": "/posts/sMM6km5Np42EghAtY/houston-hackerspace-meetup-sunday-may-22-5-00pm", "linkUrl": "https://www.lesswrong.com/posts/sMM6km5Np42EghAtY/houston-hackerspace-meetup-sunday-may-22-5-00pm", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Houston%20Hackerspace%20Meetup%3A%20Sunday%20May%2022%2C%205%3A00PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHouston%20Hackerspace%20Meetup%3A%20Sunday%20May%2022%2C%205%3A00PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsMM6km5Np42EghAtY%2Fhouston-hackerspace-meetup-sunday-may-22-5-00pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Houston%20Hackerspace%20Meetup%3A%20Sunday%20May%2022%2C%205%3A00PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsMM6km5Np42EghAtY%2Fhouston-hackerspace-meetup-sunday-may-22-5-00pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsMM6km5Np42EghAtY%2Fhouston-hackerspace-meetup-sunday-may-22-5-00pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 193, "htmlBody": "<p style=\"margin-bottom: 0in;\"><em>Sunday May 22, 5:00PM</em></p>\n<p style=\"margin-bottom: 0in;\"><em>TX/RX Hackerspace</em></p>\n<p style=\"margin-bottom: 0in;\"><em>2010 Commerce St</em></p>\n<p style=\"margin-bottom: 0in;\"><em>Houston, TX 77002</em></p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><strong>Goals:</strong></p>\n<p style=\"margin-bottom: 0in;\">In general, to become more awesome. In specific, to learn about cognitive biases as a group, figure out how to become less wrong, and have fun while doing it. We also may experiment with integrating a hackerspace, which already has several lesswrongians, into the group. The first meeting will mostly be a meet and greet to establish future directions, with perhaps a video lecture and discussion on cognitive biases depending on the time constraints of the people who come. The door to the building will have a sign marked Less Wrong, and the nearby empty lot can be used for parking.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">Dvorak, a thus far much more active member in the community, will be providing me with support in organizing the group.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><strong>Edit:</strong></p>\n<p style=\"margin-bottom: 0in;\">There will be pizza. Also, a pictoral view</p>\n<p><img src=\"http://images.lesswrong.com/t3_5pp_1.png\" alt=\"Front\" width=\"645\" height=\"470\" /></p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">This is the set of buildings that the hackerspace is in. It's difficult to see our front from this angle - unfortunately google maps decided to map everything but our little section of commerce street. It's near where the white truck and red motorcycle are.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><img src=\"http://images.lesswrong.com/t3_5pp_0.png\" alt=\"Empy Lot\" width=\"644\" height=\"465\" /></p>\n<p style=\"margin-bottom: 0in;\">And this is the empty lot that you can park in.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">For more reference:</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">http://maps.google.com/maps?client=ubuntu&amp;channel=fs&amp;q=2010+Commerce+St.+Houston,+Tx+77002&amp;oe=utf-8&amp;um=1&amp;ie=UTF-8&amp;hq=&amp;hnear=0x8640bed8ed95625d:0x4c9af214d2032035,2010+Commerce+St,+Houston,+TX+77002&amp;gl=us&amp;ei=C9LRTYHvE8fL0QGu8OjlCw&amp;sa=X&amp;oi=geocode_result&amp;ct=title&amp;resnum=1&amp;ved=0CBkQ8gEwAA</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sMM6km5Np42EghAtY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 7.152457806795085e-07, "legacy": true, "legacyId": "7405", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p style=\"margin-bottom: 0in;\"><em>Sunday May 22, 5:00PM</em></p>\n<p style=\"margin-bottom: 0in;\"><em>TX/RX Hackerspace</em></p>\n<p style=\"margin-bottom: 0in;\"><em>2010 Commerce St</em></p>\n<p style=\"margin-bottom: 0in;\"><em>Houston, TX 77002</em></p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><strong id=\"Goals_\">Goals:</strong></p>\n<p style=\"margin-bottom: 0in;\">In general, to become more awesome. In specific, to learn about cognitive biases as a group, figure out how to become less wrong, and have fun while doing it. We also may experiment with integrating a hackerspace, which already has several lesswrongians, into the group. The first meeting will mostly be a meet and greet to establish future directions, with perhaps a video lecture and discussion on cognitive biases depending on the time constraints of the people who come. The door to the building will have a sign marked Less Wrong, and the nearby empty lot can be used for parking.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">Dvorak, a thus far much more active member in the community, will be providing me with support in organizing the group.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><strong id=\"Edit_\">Edit:</strong></p>\n<p style=\"margin-bottom: 0in;\">There will be pizza. Also, a pictoral view</p>\n<p><img src=\"http://images.lesswrong.com/t3_5pp_1.png\" alt=\"Front\" width=\"645\" height=\"470\"></p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">This is the set of buildings that the hackerspace is in. It's difficult to see our front from this angle - unfortunately google maps decided to map everything but our little section of commerce street. It's near where the white truck and red motorcycle are.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><img src=\"http://images.lesswrong.com/t3_5pp_0.png\" alt=\"Empy Lot\" width=\"644\" height=\"465\"></p>\n<p style=\"margin-bottom: 0in;\">And this is the empty lot that you can park in.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">For more reference:</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">http://maps.google.com/maps?client=ubuntu&amp;channel=fs&amp;q=2010+Commerce+St.+Houston,+Tx+77002&amp;oe=utf-8&amp;um=1&amp;ie=UTF-8&amp;hq=&amp;hnear=0x8640bed8ed95625d:0x4c9af214d2032035,2010+Commerce+St,+Houston,+TX+77002&amp;gl=us&amp;ei=C9LRTYHvE8fL0QGu8OjlCw&amp;sa=X&amp;oi=geocode_result&amp;ct=title&amp;resnum=1&amp;ved=0CBkQ8gEwAA</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>", "sections": [{"title": "Goals:", "anchor": "Goals_", "level": 1}, {"title": "Edit:", "anchor": "Edit_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "12 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T06:28:37.021Z", "modifiedAt": null, "url": null, "title": "Conceptual Analysis and Moral Theory", "slug": "conceptual-analysis-and-moral-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:38.286Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "lukeprog", "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2YPbdHgcjt7g5ZaFN/conceptual-analysis-and-moral-theory", "pageUrlRelative": "/posts/2YPbdHgcjt7g5ZaFN/conceptual-analysis-and-moral-theory", "linkUrl": "https://www.lesswrong.com/posts/2YPbdHgcjt7g5ZaFN/conceptual-analysis-and-moral-theory", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Conceptual%20Analysis%20and%20Moral%20Theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConceptual%20Analysis%20and%20Moral%20Theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2YPbdHgcjt7g5ZaFN%2Fconceptual-analysis-and-moral-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Conceptual%20Analysis%20and%20Moral%20Theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2YPbdHgcjt7g5ZaFN%2Fconceptual-analysis-and-moral-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2YPbdHgcjt7g5ZaFN%2Fconceptual-analysis-and-moral-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2469, "htmlBody": "<p>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics</a>. Also see: <a href=\"http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words\">A Human&#x27;s Guide to Words</a>.</p><p>If a tree falls in the forest, and no one hears it, does it make a sound?</p><blockquote>Albert:  &quot;Of course it does.  What kind of silly question is that?  Every time I&#x27;ve listened to a tree fall, it made a sound, so I&#x27;ll guess that other trees falling also make sounds.  I don&#x27;t believe the world changes around when I&#x27;m not looking.&quot;</blockquote><p>Barry:  &quot;Wait a minute. If no one hears it, how can it be a sound?&quot;</p><p>Albert and Barry are <a href=\"https://www.lesserwrong.com/lw/np/disputing_definitions/\">not arguing about facts</a>, but <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">about definitions</a>:</p><blockquote>...the first person is speaking as if &#x27;sound&#x27; means acoustic vibrations in the air; the second person is speaking as if &#x27;sound&#x27; means an auditory experience in a brain.  If you ask &quot;Are there acoustic vibrations?&quot; or &quot;Are there auditory experiences?&quot;, the answer is at once obvious. And so the argument is really about the definition of the word &#x27;sound&#x27;.</blockquote><p>Of course, Albert and Barry <em>could</em> argue back and forth about which definition best fits their intuitions about the meaning of the word. Albert <a href=\"https://www.lesserwrong.com/lw/np/disputing_definitions/\">could</a> offer this argument in favor of using his definition of sound:</p><blockquote>My computer&#x27;s microphone can record a sound without anyone being around to hear it, store it as a file, and it&#x27;s called a &#x27;sound file&#x27;. And what&#x27;s stored in the file is the pattern of vibrations in air, not the pattern of neural firings in anyone&#x27;s brain. &#x27;Sound&#x27; means a pattern of vibrations.</blockquote><p>Barry might retort:</p><blockquote>Imagine some aliens on a distant planet. They haven&#x27;t evolved any organ that translates vibrations into neural signals, but they still hear sounds inside their own head (as an evolutionary biproduct of some other evolved cognitive mechanism). If these creatures seem metaphysically possible to you, then this shows that our concept of &#x27;sound&#x27; is not dependent on patterns of vibrations.</blockquote><p>If their debate seems silly to you, I have sad news. A large chunk of moral philosophy looks like this. What Albert and Barry are doing is what philosophers call <a href=\"http://en.wikipedia.org/wiki/Conceptual_analysis\">conceptual analysis</a>.1</p><h1>The trouble with conceptual analysis</h1><p>I won&#x27;t argue that <em>everything</em> that has ever been called &#x27;conceptual analysis&#x27; is misguided.2 Instead, I&#x27;ll give <em>examples</em> of common kinds of conceptual analysis that corrupt discussions of morality and other subjects.</p><p>The following paragraph explains succinctly what is wrong with much conceptual analysis:</p><blockquote>Analysis [had] one of two reputations. On the one hand, there was sterile cataloging of pointless folk wisdom - such as articles analyzing the concept VEHICLE, wondering whether something could be a vehicle without wheels. This seemed like trivial lexicography. On the other hand, there was metaphysically loaded analysis, in which ontological conclusions were established by holding fixed pieces of folk wisdom - such as attempts to refute general relativity by holding fixed allegedly conceptual truths, such as the idea that motion is intrinsic to moving things, or that there is an objective present.3</blockquote><p>Consider even the &#x27;naturalistic&#x27; kind of conceptual analysis practiced by Timothy Schroeder in <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three Faces of Desire</a></em>. In private correspondance, I tried to clarify Schroeder&#x27;s project:</p><blockquote>As I see it, [your book] seeks the cleanest reduction of the folk psychological term &#x27;desire&#x27; to a natural kind, ala the reduction of the folk chemical term &#x27;water&#x27; to H2O. To do this, you employ a naturalism-flavored method of conceptual analysis according to which the best theory of desire is one that is logically consistent, fits the empirical facts, and captures how we use the term and our intuitions about its meaning.</blockquote><p>Schroeder confirmed this, and it&#x27;s not hard to see the motivation for his project. We have this concept &#x27;desire&#x27;, and we might like to know: &quot;Is there anything in the world similar to what we mean by &#x27;desire&#x27;?&quot; Science can answer the &quot;is there anything&quot; part, and intuition (supposedly) can answer the &quot;what we mean by&quot; part.</p><p>The trouble is that philosophers often take this &quot;what we mean by&quot; question so seriously that thousands of pages of debate concern <em>which definition to use</em> rather than <em>which facts are true</em> and <a href=\"https://www.lesserwrong.com/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">what to anticipate</a>.</p><p>In one chapter, Schroeder offers 8 objections4 to a popular conceptual analysis of &#x27;desire&#x27; called the &#x27;action-based theory of desire&#x27;. Seven of these objections concern our intuitions about the meaning of the word &#x27;desire&#x27;, including one which asks us to imagine the existence of alien life forms that have desires about the weather but have no dispositions to act to affect the weather. If our intuitions tell us that such creatures are metaphysically possible, goes the argument, then our concept of &#x27;desire&#x27; need not be linked to dispositions to act.</p><p>Contrast this with a conversation you might have with someone from the <a href=\"http://intelligence.org/\">Singularity Institute</a>. Within <em>20 seconds</em> of arguing about the definition of &#x27;desire&#x27;, someone will say, &quot;Screw it. <a href=\"https://www.lesserwrong.com/lw/nu/taboo_your_words/\">Taboo</a> &#x27;desire&#x27; so we can argue about facts and anticipations, not definitions.&quot;5</p><h1>Disputing definitions</h1><p>Arguing about definitions is not <em>always</em> misguided. <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">Words can be wrong</a>:</p><blockquote>When the philosophers of Plato&#x27;s Academy claimed that the best definition of a human was a &quot;featherless biped&quot;, Diogenes the Cynic is said to have exhibited a plucked chicken and declared &quot;Here is Plato&#x27;s Man.&quot; The Platonists promptly changed their definition to &quot;a featherless biped with broad nails.&quot;</blockquote><p>Likewise, if I give a lecture on correlations between income and subjective well-being and I conclude by saying, &quot;And <em>that</em>, ladies and gentlemen, is my theory of the atom,&quot; then you have some reason to object. Nobody else uses the term &#x27;atom&#x27; to mean anything remotely like what I&#x27;ve just discussed. If I ever do that, I hope you <em>will</em> argue that my definition of &#x27;morality&#x27; is &#x27;wrong&#x27; (or unhelpful, or confusing, or something).</p><p>Some unfortunate words are used in a <em>wide</em> variety of vague and ambiguous ways.6 Moral terms are among these. As one example, consider some commonly used definitions for &#x27;morally good&#x27;:</p><ul><li>that which produces the most pleasure for the most people</li><li>that which is in accord with the divine will</li><li>that which adheres to a certain list of rules</li><li>that which the speaker&#x27;s intuitions approve of in a state of reflective equilibrium</li><li>that which the speaker generally approves of</li><li>that which our culture generally approves of</li><li>that which our species generally approves of</li><li>that which we would approve of if we were fully informed and perfectly rational</li><li>that which adheres to the policies we would vote to enact from behind a veil of ignorance</li><li>that which does not violate the concept of our personhood</li><li>that which resists entropy for as long as possible</li></ul><p>Often, people can&#x27;t tell you what they mean by moral terms when you question them. There is little hope of taking a survey to decide what moral terms &#x27;typically mean&#x27; or &#x27;<em>really</em> mean&#x27;. The problem may be worse for moral terms than for (say) art terms. Moral terms have more powerful connotations than art terms, and are thus a greater attractor for <a href=\"https://www.lesserwrong.com/lw/ny/sneaking_in_connotations/\">sneaking in connotations</a>. Moral terms are used to persuade. &quot;It&#x27;s just <em>wrong</em>!&quot; the moralist cries, &quot;I don&#x27;t <em>care</em> what definition you&#x27;re using right now. It&#x27;s <em>just wrong</em>: don&#x27;t do it.&quot;</p><p>Moral discourse is rife with <a href=\"http://wiki.lesswrong.com/wiki/Motivated_cognition\">motivated cognition</a>. This is part of why, I suspect, people resist dissolving moral debates even while they have no trouble <a href=\"https://www.lesserwrong.com/lw/np/disputing_definitions/\">dissolving</a> the &#x27;tree falling in a forest&#x27; debate.</p><h2>Disputing the definitions of moral terms</h2><p>So much moral philosophy is consumed by debates over definitions that I will skip to an example from someone you might hope would know better: reductionist Frank Jackson7:</p><blockquote>...if Tom tells us that what he means by a right action is one in accord with God&#x27;s will, rightness according to Tom is being in accord with God&#x27;s will. If Jack tells us that what he means by a right action is maximizing expected value as measured in hedons, then, for Jack, rightness is maximizing expected value...</blockquote><p>But if we wish to address the concerns of our fellows when we discuss the matter - and if we don&#x27;t, we will not have much of an audience - we had better mean what they mean. We had better, that is, identify our subject via the folk theory of rightness, wrongness, goodness, badness, and so on. We need to identify rightness as the property that satisfies, or near enough satisfies, the folk theory of rightness - and likewise for the other moral properties. It is, thus, folk theory that will be our guide in identifying rightness, goodness, and so on.8</p><p>The meanings of moral terms, says Jackson, are given by their place in a network of platitudes (&#x27;clauses&#x27;) from folk moral discourse:</p><blockquote>The input clauses of folk morality tell us what kinds of situations described in descriptive, non-moral terms warrant what kinds of description in ethical terms: if an act is an intentional killing, then normally it is wrong; pain is bad; &#x27;I cut, you choose&#x27; is a fair procedure; and so on. </blockquote><blockquote>The internal role clauses of folk morality articulate the interconnections between matters described in ethical, normative language: courageous people are more likely to do what is right than cowardly people; the best option is the right option; rights impose duties of respect; and so on. </blockquote><blockquote>The output clauses of folk morality take us from ethical judgements to facts about motivation and thus behaviour: the judgement that an act is right is normally accompanied by at least some desire to perform the act in question; the realization that an act would be dishonest typically dissuades an agent from performing it; properties that make something good are the properties we typically have some kind of pro-attitude towards, and so on. </blockquote><blockquote>Moral functionalism, then, is the view that the meanings of the moral terms are given by their place in this network of input, output, and internal clauses that makes up folk morality.9</blockquote><p>And thus, Jackson tosses his lot into the definitions debate. Jackson supposes that we can pick out <em>which</em> platitudes of moral discourse matter, and how <em>much</em> they matter, for determining the meaning of moral terms - despite the fact that individual humans, and especially groups of humans, are <em>themselves</em> confused about the meanings of moral terms, and which platitudes of moral discourse should &#x27;matter&#x27; in fixing their meaning.</p><p>This is a debate about definitions that will never end.</p><h2>Austere Metaethics vs. Empathic Metaethics</h2><p>In the next post, we&#x27;ll dissolve standard moral debates the same way Albert and Barry should have dissolved their debate about sound.</p><p>But that is only the first step. It is important to <em>not stop</em> after sweeping away the confusions of mainstream moral philosophy to arrive at mere <em>correct answers</em>. We must stare directly into the heart of the problem and <a href=\"https://www.lesserwrong.com/lw/up/shut_up_and_do_the_impossible/\">do the impossible</a>.</p><p>Consider Alex, who wants to do the &#x27;right&#x27; thing. But she doesn&#x27;t know what &#x27;right&#x27; means. Her question is: &quot;How do I do what is right if I don&#x27;t know exactly what &#x27;right&#x27; means?&quot;</p><p>The Austere Metaethicist might cross his arms and say:</p><blockquote>Tell me what you mean by &#x27;right&#x27;, and I will tell you what is the right thing to do. If by &#x27;right&#x27; you mean X, then Y is the right thing to do. If by &#x27;right&#x27; you mean P, then Z is the right thing to do. But if you can&#x27;t tell me what you mean by &#x27;right&#x27;, then you have failed to ask a coherent question, and no one can answer an incoherent question.</blockquote><p>The Empathic Metaethicist takes up a greater burden. The Empathic Metaethicist says to Alex:</p><blockquote>You may not know what you mean by &#x27;right.&#x27; You haven&#x27;t asked a coherent question. But let&#x27;s not stop there. Here, let me come alongside you and help decode the cognitive algorithms that generated your question in the first place, and then we&#x27;ll be able to answer your question. Then not only can we tell you what the right thing to do is, but also we can help bring your <em>emotions</em> <a href=\"https://www.lesserwrong.com/lw/5kn/conceptual_analysis_and_moral_theory/46yv\">into alignment with that truth</a>... as you go on to (say) help save the world rather than being filled with <a href=\"https://www.lesserwrong.com/lw/or/joy_in_the_merely_real/\">pointless</a> existential angst about the universe being <a href=\"http://arxiv.org/pdf/0905.1283\">made of math</a>.</blockquote><p>Austere metaethics is easy. Empathic metaethics is hard. But empathic metaethics is what needs to be done to answer Alex&#x27;s question, and it&#x27;s what needs to be done to build a <a href=\"http://intelligence.org/singularityfaq#WhatIsFriendlyAI\">Friendly AI</a>. We&#x27;ll get there in the next few posts.</p><p>Next post: <a href=\"https://www.lesserwrong.com/lw/5u2/pluralistic_moral_reductionism/\">Pluralistic Moral Reductionism</a></p><p>Previous post: <a href=\"https://www.lesserwrong.com/lw/5eh/what_is_metaethics/\">What is Metaethics?</a></p><h2>Notes</h2><p>1 Eliezer advises against reading mainstream philosophy <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3q9a\">because</a> he thinks it will &quot;teach very bad habits of thought that will lead people to be unable to do real work.&quot; Conceptual analysis is, I think, exactly that: a very bad habit of thought that renders many people unable to do real work. Also: My thanks to Eliezer for his helpful comments on an early draft of this post.</p><p>2 For example: Jackson (1998), p. 28, has a different view of conceptual analysis: &quot;conceptual analysis is the very business of addressing when and whether a story told in one vocabulary is made true by one told in some allegedly more fundamental vocabulary.&quot; For an overview of Jackson&#x27;s kind of conceptual analysis, see <a href=\"http://www.unc.edu/~ujanel/Jackson2.htm\">here</a>. Also, <a href=\"http://atheistethicist.blogspot.com/\">Alonzo Fyfe</a> reminded me that those who interpret the law must do a kind of conceptual analysis. If a law has been passed declaring that vehicles are not allowed on playgrounds, a judge must figure out whether &#x27;vehicle&#x27; includes or excludes rollerskates. More recent papers on conceptual analysis are available <a href=\"http://philpapers.org/browse/conceptual-analysis?sqc=&onlineOnly=on&cn=conceptual-analysis&showCategories=on&newWindow=on&proOnly=on&new=1&limit=100&categorizerOn=&cId=5593&publishedOnly=&hideAbstracts=&sort=pubYear&filterByAreas=&freeOnly=&start=0&format=html&jlist=&ap_c1=&ap_c2=\">at Philpapers</a>. Finally, read <a href=\"http://consc.net/constructing/chap9.pdf\">Chalmers on verbal disputes</a>.</p><p>3 Braddon-Mitchell (2008). A famous example of the first kind lies at the heart of 20th century epistemology: the definition of &#x27;knowledge.&#x27; Knowledge had long been defined as &#x27;justified true belief&#x27;, but then Gettier (1963) presented some hypothetical examples of justified true belief that many of us would <em>intuitively</em> not label as &#x27;knowledge.&#x27; Philosophers launched a cottage industry around new definitions of &#x27;knowledge&#x27; and new counterexamples to <em>those</em> definitions. Brian Weatherson called this the &quot;analysis of knowledge merry-go-round.&quot; <a href=\"https://www.lesserwrong.com/lw/5kn/conceptual_analysis_and_moral_theory/46mw\">Tyrrell McAllister</a> called it the &#x27;Gettier rabbit-hole.&#x27;</p><p>4 Schroeder (2004), pp. 15-27. Schroeder lists them as 7 objections, but I count his &#x27;trying without desiring&#x27; and &#x27;intending without desiring&#x27; objections separately.</p><p>5 Tabooing one&#x27;s words is similar to what Chalmers (2009) calls the &#x27;method of elimination&#x27;. In an earlier <a href=\"https://www.lesserwrong.com/lw/ro/2place_and_1place_words/\">post</a>, Yudkowsky used what Chalmers (2009) calls the &#x27;subscript gambit&#x27;, except Yudkowsky used underscores instead of subscripts.</p><p>6 See also Gallie (1956).</p><p>7 Eliezer <a href=\"http://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/\">said</a> that the closest thing to his metaethics from mainstream philosophy is Jackson&#x27;s &#x27;moral functionalism&#x27;, but of course moral functionalism is <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3rdb\">not quite right</a>.</p><p>8 Jackson (1998), p. 118.</p><p>9 Jackson (1998), pp. 130-131.</p><h2>References</h2><p>Braddon-Mitchell (2008). Naturalistic analysis and the a priori. In Braddon-Mitchell &amp; Nola (eds.), <em>Conceptual Analysis and Philosophical Naturalism</em> (pp. 23-43). MIT Press.</p><p>Chalmers (2009). <a href=\"http://consc.net/papers/verbal.pdf\">Verbal disputes</a>. Unpublished.</p><p>Gallie (1956). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gallie-Essentially-Contested-Concepts.pdf\">Essentially contested concepts</a>. <em>Proceedings of the Aristotelean Society, 56</em>: 167-198.</p><p>Gettier (1963). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/01/Gettier-Is-Justified-True-Belief-Knowledge.pdf\">Is justified true belief knowledge?</a> <em>Analysis, 23</em>: 121-123.</p><p>Jackson (1998). <em><a href=\"http://www.amazon.com/Metaphysics-Ethics-Defence-Conceptual-Analysis/dp/0198250614/\">From Metaphysics to Ethics: A Defense of Conceptual Analysis</a></em>. Oxford University Press.</p><p>Schroeder (2004). <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three Faces of Desire</a></em>. Oxford University Press.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Z8wZZLeLMJ3NSK7kR": 3, "FtT2T9bRbECCGYxrL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2YPbdHgcjt7g5ZaFN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 70, "baseScore": 90, "extendedScore": null, "score": 0.000171, "legacy": true, "legacyId": "7223", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "bQgRsy23biR52poMf", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "3zDX3f3QTepNeZHGc", "canonicalPrevPostSlug": "s4Mcg9aLMeRwdW7fh", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 90, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics</a>. Also see: <a href=\"http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words\">A Human's Guide to Words</a>.</p><p>If a tree falls in the forest, and no one hears it, does it make a sound?</p><blockquote>Albert:  \"Of course it does.  What kind of silly question is that?  Every time I've listened to a tree fall, it made a sound, so I'll guess that other trees falling also make sounds.  I don't believe the world changes around when I'm not looking.\"</blockquote><p>Barry:  \"Wait a minute. If no one hears it, how can it be a sound?\"</p><p>Albert and Barry are <a href=\"https://www.lesserwrong.com/lw/np/disputing_definitions/\">not arguing about facts</a>, but <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">about definitions</a>:</p><blockquote>...the first person is speaking as if 'sound' means acoustic vibrations in the air; the second person is speaking as if 'sound' means an auditory experience in a brain.  If you ask \"Are there acoustic vibrations?\" or \"Are there auditory experiences?\", the answer is at once obvious. And so the argument is really about the definition of the word 'sound'.</blockquote><p>Of course, Albert and Barry <em>could</em> argue back and forth about which definition best fits their intuitions about the meaning of the word. Albert <a href=\"https://www.lesserwrong.com/lw/np/disputing_definitions/\">could</a> offer this argument in favor of using his definition of sound:</p><blockquote>My computer's microphone can record a sound without anyone being around to hear it, store it as a file, and it's called a 'sound file'. And what's stored in the file is the pattern of vibrations in air, not the pattern of neural firings in anyone's brain. 'Sound' means a pattern of vibrations.</blockquote><p>Barry might retort:</p><blockquote>Imagine some aliens on a distant planet. They haven't evolved any organ that translates vibrations into neural signals, but they still hear sounds inside their own head (as an evolutionary biproduct of some other evolved cognitive mechanism). If these creatures seem metaphysically possible to you, then this shows that our concept of 'sound' is not dependent on patterns of vibrations.</blockquote><p>If their debate seems silly to you, I have sad news. A large chunk of moral philosophy looks like this. What Albert and Barry are doing is what philosophers call <a href=\"http://en.wikipedia.org/wiki/Conceptual_analysis\">conceptual analysis</a>.1</p><h1 id=\"The_trouble_with_conceptual_analysis\">The trouble with conceptual analysis</h1><p>I won't argue that <em>everything</em> that has ever been called 'conceptual analysis' is misguided.2 Instead, I'll give <em>examples</em> of common kinds of conceptual analysis that corrupt discussions of morality and other subjects.</p><p>The following paragraph explains succinctly what is wrong with much conceptual analysis:</p><blockquote>Analysis [had] one of two reputations. On the one hand, there was sterile cataloging of pointless folk wisdom - such as articles analyzing the concept VEHICLE, wondering whether something could be a vehicle without wheels. This seemed like trivial lexicography. On the other hand, there was metaphysically loaded analysis, in which ontological conclusions were established by holding fixed pieces of folk wisdom - such as attempts to refute general relativity by holding fixed allegedly conceptual truths, such as the idea that motion is intrinsic to moving things, or that there is an objective present.3</blockquote><p>Consider even the 'naturalistic' kind of conceptual analysis practiced by Timothy Schroeder in <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three Faces of Desire</a></em>. In private correspondance, I tried to clarify Schroeder's project:</p><blockquote>As I see it, [your book] seeks the cleanest reduction of the folk psychological term 'desire' to a natural kind, ala the reduction of the folk chemical term 'water' to H2O. To do this, you employ a naturalism-flavored method of conceptual analysis according to which the best theory of desire is one that is logically consistent, fits the empirical facts, and captures how we use the term and our intuitions about its meaning.</blockquote><p>Schroeder confirmed this, and it's not hard to see the motivation for his project. We have this concept 'desire', and we might like to know: \"Is there anything in the world similar to what we mean by 'desire'?\" Science can answer the \"is there anything\" part, and intuition (supposedly) can answer the \"what we mean by\" part.</p><p>The trouble is that philosophers often take this \"what we mean by\" question so seriously that thousands of pages of debate concern <em>which definition to use</em> rather than <em>which facts are true</em> and <a href=\"https://www.lesserwrong.com/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">what to anticipate</a>.</p><p>In one chapter, Schroeder offers 8 objections4 to a popular conceptual analysis of 'desire' called the 'action-based theory of desire'. Seven of these objections concern our intuitions about the meaning of the word 'desire', including one which asks us to imagine the existence of alien life forms that have desires about the weather but have no dispositions to act to affect the weather. If our intuitions tell us that such creatures are metaphysically possible, goes the argument, then our concept of 'desire' need not be linked to dispositions to act.</p><p>Contrast this with a conversation you might have with someone from the <a href=\"http://intelligence.org/\">Singularity Institute</a>. Within <em>20 seconds</em> of arguing about the definition of 'desire', someone will say, \"Screw it. <a href=\"https://www.lesserwrong.com/lw/nu/taboo_your_words/\">Taboo</a> 'desire' so we can argue about facts and anticipations, not definitions.\"5</p><h1 id=\"Disputing_definitions\">Disputing definitions</h1><p>Arguing about definitions is not <em>always</em> misguided. <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">Words can be wrong</a>:</p><blockquote>When the philosophers of Plato's Academy claimed that the best definition of a human was a \"featherless biped\", Diogenes the Cynic is said to have exhibited a plucked chicken and declared \"Here is Plato's Man.\" The Platonists promptly changed their definition to \"a featherless biped with broad nails.\"</blockquote><p>Likewise, if I give a lecture on correlations between income and subjective well-being and I conclude by saying, \"And <em>that</em>, ladies and gentlemen, is my theory of the atom,\" then you have some reason to object. Nobody else uses the term 'atom' to mean anything remotely like what I've just discussed. If I ever do that, I hope you <em>will</em> argue that my definition of 'morality' is 'wrong' (or unhelpful, or confusing, or something).</p><p>Some unfortunate words are used in a <em>wide</em> variety of vague and ambiguous ways.6 Moral terms are among these. As one example, consider some commonly used definitions for 'morally good':</p><ul><li>that which produces the most pleasure for the most people</li><li>that which is in accord with the divine will</li><li>that which adheres to a certain list of rules</li><li>that which the speaker's intuitions approve of in a state of reflective equilibrium</li><li>that which the speaker generally approves of</li><li>that which our culture generally approves of</li><li>that which our species generally approves of</li><li>that which we would approve of if we were fully informed and perfectly rational</li><li>that which adheres to the policies we would vote to enact from behind a veil of ignorance</li><li>that which does not violate the concept of our personhood</li><li>that which resists entropy for as long as possible</li></ul><p>Often, people can't tell you what they mean by moral terms when you question them. There is little hope of taking a survey to decide what moral terms 'typically mean' or '<em>really</em> mean'. The problem may be worse for moral terms than for (say) art terms. Moral terms have more powerful connotations than art terms, and are thus a greater attractor for <a href=\"https://www.lesserwrong.com/lw/ny/sneaking_in_connotations/\">sneaking in connotations</a>. Moral terms are used to persuade. \"It's just <em>wrong</em>!\" the moralist cries, \"I don't <em>care</em> what definition you're using right now. It's <em>just wrong</em>: don't do it.\"</p><p>Moral discourse is rife with <a href=\"http://wiki.lesswrong.com/wiki/Motivated_cognition\">motivated cognition</a>. This is part of why, I suspect, people resist dissolving moral debates even while they have no trouble <a href=\"https://www.lesserwrong.com/lw/np/disputing_definitions/\">dissolving</a> the 'tree falling in a forest' debate.</p><h2 id=\"Disputing_the_definitions_of_moral_terms\">Disputing the definitions of moral terms</h2><p>So much moral philosophy is consumed by debates over definitions that I will skip to an example from someone you might hope would know better: reductionist Frank Jackson7:</p><blockquote>...if Tom tells us that what he means by a right action is one in accord with God's will, rightness according to Tom is being in accord with God's will. If Jack tells us that what he means by a right action is maximizing expected value as measured in hedons, then, for Jack, rightness is maximizing expected value...</blockquote><p>But if we wish to address the concerns of our fellows when we discuss the matter - and if we don't, we will not have much of an audience - we had better mean what they mean. We had better, that is, identify our subject via the folk theory of rightness, wrongness, goodness, badness, and so on. We need to identify rightness as the property that satisfies, or near enough satisfies, the folk theory of rightness - and likewise for the other moral properties. It is, thus, folk theory that will be our guide in identifying rightness, goodness, and so on.8</p><p>The meanings of moral terms, says Jackson, are given by their place in a network of platitudes ('clauses') from folk moral discourse:</p><blockquote>The input clauses of folk morality tell us what kinds of situations described in descriptive, non-moral terms warrant what kinds of description in ethical terms: if an act is an intentional killing, then normally it is wrong; pain is bad; 'I cut, you choose' is a fair procedure; and so on. </blockquote><blockquote>The internal role clauses of folk morality articulate the interconnections between matters described in ethical, normative language: courageous people are more likely to do what is right than cowardly people; the best option is the right option; rights impose duties of respect; and so on. </blockquote><blockquote>The output clauses of folk morality take us from ethical judgements to facts about motivation and thus behaviour: the judgement that an act is right is normally accompanied by at least some desire to perform the act in question; the realization that an act would be dishonest typically dissuades an agent from performing it; properties that make something good are the properties we typically have some kind of pro-attitude towards, and so on. </blockquote><blockquote>Moral functionalism, then, is the view that the meanings of the moral terms are given by their place in this network of input, output, and internal clauses that makes up folk morality.9</blockquote><p>And thus, Jackson tosses his lot into the definitions debate. Jackson supposes that we can pick out <em>which</em> platitudes of moral discourse matter, and how <em>much</em> they matter, for determining the meaning of moral terms - despite the fact that individual humans, and especially groups of humans, are <em>themselves</em> confused about the meanings of moral terms, and which platitudes of moral discourse should 'matter' in fixing their meaning.</p><p>This is a debate about definitions that will never end.</p><h2 id=\"Austere_Metaethics_vs__Empathic_Metaethics\">Austere Metaethics vs. Empathic Metaethics</h2><p>In the next post, we'll dissolve standard moral debates the same way Albert and Barry should have dissolved their debate about sound.</p><p>But that is only the first step. It is important to <em>not stop</em> after sweeping away the confusions of mainstream moral philosophy to arrive at mere <em>correct answers</em>. We must stare directly into the heart of the problem and <a href=\"https://www.lesserwrong.com/lw/up/shut_up_and_do_the_impossible/\">do the impossible</a>.</p><p>Consider Alex, who wants to do the 'right' thing. But she doesn't know what 'right' means. Her question is: \"How do I do what is right if I don't know exactly what 'right' means?\"</p><p>The Austere Metaethicist might cross his arms and say:</p><blockquote>Tell me what you mean by 'right', and I will tell you what is the right thing to do. If by 'right' you mean X, then Y is the right thing to do. If by 'right' you mean P, then Z is the right thing to do. But if you can't tell me what you mean by 'right', then you have failed to ask a coherent question, and no one can answer an incoherent question.</blockquote><p>The Empathic Metaethicist takes up a greater burden. The Empathic Metaethicist says to Alex:</p><blockquote>You may not know what you mean by 'right.' You haven't asked a coherent question. But let's not stop there. Here, let me come alongside you and help decode the cognitive algorithms that generated your question in the first place, and then we'll be able to answer your question. Then not only can we tell you what the right thing to do is, but also we can help bring your <em>emotions</em> <a href=\"https://www.lesserwrong.com/lw/5kn/conceptual_analysis_and_moral_theory/46yv\">into alignment with that truth</a>... as you go on to (say) help save the world rather than being filled with <a href=\"https://www.lesserwrong.com/lw/or/joy_in_the_merely_real/\">pointless</a> existential angst about the universe being <a href=\"http://arxiv.org/pdf/0905.1283\">made of math</a>.</blockquote><p>Austere metaethics is easy. Empathic metaethics is hard. But empathic metaethics is what needs to be done to answer Alex's question, and it's what needs to be done to build a <a href=\"http://intelligence.org/singularityfaq#WhatIsFriendlyAI\">Friendly AI</a>. We'll get there in the next few posts.</p><p>Next post: <a href=\"https://www.lesserwrong.com/lw/5u2/pluralistic_moral_reductionism/\">Pluralistic Moral Reductionism</a></p><p>Previous post: <a href=\"https://www.lesserwrong.com/lw/5eh/what_is_metaethics/\">What is Metaethics?</a></p><h2 id=\"Notes\">Notes</h2><p>1 Eliezer advises against reading mainstream philosophy <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3q9a\">because</a> he thinks it will \"teach very bad habits of thought that will lead people to be unable to do real work.\" Conceptual analysis is, I think, exactly that: a very bad habit of thought that renders many people unable to do real work. Also: My thanks to Eliezer for his helpful comments on an early draft of this post.</p><p>2 For example: Jackson (1998), p. 28, has a different view of conceptual analysis: \"conceptual analysis is the very business of addressing when and whether a story told in one vocabulary is made true by one told in some allegedly more fundamental vocabulary.\" For an overview of Jackson's kind of conceptual analysis, see <a href=\"http://www.unc.edu/~ujanel/Jackson2.htm\">here</a>. Also, <a href=\"http://atheistethicist.blogspot.com/\">Alonzo Fyfe</a> reminded me that those who interpret the law must do a kind of conceptual analysis. If a law has been passed declaring that vehicles are not allowed on playgrounds, a judge must figure out whether 'vehicle' includes or excludes rollerskates. More recent papers on conceptual analysis are available <a href=\"http://philpapers.org/browse/conceptual-analysis?sqc=&amp;onlineOnly=on&amp;cn=conceptual-analysis&amp;showCategories=on&amp;newWindow=on&amp;proOnly=on&amp;new=1&amp;limit=100&amp;categorizerOn=&amp;cId=5593&amp;publishedOnly=&amp;hideAbstracts=&amp;sort=pubYear&amp;filterByAreas=&amp;freeOnly=&amp;start=0&amp;format=html&amp;jlist=&amp;ap_c1=&amp;ap_c2=\">at Philpapers</a>. Finally, read <a href=\"http://consc.net/constructing/chap9.pdf\">Chalmers on verbal disputes</a>.</p><p>3 Braddon-Mitchell (2008). A famous example of the first kind lies at the heart of 20th century epistemology: the definition of 'knowledge.' Knowledge had long been defined as 'justified true belief', but then Gettier (1963) presented some hypothetical examples of justified true belief that many of us would <em>intuitively</em> not label as 'knowledge.' Philosophers launched a cottage industry around new definitions of 'knowledge' and new counterexamples to <em>those</em> definitions. Brian Weatherson called this the \"analysis of knowledge merry-go-round.\" <a href=\"https://www.lesserwrong.com/lw/5kn/conceptual_analysis_and_moral_theory/46mw\">Tyrrell McAllister</a> called it the 'Gettier rabbit-hole.'</p><p>4 Schroeder (2004), pp. 15-27. Schroeder lists them as 7 objections, but I count his 'trying without desiring' and 'intending without desiring' objections separately.</p><p>5 Tabooing one's words is similar to what Chalmers (2009) calls the 'method of elimination'. In an earlier <a href=\"https://www.lesserwrong.com/lw/ro/2place_and_1place_words/\">post</a>, Yudkowsky used what Chalmers (2009) calls the 'subscript gambit', except Yudkowsky used underscores instead of subscripts.</p><p>6 See also Gallie (1956).</p><p>7 Eliezer <a href=\"http://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/\">said</a> that the closest thing to his metaethics from mainstream philosophy is Jackson's 'moral functionalism', but of course moral functionalism is <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3rdb\">not quite right</a>.</p><p>8 Jackson (1998), p. 118.</p><p>9 Jackson (1998), pp. 130-131.</p><h2 id=\"References\">References</h2><p>Braddon-Mitchell (2008). Naturalistic analysis and the a priori. In Braddon-Mitchell &amp; Nola (eds.), <em>Conceptual Analysis and Philosophical Naturalism</em> (pp. 23-43). MIT Press.</p><p>Chalmers (2009). <a href=\"http://consc.net/papers/verbal.pdf\">Verbal disputes</a>. Unpublished.</p><p>Gallie (1956). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/Gallie-Essentially-Contested-Concepts.pdf\">Essentially contested concepts</a>. <em>Proceedings of the Aristotelean Society, 56</em>: 167-198.</p><p>Gettier (1963). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/01/Gettier-Is-Justified-True-Belief-Knowledge.pdf\">Is justified true belief knowledge?</a> <em>Analysis, 23</em>: 121-123.</p><p>Jackson (1998). <em><a href=\"http://www.amazon.com/Metaphysics-Ethics-Defence-Conceptual-Analysis/dp/0198250614/\">From Metaphysics to Ethics: A Defense of Conceptual Analysis</a></em>. Oxford University Press.</p><p>Schroeder (2004). <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three Faces of Desire</a></em>. Oxford University Press.</p>", "sections": [{"title": "The trouble with conceptual analysis", "anchor": "The_trouble_with_conceptual_analysis", "level": 1}, {"title": "Disputing definitions", "anchor": "Disputing_definitions", "level": 1}, {"title": "Disputing the definitions of moral terms", "anchor": "Disputing_the_definitions_of_moral_terms", "level": 2}, {"title": "Austere Metaethics vs. Empathic Metaethics", "anchor": "Austere_Metaethics_vs__Empathic_Metaethics", "level": 2}, {"title": "Notes", "anchor": "Notes", "level": 2}, {"title": "References", "anchor": "References", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "481 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 481, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7X2j8HAkWdmMoS8PE", "yA4gF5KrboK2m2Xu7", "a7n8GdKiAZRX86T5A", "WBdvyyHLdxZSAMmoz", "FaJaCgqBKphrDzDSj", "yuKaWPRTxZoov4z8K", "nCvvhFBaayaXyuBiD", "x4dG4GhpZH2hgz59x", "3zDX3f3QTepNeZHGc", "s4Mcg9aLMeRwdW7fh", "eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T06:36:41.406Z", "modifiedAt": null, "url": null, "title": "Bangalore Meetup: 28th May", "slug": "bangalore-meetup-28th-may", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.787Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "znHu2zjSoCbsSikYm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/77pFWACkmGSsBAzeb/bangalore-meetup-28th-may", "pageUrlRelative": "/posts/77pFWACkmGSsBAzeb/bangalore-meetup-28th-may", "linkUrl": "https://www.lesswrong.com/posts/77pFWACkmGSsBAzeb/bangalore-meetup-28th-may", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bangalore%20Meetup%3A%2028th%20May&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABangalore%20Meetup%3A%2028th%20May%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F77pFWACkmGSsBAzeb%2Fbangalore-meetup-28th-may%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bangalore%20Meetup%3A%2028th%20May%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F77pFWACkmGSsBAzeb%2Fbangalore-meetup-28th-may", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F77pFWACkmGSsBAzeb%2Fbangalore-meetup-28th-may", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 112, "htmlBody": "<p>Bangalore hopefully has enough LessWrongers to have its own meet up. I suggest having one in the afternoon on Saturday, 28th May at Cubbon Park Bandstand. (Behind the high court in Cubbon park).</p>\n<p>I commit to be there from 4 pm-7 pm with a LW meetup sign and a book (can't commit to which book I'll be reading two weeks hence, so will edit that in later. I'll be wearing a red kurta though). Since I don't know any Bangaloreans here and have never stood around in a public park holding up a sign before, comments showing interest will be much appreciated as morale-boosters. :)</p>\n<p>I'm open to suggestions regarding both time and place.</p>\n<p><a id=\"more\"></a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "77pFWACkmGSsBAzeb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.152844073245382e-07, "legacy": true, "legacyId": "7408", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T12:42:02.466Z", "modifiedAt": null, "url": null, "title": "Future Filters [draft]", "slug": "future-filters-draft", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.273Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "snarles", "createdAt": "2009-06-01T03:48:38.132Z", "isAdmin": false, "displayName": "snarles"}, "userId": "YsmFaM5MdsDW8GNop", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CzWRRkAbFxzqKvE6o/future-filters-draft", "pageUrlRelative": "/posts/CzWRRkAbFxzqKvE6o/future-filters-draft", "linkUrl": "https://www.lesswrong.com/posts/CzWRRkAbFxzqKvE6o/future-filters-draft", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Future%20Filters%20%5Bdraft%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFuture%20Filters%20%5Bdraft%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCzWRRkAbFxzqKvE6o%2Ffuture-filters-draft%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Future%20Filters%20%5Bdraft%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCzWRRkAbFxzqKvE6o%2Ffuture-filters-draft", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCzWRRkAbFxzqKvE6o%2Ffuture-filters-draft", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 402, "htmlBody": "<p>See Katja Grace's article: http://hplusmagazine.com/2011/05/13/anthropic-principles-and-existential-risks/</p>\n<p>There are two comments I want to make about the above article.</p>\n<p>First: the resolution to God's Coin Toss seems fairly straightforward.&nbsp; I argue that the following scenario is formally equivalent to 'God's Coin Toss'</p>\n<p><strong>\"Dr. Evil's Machine\"</strong></p>\n<p><em>Dr.  Evil has a factory for making clones.&nbsp; The factory has 1000 separate  identical rooms.&nbsp; Every day, a clone is produced in each room at 9:00 AM.&nbsp; However,  there is a 50% chance of malfunction, in which case 900 of the clones suddenly die by 9:30 AM, the remaining 100 are healthy and notice nothing.&nbsp; At the end of the day Dr. Evil ships off  all the clones which were produced and restores the rooms to their  original state.</em></p>\n<p><em>You wake up at 10:00 AM and learn that you are one of  the clones produced in Dr. Evil's factory, and your learn all of the  information above.&nbsp; What is the probability that that the machine  malfunctioned today?</em></p>\n<p>In the second reformulation, the answer is clear from Bayes' rule.&nbsp; Let P(M) be the probability of malfunction, and P(S) be the probability that you are alive at 10:00 AM.&nbsp; From the information given, we have</p>\n<p>P(M) = 1/2</p>\n<p>P(~M) = 1/2</p>\n<p>P(S|M) = 1/10</p>\n<p>P(S|~M) = 1</p>\n<p>Therefore,</p>\n<p>P(S) = P(S|M) P(M) + P(S|~M)P(~M) = (1/2)(1/10) + (1/2)(1) = 11/20</p>\n<p>P(M|S) = P(S|M) P(M)/P(S) = (1/20)/(11/20) = 1/11</p>\n<p>That is, given the information you have, you should conclude that the probability that the machine malfunctioned is 1/11.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>The second comment concerns Grace's reasoning about future filters.</p>\n<p>I will assume that the following model is a fair representation of Grace's argument about relative probabilities for the first and second filters.</p>\n<p><strong>Future Filter Model I</strong></p>\n<p><em>Given: universe with N planets, T time steps. Intelligent life can arise on a planet at most once.</em></p>\n<p><em>At each time step:</em></p>\n<ol>\n<li><em>each surviving intelligent species becomes permanently visible to all other species with probability <strong>c </strong>(the third filter probability)</em></li>\n<li><em>each surviving intelligent species self-destructs with probability <strong>b</strong> (the second filter probability)</em></li>\n<li><em>each virgin planet produces an intelligent species with probability <strong>a</strong> (the first filter probability)</em></li>\n</ol>\n<p><em>Suppose N=one billion, T=one million.&nbsp; Put uniform priors on a, b, c, and the current time <strong>t</strong> (an integer between 1 and T).</em></p>\n<p><em>Your species appeared on your planet at unknown time step <strong>t_0</strong>.&nbsp; The current time <strong>t </strong>is also unknown.&nbsp; At the current time, no species has become permanently visible in the universe.&nbsp; Conditioned on this information, what is the posterior density for first filter parameter <strong>a</strong>?<br /></em></p>\n<p><em><br /></em></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CzWRRkAbFxzqKvE6o", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.153905069505003e-07, "legacy": true, "legacyId": "7414", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>See Katja Grace's article: http://hplusmagazine.com/2011/05/13/anthropic-principles-and-existential-risks/</p>\n<p>There are two comments I want to make about the above article.</p>\n<p>First: the resolution to God's Coin Toss seems fairly straightforward.&nbsp; I argue that the following scenario is formally equivalent to 'God's Coin Toss'</p>\n<p><strong id=\"_Dr__Evil_s_Machine_\">\"Dr. Evil's Machine\"</strong></p>\n<p><em>Dr.  Evil has a factory for making clones.&nbsp; The factory has 1000 separate  identical rooms.&nbsp; Every day, a clone is produced in each room at 9:00 AM.&nbsp; However,  there is a 50% chance of malfunction, in which case 900 of the clones suddenly die by 9:30 AM, the remaining 100 are healthy and notice nothing.&nbsp; At the end of the day Dr. Evil ships off  all the clones which were produced and restores the rooms to their  original state.</em></p>\n<p><em>You wake up at 10:00 AM and learn that you are one of  the clones produced in Dr. Evil's factory, and your learn all of the  information above.&nbsp; What is the probability that that the machine  malfunctioned today?</em></p>\n<p>In the second reformulation, the answer is clear from Bayes' rule.&nbsp; Let P(M) be the probability of malfunction, and P(S) be the probability that you are alive at 10:00 AM.&nbsp; From the information given, we have</p>\n<p>P(M) = 1/2</p>\n<p>P(~M) = 1/2</p>\n<p>P(S|M) = 1/10</p>\n<p>P(S|~M) = 1</p>\n<p>Therefore,</p>\n<p>P(S) = P(S|M) P(M) + P(S|~M)P(~M) = (1/2)(1/10) + (1/2)(1) = 11/20</p>\n<p>P(M|S) = P(S|M) P(M)/P(S) = (1/20)/(11/20) = 1/11</p>\n<p>That is, given the information you have, you should conclude that the probability that the machine malfunctioned is 1/11.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>The second comment concerns Grace's reasoning about future filters.</p>\n<p>I will assume that the following model is a fair representation of Grace's argument about relative probabilities for the first and second filters.</p>\n<p><strong id=\"Future_Filter_Model_I\">Future Filter Model I</strong></p>\n<p><em>Given: universe with N planets, T time steps. Intelligent life can arise on a planet at most once.</em></p>\n<p><em>At each time step:</em></p>\n<ol>\n<li><em>each surviving intelligent species becomes permanently visible to all other species with probability <strong>c </strong>(the third filter probability)</em></li>\n<li><em>each surviving intelligent species self-destructs with probability <strong>b</strong> (the second filter probability)</em></li>\n<li><em>each virgin planet produces an intelligent species with probability <strong>a</strong> (the first filter probability)</em></li>\n</ol>\n<p><em>Suppose N=one billion, T=one million.&nbsp; Put uniform priors on a, b, c, and the current time <strong>t</strong> (an integer between 1 and T).</em></p>\n<p><em>Your species appeared on your planet at unknown time step <strong>t_0</strong>.&nbsp; The current time <strong>t </strong>is also unknown.&nbsp; At the current time, no species has become permanently visible in the universe.&nbsp; Conditioned on this information, what is the posterior density for first filter parameter <strong>a</strong>?<br></em></p>\n<p><em><br></em></p>\n<p>&nbsp;</p>", "sections": [{"title": "\"Dr. Evil's Machine\"", "anchor": "_Dr__Evil_s_Machine_", "level": 1}, {"title": "Future Filter Model I", "anchor": "Future_Filter_Model_I", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "12 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T14:36:00.762Z", "modifiedAt": "2022-02-10T05:28:16.108Z", "url": null, "title": "[LINK] Two articles on Bitcoin", "slug": "link-two-articles-on-bitcoin", "viewCount": null, "lastCommentedAt": "2013-02-24T19:20:48.467Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7zSyriwymreKhESfP/link-two-articles-on-bitcoin", "pageUrlRelative": "/posts/7zSyriwymreKhESfP/link-two-articles-on-bitcoin", "linkUrl": "https://www.lesswrong.com/posts/7zSyriwymreKhESfP/link-two-articles-on-bitcoin", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Two%20articles%20on%20Bitcoin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Two%20articles%20on%20Bitcoin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7zSyriwymreKhESfP%2Flink-two-articles-on-bitcoin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Two%20articles%20on%20Bitcoin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7zSyriwymreKhESfP%2Flink-two-articles-on-bitcoin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7zSyriwymreKhESfP%2Flink-two-articles-on-bitcoin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<p>Tangential, but a subject of some local interest:</p>\n<p><strong><a href=\"http://apenwarr.ca/log/?m=201105#08\">Why Bitcoin will fail</a></strong> by Avery Pennarun. \"The sky isn't red.\" Thesis:</p>\n<ol>\n<li>The gold standard was a bad idea.</li>\n<li>Even if it [Bitcoin] was a good idea, governments will squash it.</li>\n<li>The whole technological basis (cryptosystem) is flawed.</li>\n<li>It doesn't work offline.</li>\n</ol>\n<p>I'm not sure I buy these and am not competent to evaluate his claims on 3., but would like others' critique.</p>\n<p><strong><a href=\"http://launch.is/blog/l019-bitcoin-p2p-currency-the-most-dangerous-project-weve-ev.html\">L019: Bitcoin P2P Currency: The Most Dangerous Project We've Ever Seen</a></strong> by Jason Calacanis. A rather more enthusiastic viewpoint of the project:</p>\n<ol>\n<li>Bitcoin is a technologically sound project. </li>\n<li>Bitcoin is unstoppable without end-user prosecution. </li>\n<li>Bitcoin is the most dangerous open-source project ever created. </li>\n<li>Bitcoin may be the most dangerous technological project since the internet itself. </li>\n<li>Bitcoin is a political statement by technological libertarians. </li>\n<li>Bitcoins will change the world unless governments ban them with harsh penalties. </li>\n</ol>\n<p>The actual text contains many more caveats than the eye-catching selection of points above.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jgcAJnksReZRuvgzp": 2, "xCXkjecsjwm8uSW3y": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7zSyriwymreKhESfP", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "7415", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 63, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-05-16T14:36:00.762Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T16:29:25.640Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Chronophone Motivations", "slug": "seq-rerun-chronophone-motivations", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FHH6J6B7NJYyrCLNA/seq-rerun-chronophone-motivations", "pageUrlRelative": "/posts/FHH6J6B7NJYyrCLNA/seq-rerun-chronophone-motivations", "linkUrl": "https://www.lesswrong.com/posts/FHH6J6B7NJYyrCLNA/seq-rerun-chronophone-motivations", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Chronophone%20Motivations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Chronophone%20Motivations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFHH6J6B7NJYyrCLNA%2Fseq-rerun-chronophone-motivations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Chronophone%20Motivations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFHH6J6B7NJYyrCLNA%2Fseq-rerun-chronophone-motivations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFHH6J6B7NJYyrCLNA%2Fseq-rerun-chronophone-motivations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 162, "htmlBody": "<p>Today's post, <a href=\"/lw/h6/chronophone_motivations/\">Chronophone Motivations</a> was originally published on March 24, 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>If you want to really benefit humanity, do some original thinking, especially about areas of application, and directions of effort. The point of the chronophone dilemma is to make us think about what kind of cognitive policies are good to follow when you don't know your destination in advance.</blockquote>\n<p><br /><em>This post is part of a series rerunning Eliezer Yudkowsky's old posts so that those interested can (re-)read and discuss them. The previous post was <a href=\"/r/discussion/lw/5pi/seq_rerun_archimedess_chronophone/\">Archimedes's Chronophone</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FHH6J6B7NJYyrCLNA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.154565550365371e-07, "legacy": true, "legacyId": "7418", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7khK4DShZBR8gfyHv", "pAFpKFjwWhjt4rPhT", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T17:07:49.703Z", "modifiedAt": null, "url": null, "title": "Fine-tuned for Interestingness vs. Ramsey's Theorem", "slug": "fine-tuned-for-interestingness-vs-ramsey-s-theorem", "viewCount": null, "lastCommentedAt": "2018-05-01T20:19:23.834Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4neqNL4eW9aMYxnQL/fine-tuned-for-interestingness-vs-ramsey-s-theorem", "pageUrlRelative": "/posts/4neqNL4eW9aMYxnQL/fine-tuned-for-interestingness-vs-ramsey-s-theorem", "linkUrl": "https://www.lesswrong.com/posts/4neqNL4eW9aMYxnQL/fine-tuned-for-interestingness-vs-ramsey-s-theorem", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fine-tuned%20for%20Interestingness%20vs.%20Ramsey's%20Theorem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFine-tuned%20for%20Interestingness%20vs.%20Ramsey's%20Theorem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4neqNL4eW9aMYxnQL%2Ffine-tuned-for-interestingness-vs-ramsey-s-theorem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fine-tuned%20for%20Interestingness%20vs.%20Ramsey's%20Theorem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4neqNL4eW9aMYxnQL%2Ffine-tuned-for-interestingness-vs-ramsey-s-theorem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4neqNL4eW9aMYxnQL%2Ffine-tuned-for-interestingness-vs-ramsey-s-theorem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 518, "htmlBody": "<p>I had <a href=\"/lw/36h/finetuned_mind_projection/\">posted</a> a while back on my proposed dissolution of the Fine Tuning argument. My main argument was as follows:</p>\n<blockquote>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">So the question posed to defenders of the FTA is 'why life'? Why focus on this particular fact? What is it that sets life apart from all the other propositions true about our universe but not other the other possible universes? The usual answer is that life stands out, being valuable in ways that galaxies, iPads, and all the other true propositions are not. It seems that this is an unstated premise of the FTA. But where does that premise come from? Physics gives us no instrument to measure value, so how did this concept get in what was supposed to be a cosmology-based argument?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">I present the FTA here as an argument that while seemingly complex, simply evaporates in light of the&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline; \" href=\"http://wiki.lesswrong.com/wiki/Mind_projection_fallacy\">Mind Projection Fallacy</a>. Knowing that humans tend to confuse 'I see X as valuable' with 'x is valuable', the provenance of the hidden premise 'life is valuable' is laid bare, as is the identity of the agent who is doing the valuing, and it is us. With the mystery solved, explaining why humans find life valuable does not require us to go to the extreme lengths of introducing a non-naturalistic cause for the universe.</p>\n</blockquote>\n<div>In the comments, Yvain <a href=\"/lw/36h/finetuned_mind_projection/30s0\">came up with a response</a> that I admit took me by surprise, if only because this is not the FTA that I had been exposed to (emphasis added):</div>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif;\">The conditions necessary for life are also necessary for iPads: the argument hinges on things like the ability of subatomic particles to come together to form atoms, or the ability of stars to burn. It's not a question of one interesting type of complexity versus another,&nbsp; <strong>but of a vast selection space of universes in which there is nothing complex or interesting, versus a tiny space of universes in which there are many interesting things</strong> &nbsp;like iPads and life.</span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \"><span style=\"font-family: Arial, Helvetica, sans-serif;\">I admit this explanation lacks a rigorous definition of \"interesting\", but I think the least that can be said is that our universe is interesting in being a wild outlier in various physical and mathematical characteristics, and not just \"interesting to beings with the same value system as ourselves\".</span></p>\n</blockquote>\n<p>I've been pondering how to process that response, and if the argument is&nbsp;salvageable, ever since. Do we really have to explain anthropics and the multiverse to diffuse the FTA?</p>\n<p>Today I came across <a href=\"http://www.math.grin.edu/~miletijo/museum/ramsey.html\">a great article</a> with an elegant description of Ramsey's Theorem:</p>\n<blockquote>\n<p>Expressed roughly, it tells us that complete disorder (in certain situations) is impossible. No matter how jumbled and chaotic you try to arrange certain objects, you will find yourself creating a very highly organized and structured object within it.</p>\n</blockquote>\n<p>As I understand it, positing few 'interesting' vs. the vast majority of 'uninteresting' universes is in direct contradiction with Ramsey's theorem. I put this to the more mathematically educated among this community for feedback. Beyond pushing forward this particular internal dialog of mine, it should have more general application in the fine tuning debate, should someone choose to use it there.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4neqNL4eW9aMYxnQL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 1, "extendedScore": null, "score": 7.154677103108003e-07, "legacy": true, "legacyId": "7419", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kGCzi3d8FtJyxvwXr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T18:36:52.278Z", "modifiedAt": null, "url": null, "title": "Life Extension through Diet Modification", "slug": "life-extension-through-diet-modification", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:33.317Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Caerbannog", "createdAt": "2011-04-30T02:54:30.643Z", "isAdmin": false, "displayName": "Caerbannog"}, "userId": "2AHG8DKQeWwxMCvK9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2bZ9ANSjcNPvzmGNN/life-extension-through-diet-modification", "pageUrlRelative": "/posts/2bZ9ANSjcNPvzmGNN/life-extension-through-diet-modification", "linkUrl": "https://www.lesswrong.com/posts/2bZ9ANSjcNPvzmGNN/life-extension-through-diet-modification", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Life%20Extension%20through%20Diet%20Modification&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALife%20Extension%20through%20Diet%20Modification%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2bZ9ANSjcNPvzmGNN%2Flife-extension-through-diet-modification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Life%20Extension%20through%20Diet%20Modification%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2bZ9ANSjcNPvzmGNN%2Flife-extension-through-diet-modification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2bZ9ANSjcNPvzmGNN%2Flife-extension-through-diet-modification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 355, "htmlBody": "<p>Life extension is a relevant topic here, and I was wondering if people are aware of the apparently life-extending effects of calorie restriction (CR) and intermittent fasting (IF). To the extent of my knowledge, this is the best method using currently realized technology that has shown repeated and significant life-extension benefits.<br /><br /><a href=\"http://www.ajcn.org/content/78/3/361.full.pdf\">Studies</a> show that reducing calories by 20% to 40% from ad libitum feeding (but maintaining the supply of required protein and micro-nutrients) gives improvements in markers related to aging, and extends life span in rodents and other organisms.<br /><br />Other rodent <a href=\"http://jn.nutrition.org/content/31/3/363.full.pdf\">studies</a> have also shown similar results in subjects which were kept on various intermittent fasting schedules. Rats that were fed only on alternating days gained up to 25% lifespan (see Table 2).<br /><br />The <a href=\"http://www.pnas.org/content/100/10/6216.full.pdf\">benefits</a> of IF are seen even if the total calorie intake is the same as in ad libitum subjects.<br /><br />There are ongoing full-lifespan studies in rhesus macaques to test the effects in primates, but none of these studies have completed. This <a href=\"http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6T6J-473FRHK-8&amp;_user=10&amp;_coverDate=01%2F31%2F2003&amp;_rdoc=1&amp;_fmt=high&amp;_orig=gateway&amp;_origin=gateway&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_searchStrId=1753853052&amp;_rerunOrigin=scholar.google&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=2480f68a73c621a3815773c22c8f7850&amp;searchtype=a\">abstract</a> of the interim results appears promising, though.<br /><br />Studies of CR and IF on humans have <a href=\"http://www.ajcn.org/content/86/1/7.full.pdf\">shown</a> <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2527659/pdf/pone.0003211.pdf\">effects</a> consistent with reduced mortality, including:<br />- Improved triglyceride profiles (a marker for heart disease)<br />- Increased insulin sensitivity<br />- Reduced cell proliferation (a marker for cancer)<br /><br />Generally, these diet modifications appear to not just extend life span, but improve the quality of life too. In aged subjects they improve things like: muscle mass, cognition, energy, appearance, and activity level.<br /><br />Have people heard about this or tried it? If you are trying to maximize your chance of surviving to the point that technology can lengthen lifespan indefinitely, it seems like something worth exploring.<br /><br />I tried an IF schedule for about 6 months during 2010. I followed a schedule of 3 x ~thirty hour fasts every 7 days and found it somewhat tolerable. I exercise regularly and found that exercising on the non-fasting days was not a problem. I'm thinking of starting up such a schedule again.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"vmvTYnmaKA73fYDe5": 1, "92SxJsDZ78ApAGq72": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2bZ9ANSjcNPvzmGNN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 23, "extendedScore": null, "score": 7.154935779365511e-07, "legacy": true, "legacyId": "7421", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T20:12:40.485Z", "modifiedAt": null, "url": null, "title": "Off-topic: Russian machine translation", "slug": "off-topic-russian-machine-translation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:23.448Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "thomblake", "createdAt": "2009-02-27T15:35:08.282Z", "isAdmin": false, "displayName": "thomblake"}, "userId": "zCHE6bXWKB6kfJsJS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z5xZrzDiReWGzaikT/off-topic-russian-machine-translation", "pageUrlRelative": "/posts/Z5xZrzDiReWGzaikT/off-topic-russian-machine-translation", "linkUrl": "https://www.lesswrong.com/posts/Z5xZrzDiReWGzaikT/off-topic-russian-machine-translation", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Off-topic%3A%20Russian%20machine%20translation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOff-topic%3A%20Russian%20machine%20translation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ5xZrzDiReWGzaikT%2Foff-topic-russian-machine-translation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Off-topic%3A%20Russian%20machine%20translation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ5xZrzDiReWGzaikT%2Foff-topic-russian-machine-translation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ5xZrzDiReWGzaikT%2Foff-topic-russian-machine-translation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<p>This is a little off-topic, but I can't find the answer and I realized this might actually be an excellent place to ask this question:</p>\n<p>I've noticed Google Translate seems to do a pretty bad job sometimes of Russian-to-English and vice versa, assuming that my human-translated documents are correct. &nbsp;Does anyone know of a better free service for machine translation for Russian?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z5xZrzDiReWGzaikT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 1, "extendedScore": null, "score": 7.155214114163594e-07, "legacy": true, "legacyId": "7422", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-16T23:33:25.187Z", "modifiedAt": null, "url": null, "title": "Colonization models: a programming tutorial (Part 1/2)", "slug": "colonization-models-a-programming-tutorial-part-1-2", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:24.621Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "snarles", "createdAt": "2009-06-01T03:48:38.132Z", "isAdmin": false, "displayName": "snarles"}, "userId": "YsmFaM5MdsDW8GNop", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LKQNdsgqgWX4SYTqw/colonization-models-a-programming-tutorial-part-1-2", "pageUrlRelative": "/posts/LKQNdsgqgWX4SYTqw/colonization-models-a-programming-tutorial-part-1-2", "linkUrl": "https://www.lesswrong.com/posts/LKQNdsgqgWX4SYTqw/colonization-models-a-programming-tutorial-part-1-2", "postedAtFormatted": "Monday, May 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Colonization%20models%3A%20a%20programming%20tutorial%20(Part%201%2F2)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AColonization%20models%3A%20a%20programming%20tutorial%20(Part%201%2F2)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKQNdsgqgWX4SYTqw%2Fcolonization-models-a-programming-tutorial-part-1-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Colonization%20models%3A%20a%20programming%20tutorial%20(Part%201%2F2)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKQNdsgqgWX4SYTqw%2Fcolonization-models-a-programming-tutorial-part-1-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKQNdsgqgWX4SYTqw%2Fcolonization-models-a-programming-tutorial-part-1-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4545, "htmlBody": "<p><strong>Introduction</strong></p>\n<p>Are we alone in the universe?&nbsp; How likely is our species to survive the transition from a <a href=\"http://en.wikipedia.org/wiki/Kardashev_scale\">Type 0 to a Type II civilization</a>?&nbsp; The answers to these questions would be of immense interest to our race; however, we have few tools to reason about these questions.&nbsp; This does not stop us from wanting to find answers to these questions, often by employing controversial principles of inference such as 'anthropic reasoning.'&nbsp; The reader can find a wealth of stimulating discussion about anthropic reasoning at <a href=\"http://meteuphoric.wordpress.com/\">Katja Grace's blog</a>, the site from which this post takes its inspiration.&nbsp; The purpose of this post is to give a quantitatively oriented approach to anthropic reasoning, demonstrating how computer simulations and Bayesian inference can be used as tools for exploration.</p>\n<p>The central mystery we want to examine is the <em>Fermi paradox</em>: the fact that</p>\n<ol>\n<li>we are an intelligent civilization</li>\n<li>we cannot observe any signs that other intelligent civilizations ever existed in the universe</li>\n</ol>\n<p>One explanation for the Fermi paradox is that we are the only intelligent civilization in the universe.&nbsp; A far more chilling explanation is that intelligent civilizations emerge quite frequently, but that all other intelligent civilizations that have come before us ended up destroying themselves before they could manage to make their mark on their universe.</p>\n<p>We can reason about which of the above two explanations are more likely if we have the audacity to assume <em>a model</em> for the emergence and development of civilizations in universe 'similar to ours.'&nbsp; In such a model, it is usually useful to distinguish different 'types' of civilizations.&nbsp; Type 0 civilizations are civilizations with similar levels of technology as ourselves.&nbsp; If a Type 0 civilization survives long enough and accumulates enough scientific knowledge, it can make a transition to a Type I civilization--a civilization which has attained mastery of their home planet.&nbsp; A Type I civilization, over time, can transition to a Type II civilization if it colonizes its solar system.&nbsp; We would suppose that a nearby civilization would have to have reached Type II in order for their activities to be prominent enough for us to be able to detect them.&nbsp; In the original terminology, a Type III civilization is one which has mastery of its galaxy, but in this post we take it to mean something else.</p>\n<p>The simplest model for the emergence and development of civilizations would have to specify the following:</p>\n<ol>\n<li>the rate at which intelligent life appears in universes similar to ours;</li>\n<li>the rate at which these intelligent species transition from Type 0 to Type II, Type III civilizations--or self-destruct in the process;</li>\n<li>the visibility of Type II and Type III civilizations to Type 0 civilizations elsewhere</li>\n<li>the proportion of advanced civilizations which ultimately adopt expansionist policies;</li>\n<li>the speed at which those Type III civilizations can expand and colonize the universe.</li>\n</ol>\n<p>In the model we propose in the post, the above parameters are held to be constant throughout the entire history of the universe.&nbsp; The importance of the model is that after given a particular specification of the parameters, we can apply <a href=\"http://en.wikipedia.org/wiki/Bayesian_inference\">Bayesian inference</a> to see how well the model explains the Fermi paradox.&nbsp; The idea is to simulate many different histories of universes for a given set of parameters, so as to find the <em>expected number of observers who observe the Fermi paradox</em> given a particular specification of the parameters.&nbsp; More details about Bayesian inference given in Part 2 of this tutorial.</p>\n<p>This post is targeted at readers who are interested in simulating the emergence and expansion of intelligent civilizations in 'universes similar to ours' but who lack the programming knowledge to code these simulations.&nbsp; In this post we will guide the reader through the design and production of a relatively simple universe model and the methodology for doing 'anthropic' Bayesian inference using the model.</p>\n<p><a id=\"more\"></a></p>\n<p><strong>I. The model</strong></p>\n<p>&nbsp;</p>\n<p>We are going to simulate the entire history, or time-line, of a universe.&nbsp; We assume that the universe has a finite lifespan; readers are invited to attempt to extend the model to allow for indefinite lifespans.&nbsp; For computational simplicity, we will break up the history of the universe into, say, 1000 discrete epochs, where each epoch might represent twenty million years.&nbsp; The epoch number is represented by a variable <em>t </em>ranging from 1 to 1000.&nbsp; The epoch <em>t = 1</em> does not represent the very beginning of the universe, but rather, the earliest period where intelligent life has a significant chance of appearing; likewise, the last epoch <em>t=</em>1000 would be the last period in which the cosmology of the universe allows for the emergence of intelligent life.</p>\n<p>We assume the cosmological model of space as a (the three-dimensional surface) of a four-dimensional unit sphere centered at the origin.&nbsp; That is, the universe is represented as the set of all points <em>(x,y,z,w)</em> where <em>x^2 + y^2 + z^2 + w^2 = 1</em>.&nbsp; Note that since w can be calculated from <em>x, y, z</em>, only the points<em> x, y, z </em>need be stored in the simulation.</p>\n<p>Now it is important to correctly specify the <em>speed of light</em> in terms of the units we have chosen for time and space.&nbsp; Assuming the <a href=\"http://en.wikipedia.org/wiki/Observable_universe\">maximum geodesic</a> of the universe is 100 billion light years, and given that each time step is twenty million years, this would put the<em> </em>speed of light as <strong>s = 4 x 10^-4</strong> in our units.</p>\n<p>One could go further to populate this universe with randomly located habitable planets.&nbsp; However, we would need a lot of planets for a realistic model, so this approach would not be particularly computationally efficient.&nbsp; Instead, we will <em>assume that the number of habitable planets in a region of space is proportional to its volume.&nbsp; </em>This will allow us to do the simulation without specifying the location of the planets.</p>\n<p>Now we need to specify the mechanism by which new Type 0 civilizations emerge in our universe.&nbsp; For the sake of simplicity, <em>at most one new Type 0 civilization appears in each time step.</em> (A more realistic model might employ a Poisson distribution to determine the number of new civilizations at each time step.)&nbsp; The location of the new civilization is located uniformly at random within the uninhabited volume of the universe.&nbsp; We will suppose that no new Type 0 civilization can emerge on planets already inhabited by others civilizations.&nbsp; Thus, the probability that a new Type 0 civilization emerges must depend on how much of the universe is uninhabited.&nbsp; We will posit that this probability is a constant factor, <strong>a</strong>, times the proportion of universe which is uninhabited.&nbsp; A more advanced model might have the propensity for life factor <strong>a </strong>vary with time, to account for planetary and stellar evolution.</p>\n<p>Next we need to specify how existing civilizations transition to the next stage, self-destruct, become visible or colonize other planets. We will use four types of civilizations:</p>\n<ul>\n<li>Type 0.&nbsp; Civilizations at around our stage of development.</li>\n<li>Type II.&nbsp; Civilizations which are developed enough to be visible to others.&nbsp; However, we make a distinction between two classes of Type II civilizations, a distinction not present in the original formulation of the Kardeshev scale.</li>\n<li>Type IIa. Civilizations which have adopted a non-expansionist policy, and which will remain Type IIa civilizations forever.</li>\n<li>Type IIb. Civilizations which may become Type III (expansionist) civilizations in the future</li>\n<li>Type III. We make the extreme assumption that <em>all Type III civilizations are expansionist.</em>&nbsp; That is, once a civilization becomes Type III, it starts colonizing the surrounding space as quickly as possible.&nbsp; Space colonized by Type III civilizations is<em> sterilized</em>, it can not longer produce new Type 0 civilizations.</li>\n</ul>\n<p>We have not included the \"Type I\" civilization in our model, since for our purposes Type I civilizations are virtually identical to Type 0 civilizations.&nbsp; In the same way, Type IIa civilizations would be virtually identical to 'peaceful' Type III civilizations for the purposes of out model, which is why hold all Type III civilizations to be expansionist.</p>\n<p>Here will be our model for this process:</p>\n<ol>\n<li>At each time step, the 'sphere of colonization' of a type III civilization increases its radius by the maximum speed of colonization, <strong>k * s.</strong>&nbsp; Here we have the speed multiplier <strong>k</strong> as constant, but a more realistic model might have the speed of colonization increase as the Type III civilization gains more technology</li>\n<li>Each Type IIb civilization has a probability <strong>e</strong> of transitioning to a Type III civilization.&nbsp; </li>\n<li>Each Type 0 civilization has probability <strong>b</strong> of self-destructing and probability <strong>c</strong> of transitioning to Type IIa and probability <strong>d</strong> of transitioning to Type IIb (and remains Type 0 with probability 1-b-c-d).</li>\n<li>When a civilization transitions to either Type IIa or Type IIb, it becomes 'visible.'&nbsp; A sphere of 'visibility' expands from the location of the civilization at the speed of light, and all observers within this expanding sphere become alerted to the existence of the Type II civilization.</li>\n<li>With probability <strong>a</strong>, locate a random point <strong>x</strong> within the unit sphere which is a candidate site for a new Type 0 civilization.&nbsp; If that point is within the colonization sphere of any existing civilization, no new Type 0 civilization is generated.&nbsp;&nbsp; Otherwise, create a new Type 0 civilization at that point.</li>\n</ol>\n<p>To sum up, each civilization in our universe has four variables associated with it.</p>\n<ol>\n<li>The location of its 'home planet', in three-dimensional coordinates.</li>\n<li>Its civilization stage (Type 0, Type IIa, Type IIb, Type III)</li>\n<li>Its radius of visibility</li>\n<li>Its radius of colonization</li>\n</ol>\n<p>In each step of the simulation, we need to store these quantities in a data structure.&nbsp; The data structure for the simulation should have a slot for each time step of the simulation; in each slot, we will store a list of civilizations with their associated quantities.</p>\n<p>After we have run the simulation, we can extract various quantities of interest from the data structure, for example, we might want to know:</p>\n<ol>\n<li>How many Type 0 civilizations exist at each time step?</li>\n<li>How many of these Type 0 civilizations are in the 'sphere of visibility' of a Type II+ civilization, at each time step?</li>\n</ol>\n<p>&nbsp;</p>\n<p><strong>II. Implementation</strong></p>\n<p>&nbsp;</p>\n<p>The program we will be using is the <a href=\"http://cran.r-project.org/\">R programming environment</a>, an open-source computing environment commonly used for statistical data analysis.&nbsp; No programming experience is assumed, but readers are expected to be able to learn by example.&nbsp; Conversely, readers with programming skills can skip to the quoted code blocks, reading the explanations when needed.</p>\n<p>After you install and run R, you should see a blank terminal.&nbsp; To run the code, simply copy and paste the provided code into the buffer and press 'enter.'&nbsp; We give the code in blocks so as to make copying and pasting more convenient.&nbsp; Here is the first block of code--don't be alarmed!&nbsp; We will walk through the code line-by-line immediately afterwards.</p>\n<blockquote>\n<p># Example 1<br />s = 4e-4<br />a = 0.10<br />b = 0.20; c = 0.05; d = 0.05<br />e = 0.10<br />k = 0.90<br />civs = list()<br />earth_coordinates = c(0.1,0.2,0.3,sqrt(.86))<br />human_civ = list(location=earth_coordinates,type=0,r_v=0,r_c=0,age=0)<br />zerg_civ = list(location=c(0.2,0.1,0.3,sqrt(.86)),type=3,r_v=0.2,r_c=0.1,age=20)<br />civs[[1]] = human_civ<br />civs[[2]] = zerg_civ</p>\n</blockquote>\n<p>Now we'll explain the code for \"Example 1\", starting from the top.</p>\n<ol>\n<li>The first line is a comment.&nbsp; All of the text to the right of a hash '#' symbol is ignored by the interpreter</li>\n<li>'s = 4e-4' sets the speed of light to 4 x 10^-4.&nbsp; The 'e' stands for \"times ten to the power of...\"</li>\n<li>sets the probability <strong>a</strong> to 1/100.&nbsp; Recall this is the base rate for a Type 0 civilization to emerge in a time step.</li>\n<li>sets the probabilities <strong>b, c, d</strong>.&nbsp; The semicolon ';' separates multiple commands that are on the same line</li>\n<li>sets the probability <strong>e</strong>, (type IIb -&gt; type III transition)</li>\n<li>sets the constant <strong>k</strong> to 0.9.&nbsp; That is, the maximum speed of colonization is taken to be 90% of the speed of light.</li>\n<li><strong>civs</strong> is a data structure for storing the information of all the civilizations which exist at a particular time step.&nbsp; It will be a list, with an element for each civilization in existence at that time</li>\n<li><strong>earth_coordinates</strong> is a vector with three elements: (0.1, 0.2, 0.3).&nbsp; The <strong>c()</strong> function forms a vector out of the enclosed numbers.&nbsp; As you might guess, this particular vector is the spatial coordinates of planet Earth in our example.</li>\n<li><strong>human_civ </strong>is a data structure containing all the information needed to describe (our) civilization: <strong>location</strong> will be the vector given by earth_coordinates: (0.1,0.2,0.3);<strong> type=0 </strong>indicates a Type 0 civilization, <strong>r_v</strong> is the radius of our sphere of visibility, which is zero because we haven't reached Type II yet.&nbsp; <strong>r_c </strong>is the radius of our sphere of colonization, which is zero because we haven't reached Type III yet.</li>\n<li><strong>zerg_civ</strong> holds the information for another civilization, which is older than ours by 400 million years. It has a home planet with coordinates (0.2,0.1,0.2), which has reached Type III, and which can be seen by all observers within distance 0.2, and which has colonized all planets within distance 0.1 of its home planet!</li>\n<li><strong>civs[[1]] = human_civ </strong>sets the first element of the list civs to be the data structure encapsulation information about our civilization.&nbsp; Yes, you can have the elements of lists be other lists--we will be doing that a lot.</li>\n<li><strong>civs[[2]] = zerg_civ </strong>sets the second element of the list civs to be the information about the Zerg civilization</li>\n</ol>\n<p>(In this code, we will have the parameters a, b, c, d, e, k,s be global variables.&nbsp; This is not the best coding practice, but it simplifies the code for this tutorial.)</p>\n<p>It is certainly cause for alarm that there is a hostile Type III civilization in our vicinity.&nbsp; Can we see them?&nbsp; Have we already been colonized by them?&nbsp; To answer these questions, we need to program a distance function.&nbsp; We'll be lazy here and use the Euclidean distance, instead of calculating the length of the geodesic on a 3-sphere.</p>\n<blockquote>\n<p># Code Block 1<br />distance = function(x,y) {<br />&nbsp; return(sqrt(sum((x-y)^2)))<br />}</p>\n</blockquote>\n<ol>\n<li><em></em></li>\n<li><strong>distance </strong>is the name of the function.&nbsp;&nbsp; <strong>= function(x,y)</strong> tells R that this is to be a function with two arguments, x and y.&nbsp; The <strong>{</strong> brace, or 'begin-block symbol', means that the subsequent code will be part of the functionthe <strong>return() </strong>command is for returning the 'answer' computed by the function.&nbsp; In this case, the answer is the Euclidean distance of the vectors x and y; &nbsp; <strong>sqrt()</strong> evaluates the square root of the argument.&nbsp; <strong>sum()</strong> evaluates the sum of the components of a vector.&nbsp; <strong>^2 </strong>applied to a vector squares each component of the vector.</li>\n<li><strong>}</strong> or 'end-block symbol' indicates that we are done writing the code for the function</li>\n</ol>\n<p>After you copy and paste the above code, there will be a new function in the environment, distance().&nbsp; We will use it now</p>\n<blockquote>\n<p># Example 2<br />x = human_civ$location; x<br />y = zerg_civ$location; y<br />d = distance(x,y); d<br />d &lt; zerg_civ$r_v<br />if (d &lt; zerg_civ$r_v) { print(\"enemy sighted!\") }<br />if (d &lt; zerg_civ$r_c) { print(\"war has begun...\") }</p>\n</blockquote>\n<p>Line 2: look back at how we defined the list human_civ.&nbsp; The <strong>$ </strong>symbol allows you to access the element of that list labeled as the 'location.'</p>\n<p>Line 4: Recall x is the coordinates of our planet, and y is the coordinates of the zerg home planet.&nbsp; We call the function we just defined to find the distance between our home planet and the zerg home planet, and then we store the answer in a new variable, d</p>\n<p>Line 5: A boolean expression: is d less than the zerg's radius of visibility?</p>\n<p>Line 6 &amp; 7: The if() statement executes the code in brackets only if the statement in the parentheses is true</p>\n<p>The '&lt;' symbol is obviously the comparison 'less than'.&nbsp; Less obvious: '&gt;=' for greater-or-equal-to, '==' for equal to.&nbsp; A common newbie mistake is to confuse the assignment '=' symbol for the equality '==' symbol--they have very different meanings!</p>\n<p>EXERCISE 1:&nbsp; Add some additional civilizations to the list <strong>civs</strong> manually.&nbsp; We code the civilization types as follows</p>\n<ul>\n<li>type=0 for Type 0 civs</li>\n<li>type=-1 for dead civilizations</li>\n<li>type=1 for Type IIa (non-expansionist) civs</li>\n<li>type=2 for Type IIb civs</li>\n<li>type=3 for Type III (expansionist) civs</li>\n</ul>\n<p>Now we start on coding the simulation step.&nbsp; Recall the simulation step consist of two parts.&nbsp; In the first step, we roll to see if any of the existing civilizations transition to another stage, and we update the radii of visibility and colonization for Type II+ civilizations.&nbsp; In the second step, we roll to see if a new Type 0 civilization emerges.</p>\n<p>We will code a separate transition function for each Type of civilization.&nbsp; We'll start with the Type IIb and Type III civilizations, they are the easiest.</p>\n<blockquote>\n<p># Code Block 2<br />transition_type2b = function(civ) {<br />&nbsp; civ$r_v = civ$r_v + s<br />&nbsp; civ<br />}<br />transition_type3 = function(civ) {<br />&nbsp; civ$r_v = civ$r_v + s<br />&nbsp; civ$r_c = civ$r_c + k * s<br />&nbsp; civ<br />}</p>\n</blockquote>\n<p>Notice that there is no return() statement in either function.&nbsp; That is because a function automatically returns the value in the last line (<strong>civ</strong> in this case) whenever it makes it all the way to the last line.</p>\n<p>Now, test to see if the transition function works properly on the Zerg civ.&nbsp; Also test the transition for Type 2b planets on any Type 2b planet you created in Exercise 1.</p>\n<blockquote>\n<p># Example 3<br />zerg_civ = civs[[2]]<br />zerg_civ = transition_type3(zerg_civ)<br />zerg_civ<br />civs[[2]] = zerg_civ</p>\n</blockquote>\n<p>Notice how the transition function works.&nbsp; The transition function returns an updated version of the civ it was given.&nbsp; But it does not update the original civ automatically: you have to make sure that the updated state gets stored in the appropriate place.</p>\n<p>Now, we want to make a function which automatically chooses the right transition for a given civ.&nbsp; Also, we can make it keep track of the civilization's age.</p>\n<blockquote>\n<p># Code Block 3<br />transition_civ = function(civ) {<br />&nbsp; civ$age = civ$age + 1<br />&nbsp; type = civ$type<br />&nbsp; if (type == 0) { civ = transition_type0(civ) }<br />&nbsp; if (type == 1) { civ = transition_type2a(civ) }<br />&nbsp; if (type == 2) { civ = transition_type2b(civ) }<br />&nbsp; if (type == 3) { civ = transition_type3(civ) }<br />&nbsp; civ<br />}</p>\n</blockquote>\n<p>EXERCISE: What happens if you call the transition() function on a dead (type=-1) civilization?</p>\n<p>In order to handle the transition rolls for type 0 and type IIa civilizations, we need a way to generate random numbers.&nbsp; R has a built-in function to generate random numbers from 0 to 1, the <strong>runif()</strong> function, which we demonstrate.</p>\n<blockquote>\n<p># Code Block 4<br />transition_type2a = function(civ) {<br />&nbsp; civ$r_v = civ$r_v + s<br />&nbsp; if (runif(1) &lt; e) {<br />&nbsp;&nbsp;&nbsp; civ$type = 3<br />&nbsp; }<br />&nbsp; civ&nbsp; <br />}</p>\n</blockquote>\n<p>The command <strong>runif(1)</strong> returns one random number between 0 and 1.&nbsp; See that the boolean statement <strong>(runif(1) &lt; e) </strong>is true with probability e.</p>\n<p>Now the transition for a Type 0 civilization is more complicated: it has a probability of dying, of going to Type IIa, of going to Type IIb, or staying type 0, and all these events are mutually exclusive.&nbsp; There is a simple trick for handling all that with a single roll.</p>\n<blockquote>\n<p># Code Block 5<br />transition_type0 = function(civ) {<br />&nbsp; roll = runif(1)<br />&nbsp; if (roll &lt; b) { civ$type = -1; return(civ) }<br />&nbsp; roll = roll - b<br />&nbsp; if (roll &lt; c) { civ$type = 1; return(civ) }<br />&nbsp; roll = roll - c<br />&nbsp; if (roll &lt; d) { civ$type = 2; return(civ) }<br />&nbsp; civ<br />}</p>\n</blockquote>\n<p>EXERCISE:&nbsp; Does the above code indeed transition the civ to: dead with probability b, Type IIa with probability c, Type IIb with probability d?</p>\n<p>Finally, we make a function for automatically applying the transition function to every civ in a list.&nbsp; How we will go through the list is to use a <strong>for() </strong>loop to access each of the elements civs[[1]], civs[[2]], all the way up to civs[[no_civs]].</p>\n<blockquote>\n<p># Code Block 6<br />transition_all = function(civs) {<br />&nbsp; no_civs = length(civs)<br />&nbsp; if (no_civs == 0) { return(civs) }<br />&nbsp; for (i in 1:no_civs) {<br />&nbsp;&nbsp;&nbsp; civ = civs[[i]]<br />&nbsp;&nbsp;&nbsp; civ = transition_civ(civ)<br />&nbsp;&nbsp;&nbsp; civs[[i]] = civ<br />&nbsp; }<br />&nbsp; civs<br />}</p>\n</blockquote>\n<ol>\n<li>[comment]</li>\n<li>Recall the usage of the function: you should call <strong>civs = transition_all(civs)</strong> to update the list <strong>civs</strong></li>\n<li>This step is important since R will give an error if you try to access an element in an empty list</li>\n<li>The function <strong>length()</strong> returns the number of elements contained in a list.</li>\n<li>This for loop creates a variable <strong>i</strong> initialized at 1.&nbsp; At the end of every iteration, it increments <strong>i</strong> by one.&nbsp; It stops iterating when <strong>i</strong> exceeds <strong>no_civs</strong>.</li>\n<li>Recall this accesses the <em>i</em>th element</li>\n<li>Updates the civ</li>\n<li>Store the updated civ in the list</li>\n<li>Marks the end of the for() loop</li>\n<li>Returns the updates list <strong>civs</strong></li>\n</ol>\n<p>EXERCISE: Check to see that this properly updates the civilizations in your list.&nbsp; And by the way, what civilization does Humanity become in the end?</p>\n<p>&nbsp;</p>\n<p>Now the last step of the simulation is to randomly decide if a new civilization emerges.</p>\n<p>PLANET-GENERATION PROCEDURE</p>\n<ol>\n<li>Generate a random number from 0 to 1.&nbsp; If it is less than <strong>a</strong>, no new civilization emerges, and we exit the procedure.</li>\n<li>Supposing we passed step 1, now we pick a random point <strong>x </strong>in the universe.&nbsp; If that point is in an uninhabited region of space we create a new Type 0 civilization with home planet located at <strong>x</strong>.&nbsp; But if point <strong>x</strong> is located within the sphere of colonization of any Type III civilization, no new civilization is generated.</li>\n</ol>\n<p>For this, we need a way to draw random points on the unit 3-sphere, and a method for checking whether a point lies within the sphere of colonization of an existing civilization.&nbsp; There is a cool trick from probability theory for generating points from the surface of an N-sphere, which takes advantage of the fact that the multivariate Gaussian has spherical symmetry.&nbsp; The <strong>rnorm()</strong> function samples from the standard Gaussian with mean 0 and variance 1.&nbsp; After we generate a vector which has 4 independently and identically distributed mean 0 Gaussian components, all we have to do is normalize it so that it has radius 1.</p>\n<blockquote>\n<p># Code Block 7<br />random_in_sphere = function() {<br />&nbsp; x = rnorm(4)<br />&nbsp; r = sqrt(sum(x^2))<br />&nbsp; return(x/r)<br />}</p>\n</blockquote>\n<p>EXERCISE: Try out the new function by entering the command <strong>random_in_sphere()</strong>, see that you get random points with radius 1.</p>\n<p>Next we need to code the function <strong>is_uncolonized(x)</strong>, which returns FALSE if the point x is within the sphere of colonization of an existing civilization, and TRUE otherwise.&nbsp; First, we check to see if there are any existing civilizations in the universe at all.&nbsp; If not, there is nothing to check, and we return TRUE instantly.&nbsp; But if there are any existing civilizations, we will have to see if our point x is within the colonization sphere of any of the existing civilizations.&nbsp; We will go through the list of existing civilizations one by one. using a for() loop. If at any point we find that x is within a colonization sphere, we return FALSE.&nbsp; However, if we make it through the for() loop, that means the point x was in none of the colonization spheres, so we can return TRUE.</p>\n<blockquote>\n<p># Code Block 8<br />is_uncolonized = function(civs,x) {<br />&nbsp; no_civs = length(civs)<br />&nbsp; if (no_civs == 0) {<br />&nbsp;&nbsp;&nbsp; return(TRUE)<br />&nbsp; }<br />&nbsp; for (i in 1:no_civs) {<br />&nbsp;&nbsp;&nbsp; current_civ = civs[[i]]<br />&nbsp;&nbsp;&nbsp; y = current_civ$location<br />&nbsp;&nbsp;&nbsp; if (distance(x,y) &lt; current_civ$r_c) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return(FALSE)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp; }<br />&nbsp; return(TRUE)<br />}</p>\n</blockquote>\n<p>EXERCISE: Test these functions.</p>\n<p>We are almost done with the simulation part of the code.&nbsp; We write a function to implement the planet generation step, and another to handle the simulation step in its entirety.</p>\n<blockquote>\n<p># Code Block 9<br />planet_generation = function(civs) {<br />&nbsp; no_civs = length(civs)<br />&nbsp; # with probability 1-a, no is created civilization<br />&nbsp; if (runif(1) &gt; a) { return(civs) }<br />&nbsp; #now we pick a random point<br />&nbsp; x = random_in_sphere()<br />&nbsp; #is it uninhabited?<br />&nbsp; if (is_uncolonized(civs,x)) {<br />&nbsp;&nbsp;&nbsp; #yay! now we get to add a new civilization<br />&nbsp;&nbsp;&nbsp; no_civs = no_civs + 1<br />&nbsp;&nbsp;&nbsp; new_civ = list(location=x, type=0, r_v=0, r_c=0)<br />&nbsp;&nbsp;&nbsp; civs[[no_civs]] = new_civ<br />&nbsp; }<br />&nbsp; civs<br />}<br />simulation_step = function(civs) {<br />&nbsp; civs = transition_all(civs)<br />&nbsp; civs = planet_generation(civs)<br />&nbsp; civs<br />}</p>\n</blockquote>\n<p>EXERCISE: Run a few simulation steps.&nbsp; Increase the parameters a, b, etc. if things are too slow.</p>\n<p>Now, we'll write a function for generating the entire simulation history.&nbsp; The function will return a list, <strong>history</strong>, whose <em>t</em>th element will be the list of civilizations <strong>civs</strong> at time step<em> t</em> of the simulation.</p>\n<blockquote>\n<p># Code Block 10<br />simulation = function() {<br />&nbsp; history = list()<br />&nbsp; civs = list()<br />&nbsp; for (t in 1:1000) {<br />&nbsp;&nbsp;&nbsp; civs = simulation_step(civs)<br />&nbsp;&nbsp;&nbsp; history[[t]] = civs<br />&nbsp; }<br />&nbsp; history<br />}</p>\n</blockquote>\n<p>EXERCISE: Run an entire simulation.&nbsp; How many civilizations are around at time 1000?</p>\n<p>Fantastic!&nbsp; Now we can generate entire simulated histories of universes with adjustable parameters!&nbsp; Now what?</p>\n<p>The reader quickly finds that it's a cumbersome task to manually inspect all of these <strong>history</strong> objects generated by the simulation.</p>\n<p>We leave it as a challenge to any reader experienced in R to come up with a function for visually displaying <strong>history</strong> objects in a pleasing manner.</p>\n<p>In the <a href=\"/lw/5q7/colonization_models_a_tutorial_on_computational/\">second part of this tutorial</a>, we will generate lots and lots of <strong>history</strong> objects, and write functions for extracting relevant information from these objects, in order to do Bayesian inference.</p>\n<p>EXERCISE: Modify the simulation so that all civilizations of type II or lower which come within the colonization sphere of a Type III civilization are destroyed.&nbsp; (Remember that destroyed Type II civs are still 'visible'!)</p>\n<p>EXERCISE: Implement the correct distance function for the length of the geodesic between two points on a 3-sphere.&nbsp; Does this affect results in Part 2?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HFou6RHqFagkyrKkW": 3, "2JdCpTrNgBMNpJiyB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LKQNdsgqgWX4SYTqw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 41, "extendedScore": null, "score": 6.1e-05, "legacy": true, "legacyId": "7417", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong id=\"Introduction\">Introduction</strong></p>\n<p>Are we alone in the universe?&nbsp; How likely is our species to survive the transition from a <a href=\"http://en.wikipedia.org/wiki/Kardashev_scale\">Type 0 to a Type II civilization</a>?&nbsp; The answers to these questions would be of immense interest to our race; however, we have few tools to reason about these questions.&nbsp; This does not stop us from wanting to find answers to these questions, often by employing controversial principles of inference such as 'anthropic reasoning.'&nbsp; The reader can find a wealth of stimulating discussion about anthropic reasoning at <a href=\"http://meteuphoric.wordpress.com/\">Katja Grace's blog</a>, the site from which this post takes its inspiration.&nbsp; The purpose of this post is to give a quantitatively oriented approach to anthropic reasoning, demonstrating how computer simulations and Bayesian inference can be used as tools for exploration.</p>\n<p>The central mystery we want to examine is the <em>Fermi paradox</em>: the fact that</p>\n<ol>\n<li>we are an intelligent civilization</li>\n<li>we cannot observe any signs that other intelligent civilizations ever existed in the universe</li>\n</ol>\n<p>One explanation for the Fermi paradox is that we are the only intelligent civilization in the universe.&nbsp; A far more chilling explanation is that intelligent civilizations emerge quite frequently, but that all other intelligent civilizations that have come before us ended up destroying themselves before they could manage to make their mark on their universe.</p>\n<p>We can reason about which of the above two explanations are more likely if we have the audacity to assume <em>a model</em> for the emergence and development of civilizations in universe 'similar to ours.'&nbsp; In such a model, it is usually useful to distinguish different 'types' of civilizations.&nbsp; Type 0 civilizations are civilizations with similar levels of technology as ourselves.&nbsp; If a Type 0 civilization survives long enough and accumulates enough scientific knowledge, it can make a transition to a Type I civilization--a civilization which has attained mastery of their home planet.&nbsp; A Type I civilization, over time, can transition to a Type II civilization if it colonizes its solar system.&nbsp; We would suppose that a nearby civilization would have to have reached Type II in order for their activities to be prominent enough for us to be able to detect them.&nbsp; In the original terminology, a Type III civilization is one which has mastery of its galaxy, but in this post we take it to mean something else.</p>\n<p>The simplest model for the emergence and development of civilizations would have to specify the following:</p>\n<ol>\n<li>the rate at which intelligent life appears in universes similar to ours;</li>\n<li>the rate at which these intelligent species transition from Type 0 to Type II, Type III civilizations--or self-destruct in the process;</li>\n<li>the visibility of Type II and Type III civilizations to Type 0 civilizations elsewhere</li>\n<li>the proportion of advanced civilizations which ultimately adopt expansionist policies;</li>\n<li>the speed at which those Type III civilizations can expand and colonize the universe.</li>\n</ol>\n<p>In the model we propose in the post, the above parameters are held to be constant throughout the entire history of the universe.&nbsp; The importance of the model is that after given a particular specification of the parameters, we can apply <a href=\"http://en.wikipedia.org/wiki/Bayesian_inference\">Bayesian inference</a> to see how well the model explains the Fermi paradox.&nbsp; The idea is to simulate many different histories of universes for a given set of parameters, so as to find the <em>expected number of observers who observe the Fermi paradox</em> given a particular specification of the parameters.&nbsp; More details about Bayesian inference given in Part 2 of this tutorial.</p>\n<p>This post is targeted at readers who are interested in simulating the emergence and expansion of intelligent civilizations in 'universes similar to ours' but who lack the programming knowledge to code these simulations.&nbsp; In this post we will guide the reader through the design and production of a relatively simple universe model and the methodology for doing 'anthropic' Bayesian inference using the model.</p>\n<p><a id=\"more\"></a></p>\n<p><strong id=\"I__The_model\">I. The model</strong></p>\n<p>&nbsp;</p>\n<p>We are going to simulate the entire history, or time-line, of a universe.&nbsp; We assume that the universe has a finite lifespan; readers are invited to attempt to extend the model to allow for indefinite lifespans.&nbsp; For computational simplicity, we will break up the history of the universe into, say, 1000 discrete epochs, where each epoch might represent twenty million years.&nbsp; The epoch number is represented by a variable <em>t </em>ranging from 1 to 1000.&nbsp; The epoch <em>t = 1</em> does not represent the very beginning of the universe, but rather, the earliest period where intelligent life has a significant chance of appearing; likewise, the last epoch <em>t=</em>1000 would be the last period in which the cosmology of the universe allows for the emergence of intelligent life.</p>\n<p>We assume the cosmological model of space as a (the three-dimensional surface) of a four-dimensional unit sphere centered at the origin.&nbsp; That is, the universe is represented as the set of all points <em>(x,y,z,w)</em> where <em>x^2 + y^2 + z^2 + w^2 = 1</em>.&nbsp; Note that since w can be calculated from <em>x, y, z</em>, only the points<em> x, y, z </em>need be stored in the simulation.</p>\n<p>Now it is important to correctly specify the <em>speed of light</em> in terms of the units we have chosen for time and space.&nbsp; Assuming the <a href=\"http://en.wikipedia.org/wiki/Observable_universe\">maximum geodesic</a> of the universe is 100 billion light years, and given that each time step is twenty million years, this would put the<em> </em>speed of light as <strong>s = 4 x 10^-4</strong> in our units.</p>\n<p>One could go further to populate this universe with randomly located habitable planets.&nbsp; However, we would need a lot of planets for a realistic model, so this approach would not be particularly computationally efficient.&nbsp; Instead, we will <em>assume that the number of habitable planets in a region of space is proportional to its volume.&nbsp; </em>This will allow us to do the simulation without specifying the location of the planets.</p>\n<p>Now we need to specify the mechanism by which new Type 0 civilizations emerge in our universe.&nbsp; For the sake of simplicity, <em>at most one new Type 0 civilization appears in each time step.</em> (A more realistic model might employ a Poisson distribution to determine the number of new civilizations at each time step.)&nbsp; The location of the new civilization is located uniformly at random within the uninhabited volume of the universe.&nbsp; We will suppose that no new Type 0 civilization can emerge on planets already inhabited by others civilizations.&nbsp; Thus, the probability that a new Type 0 civilization emerges must depend on how much of the universe is uninhabited.&nbsp; We will posit that this probability is a constant factor, <strong>a</strong>, times the proportion of universe which is uninhabited.&nbsp; A more advanced model might have the propensity for life factor <strong>a </strong>vary with time, to account for planetary and stellar evolution.</p>\n<p>Next we need to specify how existing civilizations transition to the next stage, self-destruct, become visible or colonize other planets. We will use four types of civilizations:</p>\n<ul>\n<li>Type 0.&nbsp; Civilizations at around our stage of development.</li>\n<li>Type II.&nbsp; Civilizations which are developed enough to be visible to others.&nbsp; However, we make a distinction between two classes of Type II civilizations, a distinction not present in the original formulation of the Kardeshev scale.</li>\n<li>Type IIa. Civilizations which have adopted a non-expansionist policy, and which will remain Type IIa civilizations forever.</li>\n<li>Type IIb. Civilizations which may become Type III (expansionist) civilizations in the future</li>\n<li>Type III. We make the extreme assumption that <em>all Type III civilizations are expansionist.</em>&nbsp; That is, once a civilization becomes Type III, it starts colonizing the surrounding space as quickly as possible.&nbsp; Space colonized by Type III civilizations is<em> sterilized</em>, it can not longer produce new Type 0 civilizations.</li>\n</ul>\n<p>We have not included the \"Type I\" civilization in our model, since for our purposes Type I civilizations are virtually identical to Type 0 civilizations.&nbsp; In the same way, Type IIa civilizations would be virtually identical to 'peaceful' Type III civilizations for the purposes of out model, which is why hold all Type III civilizations to be expansionist.</p>\n<p>Here will be our model for this process:</p>\n<ol>\n<li>At each time step, the 'sphere of colonization' of a type III civilization increases its radius by the maximum speed of colonization, <strong>k * s.</strong>&nbsp; Here we have the speed multiplier <strong>k</strong> as constant, but a more realistic model might have the speed of colonization increase as the Type III civilization gains more technology</li>\n<li>Each Type IIb civilization has a probability <strong>e</strong> of transitioning to a Type III civilization.&nbsp; </li>\n<li>Each Type 0 civilization has probability <strong>b</strong> of self-destructing and probability <strong>c</strong> of transitioning to Type IIa and probability <strong>d</strong> of transitioning to Type IIb (and remains Type 0 with probability 1-b-c-d).</li>\n<li>When a civilization transitions to either Type IIa or Type IIb, it becomes 'visible.'&nbsp; A sphere of 'visibility' expands from the location of the civilization at the speed of light, and all observers within this expanding sphere become alerted to the existence of the Type II civilization.</li>\n<li>With probability <strong>a</strong>, locate a random point <strong>x</strong> within the unit sphere which is a candidate site for a new Type 0 civilization.&nbsp; If that point is within the colonization sphere of any existing civilization, no new Type 0 civilization is generated.&nbsp;&nbsp; Otherwise, create a new Type 0 civilization at that point.</li>\n</ol>\n<p>To sum up, each civilization in our universe has four variables associated with it.</p>\n<ol>\n<li>The location of its 'home planet', in three-dimensional coordinates.</li>\n<li>Its civilization stage (Type 0, Type IIa, Type IIb, Type III)</li>\n<li>Its radius of visibility</li>\n<li>Its radius of colonization</li>\n</ol>\n<p>In each step of the simulation, we need to store these quantities in a data structure.&nbsp; The data structure for the simulation should have a slot for each time step of the simulation; in each slot, we will store a list of civilizations with their associated quantities.</p>\n<p>After we have run the simulation, we can extract various quantities of interest from the data structure, for example, we might want to know:</p>\n<ol>\n<li>How many Type 0 civilizations exist at each time step?</li>\n<li>How many of these Type 0 civilizations are in the 'sphere of visibility' of a Type II+ civilization, at each time step?</li>\n</ol>\n<p>&nbsp;</p>\n<p><strong id=\"II__Implementation\">II. Implementation</strong></p>\n<p>&nbsp;</p>\n<p>The program we will be using is the <a href=\"http://cran.r-project.org/\">R programming environment</a>, an open-source computing environment commonly used for statistical data analysis.&nbsp; No programming experience is assumed, but readers are expected to be able to learn by example.&nbsp; Conversely, readers with programming skills can skip to the quoted code blocks, reading the explanations when needed.</p>\n<p>After you install and run R, you should see a blank terminal.&nbsp; To run the code, simply copy and paste the provided code into the buffer and press 'enter.'&nbsp; We give the code in blocks so as to make copying and pasting more convenient.&nbsp; Here is the first block of code--don't be alarmed!&nbsp; We will walk through the code line-by-line immediately afterwards.</p>\n<blockquote>\n<p># Example 1<br>s = 4e-4<br>a = 0.10<br>b = 0.20; c = 0.05; d = 0.05<br>e = 0.10<br>k = 0.90<br>civs = list()<br>earth_coordinates = c(0.1,0.2,0.3,sqrt(.86))<br>human_civ = list(location=earth_coordinates,type=0,r_v=0,r_c=0,age=0)<br>zerg_civ = list(location=c(0.2,0.1,0.3,sqrt(.86)),type=3,r_v=0.2,r_c=0.1,age=20)<br>civs[[1]] = human_civ<br>civs[[2]] = zerg_civ</p>\n</blockquote>\n<p>Now we'll explain the code for \"Example 1\", starting from the top.</p>\n<ol>\n<li>The first line is a comment.&nbsp; All of the text to the right of a hash '#' symbol is ignored by the interpreter</li>\n<li>'s = 4e-4' sets the speed of light to 4 x 10^-4.&nbsp; The 'e' stands for \"times ten to the power of...\"</li>\n<li>sets the probability <strong>a</strong> to 1/100.&nbsp; Recall this is the base rate for a Type 0 civilization to emerge in a time step.</li>\n<li>sets the probabilities <strong>b, c, d</strong>.&nbsp; The semicolon ';' separates multiple commands that are on the same line</li>\n<li>sets the probability <strong>e</strong>, (type IIb -&gt; type III transition)</li>\n<li>sets the constant <strong>k</strong> to 0.9.&nbsp; That is, the maximum speed of colonization is taken to be 90% of the speed of light.</li>\n<li><strong>civs</strong> is a data structure for storing the information of all the civilizations which exist at a particular time step.&nbsp; It will be a list, with an element for each civilization in existence at that time</li>\n<li><strong>earth_coordinates</strong> is a vector with three elements: (0.1, 0.2, 0.3).&nbsp; The <strong>c()</strong> function forms a vector out of the enclosed numbers.&nbsp; As you might guess, this particular vector is the spatial coordinates of planet Earth in our example.</li>\n<li><strong>human_civ </strong>is a data structure containing all the information needed to describe (our) civilization: <strong>location</strong> will be the vector given by earth_coordinates: (0.1,0.2,0.3);<strong> type=0 </strong>indicates a Type 0 civilization, <strong>r_v</strong> is the radius of our sphere of visibility, which is zero because we haven't reached Type II yet.&nbsp; <strong>r_c </strong>is the radius of our sphere of colonization, which is zero because we haven't reached Type III yet.</li>\n<li><strong>zerg_civ</strong> holds the information for another civilization, which is older than ours by 400 million years. It has a home planet with coordinates (0.2,0.1,0.2), which has reached Type III, and which can be seen by all observers within distance 0.2, and which has colonized all planets within distance 0.1 of its home planet!</li>\n<li><strong>civs[[1]] = human_civ </strong>sets the first element of the list civs to be the data structure encapsulation information about our civilization.&nbsp; Yes, you can have the elements of lists be other lists--we will be doing that a lot.</li>\n<li><strong>civs[[2]] = zerg_civ </strong>sets the second element of the list civs to be the information about the Zerg civilization</li>\n</ol>\n<p>(In this code, we will have the parameters a, b, c, d, e, k,s be global variables.&nbsp; This is not the best coding practice, but it simplifies the code for this tutorial.)</p>\n<p>It is certainly cause for alarm that there is a hostile Type III civilization in our vicinity.&nbsp; Can we see them?&nbsp; Have we already been colonized by them?&nbsp; To answer these questions, we need to program a distance function.&nbsp; We'll be lazy here and use the Euclidean distance, instead of calculating the length of the geodesic on a 3-sphere.</p>\n<blockquote>\n<p># Code Block 1<br>distance = function(x,y) {<br>&nbsp; return(sqrt(sum((x-y)^2)))<br>}</p>\n</blockquote>\n<ol>\n<li><em></em></li>\n<li><strong>distance </strong>is the name of the function.&nbsp;&nbsp; <strong>= function(x,y)</strong> tells R that this is to be a function with two arguments, x and y.&nbsp; The <strong>{</strong> brace, or 'begin-block symbol', means that the subsequent code will be part of the functionthe <strong>return() </strong>command is for returning the 'answer' computed by the function.&nbsp; In this case, the answer is the Euclidean distance of the vectors x and y; &nbsp; <strong>sqrt()</strong> evaluates the square root of the argument.&nbsp; <strong>sum()</strong> evaluates the sum of the components of a vector.&nbsp; <strong>^2 </strong>applied to a vector squares each component of the vector.</li>\n<li><strong>}</strong> or 'end-block symbol' indicates that we are done writing the code for the function</li>\n</ol>\n<p>After you copy and paste the above code, there will be a new function in the environment, distance().&nbsp; We will use it now</p>\n<blockquote>\n<p># Example 2<br>x = human_civ$location; x<br>y = zerg_civ$location; y<br>d = distance(x,y); d<br>d &lt; zerg_civ$r_v<br>if (d &lt; zerg_civ$r_v) { print(\"enemy sighted!\") }<br>if (d &lt; zerg_civ$r_c) { print(\"war has begun...\") }</p>\n</blockquote>\n<p>Line 2: look back at how we defined the list human_civ.&nbsp; The <strong>$ </strong>symbol allows you to access the element of that list labeled as the 'location.'</p>\n<p>Line 4: Recall x is the coordinates of our planet, and y is the coordinates of the zerg home planet.&nbsp; We call the function we just defined to find the distance between our home planet and the zerg home planet, and then we store the answer in a new variable, d</p>\n<p>Line 5: A boolean expression: is d less than the zerg's radius of visibility?</p>\n<p>Line 6 &amp; 7: The if() statement executes the code in brackets only if the statement in the parentheses is true</p>\n<p>The '&lt;' symbol is obviously the comparison 'less than'.&nbsp; Less obvious: '&gt;=' for greater-or-equal-to, '==' for equal to.&nbsp; A common newbie mistake is to confuse the assignment '=' symbol for the equality '==' symbol--they have very different meanings!</p>\n<p>EXERCISE 1:&nbsp; Add some additional civilizations to the list <strong>civs</strong> manually.&nbsp; We code the civilization types as follows</p>\n<ul>\n<li>type=0 for Type 0 civs</li>\n<li>type=-1 for dead civilizations</li>\n<li>type=1 for Type IIa (non-expansionist) civs</li>\n<li>type=2 for Type IIb civs</li>\n<li>type=3 for Type III (expansionist) civs</li>\n</ul>\n<p>Now we start on coding the simulation step.&nbsp; Recall the simulation step consist of two parts.&nbsp; In the first step, we roll to see if any of the existing civilizations transition to another stage, and we update the radii of visibility and colonization for Type II+ civilizations.&nbsp; In the second step, we roll to see if a new Type 0 civilization emerges.</p>\n<p>We will code a separate transition function for each Type of civilization.&nbsp; We'll start with the Type IIb and Type III civilizations, they are the easiest.</p>\n<blockquote>\n<p># Code Block 2<br>transition_type2b = function(civ) {<br>&nbsp; civ$r_v = civ$r_v + s<br>&nbsp; civ<br>}<br>transition_type3 = function(civ) {<br>&nbsp; civ$r_v = civ$r_v + s<br>&nbsp; civ$r_c = civ$r_c + k * s<br>&nbsp; civ<br>}</p>\n</blockquote>\n<p>Notice that there is no return() statement in either function.&nbsp; That is because a function automatically returns the value in the last line (<strong>civ</strong> in this case) whenever it makes it all the way to the last line.</p>\n<p>Now, test to see if the transition function works properly on the Zerg civ.&nbsp; Also test the transition for Type 2b planets on any Type 2b planet you created in Exercise 1.</p>\n<blockquote>\n<p># Example 3<br>zerg_civ = civs[[2]]<br>zerg_civ = transition_type3(zerg_civ)<br>zerg_civ<br>civs[[2]] = zerg_civ</p>\n</blockquote>\n<p>Notice how the transition function works.&nbsp; The transition function returns an updated version of the civ it was given.&nbsp; But it does not update the original civ automatically: you have to make sure that the updated state gets stored in the appropriate place.</p>\n<p>Now, we want to make a function which automatically chooses the right transition for a given civ.&nbsp; Also, we can make it keep track of the civilization's age.</p>\n<blockquote>\n<p># Code Block 3<br>transition_civ = function(civ) {<br>&nbsp; civ$age = civ$age + 1<br>&nbsp; type = civ$type<br>&nbsp; if (type == 0) { civ = transition_type0(civ) }<br>&nbsp; if (type == 1) { civ = transition_type2a(civ) }<br>&nbsp; if (type == 2) { civ = transition_type2b(civ) }<br>&nbsp; if (type == 3) { civ = transition_type3(civ) }<br>&nbsp; civ<br>}</p>\n</blockquote>\n<p>EXERCISE: What happens if you call the transition() function on a dead (type=-1) civilization?</p>\n<p>In order to handle the transition rolls for type 0 and type IIa civilizations, we need a way to generate random numbers.&nbsp; R has a built-in function to generate random numbers from 0 to 1, the <strong>runif()</strong> function, which we demonstrate.</p>\n<blockquote>\n<p># Code Block 4<br>transition_type2a = function(civ) {<br>&nbsp; civ$r_v = civ$r_v + s<br>&nbsp; if (runif(1) &lt; e) {<br>&nbsp;&nbsp;&nbsp; civ$type = 3<br>&nbsp; }<br>&nbsp; civ&nbsp; <br>}</p>\n</blockquote>\n<p>The command <strong>runif(1)</strong> returns one random number between 0 and 1.&nbsp; See that the boolean statement <strong>(runif(1) &lt; e) </strong>is true with probability e.</p>\n<p>Now the transition for a Type 0 civilization is more complicated: it has a probability of dying, of going to Type IIa, of going to Type IIb, or staying type 0, and all these events are mutually exclusive.&nbsp; There is a simple trick for handling all that with a single roll.</p>\n<blockquote>\n<p># Code Block 5<br>transition_type0 = function(civ) {<br>&nbsp; roll = runif(1)<br>&nbsp; if (roll &lt; b) { civ$type = -1; return(civ) }<br>&nbsp; roll = roll - b<br>&nbsp; if (roll &lt; c) { civ$type = 1; return(civ) }<br>&nbsp; roll = roll - c<br>&nbsp; if (roll &lt; d) { civ$type = 2; return(civ) }<br>&nbsp; civ<br>}</p>\n</blockquote>\n<p>EXERCISE:&nbsp; Does the above code indeed transition the civ to: dead with probability b, Type IIa with probability c, Type IIb with probability d?</p>\n<p>Finally, we make a function for automatically applying the transition function to every civ in a list.&nbsp; How we will go through the list is to use a <strong>for() </strong>loop to access each of the elements civs[[1]], civs[[2]], all the way up to civs[[no_civs]].</p>\n<blockquote>\n<p># Code Block 6<br>transition_all = function(civs) {<br>&nbsp; no_civs = length(civs)<br>&nbsp; if (no_civs == 0) { return(civs) }<br>&nbsp; for (i in 1:no_civs) {<br>&nbsp;&nbsp;&nbsp; civ = civs[[i]]<br>&nbsp;&nbsp;&nbsp; civ = transition_civ(civ)<br>&nbsp;&nbsp;&nbsp; civs[[i]] = civ<br>&nbsp; }<br>&nbsp; civs<br>}</p>\n</blockquote>\n<ol>\n<li>[comment]</li>\n<li>Recall the usage of the function: you should call <strong>civs = transition_all(civs)</strong> to update the list <strong>civs</strong></li>\n<li>This step is important since R will give an error if you try to access an element in an empty list</li>\n<li>The function <strong>length()</strong> returns the number of elements contained in a list.</li>\n<li>This for loop creates a variable <strong>i</strong> initialized at 1.&nbsp; At the end of every iteration, it increments <strong>i</strong> by one.&nbsp; It stops iterating when <strong>i</strong> exceeds <strong>no_civs</strong>.</li>\n<li>Recall this accesses the <em>i</em>th element</li>\n<li>Updates the civ</li>\n<li>Store the updated civ in the list</li>\n<li>Marks the end of the for() loop</li>\n<li>Returns the updates list <strong>civs</strong></li>\n</ol>\n<p>EXERCISE: Check to see that this properly updates the civilizations in your list.&nbsp; And by the way, what civilization does Humanity become in the end?</p>\n<p>&nbsp;</p>\n<p>Now the last step of the simulation is to randomly decide if a new civilization emerges.</p>\n<p>PLANET-GENERATION PROCEDURE</p>\n<ol>\n<li>Generate a random number from 0 to 1.&nbsp; If it is less than <strong>a</strong>, no new civilization emerges, and we exit the procedure.</li>\n<li>Supposing we passed step 1, now we pick a random point <strong>x </strong>in the universe.&nbsp; If that point is in an uninhabited region of space we create a new Type 0 civilization with home planet located at <strong>x</strong>.&nbsp; But if point <strong>x</strong> is located within the sphere of colonization of any Type III civilization, no new civilization is generated.</li>\n</ol>\n<p>For this, we need a way to draw random points on the unit 3-sphere, and a method for checking whether a point lies within the sphere of colonization of an existing civilization.&nbsp; There is a cool trick from probability theory for generating points from the surface of an N-sphere, which takes advantage of the fact that the multivariate Gaussian has spherical symmetry.&nbsp; The <strong>rnorm()</strong> function samples from the standard Gaussian with mean 0 and variance 1.&nbsp; After we generate a vector which has 4 independently and identically distributed mean 0 Gaussian components, all we have to do is normalize it so that it has radius 1.</p>\n<blockquote>\n<p># Code Block 7<br>random_in_sphere = function() {<br>&nbsp; x = rnorm(4)<br>&nbsp; r = sqrt(sum(x^2))<br>&nbsp; return(x/r)<br>}</p>\n</blockquote>\n<p>EXERCISE: Try out the new function by entering the command <strong>random_in_sphere()</strong>, see that you get random points with radius 1.</p>\n<p>Next we need to code the function <strong>is_uncolonized(x)</strong>, which returns FALSE if the point x is within the sphere of colonization of an existing civilization, and TRUE otherwise.&nbsp; First, we check to see if there are any existing civilizations in the universe at all.&nbsp; If not, there is nothing to check, and we return TRUE instantly.&nbsp; But if there are any existing civilizations, we will have to see if our point x is within the colonization sphere of any of the existing civilizations.&nbsp; We will go through the list of existing civilizations one by one. using a for() loop. If at any point we find that x is within a colonization sphere, we return FALSE.&nbsp; However, if we make it through the for() loop, that means the point x was in none of the colonization spheres, so we can return TRUE.</p>\n<blockquote>\n<p># Code Block 8<br>is_uncolonized = function(civs,x) {<br>&nbsp; no_civs = length(civs)<br>&nbsp; if (no_civs == 0) {<br>&nbsp;&nbsp;&nbsp; return(TRUE)<br>&nbsp; }<br>&nbsp; for (i in 1:no_civs) {<br>&nbsp;&nbsp;&nbsp; current_civ = civs[[i]]<br>&nbsp;&nbsp;&nbsp; y = current_civ$location<br>&nbsp;&nbsp;&nbsp; if (distance(x,y) &lt; current_civ$r_c) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return(FALSE)<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp; }<br>&nbsp; return(TRUE)<br>}</p>\n</blockquote>\n<p>EXERCISE: Test these functions.</p>\n<p>We are almost done with the simulation part of the code.&nbsp; We write a function to implement the planet generation step, and another to handle the simulation step in its entirety.</p>\n<blockquote>\n<p># Code Block 9<br>planet_generation = function(civs) {<br>&nbsp; no_civs = length(civs)<br>&nbsp; # with probability 1-a, no is created civilization<br>&nbsp; if (runif(1) &gt; a) { return(civs) }<br>&nbsp; #now we pick a random point<br>&nbsp; x = random_in_sphere()<br>&nbsp; #is it uninhabited?<br>&nbsp; if (is_uncolonized(civs,x)) {<br>&nbsp;&nbsp;&nbsp; #yay! now we get to add a new civilization<br>&nbsp;&nbsp;&nbsp; no_civs = no_civs + 1<br>&nbsp;&nbsp;&nbsp; new_civ = list(location=x, type=0, r_v=0, r_c=0)<br>&nbsp;&nbsp;&nbsp; civs[[no_civs]] = new_civ<br>&nbsp; }<br>&nbsp; civs<br>}<br>simulation_step = function(civs) {<br>&nbsp; civs = transition_all(civs)<br>&nbsp; civs = planet_generation(civs)<br>&nbsp; civs<br>}</p>\n</blockquote>\n<p>EXERCISE: Run a few simulation steps.&nbsp; Increase the parameters a, b, etc. if things are too slow.</p>\n<p>Now, we'll write a function for generating the entire simulation history.&nbsp; The function will return a list, <strong>history</strong>, whose <em>t</em>th element will be the list of civilizations <strong>civs</strong> at time step<em> t</em> of the simulation.</p>\n<blockquote>\n<p># Code Block 10<br>simulation = function() {<br>&nbsp; history = list()<br>&nbsp; civs = list()<br>&nbsp; for (t in 1:1000) {<br>&nbsp;&nbsp;&nbsp; civs = simulation_step(civs)<br>&nbsp;&nbsp;&nbsp; history[[t]] = civs<br>&nbsp; }<br>&nbsp; history<br>}</p>\n</blockquote>\n<p>EXERCISE: Run an entire simulation.&nbsp; How many civilizations are around at time 1000?</p>\n<p>Fantastic!&nbsp; Now we can generate entire simulated histories of universes with adjustable parameters!&nbsp; Now what?</p>\n<p>The reader quickly finds that it's a cumbersome task to manually inspect all of these <strong>history</strong> objects generated by the simulation.</p>\n<p>We leave it as a challenge to any reader experienced in R to come up with a function for visually displaying <strong>history</strong> objects in a pleasing manner.</p>\n<p>In the <a href=\"/lw/5q7/colonization_models_a_tutorial_on_computational/\">second part of this tutorial</a>, we will generate lots and lots of <strong>history</strong> objects, and write functions for extracting relevant information from these objects, in order to do Bayesian inference.</p>\n<p>EXERCISE: Modify the simulation so that all civilizations of type II or lower which come within the colonization sphere of a Type III civilization are destroyed.&nbsp; (Remember that destroyed Type II civs are still 'visible'!)</p>\n<p>EXERCISE: Implement the correct distance function for the length of the geodesic between two points on a 3-sphere.&nbsp; Does this affect results in Part 2?</p>", "sections": [{"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "I. The model", "anchor": "I__The_model", "level": 1}, {"title": "II. Implementation", "anchor": "II__Implementation", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["k4p6AQnP4kiSW56KB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T03:54:29.547Z", "modifiedAt": null, "url": null, "title": "Colonization models: a tutorial on computational Bayesian inference (part 2/2)", "slug": "colonization-models-a-tutorial-on-computational-bayesian", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:01.098Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "snarles", "createdAt": "2009-06-01T03:48:38.132Z", "isAdmin": false, "displayName": "snarles"}, "userId": "YsmFaM5MdsDW8GNop", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k4p6AQnP4kiSW56KB/colonization-models-a-tutorial-on-computational-bayesian", "pageUrlRelative": "/posts/k4p6AQnP4kiSW56KB/colonization-models-a-tutorial-on-computational-bayesian", "linkUrl": "https://www.lesswrong.com/posts/k4p6AQnP4kiSW56KB/colonization-models-a-tutorial-on-computational-bayesian", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Colonization%20models%3A%20a%20tutorial%20on%20computational%20Bayesian%20inference%20(part%202%2F2)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AColonization%20models%3A%20a%20tutorial%20on%20computational%20Bayesian%20inference%20(part%202%2F2)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4p6AQnP4kiSW56KB%2Fcolonization-models-a-tutorial-on-computational-bayesian%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Colonization%20models%3A%20a%20tutorial%20on%20computational%20Bayesian%20inference%20(part%202%2F2)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4p6AQnP4kiSW56KB%2Fcolonization-models-a-tutorial-on-computational-bayesian", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4p6AQnP4kiSW56KB%2Fcolonization-models-a-tutorial-on-computational-bayesian", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2472, "htmlBody": "<p><strong>Recap</strong></p>\n<p><a href=\"/lw/5q1/colonization_models_a_programming_tutorial_part_12/\">Part 1</a> was a tutorial for programming a simulation for the emergence and development of intelligent species in a universe 'similar to ours.'&nbsp; In part 2, we will use the model developed in part 1 to evaluate different explanations of the <a href=\"http://en.wikipedia.org/wiki/Fermi_paradox\"><em>Fermi paradox</em></a>. However, keep in mind that the purpose of this two-part series is for showcasing useful methods, not for obtaining serious answers.</p>\n<p>We summarize the model given in part 1:</p>\n<p>SIMPLE MODEL FOR THE UNIVERSE</p>\n<ul>\n<li>The universe is represented by the set of all points in Cartesian 4-space which are of Euclidean distance 1 from the origin (that is, the 3-sphere).&nbsp; The distance between two points is taken to be the Euclidean distance (an approximation to the spherical distance which is accurate at small scales)</li>\n<li>The lifespan of the universe consists of 1000 time steps.</li>\n<li>A photon travels <strong>s=0.0004</strong> units in a time step.</li>\n<li>At the end of each time step, there is a chance that a Type 0 civilization will spontaneously emerge in an uninhabited region of space.&nbsp; The base rate for civilization birth is controlled by the parameter <strong>a</strong>.&nbsp; But this base rate is multiplied by the proportion of the universe which remains uncolonized by Type III civilizations.</li>\n<li>In each time step, a Type 0 civilization has a probability <strong>b</strong> of self-destructing, a probability <strong>c</strong> of transitioning to a non-expansionist Type IIa civilization, and a probability <strong>d</strong> of transitioning to a Type IIb civilization.</li>\n<li>Observers can detect all Type II and Type III civilizations within their past light cones.</li>\n<li>In each time step, a Type IIb civilization has a probability <strong>e</strong> of transitioning to an expansionist Type III civilization.</li>\n<li>In each time step, all Type III civilizations colonize space in all directions, expanding their sphere of colonization by <strong>k * s</strong> units per time step.</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>Section III.&nbsp; Inferential Methodology<br /></strong></p>\n<p>In this section, no apologies are made for assuming that the reader has a solid grasp of the principles of Bayesian reasoning.&nbsp; Those currently following the tutorial from Part 1 may find it a good idea to skip to Section IV first.</p>\n<p>To dodge the philosophical controversies surrounding anthropic reasoning, we will employ an <em>impartial observer model.</em>&nbsp; Like Jaynes, we introduce a robot which is capable of Bayesian reasoning, but here we imagine a model in which such a robot is instantaneously created and <em>randomly injected</em> into the universe at a random point in space, and at a random time point chosen uniformly from 1 to 1000 (and the robot is aware that it is created via this mechanism).&nbsp; We limit ourselves to asking what kind of inferences this robot would make in a given situation.&nbsp; Interestingly, the inferences made by this robot will turn out to be quite similar to the inferences that would be made under the self-indication assumption.<a id=\"more\"></a></p>\n<p>It is important to precisely specify the observational powers of this robot.&nbsp; The robot can estimate the age of the universe, but it cannot determine its location relative to the center of the universe.&nbsp; The robot can visually detect any Type II+ civilizations within its past light cone.&nbsp; Furthermore, it we specify that the robot can detect Type 0 civilizations which are within a small distance <em>u</em> of the robot.&nbsp; We also grant the robot the power to deduce the age of any such nearby Type 0 civilizations.</p>\n<p>(In fact, we grant observational powers to this robot in order so that it has close to the same observational powers that we have.&nbsp; But for now, in order to steer clear of the philosophers, we carry on innocently and say no further.)</p>\n<p>Now, at the time of its creation, the robot so happens to notice the following data.</p>\n<p>Data <em>D</em> :</p>\n<ul>\n<li><em>D1</em>: The current time is <em>t = </em>500 plus or minus 5</li>\n<li><em>D2</em>: From my location, I can detect a single Type 0 civilization, which emerged at this time step.&nbsp; No type II+ civilizations are visible from my location, and therefore, no type II+ civilizations are visible to this nearby Type 0 civilization</li>\n</ul>\n<p>The robot is aware that the universe runs according to the 'simple model of the universe,' but it does not know the values for parameters a, b, c, d, e, and k.&nbsp; Given a hypothesis <em>H </em>as to the values of those parameters, the robot can calculate the <em>posterior probability </em>of observing data <em>D</em>.</p>\n<p>We will encode the entire <em>history</em> of the universe in the form of a random variable <em>G</em> which takes values within the space of all possible histories. Even after we fix a particular history, the space-time location of the robot within this history is still random.&nbsp; This will be an important point to remember when doing inference under this impartial observer model.</p>\n<p>Define random variable <em>N</em> to be the number of new Type 0 civilizations which are outside the sphere of visibility of any type II+ civilizations in existence at time <em>t</em> = 500. Since in our model only one civilization can appear in a time step, the random variable <em>N</em> is in fact a binary random variable. Conditioned on <em>G</em> taking a particular value <em>g</em>, the random variable <em>N</em> is a fixed number. Conditioned on a particular history <em>g,</em> the probability that the robot appears within distance <em>u </em>of such a civilization is <em>P(D2|H, D1, G=g) = (u^3) (</em><em>N|H, D1, G=g) = (u^3) (N|H, G=g).&nbsp; </em>We have <em>N|D1 = N</em> since the definition of <em>N</em> does not depend on the current time step.</p>\n<p>The robot calculates the posterior probability of the data as</p>\n<p><em>P(D|H) = P(D2|H, D1) P(D1|H) = P(D2|H, D1) (1/1000) = E[P(D2|H,D1,G)]</em>/1000</p>\n<p>= <em>E[(u^3) (N|H, D1, G)]/1000 = (u^3)/1000</em> <em>E[N|H]</em></p>\n<p>Now, supposing we wanted to compare different hypotheses <em>H1, H2</em>, etc., their posterior probabilities would all share the common constant term <em>(u^3)/1000 </em>in front.&nbsp; Since only the ratios of the posterior probabilities are relevant for inference, we drop the constant term and simply remember that</p>\n<p><em>P(D|H)</em> is proportional to <em>E[N|H]</em></p>\n<p>All we need to do, then, to evaluate the plausibility of different configurations <em>H1, H2</em>, etc. of the parameters, is to compute the value of <em>E[N|H]</em>.</p>\n<p>However, in this case, conditioning on a uniform distribution on a small interval of time <em>t</em>=[495, 505] is computationally inconvenient, because very few of the histories will have a new Type 0 civilization at those specific times.&nbsp; This means that many simulations have to be performed before we can get an approximation of <em>E[N|H] </em>to the necessary degree of accuracy.</p>\n<p>We can make our problem more computationally tractable if we weaken the observational powers of our robot; hopefully, our resulting inferences will not be altered too much by this change.&nbsp; (Readers are invited to check this by implementing the inferences for the original setup.) In the modified problem the robot is unable to determine the age of the universe, nor the age any Type 0 civilization it can detect.&nbsp; The robot observes only the following data.</p>\n<p>Data <em>D </em>:</p>\n<ul>\n<li>From my location, I can detect a single Type 0 civilization.&nbsp; No type II+ civilizations are visible from my location, and therefore, no type II+ civilizations are visible to this nearby Type 0 civilization</li>\n</ul>\n<p>For the modified problem, we redefine the random variable <em>N</em> to be the number of Type 0 civilizations outside the sphere of visibility of any Type II+ civilization at random time <em>T</em>.&nbsp; Similar to before, we have</p>\n<p><em>P(D|H) = u^3 E[E[N|H]|T]</em></p>\n<p>or</p>\n<p><em>P(D|H) </em>proportional to <em>E[E[N|H]|T]</em></p>\n<p>What is interesting about this conclusion is that it is similar to the <a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">Self-Indication Assumption</a>, which, to quote the linked Wikipedia page, is the principle:</p>\n<blockquote>\n<p>Given the fact that you exist, you should (other things equal) favor hypotheses according to which many observers exist over hypotheses on which few observers exist.</p>\n</blockquote>\n<p>Whereas here, from Bayes' rule, we have:</p>\n<blockquote>\n<p>Given the fact that a civilization exists satisfying CRITERIA X, the robot should (other things equal) favor hypotheses according to which many such civilizations exist over hypotheses on which few of them exist at randomly determined time <em>T</em></p>\n</blockquote>\n<p>&nbsp;</p>\n<p><strong>Section IV.&nbsp; Implementation and Demonstration</strong></p>\n<p>We give the code for calculating <em>E[E[N|H]|T] </em>below.</p>\n<blockquote>\n<p># Code Block 11<br />no_visibles = function(civs,x) {<br />&nbsp; no_civs = length(civs)<br />&nbsp; if (no_civs == 0) {<br />&nbsp;&nbsp;&nbsp; return(TRUE)<br />&nbsp; }<br />&nbsp; for (i in 1:no_civs) {<br />&nbsp;&nbsp;&nbsp; current_civ = civs[[i]]<br />&nbsp;&nbsp;&nbsp; y = current_civ$location<br />&nbsp;&nbsp;&nbsp; if (distance(x,y) &lt; current_civ$r_v) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return(FALSE)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp; }<br />&nbsp; return(TRUE)<br />}<br />value_n = function(history) {<br />&nbsp; sum = 0<br />&nbsp; for (t in 1:1000) {<br />&nbsp;&nbsp;&nbsp; civs = history[[t]]<br />&nbsp;&nbsp;&nbsp; no_civs = length(civs)<br />&nbsp;&nbsp;&nbsp; if (no_civs &gt; 0) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i in 1:no_civs) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; civ = civs[[i]]<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (civ$type == 0) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x = civ$location<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (no_visibles(civs, x)) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sum = sum + 1<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp; }<br />&nbsp; sum/1000<br />}<br />multiple_trials_value_n = function(reps=10) {<br />&nbsp; values = numeric(0) # empty vector<br />&nbsp; for (i in 1:reps) {<br />&nbsp;&nbsp;&nbsp; history=simulation()<br />&nbsp;&nbsp;&nbsp; values[i] = value_n(history)<br />&nbsp; }<br />&nbsp; values<br />}<br />reps = 10<br />values = multiple_trials_value_n(reps)<br /># approximate value of E[[N|H]|T]<br />mean(values)<br /># standard error of the approximation<br />sqrt(var(values)/reps)<em><br /></em></p>\n</blockquote>\n<p>For those who followed part 1, the above code should be straightforward.&nbsp; At the end we calculate a standard error since we have approximately the value of <em>E[E[N|H]|T]</em> by averaging over random samples of the random variable <em>E[N|H]|T</em>.</p>\n<p>Now we can get onto the business of comparing Bayes factors for hypotheses.&nbsp; Here we take the term 'Bayes' factor to refer to the quantity <em>P(D|H)</em>. Consider the following example hypotheses.</p>\n<p>1) <em>H1: </em>\"we are alone in the universe\" (small chance of life arising)</p>\n<blockquote>\n<p># Hypothesis 1<br />a = 0.001; b = 0; c = 0.1; d = 0; e = 0; k = 0</p>\n</blockquote>\n<p>2) <em>H2: </em>\"great filter ahead\" (high chance of life, but high chance of Type 0's self-destructing)</p>\n<blockquote>\n<p><em># Hypothesis 2<br />a = 0.1; b = 0.1; c = 0.01; d = 0; e = 0; k = 0</em></p>\n</blockquote>\n<p>3) H3: \"burning the cosmic commons\" (high chance of life and of surviving to stage III, but high speed of colonization)</p>\n<blockquote>\n<p><em># Hypothesis 3<br />a = 0.1; b = 0; c = 0; d = 0.1; e = 0.1; k = 0.9</em></p>\n</blockquote>\n<p>EXERCISE: Run Code Block 11 to calculate the Bayes factors for the above hypotheses.</p>\n<p>EXERCISE 2: Can you think of a hypothesis which maximizes the Bayes Factor?</p>\n<p>EXERCISE: After assigning prior weights to hypotheses of your choosing, modify the code in order to calculate the posterior probability that a Type 0 civ observing the Fermi paradox ultimately:</p>\n<ul>\n<li>self-destructs</li>\n<li>becomes colonized while it is a Type II or lower civilization</li>\n<li>becomes a type III civilization</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>Section V. Prior Specification; MAP estimation<br /></strong></p>\n<p>SOLUTION TO EXERCISE 2:&nbsp; We can maximize the number of Type 0 observers of the Fermi paradox, naturally, by setting <strong>b, c, d</strong> to zero so that Type 0 civilizations remain Type 0 civilizations forever, and no Type II+ civilizations ever appear.</p>\n<p>This 'maximum likelihood' solution is of little value to us, however, since we would probably not give much prior weight to a model in which all Type 0 civilizations survive forever and never go interstellar.&nbsp; Recall that quantity we are actually interested in, the posterior probability of a hypothesis, depends on both the Bayes factor and the prior weight of the hypothesis:</p>\n<p><em>P(H|D)</em> proportional to <em>P(D|H) P(H)</em></p>\n<p>The parameters <em>H</em> which maximizes<em> P(H|D)</em> is called the <em>Maximum A Posteriori (MAP) estimator</em>.</p>\n<p>The business of determining prior weights of hypotheses, however, is a complicated affair.&nbsp; How can we faithfully represent the state of our knowledge of the propensity for intelligent life to evolve and develop in the universe?&nbsp; [Actually, we are still operating under the ruse that we are assigning priors for our robot, not ourselves, but since in the end we only <em>care</em> about the inferences made by the robot insofar as the similarity of our priors and the robot's priors, we might as well make the robot's priors match ours as closely as possible.]</p>\n<p>As is the custom we will seek convenient mathematical formulations for the prior distributions.&nbsp; As a guide for coming up with priors, we note:</p>\n<ul>\n<li><strong>1/a</strong> is the expected time for intelligent life to emerge in an uninhabited universe</li>\n<li><strong>1/b</strong> is the expected time for Type 0 civs to destroy themselves, when there's no possibility of ascending to Type II</li>\n<li><strong>1/(c+d)</strong> is the expected time for a Type 0 civ to ascend to Type II, when there's no possibility of self-destruction</li>\n<li><strong>d/(c+d)</strong> is the proportion of Type II civilizations which are not ideologically opposed to becoming expansionist</li>\n<li><strong>1/e</strong> is the expected time it takes for a non-pacifist Type II civilization to develop the technology required for serious large-scale colonization efforts (at which point it becomes Type III)</li>\n<li><strong>k</strong> is the speed limit on colonization relative to the speed of light.&nbsp; It's plausible that some advanced civilizations would colonize planets by sending out tiny robots, which could travel at near light speeds.&nbsp; If you think FTL travel is a possibility, you can even assign prior densities to values of k above 1.</li>\n</ul>\n<p>In fact, the above analysis suggests that it may be more natural to assign priors on the transformed parameters:</p>\n<p style=\"padding-left: 30px;\"><em>a0 = 1/a, b0 = 1/b, c0 = 1/(c+d), d0 = d/(c+d), e0 = 1/e.</em></p>\n<p>Meanwhile, if we want to restrict k to lie between 0 and 1 and vanish on the endpoints, we can do this by assigning a prior to the transformed parameter</p>\n<p style=\"padding-left: 30px;\"><em>k0 = log(k) - log(1-k)</em></p>\n<p>From these transformed parameters, we reconstitute the original parameters by</p>\n<p style=\"padding-left: 30px;\"><em>a = 1/a0, b = 1/b0, c = (1-d0)/c0, d = d0/c0, e = 1/e0, k = 1/(1 + exp(-k0))</em></p>\n<p>Since <em>a0, b0, c0, e0</em> have to be positive, natural priors for these would the exponential.&nbsp; <em>d0</em> might have a Beta prior.&nbsp; We also might as well take <em>k0</em> to have a normally distributed prior.</p>\n<p>All of these priors would be parameterized by 'hyperparameters,' which, for lack of imagination and lack of Greek symbols, we will call <em>a1, b1, c1, d1_alpha, d1_beta e1, k1</em> at the risk of some confusion.</p>\n<p>Once we have specified priors for the parameters, the very next thing a Bayesian wants to do is to compute the posterior density of the parameters.&nbsp; In our case, we will estimate the posterior by directly <em>drawing from the posterior density.</em></p>\n<p><em>[to be contd.]<br /></em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2JdCpTrNgBMNpJiyB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k4p6AQnP4kiSW56KB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 29, "extendedScore": null, "score": 7.156556087654675e-07, "legacy": true, "legacyId": "7423", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong id=\"Recap\">Recap</strong></p>\n<p><a href=\"/lw/5q1/colonization_models_a_programming_tutorial_part_12/\">Part 1</a> was a tutorial for programming a simulation for the emergence and development of intelligent species in a universe 'similar to ours.'&nbsp; In part 2, we will use the model developed in part 1 to evaluate different explanations of the <a href=\"http://en.wikipedia.org/wiki/Fermi_paradox\"><em>Fermi paradox</em></a>. However, keep in mind that the purpose of this two-part series is for showcasing useful methods, not for obtaining serious answers.</p>\n<p>We summarize the model given in part 1:</p>\n<p>SIMPLE MODEL FOR THE UNIVERSE</p>\n<ul>\n<li>The universe is represented by the set of all points in Cartesian 4-space which are of Euclidean distance 1 from the origin (that is, the 3-sphere).&nbsp; The distance between two points is taken to be the Euclidean distance (an approximation to the spherical distance which is accurate at small scales)</li>\n<li>The lifespan of the universe consists of 1000 time steps.</li>\n<li>A photon travels <strong>s=0.0004</strong> units in a time step.</li>\n<li>At the end of each time step, there is a chance that a Type 0 civilization will spontaneously emerge in an uninhabited region of space.&nbsp; The base rate for civilization birth is controlled by the parameter <strong>a</strong>.&nbsp; But this base rate is multiplied by the proportion of the universe which remains uncolonized by Type III civilizations.</li>\n<li>In each time step, a Type 0 civilization has a probability <strong>b</strong> of self-destructing, a probability <strong>c</strong> of transitioning to a non-expansionist Type IIa civilization, and a probability <strong>d</strong> of transitioning to a Type IIb civilization.</li>\n<li>Observers can detect all Type II and Type III civilizations within their past light cones.</li>\n<li>In each time step, a Type IIb civilization has a probability <strong>e</strong> of transitioning to an expansionist Type III civilization.</li>\n<li>In each time step, all Type III civilizations colonize space in all directions, expanding their sphere of colonization by <strong>k * s</strong> units per time step.</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong id=\"Section_III___Inferential_Methodology\">Section III.&nbsp; Inferential Methodology<br></strong></p>\n<p>In this section, no apologies are made for assuming that the reader has a solid grasp of the principles of Bayesian reasoning.&nbsp; Those currently following the tutorial from Part 1 may find it a good idea to skip to Section IV first.</p>\n<p>To dodge the philosophical controversies surrounding anthropic reasoning, we will employ an <em>impartial observer model.</em>&nbsp; Like Jaynes, we introduce a robot which is capable of Bayesian reasoning, but here we imagine a model in which such a robot is instantaneously created and <em>randomly injected</em> into the universe at a random point in space, and at a random time point chosen uniformly from 1 to 1000 (and the robot is aware that it is created via this mechanism).&nbsp; We limit ourselves to asking what kind of inferences this robot would make in a given situation.&nbsp; Interestingly, the inferences made by this robot will turn out to be quite similar to the inferences that would be made under the self-indication assumption.<a id=\"more\"></a></p>\n<p>It is important to precisely specify the observational powers of this robot.&nbsp; The robot can estimate the age of the universe, but it cannot determine its location relative to the center of the universe.&nbsp; The robot can visually detect any Type II+ civilizations within its past light cone.&nbsp; Furthermore, it we specify that the robot can detect Type 0 civilizations which are within a small distance <em>u</em> of the robot.&nbsp; We also grant the robot the power to deduce the age of any such nearby Type 0 civilizations.</p>\n<p>(In fact, we grant observational powers to this robot in order so that it has close to the same observational powers that we have.&nbsp; But for now, in order to steer clear of the philosophers, we carry on innocently and say no further.)</p>\n<p>Now, at the time of its creation, the robot so happens to notice the following data.</p>\n<p>Data <em>D</em> :</p>\n<ul>\n<li><em>D1</em>: The current time is <em>t = </em>500 plus or minus 5</li>\n<li><em>D2</em>: From my location, I can detect a single Type 0 civilization, which emerged at this time step.&nbsp; No type II+ civilizations are visible from my location, and therefore, no type II+ civilizations are visible to this nearby Type 0 civilization</li>\n</ul>\n<p>The robot is aware that the universe runs according to the 'simple model of the universe,' but it does not know the values for parameters a, b, c, d, e, and k.&nbsp; Given a hypothesis <em>H </em>as to the values of those parameters, the robot can calculate the <em>posterior probability </em>of observing data <em>D</em>.</p>\n<p>We will encode the entire <em>history</em> of the universe in the form of a random variable <em>G</em> which takes values within the space of all possible histories. Even after we fix a particular history, the space-time location of the robot within this history is still random.&nbsp; This will be an important point to remember when doing inference under this impartial observer model.</p>\n<p>Define random variable <em>N</em> to be the number of new Type 0 civilizations which are outside the sphere of visibility of any type II+ civilizations in existence at time <em>t</em> = 500. Since in our model only one civilization can appear in a time step, the random variable <em>N</em> is in fact a binary random variable. Conditioned on <em>G</em> taking a particular value <em>g</em>, the random variable <em>N</em> is a fixed number. Conditioned on a particular history <em>g,</em> the probability that the robot appears within distance <em>u </em>of such a civilization is <em>P(D2|H, D1, G=g) = (u^3) (</em><em>N|H, D1, G=g) = (u^3) (N|H, G=g).&nbsp; </em>We have <em>N|D1 = N</em> since the definition of <em>N</em> does not depend on the current time step.</p>\n<p>The robot calculates the posterior probability of the data as</p>\n<p><em>P(D|H) = P(D2|H, D1) P(D1|H) = P(D2|H, D1) (1/1000) = E[P(D2|H,D1,G)]</em>/1000</p>\n<p>= <em>E[(u^3) (N|H, D1, G)]/1000 = (u^3)/1000</em> <em>E[N|H]</em></p>\n<p>Now, supposing we wanted to compare different hypotheses <em>H1, H2</em>, etc., their posterior probabilities would all share the common constant term <em>(u^3)/1000 </em>in front.&nbsp; Since only the ratios of the posterior probabilities are relevant for inference, we drop the constant term and simply remember that</p>\n<p><em>P(D|H)</em> is proportional to <em>E[N|H]</em></p>\n<p>All we need to do, then, to evaluate the plausibility of different configurations <em>H1, H2</em>, etc. of the parameters, is to compute the value of <em>E[N|H]</em>.</p>\n<p>However, in this case, conditioning on a uniform distribution on a small interval of time <em>t</em>=[495, 505] is computationally inconvenient, because very few of the histories will have a new Type 0 civilization at those specific times.&nbsp; This means that many simulations have to be performed before we can get an approximation of <em>E[N|H] </em>to the necessary degree of accuracy.</p>\n<p>We can make our problem more computationally tractable if we weaken the observational powers of our robot; hopefully, our resulting inferences will not be altered too much by this change.&nbsp; (Readers are invited to check this by implementing the inferences for the original setup.) In the modified problem the robot is unable to determine the age of the universe, nor the age any Type 0 civilization it can detect.&nbsp; The robot observes only the following data.</p>\n<p>Data <em>D </em>:</p>\n<ul>\n<li>From my location, I can detect a single Type 0 civilization.&nbsp; No type II+ civilizations are visible from my location, and therefore, no type II+ civilizations are visible to this nearby Type 0 civilization</li>\n</ul>\n<p>For the modified problem, we redefine the random variable <em>N</em> to be the number of Type 0 civilizations outside the sphere of visibility of any Type II+ civilization at random time <em>T</em>.&nbsp; Similar to before, we have</p>\n<p><em>P(D|H) = u^3 E[E[N|H]|T]</em></p>\n<p>or</p>\n<p><em>P(D|H) </em>proportional to <em>E[E[N|H]|T]</em></p>\n<p>What is interesting about this conclusion is that it is similar to the <a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">Self-Indication Assumption</a>, which, to quote the linked Wikipedia page, is the principle:</p>\n<blockquote>\n<p>Given the fact that you exist, you should (other things equal) favor hypotheses according to which many observers exist over hypotheses on which few observers exist.</p>\n</blockquote>\n<p>Whereas here, from Bayes' rule, we have:</p>\n<blockquote>\n<p>Given the fact that a civilization exists satisfying CRITERIA X, the robot should (other things equal) favor hypotheses according to which many such civilizations exist over hypotheses on which few of them exist at randomly determined time <em>T</em></p>\n</blockquote>\n<p>&nbsp;</p>\n<p><strong id=\"Section_IV___Implementation_and_Demonstration\">Section IV.&nbsp; Implementation and Demonstration</strong></p>\n<p>We give the code for calculating <em>E[E[N|H]|T] </em>below.</p>\n<blockquote>\n<p># Code Block 11<br>no_visibles = function(civs,x) {<br>&nbsp; no_civs = length(civs)<br>&nbsp; if (no_civs == 0) {<br>&nbsp;&nbsp;&nbsp; return(TRUE)<br>&nbsp; }<br>&nbsp; for (i in 1:no_civs) {<br>&nbsp;&nbsp;&nbsp; current_civ = civs[[i]]<br>&nbsp;&nbsp;&nbsp; y = current_civ$location<br>&nbsp;&nbsp;&nbsp; if (distance(x,y) &lt; current_civ$r_v) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return(FALSE)<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp; }<br>&nbsp; return(TRUE)<br>}<br>value_n = function(history) {<br>&nbsp; sum = 0<br>&nbsp; for (t in 1:1000) {<br>&nbsp;&nbsp;&nbsp; civs = history[[t]]<br>&nbsp;&nbsp;&nbsp; no_civs = length(civs)<br>&nbsp;&nbsp;&nbsp; if (no_civs &gt; 0) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i in 1:no_civs) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; civ = civs[[i]]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (civ$type == 0) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x = civ$location<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (no_visibles(civs, x)) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sum = sum + 1<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp; }<br>&nbsp; sum/1000<br>}<br>multiple_trials_value_n = function(reps=10) {<br>&nbsp; values = numeric(0) # empty vector<br>&nbsp; for (i in 1:reps) {<br>&nbsp;&nbsp;&nbsp; history=simulation()<br>&nbsp;&nbsp;&nbsp; values[i] = value_n(history)<br>&nbsp; }<br>&nbsp; values<br>}<br>reps = 10<br>values = multiple_trials_value_n(reps)<br># approximate value of E[[N|H]|T]<br>mean(values)<br># standard error of the approximation<br>sqrt(var(values)/reps)<em><br></em></p>\n</blockquote>\n<p>For those who followed part 1, the above code should be straightforward.&nbsp; At the end we calculate a standard error since we have approximately the value of <em>E[E[N|H]|T]</em> by averaging over random samples of the random variable <em>E[N|H]|T</em>.</p>\n<p>Now we can get onto the business of comparing Bayes factors for hypotheses.&nbsp; Here we take the term 'Bayes' factor to refer to the quantity <em>P(D|H)</em>. Consider the following example hypotheses.</p>\n<p>1) <em>H1: </em>\"we are alone in the universe\" (small chance of life arising)</p>\n<blockquote>\n<p># Hypothesis 1<br>a = 0.001; b = 0; c = 0.1; d = 0; e = 0; k = 0</p>\n</blockquote>\n<p>2) <em>H2: </em>\"great filter ahead\" (high chance of life, but high chance of Type 0's self-destructing)</p>\n<blockquote>\n<p><em># Hypothesis 2<br>a = 0.1; b = 0.1; c = 0.01; d = 0; e = 0; k = 0</em></p>\n</blockquote>\n<p>3) H3: \"burning the cosmic commons\" (high chance of life and of surviving to stage III, but high speed of colonization)</p>\n<blockquote>\n<p><em># Hypothesis 3<br>a = 0.1; b = 0; c = 0; d = 0.1; e = 0.1; k = 0.9</em></p>\n</blockquote>\n<p>EXERCISE: Run Code Block 11 to calculate the Bayes factors for the above hypotheses.</p>\n<p>EXERCISE 2: Can you think of a hypothesis which maximizes the Bayes Factor?</p>\n<p>EXERCISE: After assigning prior weights to hypotheses of your choosing, modify the code in order to calculate the posterior probability that a Type 0 civ observing the Fermi paradox ultimately:</p>\n<ul>\n<li>self-destructs</li>\n<li>becomes colonized while it is a Type II or lower civilization</li>\n<li>becomes a type III civilization</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong id=\"Section_V__Prior_Specification__MAP_estimation\">Section V. Prior Specification; MAP estimation<br></strong></p>\n<p>SOLUTION TO EXERCISE 2:&nbsp; We can maximize the number of Type 0 observers of the Fermi paradox, naturally, by setting <strong>b, c, d</strong> to zero so that Type 0 civilizations remain Type 0 civilizations forever, and no Type II+ civilizations ever appear.</p>\n<p>This 'maximum likelihood' solution is of little value to us, however, since we would probably not give much prior weight to a model in which all Type 0 civilizations survive forever and never go interstellar.&nbsp; Recall that quantity we are actually interested in, the posterior probability of a hypothesis, depends on both the Bayes factor and the prior weight of the hypothesis:</p>\n<p><em>P(H|D)</em> proportional to <em>P(D|H) P(H)</em></p>\n<p>The parameters <em>H</em> which maximizes<em> P(H|D)</em> is called the <em>Maximum A Posteriori (MAP) estimator</em>.</p>\n<p>The business of determining prior weights of hypotheses, however, is a complicated affair.&nbsp; How can we faithfully represent the state of our knowledge of the propensity for intelligent life to evolve and develop in the universe?&nbsp; [Actually, we are still operating under the ruse that we are assigning priors for our robot, not ourselves, but since in the end we only <em>care</em> about the inferences made by the robot insofar as the similarity of our priors and the robot's priors, we might as well make the robot's priors match ours as closely as possible.]</p>\n<p>As is the custom we will seek convenient mathematical formulations for the prior distributions.&nbsp; As a guide for coming up with priors, we note:</p>\n<ul>\n<li><strong>1/a</strong> is the expected time for intelligent life to emerge in an uninhabited universe</li>\n<li><strong>1/b</strong> is the expected time for Type 0 civs to destroy themselves, when there's no possibility of ascending to Type II</li>\n<li><strong>1/(c+d)</strong> is the expected time for a Type 0 civ to ascend to Type II, when there's no possibility of self-destruction</li>\n<li><strong>d/(c+d)</strong> is the proportion of Type II civilizations which are not ideologically opposed to becoming expansionist</li>\n<li><strong>1/e</strong> is the expected time it takes for a non-pacifist Type II civilization to develop the technology required for serious large-scale colonization efforts (at which point it becomes Type III)</li>\n<li><strong>k</strong> is the speed limit on colonization relative to the speed of light.&nbsp; It's plausible that some advanced civilizations would colonize planets by sending out tiny robots, which could travel at near light speeds.&nbsp; If you think FTL travel is a possibility, you can even assign prior densities to values of k above 1.</li>\n</ul>\n<p>In fact, the above analysis suggests that it may be more natural to assign priors on the transformed parameters:</p>\n<p style=\"padding-left: 30px;\"><em>a0 = 1/a, b0 = 1/b, c0 = 1/(c+d), d0 = d/(c+d), e0 = 1/e.</em></p>\n<p>Meanwhile, if we want to restrict k to lie between 0 and 1 and vanish on the endpoints, we can do this by assigning a prior to the transformed parameter</p>\n<p style=\"padding-left: 30px;\"><em>k0 = log(k) - log(1-k)</em></p>\n<p>From these transformed parameters, we reconstitute the original parameters by</p>\n<p style=\"padding-left: 30px;\"><em>a = 1/a0, b = 1/b0, c = (1-d0)/c0, d = d0/c0, e = 1/e0, k = 1/(1 + exp(-k0))</em></p>\n<p>Since <em>a0, b0, c0, e0</em> have to be positive, natural priors for these would the exponential.&nbsp; <em>d0</em> might have a Beta prior.&nbsp; We also might as well take <em>k0</em> to have a normally distributed prior.</p>\n<p>All of these priors would be parameterized by 'hyperparameters,' which, for lack of imagination and lack of Greek symbols, we will call <em>a1, b1, c1, d1_alpha, d1_beta e1, k1</em> at the risk of some confusion.</p>\n<p>Once we have specified priors for the parameters, the very next thing a Bayesian wants to do is to compute the posterior density of the parameters.&nbsp; In our case, we will estimate the posterior by directly <em>drawing from the posterior density.</em></p>\n<p><em>[to be contd.]<br></em></p>", "sections": [{"title": "Recap", "anchor": "Recap", "level": 1}, {"title": "Section III.\u00a0 Inferential Methodology", "anchor": "Section_III___Inferential_Methodology", "level": 1}, {"title": "Section IV.\u00a0 Implementation and Demonstration", "anchor": "Section_IV___Implementation_and_Demonstration", "level": 1}, {"title": "Section V. Prior Specification; MAP estimation", "anchor": "Section_V__Prior_Specification__MAP_estimation", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LKQNdsgqgWX4SYTqw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T05:53:59.864Z", "modifiedAt": null, "url": null, "title": "Values vs. parameters", "slug": "values-vs-parameters", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:08.700Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RW4B6j2WdBhYpXx9t/values-vs-parameters", "pageUrlRelative": "/posts/RW4B6j2WdBhYpXx9t/values-vs-parameters", "linkUrl": "https://www.lesswrong.com/posts/RW4B6j2WdBhYpXx9t/values-vs-parameters", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Values%20vs.%20parameters&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AValues%20vs.%20parameters%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRW4B6j2WdBhYpXx9t%2Fvalues-vs-parameters%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Values%20vs.%20parameters%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRW4B6j2WdBhYpXx9t%2Fvalues-vs-parameters", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRW4B6j2WdBhYpXx9t%2Fvalues-vs-parameters", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 565, "htmlBody": "<p>I've written before about the difficulty of distinguishing <a href=\"/lw/55n/human_errors_human_values/\">values from errors</a>, <a href=\"/lw/256/biases_are_values/\">from algorithms, and from context</a>.&nbsp; Now I have to add to that list:&nbsp; How can we distinguish our utility function from the parameters we use to apply it?<a id=\"more\"></a></p>\n<p>In my recent discussion post, \"<a href=\"/lw/5pg/rationalists_dont_care_about_the_future/\">Rationalists don't care about the future</a>\", I showed that exponential time-discounting, plus some assumptions about physics and knowledge, leads to not caring about the future.&nbsp; Many people responded by saying that, if I care about the future, this shows that my utility function does not use exponential time-discounting.</p>\n<p>This response assumes that the shape of my time-discounting function is <em>part</em> of my utility function.&nbsp; In other words, the way you time-discount is one of your values.</p>\n<p>By contrast, Eliezer wrote an <a href=\"/lw/n2/against_discount_rates/\">earlier post</a> saying that we should use human values, but without time-discounting.&nbsp; Eliezer is aware that humans appear to use time discounting.&nbsp; Therefore, this implicitly claims that the time-discounting function is <em>not</em> one of our values.&nbsp; It's a parameter for how we implement them.</p>\n<p>(Some of the arguments Eliezer used were value-based arguments, suggesting that we can use our values to set the parameters that we use to implement our values...&nbsp; I suspect this recursive approach could introduce bogus solutions, like multiplying both sides of an equation by a variable, or worse; but that would take a longer post to address.&nbsp; I will note that some recursive equations do have unique solutions.)</p>\n<p>The program of CEV assumes that a transhuman can use some extrapolated version of values currently used by some humans.&nbsp; If that transhuman has a life expectancy of a billion years, it will likely view time discounting differently.&nbsp; Eliezer's post against time discounting suggests, to me, a God-like view of the universe, in which we eliminate time discounting in the same way (and for the same reasons) that many people want to eliminate space-discounting (not caring about far-away people) in contemporary ethics.&nbsp; This is taking an ethical code that evolved agents have, which is constructed to promote the propagation of those agents' genes, and applying it without reference to any particular set of genes.&nbsp; This is also pretty much what folk-morality says a social moral code is.&nbsp; So the idea that you can apply the same utility function from a radically different context, is inherent in CEV, and is common to much public discourse on ethics which assumes that you can construct a <em>social</em> morality that is based on the morality we find in individual agents.</p>\n<p>On the other hand, I <a href=\"/lw/55n/human_errors_human_values/3vq5\">have argued</a> that assuming that social ethics and individual ethics are the same, is either merely sloppy thinking, or an evolved (or deliberately constructed) lie.&nbsp; People who believed this would probably subscribe to a social-contract theory of ethics.&nbsp; (This view also has problems, beyond the scope of this post.)</p>\n<p>I have one heuristic that I think is pretty good for telling when something is <em>not</em> a value:&nbsp; If it's mathematically wrong, it's an error, not a value.&nbsp; So my inclination is to point out that exponential time-discounting is <em>correct</em>.&nbsp; All other forms of time-discounting lead to inconsistencies.&nbsp; You can time-discount exponentially; or you can not time-discount at all, as Eliezer suggested; or you can be in error.</p>\n<p>But my purpose in <em>this</em> post is not to continue the arguments from that other post.&nbsp; It's to point out this additional challenge in isolating what values are.&nbsp; Is your time-discounting function a value, or a value parameter?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RW4B6j2WdBhYpXx9t", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 9, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "7425", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uHrAy4yvuyzKPdRF7", "cAPCCJjggjZPxxcKh", "d5q6vKrLopC36zttS", "AvJeJw52NL9y7RJDJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T06:25:16.280Z", "modifiedAt": null, "url": null, "title": "Beyond Smart and Stupid", "slug": "beyond-smart-and-stupid", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:04.082Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2G5qvTA33ALJzbHAj/beyond-smart-and-stupid", "pageUrlRelative": "/posts/2G5qvTA33ALJzbHAj/beyond-smart-and-stupid", "linkUrl": "https://www.lesswrong.com/posts/2G5qvTA33ALJzbHAj/beyond-smart-and-stupid", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beyond%20Smart%20and%20Stupid&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeyond%20Smart%20and%20Stupid%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2G5qvTA33ALJzbHAj%2Fbeyond-smart-and-stupid%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beyond%20Smart%20and%20Stupid%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2G5qvTA33ALJzbHAj%2Fbeyond-smart-and-stupid", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2G5qvTA33ALJzbHAj%2Fbeyond-smart-and-stupid", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 789, "htmlBody": "<p>I've often wondered about people who appear to be very smart, and do very stupid things.&nbsp; One theory is that people are smart and stupid independently in different domains.&nbsp; Another theory is that \"smart\" and \"stupid\" are oversimplifications.&nbsp; In line with the second theory, here is an ad-hoc set of axes of intelligence, based only on my own observations.</p>\n<h2><a id=\"more\"></a>Memory</h2>\n<p>This may cover several sub-categories.&nbsp; The advantages of a good memory should be obvious.</p>\n<h2>Ability to follow instructions</h2>\n<p>This is more important than it sounds.&nbsp; I'm including the ability to verify mathematical proofs, and the ability to design a regression analysis for a psychology study.&nbsp; Things that aren't research or engineering, but taking known solutions and applying them.</p>\n<p>I came up with this because I have some friends who have difficult, complex jobs that they are good at - and yet frequently say incoherent things.</p>\n<p>Doctors are smart.&nbsp; Yet doctors are forbidden by law from being creative.&nbsp; They're great at following instructions.&nbsp; Becoming an MD means transforming yourself into a giant look-up table.&nbsp; You memorize anatomy, physiology, diseases, symptoms, diagnostics, and treatments.&nbsp; For every disease, there is an approved set of clinical diagnostic criteria, an approved set of laboratory diagnostics, an approved way of interpreting those tests, an approved way of presenting the results to the patient, and an approved set of possible treatments.&nbsp; After using your knowledge to observe the patient, rule out some branches of the tree of possibilities, make further tests, and discern what the underlying problem is, if instead of retrieving the approved treatment from your look-up table, you ask the engineering question, \"How can we fix this?\", you are on the path to losing your license.</p>\n<p>This ability is strongly correlated with memory.</p>\n<h2>Ability to think outside the box</h2>\n<p>This may be the same thing as creativity; but calling it \"thinking outside the box\" is less vague.&nbsp; \"Ability to not conform\" is also part of it.&nbsp; This may be anti-correlated with memory and the ability to follow instructions; it's probably more difficult to think of new approaches if old ones leap quickly to mind, just like it's difficult to compose music if every theme in your head turns into a Beatles tune after two bars.</p>\n<p>This is the distinction between an M.S. and a Ph.D. (and between an M.D. and a Ph.D. - can you tell which I have?)&nbsp; The only purpose of the years of agony of doing a dissertation no one will read is to show that you can do something original.</p>\n<p>You can be great at thinking outside the box, and still be crazy.&nbsp; Google Ment.if.ex, without the dots.&nbsp; (Do not write his name in the comments without the dots.&nbsp; Writing his name online summons him.&nbsp; I'm not joking.)</p>\n<h2>Ability to notice success and failure</h2>\n<p>A friend kept telling me about a woman he knew who he thought would be great for me.&nbsp; He told me she was smart, pretty, friendly, and fun.&nbsp; Eventually I gave in and told him I'd like to meet her.</p>\n<p>Instead of doing what had worked on me - telling her that I was right for her, smart, pretty, etc. - he told her that I was interested in her.&nbsp; Predictably, she said, \"That's creepy - I don't even know him!\"&nbsp; I asked him how it was that, in his thirty-some years of life, he hadn't noticed that that never works.&nbsp; He said he wanted to be straightforward, not sneaky.</p>\n<p>Sadly, morals are a big cause of not being able to notice success and failure.&nbsp; Someone who believes they're <em>doing the right thing</em> doesn't allow themself to ask whether they succeed or fail.</p>\n<p>The friend I mentioned is very good at following instructions.&nbsp; If you're following instructions, you might not be checking up on whether you're succeeding or failing.&nbsp; Rationalists are often bad at noticing success and failure.&nbsp; Maybe it's because we're good at following instructions - instructions on how to be rational.&nbsp; We're likely to follow our program of, say, trying to reason someone into a political view, or into liking us, without noticing that that doesn't work.</p>\n<h2>Categorization</h2>\n<p>This is a big one.&nbsp; It's pretty close to \"analytical ability\".&nbsp; By categorization I mean the ability to notice when two words mean the same thing, or similar things, or different things.&nbsp; Or when two situations or systems are similar.&nbsp; Or when one assumption is really two or three.&nbsp; Analogical reasoning requires good categorization skills.&nbsp; So does analytic thinking.&nbsp; A major fault in most people's analytic ability is their inability to keep their terms straight, and use them consistently.</p>\n<p>I include under categorization, the ability to generalize appropriately for the task.&nbsp; Overgeneralizing during analysis leads to sloppy thinking; undergeneralizing while brainstorming stifles creativity.</p>\n<h2>Social intelligence</h2>\n<p>Is this a useful primitive category?&nbsp; Lots of people think it is.&nbsp; Perhaps I don't have enough of it to understand it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ac84EpK6mZbPLzmqj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2G5qvTA33ALJzbHAj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": 36, "extendedScore": null, "score": 7.1e-05, "legacy": true, "legacyId": "7429", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I've often wondered about people who appear to be very smart, and do very stupid things.&nbsp; One theory is that people are smart and stupid independently in different domains.&nbsp; Another theory is that \"smart\" and \"stupid\" are oversimplifications.&nbsp; In line with the second theory, here is an ad-hoc set of axes of intelligence, based only on my own observations.</p>\n<h2 id=\"Memory\"><a id=\"more\"></a>Memory</h2>\n<p>This may cover several sub-categories.&nbsp; The advantages of a good memory should be obvious.</p>\n<h2 id=\"Ability_to_follow_instructions\">Ability to follow instructions</h2>\n<p>This is more important than it sounds.&nbsp; I'm including the ability to verify mathematical proofs, and the ability to design a regression analysis for a psychology study.&nbsp; Things that aren't research or engineering, but taking known solutions and applying them.</p>\n<p>I came up with this because I have some friends who have difficult, complex jobs that they are good at - and yet frequently say incoherent things.</p>\n<p>Doctors are smart.&nbsp; Yet doctors are forbidden by law from being creative.&nbsp; They're great at following instructions.&nbsp; Becoming an MD means transforming yourself into a giant look-up table.&nbsp; You memorize anatomy, physiology, diseases, symptoms, diagnostics, and treatments.&nbsp; For every disease, there is an approved set of clinical diagnostic criteria, an approved set of laboratory diagnostics, an approved way of interpreting those tests, an approved way of presenting the results to the patient, and an approved set of possible treatments.&nbsp; After using your knowledge to observe the patient, rule out some branches of the tree of possibilities, make further tests, and discern what the underlying problem is, if instead of retrieving the approved treatment from your look-up table, you ask the engineering question, \"How can we fix this?\", you are on the path to losing your license.</p>\n<p>This ability is strongly correlated with memory.</p>\n<h2 id=\"Ability_to_think_outside_the_box\">Ability to think outside the box</h2>\n<p>This may be the same thing as creativity; but calling it \"thinking outside the box\" is less vague.&nbsp; \"Ability to not conform\" is also part of it.&nbsp; This may be anti-correlated with memory and the ability to follow instructions; it's probably more difficult to think of new approaches if old ones leap quickly to mind, just like it's difficult to compose music if every theme in your head turns into a Beatles tune after two bars.</p>\n<p>This is the distinction between an M.S. and a Ph.D. (and between an M.D. and a Ph.D. - can you tell which I have?)&nbsp; The only purpose of the years of agony of doing a dissertation no one will read is to show that you can do something original.</p>\n<p>You can be great at thinking outside the box, and still be crazy.&nbsp; Google Ment.if.ex, without the dots.&nbsp; (Do not write his name in the comments without the dots.&nbsp; Writing his name online summons him.&nbsp; I'm not joking.)</p>\n<h2 id=\"Ability_to_notice_success_and_failure\">Ability to notice success and failure</h2>\n<p>A friend kept telling me about a woman he knew who he thought would be great for me.&nbsp; He told me she was smart, pretty, friendly, and fun.&nbsp; Eventually I gave in and told him I'd like to meet her.</p>\n<p>Instead of doing what had worked on me - telling her that I was right for her, smart, pretty, etc. - he told her that I was interested in her.&nbsp; Predictably, she said, \"That's creepy - I don't even know him!\"&nbsp; I asked him how it was that, in his thirty-some years of life, he hadn't noticed that that never works.&nbsp; He said he wanted to be straightforward, not sneaky.</p>\n<p>Sadly, morals are a big cause of not being able to notice success and failure.&nbsp; Someone who believes they're <em>doing the right thing</em> doesn't allow themself to ask whether they succeed or fail.</p>\n<p>The friend I mentioned is very good at following instructions.&nbsp; If you're following instructions, you might not be checking up on whether you're succeeding or failing.&nbsp; Rationalists are often bad at noticing success and failure.&nbsp; Maybe it's because we're good at following instructions - instructions on how to be rational.&nbsp; We're likely to follow our program of, say, trying to reason someone into a political view, or into liking us, without noticing that that doesn't work.</p>\n<h2 id=\"Categorization\">Categorization</h2>\n<p>This is a big one.&nbsp; It's pretty close to \"analytical ability\".&nbsp; By categorization I mean the ability to notice when two words mean the same thing, or similar things, or different things.&nbsp; Or when two situations or systems are similar.&nbsp; Or when one assumption is really two or three.&nbsp; Analogical reasoning requires good categorization skills.&nbsp; So does analytic thinking.&nbsp; A major fault in most people's analytic ability is their inability to keep their terms straight, and use them consistently.</p>\n<p>I include under categorization, the ability to generalize appropriately for the task.&nbsp; Overgeneralizing during analysis leads to sloppy thinking; undergeneralizing while brainstorming stifles creativity.</p>\n<h2 id=\"Social_intelligence\">Social intelligence</h2>\n<p>Is this a useful primitive category?&nbsp; Lots of people think it is.&nbsp; Perhaps I don't have enough of it to understand it.</p>", "sections": [{"title": "Memory", "anchor": "Memory", "level": 1}, {"title": "Ability to follow instructions", "anchor": "Ability_to_follow_instructions", "level": 1}, {"title": "Ability to think outside the box", "anchor": "Ability_to_think_outside_the_box", "level": 1}, {"title": "Ability to notice success and failure", "anchor": "Ability_to_notice_success_and_failure", "level": 1}, {"title": "Categorization", "anchor": "Categorization", "level": 1}, {"title": "Social intelligence", "anchor": "Social_intelligence", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "44 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T11:26:02.885Z", "modifiedAt": null, "url": null, "title": "How some algorithms feel from inside", "slug": "how-some-algorithms-feel-from-inside", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:39.345Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2WBF6R3ZY2DCZQK2a/how-some-algorithms-feel-from-inside", "pageUrlRelative": "/posts/2WBF6R3ZY2DCZQK2a/how-some-algorithms-feel-from-inside", "linkUrl": "https://www.lesswrong.com/posts/2WBF6R3ZY2DCZQK2a/how-some-algorithms-feel-from-inside", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20some%20algorithms%20feel%20from%20inside&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20some%20algorithms%20feel%20from%20inside%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2WBF6R3ZY2DCZQK2a%2Fhow-some-algorithms-feel-from-inside%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20some%20algorithms%20feel%20from%20inside%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2WBF6R3ZY2DCZQK2a%2Fhow-some-algorithms-feel-from-inside", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2WBF6R3ZY2DCZQK2a%2Fhow-some-algorithms-feel-from-inside", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 49, "htmlBody": "<p>So I decided to list the known applications of this popular LW phrase:</p>\n<p>\n<ul>\n<li>Believing in essences is how a <a href=\"/lw/no/how_an_algorithm_feels_from_inside/\">classifier</a> feels from inside</li>\n<li>Free will is how an <a href=\"/lw/2l2/what_a_reduction_of_could_could_look_like/\">action-chooser</a> feels from inside</li>\n<li>Self esteem is how a <a href=\"/lw/1d/simultaneously_right_and_wrong/so\">status calculation</a> feels from inside</li>\n</ul>\nWhat else?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2WBF6R3ZY2DCZQK2a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 48, "extendedScore": null, "score": 8.3e-05, "legacy": true, "legacyId": "7433", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yA4gF5KrboK2m2Xu7", "dC3rxrMkYKLfgTYEa"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T14:44:49.377Z", "modifiedAt": null, "url": null, "title": "Pascal's Mugging - Penalizing the prior probability?", "slug": "pascal-s-mugging-penalizing-the-prior-probability", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:38.545Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zdk5djtfFXSgfpeWi/pascal-s-mugging-penalizing-the-prior-probability", "pageUrlRelative": "/posts/zdk5djtfFXSgfpeWi/pascal-s-mugging-penalizing-the-prior-probability", "linkUrl": "https://www.lesswrong.com/posts/zdk5djtfFXSgfpeWi/pascal-s-mugging-penalizing-the-prior-probability", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pascal's%20Mugging%20-%20Penalizing%20the%20prior%20probability%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APascal's%20Mugging%20-%20Penalizing%20the%20prior%20probability%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzdk5djtfFXSgfpeWi%2Fpascal-s-mugging-penalizing-the-prior-probability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pascal's%20Mugging%20-%20Penalizing%20the%20prior%20probability%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzdk5djtfFXSgfpeWi%2Fpascal-s-mugging-penalizing-the-prior-probability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzdk5djtfFXSgfpeWi%2Fpascal-s-mugging-penalizing-the-prior-probability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 589, "htmlBody": "<p>Eliezer Yudkowsky <a href=\"/lw/my/the_allais_paradox/hs3\">wrote</a> that <a href=\"http://www.overcomingbias.com/\">Robin Hanson</a> solved the <a href=\"http://wiki.lesswrong.com/wiki/Pascal%27s_mugging\">Pascal's mugging</a> thought experiment:</p>\n<blockquote>\n<p>Robin Hanson has suggested penalizing the prior probability of hypotheses which argue that we are in a <em>surprisingly unique</em> position to affect large numbers of other people who cannot symmetrically affect us. Since only one in 3^^^^3 people can be in a unique position to ordain the existence of at least 3^^^^3 other people who are not symmetrically in such a situation themselves, the prior probability would be penalized by a factor on the same order as the utility.</p>\n</blockquote>\n<p>I don't quite get it, is there a post that discusses this solution in more detail?</p>\n<p>To be more specific, if a stranger approached me, offering a deal saying, \"I am the creator of the Matrix. If you fall on your knees, praise me and kiss my feet, I'll use my magic powers from outside the Matrix to run a Turing machine that simulates <a class=\"mw-redirect\" title=\"3^^^^3\" href=\"http://wiki.lesswrong.com/wiki/3%5E%5E%5E%5E3\">3^^^^3</a> copies of you having their coherent extrapolated volition satisfied maximally for 3^^^^3 years.\" Why exactly would I penalize this offer by the amount of copies being offered to be simulated? I thought the whole point was that the utility, of having 3^^^^3 copies of myself experiencing maximal happiness, does outweigh the low probability of it actually happening and the disuility of doing what the stranger asks for?</p>\n<p>I would love to see this problem being discussed again and read about the current state of knowledge.</p>\n<p>I am especially interested in the following questions:</p>\n<ul>\n<li>Is the Pascal's mugging thought experiment a \"reduction to the absurd\" of Bayes&rsquo; Theorem in combination with the expected utility formula and Solomonoff induction?<sup>1</sup></li>\n<li>Could the \"mugger\" be our own imagination?<sup>2</sup></li>\n<li>At what point does an expected utility calculation resemble a Pascal's mugging scenario and should consequently be ignored?<sup>3</sup></li>\n</ul>\n<p><sup>1</sup> <span style=\"font-size: 11px;\">If you calculate the expected utility of various outcomes you imagine impossible alternative actions. The alternatives are impossible because you already precommited to choosing the outcome with the largest expected utility. Problems: 1.) You swap your complex values for a certain terminal goal with the highest expected utility, indeed your instrumental and terminal goals converge to <em>become</em> the expected utility formula. 2.) Your decision-making is eventually dominated by extremely small probabilities of obtaining vast utility.<br /></span></p>\n<p><sup>2</sup> <span style=\"font-size: 11px;\">Insignificant inferences might exhibit hyperbolic growth in utility: 1.) There is no minimum amount of empirical evidence necessary to extrapolate the expected utility of an outcome. 2.) The extrapolation of counterfactual alternatives is unbounded, logical implications can reach out indefinitely without ever requiring new empirical evidence.</span></p>\n<p><sup>3</sup> <span style=\"font-size: 11px;\">Extrapolations work and often are the best we can do. But since there are problems like 'Pascal's Mugging', that we perceive to be undesirable and that lead to an infinite hunt for ever larger expected utility, I think it is reasonable to ask for some upper and lower bounds regarding the use and scope of certain heuristics. We agree that we are not going to stop pursuing whatever terminal goal we have chosen just because someone promises us even more utility if we do what that agent wants. We might also agree that we are not going to stop loving our girlfriend just because there are many people who do not approve our relationship and who together would experience more happiness if we divorced than the combined happiness of us and our girlfriend being married. Therefore we already informally established some upper and lower bounds. But when do we start to take our heuristics seriously and do whatever they prove to be the optimal decision? <br /></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HNJiR8Jzafsv8cHrC": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zdk5djtfFXSgfpeWi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "7434", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T14:50:52.398Z", "modifiedAt": null, "url": null, "title": "Space-worthiness", "slug": "space-worthiness", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:01.390Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p4p88WC3tarbKA8Ym/space-worthiness", "pageUrlRelative": "/posts/p4p88WC3tarbKA8Ym/space-worthiness", "linkUrl": "https://www.lesswrong.com/posts/p4p88WC3tarbKA8Ym/space-worthiness", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Space-worthiness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpace-worthiness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp4p88WC3tarbKA8Ym%2Fspace-worthiness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Space-worthiness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp4p88WC3tarbKA8Ym%2Fspace-worthiness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp4p88WC3tarbKA8Ym%2Fspace-worthiness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 129, "htmlBody": "<p><a href=\"/lw/5q1/colonization_models_a_programming_tutorial_part_12/\">A recent post about the Fermi paradox</a> left me wondering about relative difficulties of getting into space, though I don't think it affects those specific arguments.</p>\n<p>People establishing a presence in space is difficult but at least plausible-- I'm talking about biological people as we are now, and being able to live and reproduce indefinitely without returning to Earth.</p>\n<p>It would be easier if we were less massive, or our planet was less massive, or if we were more radiation resistant. It would be harder if these qualities were reversed, or if we needed a much denser atmosphere.There might come a point where it just isn't feasible for a species to get itself off its planet.</p>\n<p>Is there any reasonable speculation about where we are likely to be on the ease-of-getting-into-space spectrum?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p4p88WC3tarbKA8Ym", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "7435", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LKQNdsgqgWX4SYTqw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T15:16:42.898Z", "modifiedAt": null, "url": null, "title": "How and Why to Granularize", "slug": "how-and-why-to-granularize", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:58.353Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jTk9m75y2bpujwRfb/how-and-why-to-granularize", "pageUrlRelative": "/posts/jTk9m75y2bpujwRfb/how-and-why-to-granularize", "linkUrl": "https://www.lesswrong.com/posts/jTk9m75y2bpujwRfb/how-and-why-to-granularize", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20and%20Why%20to%20Granularize&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20and%20Why%20to%20Granularize%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjTk9m75y2bpujwRfb%2Fhow-and-why-to-granularize%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20and%20Why%20to%20Granularize%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjTk9m75y2bpujwRfb%2Fhow-and-why-to-granularize", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjTk9m75y2bpujwRfb%2Fhow-and-why-to-granularize", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1272, "htmlBody": "<p>Say you want to learn to play piano. What do you do? Do you grab some sheet music for '<a href=\"http://www.youtube.com/watch?v=h6A-JYbu1Os#t=11s\">Flight of the Bumblebee</a>' and start playing? No. First you learn how to read music, and where to put your fingers, and how to play chords, and how to use different rhythms, and how to evoke different textures. You master each of these skills in turn, one or two at a time, and it takes you weeks or months to master each little step on your way to playing Rimsky-Korsakov. And <em>then</em>&nbsp;you play 'Flight of the Bumblebee.'</p>\n<p><a href=\"/lw/58m/build_skills_in_the_right_order/\">Building small skills in the right order</a> is not just a way to <a href=\"/lw/up/shut_up_and_do_the_impossible/\">do the impossible</a> by breaking down the <em>impossible</em> into little bits of <em>possible</em>. It is also a way to maintain motivation.</p>\n<p>Imagine that you didn't feel a reward, a sense of accomplishment, until you had mastered 'Flight of the Bumblebee'. You'd have to stay motivated for <em>years</em>&nbsp;without payoff. Luckily, your brain sends out <a href=\"http://www.scholarpedia.org/article/Reward_signals\">reward signals</a> when you learn how to read music, where to put your fingers, and how to play chords. You are rewarded every step of the way. Granularizing a project into tiny bits, each of which is its own (small) reward, helps maintain your motivation and overcome <a href=\"/lw/3w3/how_to_beat_procrastination/\">the challenges of hyperbolic discounting</a>.</p>\n<p><a href=\"http://en.wiktionary.org/wiki/granularize\">Granularizing</a> is an important meta-skill. Want to play piano but don't know how? Don't feel overwhelmed watching someone play 'Flight of the Bumblebee.' Figure out how to granularize the skill of 'playing Flight of the Bumblebee' into lots of tiny sub-skills, and then master each one in turn.</p>\n<p>Want to improve your sex life? Don't feel overwhelmed watching the local Casanova or Cleopatra at work. Figure out how to granularize the skills of 'creating attraction' and 'having good sex' into lots of tiny sub-skills and master each one in turn.</p>\n<p>Want to become economically independent? Don't feel overwhelmed watching <a href=\"http://en.wikipedia.org/wiki/Timothy_Ferriss\">Tim Ferriss</a> at work. Granularize that skill into tiny sub-skills and master each one in turn.</p>\n<p>This doesn't mean that <em>anyone</em>&nbsp;can learn <em>anything</em>&nbsp;just by granularizing and then mastering sub-skills one at a time. Nor does it mean that you should apportion your limited resources to mastering just about anything. But it does mean that mastering skills that <em>are</em>&nbsp;within your reach might be easier than you think.</p>\n<p>&nbsp;</p>\n<h4><a name=\"social\"></a>Example: Social effectiveness</h4>\n<p>Take 'social effectiveness' as an example, and pretend you know almost nothing about it.</p>\n<p>So you talk to people who are socially effective and observe them and read books on social skills and come to understand some of the sub-skills involved. There are <em>verbal communication</em>&nbsp;skills involved: how to open and close conversations, how to tell jokes, how to tell compelling stories. There are <em>nonverbal communication</em>&nbsp;skills involved: facial expressions, body language, eye contact, voice tone, fashion. There are <em>receiving communication</em>&nbsp;skills involved: listening, reading body language, modeling people. There are <em>mental and emotional wellbeing</em>&nbsp;skills involved: motivation, confidence, courage. There are also <em>relationship management</em>&nbsp;skills involved: business networking, how to apportion your time to friends and family, etc.</p>\n<p>So you investigate each of those more closely. Let's zoom in on nonverbal communication. From the <a href=\"http://en.wikipedia.org/wiki/Nonverbal_communication\">Wikipedia article</a> alone, we learn of several sub-skills: <a href=\"http://en.wikipedia.org/wiki/Gestures\">gestures</a>, <a href=\"http://en.wikipedia.org/wiki/Haptic_communication\">touch</a>, <a href=\"http://en.wikipedia.org/wiki/Body_language\">body language</a>&nbsp;(including <a href=\"http://en.wikipedia.org/wiki/Human_position\">posture</a>, <a href=\"http://en.wikipedia.org/wiki/Dance\">dance</a>, and <a href=\"http://en.wikipedia.org/wiki/Human_sexual_activity\">sex</a>), <a href=\"http://en.wikipedia.org/wiki/Facial_expression\">facial expression</a>, <a href=\"http://en.wikipedia.org/wiki/Eye_contact\">eye contact</a>, <a href=\"http://en.wikipedia.org/wiki/Clothing\">fashion</a>, <a href=\"http://en.wikipedia.org/wiki/Hairstyle\">hair style</a>, <a href=\"http://en.wikipedia.org/wiki/Symbol\">symbols</a>, and&nbsp;<a href=\"http://en.wikipedia.org/wiki/Paralanguage\">paralanguage</a> (voice tone, pitch, rhythm, etc.). With a bit more thought we can realize that our <a href=\"http://en.wikipedia.org/wiki/Hygiene\">hygiene</a> certainly communicates facts to others, as does our <a href=\"http://en.wikipedia.org/wiki/Physical_fitness\">physical fitness</a>.</p>\n<p>Each of these sub-skills can be granularized. <a href=\"http://www.amazon.com/Body-Language-Handbook-Everyones-Intentions/dp/160163076X/\">There</a> <a href=\"http://www.amazon.com/What-Every-BODY-Saying-Speed-Reading/dp/0061438294/\">are</a> <a href=\"http://www.amazon.com/Body-Language-Dummies-Elizabeth-Kuhnke/dp/0470512911/\">many</a> <a href=\"http://www.amazon.com/Nonverbal-Advantage-Secrets-Language-Business/dp/1576754928/\">books</a> <a href=\"http://www.amazon.com/Teach-Yourself-Language-Gordon-Wainwright/dp/0340981954/\">on</a> <a href=\"http://www.amazon.com/Definitive-Book-Body-Language/dp/8183220142/\">body</a> <a href=\"http://www.amazon.com/Language-Competent-Teachers-Chris-Caswell/dp/0415066603/\">language</a> which teach you how to stand, how to sit, how to walk, and how to use your hands to achieve the social effects you want to achieve. There are <a href=\"http://sexuality.about.com/od/eroticbooks/tp/Sex-Books-for-Couples.htm\">books</a>, <a href=\"http://2girlsteachsex.com/\">videos</a>, and <a href=\"http://www.msnbc.msn.com/id/6331932/ns/health-sexual_health/t/sex-schools-offer-couples-lessons-love/\">classes</a> on how to develop a long list of sexual skills. <a href=\"http://www.amazon.com/Dressing-Man-Mastering-Permanent-Fashion/dp/0060191449/\">Many</a> <a href=\"http://www.amazon.com/One-Hundred-Guide-Pieces-Stylish/dp/0061664634/\">books</a> and&nbsp;<a href=\"http://www.myimageexpert.com/\">image consultants</a> can teach you each of the specific skills involved in developing a sophisticated fashion sense.</p>\n<p>But probably, you have a more specific goal than 'social effectiveness.' Maybe you want to become a powerful public speaker.&nbsp;<a href=\"http://www.toastmasters.org/\">Toastmasters</a>&nbsp;can teach you the sub-skills needed for that, and train you on them one at a time. You can also do your own training. One sub-skill you'll need is eye contact. Get a friend to do you a favor and let you stare into their eyes for 15 minutes in a row. Every time you glance away or get droopy-eyed, have them reset the stopwatch. Once you've stared into someone's eyes for 15 minutes straight, you'll probably find it easier to maintain eye contact with everyone else in life whenever you want to do so. Next, you'll have to work on the skill of not creeping people out by staring into their eyes&nbsp;<em style=\"font-style: italic;\">too</em>&nbsp;much. After that, you can develop the other sub-skills required to be an effective public speaker.</p>\n<p>Also, you <em>can</em>&nbsp;try starting with 'Flight of the Bumblebee'. You'll probably fail, but maybe you'll surprise yourself. And if you fail, this might give you specific information about which sub-skills you have already, and which skills you lack. Maybe your fingers just aren't fast enough yet. Likewise, you <em>can</em>&nbsp;start by trying to give a public speech, especially if you're not easily humiliated. There's a small chance you'll succeed right away. And if you fail, you might get some immediate data on which sub-skills you're lacking. Perhaps your verbal skills and body language are great, and you just need to work on your comedic timing and your voice tone.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>The 5-Second Level</h4>\n<p>Granularize far enough, and some of these skills can operate at <a href=\"/lw/5kz/the_5second_level/\">the 5-second level</a>. Consider the skill of eye contact. Put a pleasant, interested expression on your face and hold steady eye contact with someone who is speaking with you, and they will feel very <em>listened to</em>. Use even stronger eye contact with someone of higher status than yourself to show them that you believe you have enough value to belong in the conversation. These example applications of eye contact skill use can be generalized into a series of 5-second mental procedures.</p>\n<p>One might look like this:</p>\n<ol>\n<li>Notice someone is speaking to you.</li>\n<li>Put a pleasant, interested expression on your face.</li>\n<li>Lock eye contact with them.</li>\n</ol>\n<p>And, as a follow-up:</p>\n<ol>\n<li>Notice you're in eye contact with someone who is speaking to you.</li>\n<li>If it looks like your eye contact is strong enough to make them uncomfortable, look away for a second.</li>\n<li>Else, maintain eye contact.</li>\n</ol>\n<p>Too much eye contact with somebody can sometimes be a 'dominating' move, as in a staring contest. So:</p>\n<ol>\n<li>Notice you're in eye contact with someone of similar social status.</li>\n<li>If you have been in eye contact with them for more than 12 seconds straight, look away for a second.</li>\n<li>Else, maintain eye contact.</li>\n</ol>\n<p>And finally:</p>\n<ol>\n<li>Notice you're in eye contact with someone of much greater social status than yourself.</li>\n<li>If you have been in eye contact with them for more than 30 seconds straight, look away for a second.</li>\n<li>Else, maintain eye contact.</li>\n</ol>\n<p>&nbsp;</p>\n<h4>Granularity in action</h4>\n<p>If you're hopelessly analytic like I am, it may help to granularize a desired skill into sub-skills by drawing up a big <em>skills map</em> in software like <a href=\"http://freemind.sourceforge.net/wiki/index.php/Main_Page\">Freemind</a> (multi-platform) or <a href=\"http://www.mindmeister.com/\">MindMeister</a> (online). I've started to do this for social effectiveness. My <a href=\"http://www.mindmeister.com/96422213/social-effectiveness-skills\"><strong>map of all social skills</strong></a>&nbsp;(+ <a href=\"http://tinyurl.com/SocialSkillsMap\">recommended reading</a>) is in the <em>very</em> early stages, but I hope to eventually granularize all social skills down to the level of specific <em>exercises</em> that can be done to train each sub-sub-sub-skill of social effectiveness.</p>\n<p>The challenges of life are not so daunting when they are broken into tiny bits. When \"Become a charismatic speaker\" is transformed into \"Step One: maintain eye contact with somebody for 60 seconds in a row,\" your response may be transformed from \"Sounds hard!\" into \"Well, I can do <em>that</em>!\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 2, "fR7QfYx4JA3BnptT9": 2, "5Whwix4cZ3p5otshm": 2, "iP2X4jQNHMWHRNPne": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jTk9m75y2bpujwRfb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 72, "baseScore": 78, "extendedScore": null, "score": 0.000147, "legacy": true, "legacyId": "7386", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 78, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Say you want to learn to play piano. What do you do? Do you grab some sheet music for '<a href=\"http://www.youtube.com/watch?v=h6A-JYbu1Os#t=11s\">Flight of the Bumblebee</a>' and start playing? No. First you learn how to read music, and where to put your fingers, and how to play chords, and how to use different rhythms, and how to evoke different textures. You master each of these skills in turn, one or two at a time, and it takes you weeks or months to master each little step on your way to playing Rimsky-Korsakov. And <em>then</em>&nbsp;you play 'Flight of the Bumblebee.'</p>\n<p><a href=\"/lw/58m/build_skills_in_the_right_order/\">Building small skills in the right order</a> is not just a way to <a href=\"/lw/up/shut_up_and_do_the_impossible/\">do the impossible</a> by breaking down the <em>impossible</em> into little bits of <em>possible</em>. It is also a way to maintain motivation.</p>\n<p>Imagine that you didn't feel a reward, a sense of accomplishment, until you had mastered 'Flight of the Bumblebee'. You'd have to stay motivated for <em>years</em>&nbsp;without payoff. Luckily, your brain sends out <a href=\"http://www.scholarpedia.org/article/Reward_signals\">reward signals</a> when you learn how to read music, where to put your fingers, and how to play chords. You are rewarded every step of the way. Granularizing a project into tiny bits, each of which is its own (small) reward, helps maintain your motivation and overcome <a href=\"/lw/3w3/how_to_beat_procrastination/\">the challenges of hyperbolic discounting</a>.</p>\n<p><a href=\"http://en.wiktionary.org/wiki/granularize\">Granularizing</a> is an important meta-skill. Want to play piano but don't know how? Don't feel overwhelmed watching someone play 'Flight of the Bumblebee.' Figure out how to granularize the skill of 'playing Flight of the Bumblebee' into lots of tiny sub-skills, and then master each one in turn.</p>\n<p>Want to improve your sex life? Don't feel overwhelmed watching the local Casanova or Cleopatra at work. Figure out how to granularize the skills of 'creating attraction' and 'having good sex' into lots of tiny sub-skills and master each one in turn.</p>\n<p>Want to become economically independent? Don't feel overwhelmed watching <a href=\"http://en.wikipedia.org/wiki/Timothy_Ferriss\">Tim Ferriss</a> at work. Granularize that skill into tiny sub-skills and master each one in turn.</p>\n<p>This doesn't mean that <em>anyone</em>&nbsp;can learn <em>anything</em>&nbsp;just by granularizing and then mastering sub-skills one at a time. Nor does it mean that you should apportion your limited resources to mastering just about anything. But it does mean that mastering skills that <em>are</em>&nbsp;within your reach might be easier than you think.</p>\n<p>&nbsp;</p>\n<h4 id=\"Example__Social_effectiveness\"><a name=\"social\"></a>Example: Social effectiveness</h4>\n<p>Take 'social effectiveness' as an example, and pretend you know almost nothing about it.</p>\n<p>So you talk to people who are socially effective and observe them and read books on social skills and come to understand some of the sub-skills involved. There are <em>verbal communication</em>&nbsp;skills involved: how to open and close conversations, how to tell jokes, how to tell compelling stories. There are <em>nonverbal communication</em>&nbsp;skills involved: facial expressions, body language, eye contact, voice tone, fashion. There are <em>receiving communication</em>&nbsp;skills involved: listening, reading body language, modeling people. There are <em>mental and emotional wellbeing</em>&nbsp;skills involved: motivation, confidence, courage. There are also <em>relationship management</em>&nbsp;skills involved: business networking, how to apportion your time to friends and family, etc.</p>\n<p>So you investigate each of those more closely. Let's zoom in on nonverbal communication. From the <a href=\"http://en.wikipedia.org/wiki/Nonverbal_communication\">Wikipedia article</a> alone, we learn of several sub-skills: <a href=\"http://en.wikipedia.org/wiki/Gestures\">gestures</a>, <a href=\"http://en.wikipedia.org/wiki/Haptic_communication\">touch</a>, <a href=\"http://en.wikipedia.org/wiki/Body_language\">body language</a>&nbsp;(including <a href=\"http://en.wikipedia.org/wiki/Human_position\">posture</a>, <a href=\"http://en.wikipedia.org/wiki/Dance\">dance</a>, and <a href=\"http://en.wikipedia.org/wiki/Human_sexual_activity\">sex</a>), <a href=\"http://en.wikipedia.org/wiki/Facial_expression\">facial expression</a>, <a href=\"http://en.wikipedia.org/wiki/Eye_contact\">eye contact</a>, <a href=\"http://en.wikipedia.org/wiki/Clothing\">fashion</a>, <a href=\"http://en.wikipedia.org/wiki/Hairstyle\">hair style</a>, <a href=\"http://en.wikipedia.org/wiki/Symbol\">symbols</a>, and&nbsp;<a href=\"http://en.wikipedia.org/wiki/Paralanguage\">paralanguage</a> (voice tone, pitch, rhythm, etc.). With a bit more thought we can realize that our <a href=\"http://en.wikipedia.org/wiki/Hygiene\">hygiene</a> certainly communicates facts to others, as does our <a href=\"http://en.wikipedia.org/wiki/Physical_fitness\">physical fitness</a>.</p>\n<p>Each of these sub-skills can be granularized. <a href=\"http://www.amazon.com/Body-Language-Handbook-Everyones-Intentions/dp/160163076X/\">There</a> <a href=\"http://www.amazon.com/What-Every-BODY-Saying-Speed-Reading/dp/0061438294/\">are</a> <a href=\"http://www.amazon.com/Body-Language-Dummies-Elizabeth-Kuhnke/dp/0470512911/\">many</a> <a href=\"http://www.amazon.com/Nonverbal-Advantage-Secrets-Language-Business/dp/1576754928/\">books</a> <a href=\"http://www.amazon.com/Teach-Yourself-Language-Gordon-Wainwright/dp/0340981954/\">on</a> <a href=\"http://www.amazon.com/Definitive-Book-Body-Language/dp/8183220142/\">body</a> <a href=\"http://www.amazon.com/Language-Competent-Teachers-Chris-Caswell/dp/0415066603/\">language</a> which teach you how to stand, how to sit, how to walk, and how to use your hands to achieve the social effects you want to achieve. There are <a href=\"http://sexuality.about.com/od/eroticbooks/tp/Sex-Books-for-Couples.htm\">books</a>, <a href=\"http://2girlsteachsex.com/\">videos</a>, and <a href=\"http://www.msnbc.msn.com/id/6331932/ns/health-sexual_health/t/sex-schools-offer-couples-lessons-love/\">classes</a> on how to develop a long list of sexual skills. <a href=\"http://www.amazon.com/Dressing-Man-Mastering-Permanent-Fashion/dp/0060191449/\">Many</a> <a href=\"http://www.amazon.com/One-Hundred-Guide-Pieces-Stylish/dp/0061664634/\">books</a> and&nbsp;<a href=\"http://www.myimageexpert.com/\">image consultants</a> can teach you each of the specific skills involved in developing a sophisticated fashion sense.</p>\n<p>But probably, you have a more specific goal than 'social effectiveness.' Maybe you want to become a powerful public speaker.&nbsp;<a href=\"http://www.toastmasters.org/\">Toastmasters</a>&nbsp;can teach you the sub-skills needed for that, and train you on them one at a time. You can also do your own training. One sub-skill you'll need is eye contact. Get a friend to do you a favor and let you stare into their eyes for 15 minutes in a row. Every time you glance away or get droopy-eyed, have them reset the stopwatch. Once you've stared into someone's eyes for 15 minutes straight, you'll probably find it easier to maintain eye contact with everyone else in life whenever you want to do so. Next, you'll have to work on the skill of not creeping people out by staring into their eyes&nbsp;<em style=\"font-style: italic;\">too</em>&nbsp;much. After that, you can develop the other sub-skills required to be an effective public speaker.</p>\n<p>Also, you <em>can</em>&nbsp;try starting with 'Flight of the Bumblebee'. You'll probably fail, but maybe you'll surprise yourself. And if you fail, this might give you specific information about which sub-skills you have already, and which skills you lack. Maybe your fingers just aren't fast enough yet. Likewise, you <em>can</em>&nbsp;start by trying to give a public speech, especially if you're not easily humiliated. There's a small chance you'll succeed right away. And if you fail, you might get some immediate data on which sub-skills you're lacking. Perhaps your verbal skills and body language are great, and you just need to work on your comedic timing and your voice tone.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"The_5_Second_Level\">The 5-Second Level</h4>\n<p>Granularize far enough, and some of these skills can operate at <a href=\"/lw/5kz/the_5second_level/\">the 5-second level</a>. Consider the skill of eye contact. Put a pleasant, interested expression on your face and hold steady eye contact with someone who is speaking with you, and they will feel very <em>listened to</em>. Use even stronger eye contact with someone of higher status than yourself to show them that you believe you have enough value to belong in the conversation. These example applications of eye contact skill use can be generalized into a series of 5-second mental procedures.</p>\n<p>One might look like this:</p>\n<ol>\n<li>Notice someone is speaking to you.</li>\n<li>Put a pleasant, interested expression on your face.</li>\n<li>Lock eye contact with them.</li>\n</ol>\n<p>And, as a follow-up:</p>\n<ol>\n<li>Notice you're in eye contact with someone who is speaking to you.</li>\n<li>If it looks like your eye contact is strong enough to make them uncomfortable, look away for a second.</li>\n<li>Else, maintain eye contact.</li>\n</ol>\n<p>Too much eye contact with somebody can sometimes be a 'dominating' move, as in a staring contest. So:</p>\n<ol>\n<li>Notice you're in eye contact with someone of similar social status.</li>\n<li>If you have been in eye contact with them for more than 12 seconds straight, look away for a second.</li>\n<li>Else, maintain eye contact.</li>\n</ol>\n<p>And finally:</p>\n<ol>\n<li>Notice you're in eye contact with someone of much greater social status than yourself.</li>\n<li>If you have been in eye contact with them for more than 30 seconds straight, look away for a second.</li>\n<li>Else, maintain eye contact.</li>\n</ol>\n<p>&nbsp;</p>\n<h4 id=\"Granularity_in_action\">Granularity in action</h4>\n<p>If you're hopelessly analytic like I am, it may help to granularize a desired skill into sub-skills by drawing up a big <em>skills map</em> in software like <a href=\"http://freemind.sourceforge.net/wiki/index.php/Main_Page\">Freemind</a> (multi-platform) or <a href=\"http://www.mindmeister.com/\">MindMeister</a> (online). I've started to do this for social effectiveness. My <a href=\"http://www.mindmeister.com/96422213/social-effectiveness-skills\"><strong>map of all social skills</strong></a>&nbsp;(+ <a href=\"http://tinyurl.com/SocialSkillsMap\">recommended reading</a>) is in the <em>very</em> early stages, but I hope to eventually granularize all social skills down to the level of specific <em>exercises</em> that can be done to train each sub-sub-sub-skill of social effectiveness.</p>\n<p>The challenges of life are not so daunting when they are broken into tiny bits. When \"Become a charismatic speaker\" is transformed into \"Step One: maintain eye contact with somebody for 60 seconds in a row,\" your response may be transformed from \"Sounds hard!\" into \"Well, I can do <em>that</em>!\"</p>", "sections": [{"title": "Example: Social effectiveness", "anchor": "Example__Social_effectiveness", "level": 1}, {"title": "The 5-Second Level", "anchor": "The_5_Second_Level", "level": 1}, {"title": "Granularity in action", "anchor": "Granularity_in_action", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "60 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 60, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qwdupkFd6kmeZHYXy", "nCvvhFBaayaXyuBiD", "RWo4LwFzpHNQCTcYt", "JcpzFpPBSmzuksmWM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T15:22:24.522Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Self-deception: Hypocrisy or Akrasia?", "slug": "seq-rerun-self-deception-hypocrisy-or-akrasia", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:03.826Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cBnH8aJxe7nRaBKFJ/seq-rerun-self-deception-hypocrisy-or-akrasia", "pageUrlRelative": "/posts/cBnH8aJxe7nRaBKFJ/seq-rerun-self-deception-hypocrisy-or-akrasia", "linkUrl": "https://www.lesswrong.com/posts/cBnH8aJxe7nRaBKFJ/seq-rerun-self-deception-hypocrisy-or-akrasia", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Self-deception%3A%20Hypocrisy%20or%20Akrasia%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Self-deception%3A%20Hypocrisy%20or%20Akrasia%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcBnH8aJxe7nRaBKFJ%2Fseq-rerun-self-deception-hypocrisy-or-akrasia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Self-deception%3A%20Hypocrisy%20or%20Akrasia%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcBnH8aJxe7nRaBKFJ%2Fseq-rerun-self-deception-hypocrisy-or-akrasia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcBnH8aJxe7nRaBKFJ%2Fseq-rerun-self-deception-hypocrisy-or-akrasia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 149, "htmlBody": "<p>Today's post, <a href=\"/lw/h7/selfdeception_hypocrisy_or_akrasia/\">Self-deception: Hypocrisy or Akrasia?</a> was originally published on March 26, 2007.  A summary (from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>If part of a person&mdash;for example, the verbal module&mdash;says it wants to become more rational, we can ally with that part even when weakness of will makes the person's actions otherwise; hypocrisy need not be assumed.</blockquote>\n<p><br /><em>This post is part of a series rerunning Eliezer Yudkowsky's old posts so those interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/5q2/seq_rerun_chronophone_motivations/\">Chronophone Motivations</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cBnH8aJxe7nRaBKFJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 7.158555894767086e-07, "legacy": true, "legacyId": "7436", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JoERzF8ePGr4zP9vv", "FHH6J6B7NJYyrCLNA", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T20:13:14.234Z", "modifiedAt": null, "url": null, "title": "DC Meetup: May 22nd", "slug": "dc-meetup-may-22nd", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:04.670Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZciBtJHqTrp9hDaxY/dc-meetup-may-22nd", "pageUrlRelative": "/posts/ZciBtJHqTrp9hDaxY/dc-meetup-may-22nd", "linkUrl": "https://www.lesswrong.com/posts/ZciBtJHqTrp9hDaxY/dc-meetup-may-22nd", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20DC%20Meetup%3A%20May%2022nd&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADC%20Meetup%3A%20May%2022nd%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZciBtJHqTrp9hDaxY%2Fdc-meetup-may-22nd%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=DC%20Meetup%3A%20May%2022nd%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZciBtJHqTrp9hDaxY%2Fdc-meetup-may-22nd", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZciBtJHqTrp9hDaxY%2Fdc-meetup-may-22nd", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<p><em>Sunday, May 22nd</em></p>\n<p><em>Core hours: 1 PM - 3PM<br /></em></p>\n<p><em>Ballston Common Mall Food Court</em></p>\n<p><em>4238 Wilson Boulevard</em></p>\n<p><em>Arlington, Virginia 22203<br /></em></p>\n<p>Core hours are 1-3 PM, but many people are willing to hang out longer than that. People have stayed at previous meetups for 4 and 5 hours.</p>\n<p>We decided to meet in Virginia to see if there are any more LWers in the Northern Virginia area, and to see if we can meet them. If you've found other meetup locations inconvenient, please show up so that we can know that we might want to try and accommodate you.</p>\n<p>Join us at lesswrong-dc@googlegroups.com</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZciBtJHqTrp9hDaxY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "7437", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-05-17T21:08:20.080Z", "modifiedAt": null, "url": null, "title": "Living Forever is Hard, or, The Gompertz Curve", "slug": "living-forever-is-hard-or-the-gompertz-curve", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:06.998Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GytPrQ9cT46k9etoz/living-forever-is-hard-or-the-gompertz-curve", "pageUrlRelative": "/posts/GytPrQ9cT46k9etoz/living-forever-is-hard-or-the-gompertz-curve", "linkUrl": "https://www.lesswrong.com/posts/GytPrQ9cT46k9etoz/living-forever-is-hard-or-the-gompertz-curve", "postedAtFormatted": "Tuesday, May 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Living%20Forever%20is%20Hard%2C%20or%2C%20The%20Gompertz%20Curve&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALiving%20Forever%20is%20Hard%2C%20or%2C%20The%20Gompertz%20Curve%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGytPrQ9cT46k9etoz%2Fliving-forever-is-hard-or-the-gompertz-curve%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Living%20Forever%20is%20Hard%2C%20or%2C%20The%20Gompertz%20Curve%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGytPrQ9cT46k9etoz%2Fliving-forever-is-hard-or-the-gompertz-curve", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGytPrQ9cT46k9etoz%2Fliving-forever-is-hard-or-the-gompertz-curve", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1025, "htmlBody": "<p>I recently recalled, apropos of the <a href=\"/r/discussion/lw/5q5/life_extension_through_diet_modification/\">intermittent fasting/caloric restriction </a>discussion, a <a href=\"http://gravityandlevity.wordpress.com/2009/07/08/your-body-wasnt-built-to-last-a-lesson-from-human-mortality-rates/\">very good blog post on mortality curves and models of aging</a>:</p>\n<blockquote>\n<p>For me, a 25-year-old American, the probability of dying during the  next year is a fairly miniscule 0.03% &mdash; about 1 in 3,000.&nbsp; When I&rsquo;m 33  it will be about 1 in 1,500, when I&rsquo;m 42 it will be about 1 in 750, and  so on.&nbsp; By the time I reach age 100 (and I <em>do</em> plan on it) the  probability of living to 101 will only be about 50%.&nbsp; This is seriously  fast growth &mdash; my mortality rate is increasing exponentially with age.</p>\n<p>...This data fits the Gompertz law almost perfectly, with death rates  doubling every 8 years.&nbsp; The graph on the right also agrees with the  Gompertz law, and you can see the precipitous fall in survival rates  starting at age 80 or so.&nbsp; That decline is no joke; the sharp fall in  survival rates can be expressed mathematically as an exponential <em>within an exponential</em>:</p>\n<p style=\"text-align:center;\"><img class=\"latex\" title=\"P(t) \\approx e^{-0.003 e^{(t-25)/10}}\" src=\"http://s0.wp.com/latex.php?latex=P%28t%29+%5Capprox+e%5E%7B-0.003+e%5E%7B%28t-25%29%2F10%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\" alt=\"P(t) \\approx e^{-0.003 e^{(t-25)/10}}\" /></p>\n<p style=\"text-align: left;\">Exponential decay is sharp, but an  exponential within an exponential is so sharp that I can say with  99.999999% certainty that no human will ever live to the age of 130.&nbsp;  (Ignoring, of course, the upward shift in the lifetime distribution that  will result from future medical advances)</p>\n<p style=\"text-align: left;\">...There is one important lesson, however, to  be learned from Benjamin Gompertz&rsquo;s mysterious observation.&nbsp; By looking  at theories of human mortality that are clearly wrong, we can deduce  that our fast-rising mortality is not the result of a dangerous  environment, but of a body that has a built-in expiration date.</p>\n</blockquote>\n<p style=\"text-align: left;\">gravityandlevity then discusses some simple models of aging and the statistical characters they have which do not match Gompertz's law:</p>\n<ol>\n<li>'lightning' model: risk of mortality each period is constant; Poisson distribution:<br />\n<blockquote>\n<p style=\"text-align: left;\">What a crazy world!&nbsp; The average lifespan  would be the same, but out of every 100 people 31 would die before age  30 and 2 of them would live to be more than 300 years old.&nbsp; Clearly we  do not live in a world where mortality is governed by &ldquo;lightning bolts&rdquo;.</p>\n</blockquote>\n</li>\n<li>'accumulated lightning'; like in a video game, one has a healthbar which may take a hit each period; similar to above:<br />\n<blockquote>\n<p style=\"text-align: left;\">Shown above are the  results from a simulated world where &ldquo;lightning bolts&rdquo; of misfortune hit  people on average every 16 years, and death occurs at the fifth hit.&nbsp;  This world also has an average lifespan of 80 years (16*5 = 80), and its  distribution is a little less ridiculous than the previous case.&nbsp;  Still, it&rsquo;s no Gompertz Law: look at all those 160-year-olds!&nbsp; You can  try playing around with different &ldquo;lightning strike rates&rdquo; and different  number of hits required for death, but nothing will reproduce the  Gompertz Law.&nbsp; No explanation based on careless gods, no matter how  plentiful or how strong their blows are, will reproduce the strong upper  limit to human lifespan that we actually observe.</p>\n</blockquote>\n</li>\n</ol>\n<p>What models <em>do</em> yield a Gompertz curve? gravityandlevity describes a simple 'cops and robbers' model (which I like to think of as 'antibodies and cancers'):</p>\n<blockquote>\n<p>...in general, the cops are winning.&nbsp; They  patrol randomly through your body, and when they happen to come across a  criminal he is promptly removed.&nbsp; The cops can always defeat a criminal  they come across, unless the criminal has been allowed to sit in the  same spot for a long time.&nbsp; A criminal that remains in one place for  long enough (say, one day) can build a &ldquo;fortress&rdquo; which is too strong to  be assailed by the police.&nbsp; If this happens, you die.</p>\n<p style=\"text-align: left;\">Lucky for you, the cops are plentiful, and  on average they pass by every spot 14 times a day.&nbsp; The likelihood of  them missing a particular spot for an entire day is given (as you&rsquo;ve  learned by now) by the Poisson distribution: it is a mere <img class=\"latex\" title=\"e^{-14} \\approx 8 \\times 10^{-7}\" src=\"http://s0.wp.com/latex.php?latex=e%5E%7B-14%7D+%5Capprox+8+%5Ctimes+10%5E%7B-7%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\" alt=\"e^{-14} \\approx 8 \\times 10^{-7}\" />.</p>\n<p style=\"text-align: left;\">But what happens if your internal police  force starts to dwindle?&nbsp; Suppose that as you age the police force  suffers a slight reduction, so that they can only cover every spot 12  times a day.&nbsp; Then the probability of them missing a criminal for an  entire day decreases to <img class=\"latex\" title=\"e^{-12} \\approx 6 \\times 10^{-6}\" src=\"http://s0.wp.com/latex.php?latex=e%5E%7B-12%7D+%5Capprox+6+%5Ctimes+10%5E%7B-6%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\" alt=\"e^{-12} \\approx 6 \\times 10^{-6}\" />.&nbsp;  The difference between 14 and 12 doesn&rsquo;t seem like a big deal, but the  result was that your chance of dying during a given day jumped by more  than 10 times.&nbsp; And if the strength of your police force drops linearly  in time, your mortality rate will rise exponentially.</p>\n<p style=\"text-align: left;\">... The language of &ldquo;cops and criminals&rdquo; lends itself very easily to a  discussion of the immune system fighting infection and random mutation.&nbsp;  Particularly heartening is the fact that rates of cancer incidence also  follow the Gompertz law, doubling every 8 years or so.&nbsp; Maybe something  in the immune system is degrading over time, becoming worse at finding  and destroying mutated and potentially dangerous cells.</p>\n<p style=\"text-align: left;\">...Who are the criminals and who are the cops  that kill them?&nbsp; What is the &ldquo;incubation time&rdquo; for a criminal, and why  does it give &ldquo;him&rdquo; enough strength to fight off the immune response?&nbsp;  Why is the police force dwindling over time?&nbsp; For that matter, what kind  of &ldquo;clock&rdquo; does your body have that measures time at all? There have been attempts to describe DNA degradation (through the shortening of your<a href=\"http://en.wikipedia.org/wiki/Telomere\"> telomeres</a> or through <a href=\"http://en.wikipedia.org/wiki/DNA_methylation\">methylation</a>) as an increase in &ldquo;criminals&rdquo; that slowly overwhelm the body&rsquo;s DNA-repair mechanisms, but nothing has come of it so far.</p>\n</blockquote>\n<p style=\"text-align: left;\">This offers food for thought about various anti-aging strategies. For example, given the superexponential growth in mortality, if we had a magic medical treatment that could cut your mortality risk in half but didn't affect the <em>growth</em> of said risk, then that would buy you very little late in life, but might extend life by decades if administered at a very young age.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"t7t9nW6BtJhfGNSR6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GytPrQ9cT46k9etoz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 66, "extendedScore": null, "score": 0.000139, "legacy": true, "legacyId": "7438", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 87, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2bZ9ANSjcNPvzmGNN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}