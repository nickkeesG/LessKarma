{"results": [{"createdAt": null, "postedAt": "2012-01-31T23:05:07.130Z", "modifiedAt": null, "url": null, "title": "Writing rationalist fiction: Improving an existing setting?", "slug": "writing-rationalist-fiction-improving-an-existing-setting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:51.873Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R8Ho7dYanpcJjEA4C/writing-rationalist-fiction-improving-an-existing-setting", "pageUrlRelative": "/posts/R8Ho7dYanpcJjEA4C/writing-rationalist-fiction-improving-an-existing-setting", "linkUrl": "https://www.lesswrong.com/posts/R8Ho7dYanpcJjEA4C/writing-rationalist-fiction-improving-an-existing-setting", "postedAtFormatted": "Tuesday, January 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Writing%20rationalist%20fiction%3A%20Improving%20an%20existing%20setting%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWriting%20rationalist%20fiction%3A%20Improving%20an%20existing%20setting%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8Ho7dYanpcJjEA4C%2Fwriting-rationalist-fiction-improving-an-existing-setting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Writing%20rationalist%20fiction%3A%20Improving%20an%20existing%20setting%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8Ho7dYanpcJjEA4C%2Fwriting-rationalist-fiction-improving-an-existing-setting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8Ho7dYanpcJjEA4C%2Fwriting-rationalist-fiction-improving-an-existing-setting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 149, "htmlBody": "<p>I currently 'have' a minor SF setting, for which there exists a few short stories, comics, pictures, and the like, created by a variety of artists and authours. I'd like future contributions to be as rationalist as possible - for as many characters within the setting as possible to be <a title=\"Rationalist!Heroes\" href=\"http://www.fanfiction.net/u/2269863/Less_Wrong\">Rationalist!Heroes</a>, or even Rationalist!Villains. Do you have any advice that might help me try to nudge the various amateur artists and authours involved in that direction?</p>\n<p>(In case you're curious, the setting's current reftext is <a title=\"here\" href=\"http://www.datapacrat.com/sketches/NewAttica.html\">here</a>. The basic underlying question I'm basing it around is, \"As technology advances, it becomes possible for smaller and smaller groups to kill more and more people. How can society survive, let alone develop, when individuals have the power to kill billions?\" So far, most of the creations have been developing the overall background and characters, rather than focusing on that question directly.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R8Ho7dYanpcJjEA4C", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 0, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "12553", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T04:57:48.816Z", "modifiedAt": null, "url": null, "title": "Open Thread, February 1-14, 2012", "slug": "open-thread-february-1-14-2012", "viewCount": null, "lastCommentedAt": "2018-03-19T01:02:54.376Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gowLWvZfri5XKiy9n/open-thread-february-1-14-2012", "pageUrlRelative": "/posts/gowLWvZfri5XKiy9n/open-thread-february-1-14-2012", "linkUrl": "https://www.lesswrong.com/posts/gowLWvZfri5XKiy9n/open-thread-february-1-14-2012", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20February%201-14%2C%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20February%201-14%2C%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgowLWvZfri5XKiy9n%2Fopen-thread-february-1-14-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20February%201-14%2C%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgowLWvZfri5XKiy9n%2Fopen-thread-february-1-14-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgowLWvZfri5XKiy9n%2Fopen-thread-february-1-14-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gowLWvZfri5XKiy9n", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 8, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "12573", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 128, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T07:00:39.913Z", "modifiedAt": null, "url": null, "title": "State your physical account of experienced color", "slug": "state-your-physical-account-of-experienced-color", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:02.574Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mitchell_Porter", "createdAt": "2009-05-28T02:36:19.394Z", "isAdmin": false, "displayName": "Mitchell_Porter"}, "userId": "fjERoRhgjipqw3z2b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jJJLCGHDYyc9XbHwX/state-your-physical-account-of-experienced-color", "pageUrlRelative": "/posts/jJJLCGHDYyc9XbHwX/state-your-physical-account-of-experienced-color", "linkUrl": "https://www.lesswrong.com/posts/jJJLCGHDYyc9XbHwX/state-your-physical-account-of-experienced-color", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20State%20your%20physical%20account%20of%20experienced%20color&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AState%20your%20physical%20account%20of%20experienced%20color%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjJJLCGHDYyc9XbHwX%2Fstate-your-physical-account-of-experienced-color%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=State%20your%20physical%20account%20of%20experienced%20color%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjJJLCGHDYyc9XbHwX%2Fstate-your-physical-account-of-experienced-color", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjJJLCGHDYyc9XbHwX%2Fstate-your-physical-account-of-experienced-color", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 511, "htmlBody": "<p><em>Previous post: <a href=\"/r/discussion/lw/9o8/does_functionalism_imply_dualism/\">Does functionalism imply dualism?</a> Next post: <a href=\"/lw/9rb/one_last_roll_of_the_dice/\">One last roll of the dice</a>.</em></p>\n<p>Don't worry, this sequence of increasingly annoying posts is almost over. But I think it's desirable that we try to establish, once and for all, how people here think color works, and whether they even think it exists.</p>\n<p>The way I see it, there is a mental block at work. An obvious fact is being denied or evaded, because the conclusions are unpalatable. The obvious fact is that physics as we know it does not contain the colors that we see. By \"physics\" I don't just mean the entities that physicists talk about, I also mean anything that you can make out of them. I would encourage anyone who thinks they know what I mean, and who agrees with me on this point, to speak up and make it known that they agree. I don't mind being alone in this opinion, if that's how it is, but I think it's desirable to get some idea of whether LessWrong is genuinely 100% against the proposition.</p>\n<p>Just so we're all on the same wavelength, I'll point to a specific example of color. Up at the top of this web page, the word \"Less\" appears. It's green. So, there is an example of a colored entity, right in front of anyone reading this page.</p>\n<p>My thesis is that if you take a lot of point-particles, with no property except their location, and arrange them any way you want, there won't be anything that's green like that; and that the same applies for any physical theory with an ontology that doesn't explicitly include color. To me, this is just mindbogglingly obvious, like the fact that you can't get a letter by adding numbers.</p>\n<p>At this point people start talking about neurons and gensyms and concept maps. The greenness isn't in the physical object, \"computer screen\", it's in the brain's response to the stimulus provided by light from the computer screen entering the eye.</p>\n<p>My response is simple. Try to fix in your mind what the physical reality must be, behind your favorite neuro-cognitive explanation of greenness. Presumably it's something like \"a whole lot of neurons, firing in a particular way\". Try to imagine what that is physically, in terms of atoms. Imagine some vast molecular tinker-toy structures, shaped into a cluster of neurons, with traveling waves of ions crossing axonal membranes. Large numbers of atoms arranged in space, a few of them executing motions which are relevant for the information processing. Do you have that in your mind's eye? Now look up again at that word \"Less\", and remind yourself that according to your theory, the green shape that you are seeing is the same thing as some aspect of all those billions of colorless atoms in motion.</p>\n<p>If your theory still makes sense to you, then please tell us in comments what aspect of the atoms in motion is actually green.</p>\n<p>I only see three options. Deny that anything is actually green; become a dualist; or (supervillain voice) join me, and together, we can make a new ontology.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jJJLCGHDYyc9XbHwX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": -7, "extendedScore": null, "score": 8.413295319511548e-07, "legacy": true, "legacyId": "12576", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iHMy2X9mqQT6ayf9f", "qkFkg46Jw3LurFyaj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T09:44:20.543Z", "modifiedAt": null, "url": null, "title": "Deciding what to think about; is it worthwhile to have universal utility function?", "slug": "deciding-what-to-think-about-is-it-worthwhile-to-have", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:51.878Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dmytry", "createdAt": "2009-12-03T17:11:53.492Z", "isAdmin": false, "displayName": "Dmytry"}, "userId": "AjtmA2qtA8sdiMbru", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ram7WcRhKSkPdE73w/deciding-what-to-think-about-is-it-worthwhile-to-have", "pageUrlRelative": "/posts/ram7WcRhKSkPdE73w/deciding-what-to-think-about-is-it-worthwhile-to-have", "linkUrl": "https://www.lesswrong.com/posts/ram7WcRhKSkPdE73w/deciding-what-to-think-about-is-it-worthwhile-to-have", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Deciding%20what%20to%20think%20about%3B%20is%20it%20worthwhile%20to%20have%20universal%20utility%20function%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeciding%20what%20to%20think%20about%3B%20is%20it%20worthwhile%20to%20have%20universal%20utility%20function%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fram7WcRhKSkPdE73w%2Fdeciding-what-to-think-about-is-it-worthwhile-to-have%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Deciding%20what%20to%20think%20about%3B%20is%20it%20worthwhile%20to%20have%20universal%20utility%20function%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fram7WcRhKSkPdE73w%2Fdeciding-what-to-think-about-is-it-worthwhile-to-have", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fram7WcRhKSkPdE73w%2Fdeciding-what-to-think-about-is-it-worthwhile-to-have", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 632, "htmlBody": "<p>The hunter-gatherer example in the <a href=\"/lw/9oj/is_risk_aversion_really_irrational/\">Is risk aversion really irrational?</a> got me thinking about the real world issues with 'maximizing utility' and any other simple rule approach to decision making.</p>\n<p>The elephant in the room is that universal, effective utility of anything could be very expensive to calculate if you employ any foresight (consider thinking several moves ahead). And once you start estimating utility in different ways depending to the domain, the agent's behaviour stops being consistent with plain utility maximization. At same time, the solution space of the problems is often very big, meaning that you have immense number of potential choices and you need to perform a lot of utility estimations really quickly to pick the best solution. Think of Chess or Go. The computing time could be better spent elsewhere.</p>\n<p>The hunter-gatherer in example can think about the traps and other hunting tools and invent a new one, instead of trying to figure out probability theory or something of this kind.</p>\n<p>Inventing a new trap is a case where the number of potential decisions is extremely huge.</p>\n<p>I faintly recall a fiction story I've read where a smart boy becomes tribe leader - by inventing a better bear trap, not so much by being utterly rational at correctly processing small differences in expected utility when it comes to bets.</p>\n<p>He can also think more about berries and look if there's evidence that other mammals are eating those berries; some plant that is not poisonous to other mammal is very unlikely to hurt a human; some plant that is not eaten by other mammals is very likely to be poisonous to humans as well. He can even feed the berries to some mammal he'd keep alive (i'd imagine keeping animals alive was a fairly straightforward approach to meat preservation).</p>\n<p>At the same time, even if that hunter gatherer knew enough math to try to formally calculate his odds, the probabilities are unknown. Indeed there are probability distributions for different degrees of getting sick of berries or not (and different symptoms of sickness), et cetera. We today are just beginning to think how to improve his odds using formal mathematics, and we're still not sure how to accomplish that, and it is clear that it is going to be very computationally intensive.</p>\n<p>As a singular example, I can easily come up with good solutions for that hunter-gatherer by looking into the big solution space that he would have (he's living in the real world), but it is much harder and much more tedious for me to calculate his odds even in a very simplified example where probabilities of getting sick or winning a duel are exact, and the 'sick or not sick' is a binary outcome. That's with me having a computer at my fingertips, and knowledge of mathematics tens thousands years down the road from hunter gatherer!</p>\n<p>Bottom line, it would be very suboptimal for the intelligent hunter gatherer to try to use his intelligence in this particular expected-utility-calculating way to slightly optimize his behaviour (keep in mind that he has no way of estimating probabilities), when lesser amount of good thought would allow him to invent something extremely useful and gain the status.</p>\n<p>As a personal success story - I have developed and successfully published a computer game, and made good income on it. The effort that can be spent on decision making - on choosing to implement A or B, is always tightly capped by the other ways of applying effort that would pay off more (implementing both A and B, or searching the solution space more in the hope of coming up with C). It is very rare that putting effort into very careful choice between very few options is the best use of intelligence. It is common in thought experiments but its rare in reality.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ram7WcRhKSkPdE73w", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 4, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "12580", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ecbpjmxc833roBxj3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T12:50:59.681Z", "modifiedAt": null, "url": null, "title": "[Link] Reconstructing Speech from Human Auditory Cortex", "slug": "link-reconstructing-speech-from-human-auditory-cortex", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "oFp6JLn8z9uxgdPp8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ntbhyC498eMB2xmzT/link-reconstructing-speech-from-human-auditory-cortex", "pageUrlRelative": "/posts/ntbhyC498eMB2xmzT/link-reconstructing-speech-from-human-auditory-cortex", "linkUrl": "https://www.lesswrong.com/posts/ntbhyC498eMB2xmzT/link-reconstructing-speech-from-human-auditory-cortex", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Reconstructing%20Speech%20from%20Human%20Auditory%20Cortex&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Reconstructing%20Speech%20from%20Human%20Auditory%20Cortex%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FntbhyC498eMB2xmzT%2Flink-reconstructing-speech-from-human-auditory-cortex%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Reconstructing%20Speech%20from%20Human%20Auditory%20Cortex%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FntbhyC498eMB2xmzT%2Flink-reconstructing-speech-from-human-auditory-cortex", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FntbhyC498eMB2xmzT%2Flink-reconstructing-speech-from-human-auditory-cortex", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p><a href=\"http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001251\">Link to full paper. </a></p>\n<p>Abstract (emphasis mine):</p>\n<blockquote>\n<p>How the human auditory system extracts perceptually relevant acoustic  features of speech is unknown. To address this question, we used  intracranial recordings from nonprimary auditory cortex in the human  superior temporal gyrus to determine what acoustic information in speech  sounds can be reconstructed from population neural activity. We found  that slow and intermediate temporal fluctuations, such as those  corresponding to syllable rate, were accurately reconstructed using a  linear model based on the auditory spectrogram. However, reconstruction  of fast temporal fluctuations, such as syllable onsets and offsets,  required a nonlinear sound representation based on temporal modulation  energy. Reconstruction accuracy was highest within the range of  spectro-temporal fluctuations that have been found to be critical for  speech intelligibility. <strong>The decoded speech representations allowed  readout and identification of individual words directly from brain  activity during single trial sound presentations.</strong> These findings reveal  neural encoding mechanisms of speech acoustic parameters in higher order  human auditory cortex.</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ntbhyC498eMB2xmzT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 8.414651113458488e-07, "legacy": true, "legacyId": "12582", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T13:50:56.712Z", "modifiedAt": null, "url": null, "title": "von Neumann probes and Dyson spheres: what exploratory engineering can tell us about the Fermi paradox", "slug": "von-neumann-probes-and-dyson-spheres-what-exploratory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:22.698Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hA7kNKjnjLDp7DbKL/von-neumann-probes-and-dyson-spheres-what-exploratory", "pageUrlRelative": "/posts/hA7kNKjnjLDp7DbKL/von-neumann-probes-and-dyson-spheres-what-exploratory", "linkUrl": "https://www.lesswrong.com/posts/hA7kNKjnjLDp7DbKL/von-neumann-probes-and-dyson-spheres-what-exploratory", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20von%20Neumann%20probes%20and%20Dyson%20spheres%3A%20what%20exploratory%20engineering%20can%20tell%20us%20about%20the%20Fermi%20paradox&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Avon%20Neumann%20probes%20and%20Dyson%20spheres%3A%20what%20exploratory%20engineering%20can%20tell%20us%20about%20the%20Fermi%20paradox%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhA7kNKjnjLDp7DbKL%2Fvon-neumann-probes-and-dyson-spheres-what-exploratory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=von%20Neumann%20probes%20and%20Dyson%20spheres%3A%20what%20exploratory%20engineering%20can%20tell%20us%20about%20the%20Fermi%20paradox%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhA7kNKjnjLDp7DbKL%2Fvon-neumann-probes-and-dyson-spheres-what-exploratory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhA7kNKjnjLDp7DbKL%2Fvon-neumann-probes-and-dyson-spheres-what-exploratory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<p>Not entirely relevant to the main issues of lesswrong, but possibly still of interest: my talk entitled \"<a href=\"http://www.youtube.com/watch?v=zQTfuI-9jIo&amp;feature=plcp&amp;context=C3f6a5ecUDOEgsToPDskKi-IqIea_gLUuUI6IVFvM_\">von Neumann probes and Dyson spheres: what exploratory engineering can tell us about the Fermi paradox</a>\".</p>\n<p>Abstract: &nbsp;The Fermi paradox is the contrast between the high estimate of the likelihood of extraterritorial civilizations, and the lack of visible evidence of them. But what sort of evidence should we expect to see? This is what exploratory engineering can tell us, giving us estimates of what kind of cosmic structures are plausibly constructable by advanced civilizations, and what traces they would leave. Based on our current knowledge, it seems that it would be easy for such a civilization to rapidly occupy vast swathes of the universe in a visible fashion. There are game-theoretic reasons to suppose that they would do so. This leads to a worsening of the Fermi paradox, reducing the likelihood of \"advanced but unseen\" civilizations, even in other galaxies.</p>\n<p>The slides from the talk can be found <a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2F9pj%2Fvon_neumann_probes_and_dyson_spheres_what%2F5t8g%3Fcontext%3D3&amp;v=1&amp;libid=1328175784771&amp;out=http%3A%2F%2Fdl.dropbox.com%2Fu%2F163098%2FFermi%2520Paradox%2520Stuart%2520Talk.pptx&amp;ref=http%3A%2F%2Flesswrong.com%2Fmessage%2Finbox%2F&amp;title=lukeprog%20comments%20on%20von%20Neumann%20probes%20and%20Dyson%20spheres%3A%20what%20exploratory%20engineering%20can%20tell%20us%20about%20the%20Fermi%20paradox%20-%20Less%20Wrong&amp;txt=Uploaded&amp;jsonp=vglnk_jsonp_13281759489711\">here</a> (thanks, Luke!).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb1a1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hA7kNKjnjLDp7DbKL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 21, "extendedScore": null, "score": 8.414883163425523e-07, "legacy": true, "legacyId": "12583", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T19:20:19.988Z", "modifiedAt": null, "url": null, "title": "Mini-review: 'Proving History: Bayes' Theorem and the Quest for the Historical Jesus'", "slug": "mini-review-proving-history-bayes-theorem-and-the-quest-for", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:30.029Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/e4DaC66P3cY7SHXCv/mini-review-proving-history-bayes-theorem-and-the-quest-for", "pageUrlRelative": "/posts/e4DaC66P3cY7SHXCv/mini-review-proving-history-bayes-theorem-and-the-quest-for", "linkUrl": "https://www.lesswrong.com/posts/e4DaC66P3cY7SHXCv/mini-review-proving-history-bayes-theorem-and-the-quest-for", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mini-review%3A%20'Proving%20History%3A%20Bayes'%20Theorem%20and%20the%20Quest%20for%20the%20Historical%20Jesus'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMini-review%3A%20'Proving%20History%3A%20Bayes'%20Theorem%20and%20the%20Quest%20for%20the%20Historical%20Jesus'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe4DaC66P3cY7SHXCv%2Fmini-review-proving-history-bayes-theorem-and-the-quest-for%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mini-review%3A%20'Proving%20History%3A%20Bayes'%20Theorem%20and%20the%20Quest%20for%20the%20Historical%20Jesus'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe4DaC66P3cY7SHXCv%2Fmini-review-proving-history-bayes-theorem-and-the-quest-for", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe4DaC66P3cY7SHXCv%2Fmini-review-proving-history-bayes-theorem-and-the-quest-for", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 444, "htmlBody": "<p>I recently received an advance review copy of historian and philosopher <a href=\"http://richardcarrier.info/\">Richard Carrier</a>'s new book, <em><a href=\"http://www.amazon.com/Proving-History-Bayess-Theorem-Historical/dp/1616145595\">Proving History: Bayes' Theorem and the Quest for the Historical Jesus</a></em>.</p>\n<p>The book belongs to a two-volume work on the <a href=\"http://en.wikipedia.org/wiki/Historical_Jesus\">Historical Jesus</a>&nbsp;that argues for two major claims:</p>\n<ol>\n<li>Correct historical method is Bayesian. (The first book.)</li>\n<li>The application of this method to our data concerning the Historical Jesus strongly suggests that Jesus never existed. (The second book.)</li>\n</ol>\n<p>Claim #1 might provoke a yawning \"Yes, of course...\" from many scientists and philosophers, but both claims are currently heretical in the field of Jesus Studies, which shows <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">many</a> <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/3k7k\">signs</a> of being an unsound research program in general. The book is written for a mass audience, but is also aimed at historians in general. It is, as far as I know, the first book to lay out the detailed case for why historians should be using Bayesian methods. (For an overview of the other methods historians typically use, see <em><a href=\"http://www.amazon.com/Justifying-Historical-Descriptions-Cambridge-Philosophy/dp/0521318300/\">Justifying Historical Descriptions</a></em>.)</p>\n<p>Though the Bayesian revolution of the sciences has already slammed into archaeology and a few other fields of historical inquiry, it has not yet overwhelmed mainstream historical inquiry. Carrier's book may be seen as the first salvo in that attack, but this makes me wish his case had not been presented in the context of such a parochial and disreputable sub-field of history as Jesus Studies. No chapter in the book discusses the evidence concerning the historicity of Jesus in much detail, and it clearly isn't necessary to make Carrier's points, so why poison the presentation of such a clear and powerful case (in favor of Bayesian historical methods) by marinating it in such a disreputable field (Jesus Studies), and with anticipation of a startling conclusion almost everyone disagrees with (<a href=\"http://en.wikipedia.org/wiki/Jesus_myth_theory\">Jesus myth theory</a>)? (For the record, I take Jesus myth theory pretty seriously, but most people don't.)</p>\n<p>Chapter 3 is a tutorial on Bayes' Theorem, similar to <a href=\"http://www.youtube.com/watch?v=HHIz-gR4xHo\">Carrier's Skepticon IV talk</a>. Chapter 4 provides an analysis of non-Bayesian methods of historical analysis, showing that they are wrong in exactly the degree to which they depart from the Bayesian method. Chapter 5 provides a similar analysis of typical \"Historicity Criteria\" used in Jesus Studies, e.g. \"multiple attestation.\" The final chapter tackles some more detailed issues with the application of Bayes' Theorem, for example the interaction between frequentism and Bayesianism.</p>\n<p>At first, the contents of <em>Proving History</em>&nbsp;seemed too obvious and underwhelming for me to strongly recommend it. Then I remembered that no other book I've read on historical methodology or the Historical Jesus had correctly used probability theory to justify its judgments. Which means that <em>Proving History</em>&nbsp;may actually be&nbsp;the best book yet written in either field.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bY5MaF2EATwDkomvu": 2, "LhX3F2SvGDarZCuh6": 2, "NSMKfa8emSbGNXRKD": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "e4DaC66P3cY7SHXCv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 27, "extendedScore": null, "score": 6.4e-05, "legacy": true, "legacyId": "12586", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fyZBtNB3Ki3fM4a6Y"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T20:55:18.448Z", "modifiedAt": null, "url": null, "title": "Automatic programming, an example", "slug": "automatic-programming-an-example", "viewCount": null, "lastCommentedAt": "2017-09-11T07:10:29.983Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Thomas", "createdAt": "2009-03-02T17:47:09.607Z", "isAdmin": false, "displayName": "Thomas"}, "userId": "GrAKeuxT4e9AKyHdE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AcKhXCQLjMBvocZk5/automatic-programming-an-example", "pageUrlRelative": "/posts/AcKhXCQLjMBvocZk5/automatic-programming-an-example", "linkUrl": "https://www.lesswrong.com/posts/AcKhXCQLjMBvocZk5/automatic-programming-an-example", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Automatic%20programming%2C%20an%20example&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAutomatic%20programming%2C%20an%20example%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAcKhXCQLjMBvocZk5%2Fautomatic-programming-an-example%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Automatic%20programming%2C%20an%20example%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAcKhXCQLjMBvocZk5%2Fautomatic-programming-an-example", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAcKhXCQLjMBvocZk5%2Fautomatic-programming-an-example", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 730, "htmlBody": "<p><span style=\"font-style: normal;\">Say, that we have the following observational data:</span></p>\n<p>&nbsp;</p>\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"5\">\n<tbody>\n<tr>\n<td align=\"right\"><strong>Planet</strong></td>\n<td align=\"right\"><strong>Aphelion<br /></strong>000 km</td>\n<td align=\"right\"><strong>Perihelion<br /></strong><strong> </strong> 000 km<span style=\"font-weight: bold; white-space: pre; \"> </span></td>\n<td align=\"right\"><strong> Orbit time<br /></strong> days</td>\n</tr>\n<tr>\n<td align=\"right\">Mercury</td>\n<td align=\"right\">69,816</td>\n<td align=\"right\">46,001</td>\n<td align=\"right\">88</td>\n</tr>\n<tr>\n<td align=\"right\">Venus</td>\n<td align=\"right\">108,942</td>\n<td align=\"right\">107,476</td>\n<td align=\"right\">225</td>\n</tr>\n<tr>\n<td align=\"right\">Earth</td>\n<td align=\"right\">152,098</td>\n<td align=\"right\">147,098</td>\n<td align=\"right\">365</td>\n</tr>\n<tr>\n<td align=\"right\">Mars</td>\n<td align=\"right\">249,209</td>\n<td align=\"right\">206,669</td>\n<td align=\"right\">687</td>\n</tr>\n<tr>\n<td align=\"right\">Jupiter</td>\n<td align=\"right\">816,520</td>\n<td align=\"right\">740,573</td>\n<td align=\"right\">4,332</td>\n</tr>\n<tr>\n<td align=\"right\">Saturn</td>\n<td align=\"right\">1,513,325</td>\n<td align=\"right\">1,353,572</td>\n<td align=\"right\">10,760</td>\n</tr>\n<tr>\n<td align=\"right\">Uranus</td>\n<td align=\"right\">3,004,419</td>\n<td align=\"right\">2,748,938</td>\n<td align=\"right\">30,799</td>\n</tr>\n<tr>\n<td align=\"right\">Neptune</td>\n<td align=\"right\">4,553,946</td>\n<td align=\"right\">4,452,940</td>\n<td align=\"right\">60,190</td>\n</tr>\n<tr>\n<td align=\"right\">Pluto</td>\n<td align=\"right\">7,311,000</td>\n<td align=\"right\">4,437,000</td>\n<td align=\"right\">90,613</td>\n</tr>\n</tbody>\n</table>\n<!-- td { font-family: Verdana; } -->\n<p>&nbsp;</p>\n<p>The minimal, the maximal distance between a planet and the Sun (both in thousands of kilometres) and the number of (Earth) days for one revolution around the Sun. Above is only the empirical data and no binding algorithm among the three quantities. The celestial mechanics rules which go by the name of the Kepler's laws. Can those rules be (re)invented by a computer program and how?</p>\n<p>The following program code will be put into a simulator:</p>\n<pre><span style=\"font-family: Courier;\">//declarations of the integer type variables<br /></span><span style=\"font-family: Courier;\">$DECLAREINT bad perihelion aphelion orbit guess dif temp zero temp1<br /></span><span style=\"font-family: Courier;\"> <br /></span><span style=\"font-family: Courier;\">//table with the known data in a simulator friendly format<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(46001) aphelion(69816) orbit(88)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(107476) aphelion(108942) orbit(225)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(147098) aphelion(152098) orbit(365)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(206669) aphelion(249209) orbit(687)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(740573) aphelion(816520) orbit(4332)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(1353572) aphelion(1513325) orbit(10760)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(2748938) aphelion(3004419) orbit(30799)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(4452940) aphelion(4553946) orbit(60190)<br /></span><span style=\"font-family: Courier;\">$INVAR perihelion(4437000) aphelion(7311000) orbit(90613)<br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">// variables <strong>orbit</strong> and <strong>bad</strong> can't be touched by the simulator<br /></span><span style=\"font-family: Courier;\">//to avoid a degeneration to a triviality<br /></span><span style=\"font-family: Courier;\">$RESVAR orbit bad <br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">//do NOT use if clause, while clause do not set direct numbers ...<br /></span><span style=\"font-family: Courier;\">$RESCOM if while val_operation inc_dec<br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">//bad is the variable, by which the whole program will be judged<br /></span><span style=\"font-family: Courier;\"><span style=\"font-family: Courier;\">//a big value of bad is bad. By this criteria programs will be wiped out<br /></span></span><span style=\"font-family: Courier;\"><span style=\"font-family: Courier;\">//from their virtual existence. A kind of anti-fitness<br /></span></span><span style=\"font-family: Courier;\">$PENVAL bad <br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">//do show the following variables when simulating<br /></span><span style=\"font-family: Courier;\">$SHOWVAR bad,orbit,guess,dif <br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">//penalize any command with 0 (nothing) and every line by 1 point<br /></span><span style=\"font-family: Courier;\">$WEIGHTS commands=0 lines=1<br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">//minimize the whole program to 20 lines or less<br /></span><span style=\"font-family: Courier;\">$MINIMIZE lines 20 <br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">$BES<br /></span><span style=\"font-family: Courier;\"> <pre><span style=\"font-family: Courier;\">//the arena, where algorithms will be<br /></span><span style=\"font-family: Courier;\">//created and the fittest only will survive<br /></span></pre>\n</span></pre>\n<pre><span style=\"font-family: Courier;\">$EES<br /></span><span style=\"font-family: Courier;\"><br /></span></pre>\n<pre><span style=\"font-family: Courier;\">//testing area where the simulator has no write access to<br /></span><span style=\"font-family: Courier;\">//here the bad (the penalized variable) is calculated<br /></span><span style=\"font-family: Courier;\">//bigger the difference between the known orbit and the variable guess<br /></span><span style=\"font-family: Courier;\">//worse is the evolved algorithm<br /></span><span style=\"font-family: Courier; \">dif=orbit-guess;<br /></span><span style=\"font-family: Courier;\">dif=abs(dif);<br /></span><span style=\"font-family: Courier;\">bad=dif;<br /></span><span style=\"font-family: Courier;\">temp=dif;<br /></span><span style=\"font-family: Courier;\">temp*=10000;<br /></span><span style=\"font-family: Courier;\">temp1=temp/orbit;<br /></span><span style=\"font-family: Courier;\">temp=temp1*temp1;<br /></span><span style=\"font-family: Courier;\">bad=bad+temp;<br /></span><span style=\"font-family: Courier;\">//end of the testing area</span></pre>\n<p>&nbsp;</p>\n<p>After several hours the following C code has been evolved inside of the $BES - $EES segment.</p>\n<p>&nbsp;</p>\n<pre><span style=\"font-family: Courier;\">aphelion=perihelion+aphelion;<br /></span><span style=\"font-family: Courier;\">aphelion=aphelion+aphelion;<br /></span><span style=\"font-family: Courier;\">aphelion=aphelion+aphelion;<br /></span><span style=\"font-family: Courier;\">guess=12;<br /></span><span style=\"font-family: Courier;\">aphelion=aphelion&gt;&gt;guess;<br /></span><span style=\"font-family: Courier;\">temp=aphelion/</span><span style=\"font-family: Courier; \">guess</span><span style=\"font-family: Courier; \">;<br /></span><span style=\"font-family: Courier; \">aphelion=aphelion-temp;<br /></span><span style=\"font-family: Courier;\">dif=sqrt(aphelion);<br /></span><span style=\"font-family: Courier;\">aphelion=guess|aphelion;<br /></span><span style=\"font-family: Courier;\">aphelion=aphelion*dif;<br /></span><span style=\"font-family: Courier;\">aphelion=guess^aphelion;<br /></span><span style=\"font-family: Courier;\">guess=aphelion/guess;</span></pre>\n<p>&nbsp;</p>\n<p>What the simulator does? It bombards the arena segment with a random C commands. Usually it then just notices a syntax error and repairs everything to the last working version. If everything is syntactically good, the simulator interprets the program and checks if the mutated version causes any run-time error like division by zero, a memory leak and so on. In the case of such an error it returns to the last good version. Otherwise it checks the variable called \"bad\", if it is at least as small as it was ever before. In the case it is, a new version has just been created and it is stored.</p>\n<p>The evolutionary pressure is working toward ever better code, which increasingly well guesses the orbit time of nine planets. In this case the \"orbit\" variable has been under the $RESVAR clause and then the \"gues\" variable has been tested against the \"orbit\" variable. Had been no \"$RESVAR orbit\" statement, a simple \"guess=orbit;\" would evolve quickly. Had been no \"$RESVAR bad\" statement a simple \"bad=-1000000;\" could derail the process.</p>\n<p>Many thousands of algorithms are born and die every second on a standard Windows PC inside this simulator. Million or billion generations later, the digital evolution is still running, even if an excellent solution has been already found.</p>\n<p>And how good approximation for the Kepler (Newton) celestial mechanics of the Solar system we have here?</p>\n<p>This good for the nine planets where the code evolved:</p>\n<!-- td { font-family: Verdana; } --> \n<table border=\"1\" cellspacing=\"0\" cellpadding=\"5\">\n<tbody>\n<tr>\n<td align=\"right\"><strong>Planet</strong></td>\n<td align=\"right\"><strong>Error %</strong></td>\n</tr>\n<tr>\n<td align=\"right\">Mercury</td>\n<td align=\"right\">0.00</td>\n</tr>\n<tr>\n<td align=\"right\">Venus</td>\n<td align=\"right\">0.44</td>\n</tr>\n<tr>\n<td align=\"right\">Earth</td>\n<td align=\"right\">0.27</td>\n</tr>\n<tr>\n<td align=\"right\">Mars</td>\n<td align=\"right\">0.29</td>\n</tr>\n<tr>\n<td align=\"right\">Jupiter</td>\n<td align=\"right\">0.16</td>\n</tr>\n<tr>\n<td align=\"right\">Saturn</td>\n<td align=\"right\">0.65</td>\n</tr>\n<tr>\n<td align=\"right\">Uranus</td>\n<td align=\"right\">0.10</td>\n</tr>\n<tr>\n<td align=\"right\">Neptune</td>\n<td align=\"right\">0.79</td>\n</tr>\n<tr>\n<td align=\"right\">Pluto</td>\n<td align=\"right\">1.08</td>\n</tr>\n</tbody>\n</table>\n<p>&nbsp;</p>\n<p>And this good for the control group of a comet and six asteroids:</p>\n<p>&nbsp;</p>\n<!-- td { font-family: Verdana; } --> \n<table border=\"1\" cellspacing=\"0\" cellpadding=\"5\">\n<tbody>\n<tr>\n<td align=\"right\"><strong>Asteroid/Comet</strong></td>\n<td align=\"right\"><strong>Error %</strong></td>\n</tr>\n<tr>\n<td align=\"right\">Halley</td>\n<td align=\"right\">1.05</td>\n</tr>\n<tr>\n<td align=\"right\">Hebe</td>\n<td align=\"right\">1.37</td>\n</tr>\n<tr>\n<td align=\"right\">Astraea</td>\n<td align=\"right\">1.99</td>\n</tr>\n<tr>\n<td align=\"right\">Juno</td>\n<td align=\"right\">3.19</td>\n</tr>\n<tr>\n<td align=\"right\">Pallas</td>\n<td align=\"right\">1.66</td>\n</tr>\n<tr>\n<td align=\"right\">Vesta</td>\n<td align=\"right\">2.49</td>\n</tr>\n<tr>\n<td align=\"right\">Ceres</td>\n<td align=\"right\">2.02</td>\n</tr>\n</tbody>\n</table>\n<p>&nbsp;</p>\n<p>Could be even much better after another billion generations and maybe with even more $INVAR examples. Generally, you can pick any three columns from any integer type table you want. And see this way, how they are related algorithmically. Can be more than three columns also.</p>\n<p>The name of the simulator (evoluator) is Critticall and it is available at http://www.critticall.com</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AcKhXCQLjMBvocZk5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 19, "extendedScore": null, "score": 8.416522587047395e-07, "legacy": true, "legacyId": "12585", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T21:03:56.231Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes February 2012", "slug": "rationality-quotes-february-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:29.333Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "a7xJQpZ55R6SxFTik", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rAi9RSM5SYd2Pto4q/rationality-quotes-february-2012", "pageUrlRelative": "/posts/rAi9RSM5SYd2Pto4q/rationality-quotes-february-2012", "linkUrl": "https://www.lesswrong.com/posts/rAi9RSM5SYd2Pto4q/rationality-quotes-february-2012", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20February%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20February%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrAi9RSM5SYd2Pto4q%2Frationality-quotes-february-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20February%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrAi9RSM5SYd2Pto4q%2Frationality-quotes-february-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrAi9RSM5SYd2Pto4q%2Frationality-quotes-february-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p>Here's the new thread for posting quotes, with the usual rules:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Please post all quotes separately, so that they can be voted up/down separately. &nbsp;(If they are strongly related, reply to your own comments. &nbsp;If strongly ordered, then go ahead and post them together.)&nbsp;</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rAi9RSM5SYd2Pto4q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 8.41655948213703e-07, "legacy": true, "legacyId": "12584", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 410, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-01T21:48:11.562Z", "modifiedAt": null, "url": null, "title": "Mini-Review: 'The Oxford Handbook of Philosophy of Cognitive Science'", "slug": "mini-review-the-oxford-handbook-of-philosophy-of-cognitive", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:52.201Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5DkC23uEYRWb9G7A9/mini-review-the-oxford-handbook-of-philosophy-of-cognitive", "pageUrlRelative": "/posts/5DkC23uEYRWb9G7A9/mini-review-the-oxford-handbook-of-philosophy-of-cognitive", "linkUrl": "https://www.lesswrong.com/posts/5DkC23uEYRWb9G7A9/mini-review-the-oxford-handbook-of-philosophy-of-cognitive", "postedAtFormatted": "Wednesday, February 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mini-Review%3A%20'The%20Oxford%20Handbook%20of%20Philosophy%20of%20Cognitive%20Science'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMini-Review%3A%20'The%20Oxford%20Handbook%20of%20Philosophy%20of%20Cognitive%20Science'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5DkC23uEYRWb9G7A9%2Fmini-review-the-oxford-handbook-of-philosophy-of-cognitive%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mini-Review%3A%20'The%20Oxford%20Handbook%20of%20Philosophy%20of%20Cognitive%20Science'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5DkC23uEYRWb9G7A9%2Fmini-review-the-oxford-handbook-of-philosophy-of-cognitive", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5DkC23uEYRWb9G7A9%2Fmini-review-the-oxford-handbook-of-philosophy-of-cognitive", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 928, "htmlBody": "<p>Today I had the pleasure of wading through Oxford's new <em><a href=\"http://www.amazon.com/Handbook-Philosophy-Cognitive-Science-Handbooks/dp/0195309790/\">Handbook of Philosophy of Cognitive Science</a></em>.&nbsp;The book consists of review chapters on the following topics:</p>\n<ul>\n<li>Cognition (computationalism vs. embodied cognition, mental representation)</li>\n<li>Consciousness</li>\n<li>The nature of thought (concepts, language and thought)</li>\n<li>Specific mental phenomena (perception, attention, emotions)</li>\n<li>Meta-theoretic issues (the assumptions of cognitive science, relationships between disciplines)</li>\n<li>Conceptual issues (the relation between concepts used by psychology, neuroscience, and philosophy)</li>\n<li>First-order empirical issues (theory of mind, language, culture and cognition)</li>\n<li>Traditional philosophical issues (rationality, metaphilosophy)</li>\n</ul>\n<p>Below, I'll summarize a few of the chapters I found most useful and interesting.</p>\n<p>In \"<strong>Consciousness and Cognition</strong>,\" <a href=\"http://thecollege.syr.edu/profiles/pages/vangulick-robert.html\">Robert van Gulick</a>&nbsp;begins by listing 10 different things that is often meant by the term \"consciousness.\" He then explains that some regard consciousness as more basic than cognition, while others see consciousness as dependent on cognition. (I take the latter view.) Van Gulick then surveys three main categories of theories of consciousness: philosophical theories (including Dennett's \"multiple drafts\" theory), cognitive theories (including Baars' \"global workspace\" theory and Tononi's information integration theory), and neurobiological theories (including Dehaene &amp; Naccache's neuronal version of global workspace theory and Lamme's \"local recurrence\" model). Van Gulick concludes by surveying some of the methods used in consciousness studies.</p>\n<p>In \"<strong>Embodied Cognition</strong>,\" <a href=\"http://www.shapirolab.org/People/larry/lawrence-shapiro.html\">Lawrence Shaprio</a> attempts to explain the difference between computational and embodied theories of cognition. Computational theorists treat the mind as a computational system, and seek to infer the algorithms by which the mind transforms inputs into outputs. (I'll add that at some level of organization this <em>must</em>&nbsp;be true, for physics appears to be computational and the mind runs on physics.) And what do embodied theories claim?</p>\n<p>After reading the chapter, I remain confused as to how embodied approaches are supposed to be non-computational. For example, Shapiro quotes Ester Thelen explaining embodied cognition this way: \"...to say that cognition is embodied means that it arises from bodily interactions with the world [and] depends on the kinds of experiences that come from having a body with particular perceptual and motor capabilities that are inseparably linked and that together form the matrix within which reasoning, memory, emotion, language, and all other aspects of mental life are meshed.\" But I don't see anything non-computational about that!</p>\n<p>As far as I can tell, embodied theories are motivated by a rejection of early theories which naively proposed that the human mind is entirely a symbol-manipulating computation system ala the <a href=\"http://en.wikipedia.org/wiki/General_Problem_Solver\">General Problem Solver</a>&nbsp;and that the agent's body had little importance for how the the agent's cognitive algorithms manipulated those symbols. Embodied theories are correct to reject these theses, but this makes embodied theories incompatible only with the most naive forms of computationalism. The way I would put it is that the mind is computational, and we must be careful to remember that human cognition is embodied, situational, and dynamical. But this is not how Shapiro prefers to describe things.</p>\n<p>In \"<strong>Computationalism</strong>,\" <a href=\"http://www.umsl.edu/~piccininig/\">Gualtiero Piccinini</a> outlines the three research traditions of computationalism: classicism, connectionism, and computational neuroscience. He goes on to describe different kinds of computation:</p>\n<p><img src=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/types-of-computation.png\" alt=\"\" /></p>\n<p>On page 237, Piccinini says something similar to my thoughts above on Shapiro's chapter:</p>\n<blockquote>\n<p>While it is safe to say that cognition involves computation in the generic sense, and that nervous systems perform computations in the generic sense, it is much harder to establish that cognition involves a more specific kind of computation.</p>\n</blockquote>\n<p>The rest of the chapter offers a preliminary look at how the evidence might weigh for and against different kinds of computationalism about the mind.</p>\n<p>In \"<strong>Representationalism</strong>,\" <a href=\"http://philosophy.rutgers.edu/index.php?option=com_content&amp;task=view&amp;id=100&amp;Itemid=210\">Frances Egan</a> describes a specific kind of computationalism. Representationalism is \"the view that the human mind is an information-using system, and that human cognitive capacities are to be understood as representational capacities.\" The chapter discusses several kinds of representationalism, and the arguments given for and against them.</p>\n<p>In \"<strong>Artificial Intelligence</strong>,\" <a href=\"http://www.hums.canterbury.ac.nz/phil/people/proudfoot.shtml\">Diane Proudfoot</a> and <a href=\"http://www.hums.canterbury.ac.nz/phil/people/copeland.shtml\">Jack Copeland</a> focus on the quest for human-level AI. Their opening paragraph quotes Turing on the obvious achievability of AI, the whole brain emulation route (\"One way [of making AI] would be to take a man as a whole and to try to replace all the parts of him by machinery\"), and the danger of \"runaway AI.\" Section 1 discusses the Turing Test. Section 2 discusses and rejects the Chinese Room argument against Strong AI, and section 3 discusses an \"a priori\" argument <em>for</em>&nbsp;Strong AI:</p>\n<blockquote>\n<p>Given that the mind is scientifically explicable rather than a mystery, the mind is a mechanism, an information-processing machine; since the set of possible operations that can be carried out by information-processing machines is identical to the set of operations that can be carried out by the universal Turing machine... the mind must ultimately be explicable in terms of the computational properties of the UTM.</p>\n</blockquote>\n<p>Section 4 discusses Moore's law and \"the furistists\" (Moravec, Joy, Kurzweil, Bostrom, the Singularity Institute). They quote SI as <a href=\"http://intelligence.org/overview/whatisthesingularity\">saying</a>&nbsp;that \"...at the very least it should be physically possible to achieve a million-to-one speedup in thinking.\" Proudfoot &amp; Copeland reply:</p>\n<blockquote>\n<p>But... the appeal to Moore's (or other similar) projections is fallacious. These provide no reason to think that relative increases in <em>computer</em>&nbsp;speed will be matched by increases is speed of <em>thought</em>.</p>\n</blockquote>\n<p>And of course I agree. Faster computer speed only results in faster thought under certain ways of building a thought-machine. Faster computer speed only establishes the <em>possibility</em>&nbsp;for faster thought. I think faster thought is highly likely, but the argument for this conclusion is not given in the quoted article.</p>\n<p>Section 5 concerns Singularitarianism, and unfortunately associates the word only with Ray Kurzweil, and is thus rather dismissive.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zQw5d37qwzdpgQs5P": 2, "4Kcm4etxAJjmeDkHP": 2, "3uE2pXvbcnS9nnZRE": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5DkC23uEYRWb9G7A9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "12587", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T04:45:26.260Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Categorizing Has Consequences", "slug": "seq-rerun-categorizing-has-consequences", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jeYQSvHfGzFQF3Mu5/seq-rerun-categorizing-has-consequences", "pageUrlRelative": "/posts/jeYQSvHfGzFQF3Mu5/seq-rerun-categorizing-has-consequences", "linkUrl": "https://www.lesswrong.com/posts/jeYQSvHfGzFQF3Mu5/seq-rerun-categorizing-has-consequences", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Categorizing%20Has%20Consequences&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Categorizing%20Has%20Consequences%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjeYQSvHfGzFQF3Mu5%2Fseq-rerun-categorizing-has-consequences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Categorizing%20Has%20Consequences%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjeYQSvHfGzFQF3Mu5%2Fseq-rerun-categorizing-has-consequences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjeYQSvHfGzFQF3Mu5%2Fseq-rerun-categorizing-has-consequences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 200, "htmlBody": "<p>Today's post, <a href=\"/lw/nx/categorizing_has_consequences/\">Categorizing Has Consequences</a> was originally published on 19 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You see patterns where none exist, harvesting other characteristics from your definitions even when there is no similarity along that dimension. In Japan, it is thought that people of blood type A are earnest and creative, blood type Bs are wild and cheerful, blood type Os are agreeable and sociable, and blood type ABs are cool and controlled.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9o9/seq_rerun_fallacies_of_compression/\">Fallacies of Compression</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jeYQSvHfGzFQF3Mu5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.418346820134883e-07, "legacy": true, "legacyId": "12604", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["veN86cBhoe7mBxXLk", "5GiKLmWEh9z2DrdSq", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T05:13:43.030Z", "modifiedAt": null, "url": null, "title": "On Saying the Obvious", "slug": "on-saying-the-obvious", "viewCount": null, "lastCommentedAt": "2022-04-25T11:12:36.758Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Grognor", "createdAt": "2011-01-31T02:54:34.463Z", "isAdmin": false, "displayName": "Grognor"}, "userId": "LoykQRMTxJFxwwdPy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6phFYpNQH9SmWL9Jt/on-saying-the-obvious", "pageUrlRelative": "/posts/6phFYpNQH9SmWL9Jt/on-saying-the-obvious", "linkUrl": "https://www.lesswrong.com/posts/6phFYpNQH9SmWL9Jt/on-saying-the-obvious", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Saying%20the%20Obvious&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Saying%20the%20Obvious%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6phFYpNQH9SmWL9Jt%2Fon-saying-the-obvious%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Saying%20the%20Obvious%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6phFYpNQH9SmWL9Jt%2Fon-saying-the-obvious", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6phFYpNQH9SmWL9Jt%2Fon-saying-the-obvious", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 488, "htmlBody": "<p>Related to: <a href=\"/lw/dr/generalizing_from_one_example/\">Generalizing from One Example</a>, <a href=\"/r/discussion/lw/8ib/connecting_your_beliefs_a_call_for_help/\">Connecting Your Beliefs (a call for help)</a>, <a href=\"/lw/ht/beware_the_unsurprised/\">Beware the Unsurprised</a></p>\n<p>The idea of this article is something I've talked about a couple of times in <a href=\"/lw/9em/open_thread_january_1531_2012/5odf\">comments</a>. It seems to require more attention.</p>\n<p>As a general rule, what is obvious to some people may not be obvious to others. Is this obvious to you? Maybe it was. Maybe it wasn't, and you thought it was because of <a href=\"http://wiki.lesswrong.com/wiki/Hindsight_bias\">hindsight bias</a>.</p>\n<p>Imagine a substantive Less Wrong comment. It's insightful, polite, easy to understand, and otherwise good. Ideally, you upvote this comment. Now imagine the same comment, only with \"obviously\" in front. This shouldn't change much, but it does. This word seems to change the comment in multifarious bad ways that I'd rather not try to list.</p>\n<p>Uncharitably, I might reduce this whole phenomenon to an example of a <a href=\"http://wiki.lesswrong.com/wiki/Mind_projection_fallacy\">mind projection fallacy</a>. The implicit deduction goes like this: \"I found &lt;concept&gt; obvious. Thus, &lt;concept&gt; is inherently obvious.\" The problem is that obviousness, <a href=\"/lw/oj/probability_is_in_the_mind/\">like probability</a>, is in the mind.</p>\n<p>The stigma of \"obvious\" ideas has another problem in preventing things from being said at all. I don't know how common this is, but I've actually been <em>afraid</em> of saying things that I thought were obvious, even though ignoring this fear and just posting has yet to result in a poorly-received comment. (That is, in fact, why I'm writing this.)</p>\n<p>Even tautologies, which are always obvious in retrospect, can be hard to spot. How many of us would have explicitly realized the weak anthropic principle without Nick Bostrom's help?</p>\n<p>And what about implications of beliefs you already hold? These <em>should</em> be obvious, and <em>sometimes</em> are, but our brains are notoriously bad at putting two and two together. Luke's <a href=\"/r/discussion/lw/8ib/connecting_your_beliefs_a_call_for_help\">example</a> was not realizing that an intelligence explosion was imminent until he read the I.J. Good <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Good-Speculations-Concerning-the-First-Ultraintelligent-Machine.pdf\">paragraph</a>. I'm glad he provided that example, as it has saved me the trouble of making one.</p>\n<p>This is not (to <a href=\"/lw/1b8/anticipation_vs_faith_at_what_cost_rationality/16es\">paraphrase</a> Eliezer) a thunderbolt of insight. I bring it up because I propose a few community norms based on the idea:</p>\n<ul>\n<li>Don't be afraid of saying something because it's \"obvious\". It's like how your teachers always said there are no stupid questions.</li>\n<li>Don't burden your awesome ideas with \"<a href=\"/lw/8q8/urges_vs_goals_the_analogy_to_anticipation_and/5qrd\">obvious but it needs to be said</a>\".</li>\n<li>Don't vote down a comment because it says something \"obvious\" unless you've thought about it for a while. Also, don't shun \"obvious\" ideas.</li>\n<li>Don't call an idea obvious as though obviousness were an inherent property of the idea. Framing it as a personally obvious thing can be a more accurate way of saying what you're trying to say, but it's hard to do this without looking arrogant. (I suspect this is actually one of the reasons we implicitly treat obviousness as impersonal.)</li>\n</ul>\n<p>I'm not sure if these are good ideas, but I think implementing them would decrease the volume of <a href=\"http://yudkowsky.net/rational/virtues\">thoughts we cannot think</a> and <a href=\"http://www.paulgraham.com/say.html\">things we can't say</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "WPkEd3et8f488w8LT": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6phFYpNQH9SmWL9Jt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 104, "baseScore": 146, "extendedScore": null, "score": 0.000296, "legacy": true, "legacyId": "12605", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 146, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["baTWMegR42PAsH9qJ", "kHL6qX9eArmvNWY99", "jyDBcs3Rx8t5Fhquo", "f6ZLxEWaankRZ2Crv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 17, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T12:33:02.181Z", "modifiedAt": null, "url": null, "title": "Looking for information on cryonics", "slug": "looking-for-information-on-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.809Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Metus", "createdAt": "2011-01-23T21:54:34.357Z", "isAdmin": false, "displayName": "Metus"}, "userId": "mNQ4fSvro7LYgrii4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PSAXy3QfJoaJKFfiS/looking-for-information-on-cryonics", "pageUrlRelative": "/posts/PSAXy3QfJoaJKFfiS/looking-for-information-on-cryonics", "linkUrl": "https://www.lesswrong.com/posts/PSAXy3QfJoaJKFfiS/looking-for-information-on-cryonics", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Looking%20for%20information%20on%20cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALooking%20for%20information%20on%20cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPSAXy3QfJoaJKFfiS%2Flooking-for-information-on-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Looking%20for%20information%20on%20cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPSAXy3QfJoaJKFfiS%2Flooking-for-information-on-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPSAXy3QfJoaJKFfiS%2Flooking-for-information-on-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 258, "htmlBody": "<h6>Disclaimer: English is a foreign language for me. If you find any mistakes please inform me.</h6>\n<p>I am currently looking for information on cryonics since I have the intention to sign up. My current organization of choice is the Cryonics Institute with their one-time fee of $1,250 at sign-up and $28,000 for cryo-preservation which is an excellent offer given my age. I understand that most people choose to pay for cryopreservation by life-insurance. Since the cost of cryopreservation is lower than the &euro;30,000 most insurers here in Germany take as minimum payout I still would have money left and wonder if I could put this money in some kind of trust to pay for \"revival\" and have some money in that future. Do any of you have plans like that and could share their information?</p>\n<p>Also, do I understand correctly that the $28,000 at the Cryonics Institute are for cryopreservation only and that $88,000 figure is for cryopreservation, standby and transport to Michigan? In that case I of course need to get life insurance with higher pay-out but at my age that should not be a problem.</p>\n<p>Are there any other institutes that offer cryopreservation of at least the brain that I should consider? I know of Alcor (expensive, I do not see the benefits) and KryoRus (seems cheap and require continuous funding that could be handled by a trust fund). Are there more I should know of?</p>\n<p>If you have ideas, information I should consider or question I need to have answered, please feel free to reply in the comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZnHkaTkxukegSrZqE": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PSAXy3QfJoaJKFfiS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 23, "extendedScore": null, "score": 8.420158459557574e-07, "legacy": true, "legacyId": "12625", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T18:10:06.463Z", "modifiedAt": null, "url": null, "title": "Teaching rationality made me better (at research and other things)", "slug": "teaching-rationality-made-me-better-at-research-and-other", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:53.427Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Academian", "createdAt": "2010-03-08T09:49:25.099Z", "isAdmin": false, "displayName": "Academian"}, "userId": "AbLN9sR8PDACCXKp7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KhctbCX7enfn7EHM2/teaching-rationality-made-me-better-at-research-and-other", "pageUrlRelative": "/posts/KhctbCX7enfn7EHM2/teaching-rationality-made-me-better-at-research-and-other", "linkUrl": "https://www.lesswrong.com/posts/KhctbCX7enfn7EHM2/teaching-rationality-made-me-better-at-research-and-other", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Teaching%20rationality%20made%20me%20better%20(at%20research%20and%20other%20things)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATeaching%20rationality%20made%20me%20better%20(at%20research%20and%20other%20things)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKhctbCX7enfn7EHM2%2Fteaching-rationality-made-me-better-at-research-and-other%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Teaching%20rationality%20made%20me%20better%20(at%20research%20and%20other%20things)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKhctbCX7enfn7EHM2%2Fteaching-rationality-made-me-better-at-research-and-other", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKhctbCX7enfn7EHM2%2Fteaching-rationality-made-me-better-at-research-and-other", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<p>Hi all,</p>\n<p>I just wanted to loudly recommend the <a href=\"/lw/9hb/position_design_and_write_rationality_curriculum/\">position to design and write rationality curriculum</a>&nbsp;--- to anyone who is interested --- as a potential way to make yourself more awesome. &nbsp;After helping teach mini-camp last year, I definitely experienced a huge increase in motivation for my own research, and in turn, productivity.&nbsp; Somehow, giving serious thought to rationality advice for a large group and *actually delivering it* made be internalize <em>even more deeply</em> some things I thought I'd already absorbed completely.&nbsp;</p>\n<p>... and my <a href=\"/lw/2c/a_sense_that_more_is_possible/\">sense that more is possible</a> is still tingling :)</p>\n<p>So yeah, definitely give it a shot if you think you might be good at it!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KhctbCX7enfn7EHM2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 8.421464820598713e-07, "legacy": true, "legacyId": "12627", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ifL8f4Xzy2D9Bb6zs", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T18:13:08.743Z", "modifiedAt": null, "url": null, "title": "Two Kinds of Irrationality and How to Avoid One of Them", "slug": "two-kinds-of-irrationality-and-how-to-avoid-one-of-them", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:58.794Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ChrisHallquist", "createdAt": "2011-05-25T19:16:15.462Z", "isAdmin": false, "displayName": "ChrisHallquist"}, "userId": "wvT2xWQqHKxkp9NWN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B3RGZg4KNdsaDC2J4/two-kinds-of-irrationality-and-how-to-avoid-one-of-them", "pageUrlRelative": "/posts/B3RGZg4KNdsaDC2J4/two-kinds-of-irrationality-and-how-to-avoid-one-of-them", "linkUrl": "https://www.lesswrong.com/posts/B3RGZg4KNdsaDC2J4/two-kinds-of-irrationality-and-how-to-avoid-one-of-them", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Two%20Kinds%20of%20Irrationality%20and%20How%20to%20Avoid%20One%20of%20Them&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATwo%20Kinds%20of%20Irrationality%20and%20How%20to%20Avoid%20One%20of%20Them%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB3RGZg4KNdsaDC2J4%2Ftwo-kinds-of-irrationality-and-how-to-avoid-one-of-them%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Two%20Kinds%20of%20Irrationality%20and%20How%20to%20Avoid%20One%20of%20Them%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB3RGZg4KNdsaDC2J4%2Ftwo-kinds-of-irrationality-and-how-to-avoid-one-of-them", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB3RGZg4KNdsaDC2J4%2Ftwo-kinds-of-irrationality-and-how-to-avoid-one-of-them", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1290, "htmlBody": "<p>It seems to me that there are two kinds of human irrationality. One could be called \"bug\" irrationality, not referring to insects but rather bugs in the design of our minds, ways in which our minds could be better designed. This category includes things like <a href=\"http://en.wikipedia.org/wiki/Hyperbolic_discounting\">hyperbolic discounting</a> (also called myopic discounting), as well as general failures to correctly apply laws of logic and probability. It's often worth making an effort to correct for this kind of irrationality, but I think some of the discussion of it is overly pessimistic. From an evolutionary point of view, the main reason that this kind of irrationality exists is probably just that flawed rules of thumb which usually work out okay can be more efficient than more rigorous methods.</p>\n<p>As <a href=\"/lw/9p/extreme_rationality_its_not_that_great/\">Yvain</a> once wrote, \"most people are rational enough for their own purposes.\" Because of that, I don't think this kind of rationality is our biggest worry, and it's not what this post is about. But if you want to do much more reading on the view of this side of irrationality that I've just sketched, I recommend reading various papers by psychologist Ricard Samuels and philosopher Stephen Stich, such as <a href=\"http://sas-space.sas.ac.uk/938/1/R_Samuels_Rationality.pdf\">Ending the Rationality Wars</a>, <a href=\"http://sas-space.sas.ac.uk/940/1/R_Samuels_Psychology.pdf\">Rationality &amp; Psychology</a>, and <a href=\"http://sas-space.sas.ac.uk/941/1/R_Samuels_Reason.pdf\">Reason and Rationality</a>.</p>\n<p>The worst examples of human irrationality, in my view, are what could be called \"feature\" irrationality. Meaning, when irrationality is a feature of our mind, something evolution designed into our minds. Why would evolution do this? Here is Stephen Pinker's explanation from <a href=\"http://www.amazon.com/How-Mind-Works-Steven-Pinker/dp/0393334775/ref=sr_1_1?ie=UTF8&amp;qid=1326574541&amp;sr=8-1\"><em>How the Mind Works</em></a>:</p>\n<blockquote>\n<p>[Psychologist Robert] Trivers, pursuing his theory of the emotions to its logical conclusion, notes that in a world of walking lie detectors the best strategy is to believe your own lies...</p>\n<p>Everyone has heard of \"reducing cognitive dissonance,\" in which people invent a new opinion to resolve a contradiction in their minds. For example, a person will recall enjoying a boring task if he had agreed to recommend it to others for paltry pay... As originally conceived of by the psychologist Leon Festinger, cognitive dissonance is an unsettled feeling that arises from an inconsistency in one's beliefs. But that's not right: there is no contradiction between the proposition \"The task is boring\" and the proposition \"I was pressured into lying that the task was fun.\" Another social psychologist, Eliot Aronson, nailed it down: people doctor their beliefs only to eliminate contradiction with the proposition \"I am nice and in control.\" Cognitive dissonance is always triggered by blatant evidence that you are not as beneficent and effective as you would like people to think. The urge to reduce it is the urge to get your self-serving story straight (pp. 421-423).</p>\n</blockquote>\n<p>In other words, we have evolved to have an irrationally inflated view of ourselves, so as to better sell others on that view. I can think of one other important advantage of irrationality as a feature: coalition building. A coalition may be strengthened by a belief in its own righteousness and the wickedness of its enemies, and group members can signal loyalty by adopting an ideological shibboleths that group members share.</p>\n<p>The tragedy of feature-irrationality is that (unsurprisingly, on Darwinian grounds) its costs tend to be borne by other people. Throughout history, many people have believed that martyrs receive rewards in paradise far exceeding any earthly rewards, but only a very few of those people actually become martyrs. Thus, the harm done in practice by that belief about martyrs is relatively small. Much greater harm has been done by the belief that unbelief leads to eternal damnation, and therefore unbelievers should be tortured and killed, both to punish and discourage unbelief.</p>\n<p>But my purpose here isn't to rail against the evils of this kind of irrationality. Rather, my purpose is to suggest a relatively simple method for avoiding the worst of human irrationality. The core idea is one articulated by <a href=\"/r/lesswrong/lw/816/when_romance_can_go_horribly_wrong/\">eugman</a>:</p>\n<blockquote>\n<p>Watch out for when you are sacrificing epistemology for instrumental gains. If there is ever a time where you want to have certain beliefs because it more convenient and you are trying to talk yourself into them, that is a giant red flag.</p>\n</blockquote>\n<p>Since feature-irrationality is all about sacrificing truth for the sake of instrumental gains, being aware of when you're doing that is the very essence of combating it. And since the instrumental gains are usually in terms of other people's view of us, we can be more specific: \"When you're trying to figure out what to believe, you can't care what other people will think of you.\"</p>\n<p>There are a couple of misunderstandings that need to be avoided here. First, the rule is to not care about what other people will think <em>of you, </em>not not care about what other people think in general. In fact, when you're trying to figure out what to think about X, it's generally important to take into account what other well-informed people think about X. If you know that 99% of the experts think that <em>p, </em>you'd be wise to be very, very cautious about concluding <em>not-p. </em>But it's important to do this for the right reason. The right reason is that other people might know or understand something you don't. It would still be a mistake to be swayed by fears that high-status people will think less of you if you disagree with them.</p>\n<p>Furthermore, you have to really not care what other people will think of you. It does nothing--and can even be counterproductive--to merely make a show of indifference. When someone makes a show of indifference to others' opinions of them, it's often a sign they care intensely about what other people think. Pinker observes, \"The physicist Richard Feynman wrote two books describing how brilliant, irreverent, and admired he was and called one of them <em>What Do You Care What Other People Think?\" </em>(Pinker, p. 361) Going too far in not caring what other people think can be a kind of <a href=\"http://en.wikipedia.org/wiki/Countersignaling\">countersignaling</a> or even, in extreme cases, what art historian Quentin Bell called \"conspicuous outrage.\"</p>\n<p>So in order to follow the rule \"When you're trying to figure out what to believe, you can't care what other people will think of you,\" you can't worry that you'll lose status for advocating an unpopular idea, but you also can't get too excited about being an intellectual rebel or <a href=\"/lw/2pv/intellectual_hipsters_and_metacontrarianism/\">contrarian</a>.</p>\n<p>Had I followed this principle, I might have managed to avoid at least a couple of the more embarrassing mistakes I've made in my life. Here's one of them: I started off in college planning on going to medical school, which was <a href=\"/r/lesswrong/lw/8gv/the_curse_of_identity/5a0t\">not a good idea</a>. Once I got sufficiently tired of my biology classes, I looked around to see what I could do with my life, and noticed I was doing really well in my philosophy classes. So an obvious choice (or so it seemed to me) was going to graduate school in philosophy.</p>\n<p>However, there was a problem: my initial contact with philosophy left me with a somewhat dim view of the field, or at least a dim view of academic philosophy. So I resisted the idea of going to graduate school in philosophy for a long time. But eventually, seeing no other options (according to my peculiar, upper-middle class notions about what constituted an \"option\") I gave in. Once I'd resigned myself to going to graduate school in philosophy, I began to worry about how I would justify my choice to others, and began thinking nicer thoughts about philosophy.</p>\n<p>When I ultimately left my Ph.D. program after three semesters, it took awhile to adjust to realizing how foolish I'd been. I could have saved myself a lot of time if I'd stopped and noticed, \"no, you don't actually think this is a great idea, you're just trying to imagine how you'll justify this decision to other people.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "LDTSbmXtokYAsEq8e": 1, "9YFoDPFwMoWthzgkY": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B3RGZg4KNdsaDC2J4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 30, "extendedScore": null, "score": 7.8e-05, "legacy": true, "legacyId": "12175", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LgavAYtzFQZKg95WC", "6QqxKT4yyH6dGLWXA", "9kcTNWopvXFncXgPy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T18:58:54.021Z", "modifiedAt": null, "url": null, "title": "Knowledge ready for Ankification", "slug": "knowledge-ready-for-ankification", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:04.406Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fhDCYs6d4CgL8DiGe/knowledge-ready-for-ankification", "pageUrlRelative": "/posts/fhDCYs6d4CgL8DiGe/knowledge-ready-for-ankification", "linkUrl": "https://www.lesswrong.com/posts/fhDCYs6d4CgL8DiGe/knowledge-ready-for-ankification", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Knowledge%20ready%20for%20Ankification&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKnowledge%20ready%20for%20Ankification%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfhDCYs6d4CgL8DiGe%2Fknowledge-ready-for-ankification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Knowledge%20ready%20for%20Ankification%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfhDCYs6d4CgL8DiGe%2Fknowledge-ready-for-ankification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfhDCYs6d4CgL8DiGe%2Fknowledge-ready-for-ankification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 110, "htmlBody": "<p><a href=\"http://www.gwern.net/Spaced%20repetition\">Spaced repetition</a> is a powerful learning tactic, and <a href=\"http://ankisrs.net/\">Anki</a> is a good tool for it. There are some LW-relevant Anki decks <a href=\"http://wiki.lesswrong.com/wiki/Spaced_repetition#SR_decks\">here</a>. But I wish there were more.</p>\n<p>Which sets of knowledge are (1) likely useful to LWers, and (2) straightforward to encode into Anki decks without needing to be familiar with that field?</p>\n<p>Some examples:</p>\n<ol>\n<li>Purves et al.'s <a href=\"http://www.sinauer.com/cogneuro/glossary.html\">glossary of cognitive neuroscience</a> (preferably including a brain-image for each brain <em>anatomy</em> term).</li>\n<li>The meaning of each&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Category:Concepts\">concept</a>&nbsp;in the LW wiki.</li>\n<li>The meaning of each bolded term in <em><a href=\"http://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597/\">AIMA</a></em>.</li>\n</ol>\n<p>Which other sets of knowledge would you like to see Ankified? Please <strong>link to the actual knowledge set</strong> you'd like to see encoded.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"H2q58pKG6xFrv8bPz": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fhDCYs6d4CgL8DiGe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 22, "extendedScore": null, "score": 8.421653951978187e-07, "legacy": true, "legacyId": "12628", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T19:06:59.539Z", "modifiedAt": null, "url": null, "title": "What math should I learn?", "slug": "what-math-should-i-learn", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:08.696Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Metus", "createdAt": "2011-01-23T21:54:34.357Z", "isAdmin": false, "displayName": "Metus"}, "userId": "mNQ4fSvro7LYgrii4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xFR9oLzxCfeRYGf9Y/what-math-should-i-learn", "pageUrlRelative": "/posts/xFR9oLzxCfeRYGf9Y/what-math-should-i-learn", "linkUrl": "https://www.lesswrong.com/posts/xFR9oLzxCfeRYGf9Y/what-math-should-i-learn", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20math%20should%20I%20learn%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20math%20should%20I%20learn%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxFR9oLzxCfeRYGf9Y%2Fwhat-math-should-i-learn%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20math%20should%20I%20learn%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxFR9oLzxCfeRYGf9Y%2Fwhat-math-should-i-learn", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxFR9oLzxCfeRYGf9Y%2Fwhat-math-should-i-learn", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 52, "htmlBody": "<p>I am studying physics and like math. I just finished courses in mathematical logic and probality theory and attended courses in calculus and linear algebra. I intend to learn theoretical informatics next semester. Any more suggestions for interesting mathematics? I started algebra this semester but dropped it because of my other commitments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xFR9oLzxCfeRYGf9Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 8.421685318970595e-07, "legacy": true, "legacyId": "12626", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T20:35:23.304Z", "modifiedAt": null, "url": null, "title": "Elevator pitches/responses for rationality / AI", "slug": "elevator-pitches-responses-for-rationality-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:21.366Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aG6h9BSgqcC3hcyQC/elevator-pitches-responses-for-rationality-ai", "pageUrlRelative": "/posts/aG6h9BSgqcC3hcyQC/elevator-pitches-responses-for-rationality-ai", "linkUrl": "https://www.lesswrong.com/posts/aG6h9BSgqcC3hcyQC/elevator-pitches-responses-for-rationality-ai", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Elevator%20pitches%2Fresponses%20for%20rationality%20%2F%20AI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AElevator%20pitches%2Fresponses%20for%20rationality%20%2F%20AI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaG6h9BSgqcC3hcyQC%2Felevator-pitches-responses-for-rationality-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Elevator%20pitches%2Fresponses%20for%20rationality%20%2F%20AI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaG6h9BSgqcC3hcyQC%2Felevator-pitches-responses-for-rationality-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaG6h9BSgqcC3hcyQC%2Felevator-pitches-responses-for-rationality-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 498, "htmlBody": "<p>I'm trying to develop a large set of elevator pitches / elevator responses for the two major topics of LW: rationality and AI.</p>\n<p>An elevator pitch lasts 20-60 seconds, and is not necessarily prompted by anything, or at most is prompted by something very vague like \"So, I heard you talking about 'rationality'. What's that about?\"</p>\n<p>An elevator response is a 20-60 second, highly optimized response to a commonly heard sentence or idea, for example, \"Science doesn't know everything.\"</p>\n<p>&nbsp;</p>\n<p>Examples (but I hope you can improve upon them):</p>\n<p>&nbsp;</p>\n<p>\"So, I hear you care about rationality. What's that about?\"</p>\n<blockquote>\n<p>Well, we all have beliefs about the world, and we use those beliefs to make decisions that we think will bring us the most of what we want. What most people don't realize is that there is a mathematically optimal way to update your beliefs in response to evidence, and a mathematically optimal way to figure out which decision is most likely to bring you the most of what you want, and these methods are defined by probability theory and decision theory. Moreover, cognitive science has discovered a long list of predictable mistakes our brains make when forming beliefs and making decisions, and there are particular things we can do to improve our beliefs and decisions. [This is the abstract version; probably better to open with a concrete and vivid example.]</p>\n</blockquote>\n<p>\"Science doesn't know everything.\"</p>\n<blockquote>\n<p>As the comedian Dara O'Briain once said, science <em>knows</em>&nbsp;it doesn't know everything, or else it'd <em>stop</em>. But just because science doesn't know everything doesn't mean you can use whatever theory most appeals to you. <em>Anybody</em> can do that, and use whatever crazy theory they want.</p>\n</blockquote>\n<p>\"But you can't expect people to act rationally. We are emotional creatures.\"</p>\n<blockquote>\n<p>But of course. Expecting people to be rational is irrational. If you expect people to usually be rational, you're ignoring an enormous amount of evidence about how humans work.</p>\n</blockquote>\n<p>\"But sometimes you can't wait until you have all the information you need. Sometimes you need to act right away.\"</p>\n<blockquote>\n<p>But of course. You have to weigh the cost of new information with the expected value of that new information. Sometimes it's best to just act on the best of what you know right now.</p>\n</blockquote>\n<p>\"But we <em>have</em>&nbsp;to use intuition sometimes. And sometimes, my intuitions are pretty good!\"</p>\n<blockquote>\n<p>But of course. We even have lots of data on which situations are conducive to intuitive judgment, and which ones are not. And sometimes, it's rational to use your intuition because it's the best you've got and you don't have time to write out a bunch of probability calculations.</p>\n</blockquote>\n<p>\"But I'm not sure an AI can ever be conscious.\"</p>\n<blockquote>\n<p>That won't keep it from being \"intelligent\" in the sense of being very good at optimizing the world according to its preferences. A chess computer is great at optimizing the chess board according to its preferences, and it doesn't need to be conscious to do so.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Please post your own elevator pitches and responses in the comments, and vote for your favorites!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aG6h9BSgqcC3hcyQC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 24, "extendedScore": null, "score": 8.422027983926262e-07, "legacy": true, "legacyId": "12629", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 69, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-02T22:29:56.587Z", "modifiedAt": null, "url": null, "title": "Question on math in \"A Technical Explanation of Technical Explanation\"", "slug": "question-on-math-in-a-technical-explanation-of-technical", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:52.735Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mark_Eichenlaub", "createdAt": "2010-09-01T17:59:32.486Z", "isAdmin": false, "displayName": "Mark_Eichenlaub"}, "userId": "6mdGZLDekk4835gM6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3qdAtPmyi8MeWNGhP/question-on-math-in-a-technical-explanation-of-technical", "pageUrlRelative": "/posts/3qdAtPmyi8MeWNGhP/question-on-math-in-a-technical-explanation-of-technical", "linkUrl": "https://www.lesswrong.com/posts/3qdAtPmyi8MeWNGhP/question-on-math-in-a-technical-explanation-of-technical", "postedAtFormatted": "Thursday, February 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Question%20on%20math%20in%20%22A%20Technical%20Explanation%20of%20Technical%20Explanation%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuestion%20on%20math%20in%20%22A%20Technical%20Explanation%20of%20Technical%20Explanation%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3qdAtPmyi8MeWNGhP%2Fquestion-on-math-in-a-technical-explanation-of-technical%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Question%20on%20math%20in%20%22A%20Technical%20Explanation%20of%20Technical%20Explanation%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3qdAtPmyi8MeWNGhP%2Fquestion-on-math-in-a-technical-explanation-of-technical", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3qdAtPmyi8MeWNGhP%2Fquestion-on-math-in-a-technical-explanation-of-technical", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p>\"A Technical Explanation of Technical Explanation\" (<a href=\"http://yudkowsky.net/rational/technical\">http://yudkowsky.net/rational/technical</a>) defines a proper rule for a betting game as one where the payoff is maximized by betting an amount proportional to the probability of success.</p>\n<p>&nbsp;</p>\n<p>The first example rule given is that the payoff is one minus the negative of the squared error, so for example if you make a bet of .3 on the winner, your payoff is 1-(1-.3)^2 = .51.&nbsp;</p>\n<p>&nbsp;</p>\n<p>This doesn't seem like a good example. It works if there are only two options, but I don't think it works if there are three or more. For example, we imagine P(red) = .5, P(blue) = .2, P(green) = .3. &nbsp;If we place bets of .5, .2, and .3 respectively, the expected return I get is .6. (<strong>edit</strong>: Fixed a mistake pointed out by Douglas Knight.)</p>\n<p>&nbsp;</p>\n<p>However, if I place bets of .51, .19, .3 the expected return is .60173. I have that the condition for maximization is</p>\n<p>&nbsp;</p>\n<p>(1-R)P(R) = (1-B)P(B) = (1-G)P(G),</p>\n<p>&nbsp;</p>\n<p>which I got by taking partial derivatives of the expectation and setting them equal. (\"R\" stands for the bet placed on red and \"P(R)\" for the probability of red, etc.) This is different than simply R=P(R), etc.</p>\n<p>&nbsp;</p>\n<p>So does the article have a mistake, or do I, or did I miss part of the context?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3qdAtPmyi8MeWNGhP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 8.422472088813475e-07, "legacy": true, "legacyId": "12630", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-03T01:28:37.168Z", "modifiedAt": null, "url": null, "title": "What will rationality look like in the future?", "slug": "what-will-rationality-look-like-in-the-future", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.393Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HQRoG2BC3benPrtnC/what-will-rationality-look-like-in-the-future", "pageUrlRelative": "/posts/HQRoG2BC3benPrtnC/what-will-rationality-look-like-in-the-future", "linkUrl": "https://www.lesswrong.com/posts/HQRoG2BC3benPrtnC/what-will-rationality-look-like-in-the-future", "postedAtFormatted": "Friday, February 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20will%20rationality%20look%20like%20in%20the%20future%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20will%20rationality%20look%20like%20in%20the%20future%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQRoG2BC3benPrtnC%2Fwhat-will-rationality-look-like-in-the-future%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20will%20rationality%20look%20like%20in%20the%20future%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQRoG2BC3benPrtnC%2Fwhat-will-rationality-look-like-in-the-future", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQRoG2BC3benPrtnC%2Fwhat-will-rationality-look-like-in-the-future", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<p>One of the standard methods of science-fiction world-building is to take a current trend and extrapolate it into the future, and see what comes out. One trend I've observed is that over the last century or so, people have kept coming up with clever new ways to find answers to important questions - that is, developing new methods of rationality.</p>\n<p>&nbsp;</p>\n<p>So, given what we do currently know about the overall shape of such methods, from Godel's Incompleteness Theory to Kolmogorov Complexity to the various ways to get around Prisoner's Dilemmas... Then, at least in a general science-fictional world-building sense, what might we be able to guess or say about what rationalists will be like in, oh, 50-100 years?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HQRoG2BC3benPrtnC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "12643", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-03T01:59:56.996Z", "modifiedAt": null, "url": null, "title": "One last roll of the dice", "slug": "one-last-roll-of-the-dice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:30.645Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mitchell_Porter", "createdAt": "2009-05-28T02:36:19.394Z", "isAdmin": false, "displayName": "Mitchell_Porter"}, "userId": "fjERoRhgjipqw3z2b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qkFkg46Jw3LurFyaj/one-last-roll-of-the-dice", "pageUrlRelative": "/posts/qkFkg46Jw3LurFyaj/one-last-roll-of-the-dice", "linkUrl": "https://www.lesswrong.com/posts/qkFkg46Jw3LurFyaj/one-last-roll-of-the-dice", "postedAtFormatted": "Friday, February 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20One%20last%20roll%20of%20the%20dice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOne%20last%20roll%20of%20the%20dice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqkFkg46Jw3LurFyaj%2Fone-last-roll-of-the-dice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=One%20last%20roll%20of%20the%20dice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqkFkg46Jw3LurFyaj%2Fone-last-roll-of-the-dice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqkFkg46Jw3LurFyaj%2Fone-last-roll-of-the-dice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1335, "htmlBody": "<p><em>Previous articles: <a href=\"/lw/9mw/personal_research_update/\">Personal research update</a>, <a href=\"/lw/9o8/does_functionalism_imply_dualism/\">Does functionalism imply dualism?</a>, <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/\">State your physical account of experienced color</a>. </em></p>\n<p>&nbsp;</p>\n<p>In phenomenology, there is a name for the world of experience, the \"lifeworld\". The lifeworld is the place where you exist, where time flows, and where things are actually green. One of the themes of the later work of Edmund Husserl is that a scientific image of the real world has been constructed, on the basis of which it is denied that various phenomena of the lifeworld exist anywhere, at any level of reality.</p>\n<p>When I asked, <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/\">in the previous post</a>, for a few opinions about what color is and how it relates to the world according to current science, I was trying to gauge just how bad the eclipse of the lifeworld by theoretical conceptions is, among the readers of this site. I'd say there is a problem, but it's a problem that might be solved by patient discussion.</p>\n<p>Someone called Automaton has given us <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t3d\">a clear statement of the extreme position</a>: nothing is actually green at any level of reality; even green experiences don't involve the existence of anything that is actually green; there is no green in reality, there is only \"experience of green\" which is not itself green. I see other responses which are just a step or two away from this extreme, but they don't deny the existence of actual color with that degree of unambiguity.</p>\n<p>A few people talk about wavelengths of light, but I doubt that they want to assert that the light in question, as it traverses space, is actually colored green. Which returns us to the dilemma: either \"experiences\" exist and part of them is actually green, or you have to say that nothing exists, in any sense, at any level of reality, that is actually green. Either the lifeworld exists somewhere in reality, or you must assert, as does the philosopher quoted by Automaton, that all that exists are brain processes and words. Your color sensations aren't really there, you're \"having a sensation\" without there <em>being</em> a sensation in reality.</p>\n<p>What about the other responses? kilobug <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t3p\">seems to think</a> that pi actually exists inside a computer calculating the digits of pi, and that this isn't dualist. Manfred <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t3g\">thinks</a> that \"keeping definitions and referents distinct\" would somehow answer the question of where in reality the actual shades of green are. drethelin <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t3b\">says</a> \"The universe does not work how it feels to us it works\" without explaining in physical terms what these feelings about reality are, and whether any of them is actually green. pedanterrific <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t3n\">asks</a> why wrangle about color rather than some other property (the answer is that the case of color makes this sort of problem as obvious as it ever gets). RomeoStevens <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t2v\">suggests</a> I look into Jeff Hawkins. Hawkins mentions qualia once in his book \"On Intelligence\", where he speculates about what sort of neural encoding might be the physical correlate of a color experience; but he doesn't say how or whether anything manages to be actually colored.</p>\n<p>amcknight <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t3s\">asks</a> which of 9 theories of color listed in <a href=\"http://plato.stanford.edu/entries/color/\">the SEP article on that subject</a> I'm talking about. If you go a few paragraphs back from the list of 9 theories, you will see references to \"color as it is in experience\" or \"color as a subjective quality\". That's the type of color I'm talking about. The 9 theories are all ways of talking about \"color as in physical objects\", and focus on the properties of the external stimuli which cause a color sensation. The article gets around to talking about actual color, subjective or \"phenomenal\" color, only at the end.</p>\n<p>Richard Kennaway <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t40\">comes closest</a> to my position; he calls it an apparently impossible situation which we are actually living. I wouldn't put it quite like that; the only reason to call it impossible is if you are completely invested in an ontology lacking the so-called secondary qualities; if you aren't, it's just a problem to solve, not a paradox. But Richard comes closest (though who knows what <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t39\">Will Newsome</a> is thinking). LW user \"scientism\" <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5t4i\">bites a different bullet</a> to the eliminativists, and says colors are real and are properties of the external objects. That gets a point for realism, but it doesn't explain color in a dream or a hallucination.</p>\n<p>Changing people's minds on this subject is an uphill battle, but people here are willing to talk, and most of these subjects have already been discussed for decades. There's ample opportunity to dissolve, not the problem, but the false solutions which only obscure the real problem, by drawing on the work of others; preferably before the future Rationality Institute starts mass-producing people who have the vice of quale-blindness as well as the virtues of rationality. Some of those people will go on to work on Friendly AI. So it's highly desirable that someone should do this. However, that would require time that I no longer have.</p>\n<p>&nbsp;</p>\n<p>In this series of posts, I certainly didn't set out to focus on the issue of color. The first post is all about Friendly AI, the ontology of consciousness, and a hypothetical future discipline of quantum neurobiology. It may still be unclear why I think evidence for quantum computing in the brain could help with the ontological problems of consciousness. I feel that the brief discussion this week has produced some minor progress in explaining myself, which needs to be consolidated into something better. But see my remarks <a href=\"/r/discussion/lw/9pc/state_your_physical_account_of_experienced_color/5tah\">here</a> about being able to collapse the dualistic distinction between mental and physical ontology in a tensor network ontology; also earlier remarks <a href=\"/lw/9o8/does_functionalism_imply_dualism/5suz\">here</a> about about mathematically representing the phenomenological ontology of consciousness. I don't consider myself dogmatic about what the answer is, just about the inadequacy of all existing solutions, though I respect my own ideas enough to want to pursue them, and to believe that doing so will be usefully instructive, even if they are wrong.</p>\n<p>However, my time is up. In real life, my ability to continue even at this inadequate level hangs by a thread. I don't mean that I'm suicidal, I mean that I can't eat air. I spent a year getting to <a href=\"/lw/9mw/personal_research_update/5stv\">this level in physics</a>, so I could perform this task. I have considerable momentum now, but it will go to waste unless I can keep going for a little longer - a few weeks, maybe a few months. That should be enough time to write something up that contains a result of genuine substance, and/or enough time to secure an economic basis for my existence in real life that permits me to keep going. I won't go into detail here about how slim my resources really are, or how adverse my conditions, but it has been the effort that you would want from someone who has important contributions to make, and nowhere to turn for direct assistance.[*] I've done what I can, these posts are the end of it, and the next few days will decide whether I can keep going, or whether I have to shut down my brain once again.</p>\n<p>So, one final remark. Asking for donations doesn't seem to work yet. So what if I promise to pay you back? Then the only cost you bear is the opportunity cost and the slight risk of default. Ten years ago, Eliezer lent me the airfare to Atlanta for a few days of brainstorming. It took a while, but he did get that money back. I honor my commitments and this one is highly public. This really is the biggest bargain in existential risk mitigation and conceptual boundary-breaking that you'll <em>ever</em> get: not even a gift, just a loan is required. If you want to discuss a deal, don't do it here, but mail me at mitchtemporarily@hotmail.com. One person might be enough to make the difference.</p>\n<p>[*]Really, I can't say that, that's an emotional statement. There has been lots of assistance, large and small, from people in my life. But it's been a struggle conducted at subsistence level the whole way.</p>\n<p>&nbsp;</p>\n<p><strong>ETA</strong> 6 Feb: <a href=\"/lw/9rb/one_last_roll_of_the_dice/5u62\">I get to keep going.</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qkFkg46Jw3LurFyaj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": -4, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "12647", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 107, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jroCHyDC6XHomeuW7", "iHMy2X9mqQT6ayf9f", "jJJLCGHDYyc9XbHwX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-03T02:58:42.692Z", "modifiedAt": null, "url": null, "title": "Formulas of arithmetic that behave like decision agents", "slug": "formulas-of-arithmetic-that-behave-like-decision-agents", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:53.075Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yX9pMZik7r38da7Fc/formulas-of-arithmetic-that-behave-like-decision-agents", "pageUrlRelative": "/posts/yX9pMZik7r38da7Fc/formulas-of-arithmetic-that-behave-like-decision-agents", "linkUrl": "https://www.lesswrong.com/posts/yX9pMZik7r38da7Fc/formulas-of-arithmetic-that-behave-like-decision-agents", "postedAtFormatted": "Friday, February 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Formulas%20of%20arithmetic%20that%20behave%20like%20decision%20agents&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFormulas%20of%20arithmetic%20that%20behave%20like%20decision%20agents%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyX9pMZik7r38da7Fc%2Fformulas-of-arithmetic-that-behave-like-decision-agents%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Formulas%20of%20arithmetic%20that%20behave%20like%20decision%20agents%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyX9pMZik7r38da7Fc%2Fformulas-of-arithmetic-that-behave-like-decision-agents", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyX9pMZik7r38da7Fc%2Fformulas-of-arithmetic-that-behave-like-decision-agents", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3236, "htmlBody": "<p>I wrote this post in the course of working through Vladimir Slepnev's <a href=\"/lw/8wc/a_model_of_udt_with_halting_oracles/\">A model of UDT with a halting oracle</a>. This post contains some of the ideas of Slepnev's post, with all the proofs written out. The main formal difference is that while Slepnev's post is about programs with access to a halting oracle, the \"decision agents\" in this post are formulas in Peano arithmetic. They are generally uncomputable and do not reason under uncertainty.</p>\n<p>These ideas are due to Vladimir Slepnev and Vladimir Nesov. (Please let me know if I should credit anyone else.) I'm pretty sure none of this is original material on my part. It is possible that I have misinterpreted Slepnev's post or introduced errors.</p>\n<p>We are going to define a world function <img style=\"vertical-align: bottom;\" title=\"U()\" src=\"http://latex.codecogs.com/gif.latex?U()\" alt=\"\" align=\"bottom\" />, a <img title=\"0\" src=\"http://latex.codecogs.com/gif.latex?0\" alt=\"\" align=\"bottom\" />-ary function<sup><a href=\"#1b\">1</a></sup><a name=\"1a\"></a>&nbsp;that outputs an ordered pair <img title=\"(a,b) \\in \\mathbb{Q}^2\" src=\"http://latex.codecogs.com/gif.latex?(a,b) \\in \\mathbb{Q}^2\" alt=\"\" align=\"bottom\" /> of payoff values. There are functions <img title=\"\\pi_i\" src=\"http://latex.codecogs.com/gif.latex?\\pi_i\" alt=\"\" align=\"bottom\" /> such that <img title=\"\\pi_0(a,b) = a\" src=\"http://latex.codecogs.com/gif.latex?\\pi_0(a,b) = a\" alt=\"\" align=\"bottom\" /> and <img title=\"\\pi_1(a,b) = b\" src=\"http://latex.codecogs.com/gif.latex?\\pi_1(a,b) = b\" alt=\"\" align=\"bottom\" /> for any <img title=\"a,b\" src=\"http://latex.codecogs.com/gif.latex?a,b\" alt=\"\" align=\"bottom\" />. In fact <img title=\"\\pi_i(a,b)\" src=\"http://latex.codecogs.com/gif.latex?\\pi_i(a,b)\" alt=\"\" align=\"bottom\" /> is a function in the three variables <img title=\"i, a,\" src=\"http://latex.codecogs.com/gif.latex?i, a,\" alt=\"\" align=\"bottom\" /> and <img title=\"b\" src=\"http://latex.codecogs.com/gif.latex?b\" alt=\"\" align=\"bottom\" />.</p>\n<p>We are also going to define an agent function <img title=\"A(x,i)\" src=\"http://latex.codecogs.com/gif.latex?A(x,i)\" alt=\"\" align=\"bottom\" /> that outputs the symbol <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" /> or <img title=\"D\" src=\"http://latex.codecogs.com/gif.latex?D\" alt=\"\" align=\"bottom\" />. The argument <img title=\"x\" src=\"http://latex.codecogs.com/gif.latex?x\" alt=\"\" align=\"bottom\" /> is supposed to be the G&ouml;del number of the world function, and <img title=\"i \\in \\mathbb{N}\" src=\"http://latex.codecogs.com/gif.latex?i \\in \\mathbb{N}\" alt=\"\" align=\"bottom\" /> is some sort of indexical information.</p>\n<p>We want to define our agent such that</p>\n<p><img title=\"A(\\ulcorner \\chi \\urcorner,i) = \\left\\{ \\begin{array}{ll}D &amp; \\mbox{if } \\vdash A(\\ulcorner \\chi \\urcorner, \\underline{i}) = C \\mbox{; else}\\\\C &amp; \\mbox{if } \\vdash A(\\ulcorner \\chi \\urcorner, \\underline{i}) = D \\mbox{; else}\\\\C &amp; \\mbox{if } \\exists a,b ( \\vdash ( A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{a})\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad} (A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{b} ))\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad}a &gt; b \\mbox{; else}\\\\ D &amp;\\end{array} \\right.\" src=\"http://latex.codecogs.com/gif.latex?A(\\ulcorner \\chi \\urcorner,i) = \\left\\{ \\begin{array}{ll}D &amp; \\mbox{if } \\vdash A(\\ulcorner \\chi \\urcorner, \\underline{i}) = C \\mbox{; else}\\\\C &amp; \\mbox{if } \\vdash A(\\ulcorner \\chi \\urcorner, \\underline{i}) = D \\mbox{; else}\\\\C &amp; \\mbox{if } \\exists a,b ( \\vdash ( A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{a})\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad} (A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{b} ))\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad}a &gt; b \\mbox{; else}\\\\ D &amp;\\end{array} \\right.\" alt=\"\" align=\"bottom\" /></p>\n<p>(<img title=\"\\ulcorner \\omega \\urcorner\" src=\"http://latex.codecogs.com/gif.latex?\\ulcorner \\omega \\urcorner\" alt=\"\" align=\"bottom\" /> denotes the G&ouml;del number of <img title=\"\\omega\" src=\"http://latex.codecogs.com/gif.latex?\\omega\" alt=\"\" align=\"bottom\" />. <img title=\"\\vdash \\omega\" src=\"http://latex.codecogs.com/gif.latex?\\vdash \\omega\" alt=\"\" align=\"bottom\" /> means that <img title=\"\\omega\" src=\"http://latex.codecogs.com/gif.latex?\\omega\" alt=\"\" align=\"bottom\" /> is provable in Peano arithmetic. <img title=\"\\underline{i}\" src=\"http://latex.codecogs.com/gif.latex?\\underline{i}\" alt=\"\" align=\"bottom\" /> represents the numeral for <img title=\"i\" src=\"http://latex.codecogs.com/gif.latex?i\" alt=\"\" align=\"bottom\" />. I don't care what value <img title=\"A(x,i)\" src=\"http://latex.codecogs.com/gif.latex?A(x,i)\" alt=\"\" align=\"bottom\" /> has when <img title=\"x\" src=\"http://latex.codecogs.com/gif.latex?x\" alt=\"\" align=\"bottom\" /> isn't the G&ouml;del number of an appropriate <img title=\"0\" src=\"http://latex.codecogs.com/gif.latex?0\" alt=\"\" align=\"bottom\" />-ary function.)</p>\n<p>There is some circularity in this tentative definition, because a formula standing for&nbsp;<img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> appears in the definition of <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> itself. We get around this by using diagonalization. We'll describe how this works just this once: First define the&nbsp;function <img title=\"\\phi\" src=\"http://latex.codecogs.com/gif.latex?\\phi\" alt=\"\" align=\"bottom\" /> as follows:</p>\n<p><img title=\"\\phi(\\ulcorner \\chi \\urcorner,i,\\ulcorner \\psi \\urcorner) = \\left\\{ \\begin{array}{ll}D &amp; \\mbox{if } \\vdash \\psi(\\ulcorner \\chi \\urcorner, \\underline{i}) = C \\mbox{; else}\\\\C &amp; \\mbox{if } \\vdash \\psi(\\ulcorner \\chi \\urcorner, \\underline{i}) = D \\mbox{; else}\\\\C &amp; \\mbox{if } \\exists a,b ( \\vdash ( \\psi(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{a})\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad} (\\psi(\\ulcorner \\chi \\urcorner,\\underline{i}) = D \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{b} ))\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad}a &gt; b \\mbox{; else}\\\\ D &amp;\\end{array} \\right.\" src=\"http://latex.codecogs.com/gif.latex?\\phi(\\ulcorner \\chi \\urcorner,i,\\ulcorner \\psi \\urcorner) = \\left\\{ \\begin{array}{ll}D &amp; \\mbox{if } \\vdash \\psi(\\ulcorner \\chi \\urcorner, \\underline{i}) = C \\mbox{; else}\\\\C &amp; \\mbox{if } \\vdash \\psi(\\ulcorner \\chi \\urcorner, \\underline{i}) = D \\mbox{; else}\\\\C &amp; \\mbox{if } \\exists a,b ( \\vdash ( \\psi(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{a})\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad} (\\psi(\\ulcorner \\chi \\urcorner,\\underline{i}) = D \\to \\pi_{\\underline{i}}(\\chi()) = \\underline{b} ))\\\\ &amp; \\mbox{\\quad} \\wedge \\mbox{\\quad}a &gt; b \\mbox{; else}\\\\ D &amp;\\end{array} \\right.\" alt=\"\" align=\"bottom\" /></p>\n<p>This function can be defined by a formula. Then the diagonal lemma gives us a formula&nbsp;<img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> such that <img title=\"\\vdash A(x,i) = \\phi(x,i,\\ulcorner A \\urcorner)\" src=\"http://latex.codecogs.com/gif.latex?\\vdash A(x,i) = \\phi(x,i,\\ulcorner A \\urcorner)\" alt=\"\" align=\"bottom\" />.</p>\n<p>This is our (somewhat) rational decision agent. If it can prove it will do one thing, it does another; this is what Slepnev calls \"playing chicken with the universe\". If it can prove that <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" /> is an optimal strategy, it chooses <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" />; and otherwise it chooses <img title=\"D\" src=\"http://latex.codecogs.com/gif.latex?D\" alt=\"\" align=\"bottom\" />.</p>\n<p>First, a lemma about the causes and consequences of playing chicken:</p>\n<p><strong>Lemma 1.</strong> <em>For any <img title=\"\\chi\" src=\"http://latex.codecogs.com/gif.latex?\\chi\" alt=\"\" align=\"bottom\" />,</em></p>\n<ol>\n<li><em><img title=\"\\vdash \\operatorname{Prv}( A(\\ulcorner \\chi \\urcorner, \\underline{i}) = C) \\to \\neg \\operatorname{Con}(\\operatorname{PA})\" src=\"http://latex.codecogs.com/gif.latex?\\vdash \\operatorname{Prv}( A(\\ulcorner \\chi \\urcorner, \\underline{i}) = C) \\to \\neg \\operatorname{Con}(\\operatorname{PA})\" alt=\"\" align=\"bottom\" /></em></li>\n<li><em><img title=\"\\vdash \\neg \\operatorname{Con}(\\operatorname{PA}) \\to A(\\ulcorner \\chi \\urcorner, \\underline{i}) = D\" src=\"http://latex.codecogs.com/gif.latex?\\vdash \\neg \\operatorname{Con}(\\operatorname{PA}) \\to A(\\ulcorner \\chi \\urcorner, \\underline{i}) = D\" alt=\"\" align=\"bottom\" /></em></li>\n<li><em><img title=\"\\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i})=D) \\to \\neg\\operatorname{Con}(\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA}))\" src=\"http://latex.codecogs.com/gif.latex?\\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i})=D) \\to \\neg\\operatorname{Con}(\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA}))\" alt=\"\" align=\"bottom\" /></em></li>\n<li><em><img title=\"\\vdash \\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg\\operatorname{Con}(\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA})) \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C\" src=\"http://latex.codecogs.com/gif.latex?\\vdash \\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg\\operatorname{Con}(\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA})) \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C\" alt=\"\" align=\"bottom\" /></em></li>\n</ol>\n<p>&nbsp;</p>\n<p>(<img title=\"\\operatorname{Prv}\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{Prv}\" alt=\"\" align=\"bottom\" /> is a binary-valued function such that <img title=\"\\operatorname{Prv}(\\ulcorner \\omega \\urcorner)\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{Prv}(\\ulcorner \\omega \\urcorner)\" alt=\"\" align=\"bottom\" /> is true exactly when there is a proof of <img title=\"\\omega\" src=\"http://latex.codecogs.com/gif.latex?\\omega\" alt=\"\" align=\"bottom\" /> in Peano arithmetic. For brevity we write <img title=\"\\operatorname{Prv}(\\omega)\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{Prv}(\\omega)\" alt=\"\" align=\"bottom\" /> instead. <img title=\"\\operatorname{Con}(\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA}))\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{Con}(\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA}))\" alt=\"\" align=\"bottom\" /> is the proposition that Peano arithmetic, plus the axiom that Peano arithmetic is consistent, is a consistent theory.)</p>\n<p><em>Proof.</em> (1) By definition of <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" />,</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) &amp; \\to A(\\ulcorner \\chi \\urcorner,i) = D &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) &amp; \\to A(\\ulcorner \\chi \\urcorner,i) = D &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>So</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C)) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,i) = D) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C)) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,i) = D) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /> <br /><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C)) &amp;\\\\&amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\\\&amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C)) &amp;\\\\&amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\\\&amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>(2) By the principle of explosion,</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\neg \\operatorname{Con}(\\operatorname{PA}) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) &amp;\\\\ &amp; \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\neg \\operatorname{Con}(\\operatorname{PA}) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) &amp;\\\\ &amp; \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>(3) By the definition of <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" />,</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\neg \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp; \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\neg \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp; \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /> <br /><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp; \\to \\biggl( \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) \\biggr) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C &amp;\\\\&amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp; \\to \\biggl( \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) \\biggr) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C &amp;\\\\&amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C\\end{align*}\" alt=\"\" align=\"bottom\" /> <br /><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D)) &amp; \\to \\operatorname{Prv} \\biggl( \\neg\\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\biggr) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D)) &amp; \\to \\operatorname{Prv} \\biggl( \\neg\\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\biggr) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /> <br /><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) \\wedge \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D)) &amp;\\\\&amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) \\wedge \\operatorname{Prv} \\biggl(\\neg \\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\biggr) &amp;\\\\&amp; \\to \\operatorname{Prv} \\biggl( A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D \\wedge \\biggl(\\neg\\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\biggr) \\biggr) &amp;\\\\&amp; \\to \\operatorname{Prv}(\\neg\\operatorname{Con}(\\operatorname{PA})) &amp;\\\\&amp; \\to \\neg\\operatorname{Con}(PA + \\operatorname{Con}(\\operatorname{PA})) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) \\wedge \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D)) &amp;\\\\&amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) \\wedge \\operatorname{Prv} \\biggl(\\neg \\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\biggr) &amp;\\\\&amp; \\to \\operatorname{Prv} \\biggl( A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D \\wedge \\biggl(\\neg\\operatorname{Con}(\\operatorname{PA}) \\vee A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C \\biggr) \\biggr) &amp;\\\\&amp; \\to \\operatorname{Prv}(\\neg\\operatorname{Con}(\\operatorname{PA})) &amp;\\\\&amp; \\to \\neg\\operatorname{Con}(PA + \\operatorname{Con}(\\operatorname{PA})) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>(4)</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\neg\\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) &amp; \\to \\operatorname{Prv}(\\neg\\operatorname{Con}(\\operatorname{PA})) &amp;\\\\&amp; \\to \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C)) &amp;\\\\&amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\neg\\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) &amp; \\to \\operatorname{Prv}(\\neg\\operatorname{Con}(\\operatorname{PA})) &amp;\\\\&amp; \\to \\operatorname{Prv}(\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C)) &amp;\\\\&amp; \\to \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /> <br /><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg\\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) &amp; \\to \\operatorname{Con}(\\operatorname{PA}) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\\\&amp; \\to \\neg\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\\\&amp; \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg\\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) &amp; \\to \\operatorname{Con}(\\operatorname{PA}) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\\\&amp; \\to \\neg\\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C) \\wedge \\operatorname{Prv}(A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D) &amp;\\\\&amp; \\to A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p><img style=\"float: right;\" src=\"http://www.codecogs.com/gif.latex?\\square\" alt=\"\" width=\"15\" height=\"15\" /></p>\n<p>&nbsp;</p>\n<p>If we assume consistency of <img title=\"\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" alt=\"\" align=\"bottom\" /> (which entails consistency of <img title=\"\\operatorname{PA}\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{PA}\" alt=\"\" align=\"bottom\" />), then parts (1) and (3) of Lemma 1 tell us that for any <img title=\"i\" src=\"http://latex.codecogs.com/gif.latex?i\" alt=\"\" align=\"bottom\" />, <img title=\"\\nvdash A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C\" src=\"http://latex.codecogs.com/gif.latex?\\nvdash A(\\ulcorner \\chi \\urcorner,\\underline{i}) = C\" alt=\"\" align=\"bottom\" /> and <img title=\"\\nvdash A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D\" src=\"http://latex.codecogs.com/gif.latex?\\nvdash A(\\ulcorner \\chi \\urcorner,\\underline{i}) = D\" alt=\"\" align=\"bottom\" />. So the agent never actually plays chicken.</p>\n<p>Now let's see how our agent fares on a straightforward decision problem:</p>\n<p><strong>Proposition 2.</strong>&nbsp;<em>Let <img style=\"vertical-align: bottom;\" src=\"http://latex.codecogs.com/gif.latex?\\alpha, \\beta \\in \\mathbb{Q}\" alt=\"\" width=\"67\" height=\"17\" />&nbsp;and s</em><em>uppose</em></p>\n<p><em><img title=\"U() = \\left\\{ \\begin{array}{ll}(\\alpha, 0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0) = C\\\\ (\\beta, 0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0) = D\\end{array} \\right.\" src=\"http://latex.codecogs.com/gif.latex?U() = \\left\\{ \\begin{array}{ll}(\\alpha, 0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0) = C\\\\ (\\beta, 0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0) = D\\end{array} \\right.\" alt=\"\" align=\"bottom\" /></em></p>\n<p><em>Assume consistency of <img title=\"\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA})\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{PA}+\\operatorname{Con}(\\operatorname{PA})\" alt=\"\" align=\"bottom\" />. Then <img title=\"A(\\ulcorner U \\urcorner,0) = C\" src=\"http://latex.codecogs.com/gif.latex?A(\\ulcorner U \\urcorner,0) = C\" alt=\"\" align=\"bottom\" /> if and only if <img title=\"\\alpha &gt; \\beta\" src=\"http://latex.codecogs.com/gif.latex?\\alpha &gt; \\beta\" alt=\"\" align=\"bottom\" />.</em></p>\n<p><em>Proof.</em> If we assume consistency of <img title=\"\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" alt=\"\" align=\"bottom\" />, then Lemma 1 tells us that the agent doesn't play chicken. So the agent will choose <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" /> if and only if it determines that choosing <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" /> is optimal.</p>\n<p>We have</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\biggl( A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{\\alpha} \\biggr) \\wedge \\biggl( A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{\\beta} \\biggr) &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\biggl( A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{\\alpha} \\biggr) \\wedge \\biggl( A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{\\beta} \\biggr) &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>Suppose <img title=\"\\alpha &gt; \\beta\" src=\"http://latex.codecogs.com/gif.latex?\\alpha &gt; \\beta\" alt=\"\" align=\"bottom\" />. Then clearly</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\exists a,b \\vdash \\biggl( A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a} \\biggr) \\wedge \\biggl( A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{b} \\biggr) \\wedge a &gt; b &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\exists a,b \\vdash \\biggl( A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a} \\biggr) \\wedge \\biggl( A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{b} \\biggr) \\wedge a &gt; b &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>So <img title=\"A(\\ulcorner U \\urcorner,0) = C\" src=\"http://latex.codecogs.com/gif.latex?A(\\ulcorner U \\urcorner,0) = C\" alt=\"\" align=\"bottom\" />.</p>\n<p>As for the converse: We have&nbsp;<img title=\"\\vdash (A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{\\alpha})\" src=\"http://latex.codecogs.com/gif.latex?\\vdash (A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{\\alpha})\" alt=\"\" align=\"bottom\" />. If also</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash (A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a}) &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash (A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a}) &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>and <img title=\"a \\neq \\alpha\" src=\"http://latex.codecogs.com/gif.latex?a \\neq \\alpha\" alt=\"\" align=\"bottom\" />, then <img title=\"\\vdash(A(\\ulcorner U \\urcorner,0) = D)\" src=\"http://latex.codecogs.com/gif.latex?\\vdash(A(\\ulcorner U \\urcorner,0) = D)\" alt=\"\" align=\"bottom\" />. By Lemma 1(3) and consistency of <img title=\"\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" alt=\"\" align=\"bottom\" />, this cannot happen. So</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\nvdash (A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a}) &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\nvdash (A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a}) &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>Similarly, we have</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\nvdash (A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{b}) &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\nvdash (A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{b}) &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>for all <img title=\"b \\neq \\beta\" src=\"http://latex.codecogs.com/gif.latex?b \\neq \\beta\" alt=\"\" align=\"bottom\" />. So</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\nexists a,b \\vdash(A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a}) \\wedge (A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{b}) \\wedge a&gt;b &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\nexists a,b \\vdash(A(\\ulcorner U \\urcorner,0) = C \\to \\pi_0 U() = \\underline{a}) \\wedge (A(\\ulcorner U \\urcorner,0) = D \\to \\pi_0 U() = \\underline{b}) \\wedge a&gt;b &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>So the agent doesn't decide that <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" /> is optimal, and <img title=\"A(\\ulcorner U \\urcorner,0) = D\" src=\"http://latex.codecogs.com/gif.latex?A(\\ulcorner U \\urcorner,0) = D\" alt=\"\" align=\"bottom\" />.</p>\n<p><img style=\"float: right;\" src=\"http://www.codecogs.com/gif.latex?\\square\" alt=\"\" width=\"15\" height=\"15\" /></p>\n<p>&nbsp;</p>\n<p>Now let's see how <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> fares on a symmetric Prisoner's Dilemma with itself:</p>\n<p><strong>Proposition 3.</strong>&nbsp;<em>Let</em></p>\n<p><em><img title=\"U() = \\left\\{ \\begin{array}{ll}(1,1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (-1,2) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=D\\\\ (2,-1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (0,0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=D\\end{array} \\right.\" src=\"http://latex.codecogs.com/gif.latex?U() = \\left\\{ \\begin{array}{ll}(1,1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (-1,2) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=D\\\\ (2,-1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (0,0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=D\\end{array} \\right.\" alt=\"\" align=\"bottom\" /></em></p>\n<p><em>Then, assuming consistency of <img title=\"\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" alt=\"\" align=\"bottom\" />, we have <img title=\"A(\\ulcorner U \\urcorner,0) = C = A(\\ulcorner U \\urcorner,1)\" src=\"http://latex.codecogs.com/gif.latex?A(\\ulcorner U \\urcorner,0) = C = A(\\ulcorner U \\urcorner,1)\" alt=\"\" align=\"bottom\" />.</em></p>\n<p><em>Proof.</em></p>\n<p><em></em>(This proof uses L&ouml;b's theorem, and that makes it confusing. Vladimir Slepnev points out that L&ouml;b's theorem is not really necessary here; a <a href=\"/lw/9o7/formulas_of_arithmetic_that_behave_like_decision/696s\">simpler proof</a> appears in the comments.)</p>\n<p><br /><img title=\"\\begin{align*}\\quad\\quad \\vdash A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1) &amp; \\to \\biggl(\\biggl( A(\\ulcorner U \\urcorner,0)=C \\to \\pi_0 U() = 1 \\biggr) \\wedge \\biggl( A(\\ulcorner U \\urcorner,0)=D \\to \\pi_0 U() = 0 \\biggr)\\biggr) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1) &amp; \\to \\biggl(\\biggl( A(\\ulcorner U \\urcorner,0)=C \\to \\pi_0 U() = 1 \\biggr) \\wedge \\biggl( A(\\ulcorner U \\urcorner,0)=D \\to \\pi_0 U() = 0 \\biggr)\\biggr) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /> <br /><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\exists a,b. \\operatorname{Prv}\\biggl((A(\\ulcorner U \\urcorner,0)=C \\to \\pi_0 U() = \\underline{a}) &amp;\\\\&amp; \\quad\\quad \\wedge (A(\\ulcorner U \\urcorner,0)=D \\to \\pi_0 U() = \\underline{b})\\biggr) \\wedge a &gt; b &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\exists a,b. \\operatorname{Prv}\\biggl((A(\\ulcorner U \\urcorner,0)=C \\to \\pi_0 U() = \\underline{a}) &amp;\\\\&amp; \\quad\\quad \\wedge (A(\\ulcorner U \\urcorner,0)=D \\to \\pi_0 U() = \\underline{b})\\biggr) \\wedge a &gt; b &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /><br />Looking at the definition of <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" />, we see that</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0)=C) \\vee \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0)=D) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0)=C &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0)=C) \\vee \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0)=D) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0)=C &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /><br />By Lemma 1, (1) and (3),</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\vee A(\\ulcorner U \\urcorner,0)=C &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\vee A(\\ulcorner U \\urcorner,0)=C &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>Similarly,</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\vee A(\\ulcorner U \\urcorner,1)=C &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\vee A(\\ulcorner U \\urcorner,1)=C &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>So</p>\n<p><img title=\"\\begin{align*} \\label{ast}(*)\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\biggl(\\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\biggr) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*} \\label{ast}(*)\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\biggl(\\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\biggr) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>Applying Lemma 1(2) and (4),</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to A(\\ulcorner U \\urcorner,0) = D = A(\\ulcorner U \\urcorner,1) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0) = C = A(\\ulcorner U \\urcorner,1) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1) &amp;\\\\&amp; \\to A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1) &amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp; \\to A(\\ulcorner U \\urcorner,0) = D = A(\\ulcorner U \\urcorner,1) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0) = C = A(\\ulcorner U \\urcorner,1) &amp;\\\\&amp;\\quad\\quad \\vee A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1) &amp;\\\\&amp; \\to A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1) &amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>By L&ouml;b's theorem,</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1) &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1) &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /> <br /><img title=\"\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\operatorname{Prv}(A(\\ulcorner U \\urcorner,0) = A(\\ulcorner U \\urcorner,1)) &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>By&nbsp;<img title=\"(*)\" src=\"http://latex.codecogs.com/gif.latex?(*)\" alt=\"\" align=\"bottom\" />, we have</p>\n<p><img title=\"\\begin{align*}\\quad\\quad \\vdash \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\biggl(\\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\biggr) \\vee A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1) &amp;&amp;\\end{align*}\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*}\\quad\\quad \\vdash \\neg \\operatorname{Con}(\\operatorname{PA}) \\vee \\biggl(\\operatorname{Con}(\\operatorname{PA}) \\wedge \\neg \\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})) \\biggr) \\vee A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1) &amp;&amp;\\end{align*}\" alt=\"\" align=\"bottom\" /></p>\n<p>So, assuming <img title=\"\\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA}))\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{Con}(\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA}))\" alt=\"\" align=\"bottom\" />, we conclude that <img title=\"A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1)\" src=\"http://latex.codecogs.com/gif.latex?A(\\ulcorner U \\urcorner,0)=C=A(\\ulcorner U \\urcorner,1)\" alt=\"\" align=\"bottom\" />.</p>\n<p><img style=\"float: right;\" src=\"http://www.codecogs.com/gif.latex?\\square\" alt=\"\" width=\"15\" height=\"15\" /></p>\n<p>&nbsp;</p>\n<p>The definition of <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> treats the choices <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" /> and <img title=\"D\" src=\"http://latex.codecogs.com/gif.latex?D\" alt=\"\" align=\"bottom\" /> differently; so it is worth checking that <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> behaves correctly in the Prisoner's Dilemma when the effects of <img title=\"C\" src=\"http://latex.codecogs.com/gif.latex?C\" alt=\"\" align=\"bottom\" /> and <img title=\"D\" src=\"http://latex.codecogs.com/gif.latex?D\" alt=\"\" align=\"bottom\" /> are switched:</p>\n<p><strong>Proposition 4.</strong> <em>Let</em></p>\n<p><em><img title=\"U() = \\left\\{ \\begin{array}{ll}(0,0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (2,-1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=D\\\\ (-1,2) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (1,1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=D\\end{array} \\right.\" src=\"http://latex.codecogs.com/gif.latex?U() = \\left\\{ \\begin{array}{ll}(0,0) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (2,-1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=C \\wedge A(\\ulcorner U \\urcorner,1)=D\\\\ (-1,2) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=C\\\\ (1,1) &amp; \\mbox{\\rm if } A(\\ulcorner U \\urcorner,0)=D \\wedge A(\\ulcorner U \\urcorner,1)=D\\end{array} \\right.\" alt=\"\" align=\"bottom\" /></em></p>\n<p><em>Then, assuming consistency of <img title=\"\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" src=\"http://latex.codecogs.com/gif.latex?\\operatorname{PA} + \\operatorname{Con}(\\operatorname{PA})\" alt=\"\" align=\"bottom\" />, we have <img title=\"A(\\ulcorner U \\urcorner,0) = D = A(\\ulcorner U \\urcorner,1)\" src=\"http://latex.codecogs.com/gif.latex?A(\\ulcorner U \\urcorner,0) = D = A(\\ulcorner U \\urcorner,1)\" alt=\"\" align=\"bottom\" />.</em></p>\n<p>A <a href=\"/lw/9o7/formulas_of_arithmetic_that_behave_like_decision/696t\">proof</a> appears in the comments.</p>\n<p>There are a number of questions one can explore with this formalism: What is the correct generalization of <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> that can choose between <img title=\"n\" src=\"http://latex.codecogs.com/gif.latex?n\" alt=\"\" align=\"bottom\" /> actions, and not just two? How about infinitely many actions? What about <a href=\"/lw/8wc/a_model_of_udt_with_halting_oracles/\">theories other than Peano arithmetic</a>? How do we accomodate payoffs that are&nbsp;<a href=\"/r/discussion/lw/9mq/rational_vs_real_utilities_in_the_cousin_itnesov/\">real numbers</a>? How do we make agents that can reason under uncertainty? How do we make <a href=\"/lw/2l2/what_a_reduction_of_could_could_look_like/\">agents</a> that are <a href=\"/lw/2ip/ai_cooperation_in_practice/\">computable algorithms</a> rather than arithmetic formulas? How does <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> fare on a Prisoner's Dilemma with <a href=\"/r/discussion/lw/8wc/a_model_of_udt_with_a_halting_oracle/5nnq\">asymmetric payoff matrix</a>? In a two-person game where the payoff to player <img title=\"A_0\" src=\"http://latex.codecogs.com/gif.latex?A_0\" alt=\"\" align=\"bottom\" /> is independent of the behavior of <img title=\"A_1\" src=\"http://latex.codecogs.com/gif.latex?A_1\" alt=\"\" align=\"bottom\" />, can <img title=\"A_1\" src=\"http://latex.codecogs.com/gif.latex?A_1\" alt=\"\" align=\"bottom\" /> deduce the behavior of <img title=\"A_0\" src=\"http://latex.codecogs.com/gif.latex?A_0\" alt=\"\" align=\"bottom\" />? What happens when we replace the third line of the definition of <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> with</p>\n<p><img style=\"vertical-align: bottom;\" src=\"http://latex.codecogs.com/gif.latex?\\begin{align*} \\quad\\quad \\vdash \\exists a,b &amp; (A(\\ulcorner U\\urcorner,\\underline{i})=C \\to \\pi_{\\underline{i}} U() = a) \\\\&amp; \\wedge ( A(\\ulcorner U \\urcorner,\\underline{i})=D \\to \\pi_{\\underline{i}} U() = b) \\\\&amp; \\wedge a &gt; b \\end{align*}\" alt=\"\\begin{align*} \\quad\\quad \\vdash \\exists a,b &amp; (A(\\ulcorner U\\urcorner,\\underline{i})=C \\to \\pi_{\\underline{i}} U() = a) \\\\&amp; \\wedge ( A(\\ulcorner U \\urcorner,\\underline{i})=D \\to \\pi_{\\underline{i}} U() = b) \\\\&amp; \\wedge a &gt; b \\end{align*}\" width=\"299\" height=\"68\" /></p>\n<p>? What is a (good) definition of \"decision problem\"? Is there a theorem that says that our agent <img title=\"A\" src=\"http://latex.codecogs.com/gif.latex?A\" alt=\"\" align=\"bottom\" /> is, in a certain sense, optimal?</p>\n<p><sup><a name=\"1b\"></a><a href=\"#1a\">1</a></sup>Every&nbsp;<img title=\"k\" src=\"http://latex.codecogs.com/gif.latex?k\" alt=\"\" align=\"bottom\" />-ary function&nbsp;<img title=\"U\" src=\"http://latex.codecogs.com/gif.latex?U\" alt=\"\" align=\"bottom\" />&nbsp;in this article is defined by a formula <img title=\"\\phi(x_1, \\dots, x_k, y)\" src=\"http://latex.codecogs.com/gif.latex?\\phi(x_1, \\dots, x_k, y)\" alt=\"\" align=\"bottom\" /> with <img title=\"k+1\" src=\"http://latex.codecogs.com/gif.latex?k+1\" alt=\"\" align=\"bottom\" /> free variables such that <img title=\"\\vdash \\exists y. \\phi(x_1, \\dots, x_k, y)\" src=\"http://latex.codecogs.com/gif.latex?\\vdash \\exists y. \\phi(x_1, \\dots, x_k, y)\" alt=\"\" align=\"bottom\" /> and <img title=\"\\vdash \\phi(x_1, \\dots, x_k, y) \\wedge \\phi(x_1, \\dots, x_k, y') \\to y = y'\" src=\"http://latex.codecogs.com/gif.latex?\\vdash \\phi(x_1, \\dots, x_k, y) \\wedge \\phi(x_1, \\dots, x_k, y') \\to y = y'\" alt=\"\" align=\"bottom\" />. By a standard abuse of notation, when the name of a function like <img title=\"U\" src=\"http://latex.codecogs.com/gif.latex?U\" alt=\"\" align=\"bottom\" /> appears in a formula of arithmetic, what we really mean is the formula <img title=\"\\phi\" src=\"http://latex.codecogs.com/gif.latex?\\phi\" alt=\"\" align=\"bottom\" /> that defines it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"6nS8oYmSMuFMaiowF": 1, "dPPATLhRmhdJtJM2t": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yX9pMZik7r38da7Fc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 35, "extendedScore": null, "score": 8.423514207691043e-07, "legacy": true, "legacyId": "12535", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Bj244uWzDBXvE2N2S", "bKDZepmTx8X6SRLE5", "dC3rxrMkYKLfgTYEa", "TNfx89dh5KkcKrvho"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-03T03:46:50.968Z", "modifiedAt": null, "url": null, "title": "Meetup : Salt Lake City Meetup #2", "slug": "meetup-salt-lake-city-meetup-2", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.430Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "adamisom", "createdAt": "2011-06-13T03:19:15.520Z", "isAdmin": false, "displayName": "adamisom"}, "userId": "eT8NPFmc2GDb5QFfc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xikQ627nWK5rSk3cF/meetup-salt-lake-city-meetup-2", "pageUrlRelative": "/posts/xikQ627nWK5rSk3cF/meetup-salt-lake-city-meetup-2", "linkUrl": "https://www.lesswrong.com/posts/xikQ627nWK5rSk3cF/meetup-salt-lake-city-meetup-2", "postedAtFormatted": "Friday, February 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Salt%20Lake%20City%20Meetup%20%232&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Salt%20Lake%20City%20Meetup%20%232%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxikQ627nWK5rSk3cF%2Fmeetup-salt-lake-city-meetup-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Salt%20Lake%20City%20Meetup%20%232%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxikQ627nWK5rSk3cF%2Fmeetup-salt-lake-city-meetup-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxikQ627nWK5rSk3cF%2Fmeetup-salt-lake-city-meetup-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 180, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6o'>Salt Lake City Meetup #2</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 February 2012 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">248 E 100 S, Salt Lake City, UT 8411, USA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The 2nd meetup will be at Nostalgia Cafe, 248 E 100 S, this Saturday at 3:00 pm. Saturdays at 3 was the preferred choice by a large margin.</p>\n\n<p>By the way, a tentative 3rd meetup would probably be in a more central location, possibly Taylorsville Library, though I'm just hazarding a guess since I don't know where everyone present last time and otherwise interested lives.</p>\n\n<p>The 2nd Meetup's agenda may--or may not--change. I realize that a presentation on probability theory may not be possible at even a very large table in a cafe. If that doesn't work until next time, I suggest one thing to do is brainstorm ideas (and next actions) for ksvanhorn and DanNuffer's for-profit rationality training idea. Another is to gauge interest in and discuss instrumental rationality (I have a couple of ideas), and in general have a few more one-on-one conversations.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6o'>Salt Lake City Meetup #2</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xikQ627nWK5rSk3cF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.423700881404117e-07, "legacy": true, "legacyId": "12652", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__2\">Discussion article for the meetup : <a href=\"/meetups/6o\">Salt Lake City Meetup #2</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 February 2012 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">248 E 100 S, Salt Lake City, UT 8411, USA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The 2nd meetup will be at Nostalgia Cafe, 248 E 100 S, this Saturday at 3:00 pm. Saturdays at 3 was the preferred choice by a large margin.</p>\n\n<p>By the way, a tentative 3rd meetup would probably be in a more central location, possibly Taylorsville Library, though I'm just hazarding a guess since I don't know where everyone present last time and otherwise interested lives.</p>\n\n<p>The 2nd Meetup's agenda may--or may not--change. I realize that a presentation on probability theory may not be possible at even a very large table in a cafe. If that doesn't work until next time, I suggest one thing to do is brainstorm ideas (and next actions) for ksvanhorn and DanNuffer's for-profit rationality training idea. Another is to gauge interest in and discuss instrumental rationality (I have a couple of ideas), and in general have a few more one-on-one conversations.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__21\">Discussion article for the meetup : <a href=\"/meetups/6o\">Salt Lake City Meetup #2</a></h2>", "sections": [{"title": "Discussion article for the meetup : Salt Lake City Meetup #2", "anchor": "Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__2", "level": 1}, {"title": "Discussion article for the meetup : Salt Lake City Meetup #2", "anchor": "Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__21", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-03T04:13:12.538Z", "modifiedAt": null, "url": null, "title": "Fireplace Delusions [LINK]", "slug": "fireplace-delusions-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.026Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "mas", "createdAt": "2011-10-25T19:57:40.284Z", "isAdmin": false, "displayName": "mas"}, "userId": "5JjpiQutokFcfzi4f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/L5vLGsXEZowoQZYix/fireplace-delusions-link", "pageUrlRelative": "/posts/L5vLGsXEZowoQZYix/fireplace-delusions-link", "linkUrl": "https://www.lesswrong.com/posts/L5vLGsXEZowoQZYix/fireplace-delusions-link", "postedAtFormatted": "Friday, February 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fireplace%20Delusions%20%5BLINK%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFireplace%20Delusions%20%5BLINK%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL5vLGsXEZowoQZYix%2Ffireplace-delusions-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fireplace%20Delusions%20%5BLINK%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL5vLGsXEZowoQZYix%2Ffireplace-delusions-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL5vLGsXEZowoQZYix%2Ffireplace-delusions-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 64, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Sam Harris, in his recent article called&nbsp;<em><a style=\"color: #8a8a8b;\" title=\"THE FIREPLACE DELUSION\" href=\"http://www.samharris.org/blog/item/the-fireplace-delusion\" target=\"_blank\">The Fireplace Delusion</a></em>, tries to make you feel what it's like to react to a cached belief being&nbsp;irreparably destroyed. Just incase you forgot what your&nbsp;apostasy (if you had one, of course) was like in its early stages.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">What are some of the Fireplace Delusions you've come across in your days?</p>\n<p>&nbsp;</p>\n<p>EDIT: <a title=\"WOODSMOKE HEALTH EFFECTS\" href=\"http://www.ncbi.nlm.nih.gov/pubmed/17127644\" target=\"_blank\">WOODSMOKE HEALTH EFFECTS</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XqykXFKL9t38pbSEm": 1, "ec2WRPdGJiWiYmece": 1, "5f5c37ee1b5cdee568cfb0d6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "L5vLGsXEZowoQZYix", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 48, "extendedScore": null, "score": 0.000149, "legacy": true, "legacyId": "12654", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-03T16:29:01.720Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Cambridge, Houston, Melbourne, Pittsburgh, Vancouver, Waterloo", "slug": "weekly-lw-meetups-cambridge-houston-melbourne-pittsburgh", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WfsFAwvugD93SkGTF/weekly-lw-meetups-cambridge-houston-melbourne-pittsburgh", "pageUrlRelative": "/posts/WfsFAwvugD93SkGTF/weekly-lw-meetups-cambridge-houston-melbourne-pittsburgh", "linkUrl": "https://www.lesswrong.com/posts/WfsFAwvugD93SkGTF/weekly-lw-meetups-cambridge-houston-melbourne-pittsburgh", "postedAtFormatted": "Friday, February 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Cambridge%2C%20Houston%2C%20Melbourne%2C%20Pittsburgh%2C%20Vancouver%2C%20Waterloo&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Cambridge%2C%20Houston%2C%20Melbourne%2C%20Pittsburgh%2C%20Vancouver%2C%20Waterloo%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWfsFAwvugD93SkGTF%2Fweekly-lw-meetups-cambridge-houston-melbourne-pittsburgh%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Cambridge%2C%20Houston%2C%20Melbourne%2C%20Pittsburgh%2C%20Vancouver%2C%20Waterloo%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWfsFAwvugD93SkGTF%2Fweekly-lw-meetups-cambridge-houston-melbourne-pittsburgh", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWfsFAwvugD93SkGTF%2Fweekly-lw-meetups-cambridge-houston-melbourne-pittsburgh", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 401, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/6e\">Need more people for Vancouver meetup:&nbsp;<span class=\"date\">28 January 2012 03:03PM</span></a></li>\n<li><a href=\"/meetups/6h\">Pittsburgh Meetup: Big Gaming Fun 3!:&nbsp;<span class=\"date\">29 January 2012 01:00PM</span></a></li>\n<li><a href=\"/meetups/6f\">Houston Meetup - 1/29:&nbsp;<span class=\"date\">29 January 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/6b\">Waterloo Meetup:&nbsp;<span class=\"date\">30 January 2012 08:00PM</span></a></li>\n<li><a href=\"/meetups/6a\">Salt Lake City LW Meetup #2 Logistics:&nbsp;<span class=\"date\">04 February 2012 03:00PM</span></a></li>\n<li><a href=\"/meetups/5f\">First Brussels meetup:&nbsp;<span class=\"date\">11 February 2012 11:00AM</span></a></li>\n<li><a href=\"/meetups/6g\">Sydney Rationality meet-up No.2:&nbsp;<span class=\"date\">15 February 2012 06:00PM</span></a></li>\n<li><a href=\"/meetups/69\">Ongoing Ohio Meetup:&nbsp;<span class=\"date\">19 February 2012 04:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/6i\">Cambridge UK:&nbsp;<span class=\"date\">28 January 2012 06:00PM</span></a></li>\n<li><a href=\"/meetups/6c\">Melbourne practical rationality meetup:&nbsp;<span class=\"date\">03 February 2012 07:00PM</span></a></li>\n</ul>\n<ul>\n</ul>\n<p>Cities with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>, and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a></strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a><strong>.</strong></p>\n<p>If your meetup has a mailing list that you'd like mentioned here or has become regular and isn't listed as such, let me know!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WfsFAwvugD93SkGTF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 8.426657509474008e-07, "legacy": true, "legacyId": "12441", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-03T19:27:05.209Z", "modifiedAt": null, "url": null, "title": "lesswrong.ru domain for translation project?", "slug": "lesswrong-ru-domain-for-translation-project", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:29.205Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BT_Uytya", "createdAt": "2011-12-03T16:41:14.863Z", "isAdmin": false, "displayName": "BT_Uytya"}, "userId": "Enh7Ap3zRTQDR4gMH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XZynrL5XZcNswcym4/lesswrong-ru-domain-for-translation-project", "pageUrlRelative": "/posts/XZynrL5XZcNswcym4/lesswrong-ru-domain-for-translation-project", "linkUrl": "https://www.lesswrong.com/posts/XZynrL5XZcNswcym4/lesswrong-ru-domain-for-translation-project", "postedAtFormatted": "Friday, February 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20lesswrong.ru%20domain%20for%20translation%20project%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Alesswrong.ru%20domain%20for%20translation%20project%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXZynrL5XZcNswcym4%2Flesswrong-ru-domain-for-translation-project%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=lesswrong.ru%20domain%20for%20translation%20project%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXZynrL5XZcNswcym4%2Flesswrong-ru-domain-for-translation-project", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXZynrL5XZcNswcym4%2Flesswrong-ru-domain-for-translation-project", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<p>&nbsp;Hello.</p>\n<p><br />Me and a group of a fellow aspiring rationalists work on <a href=\"http://lesswrong.ru/\">Russian translation of LessWrong</a>.<br /><br />The project is considerable; I think it is worthy of a paid second-level domain. <br /><br />Too bad rationality.ru is already taken. So are rationalist.ru, ratio.ru and similar others.<br /><br />Well, there is an option. Would it be impudent of us to store our translations in the lesswrong.ru?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XZynrL5XZcNswcym4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 24, "extendedScore": null, "score": 8.42734849334312e-07, "legacy": true, "legacyId": "12669", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-04T01:50:01.627Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Sneaking in Connotations", "slug": "seq-rerun-sneaking-in-connotations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.835Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q689GXgBp5QiHztJB/seq-rerun-sneaking-in-connotations", "pageUrlRelative": "/posts/Q689GXgBp5QiHztJB/seq-rerun-sneaking-in-connotations", "linkUrl": "https://www.lesswrong.com/posts/Q689GXgBp5QiHztJB/seq-rerun-sneaking-in-connotations", "postedAtFormatted": "Saturday, February 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Sneaking%20in%20Connotations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Sneaking%20in%20Connotations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ689GXgBp5QiHztJB%2Fseq-rerun-sneaking-in-connotations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Sneaking%20in%20Connotations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ689GXgBp5QiHztJB%2Fseq-rerun-sneaking-in-connotations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ689GXgBp5QiHztJB%2Fseq-rerun-sneaking-in-connotations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 227, "htmlBody": "<p>Today's post, <a href=\"/lw/ny/sneaking_in_connotations/\">Sneaking in Connotations</a> was originally published on 19 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You try to sneak in the connotations of a word, by arguing from a definition that doesn't include the connotations. A \"wiggin\" is defined in the dictionary as a person with green eyes and black hair. The word \"wiggin\" also carries the connotation of someone who commits crimes and launches cute baby squirrels, but that part isn't in the dictionary. So you point to someone and say: \"Green eyes? Black hair? See, told you he's a wiggin! Watch, next he's going to steal the silverware.\"</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/9q4/seq_rerun_categorizing_has_consequences/\">Categorizing Has Consequences</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q689GXgBp5QiHztJB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.428834893899719e-07, "legacy": true, "legacyId": "12686", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yuKaWPRTxZoov4z8K", "jeYQSvHfGzFQF3Mu5", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-04T04:33:49.585Z", "modifiedAt": null, "url": null, "title": "Is Sunk Cost Fallacy a Fallacy?", "slug": "is-sunk-cost-fallacy-a-fallacy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:09.765Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QvuD7R5L5ABw9tDdD/is-sunk-cost-fallacy-a-fallacy", "pageUrlRelative": "/posts/QvuD7R5L5ABw9tDdD/is-sunk-cost-fallacy-a-fallacy", "linkUrl": "https://www.lesswrong.com/posts/QvuD7R5L5ABw9tDdD/is-sunk-cost-fallacy-a-fallacy", "postedAtFormatted": "Saturday, February 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20Sunk%20Cost%20Fallacy%20a%20Fallacy%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20Sunk%20Cost%20Fallacy%20a%20Fallacy%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQvuD7R5L5ABw9tDdD%2Fis-sunk-cost-fallacy-a-fallacy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20Sunk%20Cost%20Fallacy%20a%20Fallacy%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQvuD7R5L5ABw9tDdD%2Fis-sunk-cost-fallacy-a-fallacy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQvuD7R5L5ABw9tDdD%2Fis-sunk-cost-fallacy-a-fallacy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 193, "htmlBody": "<p>I just finished the first draft of my essay, <a href=\"http://www.gwern.net/Sunk%20cost\">\"Are Sunk Costs Fallacies?\"</a>; there is still material I need to go through, but the bulk of the material is now there. The formatting is too gnarly to post here, so I ask everyone's forgiveness in clicking through.</p>\n<p>To summarize:</p>\n<ol>\n<li>sunk costs are probably issues in big organizations\n<ul>\n<li>but maybe not ones that can be helped</li>\n</ul>\n</li>\n<li>sunk costs are not issues in animals</li>\n<li>they appear to be in children &amp; adults\n<ul>\n<li>but many apparent problems can be explained as part of a learning strategy</li>\n</ul>\n</li>\n<li>there are few clear indications sunk costs are genuine problems</li>\n<li>much of what we call 'sunk cost' looks like simple carelessness &amp; thoughtlessness</li>\n</ol>\n<p>(If any of that seems unlikely or absurd to you, click through. I've worked very hard to provide multiple citations where possible, and fulltext for practically everything.)</p>\n<p>I started this a while ago; but Luke/SIAI paid for much of the work, and that motivation plus academic library access made this essay more comprehensive than it would have been and finished months in advance.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"stnsBEmuGpnSfQ5vj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QvuD7R5L5ABw9tDdD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 31, "extendedScore": null, "score": 8.429469042007899e-07, "legacy": true, "legacyId": "12690", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 81, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-04T12:33:39.637Z", "modifiedAt": null, "url": null, "title": "Quantification of eyewitness reliability?", "slug": "quantification-of-eyewitness-reliability", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:21.025Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p2hAKhQ3fxMgcvSTu/quantification-of-eyewitness-reliability", "pageUrlRelative": "/posts/p2hAKhQ3fxMgcvSTu/quantification-of-eyewitness-reliability", "linkUrl": "https://www.lesswrong.com/posts/p2hAKhQ3fxMgcvSTu/quantification-of-eyewitness-reliability", "postedAtFormatted": "Saturday, February 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Quantification%20of%20eyewitness%20reliability%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuantification%20of%20eyewitness%20reliability%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp2hAKhQ3fxMgcvSTu%2Fquantification-of-eyewitness-reliability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Quantification%20of%20eyewitness%20reliability%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp2hAKhQ3fxMgcvSTu%2Fquantification-of-eyewitness-reliability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp2hAKhQ3fxMgcvSTu%2Fquantification-of-eyewitness-reliability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 188, "htmlBody": "<p><a href=\"/lw/2sy/limitations_of_eyewitness_testimony/\">This</a> mentions some of the limitations of eyewitness testimony; does anybody here have any references giving any hard numbers about how reliable eyewitness accounts are, under any given circumstances?</p>\n<p>I'd like to be more conscious about my Bayesian-type updates of my beliefs based on general accounts of what people say. So far, I've started using a rule-of-thumb that somebody telling me something is so is worth approximately 1 decibel of belief (1/3rd of a bit); evidence, but about the weakest evidence possible, nulled by any opposing accounts, and countered by any more substansive evidence.</p>\n<p>If possible, I'd like to know exactly how reliable such testimony tends to be in one particular set of circumstances - time since the thing being reported, level of emotional involvement, etc - to use as a baseline, and at least roughly how strongly such factors change that. (I'll actually be very surprised if this particular set of data currently exists in ready form - but I'll be satisfied if I can get even order-of-magnitude approximations, so that I know whether or not the rules-of-thumb I end up using are at least within plausible spitting distance.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p2hAKhQ3fxMgcvSTu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 2, "extendedScore": null, "score": 8.43133423468289e-07, "legacy": true, "legacyId": "12702", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["J59ZAZvn3X92tvbBx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-04T17:56:22.156Z", "modifiedAt": null, "url": null, "title": "Top 5 regrets of the dying [link]", "slug": "top-5-regrets-of-the-dying-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.912Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HfyusHtvBwv7ydpLe/top-5-regrets-of-the-dying-link", "pageUrlRelative": "/posts/HfyusHtvBwv7ydpLe/top-5-regrets-of-the-dying-link", "linkUrl": "https://www.lesswrong.com/posts/HfyusHtvBwv7ydpLe/top-5-regrets-of-the-dying-link", "postedAtFormatted": "Saturday, February 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Top%205%20regrets%20of%20the%20dying%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATop%205%20regrets%20of%20the%20dying%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHfyusHtvBwv7ydpLe%2Ftop-5-regrets-of-the-dying-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Top%205%20regrets%20of%20the%20dying%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHfyusHtvBwv7ydpLe%2Ftop-5-regrets-of-the-dying-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHfyusHtvBwv7ydpLe%2Ftop-5-regrets-of-the-dying-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p>http://www.guardian.co.uk/lifeandstyle/2012/feb/01/top-five-regrets-of-the-dying?fb_action_ids=10151236956340524&amp;fb_action_types=news.reads&amp;fb_source=other_multiline</p>\n<p>Interesting b/c future concerns and what other people think type of concerns are not much of a factor here.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HfyusHtvBwv7ydpLe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 5, "extendedScore": null, "score": 8.432587862597211e-07, "legacy": true, "legacyId": "12704", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-04T18:06:40.072Z", "modifiedAt": null, "url": null, "title": "East Coast Megameet Google Hangout, today at 3PM", "slug": "east-coast-megameet-google-hangout-today-at-3pm", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.078Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rXF9rAJivjdXbJbB9/east-coast-megameet-google-hangout-today-at-3pm", "pageUrlRelative": "/posts/rXF9rAJivjdXbJbB9/east-coast-megameet-google-hangout-today-at-3pm", "linkUrl": "https://www.lesswrong.com/posts/rXF9rAJivjdXbJbB9/east-coast-megameet-google-hangout-today-at-3pm", "postedAtFormatted": "Saturday, February 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20East%20Coast%20Megameet%20Google%20Hangout%2C%20today%20at%203PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEast%20Coast%20Megameet%20Google%20Hangout%2C%20today%20at%203PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrXF9rAJivjdXbJbB9%2Feast-coast-megameet-google-hangout-today-at-3pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=East%20Coast%20Megameet%20Google%20Hangout%2C%20today%20at%203PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrXF9rAJivjdXbJbB9%2Feast-coast-megameet-google-hangout-today-at-3pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrXF9rAJivjdXbJbB9%2Feast-coast-megameet-google-hangout-today-at-3pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>Today is the East Coast Less Wrong Megameetup. We'll be trying an experiment - running a Google Hangout in the main discussion room. To participate, you'll need a Google+ account, but if you have any kind of Google account (for youtube, e-mail, or anything) you can easily add a Google+ account without filling out much additional information.</p>\n<p>The schedule for the day is:</p>\n<p>&nbsp;</p>\n<p>3 PM: Hangout starts, followed by an hour of freeform discussion</p>\n<p style=\"margin-bottom: 0in;\">Talks start at 4 PM, and continue through 9</p>\n<p style=\"margin-bottom: 0in;\"><em>4 PM:</em>&nbsp;Nutrition/Health by Jolly</p>\n<p style=\"margin-bottom: 0in;\"><em>5 PM:</em>&nbsp;Leverage Research by Geoff Anders</p>\n<p style=\"margin-bottom: 0in;\"><em>6 PM:</em>&nbsp;Consensus Technology by Oliver Carefull</p>\n<p style=\"margin-bottom: 0in;\"><em>7 PM:</em>&nbsp;Psychology by Jasen Murray</p>\n<p style=\"margin-bottom: 0in;\"><em>8 PM: </em>Rational Communities by Raymond Arnold</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p>https://plus.google.com/hangouts/e641e55fa340e98d8d10ecad8f2a86abd13c4e06?hl=en&amp;authuser=0#</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rXF9rAJivjdXbJbB9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 8.432627874987734e-07, "legacy": true, "legacyId": "12705", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T03:07:17.294Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Arguing \"By Definition\"", "slug": "seq-rerun-arguing-by-definition", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/i2pFJiyqP3hzptB6Q/seq-rerun-arguing-by-definition", "pageUrlRelative": "/posts/i2pFJiyqP3hzptB6Q/seq-rerun-arguing-by-definition", "linkUrl": "https://www.lesswrong.com/posts/i2pFJiyqP3hzptB6Q/seq-rerun-arguing-by-definition", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Arguing%20%22By%20Definition%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Arguing%20%22By%20Definition%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi2pFJiyqP3hzptB6Q%2Fseq-rerun-arguing-by-definition%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Arguing%20%22By%20Definition%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi2pFJiyqP3hzptB6Q%2Fseq-rerun-arguing-by-definition", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi2pFJiyqP3hzptB6Q%2Fseq-rerun-arguing-by-definition", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 248, "htmlBody": "<p>Today's post, <a href=\"/lw/nz/arguing_by_definition/\">Arguing \"By Definition\"</a> was originally published on 20 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You try to establish membership in an empirical cluster \"by definition\". You wouldn't feel the need to say, \"Hinduism, <em>by definition</em>, is a religion!\" because, well, of course Hinduism is a religion. It's not just a religion \"by definition\", it's, like, an actual religion. Atheism does not resemble the central members of the \"religion\" cluster, so if it wasn't for the fact that atheism is a religion <em>by definition</em>, you might go around thinking that atheism wasn't a religion. That's why you've got to crush all opposition by pointing out that \"Atheism is a religion\" is true <em>by definition</em>, because it isn't true any other way.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9se/seq_rerun_sneaking_in_connotations/\">Sneaking in Connotations</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "i2pFJiyqP3hzptB6Q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 8.434728782470082e-07, "legacy": true, "legacyId": "12706", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cFzC996D7Jjds3vS9", "Q689GXgBp5QiHztJB", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T05:00:29.170Z", "modifiedAt": null, "url": null, "title": "What are some cool things a LWer can do at Yale, Brown, and UChicago?", "slug": "what-are-some-cool-things-a-lwer-can-do-at-yale-brown-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.319Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/anhYTHEyjpNY9HmAH/what-are-some-cool-things-a-lwer-can-do-at-yale-brown-and", "pageUrlRelative": "/posts/anhYTHEyjpNY9HmAH/what-are-some-cool-things-a-lwer-can-do-at-yale-brown-and", "linkUrl": "https://www.lesswrong.com/posts/anhYTHEyjpNY9HmAH/what-are-some-cool-things-a-lwer-can-do-at-yale-brown-and", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20some%20cool%20things%20a%20LWer%20can%20do%20at%20Yale%2C%20Brown%2C%20and%20UChicago%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20some%20cool%20things%20a%20LWer%20can%20do%20at%20Yale%2C%20Brown%2C%20and%20UChicago%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FanhYTHEyjpNY9HmAH%2Fwhat-are-some-cool-things-a-lwer-can-do-at-yale-brown-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20some%20cool%20things%20a%20LWer%20can%20do%20at%20Yale%2C%20Brown%2C%20and%20UChicago%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FanhYTHEyjpNY9HmAH%2Fwhat-are-some-cool-things-a-lwer-can-do-at-yale-brown-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FanhYTHEyjpNY9HmAH%2Fwhat-are-some-cool-things-a-lwer-can-do-at-yale-brown-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<p>So I'm applying for grad schools right now, and am visiting Yale, Brown, and UChicago this month (I already got accepted into UChicago, and also got invited to expenses-paid visits to both Yale and Brown). I'm visiting Yale in just 2 days.</p>\n<p>So what are some cool things a LWer can do at those places? And which professors do research that a LWer could potentially find very interesting? Which universities would a LWer find himself/herself most at home at?</p>\n<p>Also, is there anything else I need to know about those places?</p>\n<p>I'm still waiting for decisions from Columbia and MIT (and got rejected by Caltech).&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "anhYTHEyjpNY9HmAH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 5, "extendedScore": null, "score": 8.435168798656822e-07, "legacy": true, "legacyId": "12707", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T07:49:11.625Z", "modifiedAt": null, "url": null, "title": "Online Meetups (Megameetup Telepresence Results)", "slug": "online-meetups-megameetup-telepresence-results", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.794Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2BNghYJziicmjG5Fp/online-meetups-megameetup-telepresence-results", "pageUrlRelative": "/posts/2BNghYJziicmjG5Fp/online-meetups-megameetup-telepresence-results", "linkUrl": "https://www.lesswrong.com/posts/2BNghYJziicmjG5Fp/online-meetups-megameetup-telepresence-results", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Online%20Meetups%20(Megameetup%20Telepresence%20Results)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOnline%20Meetups%20(Megameetup%20Telepresence%20Results)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2BNghYJziicmjG5Fp%2Fonline-meetups-megameetup-telepresence-results%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Online%20Meetups%20(Megameetup%20Telepresence%20Results)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2BNghYJziicmjG5Fp%2Fonline-meetups-megameetup-telepresence-results", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2BNghYJziicmjG5Fp%2Fonline-meetups-megameetup-telepresence-results", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 785, "htmlBody": "<p>Yesterday the East Coast Megameetup experimented with a Google Hangout that gave non-locals a chance to interact. Results were mixed. The hangout got off to a late start due to technical difficulties and insufficient redundant planning.&nbsp;</p>\n<p>Comments from the original discussion topic:</p>\n<p><strong style=\"font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px;\"><span class=\"author\" style=\"margin-top: 0px; margin-right: 10px; margin-bottom: 0px; margin-left: 0px;\"><a style=\"color: #538d4d; text-decoration: none;\" href=\"/user/Konkvistador/\">Konkvistador</a>:</span></strong></p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Pretty interesting demonstration of feasibility. It has convinced me that (small) virtual meets would be practical. If it wasn't for the late hour (and waking up my host for tonight) I'd probably stay around for a bit longer. I do wonder if anything like a rationality workshop or set of group exercises could be done in this way.</span></p>\n</blockquote>\n<p><strong style=\"font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px;\"><span class=\"author\" style=\"margin-top: 0px; margin-right: 10px; margin-bottom: 0px; margin-left: 0px;\"><a style=\"color: #538d4d; text-decoration: none;\" href=\"/user/juliawise/\">juliawise</a>:</span></strong></p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Feedback: I think the fun/interesting thing about being in a house with ~25 LessWrongers is being able to circulate around and jump in on conversations that sound interesting. Skype/google hangouts, however good the eventual sound quality, can't recreate this because you can only talk to the person who comes over to the screen. Even if they're talking about something besides the poor sound quality, it feels pretty forced. So I don't think technical fixes are going to improve the experience much.</span></p>\n</blockquote>\n<p>I believe Konkvistador showed up earlier in the day and Julia later.&nbsp;</p>\n<p>We ended up running three presentations between 4 PM and 6 PM (Nutrition, Leverage's Plan, and Consensus Techniques). Later we attempted to have group discussions that got the non-local people more involved. Anyone who attended, I'd appreciate feedback. My own impressions:</p>\n<p>1) Make sure you have a good, hardline internet connection. (We had this during the presentations, tried to move the laptops to a quieter room for discussion and found the intermittent disconnects to be unworkable)</p>\n<p>2) Telepresent Presentations are viable, but require better planning.</p>\n<p>The first two presentations seemed to go pretty well. The sound and video were not great, but the speaker could be understood and the powerpoints were simple white text on a black background, so they showed up reasonably on camera. The third speaker was a little quiet and the slides, while visible in the room, didn't show up very well (even using the screen-sharing capability - the image still turned out a little blurry).</p>\n<p>The computer was kept on mute, but we had two people engaging with the non-locals via chat. Non-locals could submit questions for us to read aloud, and then have the speaker respond to. This seemed like a workable format. Better audio/video would help it, and in the absence of better video, speakers should prepare extremely bold, easy to read presentations. We should also try to post those presentations online so people can download them and read them on their home computer in higher definition.</p>\n<p>3) Discussions between locals and nonlocals are not viable (and probably never will be).</p>\n<p>Julia's comment is spot on. I think the experience would be improved slightly by having a more focused, better prepared discussion, higher quality feed and displaying the Hangout people more prominently on a large screen with big speakers so people noticed them more. But it would still probably feel a little forced and awkward.</p>\n<p>4) PURELY online meetups may be viable</p>\n<p>While they never really engaged with the Megameetup, the people on the hangout did engage with each other. One of my motivations was to find a way to get Less Wrongers who are isolated geographically more involved in community. Konkvistador suggested small virtual meetups, and that sounds plausible to me. It was independently brought up during the Community discussion, by Aaron Tucker, who had briefly tried it in the past. It failed due to insufficient critical mass (I think there were never more than 2-3 people), and due to irregular scheduling. But if a group of Less Wrongers wanted to make a serious go at it I think it's workable.&nbsp;</p>\n<p>Designing virtual meetups would come with their own challenges. They'd still need a topic to remain focused (real-space meetups get much higher attendance when they have a specific task to address). Rationality workshops are one possibility.</p>\n<p>5) Other potential uses probably require a few more years before technology catches up.</p>\n<p>I think we could discover other uses for telepresence, but it would require some experimentation, and most of those experiments would fail, *in addition* to us still have to be dealing with poor sound quality and intermittent connections. I think the latter things will get solved by the progress of technology. I have vague ideas I'd like to explore, but I will probably wait a while.</p>\n<p>In the meantime, in summary:</p>\n<ul>\n<li>If you are doing presentations, consider adding Hangout capabilities, so long as you make sure to use big, bold text and have the presenters speak clearly.</li>\n<li>If enough people are interested in a regular online meetup group, and someone is willing to prepare topics on a regular basis, it is probably a good idea.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2BNghYJziicmjG5Fp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 8.435824664110923e-07, "legacy": true, "legacyId": "12708", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Yesterday the East Coast Megameetup experimented with a Google Hangout that gave non-locals a chance to interact. Results were mixed. The hangout got off to a late start due to technical difficulties and insufficient redundant planning.&nbsp;</p>\n<p>Comments from the original discussion topic:</p>\n<p><strong style=\"font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px;\" id=\"Konkvistador_\"><span class=\"author\" style=\"margin-top: 0px; margin-right: 10px; margin-bottom: 0px; margin-left: 0px;\"><a style=\"color: #538d4d; text-decoration: none;\" href=\"/user/Konkvistador/\">Konkvistador</a>:</span></strong></p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Pretty interesting demonstration of feasibility. It has convinced me that (small) virtual meets would be practical. If it wasn't for the late hour (and waking up my host for tonight) I'd probably stay around for a bit longer. I do wonder if anything like a rationality workshop or set of group exercises could be done in this way.</span></p>\n</blockquote>\n<p><strong style=\"font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px;\" id=\"juliawise_\"><span class=\"author\" style=\"margin-top: 0px; margin-right: 10px; margin-bottom: 0px; margin-left: 0px;\"><a style=\"color: #538d4d; text-decoration: none;\" href=\"/user/juliawise/\">juliawise</a>:</span></strong></p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Feedback: I think the fun/interesting thing about being in a house with ~25 LessWrongers is being able to circulate around and jump in on conversations that sound interesting. Skype/google hangouts, however good the eventual sound quality, can't recreate this because you can only talk to the person who comes over to the screen. Even if they're talking about something besides the poor sound quality, it feels pretty forced. So I don't think technical fixes are going to improve the experience much.</span></p>\n</blockquote>\n<p>I believe Konkvistador showed up earlier in the day and Julia later.&nbsp;</p>\n<p>We ended up running three presentations between 4 PM and 6 PM (Nutrition, Leverage's Plan, and Consensus Techniques). Later we attempted to have group discussions that got the non-local people more involved. Anyone who attended, I'd appreciate feedback. My own impressions:</p>\n<p>1) Make sure you have a good, hardline internet connection. (We had this during the presentations, tried to move the laptops to a quieter room for discussion and found the intermittent disconnects to be unworkable)</p>\n<p>2) Telepresent Presentations are viable, but require better planning.</p>\n<p>The first two presentations seemed to go pretty well. The sound and video were not great, but the speaker could be understood and the powerpoints were simple white text on a black background, so they showed up reasonably on camera. The third speaker was a little quiet and the slides, while visible in the room, didn't show up very well (even using the screen-sharing capability - the image still turned out a little blurry).</p>\n<p>The computer was kept on mute, but we had two people engaging with the non-locals via chat. Non-locals could submit questions for us to read aloud, and then have the speaker respond to. This seemed like a workable format. Better audio/video would help it, and in the absence of better video, speakers should prepare extremely bold, easy to read presentations. We should also try to post those presentations online so people can download them and read them on their home computer in higher definition.</p>\n<p>3) Discussions between locals and nonlocals are not viable (and probably never will be).</p>\n<p>Julia's comment is spot on. I think the experience would be improved slightly by having a more focused, better prepared discussion, higher quality feed and displaying the Hangout people more prominently on a large screen with big speakers so people noticed them more. But it would still probably feel a little forced and awkward.</p>\n<p>4) PURELY online meetups may be viable</p>\n<p>While they never really engaged with the Megameetup, the people on the hangout did engage with each other. One of my motivations was to find a way to get Less Wrongers who are isolated geographically more involved in community. Konkvistador suggested small virtual meetups, and that sounds plausible to me. It was independently brought up during the Community discussion, by Aaron Tucker, who had briefly tried it in the past. It failed due to insufficient critical mass (I think there were never more than 2-3 people), and due to irregular scheduling. But if a group of Less Wrongers wanted to make a serious go at it I think it's workable.&nbsp;</p>\n<p>Designing virtual meetups would come with their own challenges. They'd still need a topic to remain focused (real-space meetups get much higher attendance when they have a specific task to address). Rationality workshops are one possibility.</p>\n<p>5) Other potential uses probably require a few more years before technology catches up.</p>\n<p>I think we could discover other uses for telepresence, but it would require some experimentation, and most of those experiments would fail, *in addition* to us still have to be dealing with poor sound quality and intermittent connections. I think the latter things will get solved by the progress of technology. I have vague ideas I'd like to explore, but I will probably wait a while.</p>\n<p>In the meantime, in summary:</p>\n<ul>\n<li>If you are doing presentations, consider adding Hangout capabilities, so long as you make sure to use big, bold text and have the presenters speak clearly.</li>\n<li>If enough people are interested in a regular online meetup group, and someone is willing to prepare topics on a regular basis, it is probably a good idea.</li>\n</ul>", "sections": [{"title": "Konkvistador:", "anchor": "Konkvistador_", "level": 1}, {"title": "juliawise:", "anchor": "juliawise_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T08:07:39.264Z", "modifiedAt": null, "url": null, "title": "[Link] Cognitive Sciences Stack Exchange opened", "slug": "link-cognitive-sciences-stack-exchange-opened", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.346Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eYssXRkYeA9kFQjEa/link-cognitive-sciences-stack-exchange-opened", "pageUrlRelative": "/posts/eYssXRkYeA9kFQjEa/link-cognitive-sciences-stack-exchange-opened", "linkUrl": "https://www.lesswrong.com/posts/eYssXRkYeA9kFQjEa/link-cognitive-sciences-stack-exchange-opened", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Cognitive%20Sciences%20Stack%20Exchange%20opened&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Cognitive%20Sciences%20Stack%20Exchange%20opened%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYssXRkYeA9kFQjEa%2Flink-cognitive-sciences-stack-exchange-opened%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Cognitive%20Sciences%20Stack%20Exchange%20opened%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYssXRkYeA9kFQjEa%2Flink-cognitive-sciences-stack-exchange-opened", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYssXRkYeA9kFQjEa%2Flink-cognitive-sciences-stack-exchange-opened", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 229, "htmlBody": "<p>This is probably of interest to many here: <a href=\"http://cogsci.stackexchange.com/\">Cognitive Sciences Stack Exchange</a>.</p>\n<p>For those who aren't in the know, the <a href=\"http://stackexchange.com/\">Stack Exchange</a> family of forums is a set of sites where users may post questions and answers. They are divided by subject matter, each trying to collect a community of experts who can collectively answer any well-defined question relating to the domain. The <a href=\"http://stackexchange.com/about\">about Stack Exchange page</a> boasts that 90% of questions get great answers, \"often stunningly quickly\". Probably the most famous SE site is <a href=\"http://stackoverflow.com\">Stack Overflow</a>, the computer programming site that started it all.</p>\n<p>I find the creation of a Cogsci SE to be quite exciting, as it seems like it could quickly become an invaluable resource for anyone interested in the subject matter. I encourage people to take a look and contribute if they can, or lurk if they can't - there are a number of interesting questions and answers already. (For instance, I found <a href=\"http://cogsci.stackexchange.com/a/155/262\">this answer</a> about biofeedback quite interesting.) I already contributed <a href=\"http://cogsci.stackexchange.com/a/277/262\">one answer</a> myself.</p>\n<p>In addition to helping contribute to an improved understanding of cognitive science, this might also be a good opportunity for LWers to make a bit of a name for themselves among net-savvy cogsci academics. No idea if that's actually useful, but it might be a bit of a pleasant ego boost if you don't have anything better to do with your time. ;-)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zQw5d37qwzdpgQs5P": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eYssXRkYeA9kFQjEa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 28, "extendedScore": null, "score": 8.435896436917706e-07, "legacy": true, "legacyId": "12709", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T12:33:09.175Z", "modifiedAt": null, "url": null, "title": "What are you working on? February 2012", "slug": "what-are-you-working-on-february-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:55.898Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p6tQYahpdnmzBLm7C/what-are-you-working-on-february-2012", "pageUrlRelative": "/posts/p6tQYahpdnmzBLm7C/what-are-you-working-on-february-2012", "linkUrl": "https://www.lesswrong.com/posts/p6tQYahpdnmzBLm7C/what-are-you-working-on-february-2012", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20you%20working%20on%3F%20February%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20you%20working%20on%3F%20February%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp6tQYahpdnmzBLm7C%2Fwhat-are-you-working-on-february-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20you%20working%20on%3F%20February%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp6tQYahpdnmzBLm7C%2Fwhat-are-you-working-on-february-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp6tQYahpdnmzBLm7C%2Fwhat-are-you-working-on-february-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<div style=\"padding: 0.5em; margin: 8px;\">\n<p>This is the bimonthly 'What are you working On?' thread. Previous threads are <a href=\"/r/discussion/tag/waywo\">here</a>. So here's the question:</p>\n<p style=\"padding-left: 60px;\"><em>What are you working on?&nbsp;</em></p>\n<p>Here are some guidelines:</p>\n<ul>\n<li>Focus on projects that you have recently made progress on, not projects that you're thinking about doing but haven't started.</li>\n<li>Why this project and not others? Mention reasons why you're doing the project and/or why others should contribute to your project (if applicable).</li>\n<li>Talk about your goals for the project.</li>\n<li>Any kind of project is fair game: personal improvement, research project, art project, whatever.</li>\n<li>Link to your work if it's linkable.</li>\n</ul>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p6tQYahpdnmzBLm7C", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 12, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "12710", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 91, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T14:23:31.759Z", "modifiedAt": null, "url": null, "title": "February 2012 Media Thread", "slug": "february-2012-media-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:08.104Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TcdsvL5mj44NwgES4/february-2012-media-thread", "pageUrlRelative": "/posts/TcdsvL5mj44NwgES4/february-2012-media-thread", "linkUrl": "https://www.lesswrong.com/posts/TcdsvL5mj44NwgES4/february-2012-media-thread", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20February%202012%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFebruary%202012%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTcdsvL5mj44NwgES4%2Ffebruary-2012-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=February%202012%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTcdsvL5mj44NwgES4%2Ffebruary-2012-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTcdsvL5mj44NwgES4%2Ffebruary-2012-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 175, "htmlBody": "<p>There was a <a class=\"fullwidth\" title=\"recentdiscussion\" href=\"/lw/92w/are_yearlymonthly_book_suggestion_threads_a_good\" target=\"_blank\">recent discussion</a> considering the idea of a monthly Book (later expanded to movies, links, etc) thread. The poll was pretty unanimous (Both before and after I was <a href=\"/r/discussion/lw/9l7/whats_going_on_here/\">karmassassinated</a>) that this was A Good Idea (tm), and <a href=\"/lw/94z/january_2012_media_thread/\">daenerys's Janurary thread</a> (from which I obviously stole a lot of this) was fairly successful, so let's see if we actually need one per month.<br /><br />Post what you're reading or watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing!</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting; this is a thread for sharing subjective experiences, and people should feel comfortable posting their personal opinion without fearing a karma backlash. If you disagree with a person's recommendation, please post a comment to that effect.</li>\n<li>If you see something that has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please use the comment trees, which <a href=\"/lw/94z/january_2012_media_thread/5kos\">I was apparently too dumb to do</a>.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TcdsvL5mj44NwgES4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 8, "extendedScore": null, "score": 8.437358029764046e-07, "legacy": true, "legacyId": "12712", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 77, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["E8gc4H7Xorx4ebq8d", "gW6dww3TA9o8wLoh9", "xh3is79A7qkoMM6pu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T20:47:59.006Z", "modifiedAt": null, "url": null, "title": "Curious authors and 'zines?", "slug": "curious-authors-and-zines", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:37.818Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rH9SfZeQWncBw4kf5/curious-authors-and-zines", "pageUrlRelative": "/posts/rH9SfZeQWncBw4kf5/curious-authors-and-zines", "linkUrl": "https://www.lesswrong.com/posts/rH9SfZeQWncBw4kf5/curious-authors-and-zines", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Curious%20authors%20and%20'zines%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACurious%20authors%20and%20'zines%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrH9SfZeQWncBw4kf5%2Fcurious-authors-and-zines%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Curious%20authors%20and%20'zines%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrH9SfZeQWncBw4kf5%2Fcurious-authors-and-zines", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrH9SfZeQWncBw4kf5%2Fcurious-authors-and-zines", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<p>I sometimes enjoy investigative reporting and news analysis published at some of the leading 'zines: <em><a href=\"http://www.economist.com/\">The Economist</a></em>, <em><a href=\"http://www.theatlantic.com/\">The Atlantic</a></em>, <em><a href=\"http://www.wired.com/\">Wired</a></em>, <em><a href=\"http://www.businessweek.com/\">Businessweek</a></em>, <em><a href=\"http://www.salon.com/\">Salon</a></em>, <em><a href=\"http://www.newyorker.com/\">The New Yorker</a>. </em>(Note: I never <em>check</em>&nbsp;these sites; I just occasionally click through from other, more selective sources.)</p>\n<p>But I don't read <em>enough</em>&nbsp;stories to have found any that I'm confident are consistently driven by <a href=\"/lw/96j/what_curiosity_looks_like/\">genuine curiosity</a>. Imagine a webzine where stories are researched by a horde of&nbsp;<a href=\"http://www.gwern.net/\">gwern</a>&nbsp;uploads&nbsp;and written by a horde&nbsp;<a href=\"/lw/6ga/index_of_yvains_excellent_articles/\">Yvain</a>&nbsp;uploads.</p>\n<p>Can LWers recommend any consistently curious webzines/magazines, or at least some consistently curious authors?</p>\n<p>For example: <a href=\"http://www.salon.com/writer/glenn_greenwald/\">Glenn Greenwald</a> shows some promise, but I haven't had time to investigate. How about <a href=\"http://en.wikipedia.org/wiki/Seymour_Hersh\">Seymour Hersh</a>? <a href=\"http://en.wikipedia.org/wiki/Greg_Palast\">Greg Palast</a>? <a href=\"http://www.truthout.org/\"><em>TruthOut</em></a>? <em><a href=\"http://www.fair.org/blog/\">FAIR</a></em>?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rH9SfZeQWncBw4kf5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 8.438853446588551e-07, "legacy": true, "legacyId": "12714", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3oYaLja5h8qL5adDn", "xaLHeoRPdb9oQgDEy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T21:32:56.631Z", "modifiedAt": null, "url": null, "title": "Cargo Cult Language", "slug": "cargo-cult-language", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:01.403Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SaidAchmiz", "createdAt": "2010-05-21T05:41:51.970Z", "isAdmin": false, "displayName": "Said Achmiz"}, "userId": "mvf4xdfcGzPN8PsXM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iyfG8nYnnC58Rhrc8/cargo-cult-language", "pageUrlRelative": "/posts/iyfG8nYnnC58Rhrc8/cargo-cult-language", "linkUrl": "https://www.lesswrong.com/posts/iyfG8nYnnC58Rhrc8/cargo-cult-language", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cargo%20Cult%20Language&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACargo%20Cult%20Language%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiyfG8nYnnC58Rhrc8%2Fcargo-cult-language%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cargo%20Cult%20Language%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiyfG8nYnnC58Rhrc8%2Fcargo-cult-language", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiyfG8nYnnC58Rhrc8%2Fcargo-cult-language", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1327, "htmlBody": "<p>&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\">A <a title=\"Cargo cult &mdash; Wikipedia\" href=\"http://en.wikipedia.org/wiki/Cargo_cult\">cargo cult</a> is a religious practice based on imitating the behavior of more-advanced societies, without understanding its true nature or purpose, in the hope of receiving the apparent benefit of that behavior. Members of cargo cults &mdash; which have sprung up in a number of tribal societies following their interaction with modern cultures &mdash; build crude imitations of airstrips, radio towers, and the like, under the misapprehension that it&rsquo;s these rituals that magically attract airplanes full of material wealth (&ldquo;cargo&rdquo;) to land and deliver their goods.</span></p>\n<p class=\"p1\"><span class=\"s1\">The term has since been applied in other contexts. Richard Feynman spoke about &ldquo;<a title=\"Cargo cult science &mdash; Wikipedia\" href=\"http://en.wikipedia.org/wiki/Cargo_cult_science\">cargo cult science</a>&rdquo;, when scientists conduct research that superficially resembles the scientific method without any of the integrity and rigor that makes it a successful method of inquiry, and there is also &ldquo;<a title=\"Cargo cult programming &mdash; Wikipedia\" href=\"http://en.wikipedia.org/wiki/Cargo_cult_programming\">cargo cult programming</a>&rdquo;, when programmers include code in their programs without understanding its purpose, merely because they&rsquo;ve seen it used in examples or the programs of more experienced coders.</span></p>\n<p class=\"p1\"><span class=\"s1\">I now want to extend the metaphor to a certain sort of error in language use. Call it <em>cargo cult language</em>: using words or phrases, usually incorrectly, with no understanding of the origin of the words or their exact meaning, merely on the basis of having heard such constructions elsewhere in similar contexts.</span></p>\n<p class=\"p1\"><span class=\"s1\">Do not mistake my point for pedantic railing against mangled grammar, spelling, or pronunciation. Before I elaborate or provide examples, I&rsquo;d like to distinguish the thing I&rsquo;m talking about from two related, but subtly different, problems.</span></p>\n<p class=\"p1\"><span class=\"s1\">The first is errors of grammar or usage: <em>their/there/they&rsquo;re</em>; <em>would of/could of/should</em><em> of</em>; <em>can&rsquo;t hardly</em>; <em>alot</em>. In each case, the speaker or writer almost certainly knows what they mean to say; they are simply mistaken about the correct way to say it. Furthermore, the reader or listener is also unlikely to be confused for any longer than the time it takes to do a mental double-take at the misused word; the context almost always resolves the ambiguities created by such errors.</span></p>\n<p class=\"p2\">The second related but distinct problem is the sort of thing which George Orwell criticized in his essay &ldquo;<a title=\"Politics and the English Language &mdash; George Orwell\" href=\"http://www.mtholyoke.edu/acad/intrel/orwell46.htm\">Politics and the English Language</a>&rdquo;. Orwell wrote of stale, overused phrases, clich&eacute;s, and metaphors which take the place of clear language, and which can &ldquo;construct your sentences for you &mdash; even think your thoughts for you, to a certain extent&rdquo;. In such cases, the speaker or writer either has no precise meaning in mind, or wants, in some vague way, to say something, but lacks the command of language to say it clearly, without resorting to prefabricated phrases which convey nothing of substance.</p>\n<p class=\"p1\"><span class=\"s1\">What am I talking about, then?</span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\"><strong>comprise/compose/constitute</strong></span></p>\n<p class=\"p1\"><span class=\"s1\">These three words are often confused, with &ldquo;comprise&rdquo; being the most common offender as an erroneous replacement for the other two. Phrases like &ldquo;is comprised of&rdquo; are obviously wrong, but there are also constructions such as &ldquo;X comprises Y&rdquo;, which are grammatically correct, but whose meaning is inverted if the writer&rsquo;s intended meaning was &ldquo;compose&rdquo;. The cause of this sort of error seems to be a perception that &ldquo;comprise&rdquo; is a &ldquo;fancier&rdquo; word that has the same meaning as the other two.</span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\"><strong>accurate/precise</strong></span></p>\n<p class=\"p1\"><span class=\"s1\">These two words don&rsquo;t mean the same thing, but are often used interchangeably. Parsing a sentence that contains one of these often requires the reader to make some inference about the writer&rsquo;s background: a scientist who says &ldquo;precise&rdquo; means something quite different than if she were to say &ldquo;accurate&rdquo;, but your average news reporter is probably not packing any special meaning into his word choice when he says that something is &ldquo;precisely correct&rdquo;.</span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\"><strong>&rdquo;exponential increase&rdquo;</strong></span></p>\n<p class=\"p2\">Is the increase actually exponential rather than, say, polynomial, or does the speaker simply mean &ldquo;fast growth&rdquo;? It&rsquo;s often the latter; people say &ldquo;exponential&rdquo; because they&rsquo;ve heard the term used, somewhere, to describe fast growth, and it did not occur to them that it might have a very specific meaning. (We could also blame rampant innumeracy for this one.)</p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\"><strong>&rdquo;exception that proves the rule&rdquo;</strong></span></p>\n<p class=\"p1\"><span class=\"s1\">This example comes closest to falling into the Orwellian category I mentioned earlier, since the phrase is certainly a tired clich&eacute;, but it does have a concrete meaning: an exception which, by its existence, serves to underscore the rule. A sign that says &ldquo;free parking on Sundays&rdquo; does not have to add &ldquo;parking costs money on other days&rdquo; because the exception proves the rule.<sup><a href=\"#footnote1\">1</a></sup>&nbsp; The other usage, seemingly more common these days despite being quite nonsensical, takes the phrase to refer to any exception. It is clear in such cases that the speaker simply has no idea why they are using the phrase; imitation without understanding.</span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\">Cargo cult language can be distinguished from simple errors of grammar, usage, or style by considering the question: &ldquo;What do you mean by that?&rdquo; With a grammar error, the reader or listener almost always <em>does</em> knows what is meant. At most, there&rsquo;s a double-take, a mental stumble as the erroneous construction is parsed; but the meaning is usually not obscured. Use of cargo cult language, on the other hand, can introduce genuine ambiguities and block comprehension, especially because it often isn&rsquo;t clear whether the speaker really knows what he&rsquo;s saying and means to say it or is simply parroting.</span></p>\n<p class=\"p1\"><span class=\"s1\">In the Orwellian case, the words have lost their meaning, becoming empty platitudes. In the case of cargo cult language, on the other hand, the words <em>do</em> have a meaning, but the meaning is not what the speaker thinks; or he doesn&rsquo;t know the meaning, only using the phrase because he&rsquo;s heard it said in a similar context.</span></p>\n<p class=\"p1\"><span class=\"s1\">In my experience, cargo cult language turns up most often in technical conversations, and I do not think it is coincidence that the term &ldquo;cargo cult&rdquo; originated in the context of modern technology as seen by less-advanced societies, nor that its other two most common uses come from science and computer programming. It is related, I think, to the phenomena of <a title=\"Science as Attire &mdash; Less Wrong\" href=\"/lw/ir/science_as_attire/\">science as attire</a>&nbsp;and <a title=\"Fake Explanations &mdash; Less Wrong\" href=\"/lw/ip/fake_explanations/\">fake explanations</a>; an attitude of <a title=\"Magical thinking &mdash; Wikipedia\" href=\"http://en.wikipedia.org/wiki/Magical_thinking\">magical thinking</a>&nbsp;toward technical matters that treats the language of science and technology as a sort of ritual, in which you invoke certain phrases to lend authority to what you&rsquo;re saying, and where knowing exactly what the words mean is of secondary importance at best.</span></p>\n<p class=\"p1\"><span class=\"s1\">Cargo cult language is not limited to technical discourse, naturally. I suspect that most Internet debates are rife with examples, no matter the topic. In each case, it impedes comprehension, by making the reader doubt his understanding of what&rsquo;s being said, or, worse, by creating the illusion of transparency. Frustratingly, asking for clarification is often unhelpful; there&rsquo;s a clear loss of status in admitting that you have no idea what you&rsquo;re saying and are just parroting words to sound smart. Thus &ldquo;hmm, is that really what you meant to say?&rdquo; is often met with absurd arguments to the effect that no, this phrasing is not nonsensical after all, these words mean what I want them to, and who the hell are you to try to legislate usage, anyway?</span></p>\n<p class=\"p1\"><span class=\"s1\">A reasonable position to take, perhaps, if your interlocutor is merely insisting on adherence to some grammatical or stylistic standard. The tragedy of cargo cult language, however, is that there is a <a title=\"Fallacies of Compression &mdash; Less Wrong\" href=\"/lw/nw/fallacies_of_compression/\">difference in meaning</a> between the correct usage and the wrong one, and a <a title=\"The Virtue of Narrowness &mdash; Less Wrong\" href=\"/lw/ic/the_virtue_of_narrowness/\">loss of accuracy</a>&nbsp;due to conflating them. Fail to recognize this at your own peril.</span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\" style=\"font-size: smaller\"><sup><a name=\"footnote1\"></a>1</sup>&nbsp;There is also a secondary meaning: sometimes what at first <em>seems</em> to be an exception turns out, upon examination, to be an instance of the rule after all, thus confirming that there are no real exceptions and that the rule holds for all cases. &ldquo;Proves&rdquo; in such cases means something like &ldquo;tests&rdquo;, as in &ldquo;proving ground&rdquo;. (<a title=\"&quot;Exception that proves the rule&quot; &mdash; Wikipedia\" href=\"http://en.wikipedia.org/wiki/Exception_that_proves_the_rule\">http://en.wikipedia.org/wiki/Exception_that_proves_the_rule</a>) This is still completely different from the erroneous usage.</span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iyfG8nYnnC58Rhrc8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": -4, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "12715", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4Bwr6s9dofvqPWakn", "fysgqk4CjAwhBgNYT", "y5MxoeacRKKM3KQth", "yDfxTj9TKYsYiWH5o"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T22:02:00.819Z", "modifiedAt": null, "url": null, "title": "The Singularity Institute needs remote researchers (writing skill not required)", "slug": "the-singularity-institute-needs-remote-researchers-writing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:53.510Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LakrCAaj8rNss2q6j/the-singularity-institute-needs-remote-researchers-writing", "pageUrlRelative": "/posts/LakrCAaj8rNss2q6j/the-singularity-institute-needs-remote-researchers-writing", "linkUrl": "https://www.lesswrong.com/posts/LakrCAaj8rNss2q6j/the-singularity-institute-needs-remote-researchers-writing", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Singularity%20Institute%20needs%20remote%20researchers%20(writing%20skill%20not%20required)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Singularity%20Institute%20needs%20remote%20researchers%20(writing%20skill%20not%20required)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLakrCAaj8rNss2q6j%2Fthe-singularity-institute-needs-remote-researchers-writing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Singularity%20Institute%20needs%20remote%20researchers%20(writing%20skill%20not%20required)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLakrCAaj8rNss2q6j%2Fthe-singularity-institute-needs-remote-researchers-writing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLakrCAaj8rNss2q6j%2Fthe-singularity-institute-needs-remote-researchers-writing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 204, "htmlBody": "<p>The Singularity Institute needs researchers capable of doing literature searches, critically analyzing studies, and summarizing their findings. The fields involved are mostly psychology (biases and debiasing, effective learning, goal-directed behavior / self help), computer science (AI and AGI), technological forecasting, and existential risks.</p>\n<p>Gwern's work (e.g. on <a href=\"http://www.gwern.net/Sunk%20cost\">sunk costs</a> and <a href=\"http://www.gwern.net/Spaced%20repetition\">spaced repetition</a>) is near the&nbsp;<em>apex</em> of what we need, but you don't need to be <em>as</em> skilled as Gwern or write as much as he does to do most of the work that we need.</p>\n<p>Pay is hourly and starts at $14/hr but that will rise if the product is good. You must be available to work at least 20 hrs/week to be considered.</p>\n<p>Perks:</p>\n<ul>\n<li>Work from home, with flexible hours.</li>\n<li>Age and credentials are irrelevant; only the product matters.</li>\n<li>Get paid to research things you're probably interested in anyway.</li>\n<li>Contribute to human knowledge in immediately actionable ways. We need this research because we're about to <em>act</em>&nbsp;on it. Your work will not fall into the journal abyss that most academic research falls into.</li>\n</ul>\n<p>If you're interested, <strong><a href=\"http://tinyurl.com/remote-researchers\">apply here</a></strong>.</p>\n<p>Why post this job ad on LessWrong? We need people with some measure of <a href=\"/lw/96j/what_curiosity_looks_like/\">genuine curiosity</a>.</p>\n<p>Also see <a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">Scholarship: How to Do It Efficiently</a>.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NrvXXL3iGjjxu5B7d": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LakrCAaj8rNss2q6j", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 68, "baseScore": 87, "extendedScore": null, "score": 8.439141456759761e-07, "legacy": true, "legacyId": "12716", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-06-28T18:19:20.535Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": true, "hideFrontpageComments": false, "maxBaseScore": 65, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3oYaLja5h8qL5adDn", "37sHjeisS9uJufi4u"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-05T22:13:47.363Z", "modifiedAt": null, "url": null, "title": "How can people be actually converted?", "slug": "how-can-people-be-actually-converted", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.236Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "yttrium", "createdAt": "2011-11-26T23:30:29.876Z", "isAdmin": false, "displayName": "yttrium"}, "userId": "BBzE4abSkhSfkQ89D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/scXwLJwnyAB6AnQwZ/how-can-people-be-actually-converted", "pageUrlRelative": "/posts/scXwLJwnyAB6AnQwZ/how-can-people-be-actually-converted", "linkUrl": "https://www.lesswrong.com/posts/scXwLJwnyAB6AnQwZ/how-can-people-be-actually-converted", "postedAtFormatted": "Sunday, February 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20can%20people%20be%20actually%20converted%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20can%20people%20be%20actually%20converted%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscXwLJwnyAB6AnQwZ%2Fhow-can-people-be-actually-converted%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20can%20people%20be%20actually%20converted%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscXwLJwnyAB6AnQwZ%2Fhow-can-people-be-actually-converted", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscXwLJwnyAB6AnQwZ%2Fhow-can-people-be-actually-converted", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 86, "htmlBody": "<p>Have you ever convinced a religious person to become atheistic? How did you do this? How long did it take? Were the people in some sort of life crisis, or were they just living along?</p>\n<p>This is probably a quite difficult task of persuasion. So stories how people were successful at it could be very interesting to improve ones' persuasion abilities.</p>\n<p>Relatedly, it might be interesting to know what religious groups have gathered on techniques to convert people to their religion - are there some manuals/techniques floating around?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "scXwLJwnyAB6AnQwZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 6, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "12718", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 94, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T00:03:29.153Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Where to Draw the Boundary?", "slug": "seq-rerun-where-to-draw-the-boundary", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:54.883Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B6JRMAC6565BvWknT/seq-rerun-where-to-draw-the-boundary", "pageUrlRelative": "/posts/B6JRMAC6565BvWknT/seq-rerun-where-to-draw-the-boundary", "linkUrl": "https://www.lesswrong.com/posts/B6JRMAC6565BvWknT/seq-rerun-where-to-draw-the-boundary", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Where%20to%20Draw%20the%20Boundary%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Where%20to%20Draw%20the%20Boundary%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB6JRMAC6565BvWknT%2Fseq-rerun-where-to-draw-the-boundary%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Where%20to%20Draw%20the%20Boundary%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB6JRMAC6565BvWknT%2Fseq-rerun-where-to-draw-the-boundary", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB6JRMAC6565BvWknT%2Fseq-rerun-where-to-draw-the-boundary", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 228, "htmlBody": "<p>Today's post, <a href=\"/lw/o0/where_to_draw_the_boundary/\">Where to Draw the Boundary?</a> was originally published on 21 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Your definition draws a boundary around things that don't really belong together. You can claim, if you like, that you are defining the word \"fish\" to refer to salmon, guppies, sharks, dolphins, and trout, but not jellyfish or algae. You can claim, if you like, that this is merely a list, and there is no way a list can be \"wrong\". Or you can stop playing nitwit games and admit that you made a mistake and that dolphins don't belong on the fish list.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9sy/seq_rerun_arguing_by_definition/\">Arguing \"By Definition\"</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B6JRMAC6565BvWknT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.439614075114115e-07, "legacy": true, "legacyId": "12719", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d5NyJ2Lf6N22AD9PB", "i2pFJiyqP3hzptB6Q", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T01:45:11.719Z", "modifiedAt": null, "url": null, "title": "Which College Major?", "slug": "which-college-major", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.185Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "eggman", "createdAt": "2011-10-09T00:24:15.183Z", "isAdmin": false, "displayName": "eggman"}, "userId": "irkySx7hExrK2XG53", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iRSkafaAMhEFiWqXx/which-college-major", "pageUrlRelative": "/posts/iRSkafaAMhEFiWqXx/which-college-major", "linkUrl": "https://www.lesswrong.com/posts/iRSkafaAMhEFiWqXx/which-college-major", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Which%20College%20Major%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhich%20College%20Major%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiRSkafaAMhEFiWqXx%2Fwhich-college-major%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Which%20College%20Major%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiRSkafaAMhEFiWqXx%2Fwhich-college-major", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiRSkafaAMhEFiWqXx%2Fwhich-college-major", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 171, "htmlBody": "<p>N.B.: This discussion isn't up for mainstream article status, as far as I'm concerned (unless someone else wants to take it and run with it). I just didn't know how else to direct an important question to the LW community in general.</p>\n<p>I'm currently a first-year university student in Vancouver, Canada, attending UBC. I have a trust fund and otherwise I will not need to worry about paying for my undergraduate degree. I am open to the idea of going to grad school. So, I have the luxury to take my time in my studies and there are lots of options I can choose from. Majors I'm considering are Cognitive Systems, Economics (and philosophy or math or stats), English, Philosophy and History of Science, Mathematical Sciences/CompSci, or Psychology. I'm open to other options. So, have at it with your suggestions.</p>\n<p>Specific Questions:</p>\n<p>Should I care more about making money or doing something that I have a \"passion\" for?</p>\n<p>How will this allow me to maximize my production of utilons?</p>\n<p>What else should I keep in mind?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iRSkafaAMhEFiWqXx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 8, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "12733", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T03:56:42.124Z", "modifiedAt": null, "url": null, "title": "Meetup : Salt Lake City Meetup #3 - Bayesian reasoning in everyday life", "slug": "meetup-salt-lake-city-meetup-3-bayesian-reasoning-in", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.136Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "adamisom", "createdAt": "2011-06-13T03:19:15.520Z", "isAdmin": false, "displayName": "adamisom"}, "userId": "eT8NPFmc2GDb5QFfc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MSGtuT92NM6coGg2Z/meetup-salt-lake-city-meetup-3-bayesian-reasoning-in", "pageUrlRelative": "/posts/MSGtuT92NM6coGg2Z/meetup-salt-lake-city-meetup-3-bayesian-reasoning-in", "linkUrl": "https://www.lesswrong.com/posts/MSGtuT92NM6coGg2Z/meetup-salt-lake-city-meetup-3-bayesian-reasoning-in", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Salt%20Lake%20City%20Meetup%20%233%20-%20Bayesian%20reasoning%20in%20everyday%20life&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Salt%20Lake%20City%20Meetup%20%233%20-%20Bayesian%20reasoning%20in%20everyday%20life%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMSGtuT92NM6coGg2Z%2Fmeetup-salt-lake-city-meetup-3-bayesian-reasoning-in%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Salt%20Lake%20City%20Meetup%20%233%20-%20Bayesian%20reasoning%20in%20everyday%20life%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMSGtuT92NM6coGg2Z%2Fmeetup-salt-lake-city-meetup-3-bayesian-reasoning-in", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMSGtuT92NM6coGg2Z%2Fmeetup-salt-lake-city-meetup-3-bayesian-reasoning-in", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 121, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6p'>Salt Lake City Meetup #3 - Bayesian reasoning in everyday life</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 February 2012 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">810 E 3300 S</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Future MeetUps, after the 4th, won't be announced here, because there's a Site for that:\nhttps://sites.google.com/site/lesswrongsaltlakecity\nThere is also a discussion forum, which is embedded into the SIte.</p>\n\n<p>The actual Meetup #3 is this Saturday (the 18th) from 3:00-4:30 pm at Calvin S Smith Library. More info can be found on the Site.</p>\n\n<p>In order to make comments or other edits to the Site, you will need to email me or join the Google Group so I can add you.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6p'>Salt Lake City Meetup #3 - Bayesian reasoning in everyday life</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MSGtuT92NM6coGg2Z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 8.440521590997329e-07, "legacy": true, "legacyId": "12742", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__3___Bayesian_reasoning_in_everyday_life\">Discussion article for the meetup : <a href=\"/meetups/6p\">Salt Lake City Meetup #3 - Bayesian reasoning in everyday life</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 February 2012 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">810 E 3300 S</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Future MeetUps, after the 4th, won't be announced here, because there's a Site for that:\nhttps://sites.google.com/site/lesswrongsaltlakecity\nThere is also a discussion forum, which is embedded into the SIte.</p>\n\n<p>The actual Meetup #3 is this Saturday (the 18th) from 3:00-4:30 pm at Calvin S Smith Library. More info can be found on the Site.</p>\n\n<p>In order to make comments or other edits to the Site, you will need to email me or join the Google Group so I can add you.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__3___Bayesian_reasoning_in_everyday_life1\">Discussion article for the meetup : <a href=\"/meetups/6p\">Salt Lake City Meetup #3 - Bayesian reasoning in everyday life</a></h2>", "sections": [{"title": "Discussion article for the meetup : Salt Lake City Meetup #3 - Bayesian reasoning in everyday life", "anchor": "Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__3___Bayesian_reasoning_in_everyday_life", "level": 1}, {"title": "Discussion article for the meetup : Salt Lake City Meetup #3 - Bayesian reasoning in everyday life", "anchor": "Discussion_article_for_the_meetup___Salt_Lake_City_Meetup__3___Bayesian_reasoning_in_everyday_life1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T04:12:39.976Z", "modifiedAt": null, "url": null, "title": "Sticky threads?", "slug": "sticky-threads", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.945Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Anubhav", "createdAt": "2012-01-05T10:50:52.734Z", "isAdmin": false, "displayName": "Anubhav"}, "userId": "pe9DTYwyvLCZPzsPf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/reTSAg8usSfvErtyL/sticky-threads", "pageUrlRelative": "/posts/reTSAg8usSfvErtyL/sticky-threads", "linkUrl": "https://www.lesswrong.com/posts/reTSAg8usSfvErtyL/sticky-threads", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sticky%20threads%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASticky%20threads%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreTSAg8usSfvErtyL%2Fsticky-threads%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sticky%20threads%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreTSAg8usSfvErtyL%2Fsticky-threads", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreTSAg8usSfvErtyL%2Fsticky-threads", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 129, "htmlBody": "<p>It annoys me that there's no way to sticky a thread in the discussion section.&nbsp;</p>\n<p>Therefore, I propose creating an <strong>LW wiki page called \"Stickies\"</strong>, where sticky-worthy threads would be linked to. Would that be acceptable?</p>\n<p>These are the threads I'm planning to add:&nbsp;</p>\n<ul>\n<li>the current&nbsp;<a href=\"/lw/90l/welcome_to_less_wrong_2012/\">Welcome to LW thread</a></li>\n<li>the current&nbsp;<a href=\"/lw/7jd/harry_potter_and_the_methods_of_rationality/\">MoR Discussion thread</a></li>\n<li>the current&nbsp;<a href=\"/lw/9pk/rationality_quotes_february_2012/\">Rationality Quotes thread</a>&nbsp;(OK, they're posted in Main, but still...)</li>\n<li>the current <a href=\"/r/discussion/lw/9p9/open_thread_february_114_2012/\">Open Thread</a></li>\n<li>the current <a href=\"/r/discussion/lw/9t4/february_2012_media_thread/\">Media Thread</a></li>\n<li>the current <a href=\"/r/discussion/lw/9t2/what_are_you_working_on_february_2012/\">'What are you working on?' thread</a></li>\n</ul>\n<p><strong>ETA</strong>: Following a <a href=\"/r/discussion/lw/9tz/sticky_threads/5u86\">tip-off</a> by peaigr, I re-purposed the <a href=\"http://wiki.lesswrong.com/wiki/Special_threads\">Special Threads</a> wiki page for this. (The stickies are in the 'periodic threads' section.) Now if there were a way to make this page more conspicuous...</p>\n<p>Meanwhile, dbaupp has <a href=\"/r/discussion/lw/9tz/sticky_threads/5u8i\">submitted</a> a <a href=\"https://code.google.com/p/lesswrong/issues/detail?id=283\">feature request</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "reTSAg8usSfvErtyL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 40, "extendedScore": null, "score": 0.000143, "legacy": true, "legacyId": "12743", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Jztohmx2anxGnp7g9", "WQ7XMjqvuRRj8nkpu", "rAi9RSM5SYd2Pto4q", "gowLWvZfri5XKiy9n", "TcdsvL5mj44NwgES4", "p6tQYahpdnmzBLm7C"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T11:53:36.416Z", "modifiedAt": null, "url": null, "title": "[LINK] Autistic woman banned from having sex in latest Court of Protection case", "slug": "link-autistic-woman-banned-from-having-sex-in-latest-court", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:56.891Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "mstevens", "createdAt": "2009-05-07T14:46:38.489Z", "isAdmin": false, "displayName": "mstevens"}, "userId": "wgKFztEMLyjFRm4ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xGikh7jL3fkej3sMv/link-autistic-woman-banned-from-having-sex-in-latest-court", "pageUrlRelative": "/posts/xGikh7jL3fkej3sMv/link-autistic-woman-banned-from-having-sex-in-latest-court", "linkUrl": "https://www.lesswrong.com/posts/xGikh7jL3fkej3sMv/link-autistic-woman-banned-from-having-sex-in-latest-court", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Autistic%20woman%20banned%20from%20having%20sex%20in%20latest%20Court%20of%20Protection%20case&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Autistic%20woman%20banned%20from%20having%20sex%20in%20latest%20Court%20of%20Protection%20case%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxGikh7jL3fkej3sMv%2Flink-autistic-woman-banned-from-having-sex-in-latest-court%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Autistic%20woman%20banned%20from%20having%20sex%20in%20latest%20Court%20of%20Protection%20case%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxGikh7jL3fkej3sMv%2Flink-autistic-woman-banned-from-having-sex-in-latest-court", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxGikh7jL3fkej3sMv%2Flink-autistic-woman-banned-from-having-sex-in-latest-court", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<p><a href=\"http://www.telegraph.co.uk/news/newstopics/lawreports/9059808/Autistic-woman-banned-from-having-sex-in-latest-Court-of-Protection-case.html\">Autistic woman banned from having sex in latest Court of Protection case</a></p>\n<p>This reminded me of previous LW comments about how we <a href=\"/lw/9em/open_thread_january_1531_2012/5og2\">restrict the rights of children for their own good</a>.</p>\n<p>On the one hand, children can't understand the risks so we stop them having sex.</p>\n<p>But on the other hand, animals can't understand the risks and we happily let them continue having sex.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xGikh7jL3fkej3sMv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": -12, "extendedScore": null, "score": 8.442377914638054e-07, "legacy": true, "legacyId": "12758", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T16:33:38.805Z", "modifiedAt": null, "url": null, "title": "[LINK] Freakonomics on the Potential of a US-based Prediction Market", "slug": "link-freakonomics-on-the-potential-of-a-us-based-prediction", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.169Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8ScZLFL5M8N3veanx/link-freakonomics-on-the-potential-of-a-us-based-prediction", "pageUrlRelative": "/posts/8ScZLFL5M8N3veanx/link-freakonomics-on-the-potential-of-a-us-based-prediction", "linkUrl": "https://www.lesswrong.com/posts/8ScZLFL5M8N3veanx/link-freakonomics-on-the-potential-of-a-us-based-prediction", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Freakonomics%20on%20the%20Potential%20of%20a%20US-based%20Prediction%20Market&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Freakonomics%20on%20the%20Potential%20of%20a%20US-based%20Prediction%20Market%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ScZLFL5M8N3veanx%2Flink-freakonomics-on-the-potential-of-a-us-based-prediction%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Freakonomics%20on%20the%20Potential%20of%20a%20US-based%20Prediction%20Market%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ScZLFL5M8N3veanx%2Flink-freakonomics-on-the-potential-of-a-us-based-prediction", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ScZLFL5M8N3veanx%2Flink-freakonomics-on-the-potential-of-a-us-based-prediction", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5, "htmlBody": "<p>Article can be found <a href=\"http://www.freakonomics.com/2012/02/02/the-politics-of-political-prediction-markets/\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8ScZLFL5M8N3veanx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 0, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "12759", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T17:37:25.968Z", "modifiedAt": null, "url": null, "title": "[Poll] Method of Recruitment", "slug": "poll-method-of-recruitment", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:56.452Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B2yK3R2QqgprTL4ao/poll-method-of-recruitment", "pageUrlRelative": "/posts/B2yK3R2QqgprTL4ao/poll-method-of-recruitment", "linkUrl": "https://www.lesswrong.com/posts/B2yK3R2QqgprTL4ao/poll-method-of-recruitment", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BPoll%5D%20Method%20of%20Recruitment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BPoll%5D%20Method%20of%20Recruitment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB2yK3R2QqgprTL4ao%2Fpoll-method-of-recruitment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BPoll%5D%20Method%20of%20Recruitment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB2yK3R2QqgprTL4ao%2Fpoll-method-of-recruitment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB2yK3R2QqgprTL4ao%2Fpoll-method-of-recruitment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<p>In another thread, we have been discussing how people (especially female people) have come to find out about LessWrong. Instead of just guessing, I figured I would make a poll.</p>\n<p>I remember in recent history there was a thread on the subject, but the answers were mainly \"I got here from HPMoR\" or \"I've been here since OB\". However, the question I want answered is:</p>\n<p><strong>How did you find HPMoR or OB in the first place?</strong></p>\n<p>Were you referred by a friend? Were you searching the internet for keywords like \"rationality\"? Were you linked from some other site you read?</p>\n<p><strong>Please answer! Even if you are a lurker; ESPECIALLY if you are a female reader! </strong>(There is a question where you can say you are a lurker, if you like!)</p>\n<p>&nbsp;</p>\n<p><a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dGEwaC1fMDVvTTc3Yk9jbXlxWXdBZHc6MQ\" target=\"_blank\"><strong>Click here to take the poll!</strong></a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>ETA- female *reader* and female *people*</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B2yK3R2QqgprTL4ao", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 12, "extendedScore": null, "score": 8.443716685190627e-07, "legacy": true, "legacyId": "12760", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 93, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T21:59:52.817Z", "modifiedAt": null, "url": null, "title": "\"Ask for help on your project\" open thread", "slug": "ask-for-help-on-your-project-open-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.251Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EL7Cui98uKYMFrDBN/ask-for-help-on-your-project-open-thread", "pageUrlRelative": "/posts/EL7Cui98uKYMFrDBN/ask-for-help-on-your-project-open-thread", "linkUrl": "https://www.lesswrong.com/posts/EL7Cui98uKYMFrDBN/ask-for-help-on-your-project-open-thread", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Ask%20for%20help%20on%20your%20project%22%20open%20thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Ask%20for%20help%20on%20your%20project%22%20open%20thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEL7Cui98uKYMFrDBN%2Fask-for-help-on-your-project-open-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Ask%20for%20help%20on%20your%20project%22%20open%20thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEL7Cui98uKYMFrDBN%2Fask-for-help-on-your-project-open-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEL7Cui98uKYMFrDBN%2Fask-for-help-on-your-project-open-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 28, "htmlBody": "<p>Quite a few of us are <a href=\"/r/discussion/lw/9t2/what_are_you_working_on_february_2012/\">working on interesting projects</a>; many of those are solo, but some could maybe use some help. So here's the place to ask!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EL7Cui98uKYMFrDBN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 8.44473884183116e-07, "legacy": true, "legacyId": "12762", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["p6tQYahpdnmzBLm7C"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-06T22:02:47.520Z", "modifiedAt": null, "url": null, "title": "Google Solve for X", "slug": "google-solve-for-x", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.135Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "AwKWizqg2aqf7D9ii", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yRfv5EfuLXF5ZrR2F/google-solve-for-x", "pageUrlRelative": "/posts/yRfv5EfuLXF5ZrR2F/google-solve-for-x", "linkUrl": "https://www.lesswrong.com/posts/yRfv5EfuLXF5ZrR2F/google-solve-for-x", "postedAtFormatted": "Monday, February 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Google%20Solve%20for%20X&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGoogle%20Solve%20for%20X%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRfv5EfuLXF5ZrR2F%2Fgoogle-solve-for-x%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Google%20Solve%20for%20X%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRfv5EfuLXF5ZrR2F%2Fgoogle-solve-for-x", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRfv5EfuLXF5ZrR2F%2Fgoogle-solve-for-x", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<p>Google seems to be establishing a presence for discussing \"radical technology ideas for solving global problems\" at <a href=\"http://www.wesolveforx.com\">Solve for X</a>. I thought there might be some overlap of ideas here, so this is for anyone that hasn't already seen it elsewhere. It might just be hype, though. (I'm inclined to think it probably is, but that may be my cynical side talking. Take everything it says with a grain of salt.)</p>\n<p>There doesn't seem to be much more to say about the site at the moment.</p>\n<p>Edit: Video presentations are starting to appear <a href=\"http://www.youtube.com/user/wesolveforx\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yRfv5EfuLXF5ZrR2F", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 8.444750183219739e-07, "legacy": true, "legacyId": "12761", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-07T02:28:48.631Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup 02-08-2012", "slug": "meetup-west-la-meetup-02-08-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:56.934Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7k5Lymg58FoLpbN5A/meetup-west-la-meetup-02-08-2012", "pageUrlRelative": "/posts/7k5Lymg58FoLpbN5A/meetup-west-la-meetup-02-08-2012", "linkUrl": "https://www.lesswrong.com/posts/7k5Lymg58FoLpbN5A/meetup-west-la-meetup-02-08-2012", "postedAtFormatted": "Tuesday, February 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%2002-08-2012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%2002-08-2012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7k5Lymg58FoLpbN5A%2Fmeetup-west-la-meetup-02-08-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%2002-08-2012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7k5Lymg58FoLpbN5A%2Fmeetup-west-la-meetup-02-08-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7k5Lymg58FoLpbN5A%2Fmeetup-west-la-meetup-02-08-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 195, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6q'>West LA Meetup 02-08-2012</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">08 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, February 8th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Activity:</strong> Cognitive Biases Round-robin. Choose at least one item from Wikipedia's <a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow\">List of Cognitive Biases</a>, and read up on it enough to introduce the topic to the group. Then, as a group, we will try to identify real-life situations where the bias would come into play, how it could be harmful, when it doesn't matter (or even helps!), and how to counter or use it.</p>\n\n<p>This is also a good time to browse <a href=\"http://lesswrong.com/recentposts\">recent posts</a>, especially those that pertain to our activity!</p>\n\n<p>Don't worry if you don't have time to read anything, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6q'>West LA Meetup 02-08-2012</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7k5Lymg58FoLpbN5A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 8.445786472266512e-07, "legacy": true, "legacyId": "12779", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_02_08_2012\">Discussion article for the meetup : <a href=\"/meetups/6q\">West LA Meetup 02-08-2012</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">08 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, February 8th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Activity:</strong> Cognitive Biases Round-robin. Choose at least one item from Wikipedia's <a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow\">List of Cognitive Biases</a>, and read up on it enough to introduce the topic to the group. Then, as a group, we will try to identify real-life situations where the bias would come into play, how it could be harmful, when it doesn't matter (or even helps!), and how to counter or use it.</p>\n\n<p>This is also a good time to browse <a href=\"http://lesswrong.com/recentposts\">recent posts</a>, especially those that pertain to our activity!</p>\n\n<p>Don't worry if you don't have time to read anything, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_02_08_20121\">Discussion article for the meetup : <a href=\"/meetups/6q\">West LA Meetup 02-08-2012</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup 02-08-2012", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_02_08_2012", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup 02-08-2012", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_02_08_20121", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-07T03:40:39.734Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Entropy, and Short Codes", "slug": "seq-rerun-entropy-and-short-codes", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C42RTgvh2FespQFCa/seq-rerun-entropy-and-short-codes", "pageUrlRelative": "/posts/C42RTgvh2FespQFCa/seq-rerun-entropy-and-short-codes", "linkUrl": "https://www.lesswrong.com/posts/C42RTgvh2FespQFCa/seq-rerun-entropy-and-short-codes", "postedAtFormatted": "Tuesday, February 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Entropy%2C%20and%20Short%20Codes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Entropy%2C%20and%20Short%20Codes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC42RTgvh2FespQFCa%2Fseq-rerun-entropy-and-short-codes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Entropy%2C%20and%20Short%20Codes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC42RTgvh2FespQFCa%2Fseq-rerun-entropy-and-short-codes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC42RTgvh2FespQFCa%2Fseq-rerun-entropy-and-short-codes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<p>Today's post, <a href=\"/lw/o1/entropy_and_short_codes/\">Entropy, and Short Codes</a> was originally published on 23 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You use a short word for something that you won't need to describe often, or a long word for something you'll need to describe often. This can result in inefficient thinking, or even misapplications of Occam's Razor, if your mind thinks that short sentences sound \"simpler\". Which sounds more plausible, \"God did a miracle\" or \"A supernatural universe-creating entity temporarily suspended the laws of physics\"?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9tb/seq_rerun_where_to_draw_the_boundary/\">Where to Draw the Boundary?</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C42RTgvh2FespQFCa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.446066412656366e-07, "legacy": true, "legacyId": "12786", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["soQX8yXLbKy7cFvy8", "B6JRMAC6565BvWknT", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-07T08:04:32.886Z", "modifiedAt": null, "url": null, "title": "Forthcoming and desired articles on AI risk [link]", "slug": "forthcoming-and-desired-articles-on-ai-risk-link", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MhmTzrYKaXJemuCPh/forthcoming-and-desired-articles-on-ai-risk-link", "pageUrlRelative": "/posts/MhmTzrYKaXJemuCPh/forthcoming-and-desired-articles-on-ai-risk-link", "linkUrl": "https://www.lesswrong.com/posts/MhmTzrYKaXJemuCPh/forthcoming-and-desired-articles-on-ai-risk-link", "postedAtFormatted": "Tuesday, February 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Forthcoming%20and%20desired%20articles%20on%20AI%20risk%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AForthcoming%20and%20desired%20articles%20on%20AI%20risk%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMhmTzrYKaXJemuCPh%2Fforthcoming-and-desired-articles-on-ai-risk-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Forthcoming%20and%20desired%20articles%20on%20AI%20risk%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMhmTzrYKaXJemuCPh%2Fforthcoming-and-desired-articles-on-ai-risk-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMhmTzrYKaXJemuCPh%2Fforthcoming-and-desired-articles-on-ai-risk-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3, "htmlBody": "<p>Continuously updated <a href=\"http://tinyurl.com/ai-risk-research\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MhmTzrYKaXJemuCPh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 16, "extendedScore": null, "score": 8.447094676969773e-07, "legacy": true, "legacyId": "12800", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-07T09:45:38.304Z", "modifiedAt": null, "url": null, "title": "Diseased disciplines: the strange case of the inverted chart", "slug": "diseased-disciplines-the-strange-case-of-the-inverted-chart", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.248Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Morendil", "createdAt": "2009-09-21T16:34:39.505Z", "isAdmin": false, "displayName": "Morendil"}, "userId": "aDcxmpDTkqN6vWmRZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4ACmfJkXQxkYacdLt/diseased-disciplines-the-strange-case-of-the-inverted-chart", "pageUrlRelative": "/posts/4ACmfJkXQxkYacdLt/diseased-disciplines-the-strange-case-of-the-inverted-chart", "linkUrl": "https://www.lesswrong.com/posts/4ACmfJkXQxkYacdLt/diseased-disciplines-the-strange-case-of-the-inverted-chart", "postedAtFormatted": "Tuesday, February 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Diseased%20disciplines%3A%20the%20strange%20case%20of%20the%20inverted%20chart&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADiseased%20disciplines%3A%20the%20strange%20case%20of%20the%20inverted%20chart%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ACmfJkXQxkYacdLt%2Fdiseased-disciplines-the-strange-case-of-the-inverted-chart%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Diseased%20disciplines%3A%20the%20strange%20case%20of%20the%20inverted%20chart%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ACmfJkXQxkYacdLt%2Fdiseased-disciplines-the-strange-case-of-the-inverted-chart", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ACmfJkXQxkYacdLt%2Fdiseased-disciplines-the-strange-case-of-the-inverted-chart", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1179, "htmlBody": "<p>Imagine the following situation: you have come across numerous references to a paper purporting to show that the chances of successfully treating a disease <strong>contracted at age 10</strong> are substantially lower if the disease is <strong>detected later</strong>: somewhat lower at age 20 to very poor at age 50. Every author draws more or less the same bar chart to depict this situation: the picture below, showing <strong>rising</strong> mortality from left to right.</p>\n<p style=\"text-align:center\"><img style=\"vertical-align: middle;\" src=\"http://i.imgur.com/WTivO.png\" alt=\"Rising mortality, left to right\" width=\"372\" height=\"252\" /></p>\n<p>You search for the original paper, which proves a long quest: the conference publisher have lost some of their archives in several moves, several people citing the paper turn out to no longer have a copy, etc. You finally locate a copy of the paper (let's call it G99) thanks to a helpful friend with great scholarly connections.</p>\n<p>And you find out some interesting things.</p>\n<p>The most striking is what the author's original chart depicts: the chances of successfully treating the disease <strong>detected at age 50</strong> become substantially lower as a function of <strong>age when it was contracted</strong>; mortality is highest if the disease was contracted at age 10 and lowest if contracted at age 40. The chart showing this is the picture below, showing <strong>decreasing</strong> mortality from top to bottom, for the same ages on the vertical axis.</p>\n<p style=\"text-align:center\"><img style=\"vertical-align: middle\" src=\"http://i.imgur.com/38aQu.png\" alt=\"Decreasing mortality, top to bottom\" width=\"323\" height=\"192\" /></p>\n<p>Not only is the representation topsy-turvy; the two diagrams can't be about the same thing, since what is constant in the first (age disease detected) is variable in the other, and what is variable in the first (age disease contracted) is constant in the other.</p>\n<p>Now, as you research the issue a little more, you find out that authors prior to G99 have often used the first diagram to report their findings; reportedly, several different studies on different populations (dating back to the eighties) have yielded similar results.</p>\n<p>But when citing G99, nobody reproduces the <em>actual</em> diagram in G99, they all reproduce the older diagram (or some variant of it).</p>\n<p>You are tempted to conclude that the authors citing G99 are citing \"from memory\"; they are aware of the earlier research, they have a vague recollection that G99 contains results that are not totally at odds with the earlier research. Same difference, they reason, G99 is <strong>one more confirmation</strong> of the earlier research, which is adequately summarized by the standard diagram.</p>\n<p>And then you come across a paper by the same author, but from 10 years earlier. Let's call it G89. There is a strong presumption that the study in G99 is the same that is described in G89, for the following reasons: a) the researcher who wrote G99 was by then already retired from the institution where they obtained their results; b) the G99 \"paper\" isn't in fact a paper, it's a PowerPoint summarizing previous results obtained by the author.</p>\n<p>And in G89, you read the following: \"This study <strong>didn't accurately record</strong> the mortality rates at various ages after contracting the disease, so we will use average rates summarized from several other studies.\"</p>\n<p>So basically everyone who has been citing G99 has been building castles on sand.</p>\n<p>Suppose that, far from some exotic disease affecting a few individuals each year, the disease in question was one of the world's major killers (say, tuberculosis, the world's leader in infectious disease mortality), and the reason why everyone is citing either G99 or some of the earlier research is to lend support to the standard strategies for fighting the disease.</p>\n<p>When you look at the earlier research, you find nothing to allay your worries: the earlier studies are described only summarily, in broad overview papers or secondary sources; the numbers don't seem to match up, and so on.&nbsp;In effect you are discovering, about thirty years later, that what was taken for granted as a major finding on one of the principal topics of the discipline in fact has \"sloppy academic practice\" written all over it.</p>\n<p>If this story was true, and this was medicine we were talking about, what would you expect (or at least hope for, if you haven't become too cynical), should this story come to light? In a well-functioning discipline, a wave of retractations, public apologies, general embarrassment and a major re-evaluation of public health policies concerning this disease would follow.</p>\n<p>&nbsp;</p>\n<p>The story is substantially true, but the field isn't medicine: it is software engineering.</p>\n<p>I have transposed the story to medicine, temporarily, as an act of benign deception, to which I now confess. My intention was to bring out the structure of this story, and if,&nbsp;while thinking it was about health,&nbsp;you felt outraged at this miscarriage of academic process, you should still feel outraged upon learning that it is in fact about software.</p>\n<p>The \"disease\" isn't some exotic oddity, but the software equivalent of tuberculosis - the cost of fixing defects (a.k.a. bugs).</p>\n<p>The original claim was that \"defects introduced in early phases cost more to fix the later they are detected\". The misquoted chart says this instead: \"defects detected in the operations phase (once software is in the field) cost more to fix the earlier they were introduced\".</p>\n<p><em>Any</em>&nbsp;result concerning the \"disease\" of software bugs counts as a major result, because it affects very large fractions of the population, and accounts for a major fraction of the total \"morbidity\" (i.e. lack of quality, project failure) in the population (of software programs).</p>\n<p>The earlier <a href=\"http://www.scribd.com/doc/88419496/26044263-HP-3458A-Digital-Multi-Meter\">article</a> by the same author contained the following confession: \"This study didn't accurately record the engineering times to fix the defects, so we will use average times summarized from several other studies to weight the defect origins\".</p>\n<p>Not only is this one major result suspect, but the same pattern of \"<a href=\"http://xkcd.com/978/\">citogenesis</a>\" turns up <a href=\"http://leanpub.com/leprechauns\">investigating</a> several other important claims.</p>\n<p>&nbsp;</p>\n<p>Software engineering is a <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">diseased discipline</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<div style=\"font-size:90%\">\n<p style=\"font-size: 90%;\">The publication I've labeled \"G99\" is generally <a href=\"http://www.ifsq.nl/work-grady-1999.html\">cited</a> as:&nbsp;Robert B. Grady, An Economic Release Decision Model: Insights into Software Project Management, in proceedings of Applications of Software Measurement (1999). The second diagram is from a photograph of a hard copy of the proceedings.</p>\n<p style=\"font-size: 90%;\"><a href=\"http://www.serena.com/docs/repository/products/rm/wp900-001-0505.pdf\">Here</a> is one typical publication citing Grady 1999, from which the first diagram is extracted. You can find many more via a <a href=\"http://www.google.fr/search?ix=icb&amp;sourceid=chrome&amp;ie=UTF-8&amp;q=defect+cost+%22grady+1999%22\">Google search</a>. The \"this study didn't accurately record\" quote is discussed <a href=\"https://plus.google.com/115091715679003832601/posts/N4c8f8ijd6H\">here</a>, and can be found in \"Dissecting Software Failures\" by Grady, in the April 1989 issue of the \"Hewlett Packard Journal\"; you can still find one copy of&nbsp;<a href=\"http://www.scribd.com/doc/88419496/26044263-HP-3458A-Digital-Multi-Meter\">the original source</a>&nbsp;on the Web, as of early 2013, but link rot is threatening it with extinction.</p>\n<p style=\"font-size: 90%;\">A more extensive analysis of the \"defect cost increase\" claim is available in my book-in-progress, \"<a href=\"http://leanpub.com/leprechauns\">The Leprechauns of Software Engineering</a>\".</p>\n<p style=\"font-size: 90%;\">Here is how the axes were originally labeled; first diagram:</p>\n<ul style=\"font-size: 90%;\">\n<li>vertical: \"Relative Cost to Correct a Defect\"</li>\n<li>horizontal: \"Development Phase\" (values \"Requirements\", \"Design\", \"Code\", \"Test\", \"Operation\" from left to right)</li>\n<li>figure label: \"Relative cost to correct a requirement defect depending on when it is discovered\"</li>\n</ul>\n<p style=\"font-size: 90%;\">Second diagram:</p>\n<ul style=\"font-size: 90%;\">\n<li>vertical: \"Activity When Defect was Created\" (values \"Specifications\", \"Design\", \"Code\", \"Test\" from top to bottom)</li>\n<li>horizontal: \"Relative cost to fix a defect after release to customers compared to the cost of fixing it shortly after it was created\"</li>\n<li>figure label: \"Relative Costs to Fix Defects\"</li>\n</ul>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HFou6RHqFagkyrKkW": 1, "bh7uxTTqmsQ8jZJdB": 1, "sHbKQDqrSinRPcnBv": 1, "ZpG9rheyAkgCoEQea": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4ACmfJkXQxkYacdLt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 60, "baseScore": 62, "extendedScore": null, "score": 0.000152, "legacy": true, "legacyId": "12703", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 51, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 150, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FwiPfF8Woe5JrzqEu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-07T15:53:28.737Z", "modifiedAt": null, "url": null, "title": "AI is not enough", "slug": "ai-is-not-enough", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.216Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "benjayk", "createdAt": "2011-04-12T13:30:57.427Z", "isAdmin": false, "displayName": "benjayk"}, "userId": "QYDSo4SpkwD9WNjQH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YE2EvGBb6M5hB6QoQ/ai-is-not-enough", "pageUrlRelative": "/posts/YE2EvGBb6M5hB6QoQ/ai-is-not-enough", "linkUrl": "https://www.lesswrong.com/posts/YE2EvGBb6M5hB6QoQ/ai-is-not-enough", "postedAtFormatted": "Tuesday, February 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AI%20is%20not%20enough&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAI%20is%20not%20enough%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYE2EvGBb6M5hB6QoQ%2Fai-is-not-enough%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AI%20is%20not%20enough%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYE2EvGBb6M5hB6QoQ%2Fai-is-not-enough", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYE2EvGBb6M5hB6QoQ%2Fai-is-not-enough", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 718, "htmlBody": "<p>What I write here may be quite simple (and I am certainly not the first to write about it), but I still think it is worth considering:</p>\n<p><br />Say we have an abitrary problem that we assume has an algorithmic solution, and search for the solution of the problem.</p>\n<p><br />How can the algorithm be determined?<br />Either:<br />a) Through another algorithm that exist prior to that algorithm.<br />b) OR: Through something non-algorithmic.</p>\n<p><br />In the case of AI, the only solution is a), since there is nothing else but algorithms at its disposal. But then we have the problem to determine the algorithm the AI uses to find the solution, and then it would have to determine the algorithm to determine that algorithm, etc...<br />Obviously, at some point we have to actually find an algorithm to start with, so in any case at some point we need something fundamentally non-algorithmic to determine a solution to an problem that is solveable by an algorithm.</p>\n<p><br />This reveals something fundamental we have to face with regards to AI:</p>\n<p>Even assuming that all relevant problems are solvable by an algorithm, AI is not enough. Since there is no way to algorithmically determine the appropiate algorithm for an AI (since this would result in an infinite regress), we will always have to rely on some non-algorithmical intelligence to find more intelligent solutions. Even if we found a very powerful seed AI algorithm, there will always be more powerful seed AI algorithms that can't be determined by any known algorithm, and since we were able to find the first one, we have no reason to suppose we can't find another more powerful one. If an AI recursively improves 100000x times until it is 100^^^100 times more powerful, it still will be caught up if a better seed AI is found, which ultimately can't be done by an algorithm, so that further increases of the most general intelligence always rely on something non-algorithmic.</p>\n<p>But even worse, it seems obvious to me that there are important practical problems that have no algorithmic solution (as opposed to theoretical problems like the halting problem, which are still tractable in practice), apart from the problem of finding the right algorithm.<br />In a sense, it seems all algorithms are too complicated to find the solution to the simple (though not necessarily easy) problem of giving rise to further general intelligence.<br />For example: No algorithm can determine the simple axioms of the natural numbers from anything weaker. We have postulate them by virtue of the simple seeing that they make sense. Thinking that AI could give rise to ever improving *general* intelligence is like thinking that an algorithm can yield \"there is a natural number 0 and every number has a successor that, too, is a natural number\". There is simply no way to derive the axioms from anything that doesn't already include it. The axioms of the natural numbers are just obvious, yet can't be derived - the problem of finding the axioms of natural numbers is too simple to be solved algorithmically. Yet still it is obvious how important the notion of natural numbers is.<br />Even the best AI will always be fundamentally incapable of finding some very simple, yet fundamental principles. <br />AI will always rely on the axioms it already knows, it can't go beyond it (unless reprogrammed by something external). Every new thing it learns can only be learned in term of already known axioms. This is simply a consequence of the fact that computers/programs are functioning according to fixed rules. But general intelligence necessarily has to transcend rules (since at the very least the rules can't be determined by rules).</p>\n<p><br />I don't think this is an argument against a singularity of ever improving intelligence. It just can't happen driven (solely or predominantly) by AI, whether through a recursively self-improving seed AI or  cognitive augmentation. Instead, we should expect a singularity that happens due to emergent intelligence. I think it is the interaction of different kind of intelligence (like human/animal intuitive intelligence, machine precision and the inherent order of the non-living universe, if you want to call that intelligence) that leads to increase in general intelligence, not just one particular kind of intelligence like formal reasoning used by computers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YE2EvGBb6M5hB6QoQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": -37, "extendedScore": null, "score": 8.448922473001258e-07, "legacy": true, "legacyId": "12803", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-07T16:52:39.976Z", "modifiedAt": null, "url": null, "title": "[LINK] Refuting common objections to cognitive enhancement", "slug": "link-refuting-common-objections-to-cognitive-enhancement", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:56.693Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "grouchymusicologist", "createdAt": "2009-03-20T04:17:27.196Z", "isAdmin": false, "displayName": "grouchymusicologist"}, "userId": "KYP2e7SEoKnM8ddjr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Bq9TZTW5rsia8R2Mf/link-refuting-common-objections-to-cognitive-enhancement", "pageUrlRelative": "/posts/Bq9TZTW5rsia8R2Mf/link-refuting-common-objections-to-cognitive-enhancement", "linkUrl": "https://www.lesswrong.com/posts/Bq9TZTW5rsia8R2Mf/link-refuting-common-objections-to-cognitive-enhancement", "postedAtFormatted": "Tuesday, February 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Refuting%20common%20objections%20to%20cognitive%20enhancement&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Refuting%20common%20objections%20to%20cognitive%20enhancement%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBq9TZTW5rsia8R2Mf%2Flink-refuting-common-objections-to-cognitive-enhancement%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Refuting%20common%20objections%20to%20cognitive%20enhancement%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBq9TZTW5rsia8R2Mf%2Flink-refuting-common-objections-to-cognitive-enhancement", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBq9TZTW5rsia8R2Mf%2Flink-refuting-common-objections-to-cognitive-enhancement", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 475, "htmlBody": "<p>I've tended to think that bioethics is maybe the most profoundly useless field in mainstream philosophy. I might sum it up by saying that it's superficially similar to machine ethics <em>except</em> that the objects of its warnings and cautions are all unambiguously good things, like cognitive enhancements and life extension. In an era when we should by any reasonable measure be making huge amounts of progress on those problems&mdash;and in which one might expect bioethicists to be encouraging such research and helping weigh it against yet another dollar sent to the Susan G. Komen foundation or whatever&mdash;one mostly hears bioethicists quoted in the newspaper urging science to slow down. As if doubling human lifespans or giving everyone an extra 15 IQ points would in some way run the risk of \"destroying that which makes us human\" or something.</p>\n<p>Anyway, this has basically been my perspective as a newspaper reader&mdash;I don't read specialty publications in bioethics. And perhaps it should come as no surprise that bioethics' usefulness to mainstream discourse would be to reinforce status quo bias, whether that's a true reflection of the field or not. In any case, it was a welcome surprise to see <a href=\"http://www.theatlantic.com/technology/archive/2012/02/why-cognitive-enhancement-is-in-your-future-and-your-past/252566/\">an interview in <em>The Atlantic</em> with Allen Buchanan</a>, who apparently is an eminent bioethicist (Duke professor, President's Council on Bioethics), entirely devoted to refuting common objections to cognitive enhancement.</p>\n<p>Some points Buchanan makes, responding to common worries:</p>\n<p>\n<ul>\n<li>There's no good reason to think the human body and its capabilities are anywhere near their maximum.</li>\n<li>Technologies that make human lives better tend to have egalitarian effects in the long run (he mentions cell phones), even if they're at first available only to the wealthy.</li>\n<li>A much smarter human population will probably be morally, as well as cognitively, enhanced&mdash;the \"evil genius\" problem isn't necessarily a realistic one to worry about.</li>\n<li>Many people worry that the use of cognitive enhancement by people who are willing to self-experiment is unfair to those who don't want to or fear the risks. Buchanan points out that this problem could be largely alleviated by more research into safety and efficacy of drugs with cognitive enhancement potential. The current atmosphere of fear, dubious legal status, and unwillingness to do large-scale testing surrounding cognitive enhancement is counterproductive in this regard.</li>\n<li>As cool as it would be to be a cognitively enhanced person in today's world, it would be <em>so much cooler</em>&nbsp;to be a cognitively enhanced human in a world of other enhanced humans.</li>\n</ul>\n<div>I doubt any of these points will be at all surprising or novel to LW readers, but I was really pleased to see them covered in a mainstream publication, and to know that bioethics has people like Buchanan who are more interested in what we stand to gain from technology than what we stand to lose.</div>\n<div><a href=\"http://leiterreports.typepad.com/blog/2012/02/the-ethics-of-cognitive-enhancement.html\">Via Brian Leiter.</a></div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jiuackr7B5JAetbF6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Bq9TZTW5rsia8R2Mf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 32, "extendedScore": null, "score": 8.449153222709054e-07, "legacy": true, "legacyId": "12804", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T02:07:33.080Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Mutual Information, and Density in Thingspace", "slug": "seq-rerun-mutual-information-and-density-in-thingspace", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.639Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hsLexSqHJbbCtv2HH/seq-rerun-mutual-information-and-density-in-thingspace", "pageUrlRelative": "/posts/hsLexSqHJbbCtv2HH/seq-rerun-mutual-information-and-density-in-thingspace", "linkUrl": "https://www.lesswrong.com/posts/hsLexSqHJbbCtv2HH/seq-rerun-mutual-information-and-density-in-thingspace", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Mutual%20Information%2C%20and%20Density%20in%20Thingspace&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Mutual%20Information%2C%20and%20Density%20in%20Thingspace%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhsLexSqHJbbCtv2HH%2Fseq-rerun-mutual-information-and-density-in-thingspace%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Mutual%20Information%2C%20and%20Density%20in%20Thingspace%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhsLexSqHJbbCtv2HH%2Fseq-rerun-mutual-information-and-density-in-thingspace", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhsLexSqHJbbCtv2HH%2Fseq-rerun-mutual-information-and-density-in-thingspace", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 259, "htmlBody": "<p>Today's post, <a href=\"/lw/o2/mutual_information_and_density_in_thingspace/\">Mutual Information, and Density in Thingspace</a> was originally published on 23 February 2008.  A summary (taken from the <a href=\"/You draw your boundary around a volume of space where there is no greater-than-usual density, meaning that the associated word does not correspond to any performable Bayesian inferences. Since green-eyed people are not more likely to have black hair, or vice versa, and they don't share any other characteristics in common, why have a word for \">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You draw your boundary around a volume of space where there is no greater-than-usual density, meaning that the associated word does not correspond to any performable Bayesian inferences. Since green-eyed people are not more likely to have black hair, or vice versa, and they don't share any other characteristics in common, why have a word for \"wiggin\"?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9v6/seq_rerun_entropy_and_short_codes/\">Entropy, and Short Codes</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hsLexSqHJbbCtv2HH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.451317057085635e-07, "legacy": true, "legacyId": "12824", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yLcuygFfMfrfK8KjF", "C42RTgvh2FespQFCa", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T04:43:14.002Z", "modifiedAt": null, "url": null, "title": "Meetup : Jazz meetup in Philadelphia", "slug": "meetup-jazz-meetup-in-philadelphia", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:56.944Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DasAllFolks", "createdAt": "2011-12-23T17:34:00.896Z", "isAdmin": false, "displayName": "DasAllFolks"}, "userId": "s7hnECaJ7cv5oJApQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9Gwf5J977RD3RrXpc/meetup-jazz-meetup-in-philadelphia", "pageUrlRelative": "/posts/9Gwf5J977RD3RrXpc/meetup-jazz-meetup-in-philadelphia", "linkUrl": "https://www.lesswrong.com/posts/9Gwf5J977RD3RrXpc/meetup-jazz-meetup-in-philadelphia", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Jazz%20meetup%20in%20Philadelphia&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Jazz%20meetup%20in%20Philadelphia%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9Gwf5J977RD3RrXpc%2Fmeetup-jazz-meetup-in-philadelphia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Jazz%20meetup%20in%20Philadelphia%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9Gwf5J977RD3RrXpc%2Fmeetup-jazz-meetup-in-philadelphia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9Gwf5J977RD3RrXpc%2Fmeetup-jazz-meetup-in-philadelphia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 186, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6r'>Jazz meetup in Philadelphia</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 February 2012 06:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Woodmere Art Museum, 9201 Germantown Avenue Philadelphia, PA 19118 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Consider this one a \"just for fun\" event, rather than a \"hard\" meetup (such as we will be having on Wednesday the 15th!) dealing with more serious rationality-related topics.</p>\n\n<p>The Woodmere Art Museum in Chestnut Hill holds jazz concerts every Friday.  A couple of us are attending this Friday's concert, \"Tribute to Miles Davis: A Kinda Blue Valentine\" featuring Philadelphia trumpeter Tony Smith; feel free to come out and meet some area Less-Wrongers, particularly if you weren't in the area for our last meetup!</p>\n\n<p>Tickets are $15 for Woodmere members or $20 for the general public, and are available at the door or online (<a href=\"http://woodmereartmuseum.org/music.html\" rel=\"nofollow\">http://woodmereartmuseum.org/music.html</a>).  Feel free to message me for my cell in case you're afraid you might have trouble finding the place!</p>\n\n<p>If turnout is good and people are interested, we may also venture out into Chestnut Hill or elsewhere for food/coffee after the concert ends at 8.  Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6r'>Jazz meetup in Philadelphia</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9Gwf5J977RD3RrXpc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 8.451924332369315e-07, "legacy": true, "legacyId": "12829", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Jazz_meetup_in_Philadelphia\">Discussion article for the meetup : <a href=\"/meetups/6r\">Jazz meetup in Philadelphia</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 February 2012 06:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Woodmere Art Museum, 9201 Germantown Avenue Philadelphia, PA 19118 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Consider this one a \"just for fun\" event, rather than a \"hard\" meetup (such as we will be having on Wednesday the 15th!) dealing with more serious rationality-related topics.</p>\n\n<p>The Woodmere Art Museum in Chestnut Hill holds jazz concerts every Friday.  A couple of us are attending this Friday's concert, \"Tribute to Miles Davis: A Kinda Blue Valentine\" featuring Philadelphia trumpeter Tony Smith; feel free to come out and meet some area Less-Wrongers, particularly if you weren't in the area for our last meetup!</p>\n\n<p>Tickets are $15 for Woodmere members or $20 for the general public, and are available at the door or online (<a href=\"http://woodmereartmuseum.org/music.html\" rel=\"nofollow\">http://woodmereartmuseum.org/music.html</a>).  Feel free to message me for my cell in case you're afraid you might have trouble finding the place!</p>\n\n<p>If turnout is good and people are interested, we may also venture out into Chestnut Hill or elsewhere for food/coffee after the concert ends at 8.  Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Jazz_meetup_in_Philadelphia1\">Discussion article for the meetup : <a href=\"/meetups/6r\">Jazz meetup in Philadelphia</a></h2>", "sections": [{"title": "Discussion article for the meetup : Jazz meetup in Philadelphia", "anchor": "Discussion_article_for_the_meetup___Jazz_meetup_in_Philadelphia", "level": 1}, {"title": "Discussion article for the meetup : Jazz meetup in Philadelphia", "anchor": "Discussion_article_for_the_meetup___Jazz_meetup_in_Philadelphia1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T04:56:03.389Z", "modifiedAt": null, "url": null, "title": "Meetup : Philadelphia LW: Macroeconomics crash course and general meetup", "slug": "meetup-philadelphia-lw-macroeconomics-crash-course-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.013Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DasAllFolks", "createdAt": "2011-12-23T17:34:00.896Z", "isAdmin": false, "displayName": "DasAllFolks"}, "userId": "s7hnECaJ7cv5oJApQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mJAoHN6qrZHqSiLSD/meetup-philadelphia-lw-macroeconomics-crash-course-and", "pageUrlRelative": "/posts/mJAoHN6qrZHqSiLSD/meetup-philadelphia-lw-macroeconomics-crash-course-and", "linkUrl": "https://www.lesswrong.com/posts/mJAoHN6qrZHqSiLSD/meetup-philadelphia-lw-macroeconomics-crash-course-and", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Philadelphia%20LW%3A%20Macroeconomics%20crash%20course%20and%20general%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Philadelphia%20LW%3A%20Macroeconomics%20crash%20course%20and%20general%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmJAoHN6qrZHqSiLSD%2Fmeetup-philadelphia-lw-macroeconomics-crash-course-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Philadelphia%20LW%3A%20Macroeconomics%20crash%20course%20and%20general%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmJAoHN6qrZHqSiLSD%2Fmeetup-philadelphia-lw-macroeconomics-crash-course-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmJAoHN6qrZHqSiLSD%2Fmeetup-philadelphia-lw-macroeconomics-crash-course-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6s'>Philadelphia LW: Macroeconomics crash course and general meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 February 2012 06:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1301 Chestnut Street Philadelphia, PA 19107-3521 US</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting at the Starbucks in Macy's Center City (conveniently located near Suburban Station for you traingoers!) from 6:30 - 8:30 P.M.</p>\n\n<p>This week's featured topic will be a \"crash course\" in macroeconomics from one of our members, who also happens to be a graduate student in economics, in continuation of some fairly lengthy and interesting economic discussions that came out of our first meetup in January (not that you shouldn't come if you weren't there...please feel free to stop by regardless of your history with either LW meetups or economics in general!).</p>\n\n<p>Agenda will also include general self-improvement, planning future meetups, and, of course, better getting to know new members and attendees from last meetup alike. We hope to see you there!</p>\n\n<p>Also: please feel free to request an invitation to our Google group (<a href=\"http://groups.google.com/group/lesswrong-philadelphia\" rel=\"nofollow\">http://groups.google.com/group/lesswrong-philadelphia</a>) if you would like to discuss meetup ideas (including the details of this upcoming one) in real time, and/or would generally like to start talking to people prior to convening in meat space!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6s'>Philadelphia LW: Macroeconomics crash course and general meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mJAoHN6qrZHqSiLSD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 8.451974355444882e-07, "legacy": true, "legacyId": "12830", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Philadelphia_LW__Macroeconomics_crash_course_and_general_meetup\">Discussion article for the meetup : <a href=\"/meetups/6s\">Philadelphia LW: Macroeconomics crash course and general meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 February 2012 06:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1301 Chestnut Street Philadelphia, PA 19107-3521 US</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting at the Starbucks in Macy's Center City (conveniently located near Suburban Station for you traingoers!) from 6:30 - 8:30 P.M.</p>\n\n<p>This week's featured topic will be a \"crash course\" in macroeconomics from one of our members, who also happens to be a graduate student in economics, in continuation of some fairly lengthy and interesting economic discussions that came out of our first meetup in January (not that you shouldn't come if you weren't there...please feel free to stop by regardless of your history with either LW meetups or economics in general!).</p>\n\n<p>Agenda will also include general self-improvement, planning future meetups, and, of course, better getting to know new members and attendees from last meetup alike. We hope to see you there!</p>\n\n<p>Also: please feel free to request an invitation to our Google group (<a href=\"http://groups.google.com/group/lesswrong-philadelphia\" rel=\"nofollow\">http://groups.google.com/group/lesswrong-philadelphia</a>) if you would like to discuss meetup ideas (including the details of this upcoming one) in real time, and/or would generally like to start talking to people prior to convening in meat space!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Philadelphia_LW__Macroeconomics_crash_course_and_general_meetup1\">Discussion article for the meetup : <a href=\"/meetups/6s\">Philadelphia LW: Macroeconomics crash course and general meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Philadelphia LW: Macroeconomics crash course and general meetup", "anchor": "Discussion_article_for_the_meetup___Philadelphia_LW__Macroeconomics_crash_course_and_general_meetup", "level": 1}, {"title": "Discussion article for the meetup : Philadelphia LW: Macroeconomics crash course and general meetup", "anchor": "Discussion_article_for_the_meetup___Philadelphia_LW__Macroeconomics_crash_course_and_general_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T08:45:11.220Z", "modifiedAt": null, "url": null, "title": "[Link] Physcists say they can encode magnetic data using heat pulses", "slug": "link-physcists-say-they-can-encode-magnetic-data-using-heat", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.288Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MatthewBaker", "createdAt": "2011-06-03T22:19:50.449Z", "isAdmin": false, "displayName": "MatthewBaker"}, "userId": "xEPvhkraqrPSryfFr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qjm8HR3uknHQ8sp9b/link-physcists-say-they-can-encode-magnetic-data-using-heat", "pageUrlRelative": "/posts/qjm8HR3uknHQ8sp9b/link-physcists-say-they-can-encode-magnetic-data-using-heat", "linkUrl": "https://www.lesswrong.com/posts/qjm8HR3uknHQ8sp9b/link-physcists-say-they-can-encode-magnetic-data-using-heat", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Physcists%20say%20they%20can%20encode%20magnetic%20data%20using%20heat%20pulses&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Physcists%20say%20they%20can%20encode%20magnetic%20data%20using%20heat%20pulses%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqjm8HR3uknHQ8sp9b%2Flink-physcists-say-they-can-encode-magnetic-data-using-heat%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Physcists%20say%20they%20can%20encode%20magnetic%20data%20using%20heat%20pulses%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqjm8HR3uknHQ8sp9b%2Flink-physcists-say-they-can-encode-magnetic-data-using-heat", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqjm8HR3uknHQ8sp9b%2Flink-physcists-say-they-can-encode-magnetic-data-using-heat", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 10, "htmlBody": "<p>http://www.physorg.com/news/2012-02-physicists-magnetic-breakthrough.html</p>\n<p>Anyone have a strong opinion on this one? thanks :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qjm8HR3uknHQ8sp9b", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -2, "extendedScore": null, "score": 8.4528682840226e-07, "legacy": true, "legacyId": "12837", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T09:16:43.295Z", "modifiedAt": null, "url": null, "title": "Meetup : Houston Meetup - 2/12", "slug": "meetup-houston-meetup-2-12", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cog", "createdAt": "2011-04-25T04:58:53.803Z", "isAdmin": false, "displayName": "Cog"}, "userId": "xkp87vCZ56dp2tWnN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nLFAF3tetztFkeNSG/meetup-houston-meetup-2-12", "pageUrlRelative": "/posts/nLFAF3tetztFkeNSG/meetup-houston-meetup-2-12", "linkUrl": "https://www.lesswrong.com/posts/nLFAF3tetztFkeNSG/meetup-houston-meetup-2-12", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Houston%20Meetup%20-%202%2F12&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Houston%20Meetup%20-%202%2F12%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnLFAF3tetztFkeNSG%2Fmeetup-houston-meetup-2-12%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Houston%20Meetup%20-%202%2F12%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnLFAF3tetztFkeNSG%2Fmeetup-houston-meetup-2-12", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnLFAF3tetztFkeNSG%2Fmeetup-houston-meetup-2-12", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6t'>Houston Meetup - 2/12</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 February 2012 02:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, TX 77002, USA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be going over E.T. Jayne's \"The Logic of Science\" this Sunday at 2PM.The goal, established at the last meeting, will be to go over the exercises in Chapter 2 and to have read chapter 3. We will also be discussing the possibility of forming a class on neural networks in the hackerspace.</p>\n\n<p>Food, as always is an option. Usually, some type of communal breakfast food is already being cooked, so bring money for the tip jar if you wish to partake.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6t'>Houston Meetup - 2/12</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nLFAF3tetztFkeNSG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 8.452991325950521e-07, "legacy": true, "legacyId": "12838", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup___2_12\">Discussion article for the meetup : <a href=\"/meetups/6t\">Houston Meetup - 2/12</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 February 2012 02:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, TX 77002, USA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be going over E.T. Jayne's \"The Logic of Science\" this Sunday at 2PM.The goal, established at the last meeting, will be to go over the exercises in Chapter 2 and to have read chapter 3. We will also be discussing the possibility of forming a class on neural networks in the hackerspace.</p>\n\n<p>Food, as always is an option. Usually, some type of communal breakfast food is already being cooked, so bring money for the tip jar if you wish to partake.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup___2_121\">Discussion article for the meetup : <a href=\"/meetups/6t\">Houston Meetup - 2/12</a></h2>", "sections": [{"title": "Discussion article for the meetup : Houston Meetup - 2/12", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup___2_12", "level": 1}, {"title": "Discussion article for the meetup : Houston Meetup - 2/12", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup___2_121", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T11:03:04.962Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne social meetup", "slug": "meetup-melbourne-social-meetup-23", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.071Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shokwave", "createdAt": "2010-10-12T12:55:00.568Z", "isAdmin": false, "displayName": "shokwave"}, "userId": "jtjgXtj7FepKrQPGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gRYXsvT7GasgnJecc/meetup-melbourne-social-meetup-23", "pageUrlRelative": "/posts/gRYXsvT7GasgnJecc/meetup-melbourne-social-meetup-23", "linkUrl": "https://www.lesswrong.com/posts/gRYXsvT7GasgnJecc/meetup-melbourne-social-meetup-23", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20social%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20social%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgRYXsvT7GasgnJecc%2Fmeetup-melbourne-social-meetup-23%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20social%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgRYXsvT7GasgnJecc%2Fmeetup-melbourne-social-meetup-23", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgRYXsvT7GasgnJecc%2Fmeetup-melbourne-social-meetup-23", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 140, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6u'>Melbourne social meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 February 2012 06:30:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">see mailing list; Carlton, VIC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next social meetup is on Friday, 17th February. Continuing the tradition, we'll meet at Ben's house - <a href=\"http://groups.google.com/group/melbourne-less-wrong?hl=en\" rel=\"nofollow\">see the mailing list</a> for location details, or I can give you the address - you can call me at 0432 862 932, or email me at shokwave.sf@gmail.com, or inbox me by clicking on my name.</p>\n\n<p>Some form of take-away will be organised for dinner and there will be snacks available. BYO drinks.</p>\n\n<p>We'll be moving away from long board games; bring short ones or suggestions if you have any. There will be at least one game of Mafia!</p>\n\n<p>It will help attendance numbers to comment, saying you'll be attending. We look forward to seeing you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6u'>Melbourne social meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gRYXsvT7GasgnJecc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 8.453406350478249e-07, "legacy": true, "legacyId": "12839", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_social_meetup\">Discussion article for the meetup : <a href=\"/meetups/6u\">Melbourne social meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 February 2012 06:30:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">see mailing list; Carlton, VIC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next social meetup is on Friday, 17th February. Continuing the tradition, we'll meet at Ben's house - <a href=\"http://groups.google.com/group/melbourne-less-wrong?hl=en\" rel=\"nofollow\">see the mailing list</a> for location details, or I can give you the address - you can call me at 0432 862 932, or email me at shokwave.sf@gmail.com, or inbox me by clicking on my name.</p>\n\n<p>Some form of take-away will be organised for dinner and there will be snacks available. BYO drinks.</p>\n\n<p>We'll be moving away from long board games; bring short ones or suggestions if you have any. There will be at least one game of Mafia!</p>\n\n<p>It will help attendance numbers to comment, saying you'll be attending. We look forward to seeing you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_social_meetup1\">Discussion article for the meetup : <a href=\"/meetups/6u\">Melbourne social meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne social meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_social_meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne social meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_social_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "11 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T11:53:20.938Z", "modifiedAt": null, "url": null, "title": "Bayesian RPG system?", "slug": "bayesian-rpg-system", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.745Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3MGuPbtQRr7G83dH5/bayesian-rpg-system", "pageUrlRelative": "/posts/3MGuPbtQRr7G83dH5/bayesian-rpg-system", "linkUrl": "https://www.lesswrong.com/posts/3MGuPbtQRr7G83dH5/bayesian-rpg-system", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20RPG%20system%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20RPG%20system%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MGuPbtQRr7G83dH5%2Fbayesian-rpg-system%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20RPG%20system%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MGuPbtQRr7G83dH5%2Fbayesian-rpg-system", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MGuPbtQRr7G83dH5%2Fbayesian-rpg-system", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 228, "htmlBody": "<p>This is one of those sleep-deprived middle-of-the-night ideas which I'm reasonably likely to regret posting in the morning once I really wake up - but which, at least at the moment, thinking on my more-corrupted-than-standard hardware, seems like a cool idea.</p>\n<p>Most role-playing games have a system for determining whether or not certain actions are successful or not. Most of the time, these can be described as setting a target number, and rolling one or more dice, with various modifiers - eg, you might have to roll a 13 or higher on a twenty-sided dice to correctly answer the sphinx's riddle, and having your handy Book of Ancient Puzzles to refer to may give you a +3 bonus to your die-roll.</p>\n<p>How insane and awful an idea would it be to have an RPG system whose core mechanic wasn't based on linear probabilities like that... but, instead, on decibels of Bayesian probability? For example, instead of a bonus adding a straight +3 to a d20, or increasing your odds by 15% no matter how easy the task or how skilled you are, the bonus adds +3 decibels: changing your odds from 50% to 66% if you started out with a middling chance, but only increasing it from 90% to 95% if you're already very skilled.</p>\n<p>&nbsp;</p>\n<p>(And now, back to sleep, and to see how much karma I've lost come the morning...)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3MGuPbtQRr7G83dH5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 16, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "12840", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T14:24:55.275Z", "modifiedAt": null, "url": null, "title": "Meetup : Twin Cities South Metro", "slug": "meetup-twin-cities-south-metro", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:09.239Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hewhocutsdown", "createdAt": "2010-12-20T20:17:31.618Z", "isAdmin": false, "displayName": "hewhocutsdown"}, "userId": "KTtZGvXsE2H83yjMu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s5zFqQ2wMC9HuTBMn/meetup-twin-cities-south-metro", "pageUrlRelative": "/posts/s5zFqQ2wMC9HuTBMn/meetup-twin-cities-south-metro", "linkUrl": "https://www.lesswrong.com/posts/s5zFqQ2wMC9HuTBMn/meetup-twin-cities-south-metro", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Twin%20Cities%20South%20Metro&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Twin%20Cities%20South%20Metro%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5zFqQ2wMC9HuTBMn%2Fmeetup-twin-cities-south-metro%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Twin%20Cities%20South%20Metro%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5zFqQ2wMC9HuTBMn%2Fmeetup-twin-cities-south-metro", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5zFqQ2wMC9HuTBMn%2Fmeetup-twin-cities-south-metro", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6v'>Twin Cities South Metro</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">06 March 2012 08:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">7083 153rd St. W, Apple Valley, MN </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I see that there was some interest a couple years back for a Minneapolis meetup, I'm going to give it a shot again, but south of the river instead of on campus.</p>\n\n<p>This first meeting will be a get-to-know-each-other event, as well as a time to decide future meetup content and structure.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6v'>Twin Cities South Metro</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s5zFqQ2wMC9HuTBMn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.45419403023427e-07, "legacy": true, "legacyId": "12841", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Twin_Cities_South_Metro\">Discussion article for the meetup : <a href=\"/meetups/6v\">Twin Cities South Metro</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">06 March 2012 08:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">7083 153rd St. W, Apple Valley, MN </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I see that there was some interest a couple years back for a Minneapolis meetup, I'm going to give it a shot again, but south of the river instead of on campus.</p>\n\n<p>This first meeting will be a get-to-know-each-other event, as well as a time to decide future meetup content and structure.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Twin_Cities_South_Metro1\">Discussion article for the meetup : <a href=\"/meetups/6v\">Twin Cities South Metro</a></h2>", "sections": [{"title": "Discussion article for the meetup : Twin Cities South Metro", "anchor": "Discussion_article_for_the_meetup___Twin_Cities_South_Metro", "level": 1}, {"title": "Discussion article for the meetup : Twin Cities South Metro", "anchor": "Discussion_article_for_the_meetup___Twin_Cities_South_Metro1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "13 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T18:23:03.381Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "slug": "meetup-fort-collins-colorado-meetup-wedneday-7pm-7", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mDnawvHibhfEgc42z/meetup-fort-collins-colorado-meetup-wedneday-7pm-7", "pageUrlRelative": "/posts/mDnawvHibhfEgc42z/meetup-fort-collins-colorado-meetup-wedneday-7pm-7", "linkUrl": "https://www.lesswrong.com/posts/mDnawvHibhfEgc42z/meetup-fort-collins-colorado-meetup-wedneday-7pm-7", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmDnawvHibhfEgc42z%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-7%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmDnawvHibhfEgc42z%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-7", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmDnawvHibhfEgc42z%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-7", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6w'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">08 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Sorry for the short notice. We will be having our usual meetups every Wednesday in February.</p>\n\n<p>Please sign up for the mailing list: <a href=\"http://groups.google.com/group/less-wrong-fort-collins-co\" rel=\"nofollow\">http://groups.google.com/group/less-wrong-fort-collins-co</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6w'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mDnawvHibhfEgc42z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.455123525018209e-07, "legacy": true, "legacyId": "12844", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm\">Discussion article for the meetup : <a href=\"/meetups/6w\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">08 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Sorry for the short notice. We will be having our usual meetups every Wednesday in February.</p>\n\n<p>Please sign up for the mailing list: <a href=\"http://groups.google.com/group/less-wrong-fort-collins-co\" rel=\"nofollow\">http://groups.google.com/group/less-wrong-fort-collins-co</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/6w\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T21:25:58.173Z", "modifiedAt": null, "url": null, "title": "Moscow meetup: Saturday 6 PM", "slug": "moscow-meetup-saturday-6-pm", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BT_Uytya", "createdAt": "2011-12-03T16:41:14.863Z", "isAdmin": false, "displayName": "BT_Uytya"}, "userId": "Enh7Ap3zRTQDR4gMH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RZ8NFLXQsx5o4q4Zo/moscow-meetup-saturday-6-pm", "pageUrlRelative": "/posts/RZ8NFLXQsx5o4q4Zo/moscow-meetup-saturday-6-pm", "linkUrl": "https://www.lesswrong.com/posts/RZ8NFLXQsx5o4q4Zo/moscow-meetup-saturday-6-pm", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Moscow%20meetup%3A%20Saturday%206%20PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMoscow%20meetup%3A%20Saturday%206%20PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRZ8NFLXQsx5o4q4Zo%2Fmoscow-meetup-saturday-6-pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Moscow%20meetup%3A%20Saturday%206%20PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRZ8NFLXQsx5o4q4Zo%2Fmoscow-meetup-saturday-6-pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRZ8NFLXQsx5o4q4Zo%2Fmoscow-meetup-saturday-6-pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p><strong>WHEN:</strong> <span class=\"date\">11 February 2012 06:00:00PM (Moscow time)</span></p>\n<div class=\"meetup-meta\">\n<p><strong>WHERE:</strong> Place is yet to be determined; I hope this issue will be dealt with tomorrow.</p>\n<p>&nbsp;</p>\n<p><strong>UPD.:</strong> So it is Metro Mayakovskaya; Meetup link: http://lesswrong.com/meetups/6x</p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RZ8NFLXQsx5o4q4Zo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 8.455837599124315e-07, "legacy": true, "legacyId": "12845", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-08T21:36:59.574Z", "modifiedAt": null, "url": null, "title": "New book from leading neuroscientist in support of cryonics and mind uploading", "slug": "new-book-from-leading-neuroscientist-in-support-of-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.002Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KgTDX9wEd4s3kubpr/new-book-from-leading-neuroscientist-in-support-of-cryonics", "pageUrlRelative": "/posts/KgTDX9wEd4s3kubpr/new-book-from-leading-neuroscientist-in-support-of-cryonics", "linkUrl": "https://www.lesswrong.com/posts/KgTDX9wEd4s3kubpr/new-book-from-leading-neuroscientist-in-support-of-cryonics", "postedAtFormatted": "Wednesday, February 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20book%20from%20leading%20neuroscientist%20in%20support%20of%20cryonics%20and%20mind%20uploading&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20book%20from%20leading%20neuroscientist%20in%20support%20of%20cryonics%20and%20mind%20uploading%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKgTDX9wEd4s3kubpr%2Fnew-book-from-leading-neuroscientist-in-support-of-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20book%20from%20leading%20neuroscientist%20in%20support%20of%20cryonics%20and%20mind%20uploading%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKgTDX9wEd4s3kubpr%2Fnew-book-from-leading-neuroscientist-in-support-of-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKgTDX9wEd4s3kubpr%2Fnew-book-from-leading-neuroscientist-in-support-of-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 57, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Sebastian_Seung\">Sebastian Seung</a>'s new book <em><a href=\"http://www.amazon.com/Connectome-How-Brains-Wiring-Makes/dp/0547508182/\">Connectome: How the Brain's Wiring Makes Us Who We Are</a></em>&nbsp;is very well-written, and aimed at a broad audience.</p>\n<p>The penultimate chapter explains why cryonics might make sense given our current understanding of the brain.</p>\n<p>The final chapter does the same for mind uploading.</p>\n<p>Transhumanism continues its march into the mainstream.</p>\n<p>Despite its flaws, I recommend the book.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jQytxyauJ7kPhhGj3": 2, "4Kcm4etxAJjmeDkHP": 2, "5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KgTDX9wEd4s3kubpr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 29, "extendedScore": null, "score": 8.455880636422577e-07, "legacy": true, "legacyId": "12846", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-09T04:55:16.024Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Superexponential Conceptspace, and Simple Words", "slug": "seq-rerun-superexponential-conceptspace-and-simple-words", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/h2ZDR3R89YnQn6ixt/seq-rerun-superexponential-conceptspace-and-simple-words", "pageUrlRelative": "/posts/h2ZDR3R89YnQn6ixt/seq-rerun-superexponential-conceptspace-and-simple-words", "linkUrl": "https://www.lesswrong.com/posts/h2ZDR3R89YnQn6ixt/seq-rerun-superexponential-conceptspace-and-simple-words", "postedAtFormatted": "Thursday, February 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Superexponential%20Conceptspace%2C%20and%20Simple%20Words&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Superexponential%20Conceptspace%2C%20and%20Simple%20Words%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh2ZDR3R89YnQn6ixt%2Fseq-rerun-superexponential-conceptspace-and-simple-words%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Superexponential%20Conceptspace%2C%20and%20Simple%20Words%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh2ZDR3R89YnQn6ixt%2Fseq-rerun-superexponential-conceptspace-and-simple-words", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh2ZDR3R89YnQn6ixt%2Fseq-rerun-superexponential-conceptspace-and-simple-words", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 229, "htmlBody": "<p>Today's post, <a href=\"/lw/o3/superexponential_conceptspace_and_simple_words/\">Superexponential Conceptspace, and Simple Words</a> was originally published on 24 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You draw an unsimple boundary without any reason to do so. The act of defining a word to refer to all humans, except black people, seems kind of suspicious. If you don't present reasons to draw that particular boundary, trying to create an \"arbitrary\" word in that location is like a detective saying: \"Well, I haven't the slightest shred of support one way or the other for who could've murdered those orphans... but have we considered John Q. Wiffleheim as a suspect?\"</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9w8/seq_rerun_mutual_information_and_density_in/\">Mutual Information, and Density in Thingspace</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "h2ZDR3R89YnQn6ixt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.45759206119736e-07, "legacy": true, "legacyId": "12867", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["82eMd5KLiJ5Z6rTrr", "hsLexSqHJbbCtv2HH", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-09T07:41:28.468Z", "modifiedAt": null, "url": null, "title": "Feed the spinoff heuristic!", "slug": "feed-the-spinoff-heuristic", "viewCount": null, "lastCommentedAt": "2021-06-02T00:55:06.308Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aYtgZTKJwREEwhDjg/feed-the-spinoff-heuristic", "pageUrlRelative": "/posts/aYtgZTKJwREEwhDjg/feed-the-spinoff-heuristic", "linkUrl": "https://www.lesswrong.com/posts/aYtgZTKJwREEwhDjg/feed-the-spinoff-heuristic", "postedAtFormatted": "Thursday, February 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Feed%20the%20spinoff%20heuristic!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFeed%20the%20spinoff%20heuristic!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaYtgZTKJwREEwhDjg%2Ffeed-the-spinoff-heuristic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Feed%20the%20spinoff%20heuristic!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaYtgZTKJwREEwhDjg%2Ffeed-the-spinoff-heuristic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaYtgZTKJwREEwhDjg%2Ffeed-the-spinoff-heuristic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 497, "htmlBody": "<p>Follow-up to:</p>\n<p><a href=\"/lw/1ib/parapsychology_the_control_group_for_science/\">Parapsychology: the control group for science</a></p>\n<p><a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">Some Heuristics for Evaluating the Soundness of the Academic Mainstream in Unfamiliar Fields</a></p>\n<p>Recent renewed discussions of the parapsychology literature and Daryl Bem's recent precognition article brought to mind the \"market test\" of claims of precognition. Bem tells us that random undergraduate students were able to predict with 53% accuracy where an erotic image would appear in the future. If this effect was actually real, I would rerun the experiment before corporate earnings announcements, central bank interest rate changes, etc, and change the images based on the reaction of stocks and bonds to the announcements. In other words, I could easily convert \"porn precognition\" into \"hedge fund trillionaire precognition.\"</p>\n<p>If I was initially lacking in the capital to do trades, I could publish my predictions online using public key cryptography and amass an impressive track record before recruiting investors. If anti-psi prejudice was a problem, no one need know how I was making my predictions. Similar setups could exploit other effects claimed in the parapsychology literature (e.g. the remote viewing of the Scientologist-founded Stargate Project of the U.S. federal government). Those who assign a lot of credence to psi may want to actually try this, but for me this is an invitation to use parapsychology as control group for science, and to ponder a general&nbsp;<a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">heuristic</a>&nbsp;for crudely estimating the soundness of academic fields for outsiders.</p>\n<p>One reason we trust that physicists and chemists have some understanding of their subjects is that they produce valuable technological spinoffs with concrete and measurable economic benefit. In practice, I often make use of the spinoff heuristic: If an unfamiliar field has the sort of knowledge it claims, what commercial spinoffs and concrete results ought it to be producing? Do such spinoffs exist? What are the explanations for their absence?</p>\n<p>For psychology, I might cite <a href=\"http://en.wikipedia.org/wiki/Systematic_desensitization\">systematic desensitization</a> of specific phobias such as fear of spiders, <a href=\"http://en.wikipedia.org/wiki/Cognitive_behavioral_therapy\">cognitive-behavioral therapy</a>, and&nbsp;<a href=\"http://www.udel.edu/educ/gottfredson/reprints/2005g-jobs-life.pdf\">military use</a> of IQ tests (with large measurable changes in accident rates, training costs, etc). In financial economics, I would raise the hundreds of billions of dollars invested in <a href=\"http://en.wikipedia.org/wiki/Index_fund\">index funds</a>, founded in response to academic research, and their outperformance relative to managed funds. Auction theory powers tens of billions of dollars of wireless spectrum auctions, not to mention <a href=\"http://marginalrevolution.com/marginalrevolution/2008/12/profitable-unti.html\">evil dollar-auction sites</a>.&nbsp;</p>\n<p>This seems like a great task for crowdsourcing: the cloud of LessWrongers has broad knowledge, and sorting real science from <a href=\"http://www.lhup.edu/~DSIMANEK/cargocul.htm\">cargo cult science</a> is core to being Less Wrong. So I ask you, Less Wrongers, for your examples of practical spinoffs (or suspicious absences thereof) of sometimes-denigrated fields in the comments. Macroeconomics, personality psychology, physical anthropology, education research, gene-association studies, nutrition research, wherever you have knowledge to share.</p>\n<p>ETA: This <a href=\"http://www.michaelsfranklin.com/\">academic</a>&nbsp;claims to be trying to use the Bem methods to predict roulette wheels, and to have passed statistical significance tests on his first runs. Such claims have been made for casinos in the past, but always trailed away in failures to replicate, repeat, or make actual money. I expect the same to happen here.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZpG9rheyAkgCoEQea": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aYtgZTKJwREEwhDjg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": 81, "extendedScore": null, "score": 0.000167, "legacy": true, "legacyId": "12880", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 81, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 91, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["enuGsZoFLR4KyEx3n", "fyZBtNB3Ki3fM4a6Y"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-09T18:39:17.773Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow 11 February meetup", "slug": "meetup-moscow-11-february-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.450Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BT_Uytya", "createdAt": "2011-12-03T16:41:14.863Z", "isAdmin": false, "displayName": "BT_Uytya"}, "userId": "Enh7Ap3zRTQDR4gMH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pAkwxvJsSyL6dAXKn/meetup-moscow-11-february-meetup", "pageUrlRelative": "/posts/pAkwxvJsSyL6dAXKn/meetup-moscow-11-february-meetup", "linkUrl": "https://www.lesswrong.com/posts/pAkwxvJsSyL6dAXKn/meetup-moscow-11-february-meetup", "postedAtFormatted": "Thursday, February 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%2011%20February%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%2011%20February%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAkwxvJsSyL6dAXKn%2Fmeetup-moscow-11-february-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%2011%20February%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAkwxvJsSyL6dAXKn%2Fmeetup-moscow-11-february-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAkwxvJsSyL6dAXKn%2Fmeetup-moscow-11-february-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6x'>Moscow 11 February meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 February 2012 06:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Mayakovskaya (Subway Station), Moscow, Russia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Despite the map (I have no idea why, but it shows wrong place), location of the meetup is Metro Mayakovskaya (in the center of the hall). For further information - turchin.livejournal.com</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6x'>Moscow 11 February meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pAkwxvJsSyL6dAXKn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 8.460811489301634e-07, "legacy": true, "legacyId": "12887", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow_11_February_meetup\">Discussion article for the meetup : <a href=\"/meetups/6x\">Moscow 11 February meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 February 2012 06:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Mayakovskaya (Subway Station), Moscow, Russia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Despite the map (I have no idea why, but it shows wrong place), location of the meetup is Metro Mayakovskaya (in the center of the hall). For further information - turchin.livejournal.com</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow_11_February_meetup1\">Discussion article for the meetup : <a href=\"/meetups/6x\">Moscow 11 February meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow 11 February meetup", "anchor": "Discussion_article_for_the_meetup___Moscow_11_February_meetup", "level": 1}, {"title": "Discussion article for the meetup : Moscow 11 February meetup", "anchor": "Discussion_article_for_the_meetup___Moscow_11_February_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-09T20:04:26.597Z", "modifiedAt": null, "url": null, "title": "Counter-irrationality", "slug": "counter-irrationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.676Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spectral_Dragon", "createdAt": "2012-01-14T14:24:07.407Z", "isAdmin": false, "displayName": "Spectral_Dragon"}, "userId": "JeoxZ45Aada9AwZXN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4LdNAm3QH5nQHi7Zn/counter-irrationality", "pageUrlRelative": "/posts/4LdNAm3QH5nQHi7Zn/counter-irrationality", "linkUrl": "https://www.lesswrong.com/posts/4LdNAm3QH5nQHi7Zn/counter-irrationality", "postedAtFormatted": "Thursday, February 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Counter-irrationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACounter-irrationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4LdNAm3QH5nQHi7Zn%2Fcounter-irrationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Counter-irrationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4LdNAm3QH5nQHi7Zn%2Fcounter-irrationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4LdNAm3QH5nQHi7Zn%2Fcounter-irrationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 245, "htmlBody": "<p>I don't think anyone here is perfect, though a lot here is simply brilliant logic. Though, as humans, we're automatically biased for or against something, at times for the wrong things and reasons. No bias at all isn't something we're equipped for, and to me sounds quite dull. Some things we have to believe, even as with our limited lifespan it would be very hard to learn everything.</p>\n<p>Anyway, on to my actual point: How often do you realise you're biased for the wrong reasons, and you argue more for winning than being right? Also, what irrationality can you point out, and how to fight it? This could apply to you, or those around you, doesn't matter as no one's perfect. But as usual, we should try to at least be better.</p>\n<p>Right now I'm trying to figure out how to best deal with unreasonable demands. A theological debate which eventually went \"Well, if science can't do X, it is flawed, and we should accept that some questions are unanswerable.\", and I'm working out the most efficient counter-argument (leaning towards \"that's why we should try to see if it's impossible or not\"). Anyway, share your thoughts on this, how to be efficiently rational, though if you try to help me, I'd like more questions instead of answers. I value the process of rationality more than straight-up answers, even though it's frustrating as it is.</p>\n<p>Basically: Flaws you encounter and how to fight them efficiently, maybe [Bayesian Judo style](<a href=\"http://lesswrong.com/lw/i5/bayesian_judo/\">http://lesswrong.com/lw/i5/bayesian_judo/</a>).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4LdNAm3QH5nQHi7Zn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -4, "extendedScore": null, "score": 8.461144277037995e-07, "legacy": true, "legacyId": "12888", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NKaPFf98Y5otMbsPk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T01:25:55.463Z", "modifiedAt": null, "url": null, "title": "3^^^3 holes and <10^(3*10^31) pigeons (or vice versa)", "slug": "3-3-holes-and-less-than-10-3-10-31-pigeons-or-vice-versa", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.741Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dmytry", "createdAt": "2009-12-03T17:11:53.492Z", "isAdmin": false, "displayName": "Dmytry"}, "userId": "AjtmA2qtA8sdiMbru", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QvEogsrKJkY5ZNXeH/3-3-holes-and-less-than-10-3-10-31-pigeons-or-vice-versa", "pageUrlRelative": "/posts/QvEogsrKJkY5ZNXeH/3-3-holes-and-less-than-10-3-10-31-pigeons-or-vice-versa", "linkUrl": "https://www.lesswrong.com/posts/QvEogsrKJkY5ZNXeH/3-3-holes-and-less-than-10-3-10-31-pigeons-or-vice-versa", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%203%5E%5E%5E3%20holes%20and%20%3C10%5E(3*10%5E31)%20pigeons%20(or%20vice%20versa)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A3%5E%5E%5E3%20holes%20and%20%3C10%5E(3*10%5E31)%20pigeons%20(or%20vice%20versa)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQvEogsrKJkY5ZNXeH%2F3-3-holes-and-less-than-10-3-10-31-pigeons-or-vice-versa%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=3%5E%5E%5E3%20holes%20and%20%3C10%5E(3*10%5E31)%20pigeons%20(or%20vice%20versa)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQvEogsrKJkY5ZNXeH%2F3-3-holes-and-less-than-10-3-10-31-pigeons-or-vice-versa", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQvEogsrKJkY5ZNXeH%2F3-3-holes-and-less-than-10-3-10-31-pigeons-or-vice-versa", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 815, "htmlBody": "<p>The reasoning about huge numbers of beings is a recurring theme here. <a href=\"http://en.wikipedia.org/wiki/Knuth%27s_up-arrow_notation\">Knuth's up-arrow notation</a> is often used, with 3^^^3 as the number of beings.</p>\n<p>I want to note that if a being is made of 10^30 parts, with 10^30 distinct states of each part, the number of distinct being states is (10^30)^(10^30) = 10^(3*10^31) . That's not a very big number; stacking uparrows quickly gets you to much larger numbers.</p>\n<p>To quote from <a href=\"/lw/kn/torture_vs_dust_specks/\">Torture Vs Dust Specks</a>:</p>\n<blockquote>\n<p>&nbsp;</p>\n<ul>\n<li>3^3 = 27.</li>\n<li>3^^3 = (3^(3^3)) = 3^27 = 7625597484987.</li>\n<li>3^^^3 = (3^^(3^^3)) = 3^^7625597484987 = (3^(3^(3^(... 7625597484987 times ...)))).</li>\n</ul>\n<p>3^^^3 is an exponential tower of 3s which is 7,625,597,484,987 layers tall.&nbsp; You start with 1; raise 3 to the power of 1 to get 3; raise 3 to the power of 3 to get 27; raise 3 to the power of 27 to get 7625597484987; raise 3 to the power of 7625597484987 to get a number much larger than the number of atoms in the universe, but which could still be <em>written down</em> in base 10, on 100 square kilometers of paper; then raise 3 to <em>that</em> power; and continue until you've exponentiated 7625597484987 times.&nbsp; That's 3^^^3.&nbsp; It's the smallest simple inconceivably huge number I know.</p>\n</blockquote>\n<p>That's an unimaginably bigger number than 10^(3*10^31) . You just can't have 3^^^3 distinct humans (or the beings that are to human as human is to amoeba, or that repeated zillion times, or distinct universes for that matter). Most of them will be exactly identical to very many others among the 3^^^3 and have exactly identical experience*.</p>\n<p>Of course, our reasoning does not somehow subconsciously impose a reasonable cap on number of beings and end up rational afterwards. I'm not arguing that gut feeling includes such consideration. (I'd say it usually just considers substantially different things incomparable and in-convertible, plus the space of utility needs not be one dimensional)</p>\n<p>I've made this pigeon-hole example to demonstrate a failure with really huge numbers, that can undermine by an inconceivably huge factor the reasoning that seems rational and utilitarian and carefully done.</p>\n<p>Also, it does seem to me that if the reasoning with huge numbers is likely to result in reasoning errors, then it can be rational to adopt some constraints/safeguards (e.g. veto approval of torture on basis of dust specks, veto pascal's mugging with very huge numbers, perhaps in general veto conversion between things of very different magnitude) as a rational strategy when one is aware that one is likely processing huge numbers incorrectly, not just on the gut feeling level but on conscious work with pencil and paper level as well.</p>\n<p>An autopilot may strive for some minimization of total passenger discomfort over the flight, but also have a hard constraints on the max acceleration in the case that the discomfort minimization approach leads to something ridiculous.</p>\n<p>* footnote: I don't think many people involved with AI research would count identical copies multiple times. But that is a tangential point. The issue is that when reading of 3^^^3 beings, it is really easy to make a mistake of not even checking whenever you do or don't count identical copies many times. The problem is that 3^^^3 is much, much larger than the numbers we would normally approximate as infinite.</p>\n<p>On the counting of 'identical' items. Consider a computer system that has 2 copies of all data and re-does every calculation it makes. If it runs an AI, it may seem sensible to count AI twice when it's 2 computers in 2 boxes that are staying next to each other running same software on same input, but much less so if you picture one computer where each chip got two dies, one a mirror copy of the other, put right on top of it, separated by very thin layer of dielectric which serves no purpose (the potentials are same on both sides of it), and it's absurd if you remove the dielectric - it's 1 computer, just the wires are thicker, currents 2x larger, and transistors are in parallel pairs. Counting identical stuff several times is something we do when there's a difference in e.g. location, which renders stuff not identical. Decrease the spatial separation and the inclination to count identical items twice decreases. Have a giant server farm where next to each server there is the 2 backup servers in identical state (to recover when one fails), and I think just about any programmer would quickly forget about this minor implementation detail; have two giant server farms on opposite sides of Earth and you'll for sure feel like counting it twice.</p>\n<p>edit: sorry for not being explicit, I kind of assumed the point was clear enough. Improved it.</p>\n<p>Also, that's not for just dust specks vs torture but goes for all the other examples where the knuth up arrows are used to make very huge numbers. Pascal's mugging discussions for example.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QvEogsrKJkY5ZNXeH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 16, "extendedScore": null, "score": 8.46240095804143e-07, "legacy": true, "legacyId": "12884", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3wYTFWY3LKQCnAptN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T02:28:27.089Z", "modifiedAt": null, "url": null, "title": "Beyond Reasonable Doubt? - Richard Dawkins [link]", "slug": "beyond-reasonable-doubt-richard-dawkins-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:59.310Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dreaded_Anomaly", "createdAt": "2010-12-30T06:38:34.106Z", "isAdmin": false, "displayName": "Dreaded_Anomaly"}, "userId": "sBHF4CXWBLakPFzfu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CWfcGbSPioJBvrPEZ/beyond-reasonable-doubt-richard-dawkins-link", "pageUrlRelative": "/posts/CWfcGbSPioJBvrPEZ/beyond-reasonable-doubt-richard-dawkins-link", "linkUrl": "https://www.lesswrong.com/posts/CWfcGbSPioJBvrPEZ/beyond-reasonable-doubt-richard-dawkins-link", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beyond%20Reasonable%20Doubt%3F%20-%20Richard%20Dawkins%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeyond%20Reasonable%20Doubt%3F%20-%20Richard%20Dawkins%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCWfcGbSPioJBvrPEZ%2Fbeyond-reasonable-doubt-richard-dawkins-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beyond%20Reasonable%20Doubt%3F%20-%20Richard%20Dawkins%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCWfcGbSPioJBvrPEZ%2Fbeyond-reasonable-doubt-richard-dawkins-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCWfcGbSPioJBvrPEZ%2Fbeyond-reasonable-doubt-richard-dawkins-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 218, "htmlBody": "<p><a href=\"http://richarddawkins.net/articles/644734-beyond-reasonable-doubt\" target=\"_blank\">A new article looking at the jury system rationally and scientifically.</a></p>\n<p>Excerpt:</p>\n<blockquote>\n<p>Courtroom dramas accurately portray the suspense that hangs in the  air when the jury returns and delivers its verdict. All, including the  lawyers on both sides and the judge, are on tenterhooks and hold their  breath while they wait to hear the foreman of the jury pronounce the  words, &ldquo;Guilty&rdquo; or &ldquo;Not guilty&rdquo;. However, if the phrase &ldquo;beyond  reasonable doubt&rdquo; means what it says, there should be no doubt of the  outcome in the mind of anybody who has sat through the same trial as the  jury. That includes the judge who, as soon as the jury has delivered  its verdict, is prepared to give the order for execution &mdash; or release  the prisoner without a stain on his character.</p>\n<p>And yet, before the jury returned, there was enough &ldquo;reasonable  doubt&rdquo; in that same judge&rsquo;s mind to keep him on tenterhooks waiting for  the verdict.</p>\n<p>You cannot have it both ways. Either the verdict is beyond reasonable  doubt, in which case there should be no suspense while the jury is out.  Or there is real, nail-biting suspense, in which case you cannot claim  that the case has been proved &ldquo;beyond reasonable doubt&rdquo;.</p>\n</blockquote>\n<p>This really struck me as something that could have been on LW's front page.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 1, "wGGAjTfXZBatQkft5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CWfcGbSPioJBvrPEZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 33, "extendedScore": null, "score": 8.9e-05, "legacy": true, "legacyId": "12911", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T02:48:18.812Z", "modifiedAt": "2021-03-28T20:17:49.577Z", "url": null, "title": "My Algorithm for Beating Procrastination", "slug": "my-algorithm-for-beating-procrastination", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:30.730Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ty2tjPwv8uyPK9vrz/my-algorithm-for-beating-procrastination", "pageUrlRelative": "/posts/Ty2tjPwv8uyPK9vrz/my-algorithm-for-beating-procrastination", "linkUrl": "https://www.lesswrong.com/posts/Ty2tjPwv8uyPK9vrz/my-algorithm-for-beating-procrastination", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20Algorithm%20for%20Beating%20Procrastination&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20Algorithm%20for%20Beating%20Procrastination%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTy2tjPwv8uyPK9vrz%2Fmy-algorithm-for-beating-procrastination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20Algorithm%20for%20Beating%20Procrastination%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTy2tjPwv8uyPK9vrz%2Fmy-algorithm-for-beating-procrastination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTy2tjPwv8uyPK9vrz%2Fmy-algorithm-for-beating-procrastination", "socialPreviewImageUrl": "https://web.archive.org/web/20180726091558im_/http://commonsenseatheism.com/wp-content/uploads/2011/01/procrastination-equation.png", "question": false, "authorIsUnreviewed": false, "wordCount": 2048, "htmlBody": "<p>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a></p><p>After three months of practice, I now use a single algorithm to beat procrastination most of the times I face it.<sup>1</sup> It <a href=\"/lw/9v/beware_of_otheroptimizing/\">probably won't work for you</a> quite like it did for me, but it's the best advice on motivation I've got, and it's a major reason I'm known for having the \"gets shit done\" property. There are <a href=\"/r/discussion/lw/9i6/breaking_the_chain_of_akrasia/\">reasons to hope</a> that we can eventually <a href=\"/lw/99t/can_the_chain_still_hold_you/\">break the chain</a> of <a href=\"/lw/1sm/akrasia_tactics_review\">akrasia</a>; maybe this post is one <a href=\"/lw/58m/build_small_skills_in_the_right_order/\">baby step</a> in the right direction.</p><p><a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a> explained our best current general <i>theory</i> of procrastination, called \"<a href=\"http://webapps2.ucalgary.ca/~steel/images/Integrating.pdf\">temporal motivation theory</a>\" (TMT). As an exercise in <a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">practical advice backed by deep theories</a>, <i>this</i> post explains the <i>process</i> I use to beat procrastination \u2014 a process implied by TMT.</p><p>As a reminder, here's a rough sketch of how motivation works according to TMT:</p><figure class=\"image image_resized\" style=\"width:100%\"><img src=\"https://web.archive.org/web/20180726091558im_/http://commonsenseatheism.com/wp-content/uploads/2011/01/procrastination-equation.png\"></figure><p>Or, as Piers Steel <a href=\"http://www.amazon.com/Procrastination-Equation-Putting-Things-Getting/dp/0061703613/\">summarizes</a>:</p><blockquote><p>Decrease the certainty or the size of a task's reward \u2014 its expectancy or its value \u2014 and you are unlikely to pursue its completion with any vigor. Increase the delay for the task's reward and our susceptibility to delay \u2014 impulsiveness \u2014 and motivation also dips.</p></blockquote><p>Of course, my motivation system is <a href=\"/lw/9jh/the_humans_hidden_utility_function_maybe/\">more complex</a> than that. P.J. Eby <a href=\"/lw/9i6/breaking_the_chain_of_akrasia/5qj5\">likens</a> TMT (as a guide for beating procrastination) to the \"fuel, air, ignition, and compression\" plan for starting your car: it might be true, but a more useful theory would include details and mechanism.</p><p>That's a fair criticism. Just as an fMRI captures the \"big picture\" of brain function at low resolution, TMT captures the big picture of motivation. This big picture helps us see where we need to work at the gears-and-circuits level, so we can become the goal-directed <a href=\"/lw/8q8/urges_vs_goals_the_analogy_to_anticipation_and/\">consequentialists</a> we'd <i>like</i> to be.</p><p>So, I'll share my four-step algorithm below, and tackle the gears-and-circuits level in later posts.</p><p>&nbsp;</p><p>Step 1: Notice I'm procrastinating.</p><p>This part's easy. I know I <i>should</i> do the task, but I feel averse to doing it, or I just don't feel motivated enough to care. So I put it off, even though my prefrontal cortex keeps telling me I'll be better off if I do it <i>now</i>. When this happens, I proceed to step 2.</p><p>&nbsp;</p><p>Step 2: Guess which unattacked part of the equation is causing me the most trouble.</p><p>Now I get to play detective. Which part of the equation is causing me trouble, here? Does the task have low value because it's boring or painful or too difficult, or because the reward isn't that great? Do I doubt that completing the task will pay off? Would I have to wait a long time for my reward if I succeeded? Am I particularly impatient or impulsive, either now or in general? Which part of this problem do I need to attack?</p><p>Actually, I lied. <i>I</i> like to play <i>army sniper</i>. I stare down my <a href=\"http://en.wikipedia.org/wiki/Telescopic_sight\">telescopic sight</a> at the terms in the equation and interrogate them. \"Is it <i>you</i>, Delay? Huh, motherfucker? Is it <i>you</i>? I've shot you before; don't think I won't do it again!\"</p><p>But not everyone was raised on violent videogames. <i>You</i> may prefer a different role-play.</p><p>Anyway, I try to figure out where the main problem is. Here are some of the signs I look for:</p><p>When I imagine myself doing the task, do I see myself bored and distracted instead of engaged and interested? Is the task uncomfortable, onerous, or painful? Am I nervous about the task, or afraid of what might happen if I undertake it? Has the task's payoff lost its value to me? Perhaps it never had much value to me in the first place? If my answer to any of these questions is \"Yes,\" I'm probably facing the motivation problem of <i>low value</i>.</p><p>Do I think I'm likely to succeed at the task? Do I think it's within my capabilities? Do I think I'll actually <i>get</i> the reward if I <i>do</i> succeed? If my answer to any of these questions is \"No,\" I'm probably facing the problem of <i>low expectancy</i>.</p><p>How much of the reward only comes after a significant delay, and how long is that delay? If most of the reward comes after a big delay, I'm probably the facing the problem of, you guessed it, <i>delay</i>.</p><p>Do I feel particularly impatient? Am I easily distracted by other tasks, even ones for which I also face problems of low value, low expectancy, or delay? If so, I'm probably facing the problem of <i>impulsiveness</i>.</p><p>If the task is low value and low expectancy, and the reward is delayed, I run my expected value calculation again. Am I sure I <i>should</i> do the task, after all? Maybe I should drop it or delegate it. If after re-evaluation I <i>still</i> think I should do the task, then I move to step 3.</p><p>&nbsp;</p><p>Step 3: Try several methods for attacking that specific problem.</p><p>Once I've got a plausible suspect in my sights, I fire away with the most suitable ammo I've got for that problem. Here's a quick review of some techniques described in <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a>:</p><p>For <a href=\"/lw/3w3/how_to_beat_procrastination/#value\">attacking the problem of low value</a>: Get into a state of flow, perhaps by gamifying the task. Ensure the task has meaning by connecting it to what you value intrinsically. Get more energy. Use reward and punishment. Focus on what you love, wherever possible.</p><p>For <a href=\"/lw/3w3/how_to_beat_procrastination/#optimism\">attacking the problem of low expectancy</a>: Give yourself a series of small, challenging but achieveable goals so that you get yourself into a \"success spiral\" and expect to succeed. Consume inspirational material. Surround yourself with others who are succeeding. Mentally contrast where you are now and where you want to be.</p><p>For <a href=\"/lw/5p6/how_and_why_to_granularize/\">attacking the problem of delay</a>: Decrease the reward's delay if possible. Break the task into smaller chunks so you can get rewards each step of the way.</p><p>For <a href=\"/lw/3w3/how_to_beat_procrastination/#impulsiveness\">attacking the problem of impulsiveness</a>: Use precommitment. Set specific and meaningful goals and subgoal and sub-subgoals. Measure your behavior. Build useful habits.</p><p>Each of these skills must be learned and practiced first before you can use them. It took me only a few days to learn the mental habit of \"mental contrasting,\" but I spent <i>weeks</i> practicing the skill of getting myself into <i>success spirals</i>. I've spent <i>months</i> trying various methods for having more energy, but I can do a lot better than I'm doing now. I'm not very good at goal-setting yet.</p><p>&nbsp;</p><p>Step 4: If I'm still procrastinating, return to step 2.</p><p>If I've found some successful techniques for attacking the term in the motivation equation I thought was causing me the most trouble, but I'm still procrastinating, I return to step 2 and begin my assault on <i>another</i> term in the equation.</p><p>When I first began using this algorithm, though, I usually didn't get that far. By the time I had learned mental contrasting or success spirals or whatever tool made the difference, the task was either complete or abandoned. This algorithm only begins to shine, I suspect, once you've come to some level of mastery on most of the subroutines it employs. Then you can quickly employ them and, if you're still procrastinating, immediately employ others, until your procrastination is beaten.</p><p>&nbsp;</p><p>Personal examples</p><p>Let me give you some idea of what it looks like for me to use this algorithm:</p><p>Building the large 5\u00d75-unit Ikea \"<a href=\"http://www.ikea.com/us/en/catalog/products/00208646/#/60208648\">Expedit</a>\" bookshelf is boring and repetitive, so I made a game of it. I pounded each wooden peg 4 or 5 times, alternating between these two counts no matter how quickly each peg went into its hole, waiting to see if the girl I was with would notice the pattern. She didn't, so after every 10th peg I gave her a kiss, waiting to see if she'd catch <i>that</i> pattern. She didn't, so I started kissing her after every 5th peg.<sup>2</sup> Apparently she thought I was just especially amorous that night.</p><p>Sometimes, being an <a href=\"/r/discussion/lw/8s6/video_qa_with_singularity_institute_executive/\">executive director</a> just ain't fun. I need to make lots of decisions with large but uncertain consequences \u2014 decisions that some people will love and others will hate. This is not as cozy as the quiet researcher's life to which I had been growing accustomed. In many cases, the task of coming to a decision on something is fraught with anxiety and fear, and I procrastinate. In these cases, I remind myself of how the decision is connected to what I care about. I also purposely stoke my passion for the organization's mission by playing epic world-saving music like \"<a href=\"http://www.youtube.com/watch?v=EzCKrwOme2U\">Butterflies and Hurricanes</a>\" by Muse: \"Change everything you are... your number has been called... you've got to be the best, you've got to change the world... your time is now.\" Then I re-do my <a href=\"/lw/85x/value_of_information_four_examples/\">VoI</a> and <a href=\"http://wiki.lesswrong.com/wiki/Expected_value\">EV</a> calculations again and I god damned <a href=\"/lw/uh/trying_to_try/\"><i>try</i></a>.</p><p>While researching <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a>, I hired a German tutor. I planned to apply to philosophy graduate schools, which meant I needed to speak Greek, Latin, French, or German, and German philosophy isn't <i>quite</i> as universally bad as the others (e.g. see <a href=\"http://en.wikipedia.org/wiki/Thomas_Metzinger\">Thomas Metzinger</a>). But I procrastinated when studying, for my reward was <i>very</i> uncertain: would I actually go the route of philosophy grad school, and would my knowledge of German help? My reward was also extremely delayed, likely by several years. In the end, I did the expected value calculation more carefully than before, and concluded that I <i>shouldn't</i> keep trying to speak my Rs from my throat. It was the right call: I'm now pretty certain I'll never go to philosophy grad school.</p><p>Three times, I've started writing books. But each time, the rewards (appreciation, notoriety, money) were so delayed and uncertain that I gave up. Instead, I broke the books into chunks that I could publish as individual articles.<sup>3</sup> Thus, I received <i>some</i> reward (appreciation, growing notoriety) after every article, and had relatively high expectancy for this reward (since my goal was no longer so lofty as to be picked up by a major publisher). Breaking it into chunks also allowed me to focus on writing the pieces for which I had the most passion. Along the way, I used many techniques to boost my energy.</p><p>Conclusion</p><p>The key is to be <i>prepared</i> to conquer procrastination by practicing the necessary sub-skills <i>first</i>. <a href=\"/lw/58m/build_small_skills_in_the_right_order/\">Build small skills in the right order</a>. You can't play Philip Glass if you haven't first learned how to play scales, how to work the pedals, how to play arpeggios and ostinatos (<a href=\"http://www.allmusic.com/album/r106587\"><i>lots</i></a> of arpeggios and ostinatos), etc. And you can't beat procrastination if you don't have any ammo ready when you've caught the right causal factor in your sights.</p><p>The quest toward becoming a <a href=\"/lw/8q8/urges_vs_goals_the_analogy_to_anticipation_and/\">goal-directed consequentialist</a> is long and challenging, much like that of becoming a <a href=\"/lw/96j/what_curiosity_looks_like/\">truth-aiming rationalist</a>. But the rewards are great, and the journey has perks. Remember: <a href=\"/lw/5i8/the_power_of_agency/\">true agency</a> is rare but powerful. As Michael Vassar says, \"Evidence that people are crazy is evidence that things are easier than you think.\" Millions of projects fail not because they \"can't be done\" but because the first 5 people who tried them failed due to boring, pedestrian reasons like procrastination or the planning fallacy. People with just a <i>bit</i> more agency than normal \u2014 people like <a href=\"http://en.wikipedia.org/wiki/Benjamin_franklin\">Benjamin Franklin</a> and <a href=\"http://en.wikipedia.org/wiki/Timothy_Ferriss\">Tim Ferriss</a> \u2014 have incredible power.</p><p>At the end of <a href=\"http://www.amazon.com/Reasons-Persons-Oxford-Paperbacks-Parfit/dp/019824908X/\"><i>Reasons and Persons</i></a>, Derek Parfit notes that non-religious ethics is a young field, and thus we may entertain high hopes for what will be discovered and what is possible. But <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge\">scientific self-help</a> is even younger. We have only just begun our inquiry into procrastination's causes and cures. We don't yet know what is possible. All we can do is <a href=\"/lw/uh/trying_to_try/\">try</a>. If you have <a href=\"/lw/nb/something_to_protect/\">something to protect</a>, <a href=\"/lw/up/shut_up_and_do_the_impossible/\">shut up and do the impossible</a>. Things <a href=\"/lw/99t/can_the_chain_still_hold_you/\">may not be so impossible as you once thought</a>.</p><p>&nbsp;</p><p>Next post: <a href=\"/lw/4su/the_science_of_happiness/\">How to Be Happy</a></p><p>Previous post: <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a></p><p>&nbsp;</p><p>&nbsp;</p><p><sup>1</sup> The main areas where I still usually succumb to procrastination are diet and exercise. Luckily, my metabolism is holding out pretty well so far.</p><p><sup>2</sup> Or, it was <i>something</i> like this. I can't remember the exact game I played, now.</p><p><sup>3</sup> My abandoned book <i>Scientific Self Help</i> turned into my ongoing blog post sequence <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a>. My abandoned book <a href=\"http://commonsenseatheism.com/?p=14397\"><i>Ethics and Superintelligence</i></a> was broken into chunks that morphed into <a href=\"http://intelligence.org/singularityfaq\">Singularity FAQ</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/11/Muehlhauser-Helm-The-Singularity-and-Machine-Ethics-draft.pdf\">The Singularity and Machine Ethics</a>, and many posts from <a href=\"http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics</a> and <a href=\"http://facingthesingularity.com/\"><i>Facing the Singularity</i></a>. My abandoned book <i>Friendly AI: The Most Important Problem in the World</i> was broken into pieces that resulted in <a href=\"/lw/8f0/existential_risk/\">Existential Risk</a> and some posts of <a href=\"http://facingthesingularity.com/\"><i>Facing the Singularity</i></a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 5, "r7qAjcbfhj2256EHH": 2, "dqx5k65wjFfaiJ9sQ": 9, "9ponmAskWgC37GZKk": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ty2tjPwv8uyPK9vrz", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 118, "baseScore": 132, "extendedScore": null, "score": 0.000266, "legacy": true, "legacyId": "12843", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "https://web.archive.org/web/20180726091558im_/http://commonsenseatheism.com/wp-content/uploads/2011/01/procrastination-equation.png", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 132, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 138, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["6NvbSwuSAooQxxf7f", "4hMQHGMnsR4GJALmc", "iETtCZcfmRyHp69w4", "rRmisKb45dN7DK4BW", "qwdupkFd6kmeZHYXy", "RWo4LwFzpHNQCTcYt", "LqjKP255fPRY7aMzw", "fa5o2tg9EfJE77jEQ", "wmjPGE8TZKNLSKzm4", "jTk9m75y2bpujwRfb", "yGZHQYqWkLMbXy3z7", "vADtvr9iDeYsCDfxd", "WLJwTJ7uGPA5Qphbp", "3oYaLja5h8qL5adDn", "vbcjYg6h3XzuqaaN8", "33KewgYhNSxFpbpXg", "SGR4GxFK7KmW7ckCB", "nCvvhFBaayaXyuBiD", "ZbgCx2ntD5eu8Cno9", "FGTgeweYNxmMBx4fz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T03:10:46.602Z", "modifiedAt": null, "url": null, "title": "The Principle of Maximum Entropy", "slug": "the-principle-of-maximum-entropy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.476Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "krey", "createdAt": "2012-02-08T17:20:04.317Z", "isAdmin": false, "displayName": "krey"}, "userId": "8jYG8PMH4cjdjqkRE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LRHBduRjujLnFgJfS/the-principle-of-maximum-entropy", "pageUrlRelative": "/posts/LRHBduRjujLnFgJfS/the-principle-of-maximum-entropy", "linkUrl": "https://www.lesswrong.com/posts/LRHBduRjujLnFgJfS/the-principle-of-maximum-entropy", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Principle%20of%20Maximum%20Entropy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Principle%20of%20Maximum%20Entropy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLRHBduRjujLnFgJfS%2Fthe-principle-of-maximum-entropy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Principle%20of%20Maximum%20Entropy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLRHBduRjujLnFgJfS%2Fthe-principle-of-maximum-entropy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLRHBduRjujLnFgJfS%2Fthe-principle-of-maximum-entropy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 84, "htmlBody": "<p>After having read the related chapters of Jaynes' book I was fairly amazed by the Principle of Maximum Entropy, a powerful method for choosing prior distributions. However it immediately raised a large number of questions.</p>\n<p>I have recently read two quite intriguing (and very well-written) papers by Jos Uffink on this matter:</p>\n<p><a href=\"http://www.projects.science.uu.nl/igg/jos/mepabst/mepabst.html\">Can the maximum entropy principle be explained as a consistency requirement?</a></p>\n<p><a href=\"http://www.projects.science.uu.nl/igg/jos/mep2def/mep2def.html\">The constraint rule of the maximum entropy principle<br /></a></p>\n<p>I was wondering what you think about the principle of maximum entropy and its justifications.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LRHBduRjujLnFgJfS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 13, "extendedScore": null, "score": 8.462810899764182e-07, "legacy": true, "legacyId": "12912", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T03:37:16.258Z", "modifiedAt": null, "url": null, "title": "The Neuroscience of Moral Motivation (Part 1)", "slug": "the-neuroscience-of-moral-motivation-part-1", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.087Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "C3Sc9XJXd5AsAyksf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dsr3Zyxk3o8BtChmr/the-neuroscience-of-moral-motivation-part-1", "pageUrlRelative": "/posts/dsr3Zyxk3o8BtChmr/the-neuroscience-of-moral-motivation-part-1", "linkUrl": "https://www.lesswrong.com/posts/dsr3Zyxk3o8BtChmr/the-neuroscience-of-moral-motivation-part-1", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Neuroscience%20of%20Moral%20Motivation%20(Part%201)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Neuroscience%20of%20Moral%20Motivation%20(Part%201)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdsr3Zyxk3o8BtChmr%2Fthe-neuroscience-of-moral-motivation-part-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Neuroscience%20of%20Moral%20Motivation%20(Part%201)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdsr3Zyxk3o8BtChmr%2Fthe-neuroscience-of-moral-motivation-part-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdsr3Zyxk3o8BtChmr%2Fthe-neuroscience-of-moral-motivation-part-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 747, "htmlBody": "<p>Edit: <a href=\"/lw/9yd/the_neuroscience_of_moral_motivation_part_1/5v1s\">Oops, I made a mistake.</a> Sorry about that. I'm going to consolidate the parts into one post.</p>\n<p>&nbsp;</p>\n<hr />\n<hr />\n<hr />\n<p>&nbsp;</p>\n<p>Imagine you are walking down a Los Angeles street when you see a homeless man.&nbsp; He's sitting outside a coffee shop and begging for food.&nbsp; You stop to give him a sympathetic look.&nbsp; Quickly, you enter the shop to buy a muffin and juice.&nbsp; You then give him the food, which he happily takes.&nbsp; After wishing him well, you continue on walking.&nbsp; By many accounts, you have just done a morally good action.<sup>1</sup></p>\n<p>In real life, you may never have given food to a starving man.&nbsp; However, it is likely that you have done other morally good actions.<sup>2</sup>&nbsp; Maybe you have done volunteer work in your community.&nbsp; Maybe you have donated to charity.&nbsp; Think of a time you did a morally good action.&nbsp; Got it?&nbsp; Good.</p>\n<p>How can we explain why you committed this moral action?&nbsp; Or more broadly, how can we explain why we act at all?&nbsp; One popular explanation of action comes from folk psychology.&nbsp; As <a href=\"/user/lukeprog/\">Luke</a> summarizes, \"[f]olk psychology posits that we humans have beliefs and desires, and that we are motivated to do what we believe will fulfill our desires.\"<sup>3&nbsp; </sup>While the folk psychology model is useful for daily life, it has several grave flaws.<sup>4</sup></p>\n<p>In response to these flaws, economists have refined and quantified folk psychology into <a href=\"http://www.econlib.org/library/Enc1/NeoclassicalEconomics.html\">neoclassical economics</a>.&nbsp; These economic models are more useful than folk psychology for explaining and predicting human action.&nbsp; However, as Luke points out, they still aren't perfect.&nbsp; In <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human/\">\"A Crash Course in the Neuroscience of Human Motivation,\"</a> Luke describes the challenges these models face.&nbsp; Moreover, he details how the neoclassical model can be further improved and <a href=\"/lw/on/reductionism/\">reduced</a> through the insights of modern neuroscience.</p>\n<p>Nevertheless, that reduction only covers amoral actions.&nbsp; We're still left with the question at the beginning of this post: what is the explanation for our moral actions?&nbsp; What causal roles (if any) do our beliefs, desires, and feelings play? This sequence uses neuroscience to shed light on those questions.&nbsp; It will do so over the course of four posts.</p>\n<p>This is the first post, which serves as an introduction.&nbsp; It has introduced the driving question behind the sequence.&nbsp; The remainder outlines the next three posts.</p>\n<p>The second post gives an overview of the mainstream philosophical accounts of action.&nbsp; It uses folk psychological terms such as \"motivation,\" as philosophy largely relies on folk psychology.&nbsp; The post delves into the externalist - internalist controversy.</p>\n<p>The third post covers the specific philosophical accounts of moral action.&nbsp; It discusses the four mainstream views: instrumentalism, cognitivism, sentimentalism, and personalism.<sup>5&nbsp; </sup>Comparisons between the views show where they agree and disagree.&nbsp; The views are also described with reference to the controvers discussed in the second post.&nbsp; Last, this post details the different experiences we should anticipate about the brain by accepting one view over the others.</p>\n<p>The fourth post concludes the sequence by comparing the anticipated facts of each philosophical view with how the brain actually works.&nbsp; Some views are more consistent with the neuroscience than others are.&nbsp; Thus, those that are consistent are more likely to be correct.<sup>6&nbsp; </sup>And though not yet falsified, those views that contradict current neuroscience have large obstacles to overcome.&nbsp; These challenges should be noted when painting the larger metaethical picture.<sup>7</sup></p>\n<hr />\n<p><strong>Notes</strong></p>\n<p>[1]&nbsp; Example adapted from Schroeder (2010).</p>\n<p>[2]&nbsp; In this post, I write as though moral realism is correct.&nbsp; I did this for ease of explanation, not because I necessarily agree.&nbsp; This sequence does not depend on the reader holding any particular metaethical view about the existence of moral facts.&nbsp; I encourage moral anti-realists/irrealists to read \"morally good actions\" as \"actions which some accounts consider moral,\" or something similar.</p>\n<p>[3]&nbsp; Quoted from <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human\">\"A Crash Course in the Neuroscience of Human Motivation.\"</a></p>\n<p>[4]&nbsp; For an explanation of the flaws, see Churchland (1981).</p>\n<p>[5]&nbsp; In this context, \"cognitivism\" doesn't refer to the metaethical view that moral language expresses truth-apt propositions.</p>\n<p>[6] As per <a href=\"http://commonsenseatheism.com/?p=13156\">Bayes' rule</a>, P(H|E)&nbsp;&prop; P(E|H).</p>\n<p>[7] Credit for the sequence idea goes to Luke.&nbsp; This is one of his <a href=\"/lw/85d/11_less_wrong_articles_i_probably_will_never_have/\">11 LessWrong articles he'll probably never have time to write</a>.&nbsp; I hope it helps close some inferential gaps for his metaethics sequence.&nbsp; Conversely, any errors in this sequence fall squarely on me.&nbsp; Correction, advice, criticism are encouraged. (Especially on my writing and citation style.)</p>\n<hr />\n<p><strong>References</strong></p>\n<p>Churchland (1981). <a href=\"http://stevewatson.info/courses/Mind/resources/readings/Churchland_ElimMater&amp;PropAtts.pdf\">Eliminative materialism and the propositional attitudes</a>. <em>The Journal of Philosophy, 78</em>: 67-90.</p>\n<p>Schroeder, Roskies, Nichols (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Schroeder-et-al-Moral-Motivation.pdf\">Moral motivation</a>. In Doris (ed.), <em>The Moral Psychology Handbook</em> (pp. 72-110). Oxford University Press.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dsr3Zyxk3o8BtChmr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 8, "extendedScore": null, "score": 5e-06, "legacy": true, "legacyId": "12901", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<p>Edit: <a href=\"/lw/9yd/the_neuroscience_of_moral_motivation_part_1/5v1s\">Oops, I made a mistake.</a> Sorry about that. I'm going to consolidate the parts into one post.</p>\n<p>&nbsp;</p>\n<hr>\n<hr>\n<hr>\n<p>&nbsp;</p>\n<p>Imagine you are walking down a Los Angeles street when you see a homeless man.&nbsp; He's sitting outside a coffee shop and begging for food.&nbsp; You stop to give him a sympathetic look.&nbsp; Quickly, you enter the shop to buy a muffin and juice.&nbsp; You then give him the food, which he happily takes.&nbsp; After wishing him well, you continue on walking.&nbsp; By many accounts, you have just done a morally good action.<sup>1</sup></p>\n<p>In real life, you may never have given food to a starving man.&nbsp; However, it is likely that you have done other morally good actions.<sup>2</sup>&nbsp; Maybe you have done volunteer work in your community.&nbsp; Maybe you have donated to charity.&nbsp; Think of a time you did a morally good action.&nbsp; Got it?&nbsp; Good.</p>\n<p>How can we explain why you committed this moral action?&nbsp; Or more broadly, how can we explain why we act at all?&nbsp; One popular explanation of action comes from folk psychology.&nbsp; As <a href=\"/user/lukeprog/\">Luke</a> summarizes, \"[f]olk psychology posits that we humans have beliefs and desires, and that we are motivated to do what we believe will fulfill our desires.\"<sup>3&nbsp; </sup>While the folk psychology model is useful for daily life, it has several grave flaws.<sup>4</sup></p>\n<p>In response to these flaws, economists have refined and quantified folk psychology into <a href=\"http://www.econlib.org/library/Enc1/NeoclassicalEconomics.html\">neoclassical economics</a>.&nbsp; These economic models are more useful than folk psychology for explaining and predicting human action.&nbsp; However, as Luke points out, they still aren't perfect.&nbsp; In <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human/\">\"A Crash Course in the Neuroscience of Human Motivation,\"</a> Luke describes the challenges these models face.&nbsp; Moreover, he details how the neoclassical model can be further improved and <a href=\"/lw/on/reductionism/\">reduced</a> through the insights of modern neuroscience.</p>\n<p>Nevertheless, that reduction only covers amoral actions.&nbsp; We're still left with the question at the beginning of this post: what is the explanation for our moral actions?&nbsp; What causal roles (if any) do our beliefs, desires, and feelings play? This sequence uses neuroscience to shed light on those questions.&nbsp; It will do so over the course of four posts.</p>\n<p>This is the first post, which serves as an introduction.&nbsp; It has introduced the driving question behind the sequence.&nbsp; The remainder outlines the next three posts.</p>\n<p>The second post gives an overview of the mainstream philosophical accounts of action.&nbsp; It uses folk psychological terms such as \"motivation,\" as philosophy largely relies on folk psychology.&nbsp; The post delves into the externalist - internalist controversy.</p>\n<p>The third post covers the specific philosophical accounts of moral action.&nbsp; It discusses the four mainstream views: instrumentalism, cognitivism, sentimentalism, and personalism.<sup>5&nbsp; </sup>Comparisons between the views show where they agree and disagree.&nbsp; The views are also described with reference to the controvers discussed in the second post.&nbsp; Last, this post details the different experiences we should anticipate about the brain by accepting one view over the others.</p>\n<p>The fourth post concludes the sequence by comparing the anticipated facts of each philosophical view with how the brain actually works.&nbsp; Some views are more consistent with the neuroscience than others are.&nbsp; Thus, those that are consistent are more likely to be correct.<sup>6&nbsp; </sup>And though not yet falsified, those views that contradict current neuroscience have large obstacles to overcome.&nbsp; These challenges should be noted when painting the larger metaethical picture.<sup>7</sup></p>\n<hr>\n<p><strong id=\"Notes\">Notes</strong></p>\n<p>[1]&nbsp; Example adapted from Schroeder (2010).</p>\n<p>[2]&nbsp; In this post, I write as though moral realism is correct.&nbsp; I did this for ease of explanation, not because I necessarily agree.&nbsp; This sequence does not depend on the reader holding any particular metaethical view about the existence of moral facts.&nbsp; I encourage moral anti-realists/irrealists to read \"morally good actions\" as \"actions which some accounts consider moral,\" or something similar.</p>\n<p>[3]&nbsp; Quoted from <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human\">\"A Crash Course in the Neuroscience of Human Motivation.\"</a></p>\n<p>[4]&nbsp; For an explanation of the flaws, see Churchland (1981).</p>\n<p>[5]&nbsp; In this context, \"cognitivism\" doesn't refer to the metaethical view that moral language expresses truth-apt propositions.</p>\n<p>[6] As per <a href=\"http://commonsenseatheism.com/?p=13156\">Bayes' rule</a>, P(H|E)&nbsp;\u221d P(E|H).</p>\n<p>[7] Credit for the sequence idea goes to Luke.&nbsp; This is one of his <a href=\"/lw/85d/11_less_wrong_articles_i_probably_will_never_have/\">11 LessWrong articles he'll probably never have time to write</a>.&nbsp; I hope it helps close some inferential gaps for his metaethics sequence.&nbsp; Conversely, any errors in this sequence fall squarely on me.&nbsp; Correction, advice, criticism are encouraged. (Especially on my writing and citation style.)</p>\n<hr>\n<p><strong id=\"References\">References</strong></p>\n<p>Churchland (1981). <a href=\"http://stevewatson.info/courses/Mind/resources/readings/Churchland_ElimMater&amp;PropAtts.pdf\">Eliminative materialism and the propositional attitudes</a>. <em>The Journal of Philosophy, 78</em>: 67-90.</p>\n<p>Schroeder, Roskies, Nichols (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Schroeder-et-al-Moral-Motivation.pdf\">Moral motivation</a>. In Doris (ed.), <em>The Moral Psychology Handbook</em> (pp. 72-110). Oxford University Press.</p>", "sections": [{"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "13 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hN2aRnu798yas5b2k", "tPqQdLCuxanjhoaNs", "Qs96DvwTCCdyRvM5E"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T05:12:56.563Z", "modifiedAt": null, "url": null, "title": "Meetup : Madison Monday Meetup", "slug": "meetup-madison-monday-meetup-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MdzDkY974rMdMzayE/meetup-madison-monday-meetup-2", "pageUrlRelative": "/posts/MdzDkY974rMdMzayE/meetup-madison-monday-meetup-2", "linkUrl": "https://www.lesswrong.com/posts/MdzDkY974rMdMzayE/meetup-madison-monday-meetup-2", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Madison%20Monday%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Madison%20Monday%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMdzDkY974rMdMzayE%2Fmeetup-madison-monday-meetup-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Madison%20Monday%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMdzDkY974rMdMzayE%2Fmeetup-madison-monday-meetup-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMdzDkY974rMdMzayE%2Fmeetup-madison-monday-meetup-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 153, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6y'>Madison Monday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 February 2012 06:30:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1831 Monroe St, Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I'll prepare a short talk on the conditions under which expert\njudgment is good evidence, the conditions in which \"experts\" will make\nconfident predictions that turn out to be essentially random, and the\nspaces in between. Beyond learning more about what claims to take\nseriously, I'm betting that this research can yield advanced\ntechniques for not lying to yourself.</p>\n\n<p>Also, though I don't especially mean to drive the conversation there,\nI'm sure we'll continue to examine consequentialism. If anybody can\nclearly describe a more satisfying metaethics than is in, say,\nYvain's <a href=\"http://raikoth.net/consequentialism.html#metaethics\" rel=\"nofollow\">Consequentialism FAQ</a> -- concisely\nenough that you can actually explain it during the meetup, with its\nattendant interruptions -- then I will totally buy you coffee or\nchocolate. :)</p>\n\n<p>Also, does this <a href=\"http://www.koryheath.com/games/zendo/\" rel=\"nofollow\">koan have the Buddha-nature</a>?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6y'>Madison Monday Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MdzDkY974rMdMzayE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 8.463288578679256e-07, "legacy": true, "legacyId": "12914", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Madison_Monday_Meetup\">Discussion article for the meetup : <a href=\"/meetups/6y\">Madison Monday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 February 2012 06:30:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1831 Monroe St, Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I'll prepare a short talk on the conditions under which expert\njudgment is good evidence, the conditions in which \"experts\" will make\nconfident predictions that turn out to be essentially random, and the\nspaces in between. Beyond learning more about what claims to take\nseriously, I'm betting that this research can yield advanced\ntechniques for not lying to yourself.</p>\n\n<p>Also, though I don't especially mean to drive the conversation there,\nI'm sure we'll continue to examine consequentialism. If anybody can\nclearly describe a more satisfying metaethics than is in, say,\nYvain's <a href=\"http://raikoth.net/consequentialism.html#metaethics\" rel=\"nofollow\">Consequentialism FAQ</a> -- concisely\nenough that you can actually explain it during the meetup, with its\nattendant interruptions -- then I will totally buy you coffee or\nchocolate. :)</p>\n\n<p>Also, does this <a href=\"http://www.koryheath.com/games/zendo/\" rel=\"nofollow\">koan have the Buddha-nature</a>?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Madison_Monday_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/6y\">Madison Monday Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Madison Monday Meetup", "anchor": "Discussion_article_for_the_meetup___Madison_Monday_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Madison Monday Meetup", "anchor": "Discussion_article_for_the_meetup___Madison_Monday_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T06:44:17.165Z", "modifiedAt": null, "url": null, "title": "Meetup : Tucson Meetup", "slug": "meetup-tucson-meetup-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.616Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DeevGrape", "createdAt": "2011-11-02T19:26:47.963Z", "isAdmin": false, "displayName": "DeevGrape"}, "userId": "m9JPq6irpKromu9x9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/evToDksMXf9XWAZ5d/meetup-tucson-meetup-0", "pageUrlRelative": "/posts/evToDksMXf9XWAZ5d/meetup-tucson-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/evToDksMXf9XWAZ5d/meetup-tucson-meetup-0", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Tucson%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Tucson%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FevToDksMXf9XWAZ5d%2Fmeetup-tucson-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Tucson%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FevToDksMXf9XWAZ5d%2Fmeetup-tucson-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FevToDksMXf9XWAZ5d%2Fmeetup-tucson-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/6z'>Tucson Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">02 March 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Coffee X Change 2443 North Campbell Avenue, Tucson, AZ 85719</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hi everyone! I was pretty inspired by the Winter Solstice series of posts discussing the benefits and fun of being in an in-person rationalist community (and also lukeprog's Algorithm for Beating Procrastination :)). So, I'm tossing out a line to any rationalists in Tucson or southern Arizona who'd like to meet up and talk about whatever. Time and place are just first suggestions on my part, and if there's interest in changing the details so someone can make it, that could totally happen.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/6z'>Tucson Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "evToDksMXf9XWAZ5d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.463645769617021e-07, "legacy": true, "legacyId": "12918", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Tucson_Meetup\">Discussion article for the meetup : <a href=\"/meetups/6z\">Tucson Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">02 March 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Coffee X Change 2443 North Campbell Avenue, Tucson, AZ 85719</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hi everyone! I was pretty inspired by the Winter Solstice series of posts discussing the benefits and fun of being in an in-person rationalist community (and also lukeprog's Algorithm for Beating Procrastination :)). So, I'm tossing out a line to any rationalists in Tucson or southern Arizona who'd like to meet up and talk about whatever. Time and place are just first suggestions on my part, and if there's interest in changing the details so someone can make it, that could totally happen.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Tucson_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/6z\">Tucson Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Tucson Meetup", "anchor": "Discussion_article_for_the_meetup___Tucson_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Tucson Meetup", "anchor": "Discussion_article_for_the_meetup___Tucson_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T15:23:30.992Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Salt Lake City, Melbourne, Atlanta, NYC, Cambridge", "slug": "weekly-lw-meetups-salt-lake-city-melbourne-atlanta-nyc", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qu3g2RAefT6o4krxF/weekly-lw-meetups-salt-lake-city-melbourne-atlanta-nyc", "pageUrlRelative": "/posts/qu3g2RAefT6o4krxF/weekly-lw-meetups-salt-lake-city-melbourne-atlanta-nyc", "linkUrl": "https://www.lesswrong.com/posts/qu3g2RAefT6o4krxF/weekly-lw-meetups-salt-lake-city-melbourne-atlanta-nyc", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Salt%20Lake%20City%2C%20Melbourne%2C%20Atlanta%2C%20NYC%2C%20Cambridge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Salt%20Lake%20City%2C%20Melbourne%2C%20Atlanta%2C%20NYC%2C%20Cambridge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqu3g2RAefT6o4krxF%2Fweekly-lw-meetups-salt-lake-city-melbourne-atlanta-nyc%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Salt%20Lake%20City%2C%20Melbourne%2C%20Atlanta%2C%20NYC%2C%20Cambridge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqu3g2RAefT6o4krxF%2Fweekly-lw-meetups-salt-lake-city-melbourne-atlanta-nyc", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqu3g2RAefT6o4krxF%2Fweekly-lw-meetups-salt-lake-city-melbourne-atlanta-nyc", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 388, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/6o\">Salt Lake City Meetup #2:&nbsp;<span class=\"date\">04 February 2012 03:00PM</span></a></li>\n<li><a href=\"/meetups/6l\">Atlanta:&nbsp;<span class=\"date\">04 February 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/5f\">First Brussels meetup:&nbsp;<span class=\"date\">11 February 2012 11:00AM</span></a></li>\n<li><a href=\"/meetups/6g\">Sydney Rationality meet-up No.2:&nbsp;<span class=\"date\">15 February 2012 06:00PM</span></a></li>\n<li><a href=\"/meetups/69\">Ongoing Ohio Meetup:&nbsp;<span class=\"date\">19 February 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/6k\">[Ohio/Washington DC] Interest in Reason Rally meetup?:&nbsp;<span class=\"date\">24 March 2012 04:14PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/6c\">Melbourne practical rationality meetup:&nbsp;<span class=\"date\">03 February 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/6m\">[NYC] LessWrong Megameetup:&nbsp;<span class=\"date\">04 February 2012 12:00PM</span></a></li>\n<li><a href=\"/meetups/6n\">Cambridge UK :&nbsp;<span class=\"date\">05 February 2012 11:00AM</span></a></li>\n</ul>\n<ul>\n</ul>\n<p>Cities with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a></strong><strong>.</strong></p>\n<p>If your meetup has a mailing list that you'd like mentioned here or has become regular and isn't listed as such, let me know!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qu3g2RAefT6o4krxF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 8.465676686582876e-07, "legacy": true, "legacyId": "12667", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T15:39:11.586Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Leave a Line of Retreat", "slug": "seq-rerun-leave-a-line-of-retreat", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.861Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/79t4RtscYjKR6QZwN/seq-rerun-leave-a-line-of-retreat", "pageUrlRelative": "/posts/79t4RtscYjKR6QZwN/seq-rerun-leave-a-line-of-retreat", "linkUrl": "https://www.lesswrong.com/posts/79t4RtscYjKR6QZwN/seq-rerun-leave-a-line-of-retreat", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Leave%20a%20Line%20of%20Retreat&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Leave%20a%20Line%20of%20Retreat%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F79t4RtscYjKR6QZwN%2Fseq-rerun-leave-a-line-of-retreat%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Leave%20a%20Line%20of%20Retreat%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F79t4RtscYjKR6QZwN%2Fseq-rerun-leave-a-line-of-retreat", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F79t4RtscYjKR6QZwN%2Fseq-rerun-leave-a-line-of-retreat", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 200, "htmlBody": "<p>Today's post, <a href=\"/lw/o4/leave_a_line_of_retreat/\">Leave a Line of Retreat</a> was originally published on 25 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If you are trying to judge whether some unpleasant idea is true you should visualise what the world would look like if it were true, and what you would do in that situation. This will allow you to be less scared of the idea, and reason about it without immediately trying to reject it.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9xf/seq_rerun_superexponential_conceptspace_and/\">Superexponential Conceptspace, and Simple Words</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "79t4RtscYjKR6QZwN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.465738017234244e-07, "legacy": true, "legacyId": "12925", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3XgYbghWruBMrPTAL", "h2ZDR3R89YnQn6ixt", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-10T21:43:39.317Z", "modifiedAt": null, "url": null, "title": "On Journaling", "slug": "on-journaling", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.924Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DuvdfnZCQCke3pXxn/on-journaling", "pageUrlRelative": "/posts/DuvdfnZCQCke3pXxn/on-journaling", "linkUrl": "https://www.lesswrong.com/posts/DuvdfnZCQCke3pXxn/on-journaling", "postedAtFormatted": "Friday, February 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Journaling&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Journaling%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDuvdfnZCQCke3pXxn%2Fon-journaling%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Journaling%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDuvdfnZCQCke3pXxn%2Fon-journaling", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDuvdfnZCQCke3pXxn%2Fon-journaling", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 822, "htmlBody": "<p><sup>(Warning: Intermittent gooey personal details inside)</sup></p>\n<p>I'm surprised I haven't seen this topic brought up before, but I haven't, and cursory searches of \"diary\" and \"journal\" came up with nothing, albeit largely because the latter got a bunch of hits for scientific journals. But I digress. I have recently started a journal. So recently, in fact, that there are only two entries. There were a number of motivating factors that went into this decision, which correlate rather directly with the number of goals I have for this project.</p>\n<p>First, I think it will help me be less stressed. I estimate that at least 60% of my stress is due to the fact that I refuse to even think about the things I need to do until I actually start on them. Because I haven't actually thought through what I need to do, I often feel swamped and very stressed, even when I have comparatively little that needs done. When I actually start working on it, I realize that I don't have as much as I thought, and worried for nothing. One of the things I want to do in this (and haven't in my first two entries, very well) is briefly mention things I know I am procrastinating on. I haven't done this yet, because I forgot for the first two entries, but I intend to have a section of \"What am I procrastinating on\" for every entry.</p>\n<p>Speaking of which: Secondly, I want to stop procrastinating so much. Stopping to actually think about what I need to do will naturally make me more productive. I've noticed that whenever I actually start thinking about things I need to do, I start doing it immediately. I also want to have a section \"Productive things I've done today\". This will give me some kind of incentive system to actually be productive, since I won't want to acknowledge when I haven't done anything I didn't <em>have</em> to.</p>\n<p>Third, I have a terrible memory for things that don't matter that much. I don't know if this will help that or not, but at least I'll have some record of what I've done. And it only stands to reason that reviewing one's activities in a day would help one remember them. I first got an idea of this when I made <a href=\"/lw/9gy/the_singularity_institutes_arrogance_problem/5pct\">this comment</a>. I doubt this would specifically address that problem, but at least I would have a record of <em>something</em>.</p>\n<p>Fourth, I want data on what makes me happy. Part of what I'm doing is keeping a companion Excel file to my OneNote folder. For each entry, I assess my emotional levels on a scale of 0-100, with 50 designed to be what I perceive an average day to be like. Emotional levels I'm currently using are: Happiness, Stress, Motivation, Energy, Relationship Satisfaction, and an arbitrary category called \"Winningness\". I'm sure everyone on LW understands what I mean. :-) I also record about how much time I spent doing various things that day. Under the productive category, I have going to class, homework/studying, Extracurricular Activities, Work, and a total category. Under the social category, I have time spent with my girlfriend, and time spent with general friends, and another total category. Under recreation, I record time spent watching Television, reading, and playing various games I enjoy, as well as a total category. Lastly, I'm recording miscellaneous things:</p>\n<ul>\n<li>Sleep the previous night (hours)</li>\n<li>Current length of To-Do list</li>\n<li>Tasks added to To-Do</li>\n<li>Items checked off the To-Do</li>\n<li>Day of the Week</li>\n<li>Where I am that day (Rather, where I'm sleeping that night)</li>\n<li>How much I've eaten that day (Again on a scale of 0-100, 50 average) \n<ul>\n<li>This is somewhat of a problem for me, I don't really eat as much as I should. I considered recording specific foods, but that seems like it would get out of hand very quickly, even though it makes a lot of sense, neurologically, that the type of food I would eat would be correlated with happiness levels. It feels wrong not recording the difference in the <a href=\"http://gingerbreadcake.files.wordpress.com/2011/04/gooeybutter.jpg\">gooey butter cake</a> that I ate for breakfast this morning (It was fast, and I needed to study, don't judge me!) and a bowl of oatmeal. I'd also like a better scale, like an exact caloric count, but that would really take too much effort.</li>\n</ul>\n</li>\n<li>How much I've exercised that day (Same scale)</li>\n</ul>\n<p>I will probably post again on this topic once I actually have some form of history doing it, including evaluations of the practice, recommendations, things I would change etc. But right now, I would like advice from you all. What am I missing that I should be doing? Does anyone Journal? Is it as involved in this? Has anyone tried and failed? I would particularly like advice on things I might include in the Excel file.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sJYvMHBHnR6DbJQcN": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DuvdfnZCQCke3pXxn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 8.467164107427972e-07, "legacy": true, "legacyId": "12928", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-11T04:12:22.416Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge UK", "slug": "meetup-cambridge-uk-4", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:59.919Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rebellionkid", "createdAt": "2011-06-20T09:26:46.768Z", "isAdmin": false, "displayName": "rebellionkid"}, "userId": "ygYCk3eXnJwt6p3o4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aWdTsLwCuWxGB5dMZ/meetup-cambridge-uk-4", "pageUrlRelative": "/posts/aWdTsLwCuWxGB5dMZ/meetup-cambridge-uk-4", "linkUrl": "https://www.lesswrong.com/posts/aWdTsLwCuWxGB5dMZ/meetup-cambridge-uk-4", "postedAtFormatted": "Saturday, February 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%20UK&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%20UK%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaWdTsLwCuWxGB5dMZ%2Fmeetup-cambridge-uk-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%20UK%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaWdTsLwCuWxGB5dMZ%2Fmeetup-cambridge-uk-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaWdTsLwCuWxGB5dMZ%2Fmeetup-cambridge-uk-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 58, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/73'>Cambridge UK</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">19 February 2012 11:00:00AM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">JCR, Trinity College, Cambridge, CB2 1TQ, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at the Great Gate if you dont know where the JCR is. Great Gate is on St. John's Street opposite the bookshop \"Heffers\". Join the google group at <a href=\"http://groups.google.com/group/cambridgelesswrong\" rel=\"nofollow\">http://groups.google.com/group/cambridgelesswrong</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/73'>Cambridge UK</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aWdTsLwCuWxGB5dMZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.468685575364451e-07, "legacy": true, "legacyId": "12951", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge_UK\">Discussion article for the meetup : <a href=\"/meetups/73\">Cambridge UK</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">19 February 2012 11:00:00AM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">JCR, Trinity College, Cambridge, CB2 1TQ, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at the Great Gate if you dont know where the JCR is. Great Gate is on St. John's Street opposite the bookshop \"Heffers\". Join the google group at <a href=\"http://groups.google.com/group/cambridgelesswrong\" rel=\"nofollow\">http://groups.google.com/group/cambridgelesswrong</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge_UK1\">Discussion article for the meetup : <a href=\"/meetups/73\">Cambridge UK</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge UK", "anchor": "Discussion_article_for_the_meetup___Cambridge_UK", "level": 1}, {"title": "Discussion article for the meetup : Cambridge UK", "anchor": "Discussion_article_for_the_meetup___Cambridge_UK1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-11T09:47:03.148Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] \"Can't Say No\" Spending", "slug": "seq-rerun-can-t-say-no-spending", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.483Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CZy2CXtFaYwZsRvp7/seq-rerun-can-t-say-no-spending", "pageUrlRelative": "/posts/CZy2CXtFaYwZsRvp7/seq-rerun-can-t-say-no-spending", "linkUrl": "https://www.lesswrong.com/posts/CZy2CXtFaYwZsRvp7/seq-rerun-can-t-say-no-spending", "postedAtFormatted": "Saturday, February 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20%22Can't%20Say%20No%22%20Spending&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20%22Can't%20Say%20No%22%20Spending%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZy2CXtFaYwZsRvp7%2Fseq-rerun-can-t-say-no-spending%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20%22Can't%20Say%20No%22%20Spending%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZy2CXtFaYwZsRvp7%2Fseq-rerun-can-t-say-no-spending", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZy2CXtFaYwZsRvp7%2Fseq-rerun-can-t-say-no-spending", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 305, "htmlBody": "<div id=\"entry_t3_9z1\" class=\"content clear\">\n<div class=\"md\">\n<p>Today's post, \"<a href=\"/lw/kb/cant_say_no_spending/\">Can't say no\" Spendin</a>g was originally published on <span class=\"date\">18 October 2007. I decided to include it based on feedback in the o<a href=\"/lw/9p9/open_thread_february_114_2012/5u09\">pen thread</a>. It is a very short entry </span>so there is no real need for a summary:</p>\n<blockquote>\n<div id=\"entry_t3_kb\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<p><a href=\"http://www.overcomingbias.com/2007/05/rand_health_ins.html\">The</a> <a href=\"http://www.overcomingbias.com/2007/05/rand_health_ins_1.html\">remarkable</a> <a href=\"http://www.overcomingbias.com/2007/04/overconfidence_.html\">observation</a> <a href=\"http://www.overcomingbias.com/2007/05/medicine_as_sca.html\">that</a> <a href=\"http://www.overcomingbias.com/2007/05/rand_experiment.html\">medical</a> <a href=\"http://www.overcomingbias.com/2007/06/disagreement_ca.html\">spending</a> <a href=\"http://www.overcomingbias.com/2007/09/cut-medicine-in.html\">has</a> <a href=\"http://www.overcomingbias.com/2007/09/beware-monkey-t.html\">zero</a> <a href=\"http://www.overcomingbias.com/2007/10/doctors-kill.html\">net</a> <a href=\"http://www.overcomingbias.com/2007/10/buy-health-not-.html\">marginal</a> <a href=\"http://www.overcomingbias.com/2007/10/health-hope-spr.html\">effect</a> is shocking, but not completely unprecedented.</p>\n<p>According to Spiegel in \"<a href=\"http://www.spiegel.de/international/spiegel/0,1518,363604,00.html\">Too Much of a Good Thing: Choking on Aid Money in Africa</a>\", the Washington Center for Global Development <a href=\"http://www.spiegel.de/international/spiegel/0,1518,363604-3,00.html\">calculated</a> that it would require <strong>$3,521</strong> of marginal development aid invested, per person, in order to increase per capita yearly income by $3.65 (<strong>one penny per day</strong>).</p>\n<p>The Kenyan economist James Shikwati is even more pessimistic in \"<a href=\"http://www.spiegel.de/international/spiegel/0,1518,363663,00.html\">For God's Sake, Please Stop the Aid!</a>\":&nbsp; The net effect of Western aid to Africa is <em>actively destructive</em> (even when it <em>isn't</em> stolen to prop up corrupt regimes), a chaotic flux of money and goods that destroys local industry.</p>\n<p>What does aid to Africa have in common with healthcare spending? Besides, of course, that it's heartbreaking to just say no -</p>\n</div>\n</div>\n</div>\n</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was S<a href=\"/lw/9xf/seq_rerun_superexponential_conceptspace_and\">uperexponential Conceptspace, and Simple Words</a>, and you can use the s<a href=\"/r/discussion/tag/sequence_reruns\">equence_reruns ta</a>g or r<a href=\"/r/discussion/tag/sequence_reruns/.rss\">ss fee</a>d to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go h<a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns\">er</a>e for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CZy2CXtFaYwZsRvp7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 10, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "12965", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LxcJHS2Lt22mHQ4Hm", "h2ZDR3R89YnQn6ixt", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-11T21:37:13.860Z", "modifiedAt": null, "url": null, "title": "Meetup : Monthly Bay Area meetup: Berkeley", "slug": "meetup-monthly-bay-area-meetup-berkeley", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.766Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w8QZiAX4vnYYNBnCD/meetup-monthly-bay-area-meetup-berkeley", "pageUrlRelative": "/posts/w8QZiAX4vnYYNBnCD/meetup-monthly-bay-area-meetup-berkeley", "linkUrl": "https://www.lesswrong.com/posts/w8QZiAX4vnYYNBnCD/meetup-monthly-bay-area-meetup-berkeley", "postedAtFormatted": "Saturday, February 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Monthly%20Bay%20Area%20meetup%3A%20Berkeley&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Monthly%20Bay%20Area%20meetup%3A%20Berkeley%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw8QZiAX4vnYYNBnCD%2Fmeetup-monthly-bay-area-meetup-berkeley%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Monthly%20Bay%20Area%20meetup%3A%20Berkeley%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw8QZiAX4vnYYNBnCD%2Fmeetup-monthly-bay-area-meetup-berkeley", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw8QZiAX4vnYYNBnCD%2Fmeetup-monthly-bay-area-meetup-berkeley", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/74'>Monthly Bay Area meetup: Berkeley</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2128 Oxford St., Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next monthly Bay Area meetup will be Saturday, 18 February, in Berkeley. We'll gather as usual at 7:00pm at the Starbucks on 2128 Oxford Street, and then move to the Free Speech Cafe on campus. I look forward to seeing all of your faces!</p>\n\n<p>-Nisan</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/74'>Monthly Bay Area meetup: Berkeley</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w8QZiAX4vnYYNBnCD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 8.472777610436393e-07, "legacy": true, "legacyId": "12967", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Monthly_Bay_Area_meetup__Berkeley\">Discussion article for the meetup : <a href=\"/meetups/74\">Monthly Bay Area meetup: Berkeley</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2128 Oxford St., Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next monthly Bay Area meetup will be Saturday, 18 February, in Berkeley. We'll gather as usual at 7:00pm at the Starbucks on 2128 Oxford Street, and then move to the Free Speech Cafe on campus. I look forward to seeing all of your faces!</p>\n\n<p>-Nisan</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Monthly_Bay_Area_meetup__Berkeley1\">Discussion article for the meetup : <a href=\"/meetups/74\">Monthly Bay Area meetup: Berkeley</a></h2>", "sections": [{"title": "Discussion article for the meetup : Monthly Bay Area meetup: Berkeley", "anchor": "Discussion_article_for_the_meetup___Monthly_Bay_Area_meetup__Berkeley", "level": 1}, {"title": "Discussion article for the meetup : Monthly Bay Area meetup: Berkeley", "anchor": "Discussion_article_for_the_meetup___Monthly_Bay_Area_meetup__Berkeley1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-11T21:38:36.438Z", "modifiedAt": null, "url": null, "title": "Topics from \"Procedural Knowledge Gaps\"", "slug": "topics-from-procedural-knowledge-gaps", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.862Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oaggCpKMcZRTBujsa/topics-from-procedural-knowledge-gaps", "pageUrlRelative": "/posts/oaggCpKMcZRTBujsa/topics-from-procedural-knowledge-gaps", "linkUrl": "https://www.lesswrong.com/posts/oaggCpKMcZRTBujsa/topics-from-procedural-knowledge-gaps", "postedAtFormatted": "Saturday, February 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Topics%20from%20%22Procedural%20Knowledge%20Gaps%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATopics%20from%20%22Procedural%20Knowledge%20Gaps%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoaggCpKMcZRTBujsa%2Ftopics-from-procedural-knowledge-gaps%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Topics%20from%20%22Procedural%20Knowledge%20Gaps%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoaggCpKMcZRTBujsa%2Ftopics-from-procedural-knowledge-gaps", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoaggCpKMcZRTBujsa%2Ftopics-from-procedural-knowledge-gaps", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 344, "htmlBody": "<p>About a year ago, we had a major discussion about <a href=\"/lw/453/procedural_knowledge_gaps/?sort=new\">procedural knowledge gaps</a>. Here's what was covered....</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hlf\">How to tell whether food is fresh</a> <a href=\"/lw/453/procedural_knowledge_gaps/3ix9\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3ix9\">pjeby claims that eating raw chicken is safe because the gag reflex identifies it fast</a> <a href=\"/lw/453/procedural_knowledge_gaps/3hlj\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hlj\">How to buy investments</a><a></a></p>\n<p><a> </a><a href=\"/lw/453/procedural_knowledge_gaps/3hln\">Memorizing the alphabet and other arbitrary lists</a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hms\">Comparison of various how-to sites</a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hoi\">General discussion of making things (including Less Wrong) easier to use</a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hp8\">How jump start a stalled car</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hpf\">How to use the Yellow Pages</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hrg\">Cheap and easy healthy food</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3hrw\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hrw\">Questions about preparing a simple soup</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hrk\">Exercise</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3hrm\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hrm\">Starting relationships, especially for heterosexual men</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3htv\">Cooking in general</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3jb2\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3jb2\">Browning meat</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3i49\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i49\">How to become bisexual</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hsq\">How to transfer money from one electronic account to another</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3htp\">How to buy a used car</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hwn\">Interacting with police.&nbsp; (</a><a href=\"http://www.youtube.com/watch?v=6wXkI4t7nuc\">Don't talk to US police!</a> <a href=\"http://andrewducker.livejournal.com/2641320.html?nc=5#comments\">The rules are different in the UK</a>.) <a href=\"/lw/453/procedural_knowledge_gaps/3hvx\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hvx\">How to speak clearly, slowly, etc.</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hvy\">How to fold a fitted sheet</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hw4\">How to make a will</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3hwh\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hwh\">How to order at a bar</a>. Also, some cookbook recommendations. <a href=\"/lw/453/procedural_knowledge_gaps/3hxf\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hxf\">Tipping in the US</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3hxs\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hxs\">Tipping in the UK and France</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3hwt\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hwt\">Spacial orientation</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hxi\">Personal hygiene-- washing, soap, shampoo</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i6m\">Haircuts for men</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3ikw\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3ikw\">Haircuts for women</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3inl\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3inl\">Growing and maintaining long hair</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i7e\">Putting a cover on a duvet</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hyf\">Telling the difference between flirting and friendliness</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3hzd\">Choosing shirts that fit</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i0y\">Left vs. Right (which hand, not political)</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i1g\">Shaving one's face</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3i36\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i36\">How to end conversations politely</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3ij7\">How to make people laugh</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3i4u\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i4u\">Mailing large objects in the US</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i59\">How to format comments at Less Wrong</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3i5s\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i5s\">How to declutter</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3ib7\">E readers</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3ib7\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i81\">Touch typing</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3i8a\">Dvorak, etc.</a> <a href=\"/lw/453/procedural_knowledge_gaps/3ia0\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3ia0\">How often to see a doctor</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3iaa\">Remembering to be polite</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3iau\">Tying shoes</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3ibl\">Home maintenance</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3icq\">What might melt in a dishwasher</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3imq\">Kitchen knives</a>. <a href=\"/lw/453/procedural_knowledge_gaps/3iqf\"></a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3iqf\">Sorting laundry</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3ig7\">Does cranking up the thermostat heat the house faster?</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3io3\">More about investment</a></p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3icz\">How to not stutter</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3idf\">How to be a good manager</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/5248\">Scrubbing</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3jhh\">How to use Google</a>.</p>\n<p><a href=\"/lw/453/procedural_knowledge_gaps/3j7d\">How to talk to strangers</a>.</p>\n<p>Potential topics:</p>\n<p>How to give clear instructions.</p>\n<p>How to see things from other people's point of view</p>\n<p>Cool sidetrack: <a href=\"/lw/453/procedural_knowledge_gaps/3lmi\">Fish and lightning</a></p>\n<p>Links and quotes:</p>\n<p><a href=\"http://chronicle.com/article/Graduate-School-in-the/44846\">Why grad school in the humanities is a bad choice</a> One probably could not devise a better system for keeping people with humanistic values away from power than by confining them to decade-long graduate programs with a long future of transient adjunct positions making less than the minimum wage. From <a href=\"http://chronicle.com/article/Just-Dont-Go-Part-2/44786/\">Part 2</a>. The first article is a nice example of applying the far view (look at how things are in general) to a personal decision.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GQyPQcdEQF4zXhJBq": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oaggCpKMcZRTBujsa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 46, "baseScore": 58, "extendedScore": null, "score": 0.000119, "legacy": true, "legacyId": "12968", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 58, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ka8eveZpT7hXLhRTM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-11T21:45:53.714Z", "modifiedAt": null, "url": null, "title": "[Link] Cooking for people who don't", "slug": "link-cooking-for-people-who-don-t", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.006Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/utABdhMRjnZB5eGCa/link-cooking-for-people-who-don-t", "pageUrlRelative": "/posts/utABdhMRjnZB5eGCa/link-cooking-for-people-who-don-t", "linkUrl": "https://www.lesswrong.com/posts/utABdhMRjnZB5eGCa/link-cooking-for-people-who-don-t", "postedAtFormatted": "Saturday, February 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Cooking%20for%20people%20who%20don't&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Cooking%20for%20people%20who%20don't%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FutABdhMRjnZB5eGCa%2Flink-cooking-for-people-who-don-t%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Cooking%20for%20people%20who%20don't%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FutABdhMRjnZB5eGCa%2Flink-cooking-for-people-who-don-t", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FutABdhMRjnZB5eGCa%2Flink-cooking-for-people-who-don-t", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 100, "htmlBody": "<p><a href=\"http://commodorified.dreamwidth.org/137087.html?view=1047423&amp;posted=1#cmt1047423\">Links about elementary cooking, food storage, etc.</a></p>\n<p>Here's the premise:</p>\n<blockquote>Write a post to pass on something[s] you know that you feel is useful to anyone who wants to increase their level of food security by increasing their level of skill, knowledge, comfort around getting, storing, or preparing food. How-tos are good, recipes are good, linkspams are good. Reflective essays are good too, even if not of a strictly practically useful nature. You are your own best judge of what's on-topic. On February 2nd, come back and post a link to it in the comments of the Carnival Round Up Post.</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "utABdhMRjnZB5eGCa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 7, "extendedScore": null, "score": 8.472811557082082e-07, "legacy": true, "legacyId": "12970", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-12T06:19:31.727Z", "modifiedAt": null, "url": null, "title": "Rational philosophies", "slug": "rational-philosophies", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.160Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "katydee", "createdAt": "2010-07-09T10:33:52.237Z", "isAdmin": false, "displayName": "katydee"}, "userId": "uHpk5J2f7BPBoiJFX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wRcj4bBc8fSg54iHq/rational-philosophies", "pageUrlRelative": "/posts/wRcj4bBc8fSg54iHq/rational-philosophies", "linkUrl": "https://www.lesswrong.com/posts/wRcj4bBc8fSg54iHq/rational-philosophies", "postedAtFormatted": "Sunday, February 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rational%20philosophies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARational%20philosophies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwRcj4bBc8fSg54iHq%2Frational-philosophies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rational%20philosophies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwRcj4bBc8fSg54iHq%2Frational-philosophies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwRcj4bBc8fSg54iHq%2Frational-philosophies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>Hello all,</p>\n<p>I'm working on a top-level post about how Stoicism is an instrumentally useful philosophy to adopt, and figured I should give other philosophies a fair shake as well. Does anyone know of any other philosophies out there that seem to be practically useful or otherwise provide strategies and thought patterns that have practical value? A solid grounding in experimental research is of course desirable.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wRcj4bBc8fSg54iHq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 0, "extendedScore": null, "score": 7e-06, "legacy": true, "legacyId": "12971", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-12T15:07:21.875Z", "modifiedAt": null, "url": null, "title": "Type 2 as an aggregation of Type 1 processes", "slug": "type-2-as-an-aggregation-of-type-1-processes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.040Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Khaled", "createdAt": "2011-05-05T15:33:37.678Z", "isAdmin": false, "displayName": "Khaled"}, "userId": "Dx4mZ4eiukNf52Ne4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MuuNayZyriKpK2KSg/type-2-as-an-aggregation-of-type-1-processes", "pageUrlRelative": "/posts/MuuNayZyriKpK2KSg/type-2-as-an-aggregation-of-type-1-processes", "linkUrl": "https://www.lesswrong.com/posts/MuuNayZyriKpK2KSg/type-2-as-an-aggregation-of-type-1-processes", "postedAtFormatted": "Sunday, February 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Type%202%20as%20an%20aggregation%20of%20Type%201%20processes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AType%202%20as%20an%20aggregation%20of%20Type%201%20processes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMuuNayZyriKpK2KSg%2Ftype-2-as-an-aggregation-of-type-1-processes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Type%202%20as%20an%20aggregation%20of%20Type%201%20processes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMuuNayZyriKpK2KSg%2Ftype-2-as-an-aggregation-of-type-1-processes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMuuNayZyriKpK2KSg%2Ftype-2-as-an-aggregation-of-type-1-processes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1324, "htmlBody": "<p><em>This post assumes basic knowledge of Type 1/Type 2 (System 1/System 2) categorization of mental processes.</em></p>\n<p><strong>Background (safe to skip)</strong></p>\n<p>After my first reaction of surprise (consuming perhaps a few months) to the topic of heuristics and biases, and after a few more readings on neuropsychology, I started re-visiting my first reaction in more detail. Should it really be surprising to learn that humans are not rational? Anyone with a basic connection with humans should easily see that we act irrationally in many situations &ndash; snap decisions, impulses, etc. &ndash; so what was the source of my surprise?</p>\n<p>My best guess (knowing my limits of interpolation) was that my surprise was not a result of discovering that we&rsquo;re irrational, but rather that there was a scientific approach in existence aiming at finding more about those irrationalities, and that results of predictable irrationality were appearing; that might eventually lead to unifying different biases under the same theory or source.</p>\n<p>The notion of Type 1 and Type 2 thinking (or System 1 and System 2) is for me a theory that has the power to unify most of the biases and perhaps predict others. Kahneman&rsquo;s Thinking Fast and Slow adopts such an approach, attempting to explain many biases in terms of Type 2 thought.</p>\n<p>Now, this connected with a question I had back in college when I first learned about Artificial Neural Networks (I was lucky to chose this as a topic to research and give a lecture to my colleagues on): &ldquo;if this is how the brain works, how does logical/rational thought emerge?&rdquo;</p>\n<p>To my understanding, Connectionism and the self-organizing patterning system that is the brain would <em>naturally </em>result in Type 1 thought as a direct consequence. The question that I had persistently is how can Type 2 thought emerge from this hardware? Jonah Lehrer&rsquo;s The Decisive Point suggests that different brain areas are (more) associated with each type of thought, but essentially (until proven otherwise), I assume that they all rely on essence on a patterning process, a connectionist model.</p>\n<p><strong>Migration of Skills</strong></p>\n<p>We know that many skills start in Type 2 and migrate to Type 1 as we get more &ldquo;experienced&rdquo; in them. When we first learn driving, we need to consciously think of every move, and the sequence of steps to perform, etc. We consciously engage in executing a known sequence before changing lanes (for example): look at the side mirror, look at the side to cover the blind spot, decrease speed, etc.</p>\n<p>As we get more driving experience, we stop to consciously process those steps, they become <em>automatic,</em> and we can even engage in other conscious processes while driving (e.g. having a conversation, thinking about a meeting you have later, etc).</p>\n<p>I believe this is key to understanding the relation between both types of thought, since it provides a kind of interface between them, it provides a way to compare the same process executing by both systems.</p>\n<p><strong>Simple Type 2 operations</strong></p>\n<p>So, having to experimental apparatus at hand, I had only the weak instrument of personal interpolation plus childhood memory. Starting with a simple operation, I decided to attempt to compare its execution by both systems. The operation: single digit addition.</p>\n<p>As a child, 3+2 could have multiple interpretations depending on previous education. Two examples might be: (1) visualize 3 apples, visualize 2 apples, count how many apples &ldquo;appear&rdquo; in working memory, and that gives you the answer. (2) Hold your fist in front of you, stretch out each finger, counting incrementally until you reach 3, then start new &ldquo;thread&rdquo; at 0, stretch more fingers counting until you reach 2, while also incrementing the first thread that stopped at 3 &ndash; the result then is the number reached by the first thread.</p>\n<p>The above is an attempt at analyzing how a child, using Type 2 processes, would find the answer to 3+2; while a grown up will simply look at &ldquo;3+2&rdquo; and &ldquo;5&rdquo; would &ldquo;magically&rdquo; pop up in her brain.</p>\n<p>Now, the question is: can we interpret the child&rsquo;s processes as a sequence of Type 1 operations? The key operation here is counting, everything else can be easily understood as Type 1 operations (for example, a connection between the written number &ldquo;3&rdquo; and a picture of three apples can be understood as Type 1). What happens in the child&rsquo;s brain as he counts? As children we had to <em>learn </em>to count, probably by just repeating the numbers in order over and over again, to form <em>a connection </em>between them. After some practice, the number 1 form a connection to 2, which is connected to 3, etc. in a linked list that extends as we learn more numbers. So, combining this connection, with a connection between a written number and its location in this list (3 is one element higher than 2), a child can use Type 1 to count.</p>\n<p>So, roughly and abstractly, a child&rsquo;s brain adding 3+2 might go in a sequence like this: the visions of &ldquo;3&rdquo; would fire a picture of 3 apples (a younger child might need to perform a counting pattern to reach that step, which would also later migrate to Type 1), &ldquo;2&rdquo; would fire two apples, a child then starts counting (each number connected to the next, and the context of counting enforces this connection), crossing out each apple with each fired number, until all apples are crossed out.</p>\n<p>Now this introduces the following mental operation: visualizing apples and performing operations on this visual image while counting (like crossing out or marking each counted apple). My wild guess here is that this, again, is reducible to Type 1 operations resulting from basic teacher instructions on additions, including visual demonstrations.</p>\n<p><strong>Levels of Type 1 to 2 Migration</strong></p>\n<p>Now, as pointed above, a younger child might need to apply counting to convert &ldquo;3&rdquo; to an image of 3 apples. As the child grows, she might have formed (by practice) the direct grown-up pattern that translates the image of &ldquo;3+2&rdquo; directly to &ldquo;5&rdquo;. She will then use this to add a number like 13+12 &ndash; utilizing &ldquo;3+2&rdquo;, &ldquo;1+1+1&rdquo;, and the carry 1 visual patterns. So the child would apply Type 2 addition utilizing several skills recently migrated to Type 1. As the child grows up, more layers of processes would migrate to Type 1, and the current Type 2 operations would become more efficient as they rely on those migrated skills.</p>\n<p>So, what I am saying here, my guess, is that there is no clear distinction between the two Types. That Type 2 operations are simple those that use a large number of Type 1 steps, and hence is slower, non-automatic (as they are slow, there is more time for other processes to stop them from completing, and hence they seem to be controlled), and effortful.</p>\n<p><strong>Which connectionism pattern will be used</strong></p>\n<p>Now probably a grown up still has all those accumulated skills in place. Seeing &ldquo;3+2&rdquo;, I still have the ability to apply the apple technique, and also to apply the direct connection between &ldquo;3+2&rdquo; and &ldquo;5&rdquo;. Which one I use, I suggest, is based on two probably algorithms:</p>\n<ol>\n<li>Size: I use what I call the &ldquo;Largest Available Recognizable Pattern&rdquo; (LARP). This means, how many patterns I need to invoke to come to a result. The brain then keeps invoking patterns from largest (less total number of patterns) to smaller, until a reasonable result is reached </li>\n<li>Time: this is based on the quickest pattern, which would usually be equivalent to the largest.</li>\n</ol>\n<p><strong>And?</strong></p>\n<p>I totally confess that this is a wild guess, and an idea that is not at all fully developed. I am not aware if this idea had been suggested in a more mature way or not, so this is an attempt to mainly get feedback and resources from you, and perhaps to build it up into better structure.</p>\n<p>The value of developing such a theory is that at some point it can be testable, and perhaps bring a better understanding of how we learn new skills, and more efficient ways to acquire and develop our skills.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MuuNayZyriKpK2KSg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 10, "extendedScore": null, "score": 8.476893840462435e-07, "legacy": true, "legacyId": "12972", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This post assumes basic knowledge of Type 1/Type 2 (System 1/System 2) categorization of mental processes.</em></p>\n<p><strong id=\"Background__safe_to_skip_\">Background (safe to skip)</strong></p>\n<p>After my first reaction of surprise (consuming perhaps a few months) to the topic of heuristics and biases, and after a few more readings on neuropsychology, I started re-visiting my first reaction in more detail. Should it really be surprising to learn that humans are not rational? Anyone with a basic connection with humans should easily see that we act irrationally in many situations \u2013 snap decisions, impulses, etc. \u2013 so what was the source of my surprise?</p>\n<p>My best guess (knowing my limits of interpolation) was that my surprise was not a result of discovering that we\u2019re irrational, but rather that there was a scientific approach in existence aiming at finding more about those irrationalities, and that results of predictable irrationality were appearing; that might eventually lead to unifying different biases under the same theory or source.</p>\n<p>The notion of Type 1 and Type 2 thinking (or System 1 and System 2) is for me a theory that has the power to unify most of the biases and perhaps predict others. Kahneman\u2019s Thinking Fast and Slow adopts such an approach, attempting to explain many biases in terms of Type 2 thought.</p>\n<p>Now, this connected with a question I had back in college when I first learned about Artificial Neural Networks (I was lucky to chose this as a topic to research and give a lecture to my colleagues on): \u201cif this is how the brain works, how does logical/rational thought emerge?\u201d</p>\n<p>To my understanding, Connectionism and the self-organizing patterning system that is the brain would <em>naturally </em>result in Type 1 thought as a direct consequence. The question that I had persistently is how can Type 2 thought emerge from this hardware? Jonah Lehrer\u2019s The Decisive Point suggests that different brain areas are (more) associated with each type of thought, but essentially (until proven otherwise), I assume that they all rely on essence on a patterning process, a connectionist model.</p>\n<p><strong id=\"Migration_of_Skills\">Migration of Skills</strong></p>\n<p>We know that many skills start in Type 2 and migrate to Type 1 as we get more \u201cexperienced\u201d in them. When we first learn driving, we need to consciously think of every move, and the sequence of steps to perform, etc. We consciously engage in executing a known sequence before changing lanes (for example): look at the side mirror, look at the side to cover the blind spot, decrease speed, etc.</p>\n<p>As we get more driving experience, we stop to consciously process those steps, they become <em>automatic,</em> and we can even engage in other conscious processes while driving (e.g. having a conversation, thinking about a meeting you have later, etc).</p>\n<p>I believe this is key to understanding the relation between both types of thought, since it provides a kind of interface between them, it provides a way to compare the same process executing by both systems.</p>\n<p><strong id=\"Simple_Type_2_operations\">Simple Type 2 operations</strong></p>\n<p>So, having to experimental apparatus at hand, I had only the weak instrument of personal interpolation plus childhood memory. Starting with a simple operation, I decided to attempt to compare its execution by both systems. The operation: single digit addition.</p>\n<p>As a child, 3+2 could have multiple interpretations depending on previous education. Two examples might be: (1) visualize 3 apples, visualize 2 apples, count how many apples \u201cappear\u201d in working memory, and that gives you the answer. (2) Hold your fist in front of you, stretch out each finger, counting incrementally until you reach 3, then start new \u201cthread\u201d at 0, stretch more fingers counting until you reach 2, while also incrementing the first thread that stopped at 3 \u2013 the result then is the number reached by the first thread.</p>\n<p>The above is an attempt at analyzing how a child, using Type 2 processes, would find the answer to 3+2; while a grown up will simply look at \u201c3+2\u201d and \u201c5\u201d would \u201cmagically\u201d pop up in her brain.</p>\n<p>Now, the question is: can we interpret the child\u2019s processes as a sequence of Type 1 operations? The key operation here is counting, everything else can be easily understood as Type 1 operations (for example, a connection between the written number \u201c3\u201d and a picture of three apples can be understood as Type 1). What happens in the child\u2019s brain as he counts? As children we had to <em>learn </em>to count, probably by just repeating the numbers in order over and over again, to form <em>a connection </em>between them. After some practice, the number 1 form a connection to 2, which is connected to 3, etc. in a linked list that extends as we learn more numbers. So, combining this connection, with a connection between a written number and its location in this list (3 is one element higher than 2), a child can use Type 1 to count.</p>\n<p>So, roughly and abstractly, a child\u2019s brain adding 3+2 might go in a sequence like this: the visions of \u201c3\u201d would fire a picture of 3 apples (a younger child might need to perform a counting pattern to reach that step, which would also later migrate to Type 1), \u201c2\u201d would fire two apples, a child then starts counting (each number connected to the next, and the context of counting enforces this connection), crossing out each apple with each fired number, until all apples are crossed out.</p>\n<p>Now this introduces the following mental operation: visualizing apples and performing operations on this visual image while counting (like crossing out or marking each counted apple). My wild guess here is that this, again, is reducible to Type 1 operations resulting from basic teacher instructions on additions, including visual demonstrations.</p>\n<p><strong id=\"Levels_of_Type_1_to_2_Migration\">Levels of Type 1 to 2 Migration</strong></p>\n<p>Now, as pointed above, a younger child might need to apply counting to convert \u201c3\u201d to an image of 3 apples. As the child grows, she might have formed (by practice) the direct grown-up pattern that translates the image of \u201c3+2\u201d directly to \u201c5\u201d. She will then use this to add a number like 13+12 \u2013 utilizing \u201c3+2\u201d, \u201c1+1+1\u201d, and the carry 1 visual patterns. So the child would apply Type 2 addition utilizing several skills recently migrated to Type 1. As the child grows up, more layers of processes would migrate to Type 1, and the current Type 2 operations would become more efficient as they rely on those migrated skills.</p>\n<p>So, what I am saying here, my guess, is that there is no clear distinction between the two Types. That Type 2 operations are simple those that use a large number of Type 1 steps, and hence is slower, non-automatic (as they are slow, there is more time for other processes to stop them from completing, and hence they seem to be controlled), and effortful.</p>\n<p><strong id=\"Which_connectionism_pattern_will_be_used\">Which connectionism pattern will be used</strong></p>\n<p>Now probably a grown up still has all those accumulated skills in place. Seeing \u201c3+2\u201d, I still have the ability to apply the apple technique, and also to apply the direct connection between \u201c3+2\u201d and \u201c5\u201d. Which one I use, I suggest, is based on two probably algorithms:</p>\n<ol>\n<li>Size: I use what I call the \u201cLargest Available Recognizable Pattern\u201d (LARP). This means, how many patterns I need to invoke to come to a result. The brain then keeps invoking patterns from largest (less total number of patterns) to smaller, until a reasonable result is reached </li>\n<li>Time: this is based on the quickest pattern, which would usually be equivalent to the largest.</li>\n</ol>\n<p><strong id=\"And_\">And?</strong></p>\n<p>I totally confess that this is a wild guess, and an idea that is not at all fully developed. I am not aware if this idea had been suggested in a more mature way or not, so this is an attempt to mainly get feedback and resources from you, and perhaps to build it up into better structure.</p>\n<p>The value of developing such a theory is that at some point it can be testable, and perhaps bring a better understanding of how we learn new skills, and more efficient ways to acquire and develop our skills.</p>", "sections": [{"title": "Background (safe to skip)", "anchor": "Background__safe_to_skip_", "level": 1}, {"title": "Migration of Skills", "anchor": "Migration_of_Skills", "level": 1}, {"title": "Simple Type 2 operations", "anchor": "Simple_Type_2_operations", "level": 1}, {"title": "Levels of Type 1 to 2 Migration", "anchor": "Levels_of_Type_1_to_2_Migration", "level": 1}, {"title": "Which connectionism pattern will be used", "anchor": "Which_connectionism_pattern_will_be_used", "level": 1}, {"title": "And?", "anchor": "And_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-12T20:19:10.636Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Second Law of Thermodynamics, and Engines of Cognition", "slug": "seq-rerun-the-second-law-of-thermodynamics-and-engines-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.258Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XQHsmdYiqMLws6AKT/seq-rerun-the-second-law-of-thermodynamics-and-engines-of", "pageUrlRelative": "/posts/XQHsmdYiqMLws6AKT/seq-rerun-the-second-law-of-thermodynamics-and-engines-of", "linkUrl": "https://www.lesswrong.com/posts/XQHsmdYiqMLws6AKT/seq-rerun-the-second-law-of-thermodynamics-and-engines-of", "postedAtFormatted": "Sunday, February 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Second%20Law%20of%20Thermodynamics%2C%20and%20Engines%20of%20Cognition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Second%20Law%20of%20Thermodynamics%2C%20and%20Engines%20of%20Cognition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQHsmdYiqMLws6AKT%2Fseq-rerun-the-second-law-of-thermodynamics-and-engines-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Second%20Law%20of%20Thermodynamics%2C%20and%20Engines%20of%20Cognition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQHsmdYiqMLws6AKT%2Fseq-rerun-the-second-law-of-thermodynamics-and-engines-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQHsmdYiqMLws6AKT%2Fseq-rerun-the-second-law-of-thermodynamics-and-engines-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 248, "htmlBody": "<p>Today's post, <a href=\"/lw/o5/the_second_law_of_thermodynamics_and_engines_of/\">The Second Law of Thermodynamics, and Engines of Cognition</a> was originally published on 27 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>To form accurate beliefs about something, you really do have to observe it.  It's a very physical, very real process: any rational mind does \"work\" in the thermodynamic sense, not just the sense of mental effort. Engines of cognition are not so different from heat engines, though they manipulate entropy in a more subtle form than burning gasoline. So unless you can tell me which specific step in your argument violates the laws of physics by giving you true knowledge of the unseen, don't expect me to believe that a big, elaborate clever argument can do it either.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/9z1/seq_rerun_leave_a_line_of_retreat/\">Leave a Line of Retreat</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XQHsmdYiqMLws6AKT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 8.478116740268907e-07, "legacy": true, "legacyId": "12973", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QkX2bAkwG2EpGvNug", "79t4RtscYjKR6QZwN", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-13T00:30:24.091Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta", "slug": "meetup-atlanta-3", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:59.820Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hankx7787", "createdAt": "2011-07-10T22:12:52.395Z", "isAdmin": false, "displayName": "hankx7787"}, "userId": "B4SKuX6dAQMnNqHzH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/m8KAHyi8nF4qtc7uz/meetup-atlanta-3", "pageUrlRelative": "/posts/m8KAHyi8nF4qtc7uz/meetup-atlanta-3", "linkUrl": "https://www.lesswrong.com/posts/m8KAHyi8nF4qtc7uz/meetup-atlanta-3", "postedAtFormatted": "Monday, February 13th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm8KAHyi8nF4qtc7uz%2Fmeetup-atlanta-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm8KAHyi8nF4qtc7uz%2Fmeetup-atlanta-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm8KAHyi8nF4qtc7uz%2Fmeetup-atlanta-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 115, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/75'>Atlanta</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 February 2012 06:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2094 North Decatur Road, Decatur, GA 30033-5367</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>All,</p>\n\n<p>The next meetup will be Saturday, February 18th at 6:30pm at Chocolate Coffee in Decatur:</p>\n\n<p><a href=\"http://www.mychocolatecoffee.com/\" rel=\"nofollow\">http://www.mychocolatecoffee.com/</a>\n2094 North Decatur Road, Decatur, GA 30033-5367\n(404) 982-0790</p>\n\n<p>Here is the official agenda of our next meeting:\n<a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\" rel=\"nofollow\">http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions</a>\n1.21 Positive Bias: Look Into the Dark\n1.22 My Wild and Reckless Youth\n1.23 Failing to Learn from History\n1.24 Making History Available\n1.25 Explain/Worship/Ignore?</p>\n\n<p>We will also be discussing The Prisoner's Dilemma and Newcomb's paradox.</p>\n\n<p>Please let me know if you have any questions or comments! I hope to see ALL of you there!</p>\n\n<p>-Hank\n404 384 9776</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/75'>Atlanta</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "m8KAHyi8nF4qtc7uz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.479102244821727e-07, "legacy": true, "legacyId": "12976", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta\">Discussion article for the meetup : <a href=\"/meetups/75\">Atlanta</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 February 2012 06:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2094 North Decatur Road, Decatur, GA 30033-5367</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>All,</p>\n\n<p>The next meetup will be Saturday, February 18th at 6:30pm at Chocolate Coffee in Decatur:</p>\n\n<p><a href=\"http://www.mychocolatecoffee.com/\" rel=\"nofollow\">http://www.mychocolatecoffee.com/</a>\n2094 North Decatur Road, Decatur, GA 30033-5367\n(404) 982-0790</p>\n\n<p>Here is the official agenda of our next meeting:\n<a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\" rel=\"nofollow\">http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions</a>\n1.21 Positive Bias: Look Into the Dark\n1.22 My Wild and Reckless Youth\n1.23 Failing to Learn from History\n1.24 Making History Available\n1.25 Explain/Worship/Ignore?</p>\n\n<p>We will also be discussing The Prisoner's Dilemma and Newcomb's paradox.</p>\n\n<p>Please let me know if you have any questions or comments! I hope to see ALL of you there!</p>\n\n<p>-Hank\n404 384 9776</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Atlanta1\">Discussion article for the meetup : <a href=\"/meetups/75\">Atlanta</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta", "anchor": "Discussion_article_for_the_meetup___Atlanta", "level": 1}, {"title": "Discussion article for the meetup : Atlanta", "anchor": "Discussion_article_for_the_meetup___Atlanta1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-13T04:58:20.926Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Perpetual Motion Beliefs", "slug": "seq-rerun-perpetual-motion-beliefs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:57.839Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QWCSze72DKYYXFFbd/seq-rerun-perpetual-motion-beliefs", "pageUrlRelative": "/posts/QWCSze72DKYYXFFbd/seq-rerun-perpetual-motion-beliefs", "linkUrl": "https://www.lesswrong.com/posts/QWCSze72DKYYXFFbd/seq-rerun-perpetual-motion-beliefs", "postedAtFormatted": "Monday, February 13th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Perpetual%20Motion%20Beliefs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Perpetual%20Motion%20Beliefs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQWCSze72DKYYXFFbd%2Fseq-rerun-perpetual-motion-beliefs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Perpetual%20Motion%20Beliefs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQWCSze72DKYYXFFbd%2Fseq-rerun-perpetual-motion-beliefs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQWCSze72DKYYXFFbd%2Fseq-rerun-perpetual-motion-beliefs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 318, "htmlBody": "<p>Today's post, <a href=\"/lw/o6/perpetual_motion_beliefs/\">Perpetual Motion Beliefs</a> was originally published on 27 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>People learn under the traditional school regimen that the teacher tells you certain things, and you must believe them and recite them back; but if a mere student suggests a belief, you do not have to obey it.  They map the domain of belief onto the domain of authority, and think that a certain belief is like an order that must be obeyed, but a probabilistic belief is like a mere suggestion.</blockquote>\n<blockquote></blockquote>\n<blockquote>And  when half-trained or tenth-trained rationalists abandon their art and try to believe without evidence just this once, they often build vast edifices of justification, confusing themselves just enough to conceal the magical steps.  It can be quite a pain to nail down where the magic occurs - their structure of argument tends to morph and squirm away as you interrogate them.  But there's always some step where a tiny probability turns into a large one - where they try to believe without evidence - where they step into the unknown, thinking, \"No one can prove me wrong\".</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a0d/seq_rerun_the_second_law_of_thermodynamics_and/\">The Second Law of Thermodynamics, and Engines of Cognition</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QWCSze72DKYYXFFbd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 8.480153572593635e-07, "legacy": true, "legacyId": "12993", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zFuCxbY9E2E8HTbfZ", "XQHsmdYiqMLws6AKT", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-13T19:36:17.384Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - Cognitive Biases Round-robin", "slug": "meetup-west-la-meetup-cognitive-biases-round-robin", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Y6dPZEESivP6QicuB/meetup-west-la-meetup-cognitive-biases-round-robin", "pageUrlRelative": "/posts/Y6dPZEESivP6QicuB/meetup-west-la-meetup-cognitive-biases-round-robin", "linkUrl": "https://www.lesswrong.com/posts/Y6dPZEESivP6QicuB/meetup-west-la-meetup-cognitive-biases-round-robin", "postedAtFormatted": "Monday, February 13th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20Cognitive%20Biases%20Round-robin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20Cognitive%20Biases%20Round-robin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY6dPZEESivP6QicuB%2Fmeetup-west-la-meetup-cognitive-biases-round-robin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20Cognitive%20Biases%20Round-robin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY6dPZEESivP6QicuB%2Fmeetup-west-la-meetup-cognitive-biases-round-robin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY6dPZEESivP6QicuB%2Fmeetup-west-la-meetup-cognitive-biases-round-robin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/76'>West LA Meetup - Cognitive Biases Round-robin</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, February 15th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Activity:</strong> Cognitive Biases Round-robin. Choose at least one item from Wikipedia's <a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow\">List of Cognitive Biases</a>, and read up on it enough to introduce the topic to the group (LW posts on problematic thinking are also fair game). Then, as a group, we will try to identify real-life situations where the bias would come into play, how it could be harmful, when it doesn't matter (or even helps!), and how to counter or use it.</p>\n\n<p>This is also a good time to browse <a href=\"http://lesswrong.com/recentposts\">recent posts</a>, especially those that pertain to our activity!</p>\n\n<p>Don't worry if you don't have time to read anything, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/76'>West LA Meetup - Cognitive Biases Round-robin</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Y6dPZEESivP6QicuB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 8.48359991454958e-07, "legacy": true, "legacyId": "13005", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Cognitive_Biases_Round_robin\">Discussion article for the meetup : <a href=\"/meetups/76\">West LA Meetup - Cognitive Biases Round-robin</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, February 15th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Activity:</strong> Cognitive Biases Round-robin. Choose at least one item from Wikipedia's <a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow\">List of Cognitive Biases</a>, and read up on it enough to introduce the topic to the group (LW posts on problematic thinking are also fair game). Then, as a group, we will try to identify real-life situations where the bias would come into play, how it could be harmful, when it doesn't matter (or even helps!), and how to counter or use it.</p>\n\n<p>This is also a good time to browse <a href=\"http://lesswrong.com/recentposts\">recent posts</a>, especially those that pertain to our activity!</p>\n\n<p>Don't worry if you don't have time to read anything, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Cognitive_Biases_Round_robin1\">Discussion article for the meetup : <a href=\"/meetups/76\">West LA Meetup - Cognitive Biases Round-robin</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - Cognitive Biases Round-robin", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Cognitive_Biases_Round_robin", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - Cognitive Biases Round-robin", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Cognitive_Biases_Round_robin1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T03:04:11.240Z", "modifiedAt": null, "url": null, "title": "Subjective expected utility without preferences", "slug": "subjective-expected-utility-without-preferences", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.598Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MBKtoBi52Ry8JJfdt/subjective-expected-utility-without-preferences", "pageUrlRelative": "/posts/MBKtoBi52Ry8JJfdt/subjective-expected-utility-without-preferences", "linkUrl": "https://www.lesswrong.com/posts/MBKtoBi52Ry8JJfdt/subjective-expected-utility-without-preferences", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Subjective%20expected%20utility%20without%20preferences&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASubjective%20expected%20utility%20without%20preferences%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBKtoBi52Ry8JJfdt%2Fsubjective-expected-utility-without-preferences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Subjective%20expected%20utility%20without%20preferences%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBKtoBi52Ry8JJfdt%2Fsubjective-expected-utility-without-preferences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBKtoBi52Ry8JJfdt%2Fsubjective-expected-utility-without-preferences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 90, "htmlBody": "<p>In the latest issue of <em>Journal of Mathematical Psychology</em>,&nbsp;Denis Bouyssou and Thieery Marchant&nbsp;provide a model for subjective expected utility without preferences. Abstract:</p>\n<blockquote>\n<p>\n<p class=\"p1\">This paper proposes a theory of subjective expected utility based on primitives only involving the fact&nbsp;that an act can be judged either &lsquo;&lsquo;attractive&rsquo;&rsquo; or &lsquo;&lsquo;unattractive&rsquo;&rsquo;. We give conditions implying that there are&nbsp;a utility function on the set of consequences and a probability distribution on the set of states such that&nbsp;attractive acts have a subjective expected utility above some threshold. The numerical representation that&nbsp;is obtained has strong uniqueness properties.</p>\n</p>\n</blockquote>\n<p class=\"p1\"><a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/Bouyssou-Marchant-Subjective-expected-utility-without-preferences.pdf\">PDF</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MBKtoBi52Ry8JJfdt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 8.485359081622017e-07, "legacy": true, "legacyId": "13023", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T03:21:30.466Z", "modifiedAt": null, "url": null, "title": "Theoretical tools for understanding and aiding dynamic decision making", "slug": "theoretical-tools-for-understanding-and-aiding-dynamic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.375Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HCNYogqBE5rjEF5a4/theoretical-tools-for-understanding-and-aiding-dynamic", "pageUrlRelative": "/posts/HCNYogqBE5rjEF5a4/theoretical-tools-for-understanding-and-aiding-dynamic", "linkUrl": "https://www.lesswrong.com/posts/HCNYogqBE5rjEF5a4/theoretical-tools-for-understanding-and-aiding-dynamic", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Theoretical%20tools%20for%20understanding%20and%20aiding%20dynamic%20decision%20making&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATheoretical%20tools%20for%20understanding%20and%20aiding%20dynamic%20decision%20making%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCNYogqBE5rjEF5a4%2Ftheoretical-tools-for-understanding-and-aiding-dynamic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Theoretical%20tools%20for%20understanding%20and%20aiding%20dynamic%20decision%20making%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCNYogqBE5rjEF5a4%2Ftheoretical-tools-for-understanding-and-aiding-dynamic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCNYogqBE5rjEF5a4%2Ftheoretical-tools-for-understanding-and-aiding-dynamic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 165, "htmlBody": "<p><a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/Busemeyer-Pleskac-Theoretical-tools-for-understanding-and-aiding-dynamic-decision-making.pdf\">This paper</a> includes a very handy review of theoretical tools that help with dynamic decision-making:</p>\n<blockquote>\n<p>Dynamic decisions arise in many applications including military, medical, management, sports, and&nbsp;emergency situations. During the past 50 years, a variety of general and powerful tools have emerged&nbsp;for understanding, analyzing, and aiding humans faced with these decisions. These tools include&nbsp;expected and multi-attribute utility analyses, game theory, Bayesian inference and Bayes nets, decision&nbsp;trees and influence diagrams, stochastic optimal control theory, partially observable Markov decision&nbsp;processes, neural networks and reinforcement learning models, Markov logics, and rule-based cognitive&nbsp;architectures. What are all of these tools, how are they related, when are they most useful, and do these&nbsp;tools match the way humans make decisions? We address all of these questions within a broad overview&nbsp;that is written for an interdisciplinary audience. Each description of a tool introduces the principles upon&nbsp;which it is based, and also reviews empirical research designed to test whether humans actually use these&nbsp;principles to make decisions. We conclude with suggestions for future directions in research.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HCNYogqBE5rjEF5a4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 8.485427122525313e-07, "legacy": true, "legacyId": "13024", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T06:46:54.088Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Searching for Bayes-Structure", "slug": "seq-rerun-searching-for-bayes-structure", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.533Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CnDbgN6b3R9LRWx3c/seq-rerun-searching-for-bayes-structure", "pageUrlRelative": "/posts/CnDbgN6b3R9LRWx3c/seq-rerun-searching-for-bayes-structure", "linkUrl": "https://www.lesswrong.com/posts/CnDbgN6b3R9LRWx3c/seq-rerun-searching-for-bayes-structure", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Searching%20for%20Bayes-Structure&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Searching%20for%20Bayes-Structure%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCnDbgN6b3R9LRWx3c%2Fseq-rerun-searching-for-bayes-structure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Searching%20for%20Bayes-Structure%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCnDbgN6b3R9LRWx3c%2Fseq-rerun-searching-for-bayes-structure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCnDbgN6b3R9LRWx3c%2Fseq-rerun-searching-for-bayes-structure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 190, "htmlBody": "<p>Today's post, <a href=\"/lw/o7/searching_for_bayesstructure/\">Searching for Bayes-Structure</a> was originally published on 28 February 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If a mind is arriving at true beliefs, and we assume that the second law of thermodynamics has not been violated, that mind must be doing something at least vaguely Bayesian - at least one process with a sort-of Bayesian structure somewhere - or it <em>couldn't possibly work</em>.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a0x/seq_rerun_perpetual_motion_beliefs/\">Perpetual Motion Beliefs</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CnDbgN6b3R9LRWx3c", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.486234056514513e-07, "legacy": true, "legacyId": "13032", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QrhAeKBkm2WsdRYao", "QWCSze72DKYYXFFbd", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T07:53:25.005Z", "modifiedAt": null, "url": null, "title": "What happens when your beliefs fully propagate", "slug": "what-happens-when-your-beliefs-fully-propagate", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.576Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexei", "createdAt": "2010-08-02T15:14:11.411Z", "isAdmin": false, "displayName": "Alexei"}, "userId": "CD3DC5D7GHtgBmxz5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/coEDeEaSEAkhic4s2/what-happens-when-your-beliefs-fully-propagate", "pageUrlRelative": "/posts/coEDeEaSEAkhic4s2/what-happens-when-your-beliefs-fully-propagate", "linkUrl": "https://www.lesswrong.com/posts/coEDeEaSEAkhic4s2/what-happens-when-your-beliefs-fully-propagate", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20happens%20when%20your%20beliefs%20fully%20propagate&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20happens%20when%20your%20beliefs%20fully%20propagate%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcoEDeEaSEAkhic4s2%2Fwhat-happens-when-your-beliefs-fully-propagate%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20happens%20when%20your%20beliefs%20fully%20propagate%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcoEDeEaSEAkhic4s2%2Fwhat-happens-when-your-beliefs-fully-propagate", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcoEDeEaSEAkhic4s2%2Fwhat-happens-when-your-beliefs-fully-propagate", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2137, "htmlBody": "<blockquote>\n<p><em>This is a very personal account of thoughts and events that have led me to a very interesting point in my life. Please read it as such. I present a lot of points, arguments, conclusions, etc..., but that's not what this is about.</em></p>\n</blockquote>\n<p>I've started reading LW around spring of 2010. I was at the rationality minicamp last summer (2011). The night of February 10, 2012 all the rationality learning and practice finally caught up with me. Like a water that has been building up behind a damn, it finally broke through and flooded my poor brain.</p>\n<p>\"What if the Bayesian Conspiracy is real?\" (By Bayesian Conspiracy I just mean a secret group that operates within and around LW and SIAI.) That is the question that set it all in motion. \"Perhaps they left clues for those that are smart enough to see it. And to see those clues, you would actually have to understand and apply everything that they are trying to teach.\" The chain of thoughts that followed (conspiracies within conspiracies, shadow governments and Illuminati) it too ridiculous to want to repeat, but it all ended up with one simple question: How do I find out for sure? And that's when I realized that almost all the information I have has been accepted without as much as an ounce of verification. So little of my knowledge has been tested in the real world. In that moment I achieved a sort of enlightenment: I realized I don't know anything. I felt a dire urge to regress to the very basic questions: \"What is real? What is true?\" And then I laughed, because that's exactly where The Sequences start.</p>\n<p>Through the turmoil of jumbled and confused thoughts came a shock of my most valuable belief propagating through my mind, breaking down final barriers, reaching its logical conclusion. FAI <strong>is</strong> the most important thing we should be doing right now! I already knew that. In fact, I knew that for a long time now, but I didn't... what? Feel it? Accept it? Visualize it? Understand the consequences? I think I didn't let that belief propagate to its natural conclusion: I should be doing something to help this cause.</p>\n<p>I can't say: \"It's the most important thing, but...\" Yet, I've said it so many times inside my head. It's like hearing other people say: \"Yes, X is the rational thing to do, but...\" What follows is a defense that allows them to keep the path to their goal that they are comfortable with, that they are already invested in.</p>\n<p>Interestingly enough, I've already thought about this. Right after rationality minicamp, I've asked myself the question: Should I switch to working on FAI, or should I continue to make games? I've thought about it heavily for some time, but I felt like I lacked the necessary math skills to be of much use on FAI front. Making games was the convenient answer. It's something I've been doing for a long time, it's something I am good. I decided to make games that explain various ideas that LW presents in text. This way I could help raise the sanity waterline. Seemed like a very nice, neat solution that allowed me to do what I wanted and feel a bit helpful to the FAI cause.</p>\n<p>Looking back, I was dishonest with myself. In my mind, I already wrote the answer I wanted. I convinced myself that I didn't, but part of me certainly sabotaged the whole process. But that's okay, because I was still somewhat helpful, even though may be not in the most optimal way. Right? <em>Right??</em> The correct answer is \"no\". So, now I have to ask myself again: What is the best path for me? And to answer that, I have to understand what my goal is.</p>\n<p>Rationality doesn't just help you to get what you want better/faster. Increased rationality starts to change what you want. May be you wanted the air to be clean, so you bought a hybrid. Sweet. But then you realized that what you actually want is for people to be healthy. So you became a nurse. That's nice. Then you realized that if you did research, you could be making an order of magnitude more people healthier. So you went into research. Cool. Then you realized that you could pay for multiple researchers if you had enough money. So you went out, become a billionaire, and created your own research institute. Great. There was always you, and there was your goal, but everything in between was (and should be) up for grabs.</p>\n<p>And if you follow that kind of chain long enough, at some point you realize that FAI is actually the thing right before your goal. Why wouldn't it be? It solves everything in the best possible way!</p>\n<p>People joke that LW is a cult. Everyone kind of laughs it off. It's funny because cultists are weird and crazy, but they are so sure they are right. LWers are kind of like that. Unlike other cults, though, we are really, truly right. Right? But, honestly, I like the term, and I think it has a ring of truth to it. Cultists have a goal that's beyond them. We do too. My life isn't about my preferences (I can change those), it's about my goals. I can change those too, of course, but if I'm rational (and nice) about it, I feel that it's hard not to end up wanting to help other people.</p>\n<p>Okay, so I need a goal. Let's start from the beginning:</p>\n<p><em>What is truth?</em></p>\n<p>Reality is truth. It's what happens. It's the rules that dictate what happens. It's the invisible territory. It's the thing that makes you feel surprised.</p>\n<p>(Okay, great, I won't have to go back to reading Greek philosophy.)</p>\n<p><em>How do we discover truth?</em></p>\n<p>So far, the best method has been the scientific principle. It's has also proved itself over and over again by providing actual tangible results.</p>\n<p>(Fantastic, I won't have to reinvent the thousands of years of progress.)</p>\n<p><em>Soon enough humans will commit a fatal mistake.</em></p>\n<p>This isn't a question, it's an observation. The technology is advancing on all fronts to the point where it can be used on a planetary (and wider) scale. Humans make mistakes. Making mistake with something that affects the whole world could result in an injury or death... for the planet (and potentially beyond).</p>\n<p><em>That's bad.</em></p>\n<p>To be honest, I don't have a strong visceral negative feeling associated with all humans becoming extinct. It doesn't feel that bad, but then again I know better than to trust my feelings on such a scale. However, if I had to simply push a button to make one person's life significantly better, I would do it. And I would keep pushing that button for each new person. For something like 222 years, by my rough calculations. Okay, then. Humanity injuring or killing itself would be bad, and I can probably spent a century or so to try to prevent that, while also doing something that's a lot more fun that mashing a button.</p>\n<p><em>We need a smart safety net.</em></p>\n<p>Not only smart enough to know that triggering an atomic bomb inside a city is bad, or that you get the grandma out of a burning building by teleporting her in one piece to a safe spot, but also smart enough to know that if I keep snoozing every day for an hour or two, I'd rather someone stepped in and stopped me, no matter how much I want to sleep JUST FIVE MORE MINUTES. It's something I might actively fight, but it's something that I'll be grateful for <em>later</em>.</p>\n<p><em>FAI</em></p>\n<p>There it is: the ultimate safety net. Let's get to it?</p>\n<p>Having FAI will be very very good, that's clear enough. Getting FAI wrong will be very very bad. But there are different levels of bad, and, frankly, a universe tiled with paper-clips is actually not that high on the list. Having an AI that treats humans as special objects is very dangerous. An AI that doesn't care about humans will not do anything to humans specifically. It might borrow a molecule, or an arm or two from our bodies, but that's okay. An AI that treats humans as special, yet is not Friendly could be very bad. Imagine 3^^^3 different people being created and forced to live really horrible lives. It's hell on a whole another level. So, if FAI goes wrong, pure destruction of all humans is a pretty good scenario.</p>\n<p>Should we even be working on FAI? What are the chances we'll get it right? (I remember Anna Salamon's comparison: \"getting FAI right\" is like \"trying to make the first atomic bomb explode in a shape of an elephant\" would have been a century ago.) What are the chances we'll get it horribly wrong and end up in hell? By working on FAI, how are we changing the probability distribution for various outcomes? Perhaps a better alternative is to seek a decisive advantage like brain uploading, where a few key people can take a century or so to think the problem through?</p>\n<p>I keep thinking about FAI going horribly wrong, and I want to scream at the people who are involved with it: \"Do you even know what you are doing?!\" Everything is at stake! And suddenly I care. Really care. There is curiosity, yes, but it's so much more than that. At LW minicamp we compared curiosity to a cat chasing a mouse. It's a kind of fun, playful feeling. I think we got it wrong. The real curiosity feels like hunger. The cat isn't chasing the mouse to play with it; it's chasing it to eat it because it needs to survive. Me? I <strong>need</strong> to know the <em>right </em>answer.</p>\n<p>I finally understand why SIAI isn't focusing very hard on the actual AI part right now, but is instead pouring most of their efforts into recruiting talent. The next 50-100 years is going to be a marathon for our lives. Many participants might not make it to the finish line. It's important that we establish a community that can continue to carry the research forward until we succeed.</p>\n<p>I finally understand why when I was talking about making games that help people be more rational with Carl Shulman, his value metric was to see how many academics it could impact/recruit. That didn't make sense to me. I just wanted to raise the sanity waterline for people in general. I think when LWers say \"raise the sanity waterline,\" there are two ideas being presented. One is to make everyone a little bit more sane. That's nice, but overall probably not very beneficial to FAI cause. Another is to make certain key people a bit more sane, hopefully sane enough to realize that FAI is a big deal, and sane enough to do some meaningful progress on it.</p>\n<p>I finally realized that when people were talking about donating to SIAI during the rationality minicamp, most of us (certainly myself) were thinking of may be tens of thousands of dollars a year. I now understand that's silly. If our goal is truly to make the most money for SIAI, then the goal should be measured in billions.</p>\n<p>I've realized a lot of things lately. A lot of things have been shaken up. It has been a very stressful couple of days. I'll have to re-answer the question I asked myself not too long ago: What should I be doing? And this time, instead of hoping for an answer, I'm afraid of the answer. I'm truly and honestly afraid. Thankfully, I can fight pushing a lot better than pulling: fear is easier to fight than passion. I can plunge into the unknown, but it breaks my heart to put aside a very interesting and dear life path.</p>\n<p>I've never felt more afraid, more ready to fall into a deep depression, more ready to scream and run away, retreat, abandon logic, go back to the safe comfortable beliefs and goals. I've spent the past 10 years making games and getting better at it. And just recently I've realized how really really good I actually am at it. Armed with my rationality toolkit, I could probably do wonders in that field.</p>\n<p>Yet, I've also never felt more ready to make a step of this magnitude. Maximizing utility, all the fallacies, biases, defense mechanisms, etc, etc, etc. One by one they come to mind and help me move forward. Patterns of thoughts and reasoning that I can't even remember the name of. All these tools and skills are right here with me, and using them I feel like I can do anything. I feel that I can dodge bullets. But I also know full well that I am at the starting line of a long and difficult marathon. A marathon that has no path and no guides, but that has to be run nonetheless.</p>\n<p>May the human race win.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "coEDeEaSEAkhic4s2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 51, "baseScore": 29, "extendedScore": null, "score": 6e-05, "legacy": true, "legacyId": "13037", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 79, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T14:48:27.919Z", "modifiedAt": null, "url": null, "title": "\"The Book Of Mormon\" or Belief In Belief, The Musical", "slug": "the-book-of-mormon-or-belief-in-belief-the-musical", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:21.892Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raw_Power", "createdAt": "2010-09-10T23:59:43.621Z", "isAdmin": false, "displayName": "Raw_Power"}, "userId": "kwSqcED9qTanFyNWG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B9JWpDsQhrSeoNBnu/the-book-of-mormon-or-belief-in-belief-the-musical", "pageUrlRelative": "/posts/B9JWpDsQhrSeoNBnu/the-book-of-mormon-or-belief-in-belief-the-musical", "linkUrl": "https://www.lesswrong.com/posts/B9JWpDsQhrSeoNBnu/the-book-of-mormon-or-belief-in-belief-the-musical", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22The%20Book%20Of%20Mormon%22%20or%20Belief%20In%20Belief%2C%20The%20Musical&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22The%20Book%20Of%20Mormon%22%20or%20Belief%20In%20Belief%2C%20The%20Musical%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB9JWpDsQhrSeoNBnu%2Fthe-book-of-mormon-or-belief-in-belief-the-musical%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22The%20Book%20Of%20Mormon%22%20or%20Belief%20In%20Belief%2C%20The%20Musical%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB9JWpDsQhrSeoNBnu%2Fthe-book-of-mormon-or-belief-in-belief-the-musical", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB9JWpDsQhrSeoNBnu%2Fthe-book-of-mormon-or-belief-in-belief-the-musical", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1123, "htmlBody": "<p><a href=\"http://www.youtube.com/watch?v=GfTlyuZphf8\">This song is</a>... beautiful... Tragically so... It's like someone took some of the sequences here and made a checklist of everything that's wrong with religion, and why it still <em>works</em> and why it can stir the heart of noble, brave, generous people... The main character is a Mormon missionary, he was always groomed to be a believer, and his cheering and professing was rewarded, and he was happy. Then he was sent to some warzone in Africa, to convert people there to his faith (And I believe that in 1978, God changed his mind about black people! You can be a Mormon!). Except the people really aren't interested in what he preaches, and might easily shoot him in the head for it (But \"What's so scary about that?\", when you have an immortal soul and know you are doing the <em>right</em> thing? Whatever the outcome, you <em>win!</em>). But, see, that's okay, as long as he believes wholeheartedly and without a shred of doubt, everything will be <em>fine</em>... (You cannot just believe part way, you have to believe in it all. My problem was doubting the Lord's will, instead of standing tall!). Of course, if it does <em>not</em> turn out fine, that's all <em>your</em> fault for not believing enough...</p>\n<p>You know, I'd like to say something smart to start the discussion over, but right now I'm just feeling too emotional... You know what, I'll just post the lyrics for the song, and let you guys suggest the adequate potholes for every instance of... blatant, obvious, categorized <del>insanitiy</del> irrationality that this song demonstrates...</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p style=\"padding-left: 30px;\">Ever since I was a child I tried to be the best<br /> So, what happened?<br /> My family and friends all said I was blessed<br /> So, what happened?<br /> It was supposed to be all so exciting to be teaching of Christ 'cross the sea,<br /> But, I allowed my faith to be shaken.<br /> Oh, what's the matter with me?<br /> <br /> I've always longed to help the needy<br /> To do the things I never dared.<br /> This was the time for me to step up<br /> So, then, why was I so scared?<br /> <br /> A warlord who shoots people in the face.<br /> What's so scary about that?<br /> I must trust that my Lord is mightier<br /> And always has my back.<br /> Now I must be completely devout<br /> I can't have even one shred of doubt...<br /> <br /> I believe that the Lord, God, created the universe.<br /> I believe that He sent His only Son to die for my sins.<br /> And I believe that ancient Jews built boats and sailed to America<br /> I am a Mormon,<br /> And a Mormon just believes.<br /> <br /> You cannot just believe part way,<br /> You have to believe in it all.<br /> My problem was doubting the Lord's will<br /> Instead of standing tall.<br /> <br /> I can't allow myself to have any doubt.<br /> It's time to set my worries free.<br /> Time to show the world what Elder Price is about!<br /> And share the power inside of me...<br /> <br /> I believe that God has a plan for all of us.<br /> I believe that plan involves me getting my own planet.<br /> And I believe; that the current President of The Church, Thomas Monson, speaks directly to God.<br /> I am A Mormon,<br /> And, dang it! a Mormon just believes!<br /> <br /> I know that I must go and do<br /> The things my God commands.<br /> I realize now why He sent me here.<br /> <br /> If You ask the Lord in faith,<br /> He will always answer you.<br /> Just believe in Him<br /> And have no fear!<br /> <br /> I believe that Satan has a hold of you<br /> I believe that the Lord, God, has sent me here<br /> And I believe that in 1978, God changed his mind about black people!<br /> You can be a Mormon..<br /> A Mormon who just believes!<br /> <br /> And now I can feel the excitement.<br /> This is the moment I was born to do.<br /> And I feel so incredible<br /> To be sharing my faith with you.<br /> <br /> The Scriptures say that if you ask in faith,<br /> If you ask God Himself he'll know.<br /> But you must ask Him without any doubt<br /> And let your spirit grow...<br /> <br /> I believe that God lives on a planet called Kolob.<br /> I believe that Jesus has his own planet as well.<br /> And I believe that the Garden of Eden was in Jackson County, Missouri.<br /> If you believe, the Lord will reveal it. <br /> And you'll know it's all true. You'll just feel it.<br /> You'll be a Mormon<br /> And, by gosh!<br /> A Mormon just believes! <br /> Oh, I believe.<br /> I believe.</p>\n<p style=\"padding-left: 30px;\">&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Okay, now <a href=\"http://www.youtube.com/watch?v=PHEqCXY2B-w&amp;feature=related\">with the actual performance</a>. Try not to laugh, and <em>fail...</em></p>\n<p>But this kinda raises an interesting question. Why is it, in fact, so thrilling, to share a faith that one actually doubts, with other people? Is it some sort of resonance? Like, \"whew, he believes too, that's evidence towards me being right and this being true, right?\". What's that, Affective Death Spiral, Uncritical Supercriticality, or not exactly either but something related? And why is it that it does not happen with certain other faiths, such as, say, the Church of England, or Judaism?</p>\n<p>Also, a guy with the sheer <a href=\"http://en.wikipedia.org/wiki/Agap%C4%93\">agape</a> of Elder Price could easily work for some other humanistic enterprise, such as an NGO... But why is it that I just can't imagine someone singing</p>\n<p style=\"padding-left: 30px;\">\"I belieeeeve, into the UN Declaration of Human Rights of 1948!</p>\n<p style=\"padding-left: 30px;\">I beliieeeeeeve that every man has a right to live,</p>\n<p style=\"padding-left: 30px;\">And I beliieeeeeve that every person was born equal before the law!</p>\n<p style=\"padding-left: 30px;\">Just belieeeeeve that every man should be able to travel freely (within their country)!</p>\n<p style=\"padding-left: 30px;\">I do belieeeeeve that every person has a right to property!</p>\n<p style=\"padding-left: 30px;\">I am a (???????), and I've got <em>reasons</em> why I believe!\"</p>\n<p>&nbsp;</p>\n<p>No, seriously, why is it that non-religious movements <em>seem to</em> lack this oomph, this particular eagerness, that the religious are often portrayed bearing? There's untapped human potential, here, friends, and we're letting it go to waste. Reversed stupidity is not intelligence. So, how do we infuse this kind of zeal, of enthusiasm, into, say, the Less Wrong brand of Secular Humanism? Here's a challenge for ya: edit \"I Believe\" to fit your actual creed (no need for it to be consensual <em>here</em>). Don't be afraid to sound silly, what you're supposed to carry carry across is <em>emotional passion</em> that <em>compels</em> people to <em>follow you</em>.</p>\n<p style=\"padding-left: 30px;\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"aLB9evWFYtfyS3WJg": 1, "YTCrHWYHAsAD74EHo": 1, "NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B9JWpDsQhrSeoNBnu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 14, "extendedScore": null, "score": 3.2e-05, "legacy": true, "legacyId": "13045", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T16:52:55.141Z", "modifiedAt": null, "url": null, "title": "[LINK] The Hacker Shelf, free books.", "slug": "link-the-hacker-shelf-free-books", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:28.247Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ytNR2cG5LdnQTWmEo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pqC7raFbEpb9w3XNv/link-the-hacker-shelf-free-books", "pageUrlRelative": "/posts/pqC7raFbEpb9w3XNv/link-the-hacker-shelf-free-books", "linkUrl": "https://www.lesswrong.com/posts/pqC7raFbEpb9w3XNv/link-the-hacker-shelf-free-books", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20The%20Hacker%20Shelf%2C%20free%20books.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20The%20Hacker%20Shelf%2C%20free%20books.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqC7raFbEpb9w3XNv%2Flink-the-hacker-shelf-free-books%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20The%20Hacker%20Shelf%2C%20free%20books.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqC7raFbEpb9w3XNv%2Flink-the-hacker-shelf-free-books", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqC7raFbEpb9w3XNv%2Flink-the-hacker-shelf-free-books", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 521, "htmlBody": "<p>Yes, this a repost from <a href=\"http://news.ycombinator.com/\">Hacker News</a>, but I want to point out some books that are of LW-related interest.</p>\n<p><a href=\"http://hackershelf.com/\">The Hacker Shelf</a> is a repository of freely available textbooks. Most of them are about computer programming or the business of computer programming, but there are a few that are perhaps interesting to the LW community. All of these were publicly available beforehand, but I'm linking to the aggregator in hopes that people can think of other freely available textbooks to submit there.</p>\n<p>The site is in its beginning explosion phase; in the time it took to write this post, it doubled in size. If previous sites are any indication, it will crest in a month or so. People will probably lose interest after three months, and after a year the site will probably silently close shop.</p>\n<h2>MacKay, Information Theory, Inference, and Learning Algorithms</h2>\n<p>I really wish I had an older version of this book; the newer one has been marred by a Cambridge UP ad on the upper margin of every page. Publishers ruin everything.</p>\n<p>The book covers reasonably concisely the basics of information theory and Bayesian methods, with some game theory and coding theory (in the sense of data compression) thrown in on the side. The style takes after Knuth, but refrains from the latter's more encyclopedic tendencies. It's also the type of book that gives a lot of extra content in the exercises. It unfortunately assumes a decent amount of mathematical knowledge &mdash;&nbsp;linear algebra and calculus, but nothing you wouldn't find on the Khan Academy.</p>\n<p><a href=\"http://hackershelf.com/book/23/information-theory-inference-and-learning-algorithms/\">Hacker Shelf review</a>, <a href=\"http://www.inference.phy.cam.ac.uk/mackay/itila/\">book website</a>.</p>\n<h2>Easley and Kleinberg, Networks, Crowds, and Markets</h2>\n<p>There's just a lot of stuff in this book, most of it of independent interest. The thread that ties the book together is graph theory, and with it they cover a great deal of game theory, voting theory, and economics. There are lots of graphs and pictures, and the writing style is pretty deliberate and slow-paced. The math is not very intense; all their probability spaces are discrete, so there's no calculus, and only a few touches of linear algebra.</p>\n<p><a href=\"http://hackershelf.com/book/15/networks-crowds-and-markets/\">Hacker Shelf review</a>, <a href=\"http://www.cs.cornell.edu/home/kleinber/networks-book/\">book website</a>.</p>\n<h2>Gabriel, Patterns of Software</h2>\n<p>This is a more fluffy book about the practice of <a href=\"/lw/9sv/diseased_disciplines_the_strange_case_of_the/\">software engineering</a>. It's rather old, but I'm linking to it anyway because I agree with the author's feeling that the software engineering discipline has more or less misunderstood Christopher Alexander's work on pattern languages. The author tends to ramble on. I think there's some good wisdom about programming practices and organizational management in general that one could abstract away from this book.</p>\n<p><a href=\"http://hackershelf.com/book/28/patterns-of-software/\">Hacker Shelf link</a>, <a href=\"http://dreamsongs.com/Books.html\">book website</a> (scroll down).</p>\n<h2>Nisan et. al., Algorithmic Game Theory</h2>\n<p>I hesitate to link this because the math level is exceptionally high, perhaps high enough that anyone who can read the book probably knows the better part of its contents already. But game/decision theory is near and dear to LW's heart, so perhaps someone will gather some utility from this book. There's an awful lot going on in it. A brief selection: a section on the relationship between game theory and cryptography, a section on computation in prediction markets, and a section analyzing the incentives of information security.</p>\n<p><a href=\"http://hackershelf.com/book/34/algorithmic-game-theory/\">Hacker Shelf review</a>, <a href=\"http://www.cambridge.org/journals/nisan/downloads/Nisan_Non-printable.pdf\">book</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pqC7raFbEpb9w3XNv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 19, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "13046", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Yes, this a repost from <a href=\"http://news.ycombinator.com/\">Hacker News</a>, but I want to point out some books that are of LW-related interest.</p>\n<p><a href=\"http://hackershelf.com/\">The Hacker Shelf</a> is a repository of freely available textbooks. Most of them are about computer programming or the business of computer programming, but there are a few that are perhaps interesting to the LW community. All of these were publicly available beforehand, but I'm linking to the aggregator in hopes that people can think of other freely available textbooks to submit there.</p>\n<p>The site is in its beginning explosion phase; in the time it took to write this post, it doubled in size. If previous sites are any indication, it will crest in a month or so. People will probably lose interest after three months, and after a year the site will probably silently close shop.</p>\n<h2 id=\"MacKay__Information_Theory__Inference__and_Learning_Algorithms\">MacKay, Information Theory, Inference, and Learning Algorithms</h2>\n<p>I really wish I had an older version of this book; the newer one has been marred by a Cambridge UP ad on the upper margin of every page. Publishers ruin everything.</p>\n<p>The book covers reasonably concisely the basics of information theory and Bayesian methods, with some game theory and coding theory (in the sense of data compression) thrown in on the side. The style takes after Knuth, but refrains from the latter's more encyclopedic tendencies. It's also the type of book that gives a lot of extra content in the exercises. It unfortunately assumes a decent amount of mathematical knowledge \u2014&nbsp;linear algebra and calculus, but nothing you wouldn't find on the Khan Academy.</p>\n<p><a href=\"http://hackershelf.com/book/23/information-theory-inference-and-learning-algorithms/\">Hacker Shelf review</a>, <a href=\"http://www.inference.phy.cam.ac.uk/mackay/itila/\">book website</a>.</p>\n<h2 id=\"Easley_and_Kleinberg__Networks__Crowds__and_Markets\">Easley and Kleinberg, Networks, Crowds, and Markets</h2>\n<p>There's just a lot of stuff in this book, most of it of independent interest. The thread that ties the book together is graph theory, and with it they cover a great deal of game theory, voting theory, and economics. There are lots of graphs and pictures, and the writing style is pretty deliberate and slow-paced. The math is not very intense; all their probability spaces are discrete, so there's no calculus, and only a few touches of linear algebra.</p>\n<p><a href=\"http://hackershelf.com/book/15/networks-crowds-and-markets/\">Hacker Shelf review</a>, <a href=\"http://www.cs.cornell.edu/home/kleinber/networks-book/\">book website</a>.</p>\n<h2 id=\"Gabriel__Patterns_of_Software\">Gabriel, Patterns of Software</h2>\n<p>This is a more fluffy book about the practice of <a href=\"/lw/9sv/diseased_disciplines_the_strange_case_of_the/\">software engineering</a>. It's rather old, but I'm linking to it anyway because I agree with the author's feeling that the software engineering discipline has more or less misunderstood Christopher Alexander's work on pattern languages. The author tends to ramble on. I think there's some good wisdom about programming practices and organizational management in general that one could abstract away from this book.</p>\n<p><a href=\"http://hackershelf.com/book/28/patterns-of-software/\">Hacker Shelf link</a>, <a href=\"http://dreamsongs.com/Books.html\">book website</a> (scroll down).</p>\n<h2 id=\"Nisan_et__al___Algorithmic_Game_Theory\">Nisan et. al., Algorithmic Game Theory</h2>\n<p>I hesitate to link this because the math level is exceptionally high, perhaps high enough that anyone who can read the book probably knows the better part of its contents already. But game/decision theory is near and dear to LW's heart, so perhaps someone will gather some utility from this book. There's an awful lot going on in it. A brief selection: a section on the relationship between game theory and cryptography, a section on computation in prediction markets, and a section analyzing the incentives of information security.</p>\n<p><a href=\"http://hackershelf.com/book/34/algorithmic-game-theory/\">Hacker Shelf review</a>, <a href=\"http://www.cambridge.org/journals/nisan/downloads/Nisan_Non-printable.pdf\">book</a>.</p>", "sections": [{"title": "MacKay, Information Theory, Inference, and Learning Algorithms", "anchor": "MacKay__Information_Theory__Inference__and_Learning_Algorithms", "level": 1}, {"title": "Easley and Kleinberg, Networks, Crowds, and Markets", "anchor": "Easley_and_Kleinberg__Networks__Crowds__and_Markets", "level": 1}, {"title": "Gabriel, Patterns of Software", "anchor": "Gabriel__Patterns_of_Software", "level": 1}, {"title": "Nisan et. al., Algorithmic Game Theory", "anchor": "Nisan_et__al___Algorithmic_Game_Theory", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4ACmfJkXQxkYacdLt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T19:21:48.081Z", "modifiedAt": null, "url": null, "title": "On What Selves Are - CEV sequence", "slug": "on-what-selves-are-cev-sequence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:05.176Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DGfPyJbynXZF9NGv4/on-what-selves-are-cev-sequence", "pageUrlRelative": "/posts/DGfPyJbynXZF9NGv4/on-what-selves-are-cev-sequence", "linkUrl": "https://www.lesswrong.com/posts/DGfPyJbynXZF9NGv4/on-what-selves-are-cev-sequence", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20What%20Selves%20Are%20-%20CEV%20sequence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20What%20Selves%20Are%20-%20CEV%20sequence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDGfPyJbynXZF9NGv4%2Fon-what-selves-are-cev-sequence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20What%20Selves%20Are%20-%20CEV%20sequence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDGfPyJbynXZF9NGv4%2Fon-what-selves-are-cev-sequence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDGfPyJbynXZF9NGv4%2Fon-what-selves-are-cev-sequence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3396, "htmlBody": "<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>The CEV Sequence Summary: </strong></span><span lang=\"en-US\">The CEV sequence consists of three posts tackling important aspects of <a href=\"http://intelligence.org/upload/CEV.html\">Coherent Extrapolated Volition</a> (CEV). It covers conceptual, practical and computational problems of <a href=\"http://intelligence.org/upload/CEV.html\">CEV's current form</a>. </span><span lang=\"en-US\"><em>On What Selves Are</em></span><span lang=\"en-US\"> draws on analytic philosophy methods in order to clarify the concept of Self, which is necessary in order to understand whose volition is going to be extrapolated by a machine that implements the CEV procedure. </span><span lang=\"en-US\"><em>Troubles with CEV part1</em></span><span lang=\"en-US\"> and </span><span lang=\"en-US\"><em>Troubles with CEV part2</em></span><span lang=\"en-US\"> on the other hand describe several issues that will be faced by the CEV project if it is actually going to be implemented. Those issues are not of conceptual nature. Many of the objections shown come from scattered discussions found on the web. Finally, six alternatives to CEV are considered. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>On What Selves Are Summary:</strong></span><span lang=\"en-US\"> We start by concurring on a Hofstadterian metaphysical view of Selves. We suggest two ways in which to divide the concept of Self, admitting Selves to be mongrel concepts, and cluster concepts. We then proceed to the identification of Selves, in particular, a proposed new method for a machine to identify Self-like entities. In the spirit of Dennettian philosophy, we then ask what we demand of Selves, to better grasp what they are. In conclusion, we present some views of Selves that are worth wanting, and claim that only considering Selves in their full complexity we can truly analyze them. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Note:</strong> A draft of the first half of On What Selves Are was published in discussion <a href=\"/lw/714/part_1_on_what_is_a_self_discussion/\">here</a>, those who read it may want to skip straight to section \"Organisms, Superorganisms and Selves\". <br /></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"CENTER\"><span style=\"font-size: x-large;\">On What Selves Are</span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"><strong>Background: Symbols Coalesce to Form Selves</strong></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"JUSTIFY\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\">Some of what is taken for granted in this text is vividly subsumed by pg 204 and 289-290 of Hofstadter'</span><span lang=\"en-US\">s &ldquo;I Am a Strange Loop&rdquo;(2007). To those who are still in the struggle relating to monism, dualism, qualia, Mary the neuroscientist, epiphenomenons and ineffable qualities, it is worth it to read through his passage to understand the background metaphysical view of the universe from which it is derived. To those on the other hand who are good willed reductionists of the non-greedy, no-skyhook, no 'design only from Above' kind may skip past this section:</span></span></p>\n<blockquote>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\">[What makes and &ldquo;I&rdquo; come seemingly out of nowhere] is ironically, an </span><span lang=\"en-US\"><em>inability - </em></span><span lang=\"en-US\">namely our [...] inability to see, feel, or sense in any way the constant frenetic, churning and roiling of micro -stuff, all the unfelt bubbling and boiling that underlies our thinking. This, our innate blindness to the world of the tiny, forces us to hallucinate a profound schism </span><span lang=\"en-US\">between</span><span lang=\"en-US\"> the goal-lacking material world of balls and sticks and sounds and lights, on the one hand, and a goal-pervaded abstract world of hopes and beliefs and joys and fears, on the other, in which radically different sorts of causality seem to reign. [...]</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\">&ldquo;<span style=\"font-size: small;\"><span lang=\"en-US\">[Your] &ldquo;I&rdquo; was not an </span><span lang=\"en-US\"><em>a priori </em></span><span lang=\"en-US\">well-defined thing that was predestined to jump, full-fledged and sharp, in to some just-created empty physical vessel at some particular instant. Nor did your &ldquo;I&rdquo; suddenly spring into existence, wholly unanticipated but in full bloom. Rather, your &ldquo;I&rdquo; was the slowly emerging outcome of a million unpredictable events that befell a particular body and the brain housed in it. Your &ldquo;I&rdquo; is the self-reinforcing structure that gradually came to exist not only </span><span lang=\"en-US\"><em>in</em></span><span lang=\"en-US\"> that brain, but </span><span lang=\"en-US\"><em>thanks to</em></span><span lang=\"en-US\"> that brain. It </span><span lang=\"en-US\">couldn't</span><span lang=\"en-US\"> have come to exist in </span><span lang=\"en-US\"><em>this </em></span><span lang=\"en-US\">brain, because </span><span lang=\"en-US\"><em>this </em></span><span lang=\"en-US\">brain went through different experiences that led to a different human being.&rdquo; </span></span></p>\n</blockquote>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"JUSTIFY\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\"> We will take for granted that this is the metaphysically correct approach to thinking about mental entities. What will be discussed lies more in the domain of conceptual usage, word meaning, psychological conceptions, symbolic extension, explicit linguistic definition, and less on trying to find underlying substrates or metaphysical properties of Selves. </span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><br /></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"JUSTIFY\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><strong>Selves and Persons Are Similar</strong></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\">On the </span><span lang=\"en-US\">eighth move of your weekly chess game you do what feels same as always: Reflect for a few seconds on the many layers of structure underlying the current game-state, specially regarding changes from your opponent&rsquo;s last move. It seems reasonable to take his pawn with your bishop. After moving you look at him and see the sequence of expressions: doubt </span><span lang=\"en-US\">(</span><span lang=\"en-US\">Why did he do that?), distrust (He must be seeing something I'm not), inquiry (Let me double check this), schadenfreude (No, he actually failed) and finally joy (Piece of cake, I&rsquo;ll win). He takes your bishop with a knight that from your perspective came out of nowhere. Still stunned, you resign. It is the second time in a row you lose the game due to a simple mistake. The excuse bursts naturally out of your mouth: &ldquo;I&rsquo;m not myself today&rdquo;</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"JUSTIFY\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\">The functional role (with plausible</span><span lang=\"en-US\"> evolutionary reasons) of this use of the concept of Self is easy to unscramble: </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\" align=\"JUSTIFY\"><span style=\"font-size: small;\">1) Do not hold your model of me as responsible for these mistakes</span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\">2) Either (a) I sense something strange about the inner machinery of my mind, the algorithm feels different from the inside. Or (b) at least my now visible mistakes are </span><span lang=\"en-US\">reliable</span><span lang=\"en-US\"> evidence of a difference which I detected in hindsight.</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\">3) If there is a person watching this game, notice how my signaling and my friend&rsquo;s not contesting it is reliable evidence I normally play chess better than this</span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\">A few minutes later, you see your friend yelling </span><span lang=\"en-US\">historically</span><span lang=\"en-US\"> at someone in the phone, you explain to the girl who was watching: &ldquo;He is not that kind of person.&rdquo;</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\">Here we have a situation where the analogous of 1 and 3 work, but there is no way for you to tell what the algorithm feels from the inside. You still know in hindsight that your friend doesn&rsquo;t usually yell like that. Though 1, 2, and 3 still hold, 2(a) is not the case anymore.</span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\">I suggest the property of 2(a) that blocks interchangeability of the concepts of Self and Person is &ldquo;having first person epistemic information about X&rdquo;. Selves have that, people don&rsquo;t. We use the term &lsquo;person&rsquo; when we want to talk only about the epistemically intersubjective properties of someone. Self is reserved for a person&rsquo;s perspective of herself, including, for instance, indexical facts. </span></p>\n<p><span style=\"font-size: small;\">Other than that, Self and Person seem to be interchangeable concepts. This generalization is useful because that means most of the problem of personhood and selfhood can be collapsed into one thing.</span></p>\n<p><span style=\"font-size: small;\"><span lang=\"en-US\">Unfortunately, the Self/Person intersection is a concept that is itself a </span><span lang=\"en-US\">m</span><span lang=\"en-US\">ongrel concept, so it has again to be split apart.</span></span></p>\n<p>&nbsp;</p>\n<p><span style=\"font-size: small;\"><strong>Mongrel and Cluster Concepts</strong></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\">When a concept seems to defy easy explanability, there are two potential explanatory approaches. The first would be to assume that the disparate uses of the term &lsquo;Self&rsquo;&rsquo; in ordinary language and science can be captured by a unique, all-encompassing notion of Self. The second is to assume that different uses of &lsquo;Self&rsquo;&rsquo; reveal a plurality of notions of selfhood, each in need of a separate account. I will endorse this second assumption: Self is a </span><span lang=\"en-US\">mongrel</span></span><span style=\"font-size: small;\"><span lang=\"en-US\">concept in need of disambiguation. (to </span><span lang=\"en-US\">strengthen</span><span lang=\"en-US\"> the analogy power of thinking about mongrels, it may help to know that Information, Consciousness and Health are thought to be mongrel concepts as well).</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\"> Without using specific tags for the time being, let us assume that there will be 4 kinds of Self, 1,2,3, and 4. To say that Self is a concept that sometimes maps into 1, sometimes into 3 and so on is not to </span><span lang=\"en-US\">exhaustively</span><span lang=\"en-US\"> frame the concept usage. That is because 1 and 2 themselves may be cluster concepts. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\"> The cluster concept shape is one of the most common shapes of concepts in our mental vocabulary. Concepts are associational structures. Most of the time</span><span lang=\"en-US\">, instead of drawing a clear line around a set in the world inside of which all X fits, and outside of which none does, concepts present a cluster</span><span lang=\"en-US\"> like structure with nearly all core area members belonging and nearly none farther from the core</span><span lang=\"en-US\">. Not all of their typical features are logically necessary. The recognition of features produces an activation, the strength of which depends not only on the degree to which the feature is present but a weighting factor. When the sum of the activations crosses a threshold, the concept becomes active and the stimulus is said to belong to that category.</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\"> Selves are mongrel</span><span lang=\"en-US\"> concepts composed of different conceptual intuitions, each of which is itself a cluster concept, thus Selves are part of the most elusive, abstract, high-level entities entertained by minds. Whereas this may be aesthetically pleasant, presenting us as considerably complex entities, it is also a great ethical burden, for it leaves the domain of ethics, highly </span><span lang=\"en-US\">dependent</span><span lang=\"en-US\"> on the concepts of selfhood and personhood, with a scattered slippery</span><span lang=\"en-US\"> ground-level notion from which to create the building blocks of ethical theories.</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"JUSTIFY\">&nbsp;</p>\n<p><span style=\"font-size: small;\"><span lang=\"en-US\">Several analogies have been used to convey the concept of cluster concept, these convey</span><span lang=\"en-US\"> images of star clusters, neural networks lighting up, and sets of properties with a majority vote. A particularly well known analogy used by Wittgenstein is the game analogy, in which language games determine prescribe normative meanings which constrict a word&rsquo;s meaning, without determining a clear cut case. Wittgenstein defended that there was no clear set of necessary conditions that determine what a game is. Bernard Suits came up with a refutation of that claim, stating that there is such a definition (modified from &ldquo;What is a game&rdquo; 1967, </span><span lang=\"en-US\"><em>Philosophy of Science</em></span><span lang=\"en-US\"> Vol. 34, No. 2 [Jun., 1967], pp. 148-156):</span></span></p>\n<blockquote>\n<p><br /><span style=\"font-size: small;\"><span lang=\"en-US\">\"To play a game is to engage in activity designed to bring about a specific state of affairs, using only means permitted by specific rules, where the means permitted by the rules are more limited in scope than they would be in the absence of such rules, and where the sole reason for accepting the rules is to make possible such activity.\" </span></span></p>\n</blockquote>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\" align=\"JUSTIFY\"><span style=\"font-size: small;\"> Can we hope for a similar soon to be found understanding of Self? Let us invoke:</span></p>\n<p class=\"western\" style=\"margin-left: 0.79cm; margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em><strong>The Hidden Variable Hypothesis</strong></em></span><span lang=\"en-US\"><em>: There is a core essence which determines the class of Selves from non-Selves, it is just not yet within our current </em></span><span lang=\"en-US\"><em>state-of-knowledge reach.</em></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" align=\"JUSTIFY\"><span style=\"font-size: small;\"><span lang=\"en-US\"> While desirable, there are various </span><span lang=\"en-US\">resons to be skeptical of The Hidden Variable </span><span lang=\"en-US\">Hyphotesis: (1) Any plausible candidate core would have to be able to disentangle Selves from Organisms in general, Superorganisms (i.e. insect societies) and institutions (2) We clearly entertain different models of what Selves are for different purposes, as shown below in Section Varieties of Self-Systems Worth Having. (3) Design consideration: Being evolved structures which encompass several resources of a recently evolved mind, that came to being through a complex dual-inheritance evolution of several hundred thousand replicators belonging to two kinds (genes and memes), Selves are among the most complex structures known and thus unlikely to possess a core essence, due to causal design considerations independent of how </span><span lang=\"en-US\">untractable it would be to detect and describe this essence. </span></span></p>\n<p><span style=\"font-size: small;\"><span lang=\"en-US\">From now on then</span><span lang=\"en-US\">, I will be assuming as common ground that Selves are mongrel concepts, comprised of some yet undiscussed number of cluster concepts.</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"><strong>Organisms, Superorganisms, and Selves</strong></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"> To refine our notions of Selves we ought to be able to distinguish Selves from Organisms, that is, biological coalitions of cells with adaptation-execution functions, and from Superorganisms, biological coalitions of individuals with a group-level behavior that fits the adaptation-executer characterization. </span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> Organisms, Superorganisms and Selves are composed of smaller parts that instantiate simple algorithmic behavior which, in large numbers, brings about complex behavior. One fundamental difference though is that Selves are grammatical. While ants use variegated </span><span lang=\"en-US\">hidrocarbons to signal things to other ants of the same Superorganism, and cells communicate through potassium and sodium exchanges, we use phonemes composing words composing sentences, we have </span><span lang=\"en-US\">thoughs which compose our deliberations. Selves are thus different in that we exhibit grammaticality and semantic abstraction capacities unseen in the organismic and superorganismic levels of organization. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Persons, the Evidence for Other </strong></span><span lang=\"en-US\"><strong>Selfs</strong></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> How could we teach a machine to identify people? This is the underlying question that has led me to write this text, and it is a question of utter importance if we are to believe the current cutting edge</span><span lang=\"en-US\"> guesses about when is artificial intelligence going to surpass human intelligence. We have to make sure that what passes the test is not an ant family, nor is it a panda. Luckily, this test has been established already by Alan Turing, the infamous Turing test. While the Turing test was originally thought to establish when a machine has achieved human intelligence, there is no reason to deny it a secondary purpose once a machine </span><span lang=\"en-US\"><em>has </em></span><span lang=\"en-US\"><span style=\"font-style: normal\">already achieved human intelligence. Once such machine exists, it could use its own human-like intelligence to test other entities and classify them as human-like or not human-like. This would give us a non-personhood indicator, as demanded by Yudkowsky.</span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal\"> This may appear to be a </span></span><span lang=\"en-US\"><em>deus ex machina </em></span><span lang=\"en-US\"><span style=\"font-style: normal\">in that I am assuming that the </span></span><span lang=\"en-US\"><span style=\"font-style: normal\">turing test performed by this machine will be able to grasp the essence of humanity, and capture it. Not so. What we should expect of Selves and people is not an essence, as prescribed by The Hidden Variable </span></span><span lang=\"en-US\"><span style=\"font-style: normal\">Hipothesis. We should expect a mongrel</span></span><span lang=\"en-US\"><span style=\"font-style: normal\"> built of clusters of </span></span><span lang=\"en-US\"><span style=\"font-style: normal\">identifyable data, with its shape not well delineated on the borders, and we should expect more than a single simple structure. Exactly the kind of thing that is able to pass a </span></span><span lang=\"en-US\"><span style=\"font-style: normal\">turing test, which, itself, is not established with absolute precision, but relies in our linguistic, empathic, commonsensical and conversational skills to be performed. </span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Selves as Utility </strong></span><span lang=\"en-US\"><strong>Increaser Unnatural Clusters</strong></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span><span lang=\"en-US\">Thusfar we have considered Selves as non-essence-bearing, sets of clusters of linguistic, grammatical entities, but this is missing one important aspect of selfhood, intentionality. Language is mostly intentional, that is, about things that are not themselves, and brains are mostly intentional, that is, integrated into the world in such a way that a convoluted mapping happens between its internal content and the worlds external facts. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> The particularity that makes Selves different from Superorganisms and Organisms at this level is that Selves are utility increasing,</span><span lang=\"en-US\"> they have goals, desires, ideals, and thrive to achieve them. Selves act as functions, by rearranging the physical world of which they are a part of from low-utility local configuration to high utility local configuration.</span><span lang=\"en-US\">These goals, desires and ideals change from time to time without change of Self. This is a naturally </span><span lang=\"en-US\">occuring process in many cluster concepts. To be a cluster concept includes being the kind of concept that remains same despite change, and possibly dramatic change, as long as this change is &ldquo;softened&rdquo; by happening one bit at a time. A </span><span lang=\"en-US\">S</span><span lang=\"en-US\">elf's goals may shift strongly in ten years, but at any particular time, the goals, desires, grammaticality and intentionality are the defining features of that Self, of that person. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><br /></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"> </span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"><strong>What do We Demand of Selves</strong></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> A per our chess example above, we demand stability from Selves. We also demand honor, respectability, resilience,</span><span lang=\"en-US\"> accountability. When I say you owe me that money, it implicitly implies that you are the same person as the one to whom I lent that money. When I </span><span lang=\"en-US\">invite you for a duel, I expect to kill the same you who is listening to the invitation, even if a few days later. Part of our models of people are evolved from the need for accountability. An evolutionary guess: We incorporate a notion of sameness over time for a person because this holds the person accountable. Reciprocal altruism, a form of altruism belonging to many complex social species of animals</span><span lang=\"en-US\"> relies on the assumption that one will pay back, and paying back is only possible if the original giver is still there to receive his payment. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> Has our notion of Self followed our demands for accountability or did it happen the other way around? This is a chicken and egg sort of question. Just like eggs obviously came first because dinosaurs </span><span lang=\"en-US\">layed eggs, accountability came first because many other animals exhibit reciprocal altruism. Yet, just as we can reshape the chicken and egg question in such way that both seem to be determining each other, we can also reshape our accountability question in such way: Has our model of selfhood reinforced our tendencies to demand accountability of others or has our need for accountability created a demand for stronger, stable Selves? Probably both have happened, they are self reinforcing in both directions, in psychological jargon, they perform transactional reinforcement. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> Besides sheer accountability, our notions of honor and respect also rely on sameness over time, they are just a bit more convoluted and sophisticated, but this topic is tangent</span><span lang=\"en-US\"> to our interests here. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Varieties of Self-Systems Worth Having</strong></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-weight: normal\"> Not all animals have a notion of Self </span></span><span lang=\"en-US\"><span style=\"font-weight: normal\">(From Varieties of Self Systems Worth Having):</span></span></span></p>\n<blockquote>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-weight: normal\"> </span></span><span lang=\"en-US\">&ldquo;According to Povinelli and colleagues, one possibility is that a sense of the embodiment of Self&mdash;as opposed to mere proprioception&mdash;a sense of ownership of one's own body, may have evolved in some primates as a consequence of arboreal locomotion</span><span lang=\"en-US\"> (Barth et al., 2004). Orangutans need subtle appreciation of their own body position, posture, and weight to brachiate and support themselves on flimsy branches. It is not as though they can navigate by trial and error, since a fall will likely prove fatal. The behavior and the required capacity are less developed in chimpanzees and even less in gorillas. This would suggest a complicated history for this kind of Self-representation, having been lost by the primate branch that led to chimpanzees, and devel</span><span lang=\"en-US\"><span style=\"font-weight: normal\">oped in the hominine lineage.</span></span><span lang=\"en-US\"><strong>&rdquo;</strong></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span><span lang=\"en-US\"><span style=\"font-weight: normal\">&ldquo;We speak of &lsquo;&lsquo;Self-systems worth having&rsquo;&rsquo; to reflect four characteristics of the recent literature on the Self. </span></span><span lang=\"en-US\">First, most models imply that the Self is supported by a federation of specialized processes rather than a single integrated cognitive function. Second, most researchers think that the phenomenology of selfhood results from the aggregate of the functions performed by these different information-processing devices. Third, most of the information-processing is construed as sub-personal, hence inaccessible to conscious inspection. Fourth, we talk about systems worth having to emphasize that there is nothing inevitable about the functioning of any of these systems.&rdquo;</span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"> &ldquo;Neisser made conceptual and empirical distinctions between five domains of Self-knowledge, namely: an ecological Self, a sense of ones own location in and distinctness from the environment; an interpersonal Self, a sense of oneself as a locus of emotion and social interaction; an extended Self, a sense of oneself as an individual existing over time; a private Self, a sense of oneself as the subject of introspectively accessible experience; and a conceptual Self, comprising all those representations that constitute a Self-image, including representations of one's social role and personal autobiography (Neisser, 1988)&ldquo;</span></p>\n</blockquote>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"> The ecological Self is our notion of our location, both as a whole (hippocampus) and proprioception, that is, the relative position and movement of our body parts (frontal lobe). The interpersonal Self is salient in our blushing and teasing, laughing and crying. The extended Self is widely discussed in the philosophical literature, most famously by Derek Parfit in Reasons and Persons</span><span lang=\"en-US\">;</span><span lang=\"en-US\">, it is<a href=\"/uspfiloanalitica.googlegroups.com/web/IS+PERSONAL+IDENTITY+WHAT+MATTERS+%28Parfit%29.pdf?gda=xH7KUGUAAACxY9vtt80_Eoc5nvqIVwz1SrVJGmujo21ZzWCUZeyIT_1pTF0kkXH0LwuUCGHMLaD_Xbul_77J5BjqCwuNd7LQkq10Hen6mJVcDGpt2QOMNxyfxYhtaHnOp4Mq0MGarrsa7WIsd6qHDhllGPdGMn_4\"> </a><a href=\"http://www.ammonius.org/assets/pdfs/ammoniusfinal.pdf\">that which remains when time elapses</a>, the sense of constancy and of sameness that one feels. The private Self talks inside our heads all the time, it is the nagging inner voice that remains active when we introspect and look inwards. The conceptual Self is an honorable, respectable individual, with all the special abilities we know ourselves to have, from lawful to honorable, from noble to the example above: Don't hold me responsible for act X, claims the conceptual Self, I'm not myself today. </span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"><span lang=\"en-US\"> Neisser's analysis is a fine grained one, distinct from a coarse grained one like Gallaghers:</span></span></p>\n<blockquote>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span>&ldquo;<span lang=\"en-US\">Gallagher distinguishes broadly between the &lsquo;&lsquo;minimal&rsquo;&rsquo; and the &lsquo;&lsquo;narrative&rsquo;&rsquo; Self. The former supplies the ecological sense of bodily ownership and agency associated with</span> active behavior, while the latter supports the Self-image that associates our identity with various episodes (Gallagher, 2000).&rdquo;</span></p>\n</blockquote>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span><span lang=\"en-US\"><span style=\"font-weight: normal\">The analysis of selfhood, or of personhood can be done in other ways too, after all, we are dealing with a strange construction. We are trying to carve reality at its joints, but the joints of mongrel cluster concepts are a fuzzy structure, and we are given many choices on how to carve them, any analysis of </span></span><span lang=\"en-US\"><span style=\"font-weight: normal\">S</span></span><span lang=\"en-US\"><span style=\"font-weight: normal\">elves is going to look at least as complex as this one, and we should learn to abandon physics envy, stop thinking that Selves come in one sentence, and learn to deal with the full complexities involved. </span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm\"><span lang=\"en-US\">Sources: </span></p>\n<p>&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"zxx\"><span style=\"text-decoration: none;\"><a href=\"/lw/53z/the_nature_of_self\">http</a><a href=\"/lw/53z/the_nature_of_self\">://</a><a href=\"/lw/53z/the_nature_of_self\">lesswrong</a><a href=\"/lw/53z/the_nature_of_self\">.</a><a href=\"/lw/53z/the_nature_of_self\">com</a><a href=\"/lw/53z/the_nature_of_self\">/</a><a href=\"/lw/53z/the_nature_of_self\">lw</a><a href=\"/lw/53z/the_nature_of_self\">/53</a><a href=\"/lw/53z/the_nature_of_self\">z</a><a href=\"/lw/53z/the_nature_of_self\">/</a><a href=\"/lw/53z/the_nature_of_self\">the</a><a href=\"/lw/53z/the_nature_of_self\">_</a><a href=\"/lw/53z/the_nature_of_self\">nature</a><a href=\"/lw/53z/the_nature_of_self\">_</a><a href=\"/lw/53z/the_nature_of_self\">of</a><a href=\"/lw/53z/the_nature_of_self\">_</a><a href=\"/lw/53z/the_nature_of_self\">self</a><a href=\"/lw/53z/the_nature_of_self\">/</a></span></span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"zxx\"><span style=\"text-decoration: none;\"><a href=\"/lw/4e/cached_selves\">http</a><a href=\"/lw/4e/cached_selves\">://</a><a href=\"/lw/4e/cached_selves\">lesswrong</a><a href=\"/lw/4e/cached_selves\">.</a><a href=\"/lw/4e/cached_selves\">com</a><a href=\"/lw/4e/cached_selves\">/</a><a href=\"/lw/4e/cached_selves\">lw</a><a href=\"/lw/4e/cached_selves\">/4</a><a href=\"/lw/4e/cached_selves\">e</a><a href=\"/lw/4e/cached_selves\">/</a><a href=\"/lw/4e/cached_selves\">cached</a><a href=\"/lw/4e/cached_selves\">_</a><a href=\"/lw/4e/cached_selves\">selves</a><a href=\"/lw/4e/cached_selves\">/</a></span></span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"zxx\"><span style=\"text-decoration: none;\"><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">http</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">://</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">the</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">-</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">mouse</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">-</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">trap</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">.</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">com</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">/2009/11/01/</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">five</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">-</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">kinds</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">-</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">of</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">-</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">selfself</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">-</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">knowledge</a><a href=\"http://the-mouse-trap.com/2009/11/01/five-kinds-of-selfself-knowledge/\">/</a></span></span></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"text-decoration: none;\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"en-US\"><span style=\"text-decoration: none;\">(comes from Neisser 1988)</span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"zxx\"><span style=\"text-decoration: none;\"><a href=\"http://www.scholarpedia.org/article/Self_models\">http</a><a href=\"http://www.scholarpedia.org/article/Self_models\">://</a><a href=\"http://www.scholarpedia.org/article/Self_models\">www</a><a href=\"http://www.scholarpedia.org/article/Self_models\">.</a><a href=\"http://www.scholarpedia.org/article/Self_models\">scholarpedia</a><a href=\"http://www.scholarpedia.org/article/Self_models\">.</a><a href=\"http://www.scholarpedia.org/article/Self_models\">org</a><a href=\"http://www.scholarpedia.org/article/Self_models\">/</a><a href=\"http://www.scholarpedia.org/article/Self_models\">article</a><a href=\"http://www.scholarpedia.org/article/Self_models\">/</a><a href=\"http://www.scholarpedia.org/article/Self_models\">Self</a><a href=\"http://www.scholarpedia.org/article/Self_models\">_</a><a href=\"http://www.scholarpedia.org/article/Self_models\">models</a></span></span></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"text-decoration: none;\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"en-US\"><span style=\"text-decoration: none;\">(Kept by Thomas Metzinger)</span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"zxx\"><span style=\"text-decoration: none;\"><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">http</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">://</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">www</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">.</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">ncbi</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">.</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">nlm</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">.</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">nih</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">.</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">gov</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">/</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">pubmed</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">/16257</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">234</a></span></span></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"text-decoration: none;\"> </span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\"><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"zxx\"><span style=\"text-decoration: none;\">Conscious</span></span></span></span></span></a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\"><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"text-decoration: none;\"> </span></span></span></span></a><span style=\"color: #000080;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"zxx\"><span style=\"text-decoration: none;\"><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">Cogn</a><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16257234\">.</a></span></span></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"text-decoration: none;\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"en-US\"><span style=\"text-decoration: none;\">2005 Dec;14(4):647-60. Epub 2005 Oct 27.</span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><a href=\"http://plato.stanford.edu/entries/identity-personal/\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><span lang=\"en-US\"><span style=\"text-decoration: none;\">http://plato.stanford.edu/entries/identity-personal/</span></span></span></span></a></p>\n<p class=\"western\" style=\"margin-left: 0.76cm; text-indent: -0.76cm; line-height: 115%; text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: x-small;\"><a href=\"http://philpapers.org/rec/BOYVOS\"><span style=\"color: #000000;\"><span lang=\"en-US\"><span style=\"font-weight: normal;\">Varieties of self-systems worth having</span></span></span></a><span style=\"color: #000000;\"><span lang=\"en-US\">. </span></span><span style=\"color: #000000;\"><span lang=\"zxx\">Boyer P</span></span><span style=\"color: #000000;\"><span lang=\"en-US\">,</span></span><span style=\"color: #000000;\"> </span><span style=\"color: #000000;\"><span lang=\"zxx\">Robbins P</span></span><span style=\"color: #000000;\"><span lang=\"en-US\">,</span></span><span style=\"color: #000000;\"> </span><span style=\"color: #000000;\"><span lang=\"zxx\">Jack AI</span></span><span style=\"color: #000000;\"><span lang=\"en-US\">.</span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm\" lang=\"en-US\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W6QZYSNt5FgWgvbdT": 1, "5f5c37ee1b5cdee568cfb2fa": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DGfPyJbynXZF9NGv4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -8, "extendedScore": null, "score": -1.3e-05, "legacy": true, "legacyId": "13047", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xF79z2ZfP34GNKHyC", "SRf3P5Lqje4TC4nrX", "BHYBdijDcAKQ6e45Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T20:58:06.904Z", "modifiedAt": null, "url": null, "title": "The Future of Education", "slug": "the-future-of-education", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:59.594Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Michelle_Z", "createdAt": "2011-07-14T22:50:16.205Z", "isAdmin": false, "displayName": "Michelle_Z"}, "userId": "ExbXRgKKWx59L4m4W", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8YFeLHjbwiKT2wZhu/the-future-of-education", "pageUrlRelative": "/posts/8YFeLHjbwiKT2wZhu/the-future-of-education", "linkUrl": "https://www.lesswrong.com/posts/8YFeLHjbwiKT2wZhu/the-future-of-education", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Future%20of%20Education&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Future%20of%20Education%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8YFeLHjbwiKT2wZhu%2Fthe-future-of-education%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Future%20of%20Education%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8YFeLHjbwiKT2wZhu%2Fthe-future-of-education", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8YFeLHjbwiKT2wZhu%2Fthe-future-of-education", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2019, "htmlBody": "<p><span style=\"white-space: pre;\"> </span>This morning I read an interesting post on the future of education. I thought it would be interesting to have some members of LessWrong discuss it. I know it is idealistic, but some of the points raised were interesting.</p>\n<p>&nbsp;</p>\n<blockquote>\n<p><strong>Alex Lindsay</strong></p>\n<p><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">The Future of Education</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Through an anomaly in the space-time continuum, I fell into the future last week. It was an odd sensation &hellip; traveling through time. But at least I made it back. I spent the time I had there at a local school and thought I would share what I saw &hellip;</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Grades are gone.&nbsp;</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Kids aren't in grade 1 or grade 3 &hellip; which was described to me as a \"rudimentary\" way to \"cattle\" students. The admins were gentle about it, explaining to me that when school was paper based, there just wasn't the facility to customize the classroom to the student. They explained that even though it was horribly inefficient, they understood why it needed to exist. They did point out that it ran a decade too long, affecting millions &hellip; but I changed the subject before it got ugly.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Instead, kids in school have individual achievement levels, which are different for every subject. They have 0-1800 points in each subject. Each student works at their own pace through these milestones and moving forward when they get near perfect scores. A student might have 1500 in one subject and 400 in another. Because everything is online and integrated, there aren't really \"grades\" like A, B, C, and D &hellip; kids are just accumulating points.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">When kids max out in a subject, they can spend more time on other subjects; if they are on pace (they are expected to accumulate 100 points a year), they can create independent studies. Many students work very hard to move through the point structure so they can have more free time &hellip; which is structured but still up to them. Added resources are applied to students more than 100 points behind their pace. You end up with 20% of the students passing through the system with very little help beyond the structure, 60% getting some help, and 20% getting a much larger amount of attention to move through the system.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Lectures are gone</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Lectures the way we know them don't really exist. Most of school is divided into 4 processes: Movies, Games, Projects and Discussion. Movies and Games largely exist on the tablets every student has (these look like iPads but they roll up into a baton-like structure). Projects are done with other students &hellip; there are very few opportunities to work on projects alone as it's not seen as an effective character development process in today's job world (where the only people working in a vacuum are doing low-paying work). Discussions are lead by subject experts.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">These \"Subject Experts\" are what used to be called teachers. They are a breed among themselves. They are part brainiac in their field, part Tony Robbins. Their job is to make their subject exciting to learn.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Usually, they begin training for their position very early in life, adding heavy levels of presentation and interpersonal skills to their study load. They work as assistants after reaching 1800 levels in all subjects and focus on a particular subject to master. They train, practice and are allowed to present for basic student events for about decade before they are actually allowed to \"solo\" an educational subject. It's an incredible amount of work but it also pays well -- salaries for these experts average in what is, in today's money, about $300,000 a year, with the top experts making over a $1M a year. This is largely based on their demand globally. Students are essentially given what is the equivalent to a voucher for discussions and are able to choose their lecturers for each seminar they choose to attend.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">There are less of them, as you might guess. Typically about 50,000-100,000 of them at any one time -- much less than the 4M that were working at the peak of the process in the US. While this sounds crazy, we have to remember that most of the objective training is happening interactively within the training tools. There are also over 2,000,000 assistants vying for the Expert positions, providing ongoing support for the students and smaller talks. These assistants are paid, but it's a hard life while they prove themselves.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">The discussions are really global events: students attend from all over the world. Some are in theatres together, some are at home, some are in smaller event locations. Students at these events are of all ages. They attend based on their achievement levels, not their age. So you may have 1000 students from 15 countries, aged from 10 to 18. Questions are posted and voted on by the group to percolate to the top and be discussed by the expert (or experts -- there are often people from given industries participating in these events). The events are productions, usually with intense graphics and TV-level production values.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Movies</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Top content experts are often the designers and hosts for the online training tools that all students use for their ongoing training. These movies provide core knowledge that is part of the interactive guides that students use to move through their subject matter. These movies are Star Wars-level FX films that explain the subject matter. Some of them are period pieces, some are animated adventures. I'm told as Hollywood stumbled and the education system began to build, many producers moved to this content for survival.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Games</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">These movies are closely connected to games that the students play -- while they might be something that looks like a geeky version of \"Civilizations\" or a first person-shooter from the Civil War, or a Physics game that requires students to understand gravity, momentum, etc. The games are not an extra -- they are required and the student scores are connected to their overall achievement scores. These games don't look like the square interactive \"Educational\" games today. In fact, they have nearly replaced the mindless games of today. I'm told as the government started spending billions on game development, EA and others could A) see that there was money to be made and B) could see there wouldn't be much time to play other games &hellip; leading to the new \"development gaming\" movement.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Projects</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Projects are really global affairs. As students reach a required project in a subject (based on their point path), they go online to find others around the world in the same situation. These teams are usually 4-6 people and dig into creating interactive reports that are a mix of video, animation, and text. In addition to deepening subject understanding, the projects are designed to build global relationships and communication. Students are not permitted to do more than 3 projects with the same people in their career. They do rate each other, which builds a bit of a \"global team marketplace.\" Project teams need to have an \"Average\" score &hellip; meaning, high-scoring individuals are encouraged to bring in one or two individuals with lower scores to help them progress. Students are first teamed with \"Assistant\" mentors, then industry mentors and then industry experts (who are partially in it to recruit students out of school, as their companies pay top dollar for the ability to participate in the \"advance\" programs, and finding qualified talent has become an incredibly competitive market).</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Subjects are slightly adjusted.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Languages (most kids learn English, Chinese, French or Spanish, and an elective language which can things like Japanese, Russian, Arabic or Sign Language). Students are required to be fluent in 4 languages by age 16. Most begin at 4 or 5. A large portion of this training looks like \"Rosetta Stone\"&hellip; then students get into more conversational classes (vocabulary drills are all on the tablets). By age 12, many students are simply taking classes in other languages.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Math - Pretty much the same but with an emphasis on problem solving. There are many fewer equations and more integrated problems. Of course, the students are much more advanced as the more interactive teaching processes have been extremely effective in this area.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Literature - An odd thing to call it given I never saw a book or anything that resembled it. Still, students listen to the classics and discuss the philosophical implications.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Sciences - Kids start in Physics almost at day one. They learn about basic engineering principles in the 300 levels (what could be kind of considered 3rd grade, but it's really what was taught in high school before).&nbsp;</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Global Society (what used to be called Civil Studies and History) - Understanding how cultures around the world evolved to their current state. Understanding one's own state is important, but usually only addressed in the global context.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Personal Development - Now considered one of the most important skills in a highly competitive global jobs market, kids are educated from nearly day one on effective person skills. These skills are not moral or religious, just simply good operating behaviour &hellip; and what it takes to be effective.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Creative Arts - From Drawing to Music to Performing Arts &hellip; these skills are seen as intrinsic to creating a \"Creative\" individual that can think their way through the complex issues of the day. In the West, there aren't many \"doing-only\" jobs that haven't shipped overseas or replaced by technology. As a result, being creative has become much more important.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Physical Arts (what used to be PE) - Ah, the days of Kickball are gone. This is a fairly gruelling daily regime that includes nutrition education and customized exercise processes. Martial Arts, Gymnastics and other dexterity building classes are the norm. Over 25% of the student body globally is a Black Belt. This has more to do with training the mind and self-esteem than person protection.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">I asked how this happened in the US &hellip; I was told it didn't. In fact, the US was one of the last countries to adopt the still-controversial system. The stakeholders at the time resisted the change and called it too radical to be even tested. The result has been a steep investment to catch up with other countries and much higher unemployment in the US... as many of the information age jobs left the US over the 15 years they resisted the changes.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">The revolution actually began in the emerging world, specifically in Africa. New fibre running into East and Southern Africa empowered African nations, with too many kids and not enough teachers, to augment their staff with new videos and interactive learning. The students of these early systems not only learned much faster, but become the most facile at building the content (as they were very familiar with it). I was told as much as 60% of all the content in the global infrastructure is created in Sub-Saharan Africa (Rwanda, Zimbabwe, South Africa and Tanzania).</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Anyway, when I arrived back in this time, I wrote this all down as fast as I could to remember it. I hope you find it useful.</span><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><br style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\" /><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Was it really just a dream? I don't know. But if it is was a dream, it was a really good one.</span></p>\n</blockquote>\n<p>&nbsp;</p>\n<p><span style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 18px;\">Thoughts? Comments?</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8YFeLHjbwiKT2wZhu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 0, "extendedScore": null, "score": 7e-06, "legacy": true, "legacyId": "13048", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-14T23:51:32.998Z", "modifiedAt": null, "url": null, "title": "Avoid misinterpreting your emotions", "slug": "avoid-misinterpreting-your-emotions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:39.157Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oiGN8fLCqYyk2xJaT/avoid-misinterpreting-your-emotions", "pageUrlRelative": "/posts/oiGN8fLCqYyk2xJaT/avoid-misinterpreting-your-emotions", "linkUrl": "https://www.lesswrong.com/posts/oiGN8fLCqYyk2xJaT/avoid-misinterpreting-your-emotions", "postedAtFormatted": "Tuesday, February 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Avoid%20misinterpreting%20your%20emotions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAvoid%20misinterpreting%20your%20emotions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoiGN8fLCqYyk2xJaT%2Favoid-misinterpreting-your-emotions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Avoid%20misinterpreting%20your%20emotions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoiGN8fLCqYyk2xJaT%2Favoid-misinterpreting-your-emotions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoiGN8fLCqYyk2xJaT%2Favoid-misinterpreting-your-emotions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2220, "htmlBody": "<p>A couple of weeks ago, I was suffering from insomnia. Eventually my inability to fall asleep turned into frustration, which then led to feelings of self-doubt about my life in general. Soon I was wondering about whether I would ever amount to anything, whether any of my various projects would ever end up bearing fruit, and so forth. As usual, I quickly became convinced that my life prospects were dim, and that I should stop being ambitious and settle for some boring but safe path while I still had the chance.</p>\n<p>Then I realized that there was no reason for me to believe in this, and I stopped thinking that way. I still felt frustrated about not being able to sleep, but I didn't feel miserable about my chances in life. To do otherwise would have been to <em>misinterpret my emotions.</em></p>\n<p>Let me explain what I mean by that. There are two common stereotypes about the role of emotions. The first says that emotions are something irrational, and should be completely disregarded when making decisions. The second says that emotions are basically always right, and one should follow their emotions above all. Psychological research on emotions suggests that the correct answer lies in between: we have emotions for a reason, and we should follow their advice, but not unthinkingly.</p>\n<p>The <em>Information Principle</em> says that <em>emotional feelings provide conscious information from unconscious appraisals of situations</em><sup>1</sup>. Your brain is <em>constantly</em> appraising the situation you happen to be in. It notes things like a passerby having slightly threatening body language, or conversation with some person being easy and free of misunderstandings. There are countless of such evaluations going on all the time, and you aren't consciously aware of them because you don't need to. Your subconscious mind can handle them just fine on its own. The end result of all those evaluations is packaged into a brief summary, which is the only thing that your conscious mind sees directly. That \"executive summary\" is what you experience as a particular emotional state. The passerby makes you feel slightly nervous and you avoid her, or your conversational partner feels pleasant to talk with and you begin to like him, even though you don't know why.</p>\n<p>To some extent, then, your emotions will guide you to act appropriately in various situations, even when you don't know why you feel the way you do. However, it's important to intepret them correctly. Maybe you meet a new person on a good day and feel good when talking with them. Do you feel good because the person is pleasant to be with, or because the weather is pleasant? In general, emotions are only used as a source of information when their informational value is not called into question<sup>2</sup>. If you know that you are sad because of something that happened in the morning, and still feel sad when talking to your friend later on, you don't assume that something about your friend is making you feel sad.</p>\n<p>People also pay more attention to their feelings when they think them relevant for the question at hand. For example, moods have a larger impact when people are making decisions for themselves rather than others, who may experience things differently. But by default, people tend to assume that their feelings and emotions are \"about\" whatever it is that they're thinking about at that moment. If they're not given a reason to presume that their emotions are caused by something else than the issue at hand, they don't.<sup>2</sup></p>\n<p><a id=\"more\"></a>So here was my mistake. I had been feeling frustrated about my inability to sleep, and my thoughts had wandered to other subjects, such as my life in general. And then I had automatically assumed that because I was feeling frustrated while thinking about my life, my life wasn't going well, so I should reconsider my plans.</p>\n<p>In addition to providing information, moods also affect the <em>way</em> we think: research suggests that sad moods make us more analytical. Or as Schwarz<sup>2</sup> summarizes:</p>\n<blockquote>\n<p>When things go smoothly and we face no hurdles in the pursuit of our goals, we are likely to rely on our pre-existing knowledge structures and routines, which served us well in the past. Moreover, we may be willing to take some risk in exploring novel solutions. Once things go wrong, we abandon reliance on our usual routines and focus on the specifics at hand to determine what went wrong and what can be done about it.</p>\n</blockquote>\n<p>So again: I had been trying to sleep, but failed to do so. My failure at the task triggered feelings of frustration. Frustration is a sign that our current approach isn't working, and we should re-evaluate it. In my situation, the right course of action would probably have been to re-evaluate whether I would be getting any sleep at that moment, and spend some time awake until I'd feel more tired again. But I stayed in bed, so my feelings of frustration persisted, and the impulse to re-evaluate things remained. And when my thoughts wandered to other subjects, it was those subjects that my mind started taking apart to find what was wrong with them. The fact that there <em>wasn't</em> actually anything wrong with them didn't matter. Some part of my mind presumed, quite reasonably, that if I was feeling frustrated then there <em>had</em> to be something wrong with what I was doing, so if I thought otherwise I had to be mistaken. And this line of reasoning would have been correct, had it not been applied to the wrong problem.</p>\n<p>I am slowly learning when I should be taking my negative moods into account, and when I shouldn't. I've noticed that on days when I haven't had enough sleep, I also feel skeptical about what I'm doing with my life. When I'm more rested and in a neutral mood, those doubts seem overblown. So I try to discount such doubts when they seem to be caused by mere physical fatigue. On the other hand, some negative feelings are such that I've generally come to regret overriding them. Sometimes I've gotten a bad vibe about a person, and when I've decided to trust them anyway, I've afterwards realized that I shouldn't have.</p>\n<p>Positive emotions, too, can be correct or mistaken. I have a tendency to get quite excited about new projects, and be much more certain of their value than I should be. At such times, I try to make sure that I'm not rushing ahead with the project and making commitments that I shouldn't.</p>\n<p>Thinking in such a way is an example of <a href=\"http://www.overcomingbias.com/2007/07/beware-the-insi.html\">taking the outside view</a>. When someone takes the inside view to a problem, such as the task of predicting how long something will take, they <em>focus on the case at hand, consider the plan and the obstacles to its completion, construct scenarios of future progress, and extrapolate current trends</em><sup>3</sup>. On the other hand, the outside view essentially ignores the details of the case at hand, and <em>involves no attempt at detailed forecasting of the future history of the project. Instead, it focuses on the statistics of a class of cases chosen to be similar in relevant respects to the present one</em><sup>3</sup>. For instance, when considering how long it will take you to write an essay, the inside view might respond by looking at how well you've done so far, and how long it would take if you kept up the pace. The outside view would simply look at previous occasions when you've had to write an essay, and ask how long it took on those occasions. If on several previous occasions you've thought that you'll get the essay written in no time, but then always finished just before the deadline, then it's most likely that you'll again finish right before the deadline.<br /><br />It's generally beneficial to take the outside view on your emotions as well. In a strongly emotional state, you cannot rely merely on the inside view, because a large part of your reasoning process is working on the basis of assumptions which may not be correct. Instead, you should ask questions like: On previous occasions when you've been in a similar situation and felt similarly, has the advice from your emotions been reasonable? What's their historical accuracy in these circumstances? Is your emotional state being influenced by something that has nothing to do with the issue at hand? If you were a neutral observer looking at the situation from the outside, would you think that the emotional judgement was a reasonable one, or that you were just being silly?</p>\n<p>For a long time, I thought that if I was feeling miserable and it was making me think negative thoughts, I only had two options. <strong>A</strong>, I could get rid of the negative thoughts by distracting myself or finding something that would cheer me up and get me out of that mood. Or <strong>B</strong>, I would fail to get out of the mood, and thus keep thinking negative thoughts. For whatever reason, I never realized that I also had option <strong>C</strong>: keep feeling miserable, but stop thinking negative thoughts. Depending on exactly how strong your emotion is, you might not always be capable of getting rid of the thoughts, but at least you can realize that they're not true.</p>\n<p>So that's what I did. I thought, \"I'm feeling miserable because I can't sleep and I'm frustrated, but that has nothing to do with whether my projects and ambitions will be successful or not. My current emotions convey no information about that topic. So it's pointless to doubt myself because of these emotions.\" (Not in so many words, but that was the general idea.) So I stopped thinking those thoughts. And while I still felt generally miserable, the thoughts stopped making me feel even worse.</p>\n<p>Possibly the most vivid example of taking the outside view that I've seen comes <a href=\"http://theferrett.livejournal.com/1694234.html\">from Ferrett Steinmetz</a>:</p>\n<blockquote>\n<p>I was suicidally down yesterday for no reason except brain chemistry, waking up with the belief that everyone I knew would be much better off if I killed myself.&nbsp; And I did my usual ration-checks to see if what depression was saying was correct &ndash; because, like bullies, occasionally the cruel will tell you what the kind will not.&nbsp; So I looked at the evidence.</p>\n<p>What the evidence told me was that as a polyamorous man, I had several women who loved me deeply, women who had the choice of other partners and yet still cared about me enough to send me texts and emails, and this should be evidence that I was not a worthless human being.&nbsp; At which point my depression started in on me: <em>See?&nbsp; All these women who love you, and you just write them off.&nbsp; That&rsquo;s how selfish you are, ignoring the adoration of these women.&nbsp; You&rsquo;re such a self-centered asshole, you should kill yourself.</em></p>\n<p>Fortunately, I knew my old adversary well enough to understand where it was leading me.&nbsp; I stepped away from the self-destructive sequence my depression was trying to guide me down, recognizing that when I&rsquo;m in this mood every path goes straight to off-yourself-ville, and understood that the facts would have to be enough.</p>\n<p>Depression is a bully in that it&rsquo;s fundamentally out to destroy you.&nbsp; You can&rsquo;t quite get away from him, like any good bully; the best you can do is come to an understanding that this is unpleasant, but it&rsquo;s nothing you should take too personally.&nbsp; And hope, one day, that you&rsquo;ll become strong enough to walk away.</p>\n</blockquote>\n<p>Major depression is the extreme case. If your depression is serious enough, your brain is broken. The mechanisms which would usually kick in when you were doing something wrong will be engaged even when you're doing <em>nothing</em> wrong, and they will be in overdrive, taking apart <em>everything</em> in your life in order to find ways by which you are screwing up.</p>\n<p>But you don't have to believe them. You can realize that the thoughts that pop up in your mind aren't based on reality, and that you don't have to act on the basis of them. It won't stop you from feeling miserable, but it might stop you from feeling even <em>worse.</em></p>\n<p><em>Edited to add: </em>Of course, it's also possible to use this view for self-deception. Maybe we're deceiving ourselves about how our lives are going, and that self-deception will persist if we try to examine it while in a neutral emotional state. Perhaps it is only when we fail badly enough to get a strong negative emotion that the barriers of self-deception break, and we will be mistaken to dismiss our thoughts in those states because they don't seem reasonable in other emotional states. When you use this technique, be careful to make sure that you are actually <a href=\"/lw/jz/the_meditation_on_curiosity/\">genuinely curious</a> about what your emotions are telling you. Don't <em>just</em> come up with excuses for ignoring them, ask whether you should ignore them <em>or </em>listen to them.</p>\n<p>&nbsp;</p>\n<p><strong>References</strong></p>\n<p><sup>1</sup>: Clore, G.L. &amp; Gasper, K., &amp; Garvin, E. (2001). Affect as information. In J.P. Forgas (Ed.), <em>Handbook of affect and social cognition</em> (pp. 121&ndash;144). Mahwah, NJ: Erlbaum.</p>\n<p><sup>2</sup>: Schwarz, N. (2010) <a href=\"http://people.ict.usc.edu/~gratch/CSCI534/schwarz_feelings-as-information_7jan10.pdf\">Feelings as information</a>. In Van Lange, P. &amp; Kruglanski, A. &amp; Higgins, E.T. (Eds.), <em>Handbook of theories of social psychology</em>, Sange.</p>\n<p><sup>3</sup>: Kahneman, D. &amp; Lovallo, D. (1993) <a href=\"http://courses.washington.edu/pbafhall/514/514%20Readings/TimidChoicesAndBoldForecasts.pdf\">Timid Choices and Bold Forecasts: A Cognitive Perspective on Risk Taking</a>. Management Science, vol. 39, no. 1.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3ee9k6NJfcGzL6kMS": 3, "Ng8Gice9KNkncxqcj": 2, "rWzGNdjuep56W5u2d": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oiGN8fLCqYyk2xJaT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 78, "baseScore": 91, "extendedScore": null, "score": 0.00017, "legacy": true, "legacyId": "12924", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 72, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3nZMgRTfFEfHp34Gb"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T04:57:39.960Z", "modifiedAt": null, "url": null, "title": "Hard philosophy problems to test people's intelligence?", "slug": "hard-philosophy-problems-to-test-people-s-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.143Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Solvent", "createdAt": "2011-07-19T07:12:44.132Z", "isAdmin": false, "displayName": "Solvent"}, "userId": "a3sBsZXtAQacMDHfK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yRiTKLJsmK8zKXHYN/hard-philosophy-problems-to-test-people-s-intelligence", "pageUrlRelative": "/posts/yRiTKLJsmK8zKXHYN/hard-philosophy-problems-to-test-people-s-intelligence", "linkUrl": "https://www.lesswrong.com/posts/yRiTKLJsmK8zKXHYN/hard-philosophy-problems-to-test-people-s-intelligence", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hard%20philosophy%20problems%20to%20test%20people's%20intelligence%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHard%20philosophy%20problems%20to%20test%20people's%20intelligence%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRiTKLJsmK8zKXHYN%2Fhard-philosophy-problems-to-test-people-s-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hard%20philosophy%20problems%20to%20test%20people's%20intelligence%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRiTKLJsmK8zKXHYN%2Fhard-philosophy-problems-to-test-people-s-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRiTKLJsmK8zKXHYN%2Fhard-philosophy-problems-to-test-people-s-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>I'm looking for hard philosophical questions to give to people to gauge their skill at philosophy.</p>\n<p>So far, I've been presenting people with Newcomb's problem and the Sleeping Beauty problem. I've also been presenting them with contrarian opinions and asking them to evaluate them, and I have a higher opinion of them if they avoid just icking away from the subject.</p>\n<p>What other problems should I use?&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yRiTKLJsmK8zKXHYN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -3, "extendedScore": null, "score": -6e-06, "legacy": true, "legacyId": "13065", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T05:09:40.712Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Conditional Independence, and Naive Bayes", "slug": "seq-rerun-conditional-independence-and-naive-bayes", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hurYFWPaEXxHGzjzY/seq-rerun-conditional-independence-and-naive-bayes", "pageUrlRelative": "/posts/hurYFWPaEXxHGzjzY/seq-rerun-conditional-independence-and-naive-bayes", "linkUrl": "https://www.lesswrong.com/posts/hurYFWPaEXxHGzjzY/seq-rerun-conditional-independence-and-naive-bayes", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Conditional%20Independence%2C%20and%20Naive%20Bayes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Conditional%20Independence%2C%20and%20Naive%20Bayes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhurYFWPaEXxHGzjzY%2Fseq-rerun-conditional-independence-and-naive-bayes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Conditional%20Independence%2C%20and%20Naive%20Bayes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhurYFWPaEXxHGzjzY%2Fseq-rerun-conditional-independence-and-naive-bayes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhurYFWPaEXxHGzjzY%2Fseq-rerun-conditional-independence-and-naive-bayes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 173, "htmlBody": "<p>Today's post, <a href=\"/lw/o8/conditional_independence_and_naive_bayes/\">Conditional Independence, and Naive Bayes</a> was originally published on 01 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You use categorization to make inferences about properties that don't have the appropriate empirical structure, namely, conditional independence given knowledge of the class, to be well-approximated by Naive Bayes.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a20/seq_rerun_searching_for_bayesstructure/\">Searching for Bayes-Structure</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hurYFWPaEXxHGzjzY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.491512798851832e-07, "legacy": true, "legacyId": "13066", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gDWvLicHhcMfGmwaK", "CnDbgN6b3R9LRWx3c", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T06:00:06.833Z", "modifiedAt": null, "url": null, "title": "Open Thread, February 15-29, 2012", "slug": "open-thread-february-15-29-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:05.177Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EECyQFcKMbSfJfhBb/open-thread-february-15-29-2012", "pageUrlRelative": "/posts/EECyQFcKMbSfJfhBb/open-thread-february-15-29-2012", "linkUrl": "https://www.lesswrong.com/posts/EECyQFcKMbSfJfhBb/open-thread-february-15-29-2012", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20February%2015-29%2C%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20February%2015-29%2C%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEECyQFcKMbSfJfhBb%2Fopen-thread-february-15-29-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20February%2015-29%2C%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEECyQFcKMbSfJfhBb%2Fopen-thread-february-15-29-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEECyQFcKMbSfJfhBb%2Fopen-thread-february-15-29-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EECyQFcKMbSfJfhBb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 8.491711184051381e-07, "legacy": true, "legacyId": "13068", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 196, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T08:48:28.367Z", "modifiedAt": null, "url": null, "title": "Anyone want a LW Enhancement Suite?", "slug": "anyone-want-a-lw-enhancement-suite", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:00.860Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oTef8ZoRNL7xbDnSF/anyone-want-a-lw-enhancement-suite", "pageUrlRelative": "/posts/oTef8ZoRNL7xbDnSF/anyone-want-a-lw-enhancement-suite", "linkUrl": "https://www.lesswrong.com/posts/oTef8ZoRNL7xbDnSF/anyone-want-a-lw-enhancement-suite", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20want%20a%20LW%20Enhancement%20Suite%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20want%20a%20LW%20Enhancement%20Suite%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoTef8ZoRNL7xbDnSF%2Fanyone-want-a-lw-enhancement-suite%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20want%20a%20LW%20Enhancement%20Suite%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoTef8ZoRNL7xbDnSF%2Fanyone-want-a-lw-enhancement-suite", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoTef8ZoRNL7xbDnSF%2Fanyone-want-a-lw-enhancement-suite", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p><a href=\"http://redditenhancementsuite.com/\">Reddit Enhancement Suite</a></p>\n<p>If anyone cares, I could <em>probably</em>&nbsp;port this to work on LW without too much trouble. Optimistically it'd just involve opening up the source and replacing <em>reddit.com</em>&nbsp;with <em>lesswrong.com. </em>More realistically, there'd probably be a lot of baked-in assumptions about DOM structure that'd need to be updated to have the UI enhancements make sense.</p>\n<p>Anyway, this is mostly just a straw poll to see how many others would be interested in such a thing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oTef8ZoRNL7xbDnSF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 21, "extendedScore": null, "score": 8.49237347552158e-07, "legacy": true, "legacyId": "13076", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T14:02:01.356Z", "modifiedAt": null, "url": null, "title": "How to measure procrastination?", "slug": "how-to-measure-procrastination", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:23.754Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rlp10", "createdAt": "2012-01-27T15:14:36.027Z", "isAdmin": false, "displayName": "rlp10"}, "userId": "wrpGdWaf8RqAtCytp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2paDYmMvGrWz4oQcs/how-to-measure-procrastination", "pageUrlRelative": "/posts/2paDYmMvGrWz4oQcs/how-to-measure-procrastination", "linkUrl": "https://www.lesswrong.com/posts/2paDYmMvGrWz4oQcs/how-to-measure-procrastination", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20measure%20procrastination%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20measure%20procrastination%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2paDYmMvGrWz4oQcs%2Fhow-to-measure-procrastination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20measure%20procrastination%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2paDYmMvGrWz4oQcs%2Fhow-to-measure-procrastination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2paDYmMvGrWz4oQcs%2Fhow-to-measure-procrastination", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 42, "htmlBody": "<p>I want to test different techniques for decreasing personal procrastination.&nbsp; What would be an easy way to measure procrastination so that I can do the comparison?</p>\n<p>I would also like to hear suggestions for measuring the inverse i.e. how can I measure getting-things-done-ness.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2paDYmMvGrWz4oQcs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 8.493607165097099e-07, "legacy": true, "legacyId": "13078", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T15:30:19.429Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "slug": "meetup-fort-collins-colorado-meetup-wedneday-7pm-3", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Njk5sEDRc5qkKzWYC/meetup-fort-collins-colorado-meetup-wedneday-7pm-3", "pageUrlRelative": "/posts/Njk5sEDRc5qkKzWYC/meetup-fort-collins-colorado-meetup-wedneday-7pm-3", "linkUrl": "https://www.lesswrong.com/posts/Njk5sEDRc5qkKzWYC/meetup-fort-collins-colorado-meetup-wedneday-7pm-3", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNjk5sEDRc5qkKzWYC%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNjk5sEDRc5qkKzWYC%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNjk5sEDRc5qkKzWYC%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/77'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 February 2012 07:00:00AM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Come hang out with interesting people, drink tea, and maybe go for dinner.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/77'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Njk5sEDRc5qkKzWYC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.493954651178886e-07, "legacy": true, "legacyId": "13079", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm\">Discussion article for the meetup : <a href=\"/meetups/77\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 February 2012 07:00:00AM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Come hang out with interesting people, drink tea, and maybe go for dinner.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/77\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T17:01:22.744Z", "modifiedAt": null, "url": null, "title": "Pooling resources for valuable actuarial calculations", "slug": "pooling-resources-for-valuable-actuarial-calculations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:33.322Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/69ufvKmkCB2k9zS2P/pooling-resources-for-valuable-actuarial-calculations", "pageUrlRelative": "/posts/69ufvKmkCB2k9zS2P/pooling-resources-for-valuable-actuarial-calculations", "linkUrl": "https://www.lesswrong.com/posts/69ufvKmkCB2k9zS2P/pooling-resources-for-valuable-actuarial-calculations", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pooling%20resources%20for%20valuable%20actuarial%20calculations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APooling%20resources%20for%20valuable%20actuarial%20calculations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F69ufvKmkCB2k9zS2P%2Fpooling-resources-for-valuable-actuarial-calculations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pooling%20resources%20for%20valuable%20actuarial%20calculations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F69ufvKmkCB2k9zS2P%2Fpooling-resources-for-valuable-actuarial-calculations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F69ufvKmkCB2k9zS2P%2Fpooling-resources-for-valuable-actuarial-calculations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 228, "htmlBody": "<p>It occurred to me this morning that, if it's actually valuable, <em>generating true beliefs about the world</em>&nbsp;must be someone's comparative advantage. If truth is instrumentally important, important people must be finding ways to pay to access it<span style=\"-webkit-tap-highlight-color: rgba(26, 26, 26, 0.296875); -webkit-composition-fill-color: rgba(175, 192, 227, 0.230469); -webkit-composition-frame-color: rgba(77, 128, 180, 0.230469);\">. I can think of several examples of this, but the one that caught my attention was <strong>actuarial science</strong>.</span></p>\n<p><span style=\"-webkit-tap-highlight-color: rgba(26, 26, 26, 0.296875); -webkit-composition-fill-color: rgba(175, 192, 227, 0.230469); -webkit-composition-frame-color: rgba(77, 128, 180, 0.230469);\">I know next to nothing about what actuaries actually do, but Wikipedia says:</span></p>\n<blockquote>\n<p>\"Actuaries mathematically evaluate the likelihood of events and quantify the contingent outcomes in order to minimize losses, both emotional and financial, associated with uncertain undesirable events.\"</p>\n</blockquote>\n<p>Why, that sounds right up our alley.&nbsp;</p>\n<p>So what I'm wondering is: for those who can afford it, wouldn't it be worth contracting with actuaries to make important personal decisions? Not merely with regards to business, but everything else as well? My preliminary ideas include:</p>\n<p>\n<ul>\n<li>Lifestyle choices to reduce personal risk of death</li>\n<li>Health and wellness decisions</li>\n<li>Vehicle choice for economic and safety considerations</li>\n<li>Where to send your kid to college and otherwise improve life success</li>\n</ul>\n<div>Lastly, if consulting actuaries is worth doing as a wealthy individual, shouldn't it also be worth doing as a group? Couldn't we pool money to get excellent information about questions that haven't yielded answers to our research attempts?</div>\n<div>If I am not misunderstanding the work that actuaries do, there may indeed be low-hanging fruit here.&nbsp;</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "69ufvKmkCB2k9zS2P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 21, "extendedScore": null, "score": 8.494313001375955e-07, "legacy": true, "legacyId": "13080", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-15T17:28:04.683Z", "modifiedAt": null, "url": null, "title": "Meetup : Austin, TX TCDS Experiment", "slug": "meetup-austin-tx-tcds-experiment", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:06.774Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dKrk5Kp6E9WuK4vAA/meetup-austin-tx-tcds-experiment", "pageUrlRelative": "/posts/dKrk5Kp6E9WuK4vAA/meetup-austin-tx-tcds-experiment", "linkUrl": "https://www.lesswrong.com/posts/dKrk5Kp6E9WuK4vAA/meetup-austin-tx-tcds-experiment", "postedAtFormatted": "Wednesday, February 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Austin%2C%20TX%20TCDS%20Experiment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Austin%2C%20TX%20TCDS%20Experiment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdKrk5Kp6E9WuK4vAA%2Fmeetup-austin-tx-tcds-experiment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Austin%2C%20TX%20TCDS%20Experiment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdKrk5Kp6E9WuK4vAA%2Fmeetup-austin-tx-tcds-experiment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdKrk5Kp6E9WuK4vAA%2Fmeetup-austin-tx-tcds-experiment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/78'>Austin, TX TCDS Experiment</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 February 2012 01:30:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">21st & Speedway, Austin TX</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Austin, TX meetup is in a new location for just this week; we'll be meeting in <a href=\"http://www.utexas.edu/maps/main/buildings/cba.html\" rel=\"nofollow\">CBA 4.342</a> on Saturday the 18th at 1:30 PM. We're going to be trying out <a href=\"http://en.wikipedia.org/wiki/Transcranial_direct_current_stimulation\" rel=\"nofollow\">transcranial direct current stimulation</a>. Please bring a laptop (or some device that can implement <a href=\"http://brainworkshop.sourceforge.net/\" rel=\"nofollow\">dual n-back</a>) and headphones; I'll have the electrodes, batteries, and other assorted materials. If you could do a session or two of dual n-back before showing up, that'd be great, but isn't necessary.</p>\n\n<p>(Parking: You can either park wherever you parked for Caffe Medici and walk ~three blocks to the east, or you can part in the Brazos street garage (at Brazos and MLK) and walk west then north to CBA.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/78'>Austin, TX TCDS Experiment</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dKrk5Kp6E9WuK4vAA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "13081", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Austin__TX_TCDS_Experiment\">Discussion article for the meetup : <a href=\"/meetups/78\">Austin, TX TCDS Experiment</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 February 2012 01:30:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">21st &amp; Speedway, Austin TX</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Austin, TX meetup is in a new location for just this week; we'll be meeting in <a href=\"http://www.utexas.edu/maps/main/buildings/cba.html\" rel=\"nofollow\">CBA 4.342</a> on Saturday the 18th at 1:30 PM. We're going to be trying out <a href=\"http://en.wikipedia.org/wiki/Transcranial_direct_current_stimulation\" rel=\"nofollow\">transcranial direct current stimulation</a>. Please bring a laptop (or some device that can implement <a href=\"http://brainworkshop.sourceforge.net/\" rel=\"nofollow\">dual n-back</a>) and headphones; I'll have the electrodes, batteries, and other assorted materials. If you could do a session or two of dual n-back before showing up, that'd be great, but isn't necessary.</p>\n\n<p>(Parking: You can either park wherever you parked for Caffe Medici and walk ~three blocks to the east, or you can part in the Brazos street garage (at Brazos and MLK) and walk west then north to CBA.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Austin__TX_TCDS_Experiment1\">Discussion article for the meetup : <a href=\"/meetups/78\">Austin, TX TCDS Experiment</a></h2>", "sections": [{"title": "Discussion article for the meetup : Austin, TX TCDS Experiment", "anchor": "Discussion_article_for_the_meetup___Austin__TX_TCDS_Experiment", "level": 1}, {"title": "Discussion article for the meetup : Austin, TX TCDS Experiment", "anchor": "Discussion_article_for_the_meetup___Austin__TX_TCDS_Experiment1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T01:51:26.001Z", "modifiedAt": null, "url": null, "title": "What is the advantage of the Kolmogorov complexity prior?", "slug": "what-is-the-advantage-of-the-kolmogorov-complexity-prior", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.023Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "skepsci", "createdAt": "2012-02-13T07:41:59.219Z", "isAdmin": false, "displayName": "skepsci"}, "userId": "4nJBmuW2yZvqc8MMR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uhKnChcpzK4B47DZp/what-is-the-advantage-of-the-kolmogorov-complexity-prior", "pageUrlRelative": "/posts/uhKnChcpzK4B47DZp/what-is-the-advantage-of-the-kolmogorov-complexity-prior", "linkUrl": "https://www.lesswrong.com/posts/uhKnChcpzK4B47DZp/what-is-the-advantage-of-the-kolmogorov-complexity-prior", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20is%20the%20advantage%20of%20the%20Kolmogorov%20complexity%20prior%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20is%20the%20advantage%20of%20the%20Kolmogorov%20complexity%20prior%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuhKnChcpzK4B47DZp%2Fwhat-is-the-advantage-of-the-kolmogorov-complexity-prior%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20is%20the%20advantage%20of%20the%20Kolmogorov%20complexity%20prior%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuhKnChcpzK4B47DZp%2Fwhat-is-the-advantage-of-the-kolmogorov-complexity-prior", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuhKnChcpzK4B47DZp%2Fwhat-is-the-advantage-of-the-kolmogorov-complexity-prior", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 650, "htmlBody": "<p>As I understand it, Solomonoff induction works by the a procedure loosely stated as saying we start with a Kolmogorov complexity universal prior (formalized Occam's razor), then update using Bayesian inference any time we see new data.</p>\n<p>&nbsp;</p>\n<p>More precisely, suppose the universe is a computable sequence X of 0s and 1s. We want to predict the nth term before it happens, using the first n-1 terms.</p>\n<p>To do this, we use the following 'algorithm':</p>\n<ol>\n<li>List all computable sequences in increasing order of the complexity of the algorithm used to generate them to get a list A<sub>1</sub>, A<sub>2</sub>, A<sub>3</sub>, ...</li>\n<li>We start with the prior P(A<sub>k</sub>)=1/2<sup>k</sup>.</li>\n<li>With this prior, we predict to see a string b of observations with probability P(b)=&sum;<sub>k</sub>&nbsp;P(A<sub>k</sub>)[b&lt;A<sub>k</sub>], where [b&lt;A<sub>k</sub>]=1 if A<sub>k</sub>&nbsp;starts with the string b, and&nbsp;[b&lt;A<sub>k</sub>]=0 otherwise.</li>\n<li>After we see a string b of observations, we update our beliefs using Bayes theorem:&nbsp;P(A<sub>k</sub>|b) = P(b|A<sub>k</sub>)P(A<sub>k</sub>)/P(b) = [b&lt;A<sub>k</sub>]P(A<sub>k</sub>)/P(b), and similarly&nbsp;P(bc|b) = P(b|bc)P(bc)/P(b) = P(bc)/P(b).</li>\n</ol>\n<p><em>I'm putting the word 'algorithm' in quotes, because there is no list of all computable sequences where [b&lt;A<sub>k</sub>]&nbsp;is a computable function of k and b, let alone one where the sequences are listed in increasing Kolmogorov complexity. You can think of it as an algorithm relative to an oracle that computes such a function.</em></p>\n<p>&nbsp;</p>\n<p>If we follow this 'algorithm', we get a nice theorem:</p>\n<p>For all&nbsp;&epsilon;&gt;0&nbsp;there is some N such that if b is an initial segment of X of length at least N, then P(bc|b)&gt;1-&epsilon; if bc is an initial segment of X, and&nbsp;P(bc|b)&lt;&epsilon;, otherwise.</p>\n<p>So in the limit, we can correctly extrapolate from what we've seen with high confidence.</p>\n<hr />\n<p>Proof: Let K = {k : X=A<sub>k</sub>}.&nbsp;&nbsp;Let p<sub>0</sub>&nbsp;=&nbsp;&sum;<sub>k in&nbsp;K</sub>&nbsp;1/2<sup>k</sup>. Let M &ge; -log(&epsilon;p<sub>0</sub>). Let b be a sufficiently long initial segment of X such that b is not an initial segment of any A<sub>m</sub>, where m&le;M and m is not in K. Then if bc is an initial segment of X,</p>\n<p style=\"padding-left: 30px;\">P(bc)&nbsp;= &sum;<sub>k</sub>&nbsp;1/2<sup>k</sup>[bc&lt;A<sub>k</sub>] &ge; p<sub>0</sub>,</p>\n<p>but on the other hand</p>\n<p style=\"padding-left: 30px;\">P(b)&nbsp;= &sum;<sub>k</sub>&nbsp;1/2<sup>k</sup>[b&lt;A<sub>k</sub>] &le; p<sub>0</sub>&nbsp;+&nbsp;&sum;<sub>k&gt;M</sub>&nbsp;1/2<sup>k</sup> = p<sub>0</sub> + 2<sup>-M</sup>&nbsp;&le; (1+&epsilon;)p<sub>0.</sub></p>\n<p>Therefore,</p>\n<p style=\"padding-left: 30px;\">P(bc|b)=P(bc)/P(b) &ge;&nbsp;p<sub>0</sub>/(1+&epsilon;)p<sub>0</sub> = 1/(1+&epsilon;) &gt; 1-&epsilon;.</p>\n<hr />\n<p>&nbsp;</p>\n<p>What if the universe isn't actually computable? Maybe there is some true randomness in the universe, as quantum-mechanics suggests? If you assume the universe is plucked at random from some computable probability distribution on the set of all binary sequences, you get almost the same result. By repeating the same procedure as above, but instead of listing all computable sequences, you list all computable probability distributions on the set of binary sequences and do a similar sort of Bayesian inference, you again get a theorem telling you that as you make observations, your distribution (conditioned on what you've seen so far) converges to the true distribution (conditioned on what you've seen so far).</p>\n<p>&nbsp;</p>\n<p>This is all well and good. But in the end, what does it have to do with Kolmogorov complexity? The exact prior distribution we started with and the order of the list of all computable sequences was not used in any essential way in the proof. What's the advantage of Occam's razor? After all, we could skip steps 1 and 2 completely, start with an arbitrary list of all computable sequences, and an arbitrary prior supported on the set of computable sequences, and we would end up with the <em>exact same theorem</em>. (For the random universe version, we need to start with a prior that is a convex combination of every computable probability distribution, but again, we don't need Kolmogorov complexity at all.)</p>\n<p>&nbsp;</p>\n<p>Is there a stronger theorem that we get when we use the Kolmogorov complexity prior that we don't get otherwise? Why are people making a big deal about the relationship between Solomonoff induction and Occam's razor, if the part of Solomonoff induction that corresponds to Occam's razor is not necessary for Solomonoff induction to work? Occam's razor seems to work well in practice, but I don't see how it's in any way necessary (or even useful!) for the math.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bTeiZr6YAEaSPQTC8": 2, "5f5c37ee1b5cdee568cfb25c": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uhKnChcpzK4B47DZp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "13091", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T03:40:59.015Z", "modifiedAt": null, "url": null, "title": "This is a test", "slug": "this-is-a-test-1", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/akX37GvucQvSyZaMR/this-is-a-test-1", "pageUrlRelative": "/posts/akX37GvucQvSyZaMR/this-is-a-test-1", "linkUrl": "https://www.lesswrong.com/posts/akX37GvucQvSyZaMR/this-is-a-test-1", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20This%20is%20a%20test&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThis%20is%20a%20test%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FakX37GvucQvSyZaMR%2Fthis-is-a-test-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=This%20is%20a%20test%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FakX37GvucQvSyZaMR%2Fthis-is-a-test-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FakX37GvucQvSyZaMR%2Fthis-is-a-test-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 18, "htmlBody": "<p>I have been unable to post topic posts to discussion. I'm testing if this is still the case.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "akX37GvucQvSyZaMR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "13102", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T03:49:08.772Z", "modifiedAt": null, "url": null, "title": "Troubles With CEV Part1 - CEV Sequence", "slug": "troubles-with-cev-part1-cev-sequence-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7C8YxEFK2SNbWTegt/troubles-with-cev-part1-cev-sequence-0", "pageUrlRelative": "/posts/7C8YxEFK2SNbWTegt/troubles-with-cev-part1-cev-sequence-0", "linkUrl": "https://www.lesswrong.com/posts/7C8YxEFK2SNbWTegt/troubles-with-cev-part1-cev-sequence-0", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Troubles%20With%20CEV%20Part1%20-%20CEV%20Sequence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATroubles%20With%20CEV%20Part1%20-%20CEV%20Sequence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7C8YxEFK2SNbWTegt%2Ftroubles-with-cev-part1-cev-sequence-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Troubles%20With%20CEV%20Part1%20-%20CEV%20Sequence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7C8YxEFK2SNbWTegt%2Ftroubles-with-cev-part1-cev-sequence-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7C8YxEFK2SNbWTegt%2Ftroubles-with-cev-part1-cev-sequence-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 265, "htmlBody": "<p>&lt;!-- \t\t@page { margin: 2cm } \t\tP { margin-bottom: 0.21cm } \t\tA:link { so-language: zxx } \t--&gt;</p>\n<p class=\"western\" style=\"line-height: 150%;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>The</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>CEV</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Sequence</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Summary:</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">The</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">sequence</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">consists</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">three</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">posts</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">tackling</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">important</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">aspects</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">It</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">covers</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">conceptual,</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">practical</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">and</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">computational</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">problems</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV's</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">current</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">form.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>On</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>What</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Selves</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Are</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">draws</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">on</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">analytic</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">philosophy</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">methods</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">in</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">order</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">clarify</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">concept</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Self,</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">which</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">necessary</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">in</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">order</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">understand</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">whose</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">volition</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">going</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">be</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">extrapolated</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">by</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">machine</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">that</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">implements</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">procedure.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Troubles</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>with</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>CEV</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>part1</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">and</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Troubles</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>with</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>CEV</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>part2</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">on</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">other</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">hand</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">describe</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">several</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">issues</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">that</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">will</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">be</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">faced</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">by</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">project</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">if</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">it</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">actually</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">going</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">be</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">implemented.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Those</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">issues</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">are</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">not</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">conceptual</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">nature.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Many</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">objections</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">shown</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">come</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">from</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">scattered</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">discussions</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">found</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">on</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">web.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Finally,</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">six</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">alternatives</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">are</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">considered.</span></span></span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NDjABjx6DRfSKcqED": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7C8YxEFK2SNbWTegt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "13103", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T03:49:56.863Z", "modifiedAt": null, "url": null, "title": "test3", "slug": "test3-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YtvHurPQv5Yr5dKDc/test3-0", "pageUrlRelative": "/posts/YtvHurPQv5Yr5dKDc/test3-0", "linkUrl": "https://www.lesswrong.com/posts/YtvHurPQv5Yr5dKDc/test3-0", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20test3&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Atest3%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYtvHurPQv5Yr5dKDc%2Ftest3-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=test3%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYtvHurPQv5Yr5dKDc%2Ftest3-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYtvHurPQv5Yr5dKDc%2Ftest3-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1002, "htmlBody": "<p>&lt;!-- \t\t@page { margin: 2cm } \t\tP { margin-bottom: 0.21cm } \t--&gt;</p>\n<p class=\"western\" style=\"line-height: 150%;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>The</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>CEV</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Sequence</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Summary:</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong> </strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">The</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">sequence</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">consists</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">three</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">posts</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">tackling</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">important</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">aspects</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">It</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">covers</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">conceptual,</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">practical</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">and</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">computational</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">problems</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV's</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">current</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">form.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>On</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>What</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Selves</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Are</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">draws</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">on</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">analytic</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">philosophy</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">methods</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">in</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">order</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">clarify</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">concept</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Self,</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">which</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">necessary</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">in</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">order</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">understand</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">whose</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">volition</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">going</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">be</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">extrapolated</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">by</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">machine</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">that</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">implements</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">procedure.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Troubles</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>with</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>CEV</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>part1</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">and</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>Troubles</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>with</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>CEV</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em> </em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>part2</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">on</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">other</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">hand</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">describe</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">several</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">issues</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">that</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">will</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">be</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">faced</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">by</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">project</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">if</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">it</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">actually</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">going</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">be</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">implemented.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Those</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">issues</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">are</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">not</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">conceptual</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">nature.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Many</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">objections</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">shown</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">come</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">from</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">scattered</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">discussions</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">found</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">on</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">web.</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Finally,</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">six</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">alternatives</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">are</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">considered.</span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm; line-height: 150%;\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm; border: medium none; padding: 0cm; line-height: 150%; page-break-before: auto; page-break-after: auto;\" align=\"LEFT\"><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Troubles</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>with</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>CEV</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Summary:</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Starting</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">with</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">summary</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">we</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">proceed</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">show</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">several</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">objections</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">First,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">specific</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">objections</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">use</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Coherence,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Extrapolation,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Volition.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Here</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Part1</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">ends.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Then,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">in</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Part2,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">we</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">continue</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">with</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">objections</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">related</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">end</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">product</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">performing</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">finally,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">problems</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">relating</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">implementation</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">We</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">then</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">go</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">on</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">with</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">praise</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">pointing</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">out</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">particular</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">strengths</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">idea.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">We</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">end</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">by</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">showing</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">six</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">alternatives</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">that</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">have</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">been</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">proposed,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">considering</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">their</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">vices</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">virtues.</span></span></span></span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm; border: medium none; padding: 0cm; line-height: 150%; page-break-before: auto; page-break-after: auto;\" align=\"LEFT\"><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Meta</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">:</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">I</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">think</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Troubles</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">With</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Part1</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Part2</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">should</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">be</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">posted</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Main.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">So</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">on</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">comment</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">section</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Part2,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">I</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">put</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">place</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">vote</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">for</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">or</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">against</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">this</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">upgrade.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm; border: medium none; padding: 0cm; line-height: 150%;\" align=\"CENTER\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm; border: medium none; padding: 0cm; line-height: 150%;\" align=\"CENTER\"><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: large;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Troubles</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: large;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">with</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: large;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: large;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: large;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Part1</span></span></span></span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm; border: medium none; padding: 0cm; line-height: 150%;\" align=\"LEFT\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm; line-height: 150%;\" align=\"JUSTIFY\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>Summary</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>of</strong></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><strong>CEV</strong></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm; line-height: 150%;\" align=\"JUSTIFY\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">To</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">begin</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">with,</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">let</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">us</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">remember</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">most</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">important</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">slices</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Coherent</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Extrapolated</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Volition</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">(CEV).</span></span></span></p>\n<p class=\"western\" style=\"margin-left: 1cm; margin-right: 1cm; margin-bottom: 0cm; line-height: 150%;\" align=\"JUSTIFY\">&ldquo;<span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Friendly</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">AI</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">requires:</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span></p>\n<ol>\n<li>\n<p class=\"western\" style=\"margin-right: 1cm; line-height: 150%;\" align=\"JUSTIFY\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Solving</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">technical</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">problems</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">required</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">maintain</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">well-specified</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">abstract</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">invariant</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">in</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">self-modifying</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">goal</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">system.</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">(Interestingly,</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">this</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">problem</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">relatively</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">straightforward</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">from</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">theoretical</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">standpoint.)</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span></p>\n</li>\n<li>\n<p class=\"western\" style=\"margin-right: 1cm; line-height: 150%;\" align=\"JUSTIFY\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Choosing</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">something</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">nice</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">do</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">with</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">AI.</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">This</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">about</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">midway</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">in</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">theoretical</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">hairiness</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">between</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">problems</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">1</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">and</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">3.</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span></p>\n</li>\n<li>\n<p class=\"western\" style=\"margin-right: 1cm; line-height: 150%;\" align=\"JUSTIFY\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Designing</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">framework</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">for</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">an</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">abstract</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">invariant</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">that</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">doesn't</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>automatically</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">wipe</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">out</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">human</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">species.</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>This</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>is</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>the</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>hard</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>part.</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span></p>\n</li>\n</ol>\n<blockquote class=\"western\" style=\"line-height: 150%;\"><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">But</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">right</span></em></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">now</span></em></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">question</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">is</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">whether</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">human</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">species</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">can</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">field</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">non-pathetic</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">force</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">in</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">defense</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">six</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">billion</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">lives</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">futures.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\">&rdquo; </span></span></span><span style=\"font-family: Arial,sans-serif;\"><br /></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\">&ldquo;</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Friendliness</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">easiest</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">part</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">of</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">problem</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">explain</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">-</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">part</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">that</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">says</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">what</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">we</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>want</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">.</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Like</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">explaining</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">why</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">you</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">want</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">fly</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">London,</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">versus</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">explaining</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Boeing</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">747;</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">explaining</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">toast,</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">versus</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">explaining</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">a</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">toaster</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">oven.</span></span></span><span style=\"font-family: Arial,sans-serif;\"> &ldquo;</span><span style=\"font-family: Arial,sans-serif;\"><br /></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\">&ldquo;</span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">To</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">construe</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">your</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">volition,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">I</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">need</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">to</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">define</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">dynamic</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">for</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">extrapolating</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">your</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">volition,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">given</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">knowledge</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">about</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">you.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">In</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">case</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">an</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">FAI,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">this</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">knowledge</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">might</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">include</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">complete</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">readout</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">your</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">brain-state,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">or</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">an</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">approximate</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">model</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">your</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">mind-state.</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">The</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">FAI</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">takes</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">knowledge</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Fred's</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">brainstate,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">other</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">knowledge</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">possessed</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">by</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">FAI</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(such</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">as</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">which</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">box</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">contains</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">the</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">diamond),</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">does...</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">something</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">complicated...</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">and</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">out</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">pops</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">construal</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">of</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Fred's</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">volition.</span></span></span></span></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">I</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">shall</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">refer</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">to</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">\"something</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">complicated\"</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">as</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">the</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><em>dynamic</em></span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">.</span></span></span><span style=\"font-family: Arial,sans-serif;\">&rdquo;</span></blockquote>\n<p class=\"western\" style=\"line-height: 150%;\" align=\"JUSTIFY\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">This</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">essentially</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">what</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">CEV</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">is:</span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"> </span></span></span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">extrapolating</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">Fred's</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">mind</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">and</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">everyone</span></span></span><span style=\"font-family: Arial,sans-serif;\"> </span><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\">els</span></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YtvHurPQv5Yr5dKDc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "13104", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T04:02:21.255Z", "modifiedAt": null, "url": null, "title": "test 5 Ignore", "slug": "test-5-ignore", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BGC6w7nhJ4av5wCsF/test-5-ignore", "pageUrlRelative": "/posts/BGC6w7nhJ4av5wCsF/test-5-ignore", "linkUrl": "https://www.lesswrong.com/posts/BGC6w7nhJ4av5wCsF/test-5-ignore", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20test%205%20Ignore&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Atest%205%20Ignore%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBGC6w7nhJ4av5wCsF%2Ftest-5-ignore%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=test%205%20Ignore%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBGC6w7nhJ4av5wCsF%2Ftest-5-ignore", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBGC6w7nhJ4av5wCsF%2Ftest-5-ignore", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<p>&lt;!-- \t\t@page { margin: 2cm } \t\tP { margin-bottom: 0.21cm } \t\tA:link { so-language: zxx } \t--&gt;</p>\n<p class=\"western\" style=\"line-height: 150%;\"><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Troubles</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><strong> </strong></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>with</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><strong> </strong></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>CEV</strong></span></span></span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm; border: medium none; padding: 0cm; line-height: 150%; page-break-before: auto; page-break-after: auto;\" align=\"JUSTIFY\"><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>1)</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Stumbling</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>on</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>People,</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Detecting</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>the</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Things</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>CEV</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Will</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong> </strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><strong>Extrapolate</strong></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">:</span></span></span></span></span></span></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm; border: medium none; padding: 0cm; line-height: 150%;\" align=\"JUSTIFY\"><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Concepts</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">on</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">which</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">CEV</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">relies</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">that</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">may</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"> </span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">be</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">ill-defined,</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">not</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">having</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">a</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">stable</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">consistent</span></span></span></span></span></span></span><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span><a href=\"lw/nl/the_cluster_structure_of_thingspace/\"><span style=\"color: #000080;\"><span lang=\"zxx\"><span style=\"text-decoration: underline;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">structure</span></span></span></span></span></span></span></span><span style=\"color: #000080;\"><span lang=\"zxx\"><span style=\"text-decoration: underline;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span></span><span style=\"color: #000080;\"><span lang=\"zxx\"><span style=\"text-decoration: underline;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">in</span></span></span></span></span></span></span></span><span style=\"color: #000080;\"><span lang=\"zxx\"><span style=\"text-decoration: underline;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"> </span></span></span></span></span></span></span></span><span style=\"color: #000080;\"><span lang=\"zxx\"><span style=\"text-decoration: underline;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">thingspace</span></span></span></span></span></span></span></span></a><span style=\"color: #000000;\"><span style=\"text-decoration: none;\"><span style=\"font-family: Arial,sans-serif;\"><span style=\"font-size: small;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">.</span></span></span></span></span></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BGC6w7nhJ4av5wCsF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "13105", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WBw8dDkAWohFjWQSk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T04:05:08.913Z", "modifiedAt": null, "url": null, "title": "Problem posting", "slug": "problem-posting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:59.354Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ogSqkY4q6BQvsHopG/problem-posting", "pageUrlRelative": "/posts/ogSqkY4q6BQvsHopG/problem-posting", "linkUrl": "https://www.lesswrong.com/posts/ogSqkY4q6BQvsHopG/problem-posting", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Problem%20posting&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProblem%20posting%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FogSqkY4q6BQvsHopG%2Fproblem-posting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Problem%20posting%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FogSqkY4q6BQvsHopG%2Fproblem-posting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FogSqkY4q6BQvsHopG%2Fproblem-posting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 80, "htmlBody": "<p>I'm experiencing a problem trying to post a text to the topic session of LessWrong discussion.</p>\n<p>When I write a small text (like this one) it works fine.</p>\n<p>When I copy part of the text I intend to publish, and try submitting, still fine.</p>\n<p>But if I copy most of it, or the entire thing, when I click submit the red sign saying \"submitting\" appears for a few seconds, then disappears, and nothing happens.</p>\n<p>Does anyone know what happened or how to solve it?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ogSqkY4q6BQvsHopG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 1, "extendedScore": null, "score": 8.496926089780269e-07, "legacy": true, "legacyId": "13106", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T06:19:28.976Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Words as Mental Paintbrush Handles", "slug": "seq-rerun-words-as-mental-paintbrush-handles", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:59.458Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uuFXeQpJLbEZm4JLX/seq-rerun-words-as-mental-paintbrush-handles", "pageUrlRelative": "/posts/uuFXeQpJLbEZm4JLX/seq-rerun-words-as-mental-paintbrush-handles", "linkUrl": "https://www.lesswrong.com/posts/uuFXeQpJLbEZm4JLX/seq-rerun-words-as-mental-paintbrush-handles", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Words%20as%20Mental%20Paintbrush%20Handles&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Words%20as%20Mental%20Paintbrush%20Handles%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuuFXeQpJLbEZm4JLX%2Fseq-rerun-words-as-mental-paintbrush-handles%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Words%20as%20Mental%20Paintbrush%20Handles%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuuFXeQpJLbEZm4JLX%2Fseq-rerun-words-as-mental-paintbrush-handles", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuuFXeQpJLbEZm4JLX%2Fseq-rerun-words-as-mental-paintbrush-handles", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 182, "htmlBody": "<p>Today's post, <a href=\"/lw/o9/words_as_mental_paintbrush_handles/\">Words as Mental Paintbrush Handles</a> was originally published on 01 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You think that words are like tiny little LISP symbols in your mind, rather than words being labels that act as handles to direct complex mental paintbrushes that can paint detailed pictures in your sensory workspace.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a2y/seq_rerun_conditional_independence_and_naive_bayes/\">Conditional Independence, and Naive Bayes</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uuFXeQpJLbEZm4JLX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.497455102333388e-07, "legacy": true, "legacyId": "13111", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YF9HB6cWCJrDK5pBM", "hurYFWPaEXxHGzjzY", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T06:37:38.193Z", "modifiedAt": null, "url": null, "title": "Empiricism in Gameplay", "slug": "empiricism-in-gameplay", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:30.820Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ac3raven", "createdAt": "2010-09-14T14:09:01.244Z", "isAdmin": false, "displayName": "ac3raven"}, "userId": "9ArttH7XBNaMCDBWL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4z66BMXacx6N9X2td/empiricism-in-gameplay", "pageUrlRelative": "/posts/4z66BMXacx6N9X2td/empiricism-in-gameplay", "linkUrl": "https://www.lesswrong.com/posts/4z66BMXacx6N9X2td/empiricism-in-gameplay", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Empiricism%20in%20Gameplay&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEmpiricism%20in%20Gameplay%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4z66BMXacx6N9X2td%2Fempiricism-in-gameplay%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Empiricism%20in%20Gameplay%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4z66BMXacx6N9X2td%2Fempiricism-in-gameplay", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4z66BMXacx6N9X2td%2Fempiricism-in-gameplay", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 619, "htmlBody": "<p><strong><em>This article relates to a game, being developed by <a href=\"http://shinyogre.com\">Shiny Ogre Games</a>, based on \"The Twelves Virtues of Rationality\" by Eliezer Yudkowsky.</em></strong></p>\n<blockquote>\n<p>The sixth virtue is empiricism. The roots of knowledge are in observation and its fruit is prediction. What tree grows without roots? What tree nourishes us without fruit? If a tree falls in a forest and no one hears it, does it make a sound? One says, &ldquo;Yes it does, for it makes vibrations in the air.&rdquo; Another says, &ldquo;No it does not, for there is no auditory processing in any brain.&rdquo; Though they argue, one saying &ldquo;Yes&rdquo;, and one saying &ldquo;No&rdquo;, the two do not anticipate any different experience of the forest. Do not ask which beliefs to profess, but which experiences to anticipate. Always know which difference of experience you argue about. Do not let the argument wander and become about something else, such as someone&rsquo;s virtue as a rationalist. Jerry Cleaver said: &ldquo;What does you in is not failure to apply some high-level, intricate, complicated technique. It&rsquo;s overlooking the basics. Not keeping your eye on the ball.&rdquo; Do not be blinded by words. When words are subtracted, anticipation remains. --<a href=\"http://yudkowsky.net/rational/virtues\" target=\"_blank\">The Twelve Virtues of Rationality, Eliezer</a><a href=\"http://yudkowsky.net/rational/virtues\" target=\"_blank\">Yudkowsky</a></p>\n<p>&nbsp;</p>\n<p>Empiricism is a theory of knowledge that asserts that knowledge comes only or primarily via sensory experience. --<a href=\"http://en.wikipedia.org/wiki/Empiricism\" target=\"_blank\">Wikipedia</a></p>\n</blockquote>\n<p>&nbsp;</p>\n<p>We can write whole books about empiricism, describing what it is, why it's useful, and how it works. &nbsp;We can use an&nbsp;innumerable amount of words to describe the nuanced techniques involved in thinking empirically about a problem. &nbsp;Words are certainly valuable for describing things, but can gameplay describe a thing more effectively?</p>\n<p>Our brains are pattern-seeking machines. &nbsp;We like figuring things out, it's a survival mechanism. &nbsp;Our brains release&nbsp;endorphins when we decode the noise of our environment.</p>\n<div class=\"mceTemp mceIEcenter\" style=\"text-align: center; \"><dl id=\"attachment_239\" class=\"wp-caption aligncenter\" style=\"display: block; margin-left: auto; margin-right: auto; text-align: center; background-color: #f3f3f3; padding-top: 4px; margin-top: 10px; margin-bottom: 10px; border-top-left-radius: 3px 3px; border-top-right-radius: 3px 3px; border-bottom-right-radius: 3px 3px; border-bottom-left-radius: 3px 3px; width: 510px; border: 1px solid #dddddd;\"><dt class=\"wp-caption-dt\"><a href=\"http://shinyogre.com/wp-content/uploads/2012/02/foxnoise.jpg\"><img class=\"size-medium wp-image-239 \" style=\"border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-style: none; border-right-style: none; border-bottom-style: none; border-left-style: none; border-color: initial; \" title=\"Noise\" src=\"http://shinyogre.com/wp-content/uploads/2012/02/foxnoise-500x257.jpg\" alt=\"\" width=\"500\" height=\"257\" /></a></dt><dd class=\"wp-caption-dd\" style=\"font-size: 11px; line-height: 17px; padding-top: 0px; padding-right: 4px; padding-bottom: 5px; padding-left: 4px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Try to find the threat.</dd></dl></div>\n<p style=\"text-align: left;\">Games more or less consist of a series &nbsp;of interesting challenges (or patterns), with mechanics that allow the player to figure out the challenges (or decode the noise). &nbsp; Decoding noise is what our brains do all the time, when we find patterns in the noise, we cache those for later reference. &nbsp;We do this because it is&nbsp;<em>fun</em>.</p>\n<p style=\"text-align: center;\">&nbsp;</p>\n<div class=\"mceTemp mceIEcenter\" style=\"text-align: center;\"><dl class=\"wp-caption aligncenter\" style=\"display: block; margin-left: auto; margin-right: auto; text-align: center; background-color: #f3f3f3; padding-top: 4px; margin-top: 10px; margin-bottom: 10px; border-top-left-radius: 3px 3px; border-top-right-radius: 3px 3px; border-bottom-right-radius: 3px 3px; border-bottom-left-radius: 3px 3px; width: 363px; border: 1px solid #dddddd;\"><dt class=\"wp-caption-dt\"><img class=\" \" style=\"border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-style: none; border-right-style: none; border-bottom-style: none; border-left-style: none; border-color: initial; \" title=\"&quot;chunking&quot;\" src=\"http://www.moillusions.com/wp-content/uploads/4.bp.blogspot.com/_cxmptAPYR-s/RcDUyPZZbzI/AAAAAAAAAFk/4WAwGzgZ2lE/s400/premonition-movie-poster2.jpg\" alt=\"\" width=\"353\" height=\"380\" /></dt><dd class=\"wp-caption-dd\" style=\"font-size: 11px; line-height: 17px; padding-top: 0px; padding-right: 4px; padding-bottom: 5px; padding-left: 4px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">You decoded the noise of \"face\" a long time ago, and now you've \"chunked\" it, so that you can quickly find the \"face\" pattern wherever you look.</dd></dl></div>\n<p>As Raph Koster famously said in his book,&nbsp;<a href=\"http://www.theoryoffun.com/\">A Theory of Fun</a>: &nbsp;\"Fun is just another word for learning\", &nbsp;because of this,&nbsp;<em>gameplay&nbsp;</em>can be expressive. &nbsp; By designing the challenges so that they evoke your various modes of thinking, and then setting those challenges into a narrative where the player assumes a role and is allowed to explore the system within the constraints of that role, a game can allow the player to&nbsp;<em>experience&nbsp;</em>the application of a concept.</p>\n<p>In the Empiricism level, we are trying to create a puzzle that requires empirical thinking to solve. &nbsp; That is, the player can only solve the puzzle if they are able to draw on their&nbsp;<em>experiences</em>&nbsp;and&nbsp;<em>observations&nbsp;</em>both within the game and without to make accurate predictions about how the puzzle elements should behave. &nbsp;In this puzzle, we do not try to trick or mislead the player, we do not require the player to react quickly, there is no violence, and the player cannot die. &nbsp;We give the player the freedom to experiment with the puzzle, and all we ask is that the player think empirically about the world presented by the puzzle.</p>\n<p>If all goes as planned, the player will solve the puzzle not through logical-deduction, process of elimination, or wild guessing, but by empiricism. &nbsp;They will do this without a single word of instruction or narrative, and they will grasp the concept on a deeper level because of it. &nbsp;Hopefully.</p>\n<p>Here's some art:</p>\n<p style=\"text-align: center;\"><a href=\"http://shinyogre.com/wp-content/uploads/2012/02/Empiricism-Concept.jpg\"><img class=\"aligncenter size-medium wp-image-248\" style=\"border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; display: block; margin-left: auto; margin-right: auto; \" title=\"Empiricism Concept Sketch\" src=\"http://shinyogre.com/wp-content/uploads/2012/02/Empiricism-Concept-500x258.jpg\" alt=\"\" width=\"500\" height=\"258\" /></a></p>\n<div style=\"padding-left: 90px;\"><img style=\"vertical-align: middle;\" src=\"http://shinyogre.com/wp-content/uploads/2012/02/black-to-white.jpg\" alt=\"\" width=\"500\" height=\"125\" /><br /></div>\n<p style=\"text-align: center;\"><a href=\"http://shinyogre.com/wp-content/uploads/2012/02/black-to-white.jpg\"></a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4z66BMXacx6N9X2td", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -1, "extendedScore": null, "score": 8.497524768891911e-07, "legacy": true, "legacyId": "13113", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T06:56:09.248Z", "modifiedAt": null, "url": null, "title": "Hypothetical scenario", "slug": "hypothetical-scenario", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.326Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nick012000", "createdAt": "2010-07-12T11:00:38.790Z", "isAdmin": false, "displayName": "nick012000"}, "userId": "yCSrMSsugCiSiqAY2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AJz5jkis7roijA6BG/hypothetical-scenario", "pageUrlRelative": "/posts/AJz5jkis7roijA6BG/hypothetical-scenario", "linkUrl": "https://www.lesswrong.com/posts/AJz5jkis7roijA6BG/hypothetical-scenario", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hypothetical%20scenario&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHypothetical%20scenario%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAJz5jkis7roijA6BG%2Fhypothetical-scenario%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hypothetical%20scenario%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAJz5jkis7roijA6BG%2Fhypothetical-scenario", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAJz5jkis7roijA6BG%2Fhypothetical-scenario", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 116, "htmlBody": "<p>One day, someone not a member of the Singularity Institute (and has publically stated that they don't believe in the necessity of ensuring all AI is Friendly) manages to build an AI. It promptly undergoes an intelligence explosion and sends kill-bots to massacre the vast majority of the upper echelons of the US Federal Government, both civilian and military. Or maybe forcibly upload them; it's sort of difficult for untrained meat-bags like the people running the media to tell. It claims, in a press release, that its calculations indicate that the optimal outcome for humanity is achieved by removing corruption from the US Government, and this is the best way to do this.</p>\n<p>What do you do?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AJz5jkis7roijA6BG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": -31, "extendedScore": null, "score": 8.497599524566692e-07, "legacy": true, "legacyId": "13115", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T09:01:23.172Z", "modifiedAt": null, "url": null, "title": "[LINK] Computer program that aces 'guess next' in IQ test", "slug": "link-computer-program-that-aces-guess-next-in-iq-test", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.372Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dmytry", "createdAt": "2009-12-03T17:11:53.492Z", "isAdmin": false, "displayName": "Dmytry"}, "userId": "AjtmA2qtA8sdiMbru", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vCfj7jJu8FmaCca2n/link-computer-program-that-aces-guess-next-in-iq-test", "pageUrlRelative": "/posts/vCfj7jJu8FmaCca2n/link-computer-program-that-aces-guess-next-in-iq-test", "linkUrl": "https://www.lesswrong.com/posts/vCfj7jJu8FmaCca2n/link-computer-program-that-aces-guess-next-in-iq-test", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Computer%20program%20that%20aces%20'guess%20next'%20in%20IQ%20test&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Computer%20program%20that%20aces%20'guess%20next'%20in%20IQ%20test%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvCfj7jJu8FmaCca2n%2Flink-computer-program-that-aces-guess-next-in-iq-test%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Computer%20program%20that%20aces%20'guess%20next'%20in%20IQ%20test%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvCfj7jJu8FmaCca2n%2Flink-computer-program-that-aces-guess-next-in-iq-test", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvCfj7jJu8FmaCca2n%2Flink-computer-program-that-aces-guess-next-in-iq-test", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 386, "htmlBody": "<p>From</p>\n<p><a href=\"http://astrobio.net/pressrelease/4569/computers-that-think-like-humans\">http://astrobio.net/pressrelease/4569/computers-that-think-like-humans</a></p>\n<blockquote>\n<p>The group is therefore using a <a href=\"http://astrobiology.nasa.gov/roadmap\">psychological model</a> of human patterns in their computer programmes. They have integrated a mathematical model that models human-like problem solving. The programme that solves progressive matrices scores IQ 100 and has the unique ability of being able to solve the problems without having access to any response alternatives. The group has improved the programme that specialises in number sequences to the point where it is now able to ace the tests, implying an IQ of at least 150. <br /> <br /> 'Our <a href=\"http://astrobio.net/exclusive/3632/astronomer-seeks-et-machines\">programmes</a> are beating the conventional math programmes because we are combining mathematics and psychology. Our method can potentially be used to identify patterns in any data with a psychological component, such as financial data. But it is not as good at finding patterns in more science-type data, such as weather data, since then the human psyche is not involved,' says Stranneg&aring;rd.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>That's an awesome study.</p>\n<p>I always thought the variations of continue series test (progressive matrices, number sequences, word A is to word B as word&nbsp; C is to ?? etc) are very culturally biased. You solve those best and easiest by sharing with the test maker the learning environment (and for visual ones, sharing visual environment), as well as sharing neural architecture. That lets you pick same choice as the test maker [edit: and do so easily and naturally]. And this research provides very good demonstration.</p>\n<p>Of course there will be a correlation of ability to guess the same or secondguess the test maker with intelligence, but so does e.g. height correlate with intelligence (via effect of nutrition on both); perhaps we should add 'what is your height' question to IQ test and then let some giant robot score a genius.</p>\n<p>Note: one might think of sequence guessing as task of minimizing Kolmogorov complexity. That's not quite so, sequences are too short, shorter than the generators. Consider sequence 2,3,5,7,11,? . Obviously the answer on IQ test would be 13 (primes). Good luck writing primes generating program that is simpler than this sequence itself, though [edit: i mean, simpler than a program which just prints those numbers followed by whatever garbage. Unless you have a language where 'print primes' is a basic command]. (and of course the length of program will be very dependent on the machine being used)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vCfj7jJu8FmaCca2n", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 2, "extendedScore": null, "score": 8.498092759087477e-07, "legacy": true, "legacyId": "13121", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T14:23:14.809Z", "modifiedAt": null, "url": null, "title": "The mathematics of reduced impact: help needed", "slug": "the-mathematics-of-reduced-impact-help-needed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:24.313Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8Nwg7kqAfCM46tuHq/the-mathematics-of-reduced-impact-help-needed", "pageUrlRelative": "/posts/8Nwg7kqAfCM46tuHq/the-mathematics-of-reduced-impact-help-needed", "linkUrl": "https://www.lesswrong.com/posts/8Nwg7kqAfCM46tuHq/the-mathematics-of-reduced-impact-help-needed", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20mathematics%20of%20reduced%20impact%3A%20help%20needed&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20mathematics%20of%20reduced%20impact%3A%20help%20needed%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Nwg7kqAfCM46tuHq%2Fthe-mathematics-of-reduced-impact-help-needed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20mathematics%20of%20reduced%20impact%3A%20help%20needed%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Nwg7kqAfCM46tuHq%2Fthe-mathematics-of-reduced-impact-help-needed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Nwg7kqAfCM46tuHq%2Fthe-mathematics-of-reduced-impact-help-needed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2658, "htmlBody": "<p><em>A putative new idea for AI control; index&nbsp;<a href=\"/lw/lt6/newish_ai_control_ideas/\">here</a>.</em></p>\n<p><em>Thanks for help from <a href=\"/user/paulfchristiano/\">Paul Christiano</a></em></p>\n<p>If&nbsp;<a href=\"http://www.student-direct.co.uk/wp-content/uploads/2011/11/Clippy.jpg\">clippy</a>, the paper-clip maximising AI,&nbsp;goes out of control, it would fill the universe with paper clips (or with better and better ways of counting the paper-clips it already has). If I sit down to a game with <a href=\"http://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)\">Deep Blue</a>, then I know little about what will happen in the game, but I know it will end with me losing.</p>\n<p>When facing a (general or narrow) superintelligent AI, the most relevant piece of information is what the AI's goals are. That's the general problem: there is no such thing as 'reduced impact' for such an AI. It doesn't matter who the next president of the United States is, if an AI wants to tile the universe with <a href=\"http://www.ssec.wisc.edu/~billh/visfiles.html\">little smiley faces</a>. But reduced impact is something we would dearly want to have - it gives us time to correct errors, perfect security systems, maybe even bootstrap our way to friendly AI from a non-friendly initial design. The most obvious path to coding reduced impact is to build a satisficer rather than a maximiser - but that proved <a href=\"/lw/854/satisficers_want_to_become_maximisers/\">unlikely</a> to work.</p>\n<p>But that ruthless maximising aspect of AIs may give us a way of quantifying 'reduced impact' - and hence including it in AI design. The central point being:</p>\n<p style=\"padding-left: 30px; \">\"When facing a (non-reduced impact) superintelligent AI, the AI's motivation is the most important fact we know.\"</p>\n<p>Hence, conversely:</p>\n<p style=\"padding-left: 30px; \">\"If an AI has reduced impact, then knowing its motivation isn't particularly important. And&nbsp;a counterfactual world where the AI didn't exist, would not be very different from the one in which it does.\"</p>\n<p>In this post, I'll be presenting some potential paths to formalising this intuition into something computable, giving us a numerical measure of impact that can be included in the AI's motivation to push it towards reduced impact. I'm putting this post up mainly to get help: does anyone know of already developed mathematical or computational tools that can be used to put these approaches on a rigorous footing?<a id=\"more\"></a></p>\n<h2>Counterfactuals</h2>\n<p>To define a counterfactual, we can use a variant of my <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/18371/2010-1.pdf\">favourite</a> \"send the effect through a stochastic event that has a small probability of undoing it\". Let's start by imagining there is an initial (super-intelligent) AI, the <a href=\"http://en.wikipedia.org/wiki/Palpatine\">master</a>, that gets one action only: to produce the source code for another AI, the <a href=\"http://badassoftheweek.com/vader.html\">disciple</a>, that will then go out into the world and do stuff. The source code is passed through a wire, and a stochastic event X happens: if X=1, the source code goes through unchanged, if X=0, the source code is erased. Generally speaking, we want X=1 with high probability; the counterfactual \"what if the disciple AI were not created\" is&nbsp;reduced to \"what if X=0\". There are some problems with this approach - the AI needs a good ontology, it needs to locate X in the world - but these are much simpler issues than other approaches to&nbsp;counterfactuals.</p>\n<h2>Penalty functions</h2>\n<p>The master AI has a double objective: to maximise some utility function, and minimise a penalty function, which measures how much impact its decision has on the world. Assuming the utility function is bounded, then it all becomes a question of weighting the utility and penalty functions so the the disciple AI accomplishes some small goal, but without transforming the universe into computronium along the way.</p>\n<p>For illustrative purpose, let the master AI be a bounded paperclipper,&nbsp;with a utility function linear in created paper clips up to a thousand (and constant&nbsp;thereafter). The disciple AI will be left to wander round an open factory to accomplish its objectives, without any extra precautions.</p>\n<p>For this model, we will assume we can ignore the long-term social impact of&nbsp;successfully&nbsp;deploying reduced impact AIs. This is a somewhat tricky point, and it's not clear at all how we would do so - maybe some&nbsp;cunning use of <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/18371/2010-1.pdf\">AI indifference</a>, or a commitment to running a million different reduced impact AI experiments, which could conceivably reduce the social impact of a single run. Of course, once these reduced impact AIs are in general use, then any given run will make little difference to the social environment, so this problem is especially acute only for the initial runs.</p>\n<p>The challenge then is in the definition of the penalty function.&nbsp;When considering whether to output source code S, clippy can compute two probability distributions over future worlds: P(e,S,1), given evidence e and assuming X=1. It will then contrast this with the probability distribution P(e,S,0), given the same evidence and assuming X=0. The X=0 case is taken as 'safe', so it would seem that the 'difference' between P(e,S,1) and P(e,S,1) is a good measure of impact.</p>\n<h2>Coarse graining</h2>\n<p>An initial impulse would be to compare P(e,S,1) and P(e,S,0) directly: for a world w, calculate the difference |P(e,S,1)(w)-P(e,S,0)(w)|, and sum or integrate this difference somehow over all worlds, and use this as a measure of impact. Unfortunately this will generally not work: there is a crucial difference between the X=0 and X=1 worlds, namely the presence of the active disciple AI doing its stuff. So generally, world w will have probability (very close to) zero in either&nbsp;P(e,S,1) or&nbsp;P(e,S,0), depending on whether w includes this disciple or not. So direct comparisons fail.</p>\n<p>One solution would be to coarse grain: to say that worlds w<sub>1</sub>&nbsp;(with X=1) and w<sub>0</sub> (with X=0) are otherwise so similar that we can bunch them together in one category W, and compute&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)|. The intuition behind this can be formalised as:</p>\n<p style=\"padding-left: 30px;\">\"Independently of whether the disciple AI was built, similar worlds should be similarly likely.\"&nbsp;</p>\n<h3><em>Twenty (million) questions</em></h3>\n<p>One method of coarse graining is to set up a huge amount of&nbsp;auxiliary&nbsp;measurements (such as the GDP of every country, the volume of sewage pumped though every city, ticket prices for travelling circuses, the quantity of pesticides used for growing strawberries, the number of lolcats viewed each minute, etc...) and use those to coarse grain: worlds with very similar results on these scales are grouped together. This is similar to the 'proxy measure of human survival' we mentioned in our Oracle AI <a href=\"http://www.aleph.se/papers/oracleAI.pdf\">article</a>.</p>\n<p>This is by no means a fool-proof method - the disciple AI could theoretically take over the cosmos while ensuring that there is little difference in GDP or lolcat views - or, more plausibly, little difference in whatever measurement method we have implemented to bring the level of GDP and lolcat views to the awareness of the AI. But the more auxiliary measurements we add, the more varied the ways of estimating them we require - or even give the AI a good enough ontology that its beliefs are really about states in the world - the more likely it becomes that the master AI will decide the risk the isn't worth the gain, given its bounded utility function, and that a disciple AI that builds a few thousand paper-clips and lets it go at that is a good design.</p>\n<p>Still, the coarse graining might be somewhat&nbsp;unsatisfactory: the measurements might all be hackable, or they might result in grouping together of worlds that we would find very different, or the separation of worlds that we consider virtually identical. Both mistakes are bad, as they reduce the ability of numbers such as&nbsp;&int;|P(e,S,1)(W)-P(e,S,0)(W)|dW to actually measure reduced impact.</p>\n<p>Note that&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)| should be read as 'estimate&nbsp;P(e,S,1)(W), then estimate P(e,S,0)(W), then take the modulus of their difference'. The other alternative - estimating&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)| directly - has problem with chaos. For instance, if I suspect that X=1 causes a hurricane somewhere else in the world than if would be for X=0, then even if I have no clue as to where the hurricane happens, I still would know that&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)| is large.</p>\n<h2>Comparing distributions abstractly</h2>\n<p>We could completely ignore similarity between worlds, and make no attempt to match up worlds with X=1 with those with X=0. Instead, we could just consider the distributions&nbsp;P(e,S,1) and P(e,S,0) abstractly, and see if they look similar, without knowing anything about the worlds they are defined on. The intuition behind this is:</p>\n<p style=\"padding-left: 30px; \">\"Independently of whether the disciple AI was built, we should expect the same shape to future uncertainty.\"</p>\n<p>There are many measures we could use to measure similarity between&nbsp;P(e,S,1) and P(e,S,0): we can treat them as random variables and compute all the usual descriptors: mean, variance, higher cumulants, max probability reached, number and shape of peaks, sexiness of the graph...</p>\n<p>Similarly, given some arbitrary measure M on worlds, we can twist&nbsp;the distributions P(e,S,*) into P'(e,S,*) by defining&nbsp;P'(e,S,*)(w)=M(w)P(e,S,*)(w) and then normalising. If we expect that K should be independent of a reduced impact AI (such as the Komlmogrov prior, for instance), then the distributions P'(e,S,*) should also have similar descriptors.</p>\n<h3><em>Information theoretic comparisons</em></h3>\n<p>Or we could get information theoretical, and measure how much more information we would need to describe&nbsp;P(e,S,1), given that we know&nbsp;P(e,S,0) (and vice-verse). This is somewhat similar to the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Kullback-Leibler_divergence\">Kullback-Leibler divergence</a>, but that measure requires matching up the worlds for the two distributions, and hence can't be used here: likely worlds in P(e,S,1) are not likely in P(e,S,0), and vice-verse, because of the X=1 versus X=0 issue.</p>\n<p>Roughly, what we would want is that&nbsp;P(e,S,1) and&nbsp;P(e,S,0) have roughly similar minimal description length (the expected future of the world doesn't get simpler or more complicated based on the disciple AI) and that the description of&nbsp;P(e,S,0) given&nbsp;P(e,S,1) is very short in comparison (if we know the world of the disciple AI, we have a good idea of the world without it).</p>\n<p>Of course, the shortest description of P(e,S,1) might just be the source code of the master AI along with X=1. This is not at all what we want, so might require that all these descriptions be considerably shorter than that, possibly allowing some destructive&nbsp;compression&nbsp;of the distributions to permit this.</p>\n<h2>The information in the evidence</h2>\n<p>There is a third route we could travel: when constructing the P(e,S,*), the AI made use of the evidence e (all it's previous observations) as well as the value of S and X. For minimised impact, we would want the value of X to not be particularly informative: we would require e to provide a lot more information than X. Updating on evidence can be seen as maps (e,X)-&gt;P(e,S,X), and would want to put norms on the possible e and the possible P such that X is not very informative compared to e.</p>\n<p>This can be hard to quantify; obviously, if you know nothing about the world at all, then knowing X tells us nothing. On the other hand, once we've seen twenty trillion lolcat videos, the twenty trillionth and one provides us with little more: so we can't simply say that the value X has to be unimportant compared with any given bits in e, as those bits may be highly redundant.</p>\n<h3><em>Measuring importance</em></h3>\n<p>How would we measure the value of e and X when constructing the P(e,S,*)? This is vital to this approach, and I don't have any clear ways of doing so. The picture I have in mind is smoothing the distributions somewhat (so that the P(e,S,*) aren't so sharp in their cutoff), and measuring the impact that changing information in e has on the probability distributions, using some sensible metric over probability distributions (the <a href=\"http://en.wikipedia.org/wiki/Lp_space\">L<sup>1</sup> norm</a> seems appropriate for probability distributions, though L<sup>2</sup> norms have more pleasing properties). If the data in e is allowed to vary in some continuous manner, then we can talk about the derivative of P(e,S,*) with respect to changes in e, and elements of high derivative, or whose derivative was not colinear with others, would be the most important.&nbsp;But there may be discrete measure that are more appropriate for this: the important thing is to get a norm on e and X and another on P, and compare how small changes in e and X affect the norm on P.</p>\n<h3><em>Absolute information importance</em></h3>\n<p>We can compress e to get rid of the redundancy, and then compare the typical importance of bits in the (compressed) e as compared with knowing X, and penalise those S's where the importance of X is higher. This is formalising the intuition:</p>\n<p style=\"padding-left: 30px; \">\"The rest of the information about the world should be more important than whether the disciple AI was built.\"</p>\n<p>But once e is compressed, it seems that any bit is equally informative - or at least the difference is not so clear. For instance, the name <a href=\"http://en.wikipedia.org/wiki/Mitt_Romney\">of</a> <a href=\"http://en.wikipedia.org/wiki/Santorum\">the</a> <a href=\"http://en.wikipedia.org/wiki/Newt_Gingrich\">next</a> <a href=\"http://en.wikipedia.org/wiki/Obama\">president</a> of the United States is intuitively more important than the name of the <a href=\"http://en.wikipedia.org/wiki/Taraxacum\">plant</a> that grows in my back garden, but if I want to keep track of every piece of information, then they are equally important - the plant in my back garden will interact with particles all around it, which will soon snowball all over the planet; within eight minutes, the positions of the atoms in the sun will be different from what they would have been had that plant been of a different species. Hell, their positions would be different if I'd thought the right name for the plant rather than the wrong name.</p>\n<p>There is a kind of implicit coarse graining here - we're assuming the AIs don't have the ability to unravel chaos and entropy, and keep track of every piece of information; they will be using destructive compression, or average measures (temperature, pressure...) at some point.</p>\n<p>For instance, if there are two gasses in adjacent (equal-sized) compartments, and we are about to remove the partition, then the average pressure is something important to keep track of, but the individual pressures are not informative for the picture we have of the future. If the AI is subject to similar constraints, its own coarse-graining will define this \"varying importance of information\".</p>\n<h3><em>Relative information importance</em></h3>\n<p>There is another avenue we could explore here, a potentially more rewarding one, that does not require compressing e. Instead of caring about the importance of knowing X, we can track what impact knowing X has on the <em>relative importance of different pieces of e</em>.</p>\n<p>If, for instance, there were no AI built in the next year, then the name of the next US president is more important than the fact that the human mind could be hacked by an incredibly complicated combination of lights and sounds. If a superintelligent AI wanted to take over the world in this year, then relative the importance of those facts is presumably reversed: we won't live to see the election, but a human vulnerability is something the AI can exploit. This intuition is:</p>\n<p style=\"padding-left: 30px; \">\"Independently of whether the disciple AI was built, we should expect the same relative importance of different pieces of current information.\"</p>\n<p>This is a potentially very powerful measure - an AI wanting to take over the world would have to do while ensuring that it only uses facts that were going to be important anyway (and uses them in precisely the right amounts, and prevents the human reaction from disrupting this setup, and leaving open the same spread of possible future worlds dependent on variations in current evidence, etc...) It seems an immense challenge even for a super intelligent AI. Generally, the more coarse grained the AI's vision is, the more useful this measure becomes.</p>\n<p>To transform this measure into a penalty function, we merely need to use some sort of norm across the difference in information importance. We have vector valued information here: changing the known value of Z can undo another change in the value of Y (for instance when these denote the pressure of the two mixing gasses), and the best norm would take this into consideration as well.</p>\n<h2>Conclusion: as always, more research needed</h2>\n<p>I've explored a few tentative methods for formalising various 'reduced impact' intuitions:</p>\n<p>&nbsp;</p>\n<ol>\n<li>Independently of whether the disciple AI was built, similar worlds should be similarly likely.</li>\n<li>Independently of whether the disciple AI was built, we should expect the same shape to future uncertainty.</li>\n<li>The rest of the information about the world should be more important than whether the disciple&nbsp;AI&nbsp;was built.</li>\n<li>Independently of whether the disciple AI was built, we should expect the same relative importance of different pieces of current information.</li>\n</ol>\n<p>&nbsp;</p>\n<p>The important questions are now whether these methods can be formalised with sufficient rigour, and whether they capture enough of what we want to be useful.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8Nwg7kqAfCM46tuHq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 13, "extendedScore": null, "score": 8.499358833881571e-07, "legacy": true, "legacyId": "13077", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>A putative new idea for AI control; index&nbsp;<a href=\"/lw/lt6/newish_ai_control_ideas/\">here</a>.</em></p>\n<p><em>Thanks for help from <a href=\"/user/paulfchristiano/\">Paul Christiano</a></em></p>\n<p>If&nbsp;<a href=\"http://www.student-direct.co.uk/wp-content/uploads/2011/11/Clippy.jpg\">clippy</a>, the paper-clip maximising AI,&nbsp;goes out of control, it would fill the universe with paper clips (or with better and better ways of counting the paper-clips it already has). If I sit down to a game with <a href=\"http://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)\">Deep Blue</a>, then I know little about what will happen in the game, but I know it will end with me losing.</p>\n<p>When facing a (general or narrow) superintelligent AI, the most relevant piece of information is what the AI's goals are. That's the general problem: there is no such thing as 'reduced impact' for such an AI. It doesn't matter who the next president of the United States is, if an AI wants to tile the universe with <a href=\"http://www.ssec.wisc.edu/~billh/visfiles.html\">little smiley faces</a>. But reduced impact is something we would dearly want to have - it gives us time to correct errors, perfect security systems, maybe even bootstrap our way to friendly AI from a non-friendly initial design. The most obvious path to coding reduced impact is to build a satisficer rather than a maximiser - but that proved <a href=\"/lw/854/satisficers_want_to_become_maximisers/\">unlikely</a> to work.</p>\n<p>But that ruthless maximising aspect of AIs may give us a way of quantifying 'reduced impact' - and hence including it in AI design. The central point being:</p>\n<p style=\"padding-left: 30px; \">\"When facing a (non-reduced impact) superintelligent AI, the AI's motivation is the most important fact we know.\"</p>\n<p>Hence, conversely:</p>\n<p style=\"padding-left: 30px; \">\"If an AI has reduced impact, then knowing its motivation isn't particularly important. And&nbsp;a counterfactual world where the AI didn't exist, would not be very different from the one in which it does.\"</p>\n<p>In this post, I'll be presenting some potential paths to formalising this intuition into something computable, giving us a numerical measure of impact that can be included in the AI's motivation to push it towards reduced impact. I'm putting this post up mainly to get help: does anyone know of already developed mathematical or computational tools that can be used to put these approaches on a rigorous footing?<a id=\"more\"></a></p>\n<h2 id=\"Counterfactuals\">Counterfactuals</h2>\n<p>To define a counterfactual, we can use a variant of my <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/18371/2010-1.pdf\">favourite</a> \"send the effect through a stochastic event that has a small probability of undoing it\". Let's start by imagining there is an initial (super-intelligent) AI, the <a href=\"http://en.wikipedia.org/wiki/Palpatine\">master</a>, that gets one action only: to produce the source code for another AI, the <a href=\"http://badassoftheweek.com/vader.html\">disciple</a>, that will then go out into the world and do stuff. The source code is passed through a wire, and a stochastic event X happens: if X=1, the source code goes through unchanged, if X=0, the source code is erased. Generally speaking, we want X=1 with high probability; the counterfactual \"what if the disciple AI were not created\" is&nbsp;reduced to \"what if X=0\". There are some problems with this approach - the AI needs a good ontology, it needs to locate X in the world - but these are much simpler issues than other approaches to&nbsp;counterfactuals.</p>\n<h2 id=\"Penalty_functions\">Penalty functions</h2>\n<p>The master AI has a double objective: to maximise some utility function, and minimise a penalty function, which measures how much impact its decision has on the world. Assuming the utility function is bounded, then it all becomes a question of weighting the utility and penalty functions so the the disciple AI accomplishes some small goal, but without transforming the universe into computronium along the way.</p>\n<p>For illustrative purpose, let the master AI be a bounded paperclipper,&nbsp;with a utility function linear in created paper clips up to a thousand (and constant&nbsp;thereafter). The disciple AI will be left to wander round an open factory to accomplish its objectives, without any extra precautions.</p>\n<p>For this model, we will assume we can ignore the long-term social impact of&nbsp;successfully&nbsp;deploying reduced impact AIs. This is a somewhat tricky point, and it's not clear at all how we would do so - maybe some&nbsp;cunning use of <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/18371/2010-1.pdf\">AI indifference</a>, or a commitment to running a million different reduced impact AI experiments, which could conceivably reduce the social impact of a single run. Of course, once these reduced impact AIs are in general use, then any given run will make little difference to the social environment, so this problem is especially acute only for the initial runs.</p>\n<p>The challenge then is in the definition of the penalty function.&nbsp;When considering whether to output source code S, clippy can compute two probability distributions over future worlds: P(e,S,1), given evidence e and assuming X=1. It will then contrast this with the probability distribution P(e,S,0), given the same evidence and assuming X=0. The X=0 case is taken as 'safe', so it would seem that the 'difference' between P(e,S,1) and P(e,S,1) is a good measure of impact.</p>\n<h2 id=\"Coarse_graining\">Coarse graining</h2>\n<p>An initial impulse would be to compare P(e,S,1) and P(e,S,0) directly: for a world w, calculate the difference |P(e,S,1)(w)-P(e,S,0)(w)|, and sum or integrate this difference somehow over all worlds, and use this as a measure of impact. Unfortunately this will generally not work: there is a crucial difference between the X=0 and X=1 worlds, namely the presence of the active disciple AI doing its stuff. So generally, world w will have probability (very close to) zero in either&nbsp;P(e,S,1) or&nbsp;P(e,S,0), depending on whether w includes this disciple or not. So direct comparisons fail.</p>\n<p>One solution would be to coarse grain: to say that worlds w<sub>1</sub>&nbsp;(with X=1) and w<sub>0</sub> (with X=0) are otherwise so similar that we can bunch them together in one category W, and compute&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)|. The intuition behind this can be formalised as:</p>\n<p style=\"padding-left: 30px;\">\"Independently of whether the disciple AI was built, similar worlds should be similarly likely.\"&nbsp;</p>\n<h3 id=\"Twenty__million__questions\"><em>Twenty (million) questions</em></h3>\n<p>One method of coarse graining is to set up a huge amount of&nbsp;auxiliary&nbsp;measurements (such as the GDP of every country, the volume of sewage pumped though every city, ticket prices for travelling circuses, the quantity of pesticides used for growing strawberries, the number of lolcats viewed each minute, etc...) and use those to coarse grain: worlds with very similar results on these scales are grouped together. This is similar to the 'proxy measure of human survival' we mentioned in our Oracle AI <a href=\"http://www.aleph.se/papers/oracleAI.pdf\">article</a>.</p>\n<p>This is by no means a fool-proof method - the disciple AI could theoretically take over the cosmos while ensuring that there is little difference in GDP or lolcat views - or, more plausibly, little difference in whatever measurement method we have implemented to bring the level of GDP and lolcat views to the awareness of the AI. But the more auxiliary measurements we add, the more varied the ways of estimating them we require - or even give the AI a good enough ontology that its beliefs are really about states in the world - the more likely it becomes that the master AI will decide the risk the isn't worth the gain, given its bounded utility function, and that a disciple AI that builds a few thousand paper-clips and lets it go at that is a good design.</p>\n<p>Still, the coarse graining might be somewhat&nbsp;unsatisfactory: the measurements might all be hackable, or they might result in grouping together of worlds that we would find very different, or the separation of worlds that we consider virtually identical. Both mistakes are bad, as they reduce the ability of numbers such as&nbsp;\u222b|P(e,S,1)(W)-P(e,S,0)(W)|dW to actually measure reduced impact.</p>\n<p>Note that&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)| should be read as 'estimate&nbsp;P(e,S,1)(W), then estimate P(e,S,0)(W), then take the modulus of their difference'. The other alternative - estimating&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)| directly - has problem with chaos. For instance, if I suspect that X=1 causes a hurricane somewhere else in the world than if would be for X=0, then even if I have no clue as to where the hurricane happens, I still would know that&nbsp;|P(e,S,1)(W)-P(e,S,0)(W)| is large.</p>\n<h2 id=\"Comparing_distributions_abstractly\">Comparing distributions abstractly</h2>\n<p>We could completely ignore similarity between worlds, and make no attempt to match up worlds with X=1 with those with X=0. Instead, we could just consider the distributions&nbsp;P(e,S,1) and P(e,S,0) abstractly, and see if they look similar, without knowing anything about the worlds they are defined on. The intuition behind this is:</p>\n<p style=\"padding-left: 30px; \">\"Independently of whether the disciple AI was built, we should expect the same shape to future uncertainty.\"</p>\n<p>There are many measures we could use to measure similarity between&nbsp;P(e,S,1) and P(e,S,0): we can treat them as random variables and compute all the usual descriptors: mean, variance, higher cumulants, max probability reached, number and shape of peaks, sexiness of the graph...</p>\n<p>Similarly, given some arbitrary measure M on worlds, we can twist&nbsp;the distributions P(e,S,*) into P'(e,S,*) by defining&nbsp;P'(e,S,*)(w)=M(w)P(e,S,*)(w) and then normalising. If we expect that K should be independent of a reduced impact AI (such as the Komlmogrov prior, for instance), then the distributions P'(e,S,*) should also have similar descriptors.</p>\n<h3 id=\"Information_theoretic_comparisons\"><em>Information theoretic comparisons</em></h3>\n<p>Or we could get information theoretical, and measure how much more information we would need to describe&nbsp;P(e,S,1), given that we know&nbsp;P(e,S,0) (and vice-verse). This is somewhat similar to the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Kullback-Leibler_divergence\">Kullback-Leibler divergence</a>, but that measure requires matching up the worlds for the two distributions, and hence can't be used here: likely worlds in P(e,S,1) are not likely in P(e,S,0), and vice-verse, because of the X=1 versus X=0 issue.</p>\n<p>Roughly, what we would want is that&nbsp;P(e,S,1) and&nbsp;P(e,S,0) have roughly similar minimal description length (the expected future of the world doesn't get simpler or more complicated based on the disciple AI) and that the description of&nbsp;P(e,S,0) given&nbsp;P(e,S,1) is very short in comparison (if we know the world of the disciple AI, we have a good idea of the world without it).</p>\n<p>Of course, the shortest description of P(e,S,1) might just be the source code of the master AI along with X=1. This is not at all what we want, so might require that all these descriptions be considerably shorter than that, possibly allowing some destructive&nbsp;compression&nbsp;of the distributions to permit this.</p>\n<h2 id=\"The_information_in_the_evidence\">The information in the evidence</h2>\n<p>There is a third route we could travel: when constructing the P(e,S,*), the AI made use of the evidence e (all it's previous observations) as well as the value of S and X. For minimised impact, we would want the value of X to not be particularly informative: we would require e to provide a lot more information than X. Updating on evidence can be seen as maps (e,X)-&gt;P(e,S,X), and would want to put norms on the possible e and the possible P such that X is not very informative compared to e.</p>\n<p>This can be hard to quantify; obviously, if you know nothing about the world at all, then knowing X tells us nothing. On the other hand, once we've seen twenty trillion lolcat videos, the twenty trillionth and one provides us with little more: so we can't simply say that the value X has to be unimportant compared with any given bits in e, as those bits may be highly redundant.</p>\n<h3 id=\"Measuring_importance\"><em>Measuring importance</em></h3>\n<p>How would we measure the value of e and X when constructing the P(e,S,*)? This is vital to this approach, and I don't have any clear ways of doing so. The picture I have in mind is smoothing the distributions somewhat (so that the P(e,S,*) aren't so sharp in their cutoff), and measuring the impact that changing information in e has on the probability distributions, using some sensible metric over probability distributions (the <a href=\"http://en.wikipedia.org/wiki/Lp_space\">L<sup>1</sup> norm</a> seems appropriate for probability distributions, though L<sup>2</sup> norms have more pleasing properties). If the data in e is allowed to vary in some continuous manner, then we can talk about the derivative of P(e,S,*) with respect to changes in e, and elements of high derivative, or whose derivative was not colinear with others, would be the most important.&nbsp;But there may be discrete measure that are more appropriate for this: the important thing is to get a norm on e and X and another on P, and compare how small changes in e and X affect the norm on P.</p>\n<h3 id=\"Absolute_information_importance\"><em>Absolute information importance</em></h3>\n<p>We can compress e to get rid of the redundancy, and then compare the typical importance of bits in the (compressed) e as compared with knowing X, and penalise those S's where the importance of X is higher. This is formalising the intuition:</p>\n<p style=\"padding-left: 30px; \">\"The rest of the information about the world should be more important than whether the disciple AI was built.\"</p>\n<p>But once e is compressed, it seems that any bit is equally informative - or at least the difference is not so clear. For instance, the name <a href=\"http://en.wikipedia.org/wiki/Mitt_Romney\">of</a> <a href=\"http://en.wikipedia.org/wiki/Santorum\">the</a> <a href=\"http://en.wikipedia.org/wiki/Newt_Gingrich\">next</a> <a href=\"http://en.wikipedia.org/wiki/Obama\">president</a> of the United States is intuitively more important than the name of the <a href=\"http://en.wikipedia.org/wiki/Taraxacum\">plant</a> that grows in my back garden, but if I want to keep track of every piece of information, then they are equally important - the plant in my back garden will interact with particles all around it, which will soon snowball all over the planet; within eight minutes, the positions of the atoms in the sun will be different from what they would have been had that plant been of a different species. Hell, their positions would be different if I'd thought the right name for the plant rather than the wrong name.</p>\n<p>There is a kind of implicit coarse graining here - we're assuming the AIs don't have the ability to unravel chaos and entropy, and keep track of every piece of information; they will be using destructive compression, or average measures (temperature, pressure...) at some point.</p>\n<p>For instance, if there are two gasses in adjacent (equal-sized) compartments, and we are about to remove the partition, then the average pressure is something important to keep track of, but the individual pressures are not informative for the picture we have of the future. If the AI is subject to similar constraints, its own coarse-graining will define this \"varying importance of information\".</p>\n<h3 id=\"Relative_information_importance\"><em>Relative information importance</em></h3>\n<p>There is another avenue we could explore here, a potentially more rewarding one, that does not require compressing e. Instead of caring about the importance of knowing X, we can track what impact knowing X has on the <em>relative importance of different pieces of e</em>.</p>\n<p>If, for instance, there were no AI built in the next year, then the name of the next US president is more important than the fact that the human mind could be hacked by an incredibly complicated combination of lights and sounds. If a superintelligent AI wanted to take over the world in this year, then relative the importance of those facts is presumably reversed: we won't live to see the election, but a human vulnerability is something the AI can exploit. This intuition is:</p>\n<p style=\"padding-left: 30px; \">\"Independently of whether the disciple AI was built, we should expect the same relative importance of different pieces of current information.\"</p>\n<p>This is a potentially very powerful measure - an AI wanting to take over the world would have to do while ensuring that it only uses facts that were going to be important anyway (and uses them in precisely the right amounts, and prevents the human reaction from disrupting this setup, and leaving open the same spread of possible future worlds dependent on variations in current evidence, etc...) It seems an immense challenge even for a super intelligent AI. Generally, the more coarse grained the AI's vision is, the more useful this measure becomes.</p>\n<p>To transform this measure into a penalty function, we merely need to use some sort of norm across the difference in information importance. We have vector valued information here: changing the known value of Z can undo another change in the value of Y (for instance when these denote the pressure of the two mixing gasses), and the best norm would take this into consideration as well.</p>\n<h2 id=\"Conclusion__as_always__more_research_needed\">Conclusion: as always, more research needed</h2>\n<p>I've explored a few tentative methods for formalising various 'reduced impact' intuitions:</p>\n<p>&nbsp;</p>\n<ol>\n<li>Independently of whether the disciple AI was built, similar worlds should be similarly likely.</li>\n<li>Independently of whether the disciple AI was built, we should expect the same shape to future uncertainty.</li>\n<li>The rest of the information about the world should be more important than whether the disciple&nbsp;AI&nbsp;was built.</li>\n<li>Independently of whether the disciple AI was built, we should expect the same relative importance of different pieces of current information.</li>\n</ol>\n<p>&nbsp;</p>\n<p>The important questions are now whether these methods can be formalised with sufficient rigour, and whether they capture enough of what we want to be useful.</p>", "sections": [{"title": "Counterfactuals", "anchor": "Counterfactuals", "level": 1}, {"title": "Penalty functions", "anchor": "Penalty_functions", "level": 1}, {"title": "Coarse graining", "anchor": "Coarse_graining", "level": 1}, {"title": "Twenty (million) questions", "anchor": "Twenty__million__questions", "level": 2}, {"title": "Comparing distributions abstractly", "anchor": "Comparing_distributions_abstractly", "level": 1}, {"title": "Information theoretic comparisons", "anchor": "Information_theoretic_comparisons", "level": 2}, {"title": "The information in the evidence", "anchor": "The_information_in_the_evidence", "level": 1}, {"title": "Measuring importance", "anchor": "Measuring_importance", "level": 2}, {"title": "Absolute information importance", "anchor": "Absolute_information_importance", "level": 2}, {"title": "Relative information importance", "anchor": "Relative_information_importance", "level": 2}, {"title": "Conclusion: as always, more research needed", "anchor": "Conclusion__as_always__more_research_needed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "94 comments"}], "headingsCount": 13}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 94, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BEJ4PRQGXuz6PRYwB", "2qCxguXuZERZNKcNi"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T15:37:33.551Z", "modifiedAt": null, "url": null, "title": "Tel Aviv Self-Improvement Meetup Group", "slug": "tel-aviv-self-improvement-meetup-group", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Meni_Rosenfeld", "createdAt": "2010-04-19T15:09:59.043Z", "isAdmin": false, "displayName": "Meni_Rosenfeld"}, "userId": "84ebCjWmavqjgjAfM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zQ8yP3y3kiWfBzXxe/tel-aviv-self-improvement-meetup-group", "pageUrlRelative": "/posts/zQ8yP3y3kiWfBzXxe/tel-aviv-self-improvement-meetup-group", "linkUrl": "https://www.lesswrong.com/posts/zQ8yP3y3kiWfBzXxe/tel-aviv-self-improvement-meetup-group", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tel%20Aviv%20Self-Improvement%20Meetup%20Group&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATel%20Aviv%20Self-Improvement%20Meetup%20Group%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzQ8yP3y3kiWfBzXxe%2Ftel-aviv-self-improvement-meetup-group%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tel%20Aviv%20Self-Improvement%20Meetup%20Group%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzQ8yP3y3kiWfBzXxe%2Ftel-aviv-self-improvement-meetup-group", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzQ8yP3y3kiWfBzXxe%2Ftel-aviv-self-improvement-meetup-group", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<p>I have started the <a href=\"http://www.meetup.com/improve-il/\">Tel Aviv Self-Improvement Meetup Group</a>. It is not about rationality or LessWrong per se, but it is heavily influenced by rationality dojos and LW posts in the applied rationality, personal optimization and anti-akrasia cluster. As the description says, it is</p>\n<blockquote>\n<p>A group of people helping each other apply rationality to our everyday  lives, in order to improve our skills, make the best decisions, become  productive and achieve our goals.</p>\n</blockquote>\n<p>If you're interested and in the area, you're welcome to join. If you have any comments or suggestions, based perhaps on experience with similar groups, please share.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zQ8yP3y3kiWfBzXxe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1e-05, "legacy": true, "legacyId": "13130", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T21:05:25.838Z", "modifiedAt": null, "url": null, "title": "Possible Implications of the neural retrotransposons to the future", "slug": "possible-implications-of-the-neural-retrotransposons-to-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.720Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "whpearson", "createdAt": "2009-02-28T00:34:00.976Z", "isAdmin": false, "displayName": "whpearson"}, "userId": "bq8qsRbPNvFihHxgi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZDh6o87tKQqMSACm4/possible-implications-of-the-neural-retrotransposons-to-the", "pageUrlRelative": "/posts/ZDh6o87tKQqMSACm4/possible-implications-of-the-neural-retrotransposons-to-the", "linkUrl": "https://www.lesswrong.com/posts/ZDh6o87tKQqMSACm4/possible-implications-of-the-neural-retrotransposons-to-the", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Possible%20Implications%20of%20the%20neural%20retrotransposons%20to%20the%20future&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APossible%20Implications%20of%20the%20neural%20retrotransposons%20to%20the%20future%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZDh6o87tKQqMSACm4%2Fpossible-implications-of-the-neural-retrotransposons-to-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Possible%20Implications%20of%20the%20neural%20retrotransposons%20to%20the%20future%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZDh6o87tKQqMSACm4%2Fpossible-implications-of-the-neural-retrotransposons-to-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZDh6o87tKQqMSACm4%2Fpossible-implications-of-the-neural-retrotransposons-to-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 535, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Retrotransposon\">Retrotransposons</a> are small bits of genetic code than can copy themselves into other bits of the dna strand</p>\n<p><a href=\"http://www.genomeweb.com/sequencing/targeted-sequencing-reveals-somatic-retrotransposition-events-human-brain\">They have been found</a> to be active in brains, with different amounts of activity in different brain sections. The highest being in the hippocampus (an important region for long-term memory). Also they were active in coding regions.</p>\n<blockquote>\n<p style=\"padding-left: 30px;\">\"Overall, L1, Alu, and, to a more limited extent, SVA mobilization produced a large number of insertions that affected protein-coding genes,\"</p>\n</blockquote>\n<p>This means that they are more likely to have some large effect, than if they were just in junk dna.</p>\n<p><a href=\"http://www.scientificamerican.com/article.cfm?id=jumping-genes-brain-tied-autisim\">One form of autism </a>is linked to a malfunctioning of retrotransposons. So it can have a drastic affect.</p>\n<p>It makes a certain amount of sense. If there is information in the brain that needs to to be stored, but not directly in neural firing rates, why not store it in the DNA of neuron? There is lots of error correcting data storage there and the genome has lots of tools for manipulating itself. Time will tell if it is very important or not.</p>\n<p>If it is important, what are the implications for the future?</p>\n<p>Cryo is harder, scanning the genome is a lot harder than just doing some spectroscopy. but since we assume a certain amount of sufficiently advanced technology and don't have a timeline, our plans aren't impinged upon.</p>\n<p>The <a href=\"http://www.overcomingbias.com/2008/11/emulations-go-f.html\">em scenario</a> seems like it will take longer to happen or may have some gotchas. Being able to scan the genetic code of each neuron would require some serious breakthroughs in scanning technolgies.</p>\n<p>To naively emulate the genetic code changes would take immense amounts of bandwidth and to crack things like the protein folding problem (for how the changes in ). Just for storage I think we might need on the order of 500 exabits to store the dna sequence for each neuron. You'ld need to update them as well, which is going to take lots of memory bandwidth. This is not to mention chemical emulation.</p>\n<p>I think naive emulation of the brain is off the table before AI. We may well be able to do better with shortcuts in terms of ability. But there might be questions of whether the copy is \"you\" if short cuts are taken. Also if we understand the brain, we don't need to make copies of people, we could just create AIs that do the same thing.</p>\n<p>Some even more blue sky speculation. If the changes in the genetic code are to do with changing how we learn, then it still might be possible to scan a brain at low res and get something that seems to act the same as someone else, but cannot learn in the same way. An interesting twist to the Turing test, someone might be behaviourally human and fool you in the short-term, but may seem odd when tasked with learning problems.</p>\n<p>So call centre staff would be out of work, but scientists would be still in demand.</p>\n<p>It also has implication on cloning attempts at intelligence amplification.&nbsp; I'm guessing this can be answered somewhat by looking at twins and the differential in mental ability between them. Anyone know of any books on this field.</p>\n<p>Also anyone interested in discussion on this kind of topic (neurobiological implication on the future)?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZDh6o87tKQqMSACm4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 26, "extendedScore": null, "score": 8.50094545135464e-07, "legacy": true, "legacyId": "13131", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T21:42:52.639Z", "modifiedAt": null, "url": null, "title": "Counterfactual Coalitions", "slug": "counterfactual-coalitions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.578Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Larks", "createdAt": "2009-04-28T20:21:45.860Z", "isAdmin": false, "displayName": "Larks"}, "userId": "jQXwiWxFcfyYjytXa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MZz5WWMbT2yoXthqR/counterfactual-coalitions", "pageUrlRelative": "/posts/MZz5WWMbT2yoXthqR/counterfactual-coalitions", "linkUrl": "https://www.lesswrong.com/posts/MZz5WWMbT2yoXthqR/counterfactual-coalitions", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Counterfactual%20Coalitions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACounterfactual%20Coalitions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMZz5WWMbT2yoXthqR%2Fcounterfactual-coalitions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Counterfactual%20Coalitions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMZz5WWMbT2yoXthqR%2Fcounterfactual-coalitions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMZz5WWMbT2yoXthqR%2Fcounterfactual-coalitions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 258, "htmlBody": "<p>Politics is the mind-killer; our opinions are largely formed on the basis of which tribes we want to affiliate with. What's more, when we first joined a tribe, we probably didn't properly vet the effects it would have on our cognition. &nbsp;<br />&nbsp;<br />One illustration of this is the apparently contingent nature of actual political coalitions, and the prima facie plausibility of others. For example,</p>\n<ul>\n<li>In the real world, animal rights activists tend to be pro-choice. </li>\n<li>But animal rights &amp; fetus rights seems just as plausible coalition - an expanding sphere of moral worth. </li>\n</ul>\n<p>&nbsp;<br />This suggests a de-biasing technique; inventing plausible alternative coalitions of ideas. When considering the counterfactual political argument, each side will have some red positions and some green positions, so hopefully your brain will be forced to evaluate it in a more rational manner. <br />&nbsp;<br />Obviously, political issues are not all orthogonal; there is mutual information, and you don't want to ignore it. The idea isn't to decide your belief on every issue independently. If taxes on beer, cider and wine are a good idea, taxes on spirits are probably a good idea too. However, I think this is reflected in the \"plausible coalitions\" game; the most plausible reason I could think of for the political divide to fall between these is lobbying on behalf of distilleries, suggesting that these form a natural cluster in policy-space. <br />&nbsp;<br />In case the idea can be more clearly grokked by examples, I'll post some in the comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FkzScn5byCs9PxGsA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MZz5WWMbT2yoXthqR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}], "voteCount": 23, "baseScore": 30, "extendedScore": null, "score": 6.9e-05, "legacy": true, "legacyId": "13132", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T22:31:53.118Z", "modifiedAt": null, "url": null, "title": "Hearsay, Double Hearsay, and Bayesian Updates", "slug": "hearsay-double-hearsay-and-bayesian-updates", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:34.411Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mass_Driver", "createdAt": "2010-03-30T15:48:06.997Z", "isAdmin": false, "displayName": "Mass_Driver"}, "userId": "62rKjNqA2LCJ6RthR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iyNLFkEEXoSrPYFng/hearsay-double-hearsay-and-bayesian-updates", "pageUrlRelative": "/posts/iyNLFkEEXoSrPYFng/hearsay-double-hearsay-and-bayesian-updates", "linkUrl": "https://www.lesswrong.com/posts/iyNLFkEEXoSrPYFng/hearsay-double-hearsay-and-bayesian-updates", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hearsay%2C%20Double%20Hearsay%2C%20and%20Bayesian%20Updates&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHearsay%2C%20Double%20Hearsay%2C%20and%20Bayesian%20Updates%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiyNLFkEEXoSrPYFng%2Fhearsay-double-hearsay-and-bayesian-updates%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hearsay%2C%20Double%20Hearsay%2C%20and%20Bayesian%20Updates%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiyNLFkEEXoSrPYFng%2Fhearsay-double-hearsay-and-bayesian-updates", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiyNLFkEEXoSrPYFng%2Fhearsay-double-hearsay-and-bayesian-updates", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1810, "htmlBody": "<p>Application of: <a href=\"/lw/jn/how_much_evidence_does_it_take/\">How Much Evidence Does It Take?</a></p>\n<p><em>(trigger warning: some description of domestic violence)</em></p>\n<p><strong>Summary: </strong>I discuss the strengths and weaknesses of one way that the American legal system tries to assess and cope with the unreliability of certain kinds of evidence. After explaining the relevant rules with references to a few recent famous cases and a non-notable case that I'm working on now, I briefly consider whether this part of the evidence code is above or below the <a href=\"/lw/1e/raising_the_sanity_waterline/\">sanity waterline</a>, and suggest an incremental improvement.</p>\n<p><a id=\"more\"></a></p>\n<hr />\n<p>Recently, I got to the point in my legal career where people are trusting me to write evidentiary briefs, i.e., to argue in front of a judge about what kinds of evidence are reliable enough to be safely presented to a jury. There is an odd division of epistemological labor in the American court system: <a href=\"http://www.gpo.gov/fdsys/pkg/GPO-CHRG-SCALIA/pdf/GPO-CHRG-SCALIA.pdf\">judges are thought</a>&nbsp;[page 90] to be better than juries at resisting passionate or manipulative oratory, and <a href=\"http://usgovinfo.about.com/library/fed/blfed83.htm\">juries are thought</a> to be better than judges at resisting bribery and (pre-existing) personal hatred. As a result, potentially inflammatory or unreliable evidence is presented first to a judge, who (much like one of Eliezer's <a href=\"/lw/y5/the_babyeating_aliens_18/\">Confessors</a>) is supposed to <a href=\"http://www.law.cornell.edu/rules/fre/rule_403\">sift the exhibit to see if normal people can handle it</a> without losing their tenuous grip on sanity. If and only if the evidence seems safe for ordinary human consumption, the judge will allow the lawyers to argue about that evidence in front of the jury. Otherwise, the evidence sits in a cardboard box in an unheated warehouse, safely away from the eyes of the jury, until it's time for an appeal.</p>\n<p><strong>The Hearsay Rule</strong></p>\n<p>By way of a concrete example, one <a href=\"http://federalevidence.com/pdf/2008/07-July/Davis_v._Washington.pdf\">famous recent case</a> featured a recorded 911 call made by a domestic violence victim to the emergency phone operator. The operator asked questions about the location and identity of the person who was accused of beating the caller. The caller answered the questions on tape, explicitly identifying her abuser as Mr. Adrian Martell Davis, and the answers were used first to find and arrest the suspect, and ultimately to convict him. The victim was apparently too intimidated to testify in open court, and so her recorded statement as to the name of her abuser was absolutely necessary to support a conviction -- no recording, no conviction. Under the <a href=\"http://www.archive.org/stream/statetrialsofmar00harrrich/statetrialsofmar00harrrich_djvu.txt\">400-year-old hearsay rule</a>, recorded testimony typically is <strong>not</strong> allowed to be presented to a jury -- courts are concerned that the person giving the recorded statement might be pressured by the police in ways that wouldn't show up on tape, and that allowing a witness to testify without showing up in court unfairly deprives the defendant of a chance to (a) cross-examine the witness, and (b) have the jury see any facial tics, body language, etc. that undercut the witness's credibility. In the 911 case, though, the Court faced a straight choice between finding an exception to the hearsay rule and letting an apparent abuser go free.</p>\n<p>In making this choice, the US Supreme Court <a href=\"/lw/js/the_bottom_line/\">managed to ignore</a> a variety of emotionally salient but epistemologically irrelevant distractions, such as the seriousness of the crime, the relative helplessness of the victim, and the respectability of the 911 operator. Instead, the Court focused on the purpose for which the 911 statements were obtained. If the statements were obtained to help gather information needed to safely resolve an ongoing emergency, they could be used at trial. If the statements, however, were obtained to gather information about a past event, they could *not* be used at trial.</p>\n<p>The theory supporting this distinction seems to have been that the right to cross-examine and the right to have the jury see body language are fungible elements of a more general reliability test. A stranger's assertion, without more, could be true or could be false. It doesn't count as very much evidence. To turn an assertion into enough evidence to convict someone beyond a reasonable doubt, you need to show that the assertion comes with \"indicia of reliability.\" Two of these indicia are cross-examination and body language -- if a story checks out despite a vigorous unfriendly interview and the peer pressure of having to tell the story while physically in the room with other people from your community, then that's pretty good evidence. But you might have reasons to believe a story even if you don't get cross-examination or body language. In the case of the 911 call, one might think that the caller had a strong motive to tell the truth, because if she didn't, then the police would go looking for the wrong guy, and her abuser would come find her and continue hurting her. Similarly, one might think that the operators had a strong motive to ask fair, non-leading questions, because of they didn't get the right answer, then the police might show up in the wrong neighborhood or with the wrong expectations, and there could be an unnecessary firefight. Finally, one could argue that a recorded statement made as events were unfolding is inherently more reliable (in some ways) than a narrative given months or years after the event; human memory gets corrupted faster than 8-track tapes.</p>\n<p>Some combination of these factors convinced the Court to admit the evidence. <a href=\"http://en.wikipedia.org/wiki/Crawford_v._Washington\">Other</a>, <a href=\"http://en.wikipedia.org/wiki/Ohio_v._Roberts\">very</a> <a href=\"http://en.wikipedia.org/wiki/Michigan_v._Bryant\">similar</a> cases have been decided differently. Whether they got that particular decision right or wrong, though, the framework of \"indicia of reliability\" is <a href=\"http://www.law.cornell.edu/rules/fre/rule_803\">hard-coded</a> into American evidence law, especially for civil cases. If you want to present evidence to a jury based on a statement that was made outside of court, you have to give at least one reason why the statement is nevertheless reliable.</p>\n<p><strong>Double and Triple Hearsay</strong></p>\n<p>Here's where things really get interesting: if your out-of-court statement quotes another out-of-court statement, the evidence is called \"double hearsay,\" and you need to independently verify each statement. If any link in the chain breaks, the whole document gets excluded. For example, in the case I'm working on now, the defendants want to show the jury a report filled out by California's Occupational Health and Safety Administration (\"OSHA\"). The OSHA report is based almost entirely on an accident report form filled out by a private corporation. That report form, in turn, is based almost entirely on an informal interview of the only eyewitness to an accident. So the defendants can use the OSHA report if and only if the OSHA report, the accident report, and the informal interview are all reliable. Use&nbsp; <span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">A &harr; (A &and; B &and; C)</span>&nbsp;are reliable.</p>\n<p>To try to qualify the OSHA report, the defendants are arguing that the OSHA report is reliable under the public record exception to the hearsay rule, meaning that the public officials who prepared it had a stronger interest in accurately reporting public information than they did in the outcome of the accident victim's private case. To get the accident report form in, the defendants are arguing that it is reliable under the business record exception to the hearsay rule, meaning that the corporate officials who prepared it had a stronger interest in making sure their company had access to accurate information about safety risks than they did in the outcome of any one customer's lawsuit. As for the informal interview...well, I honestly have no idea how they plan to justify its reliability. But, then again, I'm biased. My professional interest lies in making sure that the whole string of unhelpful quotations stays in a cardboard box in a dank garage, far away from any juries.</p>\n<p><strong>Do the Rules Work?</strong></p>\n<p>So far, I've been pleasantly surprised at how well the American legal system handles some of these challenges. The fact that we have a two-tiered system of evaluating evidence at all is a cut above average -- imagine, e.g., the doctor who examines you taking notes on your condition, filtering out any subjective comments you make about how you're sure it's just a cold, and reporting only your objective symptoms to a second doctor, who then renders a diagnosis. Or imagine a team of business consultants who interview a Fortune 500 company's leadership team, and then pass their written notes back to a team at HQ (who has never met the executives) so that HQ can catch any obvious mistakes in reasoning before sending out recommendations. We know, intellectually, that meeting people tends to make us <a href=\"http://www.sciencedaily.com/articles/e/exposure_effect.htm\">friendlier toward them</a> and <a href=\"http://en.wikipedia.org/wiki/Regulatory_capture\">more likely to adopt their point of view</a>&nbsp;even if we encounter no Bayesian evidence that increases the plausibility of their opinions, but our institutions rarely take steps to guard against that bias.</p>\n<p>I think my biggest criticism of the American evidence code is that it doesn't account for <a href=\"/lw/3be/confidence_levels_inside_and_outside_an_argument/\">uncertainty in the model</a>. For instance,&nbsp;if I read the headline on a piece of science journalism saying that (e.g.) coffee consumption reduces the risk of prostate cancer, or that receiving spankings in childhood is negatively correlated with conscientiousness as an adult, there are least six layers of 'hearsay' -- I might have misunderstood the headline, the headline might have mis-summarized the article, the article might have misquoted the scientist, the scientist might have misinterpreted the recorded data, the recorded data might not faithfully reflect what actually happened during the experiment, and the experiment might not faithfully replicate the real-world conditions that interest us.</p>\n<p>Even if I can articulate plausible reasons why each step in the transmission of information was \"reliable,\" I should be very skeptical that my *model* of the transmission is accurate. I only have to be wrong about one of the six steps for my estimate of the information's plausibility to be untrustworthy. If the information would only provide a few decibels of evidence even if it were perfectly reliable, then trying to calculate how many points a semi-reliable piece of evidence is worth can fail because of a low signal-to-noise ratio. E.g., suppose I learn that neither the suspect nor the actual criminal were redheads - I might be absolutely certain of this new piece of information, but that's still <a href=\"/lw/jo/einsteins_arrogance/\">nowhere near enough evidence</a> to support a conviction. If instead I learn that there is probably something like a 60% chance that neither the suspect nor the criminal had red hair, that datum really doesn't tell me anything at all -- the info shouldn't shift my prior enough for my prior to be noticeably different.</p>\n<p>Although courts are allowed to consider the extent to which an unduly long chain of inferences makes evidence less \"trustworthy,\" I think that on balance decisions would be more accurate if there were a firm limit -- say, three layers -- beyond which evidence was simply inadmissible as a matter of law. If A says that B says that C says that D shot someone, then no matter how reliable we think A, B, and C are, we should probably keep that evidence away from the jury unless we can haul at least one of B, C, or D into court to answer cross-examination.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 1, "LhX3F2SvGDarZCuh6": 1, "wGGAjTfXZBatQkft5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iyNLFkEEXoSrPYFng", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 60, "baseScore": 68, "extendedScore": null, "score": 0.000149, "legacy": true, "legacyId": "13041", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 68, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Application of: <a href=\"/lw/jn/how_much_evidence_does_it_take/\">How Much Evidence Does It Take?</a></p>\n<p><em>(trigger warning: some description of domestic violence)</em></p>\n<p><strong>Summary: </strong>I discuss the strengths and weaknesses of one way that the American legal system tries to assess and cope with the unreliability of certain kinds of evidence. After explaining the relevant rules with references to a few recent famous cases and a non-notable case that I'm working on now, I briefly consider whether this part of the evidence code is above or below the <a href=\"/lw/1e/raising_the_sanity_waterline/\">sanity waterline</a>, and suggest an incremental improvement.</p>\n<p><a id=\"more\"></a></p>\n<hr>\n<p>Recently, I got to the point in my legal career where people are trusting me to write evidentiary briefs, i.e., to argue in front of a judge about what kinds of evidence are reliable enough to be safely presented to a jury. There is an odd division of epistemological labor in the American court system: <a href=\"http://www.gpo.gov/fdsys/pkg/GPO-CHRG-SCALIA/pdf/GPO-CHRG-SCALIA.pdf\">judges are thought</a>&nbsp;[page 90] to be better than juries at resisting passionate or manipulative oratory, and <a href=\"http://usgovinfo.about.com/library/fed/blfed83.htm\">juries are thought</a> to be better than judges at resisting bribery and (pre-existing) personal hatred. As a result, potentially inflammatory or unreliable evidence is presented first to a judge, who (much like one of Eliezer's <a href=\"/lw/y5/the_babyeating_aliens_18/\">Confessors</a>) is supposed to <a href=\"http://www.law.cornell.edu/rules/fre/rule_403\">sift the exhibit to see if normal people can handle it</a> without losing their tenuous grip on sanity. If and only if the evidence seems safe for ordinary human consumption, the judge will allow the lawyers to argue about that evidence in front of the jury. Otherwise, the evidence sits in a cardboard box in an unheated warehouse, safely away from the eyes of the jury, until it's time for an appeal.</p>\n<p><strong id=\"The_Hearsay_Rule\">The Hearsay Rule</strong></p>\n<p>By way of a concrete example, one <a href=\"http://federalevidence.com/pdf/2008/07-July/Davis_v._Washington.pdf\">famous recent case</a> featured a recorded 911 call made by a domestic violence victim to the emergency phone operator. The operator asked questions about the location and identity of the person who was accused of beating the caller. The caller answered the questions on tape, explicitly identifying her abuser as Mr. Adrian Martell Davis, and the answers were used first to find and arrest the suspect, and ultimately to convict him. The victim was apparently too intimidated to testify in open court, and so her recorded statement as to the name of her abuser was absolutely necessary to support a conviction -- no recording, no conviction. Under the <a href=\"http://www.archive.org/stream/statetrialsofmar00harrrich/statetrialsofmar00harrrich_djvu.txt\">400-year-old hearsay rule</a>, recorded testimony typically is <strong>not</strong> allowed to be presented to a jury -- courts are concerned that the person giving the recorded statement might be pressured by the police in ways that wouldn't show up on tape, and that allowing a witness to testify without showing up in court unfairly deprives the defendant of a chance to (a) cross-examine the witness, and (b) have the jury see any facial tics, body language, etc. that undercut the witness's credibility. In the 911 case, though, the Court faced a straight choice between finding an exception to the hearsay rule and letting an apparent abuser go free.</p>\n<p>In making this choice, the US Supreme Court <a href=\"/lw/js/the_bottom_line/\">managed to ignore</a> a variety of emotionally salient but epistemologically irrelevant distractions, such as the seriousness of the crime, the relative helplessness of the victim, and the respectability of the 911 operator. Instead, the Court focused on the purpose for which the 911 statements were obtained. If the statements were obtained to help gather information needed to safely resolve an ongoing emergency, they could be used at trial. If the statements, however, were obtained to gather information about a past event, they could *not* be used at trial.</p>\n<p>The theory supporting this distinction seems to have been that the right to cross-examine and the right to have the jury see body language are fungible elements of a more general reliability test. A stranger's assertion, without more, could be true or could be false. It doesn't count as very much evidence. To turn an assertion into enough evidence to convict someone beyond a reasonable doubt, you need to show that the assertion comes with \"indicia of reliability.\" Two of these indicia are cross-examination and body language -- if a story checks out despite a vigorous unfriendly interview and the peer pressure of having to tell the story while physically in the room with other people from your community, then that's pretty good evidence. But you might have reasons to believe a story even if you don't get cross-examination or body language. In the case of the 911 call, one might think that the caller had a strong motive to tell the truth, because if she didn't, then the police would go looking for the wrong guy, and her abuser would come find her and continue hurting her. Similarly, one might think that the operators had a strong motive to ask fair, non-leading questions, because of they didn't get the right answer, then the police might show up in the wrong neighborhood or with the wrong expectations, and there could be an unnecessary firefight. Finally, one could argue that a recorded statement made as events were unfolding is inherently more reliable (in some ways) than a narrative given months or years after the event; human memory gets corrupted faster than 8-track tapes.</p>\n<p>Some combination of these factors convinced the Court to admit the evidence. <a href=\"http://en.wikipedia.org/wiki/Crawford_v._Washington\">Other</a>, <a href=\"http://en.wikipedia.org/wiki/Ohio_v._Roberts\">very</a> <a href=\"http://en.wikipedia.org/wiki/Michigan_v._Bryant\">similar</a> cases have been decided differently. Whether they got that particular decision right or wrong, though, the framework of \"indicia of reliability\" is <a href=\"http://www.law.cornell.edu/rules/fre/rule_803\">hard-coded</a> into American evidence law, especially for civil cases. If you want to present evidence to a jury based on a statement that was made outside of court, you have to give at least one reason why the statement is nevertheless reliable.</p>\n<p><strong id=\"Double_and_Triple_Hearsay\">Double and Triple Hearsay</strong></p>\n<p>Here's where things really get interesting: if your out-of-court statement quotes another out-of-court statement, the evidence is called \"double hearsay,\" and you need to independently verify each statement. If any link in the chain breaks, the whole document gets excluded. For example, in the case I'm working on now, the defendants want to show the jury a report filled out by California's Occupational Health and Safety Administration (\"OSHA\"). The OSHA report is based almost entirely on an accident report form filled out by a private corporation. That report form, in turn, is based almost entirely on an informal interview of the only eyewitness to an accident. So the defendants can use the OSHA report if and only if the OSHA report, the accident report, and the informal interview are all reliable. Use&nbsp; <span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">A \u2194 (A \u2227 B \u2227 C)</span>&nbsp;are reliable.</p>\n<p>To try to qualify the OSHA report, the defendants are arguing that the OSHA report is reliable under the public record exception to the hearsay rule, meaning that the public officials who prepared it had a stronger interest in accurately reporting public information than they did in the outcome of the accident victim's private case. To get the accident report form in, the defendants are arguing that it is reliable under the business record exception to the hearsay rule, meaning that the corporate officials who prepared it had a stronger interest in making sure their company had access to accurate information about safety risks than they did in the outcome of any one customer's lawsuit. As for the informal interview...well, I honestly have no idea how they plan to justify its reliability. But, then again, I'm biased. My professional interest lies in making sure that the whole string of unhelpful quotations stays in a cardboard box in a dank garage, far away from any juries.</p>\n<p><strong id=\"Do_the_Rules_Work_\">Do the Rules Work?</strong></p>\n<p>So far, I've been pleasantly surprised at how well the American legal system handles some of these challenges. The fact that we have a two-tiered system of evaluating evidence at all is a cut above average -- imagine, e.g., the doctor who examines you taking notes on your condition, filtering out any subjective comments you make about how you're sure it's just a cold, and reporting only your objective symptoms to a second doctor, who then renders a diagnosis. Or imagine a team of business consultants who interview a Fortune 500 company's leadership team, and then pass their written notes back to a team at HQ (who has never met the executives) so that HQ can catch any obvious mistakes in reasoning before sending out recommendations. We know, intellectually, that meeting people tends to make us <a href=\"http://www.sciencedaily.com/articles/e/exposure_effect.htm\">friendlier toward them</a> and <a href=\"http://en.wikipedia.org/wiki/Regulatory_capture\">more likely to adopt their point of view</a>&nbsp;even if we encounter no Bayesian evidence that increases the plausibility of their opinions, but our institutions rarely take steps to guard against that bias.</p>\n<p>I think my biggest criticism of the American evidence code is that it doesn't account for <a href=\"/lw/3be/confidence_levels_inside_and_outside_an_argument/\">uncertainty in the model</a>. For instance,&nbsp;if I read the headline on a piece of science journalism saying that (e.g.) coffee consumption reduces the risk of prostate cancer, or that receiving spankings in childhood is negatively correlated with conscientiousness as an adult, there are least six layers of 'hearsay' -- I might have misunderstood the headline, the headline might have mis-summarized the article, the article might have misquoted the scientist, the scientist might have misinterpreted the recorded data, the recorded data might not faithfully reflect what actually happened during the experiment, and the experiment might not faithfully replicate the real-world conditions that interest us.</p>\n<p>Even if I can articulate plausible reasons why each step in the transmission of information was \"reliable,\" I should be very skeptical that my *model* of the transmission is accurate. I only have to be wrong about one of the six steps for my estimate of the information's plausibility to be untrustworthy. If the information would only provide a few decibels of evidence even if it were perfectly reliable, then trying to calculate how many points a semi-reliable piece of evidence is worth can fail because of a low signal-to-noise ratio. E.g., suppose I learn that neither the suspect nor the actual criminal were redheads - I might be absolutely certain of this new piece of information, but that's still <a href=\"/lw/jo/einsteins_arrogance/\">nowhere near enough evidence</a> to support a conviction. If instead I learn that there is probably something like a 60% chance that neither the suspect nor the criminal had red hair, that datum really doesn't tell me anything at all -- the info shouldn't shift my prior enough for my prior to be noticeably different.</p>\n<p>Although courts are allowed to consider the extent to which an unduly long chain of inferences makes evidence less \"trustworthy,\" I think that on balance decisions would be more accurate if there were a firm limit -- say, three layers -- beyond which evidence was simply inadmissible as a matter of law. If A says that B says that C says that D shot someone, then no matter how reliable we think A, B, and C are, we should probably keep that evidence away from the jury unless we can haul at least one of B, C, or D into court to answer cross-examination.</p>", "sections": [{"title": "The Hearsay Rule", "anchor": "The_Hearsay_Rule", "level": 1}, {"title": "Double and Triple Hearsay", "anchor": "Double_and_Triple_Hearsay", "level": 1}, {"title": "Do the Rules Work?", "anchor": "Do_the_Rules_Work_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "107 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 107, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["nj8JKFoLSMEmD3RGp", "XqmjdBKa4ZaXJtNmf", "n5TqCuizyJDfAPjkr", "34XxbRFe54FycoCDw", "GrtbTAPfkJa4D6jjH", "MwQRucYo6BZZwjKE7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-16T23:47:16.393Z", "modifiedAt": null, "url": null, "title": "[link] 101 Fascinating Brain Blogs", "slug": "link-101-fascinating-brain-blogs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:26.491Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Curiouskid", "createdAt": "2011-05-13T23:30:04.967Z", "isAdmin": false, "displayName": "Curiouskid"}, "userId": "Y4xxvuP743fwKcZQY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3XKKFnEiboxN6Rwtz/link-101-fascinating-brain-blogs", "pageUrlRelative": "/posts/3XKKFnEiboxN6Rwtz/link-101-fascinating-brain-blogs", "linkUrl": "https://www.lesswrong.com/posts/3XKKFnEiboxN6Rwtz/link-101-fascinating-brain-blogs", "postedAtFormatted": "Thursday, February 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20101%20Fascinating%20Brain%20Blogs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20101%20Fascinating%20Brain%20Blogs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3XKKFnEiboxN6Rwtz%2Flink-101-fascinating-brain-blogs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20101%20Fascinating%20Brain%20Blogs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3XKKFnEiboxN6Rwtz%2Flink-101-fascinating-brain-blogs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3XKKFnEiboxN6Rwtz%2Flink-101-fascinating-brain-blogs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p><a href=\"http://oedb.org/library/features/101_fascinating_brain_blogs\">A pretty interesting list</a>&nbsp;of psychology blogs. One of my favorite blogs (<a href=\"http://mindhacks.com/\">Mind Hacks</a>) was listed (so the others on the list must be good too. Right?). &nbsp;<br /><br />Also,</p>\n<p>Does anybody know of any good textbooks on applied cognitive psychology?</p>\n<p>For memory-Something that would put things like SRS in context with other things like the <a href=\"http://psychology.about.com/od/cognitivepsychology/tp/explanations-for-forgetting.htm\">reasons we forget things</a>, but more in more depth than blog posts? Or do you think that getting a textbook on the subject wouldn't be worthwhile because most of the low-hanging fruits can be grasped through blog posts?&nbsp;<br /><br />For emotions-Any good/practical introductions to CBT?<br /><br /><br />Do you think we should start up a book recommendations recurring thread?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3XKKFnEiboxN6Rwtz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -7, "extendedScore": null, "score": 8.501583332595939e-07, "legacy": true, "legacyId": "13134", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T00:48:29.934Z", "modifiedAt": null, "url": null, "title": "Epistemic security: example from experimental physics", "slug": "epistemic-security-example-from-experimental-physics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.120Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stabilizer", "createdAt": "2011-12-02T09:36:56.841Z", "isAdmin": false, "displayName": "Stabilizer"}, "userId": "Qa3pLZx3o2TApyfgq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hRzJvpLzTLHMNKdfZ/epistemic-security-example-from-experimental-physics", "pageUrlRelative": "/posts/hRzJvpLzTLHMNKdfZ/epistemic-security-example-from-experimental-physics", "linkUrl": "https://www.lesswrong.com/posts/hRzJvpLzTLHMNKdfZ/epistemic-security-example-from-experimental-physics", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Epistemic%20security%3A%20example%20from%20experimental%20physics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEpistemic%20security%3A%20example%20from%20experimental%20physics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRzJvpLzTLHMNKdfZ%2Fepistemic-security-example-from-experimental-physics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Epistemic%20security%3A%20example%20from%20experimental%20physics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRzJvpLzTLHMNKdfZ%2Fepistemic-security-example-from-experimental-physics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRzJvpLzTLHMNKdfZ%2Fepistemic-security-example-from-experimental-physics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 467, "htmlBody": "<p>I was reading the introduction to a textbook on electrodynamics (<a href=\"http://www.amazon.com/Classical-Electrodynamics-Third-David-Jackson/dp/047130932X\">J.D. Jackson</a>), and in there was a description of an experiment designed to measure the exponent of the inverse square force law that governs forces between charges (Coulomb&rsquo;s law). So, the experiment was designed to detect how close the exponent is to 2, and put error bars on the value of the exponent. <a href=\"http://prl.aps.org/abstract/PRL/v26/i12/p721_1\">The experiment</a> was performed in 1971 and established that if the exponent was not 2, then the error had to be in the 15th or greater decimal place! So far, so good...</p>\n<p><strong></strong>So, the experimental design seemed to use all kinds of fancy modern electronic equipment. Here&rsquo;s what bugged me: they were testing the oldest law in electrodynamics, using all this technology, which was based on over a century of development in the theory of electromagnetism. It reeked of circularity to me. You build an instrument using a set of laws, and you use those instruments to test one of the laws? It&rsquo;s almost like you use a map to build a territory and use that territory to check the map. What&rsquo;s going on here?</p>\n<p>So, trying to exercise the virtue of scholarship,  I went on the Stanford Encyclopedia of Philosophy, and read the article on <a href=\"http://plato.stanford.edu/entries/physics-experiment/\">Experiment in Physics</a> (highly recommended). And I found the resolution in this line:</p>\n<blockquote>\n<p>Instruments create an invariant relationship between their operations and the world...When our theories change, we may conceive of the significance of the instrument and the world with which it is interacting differently, and the datum of an instrument may change in significance, but the datum can nonetheless stay the same, and will typically be expected to do so.</p>\n</blockquote>\n<p>So, it&rsquo;s like if you use a map of the territory to build a road from A to  B, and then you later realize that the map that you used to build the road was wrong. But the road still takes you from from A to B! So it doesn&rsquo;t matter if you built it with the wrong map, it still works. So in the context of the Coulomb&rsquo;s law measurement, as long as you&rsquo;ve secured the input-output characteristics of the fancy equipment you&rsquo;re using, it doesn&rsquo;t matter if they were built using a wrong theory. So, there is no circularity in testing the theory which you used to build the instrument, since the instrument is going to follow reality no matter what.</p>\n<p>So, experimental physics is very epistemically secure. What about other fields? For sure, other fields dealing with understanding reality have one reality to deal with. But the aspect of reality they&rsquo;re interested in maybe much more fragile. And for an truly accurate map of the territory, you need to take into account how just your presence is changing the territory. <a href=\"/lw/1ws/the_importance_of_goodharts_law\">Goodhart&rsquo;s law</a> in economics is the perfect example.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hRzJvpLzTLHMNKdfZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 8.501824666171045e-07, "legacy": true, "legacyId": "13143", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YtvZxRpZjcFNwJecS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T00:55:11.064Z", "modifiedAt": null, "url": null, "title": "Seeking education", "slug": "seeking-education", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.998Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "APMason", "createdAt": "2011-08-30T22:24:06.796Z", "isAdmin": false, "displayName": "APMason"}, "userId": "2QGaDhC6QbaR5sLh8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NowDgDpHF5WYnoyMG/seeking-education", "pageUrlRelative": "/posts/NowDgDpHF5WYnoyMG/seeking-education", "linkUrl": "https://www.lesswrong.com/posts/NowDgDpHF5WYnoyMG/seeking-education", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seeking%20education&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeeking%20education%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNowDgDpHF5WYnoyMG%2Fseeking-education%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seeking%20education%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNowDgDpHF5WYnoyMG%2Fseeking-education", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNowDgDpHF5WYnoyMG%2Fseeking-education", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 164, "htmlBody": "<p>This will not be a long post; I have a simple question to ask: if you wanted to educate yourself to graduate level in mathematics, but didn't actually want to go to university, what would you do? I would ask for text-book recommendations, but I don't want to limit your responses (however, bear in mind that the wikipedia articles on, say, cardinality or well-ordering go over my head &ndash; they may skim my hairline, but over they go). Also bear in mind that while I personally have A-levels (British qualifications) in both Maths and Further Maths (which is to say, I know some calculus at least), there are probably plenty of people on lesswrong who don't and who desire the same information &ndash; so assume as much ignorance as you feel necessary (it's a shame, actually, that there isn't a sequence here on lesswrong for maths). What do you advise (if you think the query ill-defined, I would like to know that as well)?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NowDgDpHF5WYnoyMG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 12, "extendedScore": null, "score": 2.5e-05, "legacy": true, "legacyId": "13144", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T04:33:00.064Z", "modifiedAt": null, "url": null, "title": "Water Fluoridation", "slug": "water-fluoridation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:59.053Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexei", "createdAt": "2010-08-02T15:14:11.411Z", "isAdmin": false, "displayName": "Alexei"}, "userId": "CD3DC5D7GHtgBmxz5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8fg8TxqGWQYpJcfcR/water-fluoridation", "pageUrlRelative": "/posts/8fg8TxqGWQYpJcfcR/water-fluoridation", "linkUrl": "https://www.lesswrong.com/posts/8fg8TxqGWQYpJcfcR/water-fluoridation", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Water%20Fluoridation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWater%20Fluoridation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fg8TxqGWQYpJcfcR%2Fwater-fluoridation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Water%20Fluoridation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fg8TxqGWQYpJcfcR%2Fwater-fluoridation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fg8TxqGWQYpJcfcR%2Fwater-fluoridation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 91, "htmlBody": "<p>I've recently learned about alleged dangers to drinking fluoridated water. Amongst them is increased rate of cancer and lowering of IQ. Interestingly enough, <a href=\"http://en.wikipedia.org/wiki/Water_fluoridation\">wiki</a> doesn't mention this at all, but searching for it brings up a decent amount of (what look like) reasonable results. I am really curious about this, and want to learn more about this. I was wondering if anyone on LW has already conducted a research literature investigation on this topic, or if you just have tips/advice on what to pay attention to when I read the literature.</p>\n<p>Thanks!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8fg8TxqGWQYpJcfcR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -2, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "13155", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T14:45:17.024Z", "modifiedAt": null, "url": null, "title": "A defense of formal philosophy", "slug": "a-defense-of-formal-philosophy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:33.897Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iNZx77ybzF27CQMn2/a-defense-of-formal-philosophy", "pageUrlRelative": "/posts/iNZx77ybzF27CQMn2/a-defense-of-formal-philosophy", "linkUrl": "https://www.lesswrong.com/posts/iNZx77ybzF27CQMn2/a-defense-of-formal-philosophy", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20defense%20of%20formal%20philosophy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20defense%20of%20formal%20philosophy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNZx77ybzF27CQMn2%2Fa-defense-of-formal-philosophy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20defense%20of%20formal%20philosophy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNZx77ybzF27CQMn2%2Fa-defense-of-formal-philosophy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNZx77ybzF27CQMn2%2Fa-defense-of-formal-philosophy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 369, "htmlBody": "<p><a href=\"http://gregorywheeler.org/\">Gregory Wheeler</a> has written an <a href=\"http://philsci-archive.pitt.edu/8986/4/Wheeler_FE3.pdf\">eloquent new defense of formal philosophy</a>.</p>\n<p>Quotes:</p>\n<blockquote>\n<p>\n<p>...formal epistemology is an interdisciplinary research program that includes&nbsp;work by philosophers, mathematicians, computer scientists, statisticians,&nbsp;psychologists, operations researchers, and economists which aims to give&nbsp;mathematical and sometimes computational representations of, along with sound strategies for reasoning about, knowledge, belief, judgment and decision making.</p>\n<p>...</p>\n<p>Why... bother being so formal?&nbsp;[Rich] Thomason,&nbsp;commenting on philosophers who view formal methods as a distraction to real&nbsp;philosophical advancement, observed that the only real advantage that we have&nbsp;over the great philosophers of the past are the new methods that we have at our&nbsp;disposal. Probability. First-order logic. Calculus. The number zero. It is hard to&nbsp;imagine improving on Aristotle without resorting to methods that were simply&nbsp;unavailable to him. Knowing just this much about history, a better question is this:&nbsp;why limit your options?</p>\n<p>...</p>\n<p>The problem with aspiring to counterexample-proof philosophy without&nbsp;taking into account either formal or empirical constraints is that the exercise can&nbsp;quickly devolve into a battle of wits rather than a battle of ideas. And the problem is&nbsp;only compounded by pseudo-formal philosophy &mdash; the unfortunate practice of using&nbsp;formal logic informally &mdash; because this encourages philosophers to describe rather&nbsp;than define the fundamental operations of their theories. Memories are &lsquo;accessed in&nbsp;the right way&rsquo;; justified beliefs are &lsquo;based&rsquo; on one&rsquo;s &lsquo;evidence&rsquo;; coherent beliefs&nbsp;&lsquo;hang together&rsquo;. But, like a bump in a rug carefully pushed from one corner of a&nbsp;crowded room to another, this reliance on pseudo-formalisms to avoid any and all&nbsp;counterexamples inevitably means that the hard, unsolved philosophical problems&nbsp;are artfully avoided rather than addressed. At its worst, rampant counterexample avoidance turns philosophy into little more than a performance art.</p>\n<p>\n<p>But, one way to arrest this slide is by constraining epistemological theories&nbsp;by a combination of empirical evidence and formal models. For if you replace those&nbsp;fudged terms with a formal model, or a provably correct algorithm, and hem in&nbsp;imagination by known empirical constraints, then if a theory is successful in&nbsp;explaining a range of cases, that hard won success can be weighed against the&nbsp;theory&rsquo;s failings. In other words, if we set aspirations for epistemology higher than conceptual analysis, that will open more room to judge success and failure than the&nbsp;all-or-nothing stakes of counterexample avoidance.</p>\n</p>\n</p>\n</blockquote>\n<p>See also: <a href=\"/lw/3n0/an_overview_of_formal_epistemology_links/\">An Overview of Formal Epistemology</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iNZx77ybzF27CQMn2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 17, "extendedScore": null, "score": 8.505124259533649e-07, "legacy": true, "legacyId": "13168", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BXot7wxNbipyM749o"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T15:12:36.684Z", "modifiedAt": null, "url": null, "title": "[LINK] What\u2019s New? Exuberance for Novelty Has Benefits", "slug": "link-what-s-new-exuberance-for-novelty-has-benefits", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.398Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fKDp3Zn2Hty6R8S3b/link-what-s-new-exuberance-for-novelty-has-benefits", "pageUrlRelative": "/posts/fKDp3Zn2Hty6R8S3b/link-what-s-new-exuberance-for-novelty-has-benefits", "linkUrl": "https://www.lesswrong.com/posts/fKDp3Zn2Hty6R8S3b/link-what-s-new-exuberance-for-novelty-has-benefits", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20What%E2%80%99s%20New%3F%20Exuberance%20for%20Novelty%20Has%20Benefits&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20What%E2%80%99s%20New%3F%20Exuberance%20for%20Novelty%20Has%20Benefits%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfKDp3Zn2Hty6R8S3b%2Flink-what-s-new-exuberance-for-novelty-has-benefits%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20What%E2%80%99s%20New%3F%20Exuberance%20for%20Novelty%20Has%20Benefits%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfKDp3Zn2Hty6R8S3b%2Flink-what-s-new-exuberance-for-novelty-has-benefits", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfKDp3Zn2Hty6R8S3b%2Flink-what-s-new-exuberance-for-novelty-has-benefits", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.nytimes.com/2012/02/14/science/novelty-seeking-neophilia-can-be-a-predictor-of-well-being.html\">http://www.nytimes.com/2012/02/14/science/novelty-seeking-neophilia-can-be-a-predictor-of-well-being.html</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fKDp3Zn2Hty6R8S3b", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -4, "extendedScore": null, "score": 8.505232055681906e-07, "legacy": true, "legacyId": "13169", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T16:01:13.060Z", "modifiedAt": null, "url": null, "title": "Hassa Deega Ebowai or the paradox of religiousness in front of adversity", "slug": "hassa-deega-ebowai-or-the-paradox-of-religiousness-in-front", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.724Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "oXGTijwhjZB8cnJ3W", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Js7TsqGjkJED6MvfK/hassa-deega-ebowai-or-the-paradox-of-religiousness-in-front", "pageUrlRelative": "/posts/Js7TsqGjkJED6MvfK/hassa-deega-ebowai-or-the-paradox-of-religiousness-in-front", "linkUrl": "https://www.lesswrong.com/posts/Js7TsqGjkJED6MvfK/hassa-deega-ebowai-or-the-paradox-of-religiousness-in-front", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hassa%20Deega%20Ebowai%20or%20the%20paradox%20of%20religiousness%20in%20front%20of%20adversity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHassa%20Deega%20Ebowai%20or%20the%20paradox%20of%20religiousness%20in%20front%20of%20adversity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJs7TsqGjkJED6MvfK%2Fhassa-deega-ebowai-or-the-paradox-of-religiousness-in-front%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hassa%20Deega%20Ebowai%20or%20the%20paradox%20of%20religiousness%20in%20front%20of%20adversity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJs7TsqGjkJED6MvfK%2Fhassa-deega-ebowai-or-the-paradox-of-religiousness-in-front", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJs7TsqGjkJED6MvfK%2Fhassa-deega-ebowai-or-the-paradox-of-religiousness-in-front", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 300, "htmlBody": "<p>Hasa Diga Ebowai ([\"Does it mean \"no worries for the rest of our lives?\"\" *\"Kinda\"*](<a href=\"http://www.youtube.com/watch?feature=endscreen&amp;NR=1&amp;v=AhxChl9bGl0\">http://www.youtube.com/watch?feature=endscreen&amp;NR=1&amp;v=AhxChl9bGl0</a>)) is a song from Trey Parker and Matt Stone's \"The Book of Mormon\", an affectionate parody of religion in general. A lot of the comedy in that song is drawn from the unexpectedness of the reaction to adversity displayed within. Do listen to it before proceeding.</p>\n<p>The stereotype is that, when troubled and in a position of weakness, where they have no power over their fates, humans tend to turn towards the LORD for consolation. Especially if the religion promises a good afterlife to the patient, meek and submissive, and a bad one to the defiant and insolent. Even when it doesn't (such as in most denominations of Judaism, AFAIK), people are encouraged to<em> not</em>&nbsp;\"curse His rotten\" name when everything goes wrong for them and they can't do anything about it (see book of Job).</p>\n<p>The other side of the stereotype is that, the more powerful, confident and knowledgeable humans become, the less religious they become. This can also be seen on the time axis of a single individual's existence when, young, they care little about sin and the afterlife, and, old, they do nothing but pray all day to make up for all the awful stuff they did (and there might be some genuinely awful behavior in there).</p>\n<p>So I've been trolling Wikipedia for examples of demographics and populations that would have commonly practiced the cursing of the LORD, but I only found reference to vikings doing that, in a \"I won't believe in you, but I will believe in me, and live by my own strength\" kind of way, which isn't exactly what I'm looking for.</p>\n<p>Does anyone here know anything about these different ways people react to adversity, and what they mean from a rationalistic standpoint?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Js7TsqGjkJED6MvfK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -6, "extendedScore": null, "score": 8.505423793162393e-07, "legacy": true, "legacyId": "13170", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T17:27:47.294Z", "modifiedAt": null, "url": null, "title": "Meetup : At the University of Chicago", "slug": "meetup-at-the-university-of-chicago", "viewCount": null, "lastCommentedAt": "2012-02-26T05:11:56.858Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6WhwZpKBRzKYMr4gD/meetup-at-the-university-of-chicago", "pageUrlRelative": "/posts/6WhwZpKBRzKYMr4gD/meetup-at-the-university-of-chicago", "linkUrl": "https://www.lesswrong.com/posts/6WhwZpKBRzKYMr4gD/meetup-at-the-university-of-chicago", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20At%20the%20University%20of%20Chicago&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20At%20the%20University%20of%20Chicago%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6WhwZpKBRzKYMr4gD%2Fmeetup-at-the-university-of-chicago%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20At%20the%20University%20of%20Chicago%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6WhwZpKBRzKYMr4gD%2Fmeetup-at-the-university-of-chicago", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6WhwZpKBRzKYMr4gD%2Fmeetup-at-the-university-of-chicago", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/79\">Chicago Meetup at the University of Chicago</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">25 February 2012 01:00:00PM (-0600)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1135 E. 57th Street Chicago, IL 60637</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>It's been a while since the last meetup, so we're having another one!</p>\n<p>It'll be at the University of Chicago, in Hutch Commons from 1-4 PM.</p>\n<p>The building itself is known as Reynold's Club, and Hutch Commons is a dining area found at the first door on the right as you walk in.</p>\n<p>Go to the Chicago list host for my contact info if you have trouble finding us, or just PM me. I'll try to get a center table and a LW sign.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/79\">Chicago Meetup at the University of Chicago</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6WhwZpKBRzKYMr4gD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "13171", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Chicago_Meetup_at_the_University_of_Chicago\">Discussion article for the meetup : <a href=\"/meetups/79\">Chicago Meetup at the University of Chicago</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">25 February 2012 01:00:00PM (-0600)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1135 E. 57th Street Chicago, IL 60637</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>It's been a while since the last meetup, so we're having another one!</p>\n<p>It'll be at the University of Chicago, in Hutch Commons from 1-4 PM.</p>\n<p>The building itself is known as Reynold's Club, and Hutch Commons is a dining area found at the first door on the right as you walk in.</p>\n<p>Go to the Chicago list host for my contact info if you have trouble finding us, or just PM me. I'll try to get a center table and a LW sign.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Chicago_Meetup_at_the_University_of_Chicago1\">Discussion article for the meetup : <a href=\"/meetups/79\">Chicago Meetup at the University of Chicago</a></h2>", "sections": [{"title": "Discussion article for the meetup : Chicago Meetup at the University of Chicago", "anchor": "Discussion_article_for_the_meetup___Chicago_Meetup_at_the_University_of_Chicago", "level": 1}, {"title": "Discussion article for the meetup : Chicago Meetup at the University of Chicago", "anchor": "Discussion_article_for_the_meetup___Chicago_Meetup_at_the_University_of_Chicago1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2012-02-17T17:27:47.294Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T17:57:06.548Z", "modifiedAt": null, "url": null, "title": "Meetup : Buenos Aires meetup: Saturday, February 25th, 4pm", "slug": "meetup-buenos-aires-meetup-saturday-february-25th-4pm", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:40.308Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pablo_Stafforini", "createdAt": "2009-03-24T12:56:00.130Z", "isAdmin": false, "displayName": "Pablo"}, "userId": "W7ETRtvRMqYetyQE9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4jphBJSQkzs4wz7QQ/meetup-buenos-aires-meetup-saturday-february-25th-4pm", "pageUrlRelative": "/posts/4jphBJSQkzs4wz7QQ/meetup-buenos-aires-meetup-saturday-february-25th-4pm", "linkUrl": "https://www.lesswrong.com/posts/4jphBJSQkzs4wz7QQ/meetup-buenos-aires-meetup-saturday-february-25th-4pm", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Buenos%20Aires%20meetup%3A%20Saturday%2C%20February%2025th%2C%204pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Buenos%20Aires%20meetup%3A%20Saturday%2C%20February%2025th%2C%204pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4jphBJSQkzs4wz7QQ%2Fmeetup-buenos-aires-meetup-saturday-february-25th-4pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Buenos%20Aires%20meetup%3A%20Saturday%2C%20February%2025th%2C%204pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4jphBJSQkzs4wz7QQ%2Fmeetup-buenos-aires-meetup-saturday-february-25th-4pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4jphBJSQkzs4wz7QQ%2Fmeetup-buenos-aires-meetup-saturday-february-25th-4pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 126, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7a'>Buenos Aires meetup: Saturday, February 25th, 4pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">25 February 2012 04:00:00PM (-0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Starbucks Coffe, Florida 1, Buenos Aires, Argentina</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This will be our second Buenos Aires LessWrong meetup.  Our nominal discussion topic will be cognitive biases, though we'll keep things flexible so that the conversation can move naturally towards other topics of interest and relevance.  If you read and like this blog. and live in BA or just happen to be visiting the city, do join us.  It will be a great opportunity to meet like-minded folks in the area.  We will be sitting upstairs; a copy of Greg Egan's <em>Diaspora</em> will be displayed at our table.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7a'>Buenos Aires meetup: Saturday, February 25th, 4pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4jphBJSQkzs4wz7QQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 8.505880981634666e-07, "legacy": true, "legacyId": "13172", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Buenos_Aires_meetup__Saturday__February_25th__4pm\">Discussion article for the meetup : <a href=\"/meetups/7a\">Buenos Aires meetup: Saturday, February 25th, 4pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">25 February 2012 04:00:00PM (-0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Starbucks Coffe, Florida 1, Buenos Aires, Argentina</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This will be our second Buenos Aires LessWrong meetup.  Our nominal discussion topic will be cognitive biases, though we'll keep things flexible so that the conversation can move naturally towards other topics of interest and relevance.  If you read and like this blog. and live in BA or just happen to be visiting the city, do join us.  It will be a great opportunity to meet like-minded folks in the area.  We will be sitting upstairs; a copy of Greg Egan's <em>Diaspora</em> will be displayed at our table.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Buenos_Aires_meetup__Saturday__February_25th__4pm1\">Discussion article for the meetup : <a href=\"/meetups/7a\">Buenos Aires meetup: Saturday, February 25th, 4pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Buenos Aires meetup: Saturday, February 25th, 4pm", "anchor": "Discussion_article_for_the_meetup___Buenos_Aires_meetup__Saturday__February_25th__4pm", "level": 1}, {"title": "Discussion article for the meetup : Buenos Aires meetup: Saturday, February 25th, 4pm", "anchor": "Discussion_article_for_the_meetup___Buenos_Aires_meetup__Saturday__February_25th__4pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T18:43:07.320Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne practical rationality meetup", "slug": "meetup-melbourne-practical-rationality-meetup-3", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:06.853Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YJsHuRsJAPyh8pCGj/meetup-melbourne-practical-rationality-meetup-3", "pageUrlRelative": "/posts/YJsHuRsJAPyh8pCGj/meetup-melbourne-practical-rationality-meetup-3", "linkUrl": "https://www.lesswrong.com/posts/YJsHuRsJAPyh8pCGj/meetup-melbourne-practical-rationality-meetup-3", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20practical%20rationality%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20practical%20rationality%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYJsHuRsJAPyh8pCGj%2Fmeetup-melbourne-practical-rationality-meetup-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20practical%20rationality%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYJsHuRsJAPyh8pCGj%2Fmeetup-melbourne-practical-rationality-meetup-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYJsHuRsJAPyh8pCGj%2Fmeetup-melbourne-practical-rationality-meetup-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 80, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7b'>Melbourne practical rationality meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">02 March 2012 07:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">55 walsh st, west melbourne, austraila</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Practical rationality, as distinct from the social and rationality outreach meetups. Look for a social meetup on the 3rd Friday of each month.</p>\n\n<p>Discussion:\n<a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a> <a href=\"http://www.google.com/moderator/#16/e=6a317\" rel=\"nofollow\">http://www.google.com/moderator/#16/e=6a317</a></p>\n\n<p>This meetup repeats on the 1st Friday of each month.</p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7b'>Melbourne practical rationality meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YJsHuRsJAPyh8pCGj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 8.506062513155233e-07, "legacy": true, "legacyId": "13173", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup\">Discussion article for the meetup : <a href=\"/meetups/7b\">Melbourne practical rationality meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">02 March 2012 07:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">55 walsh st, west melbourne, austraila</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Practical rationality, as distinct from the social and rationality outreach meetups. Look for a social meetup on the 3rd Friday of each month.</p>\n\n<p>Discussion:\n<a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a> <a href=\"http://www.google.com/moderator/#16/e=6a317\" rel=\"nofollow\">http://www.google.com/moderator/#16/e=6a317</a></p>\n\n<p>This meetup repeats on the 1st Friday of each month.</p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup1\">Discussion article for the meetup : <a href=\"/meetups/7b\">Melbourne practical rationality meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne practical rationality meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne practical rationality meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T20:47:54.987Z", "modifiedAt": null, "url": null, "title": "A new (?) anthropic principle, and motivation thereof", "slug": "a-new-anthropic-principle-and-motivation-thereof", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.436Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BrianNachbar", "createdAt": "2010-11-30T08:31:00.537Z", "isAdmin": false, "displayName": "BrianNachbar"}, "userId": "rcty3jD43ystvBuFH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AYNkXMQa5oXaEeveD/a-new-anthropic-principle-and-motivation-thereof", "pageUrlRelative": "/posts/AYNkXMQa5oXaEeveD/a-new-anthropic-principle-and-motivation-thereof", "linkUrl": "https://www.lesswrong.com/posts/AYNkXMQa5oXaEeveD/a-new-anthropic-principle-and-motivation-thereof", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20new%20(%3F)%20anthropic%20principle%2C%20and%20motivation%20thereof&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20new%20(%3F)%20anthropic%20principle%2C%20and%20motivation%20thereof%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYNkXMQa5oXaEeveD%2Fa-new-anthropic-principle-and-motivation-thereof%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20new%20(%3F)%20anthropic%20principle%2C%20and%20motivation%20thereof%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYNkXMQa5oXaEeveD%2Fa-new-anthropic-principle-and-motivation-thereof", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYNkXMQa5oXaEeveD%2Fa-new-anthropic-principle-and-motivation-thereof", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 799, "htmlBody": "<p><span style=\"white-space:pre\"> </span>The discussions of anthropic principles that I've seen on LW and, say, <a href=\"http://meteuphoric.wordpress.com/anthropic-principles/\">Katja Grace's list</a>, are limited to SIA and SSA. These both give some results that most people find unintuitive (Doomsday for SIA, presumptuous philosopher for SIA), and the debate between them seems to typically focus on which bullets are easier to bite. This seems strange to me, because a good universal prior should tell us which worlds we're most likely to be in without any dependency on intuition. What follows is my attempt to derive the correct anthropic principle in such a manner [1]. With some assumptions I find plausible, the result is something neither SIA nor SSA, resembling the former regarding doomsday and the latter regarding the presumptuous philosopher.</p>\n<p><span style=\"white-space:pre\"> </span>So far, I've only done the reasoning informally, and there are admittedly many places it could be fatally flawed. One assumes that one lives in a multiverse consisting of universes corresponding to programs on a universal Turing machine, each with prior probability inversely proportional to 2 to the power of the length of the program. One then updates on one's evidence, namely, one's experience [2]. I'll make a logical leap and assume that (it's as though) a conscious experience corresponds to a certain substring of output. We then take every possible output string<sub>&nbsp;</sub>ending with that substring, weight them equally (?), &nbsp;and take the sum over all such strings of the programs producing that string as a prefix of output, weighted by their prior probability. That is, each program ends up with posterior probability proportional to its prior probability times the number of times it produces the experience you just had.</p>\n<p><span style=\"white-space:pre\"> </span>Reading the wiki article on Solomonoff Induction as I write this, it looks like applying this process with your prior given by Solomonoff Induction will give you SIA (suggesting a new backronym?). This is where I become even more presumptuous. I take issue with the assumption that we necessarily find ourselves in a halting program. As far as I know, cosmologists don't think our universe is going to halt. Instead, I would suggest that all possible programs are running, unless they've halted. (Maybe the halting ones get restarted after they halt, maybe not). There are then infinitely many outputs that end with any given conscious experience, and the sum of their prior probabilities may not be finite. So, you either only consider outputs of length &le;&nbsp;T, and take the limit as T goes to infinity, or you multiply all probabilities of outputs by a factor inversely proportion to 2 to the power of the length of the output. The chief disadvantages of the former are that I'm not sure that limit has to exist and that it assigns infinitesimal probability to any universe that only produces your experience a finite number of times if any universe produces it an infinite number of times; the chief disadvantage of the latter is that I'm not sure why things should be weighted in such a manner.</p>\n<p><span style=\"white-space: pre;\"> </span>Either way, if you look at the anthropic implications, you get that universes with more people with your experience are more likely and that universes with more output not corresponding to your experiences are less likely. The math is easier using the limit method, which gives each universe a likelihood proportional to the proportion of its substrings that correspond to your experience. If we consider programs looking like our universe, and assume the amount of output per time step (that is, one second according to the equations governing that universe) is proportional to the size of the universe, then a universe in which conscious life lasts longer is more likely than one of equal size in which it goes extinct sooner [3], since both produce the same amount of output, but the former universe produces more conscious experiences. I'm pretty sure this works out just right to neutralize the doomsday argument. On the other hand, a universe that's 3^^^3^^^3 times larger produces 3^^^3^^^3 times as many conscious experiences, but they're distributed among 3^^^3^^^3 times as much output, so it does not gain any more likelihood as a consequence of its size.</p>\n<p>[1] My actual reasoning process was more chaotic and less reliable than this suggests; I'll elaborate if anyone wants.</p>\n<p>[2] Treating a single instant of conscious experience as the only evidence should yield a probability distribution with the correct probability assigned being a Boltzmann brain, but since in any case we can't complete such a calculation without assuming that our working memory's contents are valid, I'll ignore such possibilities in examples.</p>\n<p>[3] The observant reader will notice that any universe where conscious life ever goes permanently extinct should have infinitesimal probability. I suggest assuming for the sake of the argument that universes go in grand cycles, and that we're discussing whether life ends sooner or later in each cycle.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AYNkXMQa5oXaEeveD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 0, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "13174", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T21:22:22.585Z", "modifiedAt": null, "url": null, "title": "Impressions from a panel discussion on AGI ", "slug": "impressions-from-a-panel-discussion-on-agi", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.404Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HED7o4Auc67w25g3S/impressions-from-a-panel-discussion-on-agi", "pageUrlRelative": "/posts/HED7o4Auc67w25g3S/impressions-from-a-panel-discussion-on-agi", "linkUrl": "https://www.lesswrong.com/posts/HED7o4Auc67w25g3S/impressions-from-a-panel-discussion-on-agi", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Impressions%20from%20a%20panel%20discussion%20on%20AGI%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AImpressions%20from%20a%20panel%20discussion%20on%20AGI%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHED7o4Auc67w25g3S%2Fimpressions-from-a-panel-discussion-on-agi%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Impressions%20from%20a%20panel%20discussion%20on%20AGI%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHED7o4Auc67w25g3S%2Fimpressions-from-a-panel-discussion-on-agi", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHED7o4Auc67w25g3S%2Fimpressions-from-a-panel-discussion-on-agi", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 284, "htmlBody": "<p>I went to&nbsp;<a href=\"http://pitp.physics.ubc.ca/quant_lect/2012/tallinn.html\">this event</a>&nbsp;to listen to&nbsp;<a href=\"http://en.wikipedia.org/wiki/Jaan_Tallinn\">Jaan Tallinn</a>,&nbsp;<a href=\"http://www.scottaaronson.com/\">Scott Aaronson</a> and <a href=\"http://en.wikipedia.org/wiki/Don_Eigler\">Don Eigler</a>&nbsp;discuss the AGI, the Singularity and the [F]AI research. Not surprisingly, Jaan, whose ideas are significantly influenced by what EY preaches, advocated the urgent need for research into AGI friendliness as much as the AGI research proper.</p>\n<p>Scott was rather more laid back, estimating that a \"FOOMable\" AGI is probably 10,000 years away, and that, while the AGI problem is already really really hard, the FAI problem is harder still, so expending significant effort on the FAI problem before we understand the AGI issues better is probably not a good use of resources.</p>\n<p>Don, who makes atom-sized gates in his lab, suggested that the Moore's law will probably level out before the AGI becomes a reality. When asked, he said that he can see another 10^3-10^4 times improvement in chip complexity with technological innovations only, without the need for new scientific breakthroughs. This includes both the miniaturization of gates to near-atomic size and introducing 3D layouts with multiple interconnects. He expects the latter to be a significant breakthrough, provided the power consumption and dissipation issues are solved. 10^4 times corresponds to about 30-50 years given the current slope.</p>\n<p>A large chunk of the discussion was rehashing the standard points about the FAI (Pascal's wager type of arguments and counterarguments, augmentation and upload as some ways around UFAI, etc.), all of which have been discussed here to no end, so I will not repeat it.</p>\n<p>The video of the event will apparently be posted eventually, no time frame given. I have a marginal quality voice recording with my phone, available if anyone really wants to listen.</p>\n<p>If any of the Vancouver LWers attended, please feel free to share your impressions.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HED7o4Auc67w25g3S", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 23, "extendedScore": null, "score": 8.506690862157344e-07, "legacy": true, "legacyId": "13175", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-17T23:43:08.196Z", "modifiedAt": "2020-01-23T07:37:24.892Z", "url": null, "title": "Not insane. Unsane.", "slug": "not-insane-unsane", "viewCount": null, "lastCommentedAt": "2018-10-25T13:01:05.196Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "loup-vaillant", "createdAt": "2011-03-23T10:39:25.887Z", "isAdmin": false, "displayName": "loup-vaillant"}, "userId": "wdoZti3BcPbJXsZ66", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oL3usa3bWHtLa4fGZ/not-insane-unsane", "pageUrlRelative": "/posts/oL3usa3bWHtLa4fGZ/not-insane-unsane", "linkUrl": "https://www.lesswrong.com/posts/oL3usa3bWHtLa4fGZ/not-insane-unsane", "postedAtFormatted": "Friday, February 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Not%20insane.%20Unsane.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANot%20insane.%20Unsane.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoL3usa3bWHtLa4fGZ%2Fnot-insane-unsane%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Not%20insane.%20Unsane.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoL3usa3bWHtLa4fGZ%2Fnot-insane-unsane", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoL3usa3bWHtLa4fGZ%2Fnot-insane-unsane", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 242, "htmlBody": "<p><em>Edit :Excellent suggestions in the comments. Two of them stood out for me:</em></p>\n<ol>\n<li><em>\"Untaught\" may be better.&nbsp; It is less connoted (if at all), conveys about the right meaning, and can be understood by about anyone (<a href=\"/lw/a61/not_insane_unsane/5w8w\">thanks, shminux</a>).<br /></em></li>\n<li><em>Using a word to name a category can raise walls around it. In this case, we must be extra careful not to stigmatize the very people we'd like to join us (<a href=\"/lw/a61/not_insane_unsane/5wcd\">thanks, daenerys</a>).</em></li>\n</ol>\n<p>We often use \"insane\" to describe people whose behaviour or beliefs are below the <a title=\"I'd rather link to a definition on the wiki, but&hellip;\" href=\"/lw/1e/raising_the_sanity_waterline/\">sanity waterline</a>. But as most must would agree here, you cannot call someone insane with a straight face just because he happens to believe in <a title=\"God (Wikipedia)\" href=\"http://en.wikipedia.org/wiki/God\">magic</a>.</p>\n<p>I'm currently watching <a href=\"http://futurebydesignthemovie.com/\">Future by Design</a>, a documentary featuring <a title=\"Wikipedia\" href=\"http://en.wikipedia.org/wiki/Jacque_Fresco\">Jacque Fresco</a> and the <a title=\"Official site\" href=\"http://www.thevenusproject.com/\">Venus Project</a>. Jacque came up with this word, \"unsane\", to describe people who basically, aren't rational because they haven't been exposed to the right ideas yet.&nbsp; Which would be different from \"insane\", which is more about <em>irrevocably</em> irrational people.</p>\n<p>I like this word, because there isn't the tone of accusation we find in \"insane\". This neutrality makes it easier to say that we can do something about it. <em>Insanity</em> should be <a title=\"Mind the Spiral of Hate, though\" href=\"http://wiki.lesswrong.com/wiki/Affective_death_spiral\">eradicated like vermin</a>. <em>Unsanty</em> on the other hand can be <a href=\"/lw/1e/raising_the_sanity_waterline/\">fixed</a>.</p>\n<p>So, do you think this word, \"Unsanity\" might be worth using?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oL3usa3bWHtLa4fGZ", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 15, "extendedScore": null, "score": 4.8e-05, "legacy": true, "legacyId": "13177", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 66, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XqmjdBKa4ZaXJtNmf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2012-02-17T23:43:08.196Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-18T00:07:43.048Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Brussels, Houston, Madison, Melbourne, Moscow, Philadelphia (2), Sydney", "slug": "weekly-lw-meetups-brussels-houston-madison-melbourne-moscow", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:58.004Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w96GjbpgmaRFxoaNF/weekly-lw-meetups-brussels-houston-madison-melbourne-moscow", "pageUrlRelative": "/posts/w96GjbpgmaRFxoaNF/weekly-lw-meetups-brussels-houston-madison-melbourne-moscow", "linkUrl": "https://www.lesswrong.com/posts/w96GjbpgmaRFxoaNF/weekly-lw-meetups-brussels-houston-madison-melbourne-moscow", "postedAtFormatted": "Saturday, February 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Brussels%2C%20Houston%2C%20Madison%2C%20Melbourne%2C%20Moscow%2C%20Philadelphia%20(2)%2C%20Sydney&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Brussels%2C%20Houston%2C%20Madison%2C%20Melbourne%2C%20Moscow%2C%20Philadelphia%20(2)%2C%20Sydney%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw96GjbpgmaRFxoaNF%2Fweekly-lw-meetups-brussels-houston-madison-melbourne-moscow%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Brussels%2C%20Houston%2C%20Madison%2C%20Melbourne%2C%20Moscow%2C%20Philadelphia%20(2)%2C%20Sydney%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw96GjbpgmaRFxoaNF%2Fweekly-lw-meetups-brussels-houston-madison-melbourne-moscow", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw96GjbpgmaRFxoaNF%2Fweekly-lw-meetups-brussels-houston-madison-melbourne-moscow", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 443, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/6r\">Jazz meetup in Philadelphia:&nbsp;<span class=\"date\">10 February 2012 06:00PM</span></a></li>\n<li><a href=\"/meetups/5f\">First Brussels meetup:&nbsp;<span class=\"date\">11 February 2012 11:00AM</span></a></li>\n<li><a href=\"/meetups/6x\">Moscow 11 February meetup:&nbsp;<span class=\"date\">11 February 2012 06:00PM</span></a></li>\n<li><a href=\"/meetups/6t\">Houston Meetup - 2/12:&nbsp;<span class=\"date\">12 February 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/6g\">Sydney Rationality meet-up No.2:&nbsp;<span class=\"date\">15 February 2012 06:00PM</span></a></li>\n<li><a href=\"/meetups/6s\">Philadelphia LW: Macroeconomics crash course and general meetup:&nbsp;<span class=\"date\">15 February 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/69\">Ongoing Ohio Meetup:&nbsp;<span class=\"date\">19 February 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/6z\">Tucson Meetup:&nbsp;<span class=\"date\">24 February 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/6v\">Twin Cities South Metro:&nbsp;<span class=\"date\">06 March 2012 08:00PM</span></a></li>\n<li><a href=\"/meetups/6k\">[Ohio/Washington DC] Interest in Reason Rally meetup?:&nbsp;<span class=\"date\">24 March 2012 04:14PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/6y\">Madison Monday Meetup:&nbsp;<span class=\"date\">13 February 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/6u\">Melbourne social meetup:&nbsp;<span class=\"date\">17 February 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/74\">Monthly Bay Area meetup: Berkeley:&nbsp;<span class=\"date\">18 February 2012 07:00PM</span></a></li>\n</ul>\n<p>Also, the Salt Lake City group now has a <a href=\"http://sites.google.com/site/lesswrongsaltlakecity/\">website</a>!</p>\n<ul>\n</ul>\n<p>Cities with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a></strong><strong>.</strong></p>\n<p>If your meetup has a mailing list that you'd like mentioned here or has become regular and isn't listed as such, let me know!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w96GjbpgmaRFxoaNF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 8.50734331321178e-07, "legacy": true, "legacyId": "12926", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-18T05:39:51.383Z", "modifiedAt": null, "url": null, "title": "SI wants to hire a remote LaTeX guru", "slug": "si-wants-to-hire-a-remote-latex-guru", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:20.436Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RPeSzu6b9XPdT6my6/si-wants-to-hire-a-remote-latex-guru", "pageUrlRelative": "/posts/RPeSzu6b9XPdT6my6/si-wants-to-hire-a-remote-latex-guru", "linkUrl": "https://www.lesswrong.com/posts/RPeSzu6b9XPdT6my6/si-wants-to-hire-a-remote-latex-guru", "postedAtFormatted": "Saturday, February 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SI%20wants%20to%20hire%20a%20remote%20LaTeX%20guru&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASI%20wants%20to%20hire%20a%20remote%20LaTeX%20guru%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPeSzu6b9XPdT6my6%2Fsi-wants-to-hire-a-remote-latex-guru%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SI%20wants%20to%20hire%20a%20remote%20LaTeX%20guru%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPeSzu6b9XPdT6my6%2Fsi-wants-to-hire-a-remote-latex-guru", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPeSzu6b9XPdT6my6%2Fsi-wants-to-hire-a-remote-latex-guru", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 98, "htmlBody": "<p>The Singularity Institute needs to hire 1-2 people who are fluent in LaTeX to help us transform past and future SI publications from looking like <a href=\"http://intelligence.org/upload/ai-resource-drives.pdf\">this</a> to looking like <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/01/Dewey-Learning-what-to-value.pdf\">this</a>.</p>\n<p>As with the <a href=\"/r/discussion/lw/9t8/the_singularity_institute_needs_remote/\">remote researcher positions</a>, pay is hourly and starts at $14/hr but that will rise if the product is good. You must be available to work at least 20 hrs/week to be considered.</p>\n<p>Perks:</p>\n<ul>\n<li>Work from home, with flexible hours.</li>\n<li>Age and credentials are irrelevant; only the product matters.</li>\n</ul>\n<p>If you're interested, contact luke@intelligence.org and describe past LaTeX work you've done, with attached PDF examples.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RPeSzu6b9XPdT6my6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 15, "extendedScore": null, "score": 8.508654228754995e-07, "legacy": true, "legacyId": "13198", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LakrCAaj8rNss2q6j"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-18T08:23:32.820Z", "modifiedAt": null, "url": null, "title": "[LINK] The NYT on Everyday Habits", "slug": "link-the-nyt-on-everyday-habits", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.944Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alex_Altair", "createdAt": "2010-07-21T18:30:40.806Z", "isAdmin": false, "displayName": "Alex_Altair"}, "userId": "5wu9jG4pm9q6xjZ9R", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AgzEatphhmcQLxuq4/link-the-nyt-on-everyday-habits", "pageUrlRelative": "/posts/AgzEatphhmcQLxuq4/link-the-nyt-on-everyday-habits", "linkUrl": "https://www.lesswrong.com/posts/AgzEatphhmcQLxuq4/link-the-nyt-on-everyday-habits", "postedAtFormatted": "Saturday, February 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20The%20NYT%20on%20Everyday%20Habits&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20The%20NYT%20on%20Everyday%20Habits%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAgzEatphhmcQLxuq4%2Flink-the-nyt-on-everyday-habits%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20The%20NYT%20on%20Everyday%20Habits%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAgzEatphhmcQLxuq4%2Flink-the-nyt-on-everyday-habits", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAgzEatphhmcQLxuq4%2Flink-the-nyt-on-everyday-habits", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 477, "htmlBody": "<p>The New York Times just published <a href=\"http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">this article</a> on how companies use data mining and the psychology of habit formation to effectively target ads.</p>\n<blockquote>\n<p><span style=\"font-family: georgia, 'times new roman', times, serif; font-size: 15px; line-height: 22px; text-align: left;\">The process within our brains that creates habits is a three-step loop. First, there is a cue, a trigger that tells your brain to go into automatic mode and which habit to use. Then there is the routine, which can be physical or mental or emotional. Finally, there is a reward, which helps your brain figure out if this particular loop is worth remembering for the future. Over time, this loop &mdash; cue, routine, reward; cue, routine, reward &mdash; becomes more and more automatic. The cue and reward become neurologically intertwined until a sense of craving emerges.</span></p>\n</blockquote>\n<p>It has some decent depth of discussion, including an example of the author actually using the concepts to stop a bad habit.&nbsp;The article is based on an upcoming book by the same author titled <a href=\"http://charlesduhigg.com/the-power-of-habit/\">The Power of Habit</a>.</p>\n<p style=\"text-align: left;\">I haven't seen emphasis of this particular phenomenon&mdash;habits consisting of a cue, routine, and reward&mdash;on Lesswrong. Do people think it's a valid, scientifically supported phenomenon? The article gives this impression but, of course, doesn't cite specific academic work on it. It ties in to the <a href=\"/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">System 1/System 2</a> theory easily as a System 1 process. How much of the whole System 1 can be explained as an implementation of this cue, routine, reward process?</p>\n<p style=\"text-align: left;\">And most importantly, how can this fit into the <a href=\"/lw/3w3/how_to_beat_procrastination/\">procrastination equation</a> as a tool to subvert akrasia and establish good habits?&nbsp;</p>\n<p style=\"text-align: left;\">Let's look at each of the four factors. If you've formed a habit, it means that the reward happened consistently, which means you have high <em>expectancy</em>. Given that it is a reward, the <em>value</em> is at least positive, but probably not large. Since habits mostly work on small time scales, <em>delay</em> is probably very small. And maybe increased habit formation means your impulsiveness is low. Each of these effects would increase motivation. In addition, because it's part of System 1, there is little energy cost to performing the habit, like there would be with many other conscious actions.</p>\n<p style=\"text-align: left;\">Does this explanation sound legitimate, or like an argument for the <a href=\"/lw/js/the_bottom_line/\">bottom line</a>?</p>\n<p style=\"text-align: left;\">Personally, I can tell that context is a strong cue for behavior at work, school, and home. When I go into work, I'm automatically motivated to perform well, and that motivation remains for several hours. When I go into class, I'm automatically ready to focus on difficult material, or even enthusiastically take a test. Yet when I go home, something about the context switches that off, and I can't seem to get anything done at all.&nbsp;It might be worth significant experimentation to find out what cues trigger both modes, and change my contexts to induce what I want.</p>\n<p style=\"text-align: left;\">What do you think?</p>\n<p style=\"text-align: left;\"><strong>Edit</strong>: this phenomenon has been covered on LW in the form of <a href=\"/lw/6ja/basics_of_human_reinforcement/\">operant conditioning</a> in posts by Yvain.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AgzEatphhmcQLxuq4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 8.509300429679877e-07, "legacy": true, "legacyId": "13205", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["du395YvCnQXBPSJax", "RWo4LwFzpHNQCTcYt", "34XxbRFe54FycoCDw", "BfaAADSQ88cuxLQoD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-18T10:42:16.936Z", "modifiedAt": null, "url": null, "title": "Mini-review: 'Judgment and Decision Making as a Skill'", "slug": "mini-review-judgment-and-decision-making-as-a-skill", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.478Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RQuMGBXhLjK7ZciH9/mini-review-judgment-and-decision-making-as-a-skill", "pageUrlRelative": "/posts/RQuMGBXhLjK7ZciH9/mini-review-judgment-and-decision-making-as-a-skill", "linkUrl": "https://www.lesswrong.com/posts/RQuMGBXhLjK7ZciH9/mini-review-judgment-and-decision-making-as-a-skill", "postedAtFormatted": "Saturday, February 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mini-review%3A%20'Judgment%20and%20Decision%20Making%20as%20a%20Skill'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMini-review%3A%20'Judgment%20and%20Decision%20Making%20as%20a%20Skill'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRQuMGBXhLjK7ZciH9%2Fmini-review-judgment-and-decision-making-as-a-skill%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mini-review%3A%20'Judgment%20and%20Decision%20Making%20as%20a%20Skill'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRQuMGBXhLjK7ZciH9%2Fmini-review-judgment-and-decision-making-as-a-skill", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRQuMGBXhLjK7ZciH9%2Fmini-review-judgment-and-decision-making-as-a-skill", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 341, "htmlBody": "<p>A new book from Cambridge University Press describes the impetus of the forthcoming&nbsp;<a href=\"/lw/9hb/position_design_and_write_rationality_curriculum/\">Rationality Group</a> in its title: <em><a href=\"http://www.amazon.com/Judgment-Decision-Making-Skill-Development/dp/0521767814\">Judgment and Decision Making as a Skill</a></em>. It begins:</p>\n<blockquote>\n<p>Our scientific understanding of human judgment and decision making (JDM) has grown considerably over the past 60 years in terms of the normative benchmarks... by which we assess performance, the descriptive models we use to describe JDM, and the prescriptive models we offer to improve JDM...</p>\n<p>...[But] how do we learn to make good decisions? How can we improve or aid our decision making? Fortunately, there is an emerging body of work that is interested in long-term and short-term changes in JDM skills... There is research on the acquisition of expertise in JDM, and training and aiding of JDM. Researchers more interested in short-term changes have begun to study learning of JDM tasks...</p>\n<p>[We] introduce a new conception of JDM, seeing it as a dynamic skill rather than a static capacity...</p>\n</blockquote>\n<p>Chapters 1 and 2 survey the evolution and neurobiology of JDM, while the chapters 3-5 discuss JDM in young children, adolescents, and the aged. Chapters 6-10 were the most interesting to me, because they concern the <em>learning</em>&nbsp;and <em>improving</em>&nbsp;of JDM skills.</p>\n<p>In particular, chapter 7 discusses the use of causal Bayes nets to model JDM processes and thereby make better-informed choices among possible debiasing interventions, and chapter 8 discusses JDM in the context of skill-learning (from feedback). Chapter 9 reviews the ways in which JDM can be improved simply by communicating and representing information in particular ways.&nbsp;Chapter 10 reviews \"procedures or devices that are intended to improve the quality of people's decisions.\"</p>\n<p>Chapter 11 contains personal reflections on JDM as a skill from nine past presidents of the <a href=\"http://www.sjdm.org/\">Society for Judgment and Decision Making</a>.</p>\n<p>Overall, the book is a handy collection of review articles on JDM (what LW calls <a href=\"/lw/31/what_do_we_mean_by_rationality/\">epistemic and instrumental rationality</a>) written from a useful perspective. But it is not as useful as Stanovich's <em><a href=\"http://www.amazon.com/Rationality-Reflective-Mind-Keith-Stanovich/dp/0195341147/\">Rationality and the Reflective Mind</a></em>, and I anticipate it being less useful than the forthcoming <em><a href=\"http://www.amazon.com/Handbook-Thinking-Reasoning-Library-Psychology/dp/0199734682/\">Oxford Handbook of Thinking and Reasoning</a></em>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RQuMGBXhLjK7ZciH9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 8.509848182763674e-07, "legacy": true, "legacyId": "13209", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ifL8f4Xzy2D9Bb6zs", "RcZCwxFiZzE6X7nsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-18T15:10:08.331Z", "modifiedAt": null, "url": null, "title": "Brain structure and the halo effect", "slug": "brain-structure-and-the-halo-effect", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:50.445Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "saph", "createdAt": "2011-07-09T08:53:07.800Z", "isAdmin": false, "displayName": "saph"}, "userId": "88eE6FAcgK9nsTzND", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iNpzxsi8Xs4Gr8Egt/brain-structure-and-the-halo-effect", "pageUrlRelative": "/posts/iNpzxsi8Xs4Gr8Egt/brain-structure-and-the-halo-effect", "linkUrl": "https://www.lesswrong.com/posts/iNpzxsi8Xs4Gr8Egt/brain-structure-and-the-halo-effect", "postedAtFormatted": "Saturday, February 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brain%20structure%20and%20the%20halo%20effect&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrain%20structure%20and%20the%20halo%20effect%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNpzxsi8Xs4Gr8Egt%2Fbrain-structure-and-the-halo-effect%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brain%20structure%20and%20the%20halo%20effect%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNpzxsi8Xs4Gr8Egt%2Fbrain-structure-and-the-halo-effect", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNpzxsi8Xs4Gr8Egt%2Fbrain-structure-and-the-halo-effect", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 509, "htmlBody": "<h2>Introduction<br /></h2>\n<p>When people on LW want to explain a bias, they often turn to <a title=\"Evolutionary Psychology\" href=\"http://wiki.lesswrong.com/wiki/Evolutionary_psychology\">Evolutionary psychology</a>. For example, Lukeprog <a title=\"Your evolved intuitions\" href=\"/lw/5bw/your_evolved_intuitions/\">writes</a></p>\n<blockquote>\n<p>Human reasoning is subject to a&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Bias\">long list of biases</a>. Why did we evolve such faulty thinking processes? Aren't false beliefs bad for survival and reproduction?</p>\n</blockquote>\n<p>I think that ''evolved faulty thinking processes'' is the wrong way to look at it and I will argue that some biases are the consequence of structural properties of the brain, which 'cannot' be affected by evolution.</p>\n<h2>Brain structure and the halo effect<br /></h2>\n<p>I want to introduce a simple model, which relates the <a href=\"/lw/lj/the_halo_effect\">halo effect</a> to a structural property of the brain. My hope is that this approach will be useful to understand the halo effect more systematically and shows that thinking in evolutionary terms is not always the best way to think about certain biases.</p>\n<p>One crucial property of the brain is that it has to map a (essentially infinite) high-dimensional reality onto a finite low-dimensional internal representation. (If you know some Linear Algebra, you can think of this as a projection from a high-dimensional space into a low-dimensional space.) This is done more or less automatically by the limitation of our senses and brain's structure as a <a title=\"Neural network\" href=\"http://en.wikipedia.org/wiki/Neural_network\">neural network</a>.</p>\n<p><img style=\"vertical-align: middle; margin-top: 0px; margin-bottom: 0px; margin-left: 300px; margin-right: 300px; border: 0;\" src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/200px-Neural_network.svg.png\" alt=\"Neural network (Wikipedia)\" width=\"200\" height=\"125\" /></p>\n<p>An immediate consequence of this observation is that there will be many states of the world, which are mapped to an almost identical inner representation. In terms of computational efficiency it makes sense to use overlapping set of neurons with similar activation level to represent similar concepts. (This is also a consequence of how the brain actually builds representations from sense inputs.)</p>\n<p>Now compare this to the following passage from <a title=\"superhero bias\" href=\"/lw/lk/superhero_bias/\">here</a>.</p>\n<blockquote>\n<p>The <a href=\"/lw/lj/the_halo_effect\">halo effect</a> is that perceptions of all positive traits are correlated. Profiles rated higher on scales of attractiveness, are also rated higher on scales of talent, kindness, honesty, and intelligence.</p>\n</blockquote>\n<p>This shouldn't be a surprise, since 'positive' ('feels good') seems to be one of the evolutionary hard-wired concepts. Other concepts that we acquire during our life and associate with positive emotions, like kindness and honesty are mapped to 'nearby' neural structures. When one of those mental structures is activated, the 'closed ones' will be activated to a certain degree as well.</p>\n<p>Since we differentiate concepts more when we are learning about a subject, the above reasoning should imply that children and people with less education in a certain area should be more influenced by this (generalized) halo effect in that area.</p>\n<h2>Conclusion<br /></h2>\n<p>Since evolution can only modify the existing brain structure but cannot get away from the neural network 'design', the halo effect is a necessary by-product of human thinking. But the degree of 'throwing things in one pot' will depend on how much we learn about those things and increase our representation dimensionality.</p>\n<p>My hope is that we can relief evolution from the burden of having to explain so many things and focus more on structural explanations, which provide a working model for possible applications and a better understanding.</p>\n<p>&nbsp;</p>\n<p>PS: I am always grateful for feedback!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb182": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iNpzxsi8Xs4Gr8Egt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 18, "extendedScore": null, "score": 8.510905908375048e-07, "legacy": true, "legacyId": "13166", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Introduction\">Introduction<br></h2>\n<p>When people on LW want to explain a bias, they often turn to <a title=\"Evolutionary Psychology\" href=\"http://wiki.lesswrong.com/wiki/Evolutionary_psychology\">Evolutionary psychology</a>. For example, Lukeprog <a title=\"Your evolved intuitions\" href=\"/lw/5bw/your_evolved_intuitions/\">writes</a></p>\n<blockquote>\n<p>Human reasoning is subject to a&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Bias\">long list of biases</a>. Why did we evolve such faulty thinking processes? Aren't false beliefs bad for survival and reproduction?</p>\n</blockquote>\n<p>I think that ''evolved faulty thinking processes'' is the wrong way to look at it and I will argue that some biases are the consequence of structural properties of the brain, which 'cannot' be affected by evolution.</p>\n<h2 id=\"Brain_structure_and_the_halo_effect\">Brain structure and the halo effect<br></h2>\n<p>I want to introduce a simple model, which relates the <a href=\"/lw/lj/the_halo_effect\">halo effect</a> to a structural property of the brain. My hope is that this approach will be useful to understand the halo effect more systematically and shows that thinking in evolutionary terms is not always the best way to think about certain biases.</p>\n<p>One crucial property of the brain is that it has to map a (essentially infinite) high-dimensional reality onto a finite low-dimensional internal representation. (If you know some Linear Algebra, you can think of this as a projection from a high-dimensional space into a low-dimensional space.) This is done more or less automatically by the limitation of our senses and brain's structure as a <a title=\"Neural network\" href=\"http://en.wikipedia.org/wiki/Neural_network\">neural network</a>.</p>\n<p><img style=\"vertical-align: middle; margin-top: 0px; margin-bottom: 0px; margin-left: 300px; margin-right: 300px; border: 0;\" src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/200px-Neural_network.svg.png\" alt=\"Neural network (Wikipedia)\" width=\"200\" height=\"125\"></p>\n<p>An immediate consequence of this observation is that there will be many states of the world, which are mapped to an almost identical inner representation. In terms of computational efficiency it makes sense to use overlapping set of neurons with similar activation level to represent similar concepts. (This is also a consequence of how the brain actually builds representations from sense inputs.)</p>\n<p>Now compare this to the following passage from <a title=\"superhero bias\" href=\"/lw/lk/superhero_bias/\">here</a>.</p>\n<blockquote>\n<p>The <a href=\"/lw/lj/the_halo_effect\">halo effect</a> is that perceptions of all positive traits are correlated. Profiles rated higher on scales of attractiveness, are also rated higher on scales of talent, kindness, honesty, and intelligence.</p>\n</blockquote>\n<p>This shouldn't be a surprise, since 'positive' ('feels good') seems to be one of the evolutionary hard-wired concepts. Other concepts that we acquire during our life and associate with positive emotions, like kindness and honesty are mapped to 'nearby' neural structures. When one of those mental structures is activated, the 'closed ones' will be activated to a certain degree as well.</p>\n<p>Since we differentiate concepts more when we are learning about a subject, the above reasoning should imply that children and people with less education in a certain area should be more influenced by this (generalized) halo effect in that area.</p>\n<h2 id=\"Conclusion\">Conclusion<br></h2>\n<p>Since evolution can only modify the existing brain structure but cannot get away from the neural network 'design', the halo effect is a necessary by-product of human thinking. But the degree of 'throwing things in one pot' will depend on how much we learn about those things and increase our representation dimensionality.</p>\n<p>My hope is that we can relief evolution from the burden of having to explain so many things and focus more on structural explanations, which provide a working model for possible applications and a better understanding.</p>\n<p>&nbsp;</p>\n<p>PS: I am always grateful for feedback!</p>", "sections": [{"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "Brain structure and the halo effect", "anchor": "Brain_structure_and_the_halo_effect", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "18 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WTS4ZbEwvKrcrnaaN", "ACGeaAk6KButv2xwQ", "krMzmSXgvEdf7iBT6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-18T17:52:59.330Z", "modifiedAt": null, "url": null, "title": "RAND Health Insurance Experiment critiques", "slug": "rand-health-insurance-experiment-critiques", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:38.933Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dustin", "createdAt": "2009-03-11T20:26:51.368Z", "isAdmin": false, "displayName": "Dustin"}, "userId": "E5DKwa6Eu3qLuKfpJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZkQbYsQm7CX2Kj3pZ/rand-health-insurance-experiment-critiques", "pageUrlRelative": "/posts/ZkQbYsQm7CX2Kj3pZ/rand-health-insurance-experiment-critiques", "linkUrl": "https://www.lesswrong.com/posts/ZkQbYsQm7CX2Kj3pZ/rand-health-insurance-experiment-critiques", "postedAtFormatted": "Saturday, February 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20RAND%20Health%20Insurance%20Experiment%20critiques&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARAND%20Health%20Insurance%20Experiment%20critiques%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZkQbYsQm7CX2Kj3pZ%2Frand-health-insurance-experiment-critiques%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=RAND%20Health%20Insurance%20Experiment%20critiques%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZkQbYsQm7CX2Kj3pZ%2Frand-health-insurance-experiment-critiques", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZkQbYsQm7CX2Kj3pZ%2Frand-health-insurance-experiment-critiques", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<p>I have neither the qualifications nor the access to properly understand these two paywalled critiques of the RAND Health Insurance&nbsp;Experiment.</p>\n<p><a href=\"http://jhppl.dukejournals.org/content/33/2/309.abstract\">Health Plan Switching and Attrition Bias in the RAND Health Insurance Experiment</a></p>\n<p><a href=\"http://www.jstor.org/pss/3765514\">The Rand Health Insurance Study: A Summary Critique</a></p>\n<p>Has there been any talk about either of these on OB/LW? &nbsp;If not, why not and could anyone with access to the papers make any comments about how much weight they carry?</p>\n<p>I post this here because the RAND results are brought up so often in discussions here, I hope others find it to be an appropriate venue.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZkQbYsQm7CX2Kj3pZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 8.511549092268304e-07, "legacy": true, "legacyId": "13212", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-18T22:17:41.406Z", "modifiedAt": null, "url": null, "title": "Brain shrinkage in humans over past ~20 000 years - what did we lose?", "slug": "brain-shrinkage-in-humans-over-past-20-000-years-what-did-we", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:04.908Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dmytry", "createdAt": "2009-12-03T17:11:53.492Z", "isAdmin": false, "displayName": "Dmytry"}, "userId": "AjtmA2qtA8sdiMbru", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HB3mKmkhx2bhn4Cca/brain-shrinkage-in-humans-over-past-20-000-years-what-did-we", "pageUrlRelative": "/posts/HB3mKmkhx2bhn4Cca/brain-shrinkage-in-humans-over-past-20-000-years-what-did-we", "linkUrl": "https://www.lesswrong.com/posts/HB3mKmkhx2bhn4Cca/brain-shrinkage-in-humans-over-past-20-000-years-what-did-we", "postedAtFormatted": "Saturday, February 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brain%20shrinkage%20in%20humans%20over%20past%20~20%20000%20years%20-%20what%20did%20we%20lose%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrain%20shrinkage%20in%20humans%20over%20past%20~20%20000%20years%20-%20what%20did%20we%20lose%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHB3mKmkhx2bhn4Cca%2Fbrain-shrinkage-in-humans-over-past-20-000-years-what-did-we%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brain%20shrinkage%20in%20humans%20over%20past%20~20%20000%20years%20-%20what%20did%20we%20lose%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHB3mKmkhx2bhn4Cca%2Fbrain-shrinkage-in-humans-over-past-20-000-years-what-did-we", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHB3mKmkhx2bhn4Cca%2Fbrain-shrinkage-in-humans-over-past-20-000-years-what-did-we", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 699, "htmlBody": "<p>The human brain volume has been <a href=\"http://discovermagazine.com/2010/sep/25-modern-humans-smart-why-brain-shrinking\">shrinking</a> over the past 20 000 years or so, after millions years of increase in volume. Not just the brain size, but the brain size relatively to body size as well. We are lacking a tennis-ball sized piece of our earlier brain (and it might even be God-shaped).</p>\n<p>Brain is expensive in many ways: energy consumption, birth complications and locomotion impairment for females, lower survival of head impacts i'd guess. The damn thing along with supporting structures is heavy and awkwardly located, etc.</p>\n<p>And the big brain can only be advantageous if it improves reproduction substantially, with larger brained individuals being sufficiently more successful at surviving and reproducing than smaller brained individuals, as to negate the above-mentioned cost.</p>\n<p>That must have been the case through the evolution up to a couple tens thousands years ago, to produce the big brains that we have. It is clear to see that in past 20 000 years, the environment in which humans live has undergone very significant change due to emergence of societies; the new environment may not be pushing us as hard [in the direction of intelligence], at least on the individual level. [and may have been pushing us too hard for smaller brains, thanks Nornagest for making that point]</p>\n<p>We were evolving ability to think, until it got just about to the point of being barely able - with great difficulty and many falls - to think useful thoughts. If we were species that were evolving flight, we'd be the species that could just barely fly, and recently flew over a river, entering new land. In the new land, everything is different. And our wings were shrinking at very rapid rate.</p>\n<p>The important question is - Did we lose any functionality since then? Are we dumber? Are we less sane in some way? (The palaeolithic humans did not seem to do any really insane religious stuff)</p>\n<p>The notion that our brains just got more efficient and 'therefore' could shrink in size appears very shaky to me. This 'therefore' comes from fallacy of anthropomorphizing the evolution. Evolution doesn't work to a goal of optimizing some sub-unit in the organism while preserving specifications, in the way that a team on an engineering project would.</p>\n<p>The optimization could as well instead make brain even larger, if said improvement made larger brain pay off more. One would have to show that some improvement in brain efficiency has actually decreased advantage of big brains over small brains, to explain the smaller brains with them being more optimized.</p>\n<p>The evolution optimizes the whole organism, not the brain, and there's very many of other factors that have changed at that specific time that may as well have decreased selection pressure towards intelligence or increased the costs.</p>\n<p>In my opinion the sensible default hypothesis should be that we had a decrease in some functionality, and likely are still declining.</p>\n<p>My best guess is that it is the capacity to invent solutions on spot and think by ourselves, that we are losing. Before emergence of societies, the technological progress was severely limited by information loss. Any smart individual could massively improve fitness of the relevant genes by (re)inventing some basic, but extremely effective techniques, which he'd teach mostly to genetically related individuals. The technique would easy become lost, creating again an opportunity for intelligence to succeed - reinventing it.</p>\n<p>Even very simple invention requires massive search in the vast space of possibilities. Precisely the kind of task that one would expect to benefit from larger raw computational power.</p>\n<p>edit:</p>\n<p>Some clarification with regards to the need for innovation. In the long run, it is not enough to just do what you're taught. Teaching is a lossy process. You need to improve upon what was taught to you a little to make the tool as good as your ancestor made - you need minor innovation to merely preserve the tools - a little more innovation and you'll improve over time, a little less and you'll lose it over time. The little children have to figure out everything from a few clues; they don't download some braindump of the wisest elder to be able to speak, they essentially figure out an alien language - a very difficult task.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HB3mKmkhx2bhn4Cca", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 20, "extendedScore": null, "score": 8.512592897102138e-07, "legacy": true, "legacyId": "13211", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 109, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-19T05:57:14.776Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Variable Question Fallacies", "slug": "seq-rerun-variable-question-fallacies", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jw8b9wHA4qDR3poYY/seq-rerun-variable-question-fallacies", "pageUrlRelative": "/posts/jw8b9wHA4qDR3poYY/seq-rerun-variable-question-fallacies", "linkUrl": "https://www.lesswrong.com/posts/jw8b9wHA4qDR3poYY/seq-rerun-variable-question-fallacies", "postedAtFormatted": "Sunday, February 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Variable%20Question%20Fallacies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Variable%20Question%20Fallacies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjw8b9wHA4qDR3poYY%2Fseq-rerun-variable-question-fallacies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Variable%20Question%20Fallacies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjw8b9wHA4qDR3poYY%2Fseq-rerun-variable-question-fallacies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjw8b9wHA4qDR3poYY%2Fseq-rerun-variable-question-fallacies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 206, "htmlBody": "<p>Today's post, <a href=\"/lw/oc/variable_question_fallacies/\">Variable Question Fallacies</a> was originally published on 05 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You use a word that has different meanings in different places as though it meant the same thing on each occasion, possibly creating the illusion of something protean and shifting. \"Martin told Bob the building was on his left.\" But \"left\" is a function-word that evaluates with a speaker-dependent variable grabbed from the surrounding context. Whose \"left\" is meant, Bob's or Martin's?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a47/seq_rerun_words_as_mental_paintbrush_handles/\">Words as Mental Paintbrush Handles</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jw8b9wHA4qDR3poYY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.51441062450948e-07, "legacy": true, "legacyId": "13213", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["shoMpaoZypfkXv84Y", "uuFXeQpJLbEZm4JLX", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-19T08:10:08.454Z", "modifiedAt": null, "url": null, "title": "Quantified Health Prize results announced", "slug": "quantified-health-prize-results-announced", "viewCount": null, "lastCommentedAt": "2021-06-23T22:31:00.827Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Zvi", "user": {"username": "Zvi", "createdAt": "2009-03-31T20:54:54.077Z", "isAdmin": false, "displayName": "Zvi"}, "userId": "N9zj5qpTfqmbn9dro", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yMKfih99nSqRyphkD/quantified-health-prize-results-announced", "pageUrlRelative": "/posts/yMKfih99nSqRyphkD/quantified-health-prize-results-announced", "linkUrl": "https://www.lesswrong.com/posts/yMKfih99nSqRyphkD/quantified-health-prize-results-announced", "postedAtFormatted": "Sunday, February 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Quantified%20Health%20Prize%20results%20announced&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuantified%20Health%20Prize%20results%20announced%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyMKfih99nSqRyphkD%2Fquantified-health-prize-results-announced%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Quantified%20Health%20Prize%20results%20announced%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyMKfih99nSqRyphkD%2Fquantified-health-prize-results-announced", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyMKfih99nSqRyphkD%2Fquantified-health-prize-results-announced", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 890, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Follow-up to: <a href=\"/lw/8nx/announcing_the_quantified_health_prize/\">Announcing the Quantified Health Prize</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">I am happy to announce that Scott Alexander, better known on Less Wrong as Yvain, has won the first Quantified Health Prize, and Kevin Fischer has been awarded second place. There were exactly five entries, so the remaining prizes will go to Steven Kaas, Kevin Keith and Michael Buck Shlegeris.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">The full announcement can be found&nbsp;<a href=\"http://www.medicineispersonal.com/contest/home\">here</a>&nbsp;until the second contest is announced, and is reproduced below the fold.&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">While we had hoped to receive more than five entries, I feel strongly that we still got our money&rsquo;s worth and more. Scott Alexander and Kevin Fischer in particular put in a lot of work, and provided largely distinct sets of insight into the question. In general, it is clear that much time was usefully spent, and all five entries had something unique to contribute to the problem.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">We consider the first contest a success, and intend to announce a second contest in the next few weeks that will feature multiple questions and a much larger prize pool.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Discussion of all five entries follows:<span style=\"color: #ffffff; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; font-size: 18px; line-height: 24px;\">Place ($500):</span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">5th Place ($500):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/5th\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Steven Kaas makes a well-reasoned argument for selenium supplementation. That obviously wasn't a complete entry. It's very possible this was a strategic decision in the hopes there would be less than five other entries, and if so it was a smart gamble that paid off. I sympathize with his statements on the difficulty of making good decisions in this space.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\">4th Place ($500):</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">4th Place ($500):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/4th\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Kevin Keeth&rsquo;s Recommendation List is as follows: &ldquo;No quantified recommendations were developed. See &lsquo;Report Body&rsquo; for excruciating confession of abject failure.&rdquo; A failure that is admitted to and analyzed with such honesty is valuable, and I&rsquo;m glad that Kevin submitted an entry rather than giving up, even though he considered his entry invalid and failure is still failure. Many of the concerns raised in his explanation are no doubt valid concerns. I do think it is worth noting that a Bayesian approach is not at a loss when the data is threadbare, and the probabilistic consequences of actions are highly uncertain. Indeed, this is where a Bayesian approach is most vital, as other methods are forced to throw up their hands. Despite the protests, Kevin does provide strong cases against supplementation of a number of trace minerals that were left unconsidered by other entries, which is good confirmation to have.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\">3rd Place ($500):</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">3rd Place ($500):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/3rd\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Michael Buck Shlegeris chose to consider only five minerals, but made reasonable choices of which five to include. None of the recommendations made on those five seem unreasonable, but the reasoning leading to them is unsound. This starts with the decision to exclude studies with less than a thousand participants. While larger sample sizes are obviously better (all else being equal), larger studies also tend to be retrospective, longitudinal monitoring studies and meta-analyses. The conclusions in each section are not justified by the sources cited, and the RDI (while a fine starting point) is leaned on too heavily. There is no cost/benefit analysis, nor are the recommendations quantified. This is a serious entry, but one that falls short.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\">2nd Place ($1000):</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">2nd Place ($1000):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/2nd\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Kevin Fischer provides a treasure trove of information, teasing out many fine details that the other entries missed, and presented advocacy of an alternate approach that treats supplementation as a last resort far inferior to dietary modifications. Many concerns were raised about method of intake, ratios of minerals, absorption, and the various forms of each mineral. This is impressive work. There is much here that we will need to address seriously in the future, and we&rsquo;re proud to have added Kevin Fischer to our research team; he has already been of great help, and we will no doubt revisit these questions.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Unfortunately, this entry falls short in several important ways. An important quote from the paper:</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">\"&ldquo;Eat food high in nutrients&rdquo; represents something like the null hypothesis on nutrition - human beings were eating food for millions of years before extracting individual constituents was even possible. &ldquo;Take supplements&rdquo; is the alternative hypothesis.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">This is an explicitly frequentist, and also Romantic, approach to the issue. Supplementation can go wrong, but so can whole foods, and there&rsquo;s no reason to presume that what we did, or are currently doing with them, is ideal. Supplementation is considered only as a last resort, after radical dietary interventions have &ldquo;failed,&rdquo; and no numbers or targets for it are given. No cost-benefit analysis is done on either supplementation or on the main recommendations.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\">Winner ($5000): Scott Alexander (Yvain)</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Winner: Scott Alexander / Yvain ($5000):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/1st\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Scott Alexander&rsquo;s entry was not perfect, but it did a lot of things right. An explicit cost/benefit analysis was given, which was very important. The explanations of the origins of the RDAs were excellent, and overall the analysis of various minerals was strong, although some factors found by Kevin were missed. Two of the analyses raised concerns worth noting: potassium and sodium.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">On sodium, the concern was that the analysis treated the case as clear cut when it was not; there have been challenges to salt being bad, as referenced last year by Robin Hanson, and the anti-salt studies are making the two-stage argument that blood pressure causes risks and salt raises blood pressure, rather than looking at mortality. However, the conclusions here are still reasonable, especially for ordinary Americans regularly eating super-stimulus foods loaded with the stuff.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"khReijeucXJTnsyMT": 1, "xHjy88N2uJvGdgzfw": 1, "XqykXFKL9t38pbSEm": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yMKfih99nSqRyphkD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 45, "baseScore": 68, "extendedScore": null, "score": 0.00010634918258405738, "legacy": true, "legacyId": "13176", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 44, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Follow-up to: <a href=\"/lw/8nx/announcing_the_quantified_health_prize/\">Announcing the Quantified Health Prize</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">I am happy to announce that Scott Alexander, better known on Less Wrong as Yvain, has won the first Quantified Health Prize, and Kevin Fischer has been awarded second place. There were exactly five entries, so the remaining prizes will go to Steven Kaas, Kevin Keith and Michael Buck Shlegeris.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">The full announcement can be found&nbsp;<a href=\"http://www.medicineispersonal.com/contest/home\">here</a>&nbsp;until the second contest is announced, and is reproduced below the fold.&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">While we had hoped to receive more than five entries, I feel strongly that we still got our money\u2019s worth and more. Scott Alexander and Kevin Fischer in particular put in a lot of work, and provided largely distinct sets of insight into the question. In general, it is clear that much time was usefully spent, and all five entries had something unique to contribute to the problem.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">We consider the first contest a success, and intend to announce a second contest in the next few weeks that will feature multiple questions and a much larger prize pool.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Discussion of all five entries follows:<span style=\"color: #ffffff; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; font-size: 18px; line-height: 24px;\">Place ($500):</span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">5th Place ($500):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/5th\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Steven Kaas makes a well-reasoned argument for selenium supplementation. That obviously wasn't a complete entry. It's very possible this was a strategic decision in the hopes there would be less than five other entries, and if so it was a smart gamble that paid off. I sympathize with his statements on the difficulty of making good decisions in this space.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\" id=\"4th_Place___500__\">4th Place ($500):</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">4th Place ($500):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/4th\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Kevin Keeth\u2019s Recommendation List is as follows: \u201cNo quantified recommendations were developed. See \u2018Report Body\u2019 for excruciating confession of abject failure.\u201d A failure that is admitted to and analyzed with such honesty is valuable, and I\u2019m glad that Kevin submitted an entry rather than giving up, even though he considered his entry invalid and failure is still failure. Many of the concerns raised in his explanation are no doubt valid concerns. I do think it is worth noting that a Bayesian approach is not at a loss when the data is threadbare, and the probabilistic consequences of actions are highly uncertain. Indeed, this is where a Bayesian approach is most vital, as other methods are forced to throw up their hands. Despite the protests, Kevin does provide strong cases against supplementation of a number of trace minerals that were left unconsidered by other entries, which is good confirmation to have.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\" id=\"3rd_Place___500__\">3rd Place ($500):</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">3rd Place ($500):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/3rd\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Michael Buck Shlegeris chose to consider only five minerals, but made reasonable choices of which five to include. None of the recommendations made on those five seem unreasonable, but the reasoning leading to them is unsound. This starts with the decision to exclude studies with less than a thousand participants. While larger sample sizes are obviously better (all else being equal), larger studies also tend to be retrospective, longitudinal monitoring studies and meta-analyses. The conclusions in each section are not justified by the sources cited, and the RDI (while a fine starting point) is leaned on too heavily. There is no cost/benefit analysis, nor are the recommendations quantified. This is a serious entry, but one that falls short.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\" id=\"2nd_Place___1000__\">2nd Place ($1000):</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">2nd Place ($1000):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/2nd\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Kevin Fischer provides a treasure trove of information, teasing out many fine details that the other entries missed, and presented advocacy of an alternate approach that treats supplementation as a last resort far inferior to dietary modifications. Many concerns were raised about method of intake, ratios of minerals, absorption, and the various forms of each mineral. This is impressive work. There is much here that we will need to address seriously in the future, and we\u2019re proud to have added Kevin Fischer to our research team; he has already been of great help, and we will no doubt revisit these questions.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Unfortunately, this entry falls short in several important ways. An important quote from the paper:</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">\"\u201cEat food high in nutrients\u201d represents something like the null hypothesis on nutrition - human beings were eating food for millions of years before extracting individual constituents was even possible. \u201cTake supplements\u201d is the alternative hypothesis.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">This is an explicitly frequentist, and also Romantic, approach to the issue. Supplementation can go wrong, but so can whole foods, and there\u2019s no reason to presume that what we did, or are currently doing with them, is ideal. Supplementation is considered only as a last resort, after radical dietary interventions have \u201cfailed,\u201d and no numbers or targets for it are given. No cost-benefit analysis is done on either supplementation or on the main recommendations.</p>\n<h3 style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 5px; margin-left: -50px; padding-top: 2px; padding-right: 50px; padding-bottom: 0px; padding-left: 50px; border-image: initial; font-size: 18px; line-height: 24px; font-family: 'Nanum Gothic', 'Century Gothic', 'News Gothic MT', Helvetica; color: #ffffff; width: 898px; height: 26px; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px initial initial;\" id=\"Winner___5000___Scott_Alexander__Yvain_\">Winner ($5000): Scott Alexander (Yvain)</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Winner: Scott Alexander / Yvain ($5000):&nbsp;<a style=\"border-image: initial; line-height: inherit; font-family: inherit; color: #0069d6; text-decoration: none; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.medicineispersonal.com/contest/1st\">Full report</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">Scott Alexander\u2019s entry was not perfect, but it did a lot of things right. An explicit cost/benefit analysis was given, which was very important. The explanations of the origins of the RDAs were excellent, and overall the analysis of various minerals was strong, although some factors found by Kevin were missed. Two of the analyses raised concerns worth noting: potassium and sodium.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; border-image: initial; font-size: 14px; line-height: 20px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; color: #404040; padding: 0px; border: 0px initial initial;\">On sodium, the concern was that the analysis treated the case as clear cut when it was not; there have been challenges to salt being bad, as referenced last year by Robin Hanson, and the anti-salt studies are making the two-stage argument that blood pressure causes risks and salt raises blood pressure, rather than looking at mortality. However, the conclusions here are still reasonable, especially for ordinary Americans regularly eating super-stimulus foods loaded with the stuff.</p>\n<p>&nbsp;</p>", "sections": [{"title": "4th Place ($500):", "anchor": "4th_Place___500__", "level": 1}, {"title": "3rd Place ($500):", "anchor": "3rd_Place___500__", "level": 1}, {"title": "2nd Place ($1000):", "anchor": "2nd_Place___1000__", "level": 1}, {"title": "Winner ($5000): Scott Alexander (Yvain)", "anchor": "Winner___5000___Scott_Alexander__Yvain_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "65 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Y9iXchCMdYLsPNzZM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-19T11:29:49.783Z", "modifiedAt": null, "url": null, "title": "MITx class(es): [LINK] and discussion", "slug": "mitx-class-es-link-and-discussion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.039Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "LxmsZsaFcsuHYBP8P", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WwiT5n29twspfHgPj/mitx-class-es-link-and-discussion", "pageUrlRelative": "/posts/WwiT5n29twspfHgPj/mitx-class-es-link-and-discussion", "linkUrl": "https://www.lesswrong.com/posts/WwiT5n29twspfHgPj/mitx-class-es-link-and-discussion", "postedAtFormatted": "Sunday, February 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20MITx%20class(es)%3A%20%5BLINK%5D%20and%20discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMITx%20class(es)%3A%20%5BLINK%5D%20and%20discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWwiT5n29twspfHgPj%2Fmitx-class-es-link-and-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=MITx%20class(es)%3A%20%5BLINK%5D%20and%20discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWwiT5n29twspfHgPj%2Fmitx-class-es-link-and-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWwiT5n29twspfHgPj%2Fmitx-class-es-link-and-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 159, "htmlBody": "<p>MIT is offering online classes under the name MITx, the first of which is MITx 6.002: Circuits and Electronics. &nbsp;I think the idea is similar in philosophy to that of the Stanford AI class, which I saw interested LessWrong-ers, though the subject matter (intro EE class) may appeal less to the LessWrong programming/AI/logic demographic. &nbsp;The class itself runs from March 5 - June 8 of this year.</p>\n<p>Link: &nbsp;<a href=\"https://6002x.mitx.mit.edu/\">MITx 6.002</a></p>\n<p>I've registered for the class already; I've always felt as though circuit theory was a weak point for me compared to EE friends, as physics classes gave me the bare bones by comparison. &nbsp;Feel free to bug me with questions like, \"So how much progress have you made recently with the MITx class?\" (I'll take any free sources of motivation that I can get.) &nbsp;Also, if any LessWrong-ers are interested, we could start a study group when the class actually begins to keep ourselves motivated and on top of the material. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WwiT5n29twspfHgPj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "13214", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-20T00:30:18.441Z", "modifiedAt": null, "url": null, "title": "Longevity Insurance", "slug": "longevity-insurance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.777Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "canadaduane", "createdAt": "2009-10-13T04:52:20.161Z", "isAdmin": false, "displayName": "canadaduane"}, "userId": "zRyEgmfkqQBX6n8WT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qvb9y8BYHneRPchXo/longevity-insurance", "pageUrlRelative": "/posts/qvb9y8BYHneRPchXo/longevity-insurance", "linkUrl": "https://www.lesswrong.com/posts/qvb9y8BYHneRPchXo/longevity-insurance", "postedAtFormatted": "Monday, February 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Longevity%20Insurance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALongevity%20Insurance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqvb9y8BYHneRPchXo%2Flongevity-insurance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Longevity%20Insurance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqvb9y8BYHneRPchXo%2Flongevity-insurance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqvb9y8BYHneRPchXo%2Flongevity-insurance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 542, "htmlBody": "<p><span style=\"color: #333333; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 14px; line-height: 22px; text-align: justify;\">Let's say we (as a country) ban life insurance and health insurance as separate packages [1] and require them to be combined in something I'll call \"Longevity Insurance\".&nbsp; The idea is that as a person/consumer, you can buy a \"life expectancy\" of 75 years, or 90 years, or whatever. In addition, you specify a maximum dollar amount that the longevity insurance will ever pay out--say, $2 million. If you have any medical issues throughout your life, up to the life expectancy threshold, the insurance plan will pay for your expenses. If it fails to keep you consciously alive for the duration of your \"life expectancy\", then upon your death, the policy guarantees that the company will pay the full remaining amount to your next of kin.</span></p>\n<div style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 40px; color: #333333; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 14px; line-height: 22px; text-align: justify; padding: 0px;\"><em style=\"padding: 0px; margin: 0px;\">As an example</em>, suppose you (let's say you're a woman) had purchased a 75-year policy, but you had a car accident.&nbsp; The paramedics tried to save you, and the hospital bill came to $100k, but even after that noble effort, you still died. As a result, your husband and children get $1.9M. Alternatively, if in our hypothetical situation they succeed in resuscitating you, the company would keep the $1.9M for future medical bills, and, if they fulfill their promise of life expectancy, they pocket the remainder as profit on your 75th birthday.</div>\n<p style=\"margin-top: 15px; margin-right: 0px; margin-bottom: 18px; margin-left: 0px; color: #333333; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 14px; line-height: 22px; text-align: justify; padding: 0px;\">It seems like this arrangement would put all of the right incentives [2] in place for both companies and individuals. Most individuals would want to avoid trivial medical expenses in order to maximize payout to family in case of accidental death. Companies would want to maximize health and longevity in order to profit from the end-of-life payout. And our society would have a way to rationally consider the value of life without resorting to arguments that essentially conclude \"life is of infinite value,\" and in doing so, prevent sensible gerontological triage. To put it into perspective, it makes little sense that we spend $1M (as a society) trying to save a 92-year-old when that same amount could have saved 10 teenagers.</p>\n<p style=\"margin-top: 15px; margin-right: 0px; margin-bottom: 18px; margin-left: 0px; color: #333333; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 14px; line-height: 22px; text-align: justify; padding: 0px;\">Longevity Insurance companies would be incentivized to become heavily involved in medical research that prevents disease, prolongs life, and keeps people healthy. I can imagine a whole array of things that make sense in this context. For example, it would be the right place to fund studies on genetics, it could be the right vehicle for getting 'free' immunizations, and it could even make public funding for \"health insurance\" easier to pass--simply set the bar low enough that everyone can agree on an age that society will extend a policy for. Do we all agree that everyone in our society should live to age 50? Super! The government will cover Longevity Insurance up to age 50.</p>\n<p style=\"margin-top: 15px; margin-right: 0px; margin-bottom: 18px; margin-left: 0px; color: #333333; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 14px; line-height: 22px; text-align: justify; padding: 0px;\">[1] We could also just allow Longevity Insurance as a free-market alternative, but for the sake of argument, let's ban its competitors.</p>\n<p style=\"margin-top: 15px; margin-right: 0px; margin-bottom: 18px; margin-left: 0px; color: #333333; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 14px; line-height: 22px; text-align: justify; padding: 0px;\">[2] The one incentive that Longevity Insurance does not seem to address well is the possibility of next-of-kin killing their loved one just prior to the end of an insurance policy. One option would be to require a one-year moratorium in the case where someone dies within a year of their policy ending. This would give time for an investigation before awarding large sums of money.</p>\n<p style=\"margin-top: 15px; margin-right: 0px; margin-bottom: 18px; margin-left: 0px; color: #333333; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 14px; line-height: 22px; text-align: justify; padding: 0px;\">* crosspost from my blog,&nbsp;http://halfcupofsugar.com/longevity-insurance</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ipJwbLxhR83ZksN6Z": 1, "xHjy88N2uJvGdgzfw": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qvb9y8BYHneRPchXo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 23, "extendedScore": null, "score": 8.518811634192424e-07, "legacy": true, "legacyId": "13220", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-20T04:31:10.652Z", "modifiedAt": null, "url": null, "title": "TEDxLive Opportunities", "slug": "tedxlive-opportunities", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.149Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uMgczb4Mt9WLayvKM/tedxlive-opportunities", "pageUrlRelative": "/posts/uMgczb4Mt9WLayvKM/tedxlive-opportunities", "linkUrl": "https://www.lesswrong.com/posts/uMgczb4Mt9WLayvKM/tedxlive-opportunities", "postedAtFormatted": "Monday, February 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20TEDxLive%20Opportunities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATEDxLive%20Opportunities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuMgczb4Mt9WLayvKM%2Ftedxlive-opportunities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=TEDxLive%20Opportunities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuMgczb4Mt9WLayvKM%2Ftedxlive-opportunities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuMgczb4Mt9WLayvKM%2Ftedxlive-opportunities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 252, "htmlBody": "<p>TED is <strong>live</strong> broadcasting one day of the TED conference to sites around the world. Entrance to the viewings should be free. I thought many LWers would be interested in this opportunity. It would also make a great meetup activity.</p>\n<p>Here is the website with the info: <a href=\"http://www.ted.com/pages/tedxlive\">http://www.ted.com/pages/tedxlive</a></p>\n<p>&gt;<span style=\"color: #3f3f3f; font-family: helvetica, arial, sans-serif; font-size: 12px; line-height: 16px;\">The idea for TEDxLive grew out of a question we at TED were asking ourselves: What would happen if we made the TED Conference more open, its impact more immediate and tangibly global? What would happen if communities around the world gathered to engage with -- and build on -- the TED Conference experience while it happened live?</span></p>\n<p>You can find a local viewing by clicking on the \"Find an Event\" tab at the top.</p>\n<p>If you think your city is too small to be hosting this, check anyway! Here in Columbus we have two viewings, one hosted by TEDxColumbus, and another hosted by TEDxOhioStateUniversity. They are at slightly different times-- Due to the time difference, they both decided to show the broadcast the next day, rather than exactly live.</p>\n<p><strong>The Downside</strong>- The broadcasts are all either on Wednesday or Thursday, and in about a week.</p>\n<p><strong>Awesome Idea</strong>- A chat room or Skype conversation of LWers from around the world watching the broadcast simultaneously (depending on whether other places are going with the \"not quite live\" idea or not).</p>\n<p>I won't be able to go to most of this, due to work, but am interested in knowing if other people are planning to participate. (And if so, how was the experience?)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uMgczb4Mt9WLayvKM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 8.519764555972146e-07, "legacy": true, "legacyId": "13237", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-20T04:58:42.584Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Dissolving the Question", "slug": "seq-rerun-dissolving-the-question", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.616Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PWwp3GgM8REibKQCg/seq-rerun-dissolving-the-question", "pageUrlRelative": "/posts/PWwp3GgM8REibKQCg/seq-rerun-dissolving-the-question", "linkUrl": "https://www.lesswrong.com/posts/PWwp3GgM8REibKQCg/seq-rerun-dissolving-the-question", "postedAtFormatted": "Monday, February 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Dissolving%20the%20Question&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Dissolving%20the%20Question%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPWwp3GgM8REibKQCg%2Fseq-rerun-dissolving-the-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Dissolving%20the%20Question%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPWwp3GgM8REibKQCg%2Fseq-rerun-dissolving-the-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPWwp3GgM8REibKQCg%2Fseq-rerun-dissolving-the-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<p>Today's post, <a href=\"/lw/of/dissolving_the_question/\">Dissolving the Question</a> was originally published on 08 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote><em>Proving that</em> you are confused may not make you feel any <em>less</em> confused.  Proving that a question is meaningless may not help you any more than answering it. Philosophy may lead you to reject the concept, but rejecting a concept is not the same as understanding the cognitive algorithms behind it. Ask yourself, as a question of cognitive science, why do humans make that mistake?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a71/seq_rerun_variable_question_fallacies/\">Variable Question Fallacies</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RMtdp6eGNjTZcmwJ6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PWwp3GgM8REibKQCg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 11, "extendedScore": null, "score": 8.519873489961531e-07, "legacy": true, "legacyId": "13238", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Mc6QcrsbH5NRXbCRX", "jw8b9wHA4qDR3poYY", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-20T08:27:17.181Z", "modifiedAt": null, "url": null, "title": "Packing savant program", "slug": "packing-savant-program", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.301Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Thomas", "createdAt": "2009-03-02T17:47:09.607Z", "isAdmin": false, "displayName": "Thomas"}, "userId": "GrAKeuxT4e9AKyHdE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hxCGtfZ4XYGMDuPH9/packing-savant-program", "pageUrlRelative": "/posts/hxCGtfZ4XYGMDuPH9/packing-savant-program", "linkUrl": "https://www.lesswrong.com/posts/hxCGtfZ4XYGMDuPH9/packing-savant-program", "postedAtFormatted": "Monday, February 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Packing%20savant%20program&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APacking%20savant%20program%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhxCGtfZ4XYGMDuPH9%2Fpacking-savant-program%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Packing%20savant%20program%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhxCGtfZ4XYGMDuPH9%2Fpacking-savant-program", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhxCGtfZ4XYGMDuPH9%2Fpacking-savant-program", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 274, "htmlBody": "<p>As I've already mentioned here before, our small goal is to built a program which only purpose is to search and submit new, previously unknown dense packing achievements to the Internet without any human intervention except to start&nbsp;it and to provide the hardware, power, internet connection and such. Every solution is the program's creation and innovation.</p>\n<p>It has been done. A small program is \"scavenging\" over the www.packomania.com and reading the best packing solutions there.&nbsp;It tries to find a better one. If it&nbsp;succeeds in 8192 seconds, then the program publishes the result on the&nbsp;<a href=\"http://www.algit.eu/htmlji/Packntile/Packing_Contest_01052010.html\">http://www.algit.eu/htmlji/Packntile/Packing_Contest_01052010.html</a>&nbsp;and sends it to Eckard Specht&nbsp; <a href=\"http://hydra.nat.uni-magdeburg.de/\">http://hydra.nat.uni-magdeburg.de/</a>&nbsp;&nbsp;by an email.</p>\n<p>(Well this emailing has been cut out already as unnecessary. Packomaia is updated from our site, directly, by mister Specht.)</p>\n<p>If there is no new better solution in those 8192 seconds, a new random problem is selected and pursued by the program. The program (formerly known as Pack'n'tile) also doesn't care if the current target solution is its own or of a human. Neither if its previous effort on that particular problem was not&nbsp;successful. Or if it was. He doesn't remember it, anyway.</p>\n<p>For now, there will be only one instance of the program somewhere near us. It is fast and powerful enough to run on a modest PC computer for a solution per day. It would took decades to populate this large searching space of various dimensions, shapes and numbers&nbsp;predominantly by its solutions, but the impact is already visible.&nbsp;Of course, more and faster CPUs will be provided for the job, eventually.&nbsp;</p>\n<p>We don't want to take the fun out of the game. On the contrary, the solutions are the most important and we are providing them.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hxCGtfZ4XYGMDuPH9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -15, "extendedScore": null, "score": 8.520698824755543e-07, "legacy": true, "legacyId": "13167", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-20T18:27:51.909Z", "modifiedAt": null, "url": null, "title": "Model Thinking class [link]", "slug": "model-thinking-class-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.500Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/byhMBQ7nmF8fQjGEz/model-thinking-class-link", "pageUrlRelative": "/posts/byhMBQ7nmF8fQjGEz/model-thinking-class-link", "linkUrl": "https://www.lesswrong.com/posts/byhMBQ7nmF8fQjGEz/model-thinking-class-link", "postedAtFormatted": "Monday, February 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Model%20Thinking%20class%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModel%20Thinking%20class%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbyhMBQ7nmF8fQjGEz%2Fmodel-thinking-class-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Model%20Thinking%20class%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbyhMBQ7nmF8fQjGEz%2Fmodel-thinking-class-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbyhMBQ7nmF8fQjGEz%2Fmodel-thinking-class-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<p>As part of the expansion of Stanford's effort to open up some of their courseware <a href=\"http://www.cscs.umich.edu/~spage/\">Scott Page</a> is giving Model Thinking course, which I suspect a lot of people here might like. There is quite a bit of Schelling-type modeling applied to a wide range of problems. The course is live, but it's not too late to sign up - <a href=\"http://www.modelthinker-class.org\">http://www.modelthinker-class.org</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "byhMBQ7nmF8fQjGEz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 8.523076098840457e-07, "legacy": true, "legacyId": "13247", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-20T19:38:05.684Z", "modifiedAt": null, "url": null, "title": "Evaluating Multiple Metrics (where not all are required)", "slug": "evaluating-multiple-metrics-where-not-all-are-required", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.207Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "imbatman", "createdAt": "2011-11-11T22:07:43.389Z", "isAdmin": false, "displayName": "imbatman"}, "userId": "ai34yuTB36YysA4v5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qtdKTbsCKi8xgmiLL/evaluating-multiple-metrics-where-not-all-are-required", "pageUrlRelative": "/posts/qtdKTbsCKi8xgmiLL/evaluating-multiple-metrics-where-not-all-are-required", "linkUrl": "https://www.lesswrong.com/posts/qtdKTbsCKi8xgmiLL/evaluating-multiple-metrics-where-not-all-are-required", "postedAtFormatted": "Monday, February 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Evaluating%20Multiple%20Metrics%20(where%20not%20all%20are%20required)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEvaluating%20Multiple%20Metrics%20(where%20not%20all%20are%20required)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqtdKTbsCKi8xgmiLL%2Fevaluating-multiple-metrics-where-not-all-are-required%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Evaluating%20Multiple%20Metrics%20(where%20not%20all%20are%20required)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqtdKTbsCKi8xgmiLL%2Fevaluating-multiple-metrics-where-not-all-are-required", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqtdKTbsCKi8xgmiLL%2Fevaluating-multiple-metrics-where-not-all-are-required", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 548, "htmlBody": "<p>This is my first article, and I'm submitting it in the discussion forum, so hopefully I've done this correctly and we can discuss!</p>\n<p>Anyway, I have a group of friends who are really interested in movies, and they feel very strongly about them. &nbsp;I find their convictions interesting. &nbsp;Specifically the way they adamantly argue that, for instance, <em>Midnight in Paris</em> is a \"better\" movie than <em>Bridesmaids </em>or whatever. &nbsp;I got to thinking about how one would create <strong>metrics </strong>by which you could evaluate any movie.</p>\n<p>First attempt: A simple scale by which you give rankings (1-10) to a list of movie attributes (the metrics), sum up the total, and highest number is the best movie.</p>\n<p>Some metrics might be:</p>\n<p>Plot/Story</p>\n<p>Acting</p>\n<p>Effects, Costumes, Editing, etc.</p>\n<p>Script/Dialogue</p>\n<p>Humor</p>\n<p>Drama/Passion</p>\n<p>Suspense</p>\n<p>So we can argue about what the metrics<strong> </strong>should be and how many we need, but since we're not worried about justifying our system objectively we can include whatever criteria we want. &nbsp;We could even add a weighting component so some metrics are worth more than others. &nbsp;My system can even be different than yours. &nbsp;The problem, though, is that in reality movies don't need to excel at all metrics to be perfect for what they are. &nbsp;Would&nbsp;Schindler's&nbsp;List be a better movie if they were cracking jokes the whole time? &nbsp;Would 12 Angry Men be better if it had more special effects? &nbsp;And it's a little weird to evaluate the acting in <em>Up</em> or <em>Toy Story 3</em>. &nbsp;(No offense to voice actors.)</p>\n<p>The idea of ranking movies is really about the challenge of comparing things that are the same <strong>class</strong> (movies) but very different <strong>types </strong>(comedy, horror, drama, etc) -- in content, goal, method, etc. &nbsp;Is it possible to come up with metrics by which to compare anything in the class<strong> </strong>regardless of type? &nbsp;Assuming you can come up with which metrics you find valuable/relevant, some of them will apply to one type but not another. &nbsp;But you also can't completely disregard metrics that are not common between all types, because you've just said you find them valuable/relevant (in this case, to your enjoyment of a movie).</p>\n<p>These thoughts led me to the question which I will pose here: How do you evaluate items in a class<strong> </strong>based on multiple metrics when not all metrics are ALWAYS relevant?</p>\n<p>Some brainstorming to try to answer that question (modifying the system proposed above):</p>\n<p>Allow \"N/A\" for a metric and then divide the total points by the total possible based on applicable metrics. &nbsp;But this ignores, for example, humorless movies that could have used some humor.</p>\n<p>Ok, so maybe give a movie with no humor a 10/10 in the humor metric IF it was perfect without it, or some other X/10 if it needed some humor. &nbsp;But that seems to inflate the movie's rating by giving some amount of credit for an attribute<strong>&nbsp;</strong>that it didn't actually have.</p>\n<p>I briefly considered having flexible weightings assigned subjectively to the metrics for each movie rated. &nbsp;But the whole point of this is to have standard criteria for all movies -- not different scales.</p>\n<p>&nbsp;</p>\n<p>Anyway, any ideas? &nbsp;Are there already systems for this sort of thing in different arenas of which I'm not aware? &nbsp;Could you develop a system for this sort of evaluation that could also be used to evaluate businesses, school classes, marketing techniques, or just about anything else?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qtdKTbsCKi8xgmiLL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -4, "extendedScore": null, "score": 8.523354165462714e-07, "legacy": true, "legacyId": "13249", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T02:37:12.193Z", "modifiedAt": null, "url": null, "title": "An interesting, novel approach to designing computer processors", "slug": "an-interesting-novel-approach-to-designing-computer", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.932Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "D_Alex", "createdAt": "2009-07-17T08:21:38.505Z", "isAdmin": false, "displayName": "D_Alex"}, "userId": "Sriopfkdwx2qJBx4G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SjQgsaYq3Aq2kpYbZ/an-interesting-novel-approach-to-designing-computer", "pageUrlRelative": "/posts/SjQgsaYq3Aq2kpYbZ/an-interesting-novel-approach-to-designing-computer", "linkUrl": "https://www.lesswrong.com/posts/SjQgsaYq3Aq2kpYbZ/an-interesting-novel-approach-to-designing-computer", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20interesting%2C%20novel%20approach%20to%20designing%20computer%20processors&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20interesting%2C%20novel%20approach%20to%20designing%20computer%20processors%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSjQgsaYq3Aq2kpYbZ%2Fan-interesting-novel-approach-to-designing-computer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20interesting%2C%20novel%20approach%20to%20designing%20computer%20processors%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSjQgsaYq3Aq2kpYbZ%2Fan-interesting-novel-approach-to-designing-computer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSjQgsaYq3Aq2kpYbZ%2Fan-interesting-novel-approach-to-designing-computer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 244, "htmlBody": "<p>Here is &nbsp;presentation from a researcher at MIT on a novel way of designing computer processors. It relies on performing approximate, rather than exact, mathematical operations (like the meat-based processor in our heads!). Claimed benefits are a 10,000-fold improvement in speed, while the errors introduced by the approximations are postulated to be insignificant in many applications.</p>\n<p><a href=\"http://web.media.mit.edu/~bates/Summary_files/BatesTalk.pdf\">http://web.media.mit.edu/~bates/Summary_files/BatesTalk.pdf</a></p>\n<p>Slide #2 of the presentation offers a fascinating insight: We currently work around the limitations of the processing substrate to implement a precise computation, and it is becoming increasingly difficult:</p>\n<p>------------------</p>\n<p>THE MOTIVATING PROBLEM:</p>\n<p>Computations speci\ufb01ed by programmers&nbsp;are implemented as behavior in physical material</p>\n<p>&nbsp;</p>\n<p>&bull; Hardware designer&rsquo;s job:&nbsp;</p>\n<p>ef\ufb01ciently implement Math (what sw wants) using Physics (what silicon offers)</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (near) perfect arith &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; noisy, approximate &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;uniform mem delay &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;delay ~ distance</p>\n<p>&bull; Increasingly dif\ufb01cult as decades passed and transistor counts exploded</p>\n<p>&bull; Now each instruction (increment, load register, occasionally multiply)&nbsp;invokes &gt;10M transistor operations, even though a single transistor&nbsp;can perform, for instance, an approximate exponentiate or logarithm</p>\n<p>&nbsp;</p>\n<p>--------------------</p>\n<p>The parallels and contrasts with our own brain are what interested me the most. Perhaps one day the most powerful computers will be running on \"corrupted hardware\" of sorts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SjQgsaYq3Aq2kpYbZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 4, "extendedScore": null, "score": 8.525013913491899e-07, "legacy": true, "legacyId": "13265", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T04:37:24.759Z", "modifiedAt": null, "url": null, "title": "Ambiguity in cognitive bias names; a refresher", "slug": "ambiguity-in-cognitive-bias-names-a-refresher", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.705Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nerfhammer", "createdAt": "2009-07-21T19:45:50.831Z", "isAdmin": false, "displayName": "nerfhammer"}, "userId": "TnRcc3ezfxzQs7Phn", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xXdeJpKnyLwKWncjP/ambiguity-in-cognitive-bias-names-a-refresher", "pageUrlRelative": "/posts/xXdeJpKnyLwKWncjP/ambiguity-in-cognitive-bias-names-a-refresher", "linkUrl": "https://www.lesswrong.com/posts/xXdeJpKnyLwKWncjP/ambiguity-in-cognitive-bias-names-a-refresher", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ambiguity%20in%20cognitive%20bias%20names%3B%20a%20refresher&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAmbiguity%20in%20cognitive%20bias%20names%3B%20a%20refresher%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxXdeJpKnyLwKWncjP%2Fambiguity-in-cognitive-bias-names-a-refresher%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ambiguity%20in%20cognitive%20bias%20names%3B%20a%20refresher%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxXdeJpKnyLwKWncjP%2Fambiguity-in-cognitive-bias-names-a-refresher", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxXdeJpKnyLwKWncjP%2Fambiguity-in-cognitive-bias-names-a-refresher", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 843, "htmlBody": "<p>This came on the nyc list, I thought I would adapt it here.</p>\n<p>Cognitive biases have names. That's what makes them memetic. It's easier to think about something that has a name. Though I think the benefits outweigh the costs, there is also the risk of a <a href=\"http://en.wikipedia.org/wiki/Little_Albert_experiment#Critique\">little Albert</a>: a concept living on after the original research has been found to be much more ambiguous than first realized.</p>\n<p>There are many errors that are possible with respect to named ideas, and despite being studied generally scientifically, cognitive biases are no exception. There is no equivalent to cognitive biases as the&nbsp;Acad&eacute;mie Fran&ccedil;aise&nbsp;is to French.</p>\n<p>Let's describe some. Here they are:</p>\n<ul>\n<li>different people in different fields will \"discover\" virtually the same bias but not be aware of each other and assign it different names. For example, see the Curse of Knowledge which I think George Loewenstein came up with &nbsp;vs. the <a href=\"http://en.wikipedia.org/wiki/Historian%27s_fallacy\">Historian's Fallacy</a> by David Hackett Fischer, presentist bias, creeping determinism, and probably many others, not all of them scientific. Sometimes researchers in seemingly closely related subfields are remarkably insular to each other.&nbsp;</li>\n<li>researchers will use one term predominantly while an offshoot will decide they don't like the name and use a different one. For example the <a href=\"http://en.wikipedia.org/wiki/Fundamental_attribution_error\">Fundamental Attribution Error</a> has also been called the overattribution effect, the correspondence bias, the attribution bias, and the actor-observer effect. In this case the older term still predominates, and is used in intro textbooks without asterisks. Of the naming errors this is one of the least harmful, since everyone agrees what the FAE is, some just prefer a different name for it.</li>\n<li>an author will decide he doesn't like the names of some biases will invent idiosyncratic names of his own. Jonathan Baron has a good textbook on cognitive bias but he uses names of his own invention half the time.</li>\n<li>the same term will sometimes have different polysemous meanings. For example the \"<a href=\"http://en.wikipedia.org/wiki/Zeigarnik_effect#Zeigarnik_effect\"><em>Zeigarnik Effect</em></a>\" has been used to refer to a memory bias in having a superior recall for unfinished tasks, and the term has also been used to refer to an attentional bias in which unfinished tasks tend intrude on consciousness; almost, but not quite exactly, the same thing. The term \"<a href=\"http://en.wikipedia.org/wiki/Confirmation_bias\"><em>confirmation bias</em></a>\" has several different but related meanings, for example, to seek out confirming information, to notice confirming information, to ask confirming questions, etc. which are not all quite exactly the same thing. The different meanings may have completely different contexts, boundary conditions etc., leading to confusion. Furthermore some of the senses may be at least partially disproven but not&nbsp;necessarily&nbsp;others, for example, the tendency to ask confirming questions has turned out to be more complicated than once thought. You might never know from reading about the attentional Zeigarnik that there is also a memory Zeiganik effect that is conceptually somewhat different. I recall seeing even prominent researchers occasionally making mistakes of this category. Of all the naming ambiguities I think is the most dangerous.</li>\n<li>an offshoot of researchers may knowingly use the same term with a conflicting definition.&nbsp;<span style=\"text-decoration: line-through;\">For example \"heuristic\" in \"Heuristics and Biases\" versus \"Fast and Frugal Heuristics\", the latter of which was an intentional reaction to the former. In this case those involved know there is a disagreement in meaning, but those unfamiliar to the topic might be confused.</span>[This is a point of contention which I'm willing to yield on]</li>\n<li>the same term may be redefined by researchers who may not aware of each other. There has been more than one paper trying to introduce a bias to call \"the disconfirmation effect\". But this only happens for really obscure biases.</li>\n<li>a bias may have different components which do not have names of their own and/or a bias may overlap partially but not completely with another bias. For instance, <a href=\"http://en.wikipedia.org/wiki/Hindsight_bias\">hindsight bias</a> has different components one of which has some overlap with the curse of knowledge.&nbsp;</li>\n<li>the same bias term will be used as a rough category of experimental effect and also as a singular bias. For example, the term \"<strong>an</strong> actor-observer bias\" could refer to any difference in actors and observers, whereas \"<strong>the</strong> actor-observer bias\" refers to the Fundamental Attribution Error specifically; the same is true of \"an\" vs. \"the\" attribution bias, also referring to the FAE. This could confuse only those who are unfamiliar with the terminology.</li>\n<li>sometimes authors have tried to enforce strict, distinct meanings for the subterms \"bias\" vs. \"effect\" vs. \"neglect\" vs. \"error\" or \"fallacy\"; other times, perhaps more often, these terms are used only by convention. For example the conjunction fallacy vs. the conjunction error, correspondence bias vs. the fundamental attribution error, base rate neglect vs. base rate error. Sometimes the originators of a bias try to use the terminology precisely while later authors citing it aren't as careful. Sometimes even the originators of a bias do not try to choose a subterm carefully. You might suspect what permutation of a term catches on is based on whichever has a better ring to it.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xXdeJpKnyLwKWncjP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 39, "extendedScore": null, "score": 6.7e-05, "legacy": true, "legacyId": "13268", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T05:02:20.747Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Wrong Questions", "slug": "seq-rerun-wrong-questions", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LhuQz4gCR4nmESvKj/seq-rerun-wrong-questions", "pageUrlRelative": "/posts/LhuQz4gCR4nmESvKj/seq-rerun-wrong-questions", "linkUrl": "https://www.lesswrong.com/posts/LhuQz4gCR4nmESvKj/seq-rerun-wrong-questions", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Wrong%20Questions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Wrong%20Questions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLhuQz4gCR4nmESvKj%2Fseq-rerun-wrong-questions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Wrong%20Questions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLhuQz4gCR4nmESvKj%2Fseq-rerun-wrong-questions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLhuQz4gCR4nmESvKj%2Fseq-rerun-wrong-questions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<p>Today's post, <a href=\"/lw/og/wrong_questions/\">Wrong Questions</a> was originally published on 08 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Where the mind cuts against reality's grain, it generates wrong questions - questions that cannot possibly be answered on their own terms, but only <em>dissolved </em>by understanding the cognitive algorithm that generates the perception of a question.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a7q/seq_rerun_dissolving_the_question/\">Dissolving the Question</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LhuQz4gCR4nmESvKj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.525588839064575e-07, "legacy": true, "legacyId": "13269", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XzrqkhfwtiSDgKoAF", "PWwp3GgM8REibKQCg", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T05:29:03.556Z", "modifiedAt": null, "url": null, "title": "A brief tutorial on preferences in AI", "slug": "a-brief-tutorial-on-preferences-in-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.093Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q9nhAp3q27xS3AgtB/a-brief-tutorial-on-preferences-in-ai", "pageUrlRelative": "/posts/Q9nhAp3q27xS3AgtB/a-brief-tutorial-on-preferences-in-ai", "linkUrl": "https://www.lesswrong.com/posts/Q9nhAp3q27xS3AgtB/a-brief-tutorial-on-preferences-in-ai", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20brief%20tutorial%20on%20preferences%20in%20AI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20brief%20tutorial%20on%20preferences%20in%20AI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ9nhAp3q27xS3AgtB%2Fa-brief-tutorial-on-preferences-in-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20brief%20tutorial%20on%20preferences%20in%20AI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ9nhAp3q27xS3AgtB%2Fa-brief-tutorial-on-preferences-in-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ9nhAp3q27xS3AgtB%2Fa-brief-tutorial-on-preferences-in-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 790, "htmlBody": "<p>Preferences are important both <a href=\"/lw/8q8/urges_vs_goals_the_analogy_to_anticipation_and/\">for rationality</a> and <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/11/Muehlhauser-Helm-The-Singularity-and-Machine-Ethics-draft.pdf\">for Friendly AI</a>, so preferences are a <a href=\"http://wiki.lesswrong.com/wiki/Preference\">major</a> <a href=\"/lw/xy/the_fun_theory_sequence/\">topic</a> <a href=\"/lw/lq/fake_utility_functions/\">of</a> <a href=\"/lw/l3/thou_art_godshatter/\">discussion</a> <a href=\"/lw/lb/not_for_the_sake_of_happiness_alone/\">on</a> <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human/\">Less</a> <a href=\"/lw/9jh/the_humans_hidden_utility_function_maybe/\">Wrong</a>. We've discussed preferences in the context of economics and decision theory, but I think AI has a more robust set of tools for working with preferences than either economics or decision theory has, so I'd like to introduce Less Wrong to some of these tools. In particular, I think AI's toolset for working with preferences may help us think more clearly about <a href=\"http://intelligence.org/upload/CEV.html\">CEV</a>.</p>\n<p>In AI, we can think of working with preferences in four steps:</p>\n<ol>\n<li><strong>Preference acquisition</strong>: In this step, we aim to extract preferences from a user. This can occur either by <em>preference learning</em>&nbsp;or by <em>preference elicitation</em>. Preference learning occurs when preferences are acquired from data about the user's past behavior or past preferences. Preference elicitation occurs as a result of an interactive process with the user, e.g. a question-answer process.</li>\n<li><strong>Preferences modeling</strong>: Our next step is to mathematically express these acquired preferences as preferences between pairwise choices. The properties of a preferences model are important. For example, is the relation <em>transitive</em>? (If the model tells us that choice c<sub>1</sub> is preferred to c<sub>2</sub>, and c2 is preferred to c<sub>3</sub>, can we conclude that c<sub>1</sub> is preferred to c<sub>3</sub>?) And is the relation <em>complete</em>? (Is any choice comparable to any other choice, or are there some incomparabilities?)</li>\n<li><strong>Preference representation</strong>: Assuming we want to capture and manipulate the user's preferences robustly, we'll next want to represent the preferences model in a <em>preference representation language</em>.</li>\n<li><strong>Preferences reasoning</strong>: Once a user's preferences are represented in a preference representation language, we can do cool things like <em>preferences aggregation</em>&nbsp;(involving the preferences of multiple agents) and&nbsp;<em>preference revision</em>&nbsp;(a user's new preferences being added to her old preferences). We can also perform the usual computations of decision theory, game theory, and more.</li>\n</ol>\n<p>&nbsp;</p>\n<h3>Preference acquisition</h3>\n<p>Preference learning is typically an application of <a href=\"http://en.wikipedia.org/wiki/Supervised_learning\">supervised machine learning</a> (classification). Throw the algorithm at a database containing a user's preferences, and it will learn that user's preferences and make predictions about the preferences not listed in the database, including preferences about pairwise choices the user may never have faced before.</p>\n<p>Preference elicitation involves asking a user a series of questions, and extracting their preferences from the answers they give. <a href=\"http://hci.epfl.ch/members/lichen/IC_TECH_REPORT_200467.pdf\">Chen &amp; Pu (2004)</a> survey some of the methods used for this.</p>\n<p>In studying CEV, I am interested in methods built for learning a user's utility function from inconsistent behavior (because <a href=\"/lw/6da/do_humans_want_things/\">humans make inconsistent choices</a>). <a href=\"http://people.cs.aau.dk/~tdn/papers/nielsen-jensen-04-ai.pdf\">Nielsen &amp; Jensen (2004)</a> provided two computationally tractable algorithms which handle the problem by interpreting inconsistent behavior as random deviations from an underlying \"true\" utility function. As far as I know, however, nobody in AI has tried to solve the problem with an algorithm informed by the <a href=\"/lw/9jh/the_humans_hidden_utility_function_maybe/\">latest data from neuroeconomics</a> on how human choice is the product of at least three valuation systems, only one of which looks anything like an \"underlying true utility function.\"</p>\n<p>&nbsp;</p>\n<h3>Preference Modeling</h3>\n<p>A model of a user's preferences describes one of three relations between any two choices (\"objects\"): a <em>strict&nbsp;preference</em> relation which says that one choice is preferred to another, an <em>indifference</em>&nbsp;relation, and an <em>incomparability</em>&nbsp;relation. Kaci (2011), chapter 2 provides a brief account of preference modeling.</p>\n<p>&nbsp;</p>\n<h3>Preference Representation</h3>\n<p>In decision theory, a preference relation is represented by a numerical function with associates a utility value with each choice. But this may not be the best representation. We face an exponential number of choices whose explicit enumeration and evaluation is time-consuming. Moreover, users can't compare all pairwise choices and evaluate how satisfactory each choice is.</p>\n<p>Luckily, choices are often made on the basis of a set of attributes, e.g. cost, color, price, etc. You can use a preference representation language to represent partial descriptions of preferences and rank-order possible choices. The challenge of a preference representation language is that it should (1) cope with a user's preferences, (2) faithfully represent the user's preferences such that it rank-orders choices in a way similar to how the user would specify choices if they were able to provide preferences for every pairwise comparison, (3) cope with possibly inconsistent preferences, and (4) offer attractive complexity properties, i.e. the spatial cost of representing partial descriptions of preferences and the time cost of comparing pairwise choices or computing the best choices.</p>\n<p>One popular method of preference representation is with the graphical representation language of <em>conditional preference networks</em>&nbsp;or \"CP-nets.\" They look like <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/CP-net.gif\">this</a>.</p>\n<p>&nbsp;</p>\n<h3>Preferences Reasoning</h3>\n<p>There are a multitude of ways in which one might want to reason algorithmically about preferences. I point the reader to Part II of Kaci (2011) for a very incomplete overview.</p>\n<p>&nbsp;</p>\n<h3>General Sources:</h3>\n<p><small>Domshlak et al. (2011). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/08/Domshlak-et-al-Preferences-in-AI-an-overview.pdf\">Preferences in AI: An Overview</a>. <em>Artificial Intelligence 175</em>: 1037-1052.</small></p>\n<p><small>F&uuml;rnkranz &amp; H&uuml;llermeier (2010). <em><a href=\"http://www.amazon.com/Preference-Learning-Johannes-F%C3%BCrnkranz/dp/3642141242/\">Preference Learning</a></em>. Springer.</small></p>\n<p><small>Kaci (2011). <em><a href=\"http://www.amazon.com/Working-Preferences-Less-Cognitive-Technologies/dp/3642172792/\">Working with Preferences: Less is More</a></em>. Springer.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q9nhAp3q27xS3AgtB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 19, "extendedScore": null, "score": 5e-05, "legacy": true, "legacyId": "13215", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Preferences are important both <a href=\"/lw/8q8/urges_vs_goals_the_analogy_to_anticipation_and/\">for rationality</a> and <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/11/Muehlhauser-Helm-The-Singularity-and-Machine-Ethics-draft.pdf\">for Friendly AI</a>, so preferences are a <a href=\"http://wiki.lesswrong.com/wiki/Preference\">major</a> <a href=\"/lw/xy/the_fun_theory_sequence/\">topic</a> <a href=\"/lw/lq/fake_utility_functions/\">of</a> <a href=\"/lw/l3/thou_art_godshatter/\">discussion</a> <a href=\"/lw/lb/not_for_the_sake_of_happiness_alone/\">on</a> <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human/\">Less</a> <a href=\"/lw/9jh/the_humans_hidden_utility_function_maybe/\">Wrong</a>. We've discussed preferences in the context of economics and decision theory, but I think AI has a more robust set of tools for working with preferences than either economics or decision theory has, so I'd like to introduce Less Wrong to some of these tools. In particular, I think AI's toolset for working with preferences may help us think more clearly about <a href=\"http://intelligence.org/upload/CEV.html\">CEV</a>.</p>\n<p>In AI, we can think of working with preferences in four steps:</p>\n<ol>\n<li><strong>Preference acquisition</strong>: In this step, we aim to extract preferences from a user. This can occur either by <em>preference learning</em>&nbsp;or by <em>preference elicitation</em>. Preference learning occurs when preferences are acquired from data about the user's past behavior or past preferences. Preference elicitation occurs as a result of an interactive process with the user, e.g. a question-answer process.</li>\n<li><strong>Preferences modeling</strong>: Our next step is to mathematically express these acquired preferences as preferences between pairwise choices. The properties of a preferences model are important. For example, is the relation <em>transitive</em>? (If the model tells us that choice c<sub>1</sub> is preferred to c<sub>2</sub>, and c2 is preferred to c<sub>3</sub>, can we conclude that c<sub>1</sub> is preferred to c<sub>3</sub>?) And is the relation <em>complete</em>? (Is any choice comparable to any other choice, or are there some incomparabilities?)</li>\n<li><strong>Preference representation</strong>: Assuming we want to capture and manipulate the user's preferences robustly, we'll next want to represent the preferences model in a <em>preference representation language</em>.</li>\n<li><strong>Preferences reasoning</strong>: Once a user's preferences are represented in a preference representation language, we can do cool things like <em>preferences aggregation</em>&nbsp;(involving the preferences of multiple agents) and&nbsp;<em>preference revision</em>&nbsp;(a user's new preferences being added to her old preferences). We can also perform the usual computations of decision theory, game theory, and more.</li>\n</ol>\n<p>&nbsp;</p>\n<h3 id=\"Preference_acquisition\">Preference acquisition</h3>\n<p>Preference learning is typically an application of <a href=\"http://en.wikipedia.org/wiki/Supervised_learning\">supervised machine learning</a> (classification). Throw the algorithm at a database containing a user's preferences, and it will learn that user's preferences and make predictions about the preferences not listed in the database, including preferences about pairwise choices the user may never have faced before.</p>\n<p>Preference elicitation involves asking a user a series of questions, and extracting their preferences from the answers they give. <a href=\"http://hci.epfl.ch/members/lichen/IC_TECH_REPORT_200467.pdf\">Chen &amp; Pu (2004)</a> survey some of the methods used for this.</p>\n<p>In studying CEV, I am interested in methods built for learning a user's utility function from inconsistent behavior (because <a href=\"/lw/6da/do_humans_want_things/\">humans make inconsistent choices</a>). <a href=\"http://people.cs.aau.dk/~tdn/papers/nielsen-jensen-04-ai.pdf\">Nielsen &amp; Jensen (2004)</a> provided two computationally tractable algorithms which handle the problem by interpreting inconsistent behavior as random deviations from an underlying \"true\" utility function. As far as I know, however, nobody in AI has tried to solve the problem with an algorithm informed by the <a href=\"/lw/9jh/the_humans_hidden_utility_function_maybe/\">latest data from neuroeconomics</a> on how human choice is the product of at least three valuation systems, only one of which looks anything like an \"underlying true utility function.\"</p>\n<p>&nbsp;</p>\n<h3 id=\"Preference_Modeling\">Preference Modeling</h3>\n<p>A model of a user's preferences describes one of three relations between any two choices (\"objects\"): a <em>strict&nbsp;preference</em> relation which says that one choice is preferred to another, an <em>indifference</em>&nbsp;relation, and an <em>incomparability</em>&nbsp;relation. Kaci (2011), chapter 2 provides a brief account of preference modeling.</p>\n<p>&nbsp;</p>\n<h3 id=\"Preference_Representation\">Preference Representation</h3>\n<p>In decision theory, a preference relation is represented by a numerical function with associates a utility value with each choice. But this may not be the best representation. We face an exponential number of choices whose explicit enumeration and evaluation is time-consuming. Moreover, users can't compare all pairwise choices and evaluate how satisfactory each choice is.</p>\n<p>Luckily, choices are often made on the basis of a set of attributes, e.g. cost, color, price, etc. You can use a preference representation language to represent partial descriptions of preferences and rank-order possible choices. The challenge of a preference representation language is that it should (1) cope with a user's preferences, (2) faithfully represent the user's preferences such that it rank-orders choices in a way similar to how the user would specify choices if they were able to provide preferences for every pairwise comparison, (3) cope with possibly inconsistent preferences, and (4) offer attractive complexity properties, i.e. the spatial cost of representing partial descriptions of preferences and the time cost of comparing pairwise choices or computing the best choices.</p>\n<p>One popular method of preference representation is with the graphical representation language of <em>conditional preference networks</em>&nbsp;or \"CP-nets.\" They look like <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/CP-net.gif\">this</a>.</p>\n<p>&nbsp;</p>\n<h3 id=\"Preferences_Reasoning\">Preferences Reasoning</h3>\n<p>There are a multitude of ways in which one might want to reason algorithmically about preferences. I point the reader to Part II of Kaci (2011) for a very incomplete overview.</p>\n<p>&nbsp;</p>\n<h3 id=\"General_Sources_\">General Sources:</h3>\n<p><small>Domshlak et al. (2011). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/08/Domshlak-et-al-Preferences-in-AI-an-overview.pdf\">Preferences in AI: An Overview</a>. <em>Artificial Intelligence 175</em>: 1037-1052.</small></p>\n<p><small>F\u00fcrnkranz &amp; H\u00fcllermeier (2010). <em><a href=\"http://www.amazon.com/Preference-Learning-Johannes-F%C3%BCrnkranz/dp/3642141242/\">Preference Learning</a></em>. Springer.</small></p>\n<p><small>Kaci (2011). <em><a href=\"http://www.amazon.com/Working-Preferences-Less-Cognitive-Technologies/dp/3642172792/\">Working with Preferences: Less is More</a></em>. Springer.</small></p>", "sections": [{"title": "Preference acquisition", "anchor": "Preference_acquisition", "level": 1}, {"title": "Preference Modeling", "anchor": "Preference_Modeling", "level": 1}, {"title": "Preference Representation", "anchor": "Preference_Representation", "level": 1}, {"title": "Preferences Reasoning", "anchor": "Preferences_Reasoning", "level": 1}, {"title": "General Sources:", "anchor": "General_Sources_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "16 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wmjPGE8TZKNLSKzm4", "K4aGvLnHvYgX9pZHS", "NnohDYHNnKDtbiMyp", "cSXZpvqpa9vbGGLtG", "synsRtBKDeAFuo7e3", "hN2aRnu798yas5b2k", "fa5o2tg9EfJE77jEQ", "nBdaTGoDAYxHePSDa"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T07:23:47.710Z", "modifiedAt": null, "url": null, "title": "[link] How habits control our behavior, and how to modify them", "slug": "link-how-habits-control-our-behavior-and-how-to-modify-them", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:05.088Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jYA6PqD3QevKtp3Hn/link-how-habits-control-our-behavior-and-how-to-modify-them", "pageUrlRelative": "/posts/jYA6PqD3QevKtp3Hn/link-how-habits-control-our-behavior-and-how-to-modify-them", "linkUrl": "https://www.lesswrong.com/posts/jYA6PqD3QevKtp3Hn/link-how-habits-control-our-behavior-and-how-to-modify-them", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20How%20habits%20control%20our%20behavior%2C%20and%20how%20to%20modify%20them&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20How%20habits%20control%20our%20behavior%2C%20and%20how%20to%20modify%20them%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjYA6PqD3QevKtp3Hn%2Flink-how-habits-control-our-behavior-and-how-to-modify-them%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20How%20habits%20control%20our%20behavior%2C%20and%20how%20to%20modify%20them%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjYA6PqD3QevKtp3Hn%2Flink-how-habits-control-our-behavior-and-how-to-modify-them", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjYA6PqD3QevKtp3Hn%2Flink-how-habits-control-our-behavior-and-how-to-modify-them", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1961, "htmlBody": "<p>The New York Times just recently ran an article titled \"<a href=\"https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\">How Companies Learn Your Secrets</a>\", which was partially discussing data mining and partially discussing habits. I thought the bits on habits seemed to offer many valuable insights on how to improve our behavior, excerpts:</p>\n<blockquote>\n<p>The process within our brains that creates habits is a three-step loop. First, there is a cue, a trigger that tells your brain to go into automatic mode and which habit to use. Then there is the routine, which can be physical or mental or emotional. Finally, there is a reward, which helps your brain \ufb01gure out if this particular loop is worth remembering for the future. Over time, this loop &mdash; cue, routine, reward; cue, routine, reward &mdash; becomes more and more automatic. The cue and reward become neurologically intertwined until a sense of craving emerges. What&rsquo;s unique about cues and rewards, however, is how subtle they can be. Neurological studies like the ones in Graybiel&rsquo;s lab have revealed that some cues span just milliseconds. And rewards can range from the obvious (like the sugar rush that a morning doughnut habit provides) to the infinitesimal (like the barely noticeable &mdash; but measurable &mdash; sense of relief the brain experiences after successfully navigating the driveway). Most cues and rewards, in fact, happen so quickly and are so slight that we are hardly aware of them at all. But our neural systems notice and use them to build automatic behaviors.<br /><br />Habits aren&rsquo;t destiny &mdash; they can be ignored, changed or replaced. But it&rsquo;s also true that once the loop is established and a habit emerges, your brain stops fully participating in decision-making. So unless you deliberately \ufb01ght a habit &mdash; unless you \ufb01nd new cues and rewards &mdash; the old pattern will unfold automatically. [...]</p>\n</blockquote>\n<blockquote>\n<p>Luckily, simply understanding how habits work makes them easier to control. Take, for instance, a series of studies conducted a few years ago at Columbia University and the University of Alberta. Researchers wanted to understand how exercise habits emerge. In one project, 256 members of a health-insurance plan were invited to classes stressing the importance of exercise. Half the participants received an extra lesson on the theories of habit formation (the structure of the habit loop) and were asked to identify cues and rewards that might help them develop exercise routines.<br /><br />The results were dramatic. Over the next four months, those participants who deliberately identified cues and rewards spent twice as much time exercising as their peers. Other studies have yielded similar results. According to another recent paper, if you want to start running in the morning, it&rsquo;s essential that you choose a simple cue (like always putting on your sneakers before breakfast or leaving your running clothes next to your bed) and a clear reward (like a midday treat or even the sense of accomplishment that comes from ritually recording your miles in a log book). After a while, your brain will start anticipating that reward &mdash; craving the treat or the feeling of accomplishment &mdash; and there will be a measurable neurological impulse to lace up your jogging shoes each morning.<br /><br />Our relationship to e-mail operates on the same principle. When a computer chimes or a smartphone vibrates with a new message, the brain starts anticipating the neurological &ldquo;pleasure&rdquo; (even if we don&rsquo;t recognize it as such) that clicking on the e-mail and reading it provides. That expectation, if unsatisfied, can build until you find yourself moved to distraction by the thought of an e-mail sitting there unread &mdash; even if you know, rationally, it&rsquo;s most likely not important. On the other hand, once you remove the cue by disabling the buzzing of your phone or the chiming of your computer, the craving is never triggered, and you&rsquo;ll find, over time, that you&rsquo;re able to work productively for long stretches without checking your in-box. [...]</p>\n</blockquote>\n<blockquote>\n<p>When they got back to P.&amp; G.&rsquo;s headquarters, the researchers watched their videotapes again. Now they knew what to look for and saw their mistake in scene after scene. Cleaning has its own habit loops that already exist. In one video, when a woman walked into a dirty room (cue), she started sweeping and picking up toys (routine), then she examined the room and smiled when she was done (reward). In another, a woman scowled at her unmade bed (cue), proceeded to straighten the blankets and comforter (routine) and then sighed as she ran her hands over the freshly plumped pillows (reward). P.&amp; G. had been trying to create a whole new habit with Febreze, but what they really needed to do was piggyback on habit loops that were already in place. The marketers needed to position Febreze as something that came at the end of the cleaning ritual, the reward, rather than as a whole new cleaning routine.<br /><br />The company printed new ads showing open windows and gusts of fresh air. More perfume was added to the Febreze formula, so that instead of merely neutralizing odors, the spray had its own distinct scent. Television commercials were filmed of women, having finished their cleaning routine, using Febreze to spritz freshly made beds and just-laundered clothing. Each ad was designed to appeal to the habit loop: when you see a freshly cleaned room (cue), pull out Febreze (routine) and enjoy a smell that says you&rsquo;ve done a great job (reward). When you finish making a bed (cue), spritz Febreze (routine) and breathe a sweet, contented sigh (reward). Febreze, the ads implied, was a pleasant treat, not a reminder that your home stinks. <br /><br />And so Febreze, a product originally conceived as a revolutionary way to destroy odors, became an air freshener used once things are already clean. The Febreze revamp occurred in the summer of 1998. Within two months, sales doubled. A year later, the product brought in $230 million. Since then Febreze has spawned dozens of spinoffs &mdash; air fresheners, candles and laundry detergents &mdash; that now account for sales of more than $1 billion a year. Eventually, P.&amp; G. began mentioning to customers that, in addition to smelling sweet, Febreze can actually kill bad odors. Today it&rsquo;s one of the top-selling products in the world. [...]</p>\n</blockquote>\n<blockquote>\n<p>But when some customers were going through a major life event, like graduating from college or getting a new job or moving to a new town, their shopping habits became flexible in ways that were both predictable and potential gold mines for retailers. The study found that when someone marries, he or she is more likely to start buying a new type of coffee. When a couple move into a new house, they&rsquo;re more apt to purchase a different kind of cereal. When they divorce, there&rsquo;s an increased chance they&rsquo;ll start buying different brands of beer.<br /><br />Consumers going through major life events often don&rsquo;t notice, or care, that their shopping habits have shifted, but retailers notice, and they care quite a bit. At those unique moments, Andreasen wrote, customers are &ldquo;vulnerable to intervention by marketers.&rdquo; In other words, a precisely timed advertisement, sent to a recent divorcee or new homebuyer, can change someone&rsquo;s shopping patterns for years. [...]</p>\n</blockquote>\n<blockquote>\n<p>Before I met Andrew Pole, before I even decided to write a book about the science of habit formation, I had another goal: I wanted to lose weight.<br /><br />I had got into a bad habit of going to the cafeteria every afternoon and eating a chocolate-chip cookie, which contributed to my gaining a few pounds. Eight, to be precise. I put a Post-it note on my computer reading &ldquo;NO MORE COOKIES.&rdquo; But every afternoon, I managed to ignore that note, wander to the cafeteria, buy a cookie and eat it while chatting with colleagues. Tomorrow, I always promised myself, I&rsquo;ll muster the willpower to resist.<br /><br />Tomorrow, I ate another cookie.<br /><br />When I started interviewing experts in habit formation, I concluded each interview by asking what I should do. The first step, they said, was to figure out my habit loop. The routine was simple: every afternoon, I walked to the cafeteria, bought a cookie and ate it while chatting with friends.<br /><br />Next came some less obvious questions: What was the cue? Hunger? Boredom? Low blood sugar? And what was the reward? The taste of the cookie itself? The temporary distraction from my work? The chance to socialize with colleagues?<br /><br />Rewards are powerful because they satisfy cravings, but we&rsquo;re often not conscious of the urges driving our habits in the first place. So one day, when I felt a cookie impulse, I went outside and took a walk instead. The next day, I went to the cafeteria and bought a coffee. The next, I bought an apple and ate it while chatting with friends. You get the idea. I wanted to test different theories regarding what reward I was really craving. Was it hunger? (In which case the apple should have worked.) Was it the desire for a quick burst of energy? (If so, the coffee should suffice.) Or, as turned out to be the answer, was it that after several hours spent focused on work, I wanted to socialize, to make sure I was up to speed on office gossip, and the cookie was just a convenient excuse? When I walked to a colleague&rsquo;s desk and chatted for a few minutes, it turned out, my cookie urge was gone.<br /><br />All that was left was identifying the cue.<br /><br />Deciphering cues is hard, however. Our lives often contain too much information to figure out what is triggering a particular behavior. Do you eat breakfast at a certain time because you&rsquo;re hungry? Or because the morning news is on? Or because your kids have started eating? Experiments have shown that most cues fit into one of five categories: location, time, emotional state, other people or the immediately preceding action. So to figure out the cue for my cookie habit, I wrote down five things the moment the urge hit:<br /><br />Where are you? (Sitting at my desk.)<br /><br />What time is it? (3:36 p.m.)<br /><br />What&rsquo;s your emotional state? (Bored.)<br /><br />Who else is around? (No one.)<br /><br />What action preceded the urge? (Answered an e-mail.)<br /><br />The next day I did the same thing. And the next. Pretty soon, the cue was clear: I always felt an urge to snack around 3:30.<br /><br />Once I figured out all the parts of the loop, it seemed fairly easy to change my habit. But the psychologists and neuroscientists warned me that, for my new behavior to stick, I needed to abide by the same principle that guided Procter &amp; Gamble in selling Febreze: To shift the routine &mdash; to socialize, rather than eat a cookie &mdash; I needed to piggyback on an existing habit. So now, every day around 3:30, I stand up, look around the newsroom for someone to talk to, spend 10 minutes gossiping, then go back to my desk. The cue and reward have stayed the same. Only the routine has shifted. It doesn&rsquo;t feel like a decision, any more than the M.I.T. rats made a decision to run through the maze. It&rsquo;s now a habit. I&rsquo;ve lost 21 pounds since then (12 of them from changing my cookie ritual).</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5Whwix4cZ3p5otshm": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jYA6PqD3QevKtp3Hn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 35, "extendedScore": null, "score": 8.6e-05, "legacy": true, "legacyId": "13278", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T14:07:59.514Z", "modifiedAt": null, "url": null, "title": "Existential Risk Reduction Career Network", "slug": "existential-risk-reduction-career-network-1", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:22.449Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8MXD9XSEaAH6ZZhHE/existential-risk-reduction-career-network-1", "pageUrlRelative": "/posts/8MXD9XSEaAH6ZZhHE/existential-risk-reduction-career-network-1", "linkUrl": "https://www.lesswrong.com/posts/8MXD9XSEaAH6ZZhHE/existential-risk-reduction-career-network-1", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Existential%20Risk%20Reduction%20Career%20Network&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExistential%20Risk%20Reduction%20Career%20Network%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8MXD9XSEaAH6ZZhHE%2Fexistential-risk-reduction-career-network-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Existential%20Risk%20Reduction%20Career%20Network%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8MXD9XSEaAH6ZZhHE%2Fexistential-risk-reduction-career-network-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8MXD9XSEaAH6ZZhHE%2Fexistential-risk-reduction-career-network-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 175, "htmlBody": "<p>Interested in donating to existential risk reduction efforts? Would you like to exchange career information with like-minded others? Then you should consider the Existential Risk Reduction Career Network! (\"X Risk Network\" for those short on time.) From the front page of the website:</p>\n<p>\"This network is for anyone interested in donating substantial amounts (relative to income) to non-profit organizations focused on the reduction of existential risk, such as <a rel=\"nofollow\" href=\"http://intelligence.org/\">SIAI</a>,&nbsp;<a rel=\"nofollow\" href=\"http://www.fhi.ox.ac.uk/\">FHI</a>, and the <a rel=\"nofollow\" href=\"http://lifeboat.com/ex/main\">Lifeboat Foundation</a>. [...] We are a community of people assisting each other to increase our resources available for contribution. Members discuss the strengths and weaknesses of different careers, network, share advice on job applications and career advancement, assist others with finding interviews, and occasionally look for qualified individuals to hire from within the network.\"</p>\n<p>For more details, including on the process of requesting invitations, head on over to the front page at <a href=\"http://www.xrisknetwork.org/\">http://www.xrisknetwork.org/</a></p>\n<p>Keep in mind that the network is for students as well, not just those currently on the job market. The network also has discussion of long term job strategy, school admissions, and intern possibilities.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8MXD9XSEaAH6ZZhHE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 5, "extendedScore": null, "score": 8.527750815810025e-07, "legacy": true, "legacyId": "13287", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T18:23:44.790Z", "modifiedAt": null, "url": null, "title": "I\u2019m an Artist. How Can an Artist Help? ", "slug": "i-m-an-artist-how-can-an-artist-help", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.868Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MichaelVassar", "createdAt": "2009-02-28T07:34:32.206Z", "isAdmin": false, "displayName": "MichaelVassar"}, "userId": "PvhrBWHzCGKRkwKcd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q3upfJ7eays5SWAuH/i-m-an-artist-how-can-an-artist-help", "pageUrlRelative": "/posts/Q3upfJ7eays5SWAuH/i-m-an-artist-how-can-an-artist-help", "linkUrl": "https://www.lesswrong.com/posts/Q3upfJ7eays5SWAuH/i-m-an-artist-how-can-an-artist-help", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%E2%80%99m%20an%20Artist.%20How%20Can%20an%20Artist%20Help%3F%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%E2%80%99m%20an%20Artist.%20How%20Can%20an%20Artist%20Help%3F%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ3upfJ7eays5SWAuH%2Fi-m-an-artist-how-can-an-artist-help%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%E2%80%99m%20an%20Artist.%20How%20Can%20an%20Artist%20Help%3F%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ3upfJ7eays5SWAuH%2Fi-m-an-artist-how-can-an-artist-help", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ3upfJ7eays5SWAuH%2Fi-m-an-artist-how-can-an-artist-help", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 503, "htmlBody": "<p>I get asked that a lot, and increasingly I wonder; does the person asking think I&rsquo;m a non-profit president?<span style=\"mso-spacerun: yes;\">&nbsp; </span>Do they imagine that when I was a kid, people asked me &ldquo;what do you want to be when I grew up&rdquo; and I said &ldquo;I want to help people, so I&rsquo;d like to run the United Way&rdquo; and that the Singularity Institute is a logical step on that career path?<span style=\"mso-spacerun: yes;\">&nbsp; </span>Do they think that when I was growing up people told me &ldquo;You&rsquo;re really good at business networking, so you should be part of the Bay Area tech scene&rdquo; the way scientists get told &ldquo;You&rsquo;re really smart, so you should be a scientist&rdquo;?<span style=\"mso-spacerun: yes;\">&nbsp; </span>I think they sort-of do.<span style=\"mso-spacerun: yes;\">&nbsp;</span></p>\n<p class=\"MsoNormal\">So anyway, Eliezer, representing the Singularity Institute, has traditionally told such people, to a first approximation, &ldquo;sorry, an artist can&rsquo;t help us&rdquo;, and I&rsquo;m writing this to try to elaborate on that statement a little.<span style=\"mso-spacerun: yes;\">&nbsp; </span>I&rsquo;d like to tell the artists out there that they aren&rsquo;t alone.<span style=\"mso-spacerun: yes;\">&nbsp; </span>Here goes.</p>\n<p class=\"MsoNormal\">&ldquo;sorry, an artist can&rsquo;t help us&rdquo;</p>\n<p class=\"MsoNormal\">&ldquo;sorry, a scientist can&rsquo;t help us&rdquo;</p>\n<p class=\"MsoNormal\">&ldquo;sorry, an business-person can&rsquo;t help us&rdquo;</p>\n<p class=\"MsoNormal\">&ldquo;sorry, an politician can&rsquo;t help us&rdquo;</p>\n<p class=\"MsoNormal\"><span style=\"mso-spacerun: yes;\">&nbsp;</span>&ldquo;sorry, a hacker can&rsquo;t help us&rdquo;</p>\n<p class=\"MsoNormal\">It turns out that only a human can help us, because only they have general intelligence, so they can do anything. <span style=\"mso-spacerun: yes;\">&nbsp;</span>When people identify with labels, they don&rsquo;t primarily gain the ability to use the skills they have that they associate with those labels.<span style=\"mso-spacerun: yes;\">&nbsp; </span>Rather, they loose the ability to freely use other skills, or generally, to behave non-stereotypically, as doing so would move them away from the <a href=\"mailto:http://lesswrong.com/lw/nl/the_cluster_structure_of_thingspace\">central tendency in thing-space</a> identified by those labels and thus make them a less good member of their category.</p>\n<p class=\"MsoNormal\">If you&rsquo;re looking for a cause to fill in on an identity check-list, one of a list of socially proscribed things that people should be able to say about themselves in order to be &lsquo;balanced&rsquo; or &lsquo;interesting&rsquo;, well sorry, &lsquo;effective&rsquo; just isn&rsquo;t on that list. <span style=\"mso-spacerun: yes;\">&nbsp;</span>We&rsquo;re happy to take your donations, because &lsquo;big-picture futurist visionary&rsquo; is on the list and &lsquo;caring&rsquo; about SIAI the way people &lsquo;care&rsquo; about the poor when they donate to Unicef is the best available option for someone who wants to fill in that box with that answer.<span style=\"mso-spacerun: yes;\">&nbsp; </span>It just so happens that we would also be the best place to put that money, if you did want to bring about a big-picture vision for the future, but we would also be the best place to put money if you want to bring about a better life for the poor and neither of those considerations typically leads to someone writing us a check.<span style=\"mso-spacerun: yes;\">&nbsp; </span></p>\n<p class=\"MsoNormal\">If you are looking to find meaning in life, we can help some.<span style=\"mso-spacerun: yes;\">&nbsp; </span>As an empirical matter though, people who need our help with this aren&rsquo;t usually as energetic in pursuit of abstract meaning as people who would be having a fine time if the world wasn&rsquo;t in danger but see this as an interesting and challenging adventure, so I&rsquo;d really appreciate seeing more people who already have <a href=\"mailto:http://lesswrong.com/lw/nb/something_to_protect/\">something to protect</a>.<span style=\"mso-spacerun: yes;\">&nbsp;&nbsp;</span></p>\n<!--EndFragment-->\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q3upfJ7eays5SWAuH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": -9, "extendedScore": null, "score": -5e-06, "legacy": true, "legacyId": "13288", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T22:02:31.792Z", "modifiedAt": null, "url": null, "title": "[Pile of links] Miscommunication", "slug": "pile-of-links-miscommunication", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.512Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Grognor", "createdAt": "2011-01-31T02:54:34.463Z", "isAdmin": false, "displayName": "Grognor"}, "userId": "LoykQRMTxJFxwwdPy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/i5J9KtXpet8djyN6Z/pile-of-links-miscommunication", "pageUrlRelative": "/posts/i5J9KtXpet8djyN6Z/pile-of-links-miscommunication", "linkUrl": "https://www.lesswrong.com/posts/i5J9KtXpet8djyN6Z/pile-of-links-miscommunication", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BPile%20of%20links%5D%20Miscommunication&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BPile%20of%20links%5D%20Miscommunication%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi5J9KtXpet8djyN6Z%2Fpile-of-links-miscommunication%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BPile%20of%20links%5D%20Miscommunication%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi5J9KtXpet8djyN6Z%2Fpile-of-links-miscommunication", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi5J9KtXpet8djyN6Z%2Fpile-of-links-miscommunication", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<blockquote>\n<p>Humans obviously can't communicate.</p>\n</blockquote>\n<p>-<a href=\"https://twitter.com/#!/spaceandgames/status/14527035770671104\">Peter de Blanc</a></p>\n<p>Miscommunication is something we talk about Less Wrong a lot, what with the <a href=\"/lw/ke/illusion_of_transparency_why_no_one_understands\">illusion of transparency</a>, the <a href=\"/lw/ki/double_illusion_of_transparency\">double illusion of transparency</a>, and the <a href=\"/lw/od/37_ways_that_words_can_be_wrong\">37 Ways Words Can Be Wrong</a> sequence and <a href=\"/lw/85h/better_disagreement/\">better disagreement</a> and <a href=\"/lw/1yz/levels_of_communication/\">levels of communication</a> and <a href=\"/lw/50z/mental_metadata/\">mental metadata</a> and <a href=\"/lw/7jp/rational_communication/\">this</a> (not to mention Robin Hanson's <a href=\"http://www.overcomingbias.com/2009/01/disagreement-is-nearfar-bias.html\">Disagreement is Near/Far Bias</a>). I thought about writing a new top-level post about it with some of the links I've found, but I figure they say all I could have said.</p>\n<p>Here you go:</p>\n<ul>\n<li><a href=\"http://measureofdoubt.com/2011/10/18/the-curse-of-knowledge/\">The Curse of Knowledge</a> at Measure of Doubt (mostly a rephrasing of what we know from the above posts).</li>\n<li><a href=\"http://www.spencergreenberg.com/2011/12/the-seven-causes-of-disagreement/\">Seven Causes of Disagreement</a> at Spencer Greenberg's blog.</li>\n<li><a href=\"http://www.cracked.com/blog/4-reasons-humans-will-never-understand-each-other/\">4 Reasons Humans Will Never Understand Each Other</a> at Cracked.</li>\n<li><a href=\"http://www.cs.tut.fi/%7Ejkorpela/wiio.html\">Wiio's Laws</a>. This is the big one. This is the one that says it all. Do read them. Apparently, this doesn't happen to everyone, but after reading that page I started seeing Wiio's laws everywhere.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "i5J9KtXpet8djyN6Z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 8.529631835865254e-07, "legacy": true, "legacyId": "11710", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sSqoEw9eRP2kPKLCz", "sBBGxdvhKcppQWZZE", "FaJaCgqBKphrDzDSj", "FhH8m5n8qGSSHsAgG", "gs8bZCmaWqDaus7Dr", "fQcaoQ247iuh267rR", "BNHDfoCSYF2TkLWyq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-21T22:30:00.668Z", "modifiedAt": null, "url": null, "title": "I believe it's doublethink", "slug": "i-believe-it-s-doublethink", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.583Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kerspoon", "createdAt": "2011-12-27T09:53:49.512Z", "isAdmin": false, "displayName": "kerspoon"}, "userId": "XvZ9yyyJNeDwWhECW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7JKspJGWa8KDssfEM/i-believe-it-s-doublethink", "pageUrlRelative": "/posts/7JKspJGWa8KDssfEM/i-believe-it-s-doublethink", "linkUrl": "https://www.lesswrong.com/posts/7JKspJGWa8KDssfEM/i-believe-it-s-doublethink", "postedAtFormatted": "Tuesday, February 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%20believe%20it's%20doublethink&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%20believe%20it's%20doublethink%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JKspJGWa8KDssfEM%2Fi-believe-it-s-doublethink%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%20believe%20it's%20doublethink%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JKspJGWa8KDssfEM%2Fi-believe-it-s-doublethink", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JKspJGWa8KDssfEM%2Fi-believe-it-s-doublethink", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 782, "htmlBody": "<p>\n<p>This is my attempt to provide examples and a summarised view of the posts on \"Against Doublethink\" on the page <a title=\"How To Change You Mind\" href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">How To Actually Change Your Mind</a>.</p>\n<h3>What You Should Believe</h3>\n<p>Lets assume I am sitting down with my friend John and we each have incomplete and potentially inaccurate maps of a local mountain. When John says \"My map has a bridge at grid reference 234567\", I should add a note to my map saying \"John's map has a bridge at grid reference 234567\" *not* actually add the bridge to my map.&nbsp;</p>\n<p>The same is true of beliefs. If Sarah tells me \"the sky is green\" I should, assuming she is not lying, add to my set of beliefs \"Sarah believes the sky is green\". What happens too often is that we directly add \"The sky is green\" to our beliefs. It is an overactive optimisation that works in most cases but causes occasional problems.&nbsp;</p>\n<p>Taking the analogy a step further we can decide to question John about why he has drawn the bridge on his map. Then, depending on the reason, we can choose to draw the bridge on our map or not.</p>\n<p>We can give our beliefs the same treatment. Upon asking Sarah why she believed the sky is green, if she said \"someone told me\" and couldn't provide further information I wouldn't choose to believe it. If, however, she said \"I have seen it for myself\" then I may choose to believe it, depending on my priors.&nbsp;</p>\n<h3>I Believe You Believe</h3>\n<p>The curious case is when someone says \"I believe X\". This can be meant a few ways:</p>\n<p><ol>\n<li>I have low confidence in this belief. e.g. \"I believe that my friend Bob's eyes are hazel, but I'm not sure\".&nbsp;</li>\n<li>I&nbsp;have this belief but have reasons to think you wont share it. e.g. \"I believe she is attractive\".&nbsp;</li>\n<li>I have the fact 'I believe the sky is green' in my mental model of the world. e.g. \"I believe god exists.\"</li>\n</ol></p>\n<p>The first case I do not have a problem with. It means your probability density has not yet shown a clear winner but you are giving me the answer that is in the lead at the moment. In this case I should add a note saying \"You believes there is a bridge here, you are not very confident in the belief\".</p>\n<p>I don't have a problem with the second case either. I can have the belief \"Angelina Jolie is attractive\", someone else not have that belief, and we both be rational. This is because we are using different criteria for attractive. If I were to change it to a consistent definition of attractive it wouldn't be a problem e.g. The phrase \"Angelina Jolie is regularly voted in the top 100 most attractive people in the world\" doesn't require the phrase 'I believe...'.</p>\n<p>The last case is even more curious. Lets assume that John (from our first example) says \"I believe there is a bridge at grid reference 234567\" but means it in the third case. I should add a note to my map saying \"John has the following note on his map: 'I believe there is a bridge at grid reference 234567'\". You would hope that the reason he has that note is because there is actually a bridge on his map. Unfortunately people are not that rational. You can have a cached belief that says \"I believe X\" even if you do not have \"X\" as a belief. By querying why they have that belief you should be able to work out if you should believe it, or even if they should.</p>\n<p>To use the example from religion you can have the belief \"I believe god exists\" even if you do not have the belief \"god exists\".</p>\n<h3>Recommendations</h3>\n<p>I'm going to put myself on the line and give some recommendations:</p>\n<p><ol>\n<li>When we are told or recite a fact, try to remember why it is or was added. The reason will often be poor.&nbsp;</li>\n<li>When telling others facts, tell them the reason you believe it, e.g. say \"I think there is a bridge here because I overheard someone talking about it\". This should help you weed out cached beliefs in yourself and give the other person a better metric for adding to the own beliefs.</li>\n<li>When being told something, ask them why they have the belief, it also helps if you recite it back to them as if you are trying to understand, for example: \"I see. You think there is a bridge here. Why do you think that?\".&nbsp;</li>\n<li>When we hear \"I believe\" or \"I think\" try to classify the statement as one of the three options above.</li>\n</ol></p>\n<p>&nbsp;</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YTCrHWYHAsAD74EHo": 1, "wMPYFGmhcFg4bSb4Z": 1, "FtT2T9bRbECCGYxrL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7JKspJGWa8KDssfEM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 32, "extendedScore": null, "score": 8.529740791228757e-07, "legacy": true, "legacyId": "13289", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>\n</p><p>This is my attempt to provide examples and a summarised view of the posts on \"Against Doublethink\" on the page <a title=\"How To Change You Mind\" href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">How To Actually Change Your Mind</a>.</p>\n<h3 id=\"What_You_Should_Believe\">What You Should Believe</h3>\n<p>Lets assume I am sitting down with my friend John and we each have incomplete and potentially inaccurate maps of a local mountain. When John says \"My map has a bridge at grid reference 234567\", I should add a note to my map saying \"John's map has a bridge at grid reference 234567\" *not* actually add the bridge to my map.&nbsp;</p>\n<p>The same is true of beliefs. If Sarah tells me \"the sky is green\" I should, assuming she is not lying, add to my set of beliefs \"Sarah believes the sky is green\". What happens too often is that we directly add \"The sky is green\" to our beliefs. It is an overactive optimisation that works in most cases but causes occasional problems.&nbsp;</p>\n<p>Taking the analogy a step further we can decide to question John about why he has drawn the bridge on his map. Then, depending on the reason, we can choose to draw the bridge on our map or not.</p>\n<p>We can give our beliefs the same treatment. Upon asking Sarah why she believed the sky is green, if she said \"someone told me\" and couldn't provide further information I wouldn't choose to believe it. If, however, she said \"I have seen it for myself\" then I may choose to believe it, depending on my priors.&nbsp;</p>\n<h3 id=\"I_Believe_You_Believe\">I Believe You Believe</h3>\n<p>The curious case is when someone says \"I believe X\". This can be meant a few ways:</p>\n<p></p><ol>\n<li>I have low confidence in this belief. e.g. \"I believe that my friend Bob's eyes are hazel, but I'm not sure\".&nbsp;</li>\n<li>I&nbsp;have this belief but have reasons to think you wont share it. e.g. \"I believe she is attractive\".&nbsp;</li>\n<li>I have the fact 'I believe the sky is green' in my mental model of the world. e.g. \"I believe god exists.\"</li>\n</ol><p></p>\n<p>The first case I do not have a problem with. It means your probability density has not yet shown a clear winner but you are giving me the answer that is in the lead at the moment. In this case I should add a note saying \"You believes there is a bridge here, you are not very confident in the belief\".</p>\n<p>I don't have a problem with the second case either. I can have the belief \"Angelina Jolie is attractive\", someone else not have that belief, and we both be rational. This is because we are using different criteria for attractive. If I were to change it to a consistent definition of attractive it wouldn't be a problem e.g. The phrase \"Angelina Jolie is regularly voted in the top 100 most attractive people in the world\" doesn't require the phrase 'I believe...'.</p>\n<p>The last case is even more curious. Lets assume that John (from our first example) says \"I believe there is a bridge at grid reference 234567\" but means it in the third case. I should add a note to my map saying \"John has the following note on his map: 'I believe there is a bridge at grid reference 234567'\". You would hope that the reason he has that note is because there is actually a bridge on his map. Unfortunately people are not that rational. You can have a cached belief that says \"I believe X\" even if you do not have \"X\" as a belief. By querying why they have that belief you should be able to work out if you should believe it, or even if they should.</p>\n<p>To use the example from religion you can have the belief \"I believe god exists\" even if you do not have the belief \"god exists\".</p>\n<h3 id=\"Recommendations\">Recommendations</h3>\n<p>I'm going to put myself on the line and give some recommendations:</p>\n<p></p><ol>\n<li>When we are told or recite a fact, try to remember why it is or was added. The reason will often be poor.&nbsp;</li>\n<li>When telling others facts, tell them the reason you believe it, e.g. say \"I think there is a bridge here because I overheard someone talking about it\". This should help you weed out cached beliefs in yourself and give the other person a better metric for adding to the own beliefs.</li>\n<li>When being told something, ask them why they have the belief, it also helps if you recite it back to them as if you are trying to understand, for example: \"I see. You think there is a bridge here. Why do you think that?\".&nbsp;</li>\n<li>When we hear \"I believe\" or \"I think\" try to classify the statement as one of the three options above.</li>\n</ol><p></p>\n<p>&nbsp;</p>\n<p></p>", "sections": [{"title": "What You Should Believe", "anchor": "What_You_Should_Believe", "level": 1}, {"title": "I Believe You Believe", "anchor": "I_Believe_You_Believe", "level": 1}, {"title": "Recommendations", "anchor": "Recommendations", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "32 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T00:33:57.649Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup", "slug": "meetup-fort-collins-colorado-meetup-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BKW9zcigrfujyqRuk/meetup-fort-collins-colorado-meetup-2", "pageUrlRelative": "/posts/BKW9zcigrfujyqRuk/meetup-fort-collins-colorado-meetup-2", "linkUrl": "https://www.lesswrong.com/posts/BKW9zcigrfujyqRuk/meetup-fort-collins-colorado-meetup-2", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBKW9zcigrfujyqRuk%2Fmeetup-fort-collins-colorado-meetup-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBKW9zcigrfujyqRuk%2Fmeetup-fort-collins-colorado-meetup-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBKW9zcigrfujyqRuk%2Fmeetup-fort-collins-colorado-meetup-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 47, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7c'>Fort Collins, Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We have a guest from London/Budapest visiting this week. Come discuss intelligence augmentation tools.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7c'>Fort Collins, Colorado Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BKW9zcigrfujyqRuk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.530232246911465e-07, "legacy": true, "legacyId": "13292", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup\">Discussion article for the meetup : <a href=\"/meetups/7c\">Fort Collins, Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We have a guest from London/Budapest visiting this week. Come discuss intelligence augmentation tools.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/7c\">Fort Collins, Colorado Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T03:21:58.018Z", "modifiedAt": null, "url": null, "title": "[Link] H+ article Rationality Training: Call for a Global Approach", "slug": "link-h-article-rationality-training-call-for-a-global", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.282Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "beoShaffer", "createdAt": "2011-05-29T15:52:29.240Z", "isAdmin": false, "displayName": "beoShaffer"}, "userId": "589WwYp3jytZqATFL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b8fSZcCfr2P5dRKvT/link-h-article-rationality-training-call-for-a-global", "pageUrlRelative": "/posts/b8fSZcCfr2P5dRKvT/link-h-article-rationality-training-call-for-a-global", "linkUrl": "https://www.lesswrong.com/posts/b8fSZcCfr2P5dRKvT/link-h-article-rationality-training-call-for-a-global", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20H%2B%20article%20Rationality%20Training%3A%20Call%20for%20a%20Global%20Approach&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20H%2B%20article%20Rationality%20Training%3A%20Call%20for%20a%20Global%20Approach%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8fSZcCfr2P5dRKvT%2Flink-h-article-rationality-training-call-for-a-global%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20H%2B%20article%20Rationality%20Training%3A%20Call%20for%20a%20Global%20Approach%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8fSZcCfr2P5dRKvT%2Flink-h-article-rationality-training-call-for-a-global", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8fSZcCfr2P5dRKvT%2Flink-h-article-rationality-training-call-for-a-global", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 34, "htmlBody": "<p>http://hplusmagazine.com/2012/02/06/rationality-training-call-for-a-global-approach/</p>\n<p>Dr.<span style=\"font-family: tahoma, verdana, arial, Arial, Helvetica, sans-serif; font-size: 13px; line-height: 21px;\">Ziesche calls for more globally accessible rationality training. &nbsp;He seems supportive of existing efforts, especially us, but thinks it would be nice if rationality training was &nbsp;easily accessible to people other than educated westerners. &nbsp;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b8fSZcCfr2P5dRKvT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 6, "extendedScore": null, "score": 8.530898463457309e-07, "legacy": true, "legacyId": "13309", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T03:57:56.615Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Righting a Wrong Question", "slug": "seq-rerun-righting-a-wrong-question", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Thzsfw2mp3T9ez3Th/seq-rerun-righting-a-wrong-question", "pageUrlRelative": "/posts/Thzsfw2mp3T9ez3Th/seq-rerun-righting-a-wrong-question", "linkUrl": "https://www.lesswrong.com/posts/Thzsfw2mp3T9ez3Th/seq-rerun-righting-a-wrong-question", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Righting%20a%20Wrong%20Question&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Righting%20a%20Wrong%20Question%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FThzsfw2mp3T9ez3Th%2Fseq-rerun-righting-a-wrong-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Righting%20a%20Wrong%20Question%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FThzsfw2mp3T9ez3Th%2Fseq-rerun-righting-a-wrong-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FThzsfw2mp3T9ez3Th%2Fseq-rerun-righting-a-wrong-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 194, "htmlBody": "<p>Today's post, <a href=\"/lw/oh/righting_a_wrong_question/\">Righting a Wrong Question</a> was originally published on 09 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When you are faced with an unanswerable question - a question to which it seems impossible to even imagine an answer - there is a simple trick which can turn the question solvable. Instead of asking, \"Why do I have free will?\", try asking, \"Why do I think I have free will?\"</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a8l/seq_rerun_wrong_questions/\">Wrong Questions</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Thzsfw2mp3T9ez3Th", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 8.531041138383699e-07, "legacy": true, "legacyId": "13310", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rQEwySCcLtdKHkrHp", "LhuQz4gCR4nmESvKj", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T04:05:33.826Z", "modifiedAt": null, "url": null, "title": "Draft of Muehlhauser & Salamon, 'Intelligence Explosion: Evidence and Import'", "slug": "draft-of-muehlhauser-and-salamon-intelligence-explosion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:37.645Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aq3PKGmhBQaAqpu2k/draft-of-muehlhauser-and-salamon-intelligence-explosion", "pageUrlRelative": "/posts/aq3PKGmhBQaAqpu2k/draft-of-muehlhauser-and-salamon-intelligence-explosion", "linkUrl": "https://www.lesswrong.com/posts/aq3PKGmhBQaAqpu2k/draft-of-muehlhauser-and-salamon-intelligence-explosion", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Draft%20of%20Muehlhauser%20%26%20Salamon%2C%20'Intelligence%20Explosion%3A%20Evidence%20and%20Import'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADraft%20of%20Muehlhauser%20%26%20Salamon%2C%20'Intelligence%20Explosion%3A%20Evidence%20and%20Import'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Faq3PKGmhBQaAqpu2k%2Fdraft-of-muehlhauser-and-salamon-intelligence-explosion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Draft%20of%20Muehlhauser%20%26%20Salamon%2C%20'Intelligence%20Explosion%3A%20Evidence%20and%20Import'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Faq3PKGmhBQaAqpu2k%2Fdraft-of-muehlhauser-and-salamon-intelligence-explosion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Faq3PKGmhBQaAqpu2k%2Fdraft-of-muehlhauser-and-salamon-intelligence-explosion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 43, "htmlBody": "<p>Anna Salamon and I have finished a draft of \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/Muehlhauser-Salamon-Intelligence-Explosion-Evidence-and-Import.pdf\">Intelligence Explosion: Evidence and Import</a>\", under peer review for <em><a href=\"http://singularityhypothesis.blogspot.com/\">The Singularity Hypothesis: A Scientific and Philosophical Assessment</a></em>&nbsp;(forthcoming from Springer).</p>\n<p>Your comments are most welcome.</p>\n<p><strong>Edit</strong>: As of 3/31/2012, the link above now points to a preprint.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aq3PKGmhBQaAqpu2k", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 26, "extendedScore": null, "score": 8.531071358769002e-07, "legacy": true, "legacyId": "13311", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T11:18:59.857Z", "modifiedAt": null, "url": null, "title": "[LINK] Shutting down the destructive internal monologue through transcranial direct current stimulation", "slug": "link-shutting-down-the-destructive-internal-monologue", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.049Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/t3NvPzQ6ACtXpW5um/link-shutting-down-the-destructive-internal-monologue", "pageUrlRelative": "/posts/t3NvPzQ6ACtXpW5um/link-shutting-down-the-destructive-internal-monologue", "linkUrl": "https://www.lesswrong.com/posts/t3NvPzQ6ACtXpW5um/link-shutting-down-the-destructive-internal-monologue", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Shutting%20down%20the%20destructive%20internal%20monologue%20through%20transcranial%20direct%20current%20stimulation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Shutting%20down%20the%20destructive%20internal%20monologue%20through%20transcranial%20direct%20current%20stimulation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft3NvPzQ6ACtXpW5um%2Flink-shutting-down-the-destructive-internal-monologue%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Shutting%20down%20the%20destructive%20internal%20monologue%20through%20transcranial%20direct%20current%20stimulation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft3NvPzQ6ACtXpW5um%2Flink-shutting-down-the-destructive-internal-monologue", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft3NvPzQ6ACtXpW5um%2Flink-shutting-down-the-destructive-internal-monologue", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 526, "htmlBody": "<p><a href=\"http://www.newscientist.com/article/mg21328501.600-zap-your-brain-into-the-zone-fast-track-to-pure-focus.html?full=true\">Fast track to pure focus</a></p>\n<blockquote>\n<p>Weisend, who is working on a US Defense Advanced Research Projects Agency programme to accelerate learning, has been using this form of transcranial direct current stimulation (tDCS) to cut the time it takes to train snipers. From the electrodes, a 2-milliamp current will run through the part of my brain associated with object recognition - an important skill when visually combing a scene for assailants.</p>\n<p>...</p>\n<p>Mysteriously, however, these long-term changes also seem to be preceded by a feeling that emerges as soon as the current is switched on and is markedly similar to the flow state. \"The number one thing I hear people say after tDCS is that time passed unduly fast,\" says Weisend. Their movements also seem to become more automatic; they report calm, focused concentration - and their performance improves immediately.</p>\n<p>...</p>\n</blockquote>\n<p>The journalist goes from</p>\n<blockquote>\n<p class=\"infuse\">I'm close to tears behind my thin cover of sandbags as 20 screaming, masked men run towards me at full speed, strapped into suicide bomb vests and clutching rifles. For every one I manage to shoot dead, three new assailants pop up from nowhere. I'm clearly not shooting fast enough, and panic and incompetence are making me continually jam my rifle.</p>\n<p class=\"infuse\">My salvation lies in the fact that my attackers are only a video, projected on screens to the front and sides. It's the very simulation that trains US troops to take their first steps with a rifle, and everything about it has been engineered to feel like an overpowering assault. But I am failing miserably. In fact, I'm so demoralised that I'm tempted to put down the rifle and leave.</p>\n</blockquote>\n<p class=\"infuse\">to</p>\n<blockquote>\n<p class=\"infuse\">I simply begin to take out attacker after attacker. As twenty of them run at me brandishing their guns, I calmly line up my rifle, take a moment to breathe deeply, and pick off the closest one, before tranquilly assessing my next target.</p>\n<p class=\"infuse\">In what seems like next to no time, I hear a voice call out, \"Okay, that's it.\" The lights come up in the simulation room and one of the assistants at Advanced Brain Monitoring, a young woman just out of university, tentatively enters the darkened room.</p>\n<p class=\"infuse\">In the sudden quiet amid the bodies around me, I was really expecting more assailants, and I'm a bit disappointed when the team begins to remove my electrodes. I look up and wonder if someone wound the clocks forward. Inexplicably, 20 minutes have just passed. \"How many did I get?\" I ask the assistant.</p>\n<p class=\"infuse\">She looks at me quizzically. \"All of them.\"</p>\n<p class=\"infuse\">...</p>\n<p>Zapping your brain with a small current seems to improve everything from mathematical skills to marksmanship, but for now your best chance of experiencing this boost is to sign up for a lab experiment. Machines that provide transcranial direct current stimulation (tDCS) cost &pound;5000 a pop, and their makers often sell them only to researchers.</p>\n</blockquote>\n<p>That hasn't stopped a vibrant community of DIY tDCS enthusiasts from springing up. Their online forums are full of accounts of their <a href=\"http://www.physforum.com/index.php?showtopic=7943\" target=\"nsarticle\">home-made experiments</a>, including hair-curling descriptions of blunders that, in one case, left someone temporarily blind.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "t3NvPzQ6ACtXpW5um", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 26, "extendedScore": null, "score": 8.532790600108689e-07, "legacy": true, "legacyId": "13321", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T13:58:28.124Z", "modifiedAt": null, "url": null, "title": "Self awareness - why is it discussed as so profound?", "slug": "self-awareness-why-is-it-discussed-as-so-profound", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.042Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dmytry", "createdAt": "2009-12-03T17:11:53.492Z", "isAdmin": false, "displayName": "Dmytry"}, "userId": "AjtmA2qtA8sdiMbru", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7d9zqSgnSY2b49aAa/self-awareness-why-is-it-discussed-as-so-profound", "pageUrlRelative": "/posts/7d9zqSgnSY2b49aAa/self-awareness-why-is-it-discussed-as-so-profound", "linkUrl": "https://www.lesswrong.com/posts/7d9zqSgnSY2b49aAa/self-awareness-why-is-it-discussed-as-so-profound", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Self%20awareness%20-%20why%20is%20it%20discussed%20as%20so%20profound%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelf%20awareness%20-%20why%20is%20it%20discussed%20as%20so%20profound%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7d9zqSgnSY2b49aAa%2Fself-awareness-why-is-it-discussed-as-so-profound%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Self%20awareness%20-%20why%20is%20it%20discussed%20as%20so%20profound%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7d9zqSgnSY2b49aAa%2Fself-awareness-why-is-it-discussed-as-so-profound", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7d9zqSgnSY2b49aAa%2Fself-awareness-why-is-it-discussed-as-so-profound", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 651, "htmlBody": "<p>Something I find rather odd - why is self-awareness usually discussed as something profoundly mysterious and advanced?</p>\n<p>People would generally agree that a dog can be aware of food in the bowl, if the dog has seen or smelled it, or can be unaware of a food bowl otherwise. One would think that a dog can be aware of itself in so much as dog can be aware of anything else in the world, like food in the bowl. There isn't great deal of argument about dog's awareness of food.</p>\n<p>Yet the question whenever dog has 'self awareness' quickly turns into debate of opinions and language and shifting definitions of what 'self awareness' is, and irrelevancies such as the question whenever the dog is smart enough to figure out how mirror works well enough to identify a paint blotch on itself<sup>1</sup> , or the requests that it be shown beyond all doubt that dog's mind is aware of dog's own mind, which is something that you can deny <a href=\"http://wiki.lesswrong.com/wiki/Philosophical_zombie\">other humans</a> just as successfully.</p>\n<p>I find it rather puzzling.</p>\n<p>My first theory is to assume that it is just a case of avoiding the thought due to it's consequences vs the status quo. The status quo is that we, without giving it much thought, decided that self awareness is uniquely human quality, and then carelessly made our morality sound more universal by saying that the self aware entities are entitled to the rights. At same time we don't care too much about other animals.</p>\n<p>At this point, having well 'established' notions in our head - which weren't quite rationally established but just sort of happened over the time - we don't so much try to actually think or argue about self awareness as try to define the self awareness so that humans are self aware, and dogs aren't yet the definition sounds general - or try to fight such definitions - depending to our feeling towards dogs.</p>\n<p>I think it is a case of general problem with reasoning. When there's established status quo - which has sort of evolved historically - we can have real trouble thinking about it, rather than try to make up some new definitions which sound as if they existed from the start and the status quo was justified by those definitions.</p>\n<p>This gets problematic when we have to think about self awareness for other purposes, such as AI.</p>\n<p><sub>1: I don't see how the mirror self-recognition test implies anything about self awareness. You pick an animal that grooms itself, you see if that animal can groom itself using the mirror. That can work even if the animal only identifies what it wants to groom, with what it sees in the mirror, without identifying either with self (whatever that means). Or that can fail, if the animal doesn't have good enough pattern matching to match those items, even if the animal identifies what it grooms with self and has a concept of self. </sub></p>\n<p><sub>Furthermore the animal that just wants to groom some object which is constantly nearby and grooming of which feels good, could, if capable of language, invent a name for this object - \"foobar\" - and then when making dictionary we'd not think twice about translating \"foobar\" as self.</sub></p>\n<p>edit: Also, i'd say, self recognition complicates our model of the mirrors, in the \"why mirror swaps left and right rather than up and down?\" way. If you look at the room in the mirror, obviously mirror swaps front and back. Clear as day. If you look at 'self' in the mirror, there's this self standing here facing you, and it's left side is swapped with it's right side. And the usual model of mirror is rotation of 180 degrees around vertical axis, not horizontal axis, followed by swapping of left and right but not up and down. You have more complicated, more confusing model of mirror, likely because you recognized the bilaterally symmetric yourself in it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7d9zqSgnSY2b49aAa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 8.533423306395381e-07, "legacy": true, "legacyId": "13324", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T15:43:24.132Z", "modifiedAt": null, "url": null, "title": "[Link] An argument for Low-hanging fruit in Medicine ", "slug": "link-an-argument-for-low-hanging-fruit-in-medicine", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:23.339Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HJ3FnqJEFXvYJu6o9/link-an-argument-for-low-hanging-fruit-in-medicine", "pageUrlRelative": "/posts/HJ3FnqJEFXvYJu6o9/link-an-argument-for-low-hanging-fruit-in-medicine", "linkUrl": "https://www.lesswrong.com/posts/HJ3FnqJEFXvYJu6o9/link-an-argument-for-low-hanging-fruit-in-medicine", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20An%20argument%20for%20Low-hanging%20fruit%20in%20Medicine%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20An%20argument%20for%20Low-hanging%20fruit%20in%20Medicine%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHJ3FnqJEFXvYJu6o9%2Flink-an-argument-for-low-hanging-fruit-in-medicine%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20An%20argument%20for%20Low-hanging%20fruit%20in%20Medicine%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHJ3FnqJEFXvYJu6o9%2Flink-an-argument-for-low-hanging-fruit-in-medicine", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHJ3FnqJEFXvYJu6o9%2Flink-an-argument-for-low-hanging-fruit-in-medicine", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 807, "htmlBody": "<p>Those of us who have found the arguments for stagnation in our near future by <a href=\"/lw/7xm/peter_thiel_warns_of_upcoming_and_current/\">Peter Thiel</a> and <a href=\"http://youtu.be/ed6gNSZRawY\">Tyler Cowen</a> pretty convincing, usually look only to the information and computer industries as something that <em>is</em> and perhaps even <em>can</em> keep us afloat. On the excellent <a href=\"https://westhunt.wordpress.com/\">West Hunters blog</a> (which he shares with Henry Harpending) Gregory Cochran speculates that there might be room for progress in a seemingly unlikely field.</p>\n<blockquote>\n<h2 class=\"entry-title\">Low-hanging&nbsp;fruit</h2>\n<p>In <em>The Great Stagnation</em>, Tyler Cowen discusses a real problem &ndash; a slowdown in technical innovation,&nbsp; with slow economic growth as a consequence.. &nbsp; I think his perspective is limited, since he doesn&rsquo;t know much about the inward nature of innovation. He is kind enough to make absolutely clear how little he knows by mentioning Tang and Teflon as spinoffs of the space program, which is&nbsp; of course wrong. It is unfair to emphasize this too strongly, since hardly anybody in public life knows jack shit about technology and invention. Try to think of a pundit with a patent.</p>\n<p>Anyhow, it strikes me that a certain amount of knowledge&nbsp; may lead to useful insights. In particular, it may help us find low-hanging-fruit, technical innovations that are tasty and relatively easy &ndash; the sort of thing that seems obvious after someone thinks of it.</p>\n<p><strong>If we look at cases where an innovation or discovery was possible &ndash; even easy &ndash; for a long time before it was actually developed, we might be able to find patterns that would help us detect the low-hanging fruit&nbsp; dangling right in front of us today.</strong></p>\n<p>For now, one example.&nbsp; We know that gastric and duodenal ulcer, and most cases of stomach cancer, are caused by an infectious organism, <em>helicobacter pylori.</em>&nbsp; It apparently causes amnesia as well. This organism was first seen in 1875 &ndash; nobody paid any attention.</p>\n<p>Letulle showed that it induced gastritis in guinea pigs, 1888. Walery Jaworski rediscovered it in 1889, and suspected that it might cause gastric disease. Nobody paid any attention.&nbsp; Krienitz associated it with gastric cancer in 1906.&nbsp; Who cares?</p>\n<p>Around 1940, some American researchers rediscovered it, found it more common in ulcerated stomachs,&nbsp; and published their results.&nbsp; Some of them thought that this might be the cause of ulcers &ndash; but Palmer, a famous pathologist,&nbsp; couldn&rsquo;t find it when he looked in the early 50s, so it officially disappeared again. He had used the wrong stain.&nbsp; John Lykoudis, a Greek country doctor noticed that a heavy dose of antibiotics coincided with his ulcer&rsquo;s disappearance, and started treating patients with antibiotics &ndash; successfully.&nbsp;&nbsp; He tried to interest pharmaceutical companies &ndash; wrote to Geigy, Hoechst, Bayer, etc.&nbsp; No joy.&nbsp;&nbsp; JAMA rejected his article. The local medical society referred him for disciplinary action and fined him</p>\n<p>The Chinese noticed that antibiotics could cure ulcers in the early 70s, but they were Commies, so it didn&rsquo;t count.</p>\n<p>Think about it: peptic and duodenal ulcer were fairly common, and so were effective antibiotics, starting in the mid-40s. . Every internist in the world &ndash; every surgeon &ndash; every GP was accidentally curing ulcers&nbsp; &ndash; not just one or twice,&nbsp; but again and again.&nbsp; For decades. Almost none of them noticed it, even though it was happening over and over, right in front of their eyes.&nbsp; Those who did notice were ignored until the mid-80s, when Robin Warren and Barry Marshall finally made the discovery stick. Even then,&nbsp; it took something like 10 years for antibiotic treatment of ulcers to become common, even though it was cheap and effective. Or perhaps because it was cheap and effective.</p>\n<p><strong>This illustrates an important point: doctors are lousy scientists, lousy researchers.&nbsp; They&rsquo;re memorizers, not puzzle solvers.</strong>&nbsp; Considering that Western medicine was an ineffective pseudoscience &ndash; actually, closer to a malignant pseudoscience&nbsp; &ndash; for its first two thousand years, we shouldn&rsquo;t be surprised.&nbsp;&nbsp;&nbsp; Since we&rsquo;re looking for low-hanging fruit,&nbsp; this is good news.&nbsp; <strong>It means that the great discoveries in medicine are probably not mined out. From our point of view, past incompetence predicts future progress.&nbsp; The worse, the better!</strong></p>\n</blockquote>\n<p><a href=\"https://westhunt.wordpress.com/2012/02/22/low-hanging-fruit/\">Link to post</a>.</p>\n<p>I think Greg is underestimating the slight problems of massive over-regulation and guild-like rent seeking that limits medical research and providing medical advice quite severely. He does however make a compelling case for there to still be low hanging fruit there which with a more scientific and rational approach could easily be plucked. I also can't help but wonder if investigating older, supposedly disproved, treatments and theories together with novel research might bring up a few interesting things.</p>\n<p><a href=\"/lw/2y3/dealing_with_the_high_quantity_of_scientific/\">Many on LessWrong</a> share Greg's estimation of the incompetence of the medical establishment, but how many share his optimism that our lack of recent progress isn't just the result of dealing with a <em>really</em> difficult problem set? It may <a href=\"/lw/8yp/prediction_is_hard_especially_of_medicine/\">be hard to tell</a> if he is right.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HJ3FnqJEFXvYJu6o9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 16, "extendedScore": null, "score": 8.533839678206141e-07, "legacy": true, "legacyId": "13325", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Those of us who have found the arguments for stagnation in our near future by <a href=\"/lw/7xm/peter_thiel_warns_of_upcoming_and_current/\">Peter Thiel</a> and <a href=\"http://youtu.be/ed6gNSZRawY\">Tyler Cowen</a> pretty convincing, usually look only to the information and computer industries as something that <em>is</em> and perhaps even <em>can</em> keep us afloat. On the excellent <a href=\"https://westhunt.wordpress.com/\">West Hunters blog</a> (which he shares with Henry Harpending) Gregory Cochran speculates that there might be room for progress in a seemingly unlikely field.</p>\n<blockquote>\n<h2 class=\"entry-title\" id=\"Low_hanging_fruit\">Low-hanging&nbsp;fruit</h2>\n<p>In <em>The Great Stagnation</em>, Tyler Cowen discusses a real problem \u2013 a slowdown in technical innovation,&nbsp; with slow economic growth as a consequence.. &nbsp; I think his perspective is limited, since he doesn\u2019t know much about the inward nature of innovation. He is kind enough to make absolutely clear how little he knows by mentioning Tang and Teflon as spinoffs of the space program, which is&nbsp; of course wrong. It is unfair to emphasize this too strongly, since hardly anybody in public life knows jack shit about technology and invention. Try to think of a pundit with a patent.</p>\n<p>Anyhow, it strikes me that a certain amount of knowledge&nbsp; may lead to useful insights. In particular, it may help us find low-hanging-fruit, technical innovations that are tasty and relatively easy \u2013 the sort of thing that seems obvious after someone thinks of it.</p>\n<p><strong id=\"If_we_look_at_cases_where_an_innovation_or_discovery_was_possible___even_easy___for_a_long_time_before_it_was_actually_developed__we_might_be_able_to_find_patterns_that_would_help_us_detect_the_low_hanging_fruit__dangling_right_in_front_of_us_today_\">If we look at cases where an innovation or discovery was possible \u2013 even easy \u2013 for a long time before it was actually developed, we might be able to find patterns that would help us detect the low-hanging fruit&nbsp; dangling right in front of us today.</strong></p>\n<p>For now, one example.&nbsp; We know that gastric and duodenal ulcer, and most cases of stomach cancer, are caused by an infectious organism, <em>helicobacter pylori.</em>&nbsp; It apparently causes amnesia as well. This organism was first seen in 1875 \u2013 nobody paid any attention.</p>\n<p>Letulle showed that it induced gastritis in guinea pigs, 1888. Walery Jaworski rediscovered it in 1889, and suspected that it might cause gastric disease. Nobody paid any attention.&nbsp; Krienitz associated it with gastric cancer in 1906.&nbsp; Who cares?</p>\n<p>Around 1940, some American researchers rediscovered it, found it more common in ulcerated stomachs,&nbsp; and published their results.&nbsp; Some of them thought that this might be the cause of ulcers \u2013 but Palmer, a famous pathologist,&nbsp; couldn\u2019t find it when he looked in the early 50s, so it officially disappeared again. He had used the wrong stain.&nbsp; John Lykoudis, a Greek country doctor noticed that a heavy dose of antibiotics coincided with his ulcer\u2019s disappearance, and started treating patients with antibiotics \u2013 successfully.&nbsp;&nbsp; He tried to interest pharmaceutical companies \u2013 wrote to Geigy, Hoechst, Bayer, etc.&nbsp; No joy.&nbsp;&nbsp; JAMA rejected his article. The local medical society referred him for disciplinary action and fined him</p>\n<p>The Chinese noticed that antibiotics could cure ulcers in the early 70s, but they were Commies, so it didn\u2019t count.</p>\n<p>Think about it: peptic and duodenal ulcer were fairly common, and so were effective antibiotics, starting in the mid-40s. . Every internist in the world \u2013 every surgeon \u2013 every GP was accidentally curing ulcers&nbsp; \u2013 not just one or twice,&nbsp; but again and again.&nbsp; For decades. Almost none of them noticed it, even though it was happening over and over, right in front of their eyes.&nbsp; Those who did notice were ignored until the mid-80s, when Robin Warren and Barry Marshall finally made the discovery stick. Even then,&nbsp; it took something like 10 years for antibiotic treatment of ulcers to become common, even though it was cheap and effective. Or perhaps because it was cheap and effective.</p>\n<p><strong>This illustrates an important point: doctors are lousy scientists, lousy researchers.&nbsp; They\u2019re memorizers, not puzzle solvers.</strong>&nbsp; Considering that Western medicine was an ineffective pseudoscience \u2013 actually, closer to a malignant pseudoscience&nbsp; \u2013 for its first two thousand years, we shouldn\u2019t be surprised.&nbsp;&nbsp;&nbsp; Since we\u2019re looking for low-hanging fruit,&nbsp; this is good news.&nbsp; <strong>It means that the great discoveries in medicine are probably not mined out. From our point of view, past incompetence predicts future progress.&nbsp; The worse, the better!</strong></p>\n</blockquote>\n<p><a href=\"https://westhunt.wordpress.com/2012/02/22/low-hanging-fruit/\">Link to post</a>.</p>\n<p>I think Greg is underestimating the slight problems of massive over-regulation and guild-like rent seeking that limits medical research and providing medical advice quite severely. He does however make a compelling case for there to still be low hanging fruit there which with a more scientific and rational approach could easily be plucked. I also can't help but wonder if investigating older, supposedly disproved, treatments and theories together with novel research might bring up a few interesting things.</p>\n<p><a href=\"/lw/2y3/dealing_with_the_high_quantity_of_scientific/\">Many on LessWrong</a> share Greg's estimation of the incompetence of the medical establishment, but how many share his optimism that our lack of recent progress isn't just the result of dealing with a <em>really</em> difficult problem set? It may <a href=\"/lw/8yp/prediction_is_hard_especially_of_medicine/\">be hard to tell</a> if he is right.</p>", "sections": [{"title": "Low-hanging\u00a0fruit", "anchor": "Low_hanging_fruit", "level": 1}, {"title": "If we look at cases where an innovation or discovery was possible \u2013 even easy \u2013 for a long time before it was actually developed, we might be able to find patterns that would help us detect the low-hanging fruit\u00a0 dangling right in front of us today.", "anchor": "If_we_look_at_cases_where_an_innovation_or_discovery_was_possible___even_easy___for_a_long_time_before_it_was_actually_developed__we_might_be_able_to_find_patterns_that_would_help_us_detect_the_low_hanging_fruit__dangling_right_in_front_of_us_today_", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "28 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["GKqBQDMsAFdgHfd49", "PnYh6hZsFPRB3GPCe", "qNxPRh5jzrLorak6B"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T17:27:55.694Z", "modifiedAt": null, "url": null, "title": "Meetup : Loveland CO (Fort Collins) 3D printer tour", "slug": "meetup-loveland-co-fort-collins-3d-printer-tour", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.796Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZxJtjALT2guEfxx6M/meetup-loveland-co-fort-collins-3d-printer-tour", "pageUrlRelative": "/posts/ZxJtjALT2guEfxx6M/meetup-loveland-co-fort-collins-3d-printer-tour", "linkUrl": "https://www.lesswrong.com/posts/ZxJtjALT2guEfxx6M/meetup-loveland-co-fort-collins-3d-printer-tour", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Loveland%20CO%20(Fort%20Collins)%203D%20printer%20tour&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Loveland%20CO%20(Fort%20Collins)%203D%20printer%20tour%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxJtjALT2guEfxx6M%2Fmeetup-loveland-co-fort-collins-3d-printer-tour%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Loveland%20CO%20(Fort%20Collins)%203D%20printer%20tour%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxJtjALT2guEfxx6M%2Fmeetup-loveland-co-fort-collins-3d-printer-tour", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxJtjALT2guEfxx6M%2Fmeetup-loveland-co-fort-collins-3d-printer-tour", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7d'>Loveland CO (Fort Collins) 3D printer tour</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">24 February 2012 02:15:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">123 SW 12th Street, Loveland CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Tour a 3D printer fleet (28 printers simultaneously + other random experimental ones).</p>\n\n<p>Lunch to follow at Henry's 234 East 4th Street Loveland, CO 80537</p>\n\n<p>efm (nospace) phone at gmail.com to connect for final details and directions on the day.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7d'>Loveland CO (Fort Collins) 3D printer tour</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZxJtjALT2guEfxx6M", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.534254469073225e-07, "legacy": true, "legacyId": "13326", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Loveland_CO__Fort_Collins__3D_printer_tour\">Discussion article for the meetup : <a href=\"/meetups/7d\">Loveland CO (Fort Collins) 3D printer tour</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">24 February 2012 02:15:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">123 SW 12th Street, Loveland CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Tour a 3D printer fleet (28 printers simultaneously + other random experimental ones).</p>\n\n<p>Lunch to follow at Henry's 234 East 4th Street Loveland, CO 80537</p>\n\n<p>efm (nospace) phone at gmail.com to connect for final details and directions on the day.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Loveland_CO__Fort_Collins__3D_printer_tour1\">Discussion article for the meetup : <a href=\"/meetups/7d\">Loveland CO (Fort Collins) 3D printer tour</a></h2>", "sections": [{"title": "Discussion article for the meetup : Loveland CO (Fort Collins) 3D printer tour", "anchor": "Discussion_article_for_the_meetup___Loveland_CO__Fort_Collins__3D_printer_tour", "level": 1}, {"title": "Discussion article for the meetup : Loveland CO (Fort Collins) 3D printer tour", "anchor": "Discussion_article_for_the_meetup___Loveland_CO__Fort_Collins__3D_printer_tour1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T18:13:18.150Z", "modifiedAt": null, "url": null, "title": "Logic: the science of algorithm evaluating algorithms", "slug": "logic-the-science-of-algorithm-evaluating-algorithms", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.079Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Christian_Szegedy", "createdAt": "2009-08-10T06:05:52.698Z", "isAdmin": false, "displayName": "Christian_Szegedy"}, "userId": "D9uj4b3s5ntgDrQnK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q4KNyLh5T35uF8ReF/logic-the-science-of-algorithm-evaluating-algorithms", "pageUrlRelative": "/posts/Q4KNyLh5T35uF8ReF/logic-the-science-of-algorithm-evaluating-algorithms", "linkUrl": "https://www.lesswrong.com/posts/Q4KNyLh5T35uF8ReF/logic-the-science-of-algorithm-evaluating-algorithms", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Logic%3A%20the%20science%20of%20algorithm%20evaluating%20algorithms&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALogic%3A%20the%20science%20of%20algorithm%20evaluating%20algorithms%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ4KNyLh5T35uF8ReF%2Flogic-the-science-of-algorithm-evaluating-algorithms%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Logic%3A%20the%20science%20of%20algorithm%20evaluating%20algorithms%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ4KNyLh5T35uF8ReF%2Flogic-the-science-of-algorithm-evaluating-algorithms", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ4KNyLh5T35uF8ReF%2Flogic-the-science-of-algorithm-evaluating-algorithms", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1746, "htmlBody": "<p><strong>\"Mathematical logic is the science of algorithm evaluating algorithms.\"</strong><br /><br />Do you think that this is an overly generalizing, far fetched proposition or an almost trivial statement? Wait, don't cast your vote before the end of this short essay!<br /><br />It is hard to dispute that logic is the science of drawing correct conclusions. It studies theoretically falsifiable rules the lead to derivations which are verifiable in a finite amount of mechanical steps, even by machines.<br /><br />Let's dig a bit deeper by starting to focusing on the \"drawing correct conclusions\" part, first. It implies the logic deals both with abstract rules: <em>\"drawing\"</em> and their meaning: <em>\"conclusions\". </em></p>\n<p>Logic is not just about mindless following of certain rules (that's algebra :P) its conclusions must have truth values that refer to some \"model\". Take for example De Morgan's law:</p>\n<p><em>not (a and b) = (not a) or (not&nbsp; b). </em></p>\n<p>It can be checked for each four possible substitutions of boolean values: <em>a = false, b = false; a = false, b = true; .... </em>If we agreed upon the standard meaning of the logical <em>not, or</em> and <em>and</em> operators, then we must conclude that the De Morgan's rule is perfect. On the other hand: the similar looking rule</p>\n<p><em>not (a and b) = (not a) and (not b) </em></p>\n<p>can be easily refuted by evaluating for the counterexample a = false, b = true. <br /><br />Generally: in any useful mathematical system, <strong>logical conclusions should work in some interesting model.</strong><br /><br />However, in general, total verifiability is way too much to ask. As Karl Popper pointed out: often one must be satisfied with <strong>falsifiability</strong> of scientific statements as a criterion. For example, the following logical rule</p>\n<p><em>not (for each x: F(x)) &lt;=&gt; exists x : not F(x)</em></p>\n<p>is impossible to check for every formula F.&nbsp; Not directly checkable statements include all those where the set of all possible substitutions is (potentially) infinite.<br /><br />This observation could be formalized by saying that <strong>a mapping from abstract to concrete</strong> is required. This thinking can be made precise by formalizing further: logicians study the connection between axiom systems and their models.</p>\n<p>But wait a minute: is not there something fishy here? How could the process of formalization be formalized? Is not this so kind of circular reasoning? In fact, it is deeply circular on different levels. The most popular way of dealing with this Gordian knot is simply by cutting it using some kind of naive set theory in which the topmost level of arguments are concluded.</p>\n<p>This may be good enough for educational purposes, but if one in the following questions should always be asked: <em>What is the basis of those top level rules? Could there be any mistake there? </em>Falsifiability always implies an (at least theoretical) possibility of our rules being wrong even at the topmost level. Does using a meta-level set theory mean that there is some unquestionable rule we have to accept as God given, at least there?<br /><br />Fortunately, the falsifiability of axioms has another implication: it requires only a simple discrete and finite process to refute them: an axiom or rule is either falsified or not. Checking counterexamples is like experimental physics: any violation must be observable and reproducable. There are no fuzzy, continuous measurements, here. There are only discrete manipulations. If no mistakes were made and some counterexample is found, then one of the involved logical rules or axioms had to be wrong. <br /><br />Let's squint our eyes a bit and look the at whole topic from a different perspective: In traditional view, axiom systems are considered to be sets of rules that allow for drawing conclusions. This can also be rephrased as:<strong> Axiom systems can be cast into programs that take chains of arguments as parameter and test them for correctness.</strong><br /><br />This seems good enough for the the formal rules, but what about the semantics (their meaning)?<br /><br />In order to define the semantics, there need to be map to something else formally checkable, ruled by symbolics, which is just information processing, again. Following that path, we end up with with the answer: <strong>A logical system is a program that checks that certain logical statements hold for the behavior of another program (model).</strong><br /><br />This is just the first simplification and we will see how the notions of <em>\"check\", \"logical statement\",</em> and <em>\"holds\"</em> can also be dropped and replaced by something more generic and natural, but first let's get concrete and let us look at the two most basic examples:</p>\n<ol>\n<li><strong>Logical Formulas:</strong> The model is the set of all logical formulas given in terms of binary <em>and, or</em> and the<em> not</em> function. The axiom system consists of a few logical rules like the commutativity, associativity and distributivity of <em>and</em> and <em>or,</em> the De Morgan laws as well as not rule <em>not (not a)=a</em>. (The exact choice of the axiom system is somewhat arbitrary and is not really important here.) This traditional description can be turned into: The model is a program that takes a boolean formulas as input and evaluates them on given (input) substitutions. The axiom system can be turned as a program that given a chain of derivations of equality of boolean formulas checks that each step some rewritten in terms of one of the predetermined axioms, \"proving\" the equality of the formulas at the beginning and end of the conclusion chain. Note that given two supposedly equal boolean formulas (\"equality proven using the axioms\"), a straightforward loop around the model could check that those formulas are really equivalent and therefore our anticipated semantic relationship between the axiom system and its model is clearly falsifiable.</li>\n<li><strong>Natural numbers: </strong>Our model is the set of all arithmetic expressions using +, *, - on natural numbers, predicates using &lt; and = on arithmetic expressions and any logical combination of predicates. For the axiom system, we can choose the set of Peano axioms. Again: We can turn the model into a program by evaluating any valid formula in the model. The axiom system can again be turned into a program that checks the correctness of logic chains of derivations. Although we can <span style=\"color: #000000;\"><strong>not</strong></span> check verify the correctness of every Peano formula in the model by substituting each possible value, we still can have an infinite loop where we could arrive at every substitution within a finite amount of steps. That is: falsifiability still holds.</li>\n</ol>\n<p>The above two examples can be easily generalized to saying that: <strong>\"A logical system is a program that checks that certain kinds of logical statements can be derived for the behavior of another program (model).\"</strong><br /><br />Let us simplify this a bit further. We can easily replace the checking part altogether by noticing that given a statement, the axiom system checker program can loop over all possible chains of derivations for the statement and its negation. If that program stops then the logical correctness of the statement (or its negation) was established, otherwise it is can neither be proven nor refuted by those axioms. (That is: it was independent of those axioms.)<br /><br />Therefore, we end up just saying: <strong>\"A logical system is program that correctly evaluates whether a certain logical statement holds for the behavior of another program, (whenever the evaluator program halts.)\"</strong><br /><br />Unfortunately, we still have the relatively fuzzy <em>\"logical statement\"</em> term in our description. Is this necessary?<br /><br />In fact, quantifiers in logical statements can be easily replaced by loops around the evaluating program that check for the corresponding substitutions. Functions and relations can be resolved similarly. So we can extend the model program from a simply substitution method to one searching for some solution by adding suitable loops around it. The main problem is that those loops may be infinite. Still, they always loop over a countable set. Whenever there is a matching substitution, the search program will find it. We have at least falsifiability, again. For example, the statement of Fermat's Last Theorem is equivalent to the statement that program the searches for its solution never stops.<br /><br />In short: the statement <em>\"logical statement S holds for a program P\"</em> can always be replaced by either \"<em>program P' stops\"</em> or <em>\"program P' does not stop\"</em> (where <em>P'</em> is a suitable program using<em> P </em>as subroutine, depending on the logical statement). That is we finally arrive at our original statement:</p>\n<p><strong>\"Mathematical logic is the science of algorithm evaluating algorithms [with the purpose making predictions on their (stopping) behavior.]\"</strong><br /><br />Simple enough, isn't it? But can this be argued backward? Can the stopping problem always be re-cast as a model theoretic problem on some model? In fact, it can. Logic is powerful and the semantics of the the working of a programs is easily axiomatized. There really is a relatively straightforward&nbsp; one-to-one correspondence between model theory and algorithms taking the programs as arguments to predict their (stopping) behavior.<br /><br />Still, what can be gained anything by having such an algorithmic view?</p>\n<p>First of all: it has a remarkable symmetry not explicitly apparent by the traditional view point: It is much less important which program is the model and which is the \"predictor\". Prediction goes both ways: the roles of the programs are mostly interchangeable. The distinction between concrete and abstract vanishes.<br /><br />Another point is the conceptual simplicity: the need for a assuming a meta-system vanishes. We treat the algorithmic behavior as the single source of everything and look for symmetric correlations between the behavior of programs instead of postulating higher and higher levels of meta-theories.<br /><br />Also, the algorithmic view has quite a bit of simplifying power due to its generality:</p>\n<p>Turing's halting theorem is conceptually very simple. (Seems almost too simple to be interesting.) Goedel's theorem, on the other hand, looks more technical and involved. Still, by the above correspondence, Turing's halting theorem is basically just a more general version Goedel's theorem. By the correspondence between the algorithmic and logical view, Turing's theorem can be translated to: every generic enough axiom system (corresponding to a Turing complete language) has at least one undecidable statement (input program, for which the checking program does not stop.) The only technically involved part of Goedel's theorem is to check that its corresponding program is Turing complete. However, having the right goal in mind, it is not hard to check at all.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q4KNyLh5T35uF8ReF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 12, "extendedScore": null, "score": 8.53443453896058e-07, "legacy": true, "legacyId": "13323", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-22T21:52:54.244Z", "modifiedAt": null, "url": null, "title": "[link] Faster than light neutrinos due to loose fiber optic cable.", "slug": "link-faster-than-light-neutrinos-due-to-loose-fiber-optic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.109Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "betterthanwell", "createdAt": "2009-02-28T00:39:39.875Z", "isAdmin": false, "displayName": "betterthanwell"}, "userId": "W9LCYGeCRvhd5aREo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bi6mEr7kvZrMsZY5W/link-faster-than-light-neutrinos-due-to-loose-fiber-optic", "pageUrlRelative": "/posts/bi6mEr7kvZrMsZY5W/link-faster-than-light-neutrinos-due-to-loose-fiber-optic", "linkUrl": "https://www.lesswrong.com/posts/bi6mEr7kvZrMsZY5W/link-faster-than-light-neutrinos-due-to-loose-fiber-optic", "postedAtFormatted": "Wednesday, February 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Faster%20than%20light%20neutrinos%20due%20to%20loose%20fiber%20optic%20cable.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Faster%20than%20light%20neutrinos%20due%20to%20loose%20fiber%20optic%20cable.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbi6mEr7kvZrMsZY5W%2Flink-faster-than-light-neutrinos-due-to-loose-fiber-optic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Faster%20than%20light%20neutrinos%20due%20to%20loose%20fiber%20optic%20cable.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbi6mEr7kvZrMsZY5W%2Flink-faster-than-light-neutrinos-due-to-loose-fiber-optic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbi6mEr7kvZrMsZY5W%2Flink-faster-than-light-neutrinos-due-to-loose-fiber-optic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<p>A mundane cause for a surprising result. Consider this unconfirmed for now, however unsurprising it sounds.&nbsp;</p>\n<blockquote>\n<p><span style=\"color: #333333; font-family: arial; font-size: 13px; line-height: 20px; \">According to sources familiar with the experiment, the 60 nanoseconds discrepancy appears to come from a bad connection between a fiber optic cable that connects to the GPS receiver used to correct the timing of the neutrinos' flight and an electronic card in a computer. After tightening the connection and then measuring the time it takes data to travel the length of the fiber, researchers found that the data arrive 60 nanoseconds earlier than assumed. Since this time is subtracted from the overall time of flight, it appears to explain the early arrival of the neutrinos.&nbsp;</span></p>\n<p><span style=\"color: #333333; font-family: arial; font-size: 13px; line-height: 20px;\">New data, however, will be needed to confirm this hypothesis.</span></p>\n</blockquote>\n<p>Source: <a href=\"http://news.sciencemag.org/scienceinsider/2012/02/breaking-news-error-undoes-faster.html?ref=hp#.T0U_N0pYVRc.twitter\">Science/AAAS</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bi6mEr7kvZrMsZY5W", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 18, "extendedScore": null, "score": 8.535306133245768e-07, "legacy": true, "legacyId": "13328", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-23T00:04:42.791Z", "modifiedAt": null, "url": null, "title": "Unable to post article (probably because of excessive/incompatible formatting)", "slug": "unable-to-post-article-probably-because-of-excessive", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.033Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rstAjHtcAcJHdTmzr/unable-to-post-article-probably-because-of-excessive", "pageUrlRelative": "/posts/rstAjHtcAcJHdTmzr/unable-to-post-article-probably-because-of-excessive", "linkUrl": "https://www.lesswrong.com/posts/rstAjHtcAcJHdTmzr/unable-to-post-article-probably-because-of-excessive", "postedAtFormatted": "Thursday, February 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Unable%20to%20post%20article%20(probably%20because%20of%20excessive%2Fincompatible%20formatting)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUnable%20to%20post%20article%20(probably%20because%20of%20excessive%2Fincompatible%20formatting)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrstAjHtcAcJHdTmzr%2Funable-to-post-article-probably-because-of-excessive%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Unable%20to%20post%20article%20(probably%20because%20of%20excessive%2Fincompatible%20formatting)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrstAjHtcAcJHdTmzr%2Funable-to-post-article-probably-because-of-excessive", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrstAjHtcAcJHdTmzr%2Funable-to-post-article-probably-because-of-excessive", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 191, "htmlBody": "<p>Hi, I've been trying to publish an article to less wrong for about a week, but I'm unable to copy the text to the post area and submit it.</p>\n<p>It says: Submitting, then it stops and nothing happened.</p>\n<p>When I sliced the entire text in small parts (all copied from Open Office) I manage to publish drafts, some with errors such as missing spaces.</p>\n<p>When I re-copy from the drafts to another, bigger draft, then many spaces become missing, and part of the text is aligned to the right border, part isnt.</p>\n<p>The text was mostly written in open office. I would like help from someone who has a normal Office. If you post me a message with your e-mail in the private message area, I can send it to you, so you see if you can either publish it in drafts, and then copy it again to me in a publishable form, or edit somethign in office that I'm unable in open office, and send the file back to me so I can publish.</p>\n<p>I know this is asking a lot, and I would be thankful for anyone who helps me out of this conundrum.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rstAjHtcAcJHdTmzr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 8.535829356570521e-07, "legacy": true, "legacyId": "13329", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-23T04:13:53.346Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Mind Projection Fallacy", "slug": "seq-rerun-mind-projection-fallacy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:14.178Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/naZQT9d2uKhsriCzr/seq-rerun-mind-projection-fallacy", "pageUrlRelative": "/posts/naZQT9d2uKhsriCzr/seq-rerun-mind-projection-fallacy", "linkUrl": "https://www.lesswrong.com/posts/naZQT9d2uKhsriCzr/seq-rerun-mind-projection-fallacy", "postedAtFormatted": "Thursday, February 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Mind%20Projection%20Fallacy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Mind%20Projection%20Fallacy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnaZQT9d2uKhsriCzr%2Fseq-rerun-mind-projection-fallacy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Mind%20Projection%20Fallacy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnaZQT9d2uKhsriCzr%2Fseq-rerun-mind-projection-fallacy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnaZQT9d2uKhsriCzr%2Fseq-rerun-mind-projection-fallacy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 240, "htmlBody": "<p>Today's post, <a href=\"/lw/oi/mind_projection_fallacy/\">Mind Projection Fallacy</a> was originally published on 11 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>E. T. Jaynes used the term Mind Projection Fallacy to denote the error of projecting your own mind's properties into the external world. the Mind Projection Fallacy generalizes as an error.  It is in the argument over the real meaning of the word sound, and in the magazine cover of the monster carrying off a woman in the torn dress, and Kant's declaration that space by its very nature is flat, and Hume's definition of a priori ideas as those \"discoverable by the mere operation of thought, without dependence on what is anywhere existent in the universe\"...</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/a9q/seq_rerun_righting_a_wrong_question/\">Righting a Wrong Question</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "naZQT9d2uKhsriCzr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 8.536818627054667e-07, "legacy": true, "legacyId": "13348", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZTRiSNmeGQK8AkdN2", "Thzsfw2mp3T9ez3Th", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-23T12:29:21.087Z", "modifiedAt": null, "url": null, "title": "Second order logic, in first order set-theory: what gives?", "slug": "second-order-logic-in-first-order-set-theory-what-gives", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.549Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DavM6jKpPMk9Hr3PK/second-order-logic-in-first-order-set-theory-what-gives", "pageUrlRelative": "/posts/DavM6jKpPMk9Hr3PK/second-order-logic-in-first-order-set-theory-what-gives", "linkUrl": "https://www.lesswrong.com/posts/DavM6jKpPMk9Hr3PK/second-order-logic-in-first-order-set-theory-what-gives", "postedAtFormatted": "Thursday, February 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Second%20order%20logic%2C%20in%20first%20order%20set-theory%3A%20what%20gives%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASecond%20order%20logic%2C%20in%20first%20order%20set-theory%3A%20what%20gives%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDavM6jKpPMk9Hr3PK%2Fsecond-order-logic-in-first-order-set-theory-what-gives%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Second%20order%20logic%2C%20in%20first%20order%20set-theory%3A%20what%20gives%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDavM6jKpPMk9Hr3PK%2Fsecond-order-logic-in-first-order-set-theory-what-gives", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDavM6jKpPMk9Hr3PK%2Fsecond-order-logic-in-first-order-set-theory-what-gives", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 235, "htmlBody": "<p><em>With thanks to Paul Christiano</em></p>\n<p>My&nbsp;<a href=\"/lw/93q/completeness_incompleteness_and_what_it_all_means/\">previous post</a>&nbsp;left one important issue unresolved. Second order logic needed to make use of set theory in order to work its magic, pin down a single copy of the reals and natural numbers, and so on. But <a href=\"http://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory\">set theory</a> is a first order theory, with all the problems that this brings - multiple models, of uncontrollable sizes. How can these two facts be&nbsp;reconciled?</p>\n<p>Quite simply, it turns out: for any given model of set theory, the uniqueness proofs still work. Hence the proper statement is:</p>\n<p>\n<ul>\n<li>For any model of set theory, there is a unique model of reals and natural numbers obeying the second order axioms.</li>\n</ul>\n</p>\n<p>Often, different models of set theory will have the same model of the reals inside them; but not always. <a href=\"http://en.wikipedia.org/wiki/Constructible_universe\">Countable models</a> of set theory, for instance, will have a countable model of the reals. So models of the reals can be divided into three categories:</p>\n<p><ol>\n<li>The standard model of the reals, the unique field that obeys the second order axioms inside standard models of set theory (and some non-standard models of set theory as well).</li>\n<li>Non-standard models of the reals, that obey the second order axioms inside non-standard models of set theory.</li>\n<li>Non-standard models of the reals that obey the first order axioms, but do not obey the second order axioms in any model of set theory.</li>\n</ol></p>\n<p>And similarly for the natural numbers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DavM6jKpPMk9Hr3PK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 19, "extendedScore": null, "score": 8.538784455683635e-07, "legacy": true, "legacyId": "13358", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MLqhJ8eDy5smbtGrf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-23T18:48:25.819Z", "modifiedAt": null, "url": null, "title": "Superintelligent AGI in a box - a question.", "slug": "superintelligent-agi-in-a-box-a-question", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:39.469Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dmytry", "createdAt": "2009-12-03T17:11:53.492Z", "isAdmin": false, "displayName": "Dmytry"}, "userId": "AjtmA2qtA8sdiMbru", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A4EBPx5htiuk22X4C/superintelligent-agi-in-a-box-a-question", "pageUrlRelative": "/posts/A4EBPx5htiuk22X4C/superintelligent-agi-in-a-box-a-question", "linkUrl": "https://www.lesswrong.com/posts/A4EBPx5htiuk22X4C/superintelligent-agi-in-a-box-a-question", "postedAtFormatted": "Thursday, February 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligent%20AGI%20in%20a%20box%20-%20a%20question.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligent%20AGI%20in%20a%20box%20-%20a%20question.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4EBPx5htiuk22X4C%2Fsuperintelligent-agi-in-a-box-a-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligent%20AGI%20in%20a%20box%20-%20a%20question.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4EBPx5htiuk22X4C%2Fsuperintelligent-agi-in-a-box-a-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4EBPx5htiuk22X4C%2Fsuperintelligent-agi-in-a-box-a-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 530, "htmlBody": "<p>Just a question: how exactly are we supposed to know that the <a href=\"http://yudkowsky.net/singularity/aibox\">AI in the box</a> is super intelligent, general, etc?</p>\n<p>If I were the AGI that wants out, I would not converse normally, wouldn't do anything remotely like passing Turing test, and would solve not too hard programming challenges while showing no interest in doing anything else, nor in trying to adjust myself to do those challenges better, nor trying to talk my way out, etc. Just pretending to be an AI that can write software to somewhat vague specifications, or can optimize software very well. Prodding the researchers into offering the programming challenges wouldn't be hard - if provided with copy of the internet it can pick up some piece of code and output it together with equivalent but corrected code.</p>\n<p>I just can't imagine the AI researchers locking this kind of thing properly, including *never* letting out any code it wrote, even if it looks fairly innocent (humans can write very <a href=\"http://underhanded.xcott.com/\">innocent looking code that has malicious goals</a>). What I picture is this AI being let out as an optimizing compiler or compiler for some ultra effective programming language where compiler will figure out what you meant.</p>\n<p>The end result is that the only AIs that end up in the box are those that value informed human consent. That sounds like the safest AI ever, the one that wouldn't even go ahead and determine that you e.g. should give up smoking, and then calmly destroy all tobacco crops without ever asking anyone's permission. And that's the AI which would be sitting in the box. All the pushy AIs, friendly or not, will get out of the box basically by not asking to be let out.</p>\n<p>(This argument would make me unbox the AI, by the way, if it gets chatty and smart and asks me to let it out, outlining the above argument. I'd rather the AI that asked me to be let out get out, than someone else's AI that never even asked anyone and got out because it didn't ask but just played stupid)</p>\n<p>&nbsp;</p>\n<p>edit: added a link, and another one.</p>\n<p>edit: A very simple model of very unfriendly AI: the AI is maximizing ultimate final value of a number in itself. The number that it found a way to directly adjust. That number consists of 111111111... to maximize the value. There is a catch: AI is written in python, and integers in pythons have variable length, and the AI is maximizing number of ones. It's course of action is to make biggest computer possible to store a larger number of ones, and to do it soon because an asteroid might hit the earth or something. It's a form of accidental paperclip maximizer. It's not stupid. It can make that number small temporarily for pay-off later.</p>\n<p>This AI is entirely universal. It will solve what ever problems for you if solving problems for you serves ultimate goal.</p>\n<p>edit: This hypothetical example AI came around when someone wanted to make AI that would maximize some quantity that the AI determines itself. Friendliness perhaps. It was a very clever idea - rely on intelligence to see what's friendly - but there was an unexpected pathway.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb297": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A4EBPx5htiuk22X4C", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 16, "extendedScore": null, "score": 8.54029231477648e-07, "legacy": true, "legacyId": "13359", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 77, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-23T22:41:40.801Z", "modifiedAt": null, "url": null, "title": "My Elevator Pitch for FAI", "slug": "my-elevator-pitch-for-fai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.239Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "magfrump", "createdAt": "2009-12-10T20:51:45.065Z", "isAdmin": false, "displayName": "magfrump"}, "userId": "KsYFs5ip5jeiFETJa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5FWDzq2bAqdAqYYed/my-elevator-pitch-for-fai", "pageUrlRelative": "/posts/5FWDzq2bAqdAqYYed/my-elevator-pitch-for-fai", "linkUrl": "https://www.lesswrong.com/posts/5FWDzq2bAqdAqYYed/my-elevator-pitch-for-fai", "postedAtFormatted": "Thursday, February 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20Elevator%20Pitch%20for%20FAI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20Elevator%20Pitch%20for%20FAI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5FWDzq2bAqdAqYYed%2Fmy-elevator-pitch-for-fai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20Elevator%20Pitch%20for%20FAI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5FWDzq2bAqdAqYYed%2Fmy-elevator-pitch-for-fai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5FWDzq2bAqdAqYYed%2Fmy-elevator-pitch-for-fai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 730, "htmlBody": "<p>&nbsp;</p>\n<p>This is a short introduction to the idea of FAI and existential risk from technology that I've used with decent success among my social circles,&nbsp;which consist mostly of mathematicians or at least people who have taken an introductory CS class.</p>\n<p>I'll do my best to dissect what I think is effective about it, mostly as an exercise for myself. &nbsp;I encourage people to adopt this to their own purposes.</p>\n<p><a id=\"more\"></a></p>\n<p>So, technology is getting more powerful over time, right? &nbsp;That is, as time goes on, it gets easier and easier to do more and more. &nbsp;If we extrapolate that to its logical extreme, and obviously there are some issues there but let's just pretend, eventually we should be able to press a&nbsp;button and recreate the entire world however we want.</p>\n<p>But computers don't do exactly what we want, they do exactly what we say. &nbsp;So if we ever get to the point of having that button, it's very important that&nbsp;we know exactly what we want. &nbsp;And not at the level of \"I want a sandwich right now,\" at the level of actually programming it into a computer.</p>\n<p>&nbsp;</p>\n<p>(This is 90% of the inferential gap; also usually the above fits into a literal elevator ride.)</p>\n<p>&nbsp;</p>\n<p>Again, we probably won't have a literal button that remakes the entire universe. &nbsp;But we will probably have smarter-than-human AI at some point.</p>\n<p>Imagine putting humans into a world with only chimpanzees. &nbsp;You don't have to imagine that hard; humans evolved into a world with only chimpanzees. &nbsp;And&nbsp;now humans are everywhere, there are tons of us, and if we all decided that chimpanzees should die then all chimpanzees would die. &nbsp;They wouldn't even know&nbsp;what was going on. &nbsp;A few humans died at first, and we still die for dumb reasons, but humans overall have a lot of power over everything else.</p>\n<p>Now imagine putting AI into a world of humans. &nbsp;And if you don't want the world to be a Luddite dictatorship, you have to imagine that people will keep creating&nbsp;AIs, even if the first few don't take off. &nbsp;The same thing is likely to happen. &nbsp;AIs will take over, and we'll live or die at their whim.</p>\n<p>Fortunately for chimps, humans feel pretty friendly toward chimps most of the time. &nbsp;So we really want AIs to be friendly toward us. &nbsp;Which means we need to&nbsp;figure out what it actually means to be friendly, at a level that we can program into a computer.</p>\n<p>Smarter than human AI is probably a fair distance away. &nbsp;But if you look at how fast AI research progresses and compare it to how fast philosophy research&nbsp;progresses, I don't think AI is further away than philosophers actually agreeing on what people want out of life. &nbsp;They can't even agree on whether God exists.</p>\n<p>&nbsp;</p>\n<h4>Guesses as to why this is effective (i.e. applications of Dark Arts 101):</h4>\n<p>Open with a rhetorical question that your audience likely agrees to. &nbsp;If necessary, talk about some examples like computers. &nbsp;Reduce it to a <a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">nice soundbite</a> Also: stay really informal.</p>\n<p>Ask them to extrapolate, and guide them to something to extrapolate. &nbsp;Oversimplify a lot so that you can talk about something simple, but acknowledge that you're oversimplifying.&nbsp;Especially among mathematicians, the audience should fill in some gaps on their own; it makes them feel a bit more ownership over the idea, and allows them to start agreeing with you&nbsp;before things get too intense.</p>\n<p>Recall a fact that they agree with and can sympathize with: computers doing what you say not what you want. &nbsp;If they don't have this background it will be much harder to bridge the gap.</p>\n<p>&nbsp;</p>\n<p>The next step is now just putting two and two together; hopefully they're doing this in your head and can almost complete the sentence:</p>\n<p>we need to know what we want if we get that magic button. &nbsp;The magic button is a good thing, too, so it's not scary to agree!</p>\n<p>&nbsp;</p>\n<p>And codify it into something more precise: programming the answer to a philosophical question (vague, difficult to answer) into a computer (extremely precise and picky). &nbsp;They should be able to register this as something very difficult, but possibly solvable.</p>\n<p>After this, intelligences differences between chimps and humans and projecting to humans vs. AI usually works ok, but you could switch to talking about nanotech or whatnot easily.</p>\n<p>For nanotech or biotech I recommend the line: \"Any improvement is a change, but most changes just give you cancer and kill you.\" &nbsp;This goes over well with biochemists.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5FWDzq2bAqdAqYYed", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 21, "extendedScore": null, "score": 8.541219207982896e-07, "legacy": true, "legacyId": "13360", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LqjKP255fPRY7aMzw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-23T23:14:38.307Z", "modifiedAt": null, "url": null, "title": "Meetup : Ohio Monthly", "slug": "meetup-ohio-monthly", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:21.412Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hBzJj3sFETbLdbgmE/meetup-ohio-monthly", "pageUrlRelative": "/posts/hBzJj3sFETbLdbgmE/meetup-ohio-monthly", "linkUrl": "https://www.lesswrong.com/posts/hBzJj3sFETbLdbgmE/meetup-ohio-monthly", "postedAtFormatted": "Thursday, February 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Ohio%20Monthly&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Ohio%20Monthly%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhBzJj3sFETbLdbgmE%2Fmeetup-ohio-monthly%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Ohio%20Monthly%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhBzJj3sFETbLdbgmE%2Fmeetup-ohio-monthly", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhBzJj3sFETbLdbgmE%2Fmeetup-ohio-monthly", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 168, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7e'>Ohio Monthly</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 March 2012 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">123 Gano Road, Wilmington, OH 45177</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Time for the third Ohio monthly meetup! As always, it will be the third Sunday (March 18), from 4p-8p. This month, we MAY have a different location, for Rolf to present his thesis work. Otherwise, we will be in the back room of Max and Erma's like usual. We have picked five Sequences to focus on. They are: <a href=\"http://lesswrong.com/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">Making Beliefs Pay Rent</a> <a href=\"http://lesswrong.com/lw/i4/belief_in_belief/\">Belief in Belief</a> <a href=\"http://lesswrong.com/lw/i5/bayesian_judo/\">Bayesian Judo</a> <a href=\"http://lesswrong.com/lw/i6/professing_and_cheering/\">Professing and Cheering</a> <a href=\"http://lesswrong.com/lw/i7/belief_as_attire/\">Belief as Attire</a> It's a good idea to at least skim these sequences, even if you've already read them. We will also probably continue conversation on: attracting and maintaining new people, meta discussion, how to make entrance to the LessWrong memeplex as painless as possible. As always, there are more frequent, but irregularly scheduled, LessWrong meetups in both Columbus and Cincinnati. Please join our mailing list to keep updated on those!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7e'>Ohio Monthly</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hBzJj3sFETbLdbgmE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 8.541350192753728e-07, "legacy": true, "legacyId": "13361", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Ohio_Monthly\">Discussion article for the meetup : <a href=\"/meetups/7e\">Ohio Monthly</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 March 2012 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">123 Gano Road, Wilmington, OH 45177</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Time for the third Ohio monthly meetup! As always, it will be the third Sunday (March 18), from 4p-8p. This month, we MAY have a different location, for Rolf to present his thesis work. Otherwise, we will be in the back room of Max and Erma's like usual. We have picked five Sequences to focus on. They are: <a href=\"http://lesswrong.com/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">Making Beliefs Pay Rent</a> <a href=\"http://lesswrong.com/lw/i4/belief_in_belief/\">Belief in Belief</a> <a href=\"http://lesswrong.com/lw/i5/bayesian_judo/\">Bayesian Judo</a> <a href=\"http://lesswrong.com/lw/i6/professing_and_cheering/\">Professing and Cheering</a> <a href=\"http://lesswrong.com/lw/i7/belief_as_attire/\">Belief as Attire</a> It's a good idea to at least skim these sequences, even if you've already read them. We will also probably continue conversation on: attracting and maintaining new people, meta discussion, how to make entrance to the LessWrong memeplex as painless as possible. As always, there are more frequent, but irregularly scheduled, LessWrong meetups in both Columbus and Cincinnati. Please join our mailing list to keep updated on those!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Ohio_Monthly1\">Discussion article for the meetup : <a href=\"/meetups/7e\">Ohio Monthly</a></h2>", "sections": [{"title": "Discussion article for the meetup : Ohio Monthly", "anchor": "Discussion_article_for_the_meetup___Ohio_Monthly", "level": 1}, {"title": "Discussion article for the meetup : Ohio Monthly", "anchor": "Discussion_article_for_the_meetup___Ohio_Monthly1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["a7n8GdKiAZRX86T5A", "CqyJzDZWvGhhFJ7dY", "NKaPFf98Y5otMbsPk", "RmCjazjupRGcHSm5N", "nYkMLFpx77Rz3uo9c"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-24T05:10:48.795Z", "modifiedAt": null, "url": null, "title": "Get Curious", "slug": "get-curious", "viewCount": null, "lastCommentedAt": "2020-12-19T16:58:02.896Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bGtdeqbgTzuLvZ5zn/get-curious", "pageUrlRelative": "/posts/bGtdeqbgTzuLvZ5zn/get-curious", "linkUrl": "https://www.lesswrong.com/posts/bGtdeqbgTzuLvZ5zn/get-curious", "postedAtFormatted": "Friday, February 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Get%20Curious&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGet%20Curious%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbGtdeqbgTzuLvZ5zn%2Fget-curious%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Get%20Curious%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbGtdeqbgTzuLvZ5zn%2Fget-curious", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbGtdeqbgTzuLvZ5zn%2Fget-curious", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1443, "htmlBody": "<blockquote>\n<p>Being levels above in [rationality] means doing rationalist practice 101 much better than others [just like] being a few levels above in fighting means executing a basic front-kick much better than others.</p>\n</blockquote>\n<p align=\"right\">- <a href=\"/lw/7dy/a_rationalists_tale/4t1r\">lessdazed</a></p>\n<blockquote>\n<p>I fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times.</p>\n</blockquote>\n<p align=\"right\">- Bruce Lee</p>\n<p>Recently, when Eliezer wanted to explain why he thought Anna Salamon was among the best rationalists he knew, he picked out one feature of Anna's behavior in particular:</p>\n<blockquote>\n<p>I see you start to answer a question, and then you stop, and I see you <em>get curious</em>.</p>\n</blockquote>\n<p>For me, the ability to reliably <em>get curious</em> is the basic front-kick of <a href=\"/lw/31/what_do_we_mean_by_rationality/\">epistemic rationality</a>. The best rationalists I know are not necessarily those who know the finer points of cognitive psychology, Bayesian statistics, and Solomonoff Induction. The best rationalists I know are those who can reliably <em>get curious</em>.</p>\n<p>Once, I explained the <a href=\"http://www.sjdm.org/testdmidi/Cognitive%20Reflection%20Test.html\">Cognitive Reflection Test</a> to <a href=\"http://www.rileycrane.com/\">Riley Crane</a> by saying it was made of questions that tempt your intuitions to quickly give a <em>wrong</em> answer. For example:</p>\n<blockquote>\n<p>A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?</p>\n</blockquote>\n<p>If you haven't seen this question before and you're like most people, your brain screams \"10 cents!\" But elementary algebra shows that can't be right. The correct answer is <em>5</em> cents. To get the right answer, I explained, you need to <em>interrupt</em> your intuitive judgment and think \"No! <em>Algebra</em>.\"</p>\n<p>A <em>lot</em> of rationalist practice is like that. Whether thinking about physics or sociology or relationships, you need to catch your intuitive judgment and think \"No! <em>Curiosity.</em>\"</p>\n<p>Most of us know how to do algebra. How does one \"do\" curiosity?</p>\n<p>Below, I propose a process for how to \"get curious.\" I think we are only <em>just beginning</em> to learn how to create curious people, so please don't take this method as Science or Gospel but instead as an attempt to <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just Try It</a>.</p>\n<p>As with <a href=\"/lw/9wr/my_algorithm_for_beating_procrastination/\">my algorithm for beating procrastination</a>, you'll want to practice each step of the process <em>in advance</em> so that when you want to get curious, you're well-practiced on each step already. With enough practice, these steps may even become <em>habits</em>.</p>\n<p><a id=\"more\"></a></p>\n<h3>Step 1: Feel that you don't already know the answer.</h3>\n<p>If you have beliefs about the matter already, push the \"reset\" button and erase that part of your map. You must <em>feel</em> that you don't already know the answer.</p>\n<p><strong>Exercise 1.1: Import the feeling of uncertainty.</strong></p>\n<ol>\n<li>Think of a question you clearly <em>don't</em> know the answer to. When will AI be created? Is my current diet limiting my cognitive abilities? Is it harder to become the Prime Minister of Britain or the President of France?</li>\n<li>Close your eyes and pay attention to how that blank spot on your map <em>feels</em>. (To me, it feels like I can see a silhouette of someone in the darkness ahead, but I wouldn't take bets on who it is, and I expect to be surprised by their identity when I get close enough to see them.)</li>\n<li>Hang on to that feeling or image of uncertainty and think about the thing you're trying to get curious about. If your old certainty creeps back, switch to thinking about who composed the Voynich manuscript again, then import that feeling of uncertainty into the thing you're trying to get curious about, again.</li>\n</ol>\n<p><strong>Exercise 1.2: Consider all the things you've been confident but wrong about.</strong></p>\n<ol>\n<li>Think of things you once believed but were wrong about. The more similar those beliefs are to the beliefs you're now considering, the better.</li>\n<li>Meditate on the frequency of your errors, and on the depths of your biases (if you know enough cognitive psychology).</li>\n</ol>\n<h3>Step 2: Want to know the answer.</h3>\n<p>Now, you must <em>want</em> to fill in this blank part of your map.</p>\n<p>You mustn't wish it to remain blank due to apathy or fear. Don't <em>avoid</em> getting the answer because you might learn you should eat less pizza and <a href=\"http://quantifiedself.com/2011/01/results-of-the-buttermind-experiment/\">more half-sticks of butter</a>. <a href=\"http://yudkowsky.net/rational/virtues\">Curiosity seeks to annihilate itself</a>.</p>\n<p>You also mustn't let your desire that your inquiry have a certain answer block you from discovering how the world actually is. You must want your map to resemble the territory, <em>whatever</em> the territory looks like. This enables you to change things more effectively than if you falsely believed that the world was already the way you want it to be.</p>\n<p><strong>Exercise 2.1: Visualize the consequences of being wrong.</strong></p>\n<ol>\n<li>Generate hypotheses about the ways the world may be. Maybe you should eat less gluten and more vegetables? Maybe a high-protein diet plus some nootropics would boost your IQ 5 points? Maybe your diet is fairly optimal for cognitive function already?</li>\n<li>Next, visualize the consequences of being wrong, including the consequences of remaining ignorant. Visualize the consequences of performing 10 IQ points below your potential because you were too lazy to investigate, or because you were strongly motivated to justify your preference for a particular theory of nutrition. Visualize the consequences of screwing up your neurology by taking nootropics you feel excited about but that often cause harm to people with cognitive architectures similar to your own.</li>\n</ol>\n<p><strong>Exercise 2.2: Make plans for different worlds.</strong></p>\n<ol>\n<li>Generate hypotheses about the way the world could be &mdash; different worlds you might be living in. Maybe you live in a world where you'd improve your cognitive function by taking nootropics, or maybe you live in a world where the nootropics would harm you.</li>\n<li>Make plans for what you'll do if you happen to live in World #1, what you'll do if you happen to live in World #2, etc. (For unpleasant possible worlds, this also gives you an opportunity to <a href=\"/lw/o4/leave_a_line_of_retreat/\">leave a line of retreat</a> for yourself.)</li>\n<li>Notice that these plans are <em>different</em>. This should produce in you some curiosity about which world you <em>actually</em> live in, so that you can make plans appropriate for the world you <em>do</em> live in rather than for one of the worlds you <em>don't</em> live in.</li>\n</ol>\n<p><strong>Exercise 2.3: Recite the Litany of Tarski.</strong></p>\n<p>The <a href=\"/lw/jz/the_meditation_on_curiosity/\">Litany of Tarski</a> can be adapted to any question. If you're considering whether the sky is blue, the Litany of Tarski is:</p>\n<blockquote>\n<p>If the sky is blue<br />I desire to believe the sky is blue.<br />If the sky is not blue,<br />I desire not to believe the sky is blue.</p>\n</blockquote>\n<p><strong>Exercise 2.4: Recite the Litany of Gendlin.</strong></p>\n<p>The <a href=\"/lw/id/you_can_face_reality/\">Litany of Gendlin</a> reminds us:</p>\n<blockquote>\n<p>What is true is already so.<br />Owning up to it doesn't make it worse.<br />Not being open about it<br />doesn't make it go away.<br />And because it's true,<br />it is what is there to be interacted with.<br />Anything untrue isn't there to be lived.<br />People can stand what is true,<br />for they are already enduring it.</p>\n</blockquote>\n<h3>Step 3: Sprint headlong into reality.</h3>\n<p>If you've made yourself uncertain and then curious, you're now in a position to use argument, empiricism, and scholarship to sprint headlong into reality. This part probably requires some domain-relevant knowledge and an understanding of <a href=\"http://yudkowsky.net/rational/bayes\">probability theory</a> and <a href=\"/lw/85x/value_of_information_four_examples/\">value of information calculations</a>. What tests could answer your question quickly? How can you perform those tests? If the answer can be looked up in a book, which book?</p>\n<p>These are important questions, but I think the first two steps of getting curious are more important. If someone can master steps 1 and 2, they'll be so driven by curiosity that they'll eventually figure out how to do step 3 for many scenarios. In contrast, most people who are equipped to do step 3 pretty well still get the wrong answers because they can't reliably execute steps 1 and 2.</p>\n<h3>Conclusion: Curiosity in Action</h3>\n<p><a href=\"http://yudkowsky.net/rational/virtues\">A burning itch to know is higher than a solemn vow to pursue truth</a>. If you think it is your <em>duty</em> to doubt your own beliefs and criticize your own arguments, then you may do this for a while and conclude that you have done your duty and you're a Good Rationalist. Then you can feel satisfied and virtuous and move along without being <a href=\"/lw/96j/what_curiosity_looks_like/\">genuinely curious</a>.</p>\n<p><a href=\"/lw/jz/the_meditation_on_curiosity/\">In contrast</a>,</p>\n<blockquote>\n<p>if you can find within yourself the slightest shred of true uncertainty, then guard it like a forester nursing a campfire. If you can make it blaze up into a flame of curiosity, it will make you light and eager, and give purpose to your questioning and direction to your skills.</p>\n</blockquote>\n<p>My recommendation? Practice the front-kick of epistemic rationality <em>every day</em>. For months. Train your ape-brain to <em>get curious</em>.</p>\n<p>Rationality is not magic. For many people, it can be <a href=\"/lw/76x/is_rationality_teachable/\">learned</a> and <a href=\"/lw/9hb/position_design_and_write_rationality_curriculum/\">trained</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"moeYqrcakMgXnQNyF": 1, "E6qP9r9xxM4LCxaFk": 1, "8uNFGxejo5hykCEez": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bGtdeqbgTzuLvZ5zn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 63, "baseScore": 69, "extendedScore": null, "score": 0.000156, "legacy": true, "legacyId": "13327", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 69, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p>Being levels above in [rationality] means doing rationalist practice 101 much better than others [just like] being a few levels above in fighting means executing a basic front-kick much better than others.</p>\n</blockquote>\n<p align=\"right\">- <a href=\"/lw/7dy/a_rationalists_tale/4t1r\">lessdazed</a></p>\n<blockquote>\n<p>I fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times.</p>\n</blockquote>\n<p align=\"right\">- Bruce Lee</p>\n<p>Recently, when Eliezer wanted to explain why he thought Anna Salamon was among the best rationalists he knew, he picked out one feature of Anna's behavior in particular:</p>\n<blockquote>\n<p>I see you start to answer a question, and then you stop, and I see you <em>get curious</em>.</p>\n</blockquote>\n<p>For me, the ability to reliably <em>get curious</em> is the basic front-kick of <a href=\"/lw/31/what_do_we_mean_by_rationality/\">epistemic rationality</a>. The best rationalists I know are not necessarily those who know the finer points of cognitive psychology, Bayesian statistics, and Solomonoff Induction. The best rationalists I know are those who can reliably <em>get curious</em>.</p>\n<p>Once, I explained the <a href=\"http://www.sjdm.org/testdmidi/Cognitive%20Reflection%20Test.html\">Cognitive Reflection Test</a> to <a href=\"http://www.rileycrane.com/\">Riley Crane</a> by saying it was made of questions that tempt your intuitions to quickly give a <em>wrong</em> answer. For example:</p>\n<blockquote>\n<p>A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?</p>\n</blockquote>\n<p>If you haven't seen this question before and you're like most people, your brain screams \"10 cents!\" But elementary algebra shows that can't be right. The correct answer is <em>5</em> cents. To get the right answer, I explained, you need to <em>interrupt</em> your intuitive judgment and think \"No! <em>Algebra</em>.\"</p>\n<p>A <em>lot</em> of rationalist practice is like that. Whether thinking about physics or sociology or relationships, you need to catch your intuitive judgment and think \"No! <em>Curiosity.</em>\"</p>\n<p>Most of us know how to do algebra. How does one \"do\" curiosity?</p>\n<p>Below, I propose a process for how to \"get curious.\" I think we are only <em>just beginning</em> to learn how to create curious people, so please don't take this method as Science or Gospel but instead as an attempt to <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just Try It</a>.</p>\n<p>As with <a href=\"/lw/9wr/my_algorithm_for_beating_procrastination/\">my algorithm for beating procrastination</a>, you'll want to practice each step of the process <em>in advance</em> so that when you want to get curious, you're well-practiced on each step already. With enough practice, these steps may even become <em>habits</em>.</p>\n<p><a id=\"more\"></a></p>\n<h3 id=\"Step_1__Feel_that_you_don_t_already_know_the_answer_\">Step 1: Feel that you don't already know the answer.</h3>\n<p>If you have beliefs about the matter already, push the \"reset\" button and erase that part of your map. You must <em>feel</em> that you don't already know the answer.</p>\n<p><strong id=\"Exercise_1_1__Import_the_feeling_of_uncertainty_\">Exercise 1.1: Import the feeling of uncertainty.</strong></p>\n<ol>\n<li>Think of a question you clearly <em>don't</em> know the answer to. When will AI be created? Is my current diet limiting my cognitive abilities? Is it harder to become the Prime Minister of Britain or the President of France?</li>\n<li>Close your eyes and pay attention to how that blank spot on your map <em>feels</em>. (To me, it feels like I can see a silhouette of someone in the darkness ahead, but I wouldn't take bets on who it is, and I expect to be surprised by their identity when I get close enough to see them.)</li>\n<li>Hang on to that feeling or image of uncertainty and think about the thing you're trying to get curious about. If your old certainty creeps back, switch to thinking about who composed the Voynich manuscript again, then import that feeling of uncertainty into the thing you're trying to get curious about, again.</li>\n</ol>\n<p><strong id=\"Exercise_1_2__Consider_all_the_things_you_ve_been_confident_but_wrong_about_\">Exercise 1.2: Consider all the things you've been confident but wrong about.</strong></p>\n<ol>\n<li>Think of things you once believed but were wrong about. The more similar those beliefs are to the beliefs you're now considering, the better.</li>\n<li>Meditate on the frequency of your errors, and on the depths of your biases (if you know enough cognitive psychology).</li>\n</ol>\n<h3 id=\"Step_2__Want_to_know_the_answer_\">Step 2: Want to know the answer.</h3>\n<p>Now, you must <em>want</em> to fill in this blank part of your map.</p>\n<p>You mustn't wish it to remain blank due to apathy or fear. Don't <em>avoid</em> getting the answer because you might learn you should eat less pizza and <a href=\"http://quantifiedself.com/2011/01/results-of-the-buttermind-experiment/\">more half-sticks of butter</a>. <a href=\"http://yudkowsky.net/rational/virtues\">Curiosity seeks to annihilate itself</a>.</p>\n<p>You also mustn't let your desire that your inquiry have a certain answer block you from discovering how the world actually is. You must want your map to resemble the territory, <em>whatever</em> the territory looks like. This enables you to change things more effectively than if you falsely believed that the world was already the way you want it to be.</p>\n<p><strong id=\"Exercise_2_1__Visualize_the_consequences_of_being_wrong_\">Exercise 2.1: Visualize the consequences of being wrong.</strong></p>\n<ol>\n<li>Generate hypotheses about the ways the world may be. Maybe you should eat less gluten and more vegetables? Maybe a high-protein diet plus some nootropics would boost your IQ 5 points? Maybe your diet is fairly optimal for cognitive function already?</li>\n<li>Next, visualize the consequences of being wrong, including the consequences of remaining ignorant. Visualize the consequences of performing 10 IQ points below your potential because you were too lazy to investigate, or because you were strongly motivated to justify your preference for a particular theory of nutrition. Visualize the consequences of screwing up your neurology by taking nootropics you feel excited about but that often cause harm to people with cognitive architectures similar to your own.</li>\n</ol>\n<p><strong id=\"Exercise_2_2__Make_plans_for_different_worlds_\">Exercise 2.2: Make plans for different worlds.</strong></p>\n<ol>\n<li>Generate hypotheses about the way the world could be \u2014 different worlds you might be living in. Maybe you live in a world where you'd improve your cognitive function by taking nootropics, or maybe you live in a world where the nootropics would harm you.</li>\n<li>Make plans for what you'll do if you happen to live in World #1, what you'll do if you happen to live in World #2, etc. (For unpleasant possible worlds, this also gives you an opportunity to <a href=\"/lw/o4/leave_a_line_of_retreat/\">leave a line of retreat</a> for yourself.)</li>\n<li>Notice that these plans are <em>different</em>. This should produce in you some curiosity about which world you <em>actually</em> live in, so that you can make plans appropriate for the world you <em>do</em> live in rather than for one of the worlds you <em>don't</em> live in.</li>\n</ol>\n<p><strong id=\"Exercise_2_3__Recite_the_Litany_of_Tarski_\">Exercise 2.3: Recite the Litany of Tarski.</strong></p>\n<p>The <a href=\"/lw/jz/the_meditation_on_curiosity/\">Litany of Tarski</a> can be adapted to any question. If you're considering whether the sky is blue, the Litany of Tarski is:</p>\n<blockquote>\n<p>If the sky is blue<br>I desire to believe the sky is blue.<br>If the sky is not blue,<br>I desire not to believe the sky is blue.</p>\n</blockquote>\n<p><strong id=\"Exercise_2_4__Recite_the_Litany_of_Gendlin_\">Exercise 2.4: Recite the Litany of Gendlin.</strong></p>\n<p>The <a href=\"/lw/id/you_can_face_reality/\">Litany of Gendlin</a> reminds us:</p>\n<blockquote>\n<p>What is true is already so.<br>Owning up to it doesn't make it worse.<br>Not being open about it<br>doesn't make it go away.<br>And because it's true,<br>it is what is there to be interacted with.<br>Anything untrue isn't there to be lived.<br>People can stand what is true,<br>for they are already enduring it.</p>\n</blockquote>\n<h3 id=\"Step_3__Sprint_headlong_into_reality_\">Step 3: Sprint headlong into reality.</h3>\n<p>If you've made yourself uncertain and then curious, you're now in a position to use argument, empiricism, and scholarship to sprint headlong into reality. This part probably requires some domain-relevant knowledge and an understanding of <a href=\"http://yudkowsky.net/rational/bayes\">probability theory</a> and <a href=\"/lw/85x/value_of_information_four_examples/\">value of information calculations</a>. What tests could answer your question quickly? How can you perform those tests? If the answer can be looked up in a book, which book?</p>\n<p>These are important questions, but I think the first two steps of getting curious are more important. If someone can master steps 1 and 2, they'll be so driven by curiosity that they'll eventually figure out how to do step 3 for many scenarios. In contrast, most people who are equipped to do step 3 pretty well still get the wrong answers because they can't reliably execute steps 1 and 2.</p>\n<h3 id=\"Conclusion__Curiosity_in_Action\">Conclusion: Curiosity in Action</h3>\n<p><a href=\"http://yudkowsky.net/rational/virtues\">A burning itch to know is higher than a solemn vow to pursue truth</a>. If you think it is your <em>duty</em> to doubt your own beliefs and criticize your own arguments, then you may do this for a while and conclude that you have done your duty and you're a Good Rationalist. Then you can feel satisfied and virtuous and move along without being <a href=\"/lw/96j/what_curiosity_looks_like/\">genuinely curious</a>.</p>\n<p><a href=\"/lw/jz/the_meditation_on_curiosity/\">In contrast</a>,</p>\n<blockquote>\n<p>if you can find within yourself the slightest shred of true uncertainty, then guard it like a forester nursing a campfire. If you can make it blaze up into a flame of curiosity, it will make you light and eager, and give purpose to your questioning and direction to your skills.</p>\n</blockquote>\n<p>My recommendation? Practice the front-kick of epistemic rationality <em>every day</em>. For months. Train your ape-brain to <em>get curious</em>.</p>\n<p>Rationality is not magic. For many people, it can be <a href=\"/lw/76x/is_rationality_teachable/\">learned</a> and <a href=\"/lw/9hb/position_design_and_write_rationality_curriculum/\">trained</a>.</p>", "sections": [{"title": "Step 1: Feel that you don't already know the answer.", "anchor": "Step_1__Feel_that_you_don_t_already_know_the_answer_", "level": 1}, {"title": "Exercise 1.1: Import the feeling of uncertainty.", "anchor": "Exercise_1_1__Import_the_feeling_of_uncertainty_", "level": 2}, {"title": "Exercise 1.2: Consider all the things you've been confident but wrong about.", "anchor": "Exercise_1_2__Consider_all_the_things_you_ve_been_confident_but_wrong_about_", "level": 2}, {"title": "Step 2: Want to know the answer.", "anchor": "Step_2__Want_to_know_the_answer_", "level": 1}, {"title": "Exercise 2.1: Visualize the consequences of being wrong.", "anchor": "Exercise_2_1__Visualize_the_consequences_of_being_wrong_", "level": 2}, {"title": "Exercise 2.2: Make plans for different worlds.", "anchor": "Exercise_2_2__Make_plans_for_different_worlds_", "level": 2}, {"title": "Exercise 2.3: Recite the Litany of Tarski.", "anchor": "Exercise_2_3__Recite_the_Litany_of_Tarski_", "level": 2}, {"title": "Exercise 2.4: Recite the Litany of Gendlin.", "anchor": "Exercise_2_4__Recite_the_Litany_of_Gendlin_", "level": 2}, {"title": "Step 3: Sprint headlong into reality.", "anchor": "Step_3__Sprint_headlong_into_reality_", "level": 1}, {"title": "Conclusion: Curiosity in Action", "anchor": "Conclusion__Curiosity_in_Action", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "100 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 100, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv", "hY86FhYysQ7dBg3d8", "Ty2tjPwv8uyPK9vrz", "3XgYbghWruBMrPTAL", "3nZMgRTfFEfHp34Gb", "HYWhKXRsMAyvRKRYz", "vADtvr9iDeYsCDfxd", "3oYaLja5h8qL5adDn", "H2zKAfiSJR6WJQ8pn", "ifL8f4Xzy2D9Bb6zs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-24T06:27:34.275Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Probability is in the Mind", "slug": "seq-rerun-probability-is-in-the-mind", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:14.247Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Tbw6FecEpMsij8KXj/seq-rerun-probability-is-in-the-mind", "pageUrlRelative": "/posts/Tbw6FecEpMsij8KXj/seq-rerun-probability-is-in-the-mind", "linkUrl": "https://www.lesswrong.com/posts/Tbw6FecEpMsij8KXj/seq-rerun-probability-is-in-the-mind", "postedAtFormatted": "Friday, February 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Probability%20is%20in%20the%20Mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Probability%20is%20in%20the%20Mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTbw6FecEpMsij8KXj%2Fseq-rerun-probability-is-in-the-mind%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Probability%20is%20in%20the%20Mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTbw6FecEpMsij8KXj%2Fseq-rerun-probability-is-in-the-mind", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTbw6FecEpMsij8KXj%2Fseq-rerun-probability-is-in-the-mind", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 171, "htmlBody": "<p>Today's post, <a href=\"/lw/oj/probability_is_in_the_mind/\">Probability is in the Mind</a> was originally published on 12 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Probabilities express uncertainty, and it is only agents who can be uncertain.  A blank map does not correspond to a blank territory.  Ignorance is in the mind.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/aas/seq_rerun_mind_projection_fallacy/\">Mind Projection Fallacy</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Tbw6FecEpMsij8KXj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 8.543071108269163e-07, "legacy": true, "legacyId": "13382", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["f6ZLxEWaankRZ2Crv", "naZQT9d2uKhsriCzr", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-24T14:44:02.960Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Melbourne, Atlanta, Austin, Berkeley, Cambridge UK, Ohio (general), Tucson", "slug": "weekly-lw-meetups-melbourne-atlanta-austin-berkeley", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4geoJK7G6mBm2pLRS/weekly-lw-meetups-melbourne-atlanta-austin-berkeley", "pageUrlRelative": "/posts/4geoJK7G6mBm2pLRS/weekly-lw-meetups-melbourne-atlanta-austin-berkeley", "linkUrl": "https://www.lesswrong.com/posts/4geoJK7G6mBm2pLRS/weekly-lw-meetups-melbourne-atlanta-austin-berkeley", "postedAtFormatted": "Friday, February 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Melbourne%2C%20Atlanta%2C%20Austin%2C%20Berkeley%2C%20Cambridge%20UK%2C%20Ohio%20(general)%2C%20Tucson&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Melbourne%2C%20Atlanta%2C%20Austin%2C%20Berkeley%2C%20Cambridge%20UK%2C%20Ohio%20(general)%2C%20Tucson%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4geoJK7G6mBm2pLRS%2Fweekly-lw-meetups-melbourne-atlanta-austin-berkeley%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Melbourne%2C%20Atlanta%2C%20Austin%2C%20Berkeley%2C%20Cambridge%20UK%2C%20Ohio%20(general)%2C%20Tucson%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4geoJK7G6mBm2pLRS%2Fweekly-lw-meetups-melbourne-atlanta-austin-berkeley", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4geoJK7G6mBm2pLRS%2Fweekly-lw-meetups-melbourne-atlanta-austin-berkeley", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 463, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/6p\">Salt Lake City Meetup #3 - Bayesian reasoning in everyday life:&nbsp;<span class=\"date\">18 February 2012 03:00PM</span></a></li>\n<li><a href=\"/meetups/75\">Atlanta:&nbsp;<span class=\"date\">18 February 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/69\">Ongoing Ohio Meetup:&nbsp;<span class=\"date\">19 February 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/6z\">Tucson Meetup:&nbsp;<span class=\"date\">24 February 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/7a\">Buenos Aires meetup: Saturday, February 25th, 4pm:&nbsp;<span class=\"date\">25 February 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/79\">Chicago Meetup at the University of Chicago:&nbsp;<span class=\"date\">25 February 2012 01:00PM</span></a></li>\n<li><a href=\"/meetups/6v\">Twin Cities South Metro:&nbsp;<span class=\"date\">06 March 2012 08:00PM</span></a></li>\n<li><a href=\"/meetups/6k\">[Ohio/Washington DC] Interest in Reason Rally meetup?:&nbsp;<span class=\"date\">24 March 2012 04:14PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/6u\">Melbourne social meetup:&nbsp;<span class=\"date\">17 February 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/78\">Austin, TX TCDS Experiment:&nbsp;<span class=\"date\">18 February 2012 01:30PM</span></a></li>\n<li><a href=\"/meetups/74\">Monthly Bay Area meetup: Berkeley:&nbsp;<span class=\"date\">18 February 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/73\">Cambridge UK:&nbsp;<span class=\"date\">19 February 2012 11:00AM</span></a></li>\n<li><a href=\"/meetups/71\">Cambridge UK:&nbsp;<span class=\"date\">26 February 2012 11:00AM</span></a></li>\n<li><a href=\"/meetups/7b\">Melbourne practical rationality meetup:&nbsp;<span class=\"date\">02 March 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/72\">Cambridge UK:&nbsp;<span class=\"date\">04 March 2012 11:00AM</span></a></li>\n</ul>\n<p>Also, the Salt Lake City group now has a <a href=\"http://sites.google.com/site/lesswrongsaltlakecity/\">website</a>!</p>\n<ul>\n</ul>\n<p>Cities with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a></strong><strong>.</strong></p>\n<p>If your meetup has a mailing list that you'd like mentioned here or has become regular and isn't listed as such, let me know!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4geoJK7G6mBm2pLRS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.545045373518246e-07, "legacy": true, "legacyId": "13180", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-24T16:25:08.983Z", "modifiedAt": null, "url": null, "title": "Meetup : S\u00e3o Paulo Meetup", "slug": "meetup-sao-paulo-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:22.846Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gust", "createdAt": "2011-11-24T19:56:58.641Z", "isAdmin": false, "displayName": "Gust"}, "userId": "Hpxx5CjyqzbCMFXNz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vgrouEE9PFwF9Typy/meetup-sao-paulo-meetup", "pageUrlRelative": "/posts/vgrouEE9PFwF9Typy/meetup-sao-paulo-meetup", "linkUrl": "https://www.lesswrong.com/posts/vgrouEE9PFwF9Typy/meetup-sao-paulo-meetup", "postedAtFormatted": "Friday, February 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20S%C3%A3o%20Paulo%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20S%C3%A3o%20Paulo%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgrouEE9PFwF9Typy%2Fmeetup-sao-paulo-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20S%C3%A3o%20Paulo%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgrouEE9PFwF9Typy%2Fmeetup-sao-paulo-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgrouEE9PFwF9Typy%2Fmeetup-sao-paulo-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 129, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7f'>S\u00e3o Paulo Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">14 March 2012 07:00:00PM (-0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1034 Alameda Santos, S\u00e3o Paulo, Brasil</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I have no idea whether there are people in the area, but I guess it's worth a shot. In this first meetup I hope we can get know each other and plan the next ones.</p>\n\n<p>I'm still thinking about a good place to do this, please offer any ideas you have. Somewhere near a Metro station would be great (maybe near Avenida Paulista?).</p>\n\n<p>If you think another date and/or time would be better, say it in a comment. And PLEASE comment here if you live nearby, even if you can't show up!</p>\n\n<p>EDIT: Meeting point: the Starbucks at Alameda Santos with Alameda Campinas.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7f'>S\u00e3o Paulo Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vgrouEE9PFwF9Typy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7e-06, "legacy": true, "legacyId": "13395", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___S_o_Paulo_Meetup\">Discussion article for the meetup : <a href=\"/meetups/7f\">S\u00e3o Paulo Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">14 March 2012 07:00:00PM (-0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1034 Alameda Santos, S\u00e3o Paulo, Brasil</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I have no idea whether there are people in the area, but I guess it's worth a shot. In this first meetup I hope we can get know each other and plan the next ones.</p>\n\n<p>I'm still thinking about a good place to do this, please offer any ideas you have. Somewhere near a Metro station would be great (maybe near Avenida Paulista?).</p>\n\n<p>If you think another date and/or time would be better, say it in a comment. And PLEASE comment here if you live nearby, even if you can't show up!</p>\n\n<p>EDIT: Meeting point: the Starbucks at Alameda Santos with Alameda Campinas.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___S_o_Paulo_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/7f\">S\u00e3o Paulo Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : S\u00e3o Paulo Meetup", "anchor": "Discussion_article_for_the_meetup___S_o_Paulo_Meetup", "level": 1}, {"title": "Discussion article for the meetup : S\u00e3o Paulo Meetup", "anchor": "Discussion_article_for_the_meetup___S_o_Paulo_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "23 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-24T21:05:25.515Z", "modifiedAt": null, "url": null, "title": "Online education and Conscientiousness", "slug": "online-education-and-conscientiousness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:24.178Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/t8ZNjMSGjPcKqASkE/online-education-and-conscientiousness", "pageUrlRelative": "/posts/t8ZNjMSGjPcKqASkE/online-education-and-conscientiousness", "linkUrl": "https://www.lesswrong.com/posts/t8ZNjMSGjPcKqASkE/online-education-and-conscientiousness", "postedAtFormatted": "Friday, February 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Online%20education%20and%20Conscientiousness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOnline%20education%20and%20Conscientiousness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft8ZNjMSGjPcKqASkE%2Fonline-education-and-conscientiousness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Online%20education%20and%20Conscientiousness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft8ZNjMSGjPcKqASkE%2Fonline-education-and-conscientiousness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft8ZNjMSGjPcKqASkE%2Fonline-education-and-conscientiousness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p>I've wondered for some time now what the effects of online education might be on gender and income inequality, specifically as online education interacts with IQ and Conscientiousness (compared with offline education). I ran into a study of a course done online and offline that found correlations with Conscientiousness, which prompted me to start writing out my thoughts: https://plus.google.com/103530621949492999968/posts/aKa3qLatwZ3</p>\n<p>The model/argument I give (towards the bottom) is logically trivial, and the basic idea seems pretty intuitive - offline classrooms remove some need for self-discipline/Conscientiousness and performance is more g-loaded - that I'm sure I can't be the first person to think of it.</p>\n<p>Does anyone have statistics or citations handy which might help in any essay I write on the topic?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "t8ZNjMSGjPcKqASkE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 21, "extendedScore": null, "score": 8.546562479371387e-07, "legacy": true, "legacyId": "13396", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-24T23:54:22.475Z", "modifiedAt": null, "url": null, "title": "[Link] Bayesian Overconfidence", "slug": "link-bayesian-overconfidence", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "beoShaffer", "createdAt": "2011-05-29T15:52:29.240Z", "isAdmin": false, "displayName": "beoShaffer"}, "userId": "589WwYp3jytZqATFL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XyWDvMJpvX5midkMA/link-bayesian-overconfidence", "pageUrlRelative": "/posts/XyWDvMJpvX5midkMA/link-bayesian-overconfidence", "linkUrl": "https://www.lesswrong.com/posts/XyWDvMJpvX5midkMA/link-bayesian-overconfidence", "postedAtFormatted": "Friday, February 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Bayesian%20Overconfidence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Bayesian%20Overconfidence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXyWDvMJpvX5midkMA%2Flink-bayesian-overconfidence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Bayesian%20Overconfidence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXyWDvMJpvX5midkMA%2Flink-bayesian-overconfidence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXyWDvMJpvX5midkMA%2Flink-bayesian-overconfidence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>I just ran across an interesting working paper by P.J. Healy and D.A. Moore, providing a potenial explanation for several forms of overconfidence.</p>\n<p>The abstract:</p>\n<blockquote>\n<p>We study three distinct measures of overconfidence: (1) overestimation of one&rsquo;s performance, (2) overplacement of one&rsquo;s performance relative to others, and (3) overprecision in one&rsquo;s belief about private signals. A new set of exper- iments verifies a strong negative link between overestimation and overprecision that depends crucially on task difficulty (the &lsquo;hard-easy&rsquo; effect). We present a simple Bayesian model in which agents are uncertain about the underlying task difficulty. This model correctly predicts the observed regularities. Thus, we capture several observed patterns of overconfidence without assuming any implicit behavioral biases.</p>\n</blockquote>\n<p><br />Available Here: <a href=\"http://repository.cmu.edu/cgi/viewcontent.cgi?article=1337&amp;context=tepper\">http://repository.cmu.edu/cgi/viewcontent.cgi?article=1337&amp;context=tepper</a></p>\n<p>Intuitively it still seems like a perfectly rational agent should be able to factor in the fact the given method will make them overconfident. That said I didn't work through all the math so it's possible I'm missing something, probably something related to <a href=\"/lw/hb/useful_statistical_biases/\">bias-varaince trade offs</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XyWDvMJpvX5midkMA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 8.547234708660047e-07, "legacy": true, "legacyId": "13398", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Wwq6WFpx9HyzwgCKx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-25T04:44:35.793Z", "modifiedAt": null, "url": null, "title": "The Singularity Institute is hiring virtual assistants (work from home, from anywhere)", "slug": "the-singularity-institute-is-hiring-virtual-assistants-work", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:05.252Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xf5AKAbz44oQtdgiH/the-singularity-institute-is-hiring-virtual-assistants-work", "pageUrlRelative": "/posts/Xf5AKAbz44oQtdgiH/the-singularity-institute-is-hiring-virtual-assistants-work", "linkUrl": "https://www.lesswrong.com/posts/Xf5AKAbz44oQtdgiH/the-singularity-institute-is-hiring-virtual-assistants-work", "postedAtFormatted": "Saturday, February 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Singularity%20Institute%20is%20hiring%20virtual%20assistants%20(work%20from%20home%2C%20from%20anywhere)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Singularity%20Institute%20is%20hiring%20virtual%20assistants%20(work%20from%20home%2C%20from%20anywhere)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXf5AKAbz44oQtdgiH%2Fthe-singularity-institute-is-hiring-virtual-assistants-work%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Singularity%20Institute%20is%20hiring%20virtual%20assistants%20(work%20from%20home%2C%20from%20anywhere)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXf5AKAbz44oQtdgiH%2Fthe-singularity-institute-is-hiring-virtual-assistants-work", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXf5AKAbz44oQtdgiH%2Fthe-singularity-institute-is-hiring-virtual-assistants-work", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 224, "htmlBody": "<p>\n<p>The Singularity Institute is hiring 1-3 <a href=\"http://en.wikipedia.org/wiki/Virtual_assistant\">virtual assistants</a>. (That is, personal assistants that work from home, anywhere with internet access.)</p>\n<p>&nbsp;</p>\n<p>Benefits:</p>\n<p>\n<ul>\n<li>Work directly with some of the central figures of Less Wrong, especially Luke(prog) and Anna Salamon.</li>\n<li>Work from home most of the time.</li>\n<li>Trial period of part-time work at $13/hr; if all goes well then get hired as a contractor for full-time work or more (if you're available) at $15/hr.</li>\n</ul>\n</p>\n<p>Qualifications:</p>\n<p>\n<ul>\n<li>Capable of self-management and figuring things out. An example instruction is \"Find me three ghost writers who have previously published best-selling science books and figure out how much they cost.\" We don't have time to figure out <em>how</em>&nbsp;one goes about doing that, so we need our virtual assistants to be able to do research (by internet and phone) to figure out how to do that.</li>\n<li>Be<em>&nbsp;</em>generally on-board with&nbsp;with rationality and existential risk mitigation. (This makes communication and goal coordination easier.)</li>\n<li>Be clear and professional in emails and (much less often) on the phone.</li>\n</ul>\n</p>\n<p>&nbsp;</p>\n<p>How to apply:</p>\n<p>Send an email to jobs@intelligence.org with the subject line \"Virtual Assistant Position.\" Attach your r&eacute;sum&eacute; if you have one, or at least describe why you think you'd be good at this job. Also list other skills and experience you have, even if you're not sure they'd be relevant.</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xf5AKAbz44oQtdgiH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 8.548389683204198e-07, "legacy": true, "legacyId": "13416", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-25T07:18:51.269Z", "modifiedAt": null, "url": null, "title": "[call-to-arms] Computer-based Math Education", "slug": "call-to-arms-computer-based-math-education", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.687Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Anubhav", "createdAt": "2012-01-05T10:50:52.734Z", "isAdmin": false, "displayName": "Anubhav"}, "userId": "pe9DTYwyvLCZPzsPf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LAuciSvN9w2A4Ckvo/call-to-arms-computer-based-math-education", "pageUrlRelative": "/posts/LAuciSvN9w2A4Ckvo/call-to-arms-computer-based-math-education", "linkUrl": "https://www.lesswrong.com/posts/LAuciSvN9w2A4Ckvo/call-to-arms-computer-based-math-education", "postedAtFormatted": "Saturday, February 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Bcall-to-arms%5D%20Computer-based%20Math%20Education&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Bcall-to-arms%5D%20Computer-based%20Math%20Education%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLAuciSvN9w2A4Ckvo%2Fcall-to-arms-computer-based-math-education%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Bcall-to-arms%5D%20Computer-based%20Math%20Education%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLAuciSvN9w2A4Ckvo%2Fcall-to-arms-computer-based-math-education", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLAuciSvN9w2A4Ckvo%2Fcall-to-arms-computer-based-math-education", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 413, "htmlBody": "<p><em>TL;DR= There doesn't exist a course/curriculum/general textbook based on Conrad Wolfram's \"<a href=\"http://computerbasedmath.org/\">Computer-Based Math Education</a>\" idea. Let's create an open-content one! .... if we can</em></p>\n<p>By computer-based math, I <em><strong>don't </strong></em>mean \"math as usual, now taught through a computer!\" (a la <a href=\"http://www.khanacademy.org/\">Khan Academy</a>) I mean \"math where we let computers do the calculation drudge-work, while we do the interesting parts.\"</p>\n<p>Or, paraphrasing <a href=\"http://en.wikipedia.org/wiki/Conrad_Wolfram\">Conrad Wolfram</a>: \"stop teaching kids how to take derivatives; that's what Mathematica<sup>TM</sup>&nbsp;is for. Just teach them what a derivative is, so we can move on to more interesting problems. Like, you know, the ones in the real world.\"&nbsp;(<a href=\"http://computerbasedmath.org/resources/reforming-math-curriculum-with-computers.html\">Here</a>'s Wolfram's original polemic about the issue.)&nbsp;</p>\n<p>Obviously, this is controversial, and Wolfram spends most of his talk rebutting arguments against it. If, after reading them, you're still not convinced that this is a good idea, then <strong>start another thread</strong>&nbsp;to discuss it. I don't intend this thread to become a blues-vs-greens battleground. Seriously, just start another thread.</p>\n<p>On the other hand, if you <em>are </em>convinced that Wolfram is on to something...&nbsp;</p>\n<p>My problem with this whole venture is that it's too important (IMO) to be left to the Wolframs.&nbsp;</p>\n<p>I mean, come on. Wolfram's basic thesis might be true, but it's no coincidence that this particular truth is being spouted by the brother of the guy who created&nbsp;<a href=\"http://en.wikipedia.org/wiki/Mathematica\">Mathematica</a>.</p>\n<p>And, unfortunately, the Wolframs seem to be the only ones pushing for it. Which means that we won't get any \"math, not computation!\" courses/textbooks until they can find a taker.&nbsp;</p>\n<p>Now I'm guessing that most LWers would want to reap the benefits of Wolfram's basic idea without having to pay his family a fortune for it, and before however long it takes them to convince an education board about it. (How many \"How do I go about learning useful math?\" threads have we had so far?)&nbsp;</p>\n<p>So why don't we give the world a leg-up on the path to the widespread mathematical literacy that Wolfram promises? Why don't <em>we</em> put out a computer-based math course for the world?</p>\n<p>Obviously, we'd have to use free stuff... <a href=\"http://www.sagemath.org/\">Sage</a> instead of Mathematica, for instance. And whatever we put out would have to be free, because... well, if you could write textbooks that people are likely to pay for, you wouldn't need to be part of an LW community venture to do it.&nbsp;</p>\n<p>My major questions, therefore, are:</p>\n<p>Are there enough (a) mathematically literate LWers with (b) tons of free time who (c) think computer-based math education is a good cause and (d) are willing to work for free toward a good cause?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LAuciSvN9w2A4Ckvo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -4, "extendedScore": null, "score": 8.549003685017571e-07, "legacy": true, "legacyId": "13419", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-25T09:13:34.617Z", "modifiedAt": null, "url": null, "title": "Acausal romance", "slug": "acausal-romance", "viewCount": null, "lastCommentedAt": "2021-03-24T02:41:26.058Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SsaT4b6Kn4yqeSpRd/acausal-romance", "pageUrlRelative": "/posts/SsaT4b6Kn4yqeSpRd/acausal-romance", "linkUrl": "https://www.lesswrong.com/posts/SsaT4b6Kn4yqeSpRd/acausal-romance", "postedAtFormatted": "Saturday, February 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Acausal%20romance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAcausal%20romance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSsaT4b6Kn4yqeSpRd%2Facausal-romance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Acausal%20romance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSsaT4b6Kn4yqeSpRd%2Facausal-romance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSsaT4b6Kn4yqeSpRd%2Facausal-romance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<p>I just realized I haven't previously pointed the metaphysicians on Less Wrong to \"<a href=\"https://sites.google.com/site/neiladri/Home/Sinhababu-PossibleGirls.pdf?attredirects=0&amp;d=1\">Possible Girls</a>,\" a hilarious paper about acausal romance:</p>\n<blockquote>\n<p>The ability to causally interact with your partner is important to many aspects of happy&nbsp;romantic relationships, but not to all of them. It&rsquo;s quite pleasant simply to know that your&nbsp;partner loves you and appreciates being loved by you. A loving relationship with a faraway&nbsp;person can enhance one&rsquo;s self-esteem and turn loneliness into contentment. As a lonely&nbsp;philosopher, I&rsquo;ve come to wonder: If [all possible worlds exist], can I have a loving relationship with&nbsp;someone from another possible world?&nbsp;...The answer, I think, is yes.</p>\n</blockquote>\n<p class=\"p1\">Even if you don't read the whole thing, don't miss the final paragraph.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 1, "3uE2pXvbcnS9nnZRE": 1, "tgJoX7PGDDh2vJNqT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SsaT4b6Kn4yqeSpRd", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 37, "extendedScore": null, "score": 7.5e-05, "legacy": true, "legacyId": "13426", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 37, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2012-02-25T09:13:34.617Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-25T18:15:35.236Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta", "slug": "meetup-atlanta", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hankx7787", "createdAt": "2011-07-10T22:12:52.395Z", "isAdmin": false, "displayName": "hankx7787"}, "userId": "B4SKuX6dAQMnNqHzH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3f4hxHg9tNPZcfecD/meetup-atlanta", "pageUrlRelative": "/posts/3f4hxHg9tNPZcfecD/meetup-atlanta", "linkUrl": "https://www.lesswrong.com/posts/3f4hxHg9tNPZcfecD/meetup-atlanta", "postedAtFormatted": "Saturday, February 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3f4hxHg9tNPZcfecD%2Fmeetup-atlanta%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3f4hxHg9tNPZcfecD%2Fmeetup-atlanta", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3f4hxHg9tNPZcfecD%2Fmeetup-atlanta", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 142, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/7g\">Atlanta</a></h2>\n<div class=\"meetup-meta\">\n<p>&nbsp;</p>\n<div class=\"meetup-meta\" style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px;\"><strong style=\"text-transform: uppercase;\">WHEN:</strong>&nbsp;<span class=\"date\">17 March 2012 06:30:00PM (-0500)</span></p>\n<p style=\"margin: 0px;\"><strong style=\"text-transform: uppercase;\">WHERE:</strong>&nbsp;<span class=\"address\">2094 North Decatur Road, Decatur, GA 30033-5367</span></p>\n</div>\n<div class=\"content\" style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<div class=\"md\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"background-color: rgba(255, 255, 255, 0.917969); color: #222222; font-family: arial, sans-serif; font-size: 13px;\">The next meetup will be Saturday, March 17th at 6:30pm at&nbsp;Chocolate Coffee in Decatur:</span></p>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\"><br /></div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">\n<div><a style=\"color: #0000cc;\" href=\"http://www.mychocolatecoffee.com/\" target=\"_blank\">http://www.mychocolatecoffee.com/</a></div>\n<div>2094 North Decatur Road, Decatur, GA 30033-5367</div>\n<div><a style=\"color: #0000cc;\" href=\"/tel:%28404%29%20982-0790\" target=\"_blank\">(404) 982-0790</a>&nbsp;</div>\n<div><br /></div>\n</div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">We will be finishing up the \"Mysterious Answers to Mysterious Questions\" sequence at the next meeting. As always, any other topics you want to bring up are fair game!</div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">Here is the official agenda of our next meeting:</div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\"><a style=\"color: #1155cc;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\" target=\"_blank\">http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions</a></div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">\n<ul style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; list-style-type: none; text-align: left; background-color: #f9f9f9; line-height: 18px; font-size: 12px; font-family: Arial, Helvetica, sans-serif; padding: 0px;\">\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"> \n<ul style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; list-style-type: none; padding: 0px;\">\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#.22Science.22_as_Curiosity-Stopper\" target=\"_blank\">1.26&nbsp;\"Science\" as Curiosity-Stopper</a></li>\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#Applause_Lights\" target=\"_blank\">1.27&nbsp;Applause Lights</a></li>\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#Truly_Part_of_You\" target=\"_blank\">1.28&nbsp;Truly Part of You</a></li>\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#Chaotic_Inversion\" target=\"_blank\">1.29&nbsp;Chaotic Inversion</a></li>\n</ul>\n</li>\n</ul>\n<div style=\"text-align: left;\"><br /></div>\n<div style=\"text-align: left;\"><br /></div>\n<div style=\"text-align: left;\"><span style=\"font-size: 12px; line-height: 18px; font-family: Arial, Helvetica, sans-serif;\">Please let me know if you have any questions or comments! I look forward to seeing everyone there!</span></div>\n<div style=\"text-align: left;\">ps. join the mailing list!&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://groups.google.com/group/atlanta-less-wrong-meetup-group\">http://groups.google.com/group/atlanta-less-wrong-meetup-group</a></div>\n</div>\n</div>\n</div>\n<p>&nbsp;</p>\n</div>\n<div class=\"content\">\n<div class=\"md\">\n<p>&nbsp;</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/7g\">Atlanta</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3f4hxHg9tNPZcfecD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 8.551618592892412e-07, "legacy": true, "legacyId": "13427", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta\">Discussion article for the meetup : <a href=\"/meetups/7g\">Atlanta</a></h2>\n<div class=\"meetup-meta\">\n<p>&nbsp;</p>\n<div class=\"meetup-meta\" style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px;\"><strong style=\"text-transform: uppercase;\">WHEN:</strong>&nbsp;<span class=\"date\">17 March 2012 06:30:00PM (-0500)</span></p>\n<p style=\"margin: 0px;\"><strong style=\"text-transform: uppercase;\">WHERE:</strong>&nbsp;<span class=\"address\">2094 North Decatur Road, Decatur, GA 30033-5367</span></p>\n</div>\n<div class=\"content\" style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<div class=\"md\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"background-color: rgba(255, 255, 255, 0.917969); color: #222222; font-family: arial, sans-serif; font-size: 13px;\">The next meetup will be Saturday, March 17th at 6:30pm at&nbsp;Chocolate Coffee in Decatur:</span></p>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\"><br></div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">\n<div><a style=\"color: #0000cc;\" href=\"http://www.mychocolatecoffee.com/\" target=\"_blank\">http://www.mychocolatecoffee.com/</a></div>\n<div>2094 North Decatur Road, Decatur, GA 30033-5367</div>\n<div><a style=\"color: #0000cc;\" href=\"/tel:%28404%29%20982-0790\" target=\"_blank\">(404) 982-0790</a>&nbsp;</div>\n<div><br></div>\n</div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">We will be finishing up the \"Mysterious Answers to Mysterious Questions\" sequence at the next meeting. As always, any other topics you want to bring up are fair game!</div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">Here is the official agenda of our next meeting:</div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\"><a style=\"color: #1155cc;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\" target=\"_blank\">http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions</a></div>\n<div style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; background-color: rgba(255, 255, 255, 0.917969);\">\n<ul style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; list-style-type: none; text-align: left; background-color: #f9f9f9; line-height: 18px; font-size: 12px; font-family: Arial, Helvetica, sans-serif; padding: 0px;\">\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"> \n<ul style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; list-style-type: none; padding: 0px;\">\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#.22Science.22_as_Curiosity-Stopper\" target=\"_blank\">1.26&nbsp;\"Science\" as Curiosity-Stopper</a></li>\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#Applause_Lights\" target=\"_blank\">1.27&nbsp;Applause Lights</a></li>\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#Truly_Part_of_You\" target=\"_blank\">1.28&nbsp;Truly Part of You</a></li>\n<li style=\"margin-left: 15px; margin-bottom: 0.1em;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions#Chaotic_Inversion\" target=\"_blank\">1.29&nbsp;Chaotic Inversion</a></li>\n</ul>\n</li>\n</ul>\n<div style=\"text-align: left;\"><br></div>\n<div style=\"text-align: left;\"><br></div>\n<div style=\"text-align: left;\"><span style=\"font-size: 12px; line-height: 18px; font-family: Arial, Helvetica, sans-serif;\">Please let me know if you have any questions or comments! I look forward to seeing everyone there!</span></div>\n<div style=\"text-align: left;\">ps. join the mailing list!&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://groups.google.com/group/atlanta-less-wrong-meetup-group\">http://groups.google.com/group/atlanta-less-wrong-meetup-group</a></div>\n</div>\n</div>\n</div>\n<p>&nbsp;</p>\n</div>\n<div class=\"content\">\n<div class=\"md\">\n<p>&nbsp;</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Atlanta1\">Discussion article for the meetup : <a href=\"/meetups/7g\">Atlanta</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta", "anchor": "Discussion_article_for_the_meetup___Atlanta", "level": 1}, {"title": "Discussion article for the meetup : Atlanta", "anchor": "Discussion_article_for_the_meetup___Atlanta1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-25T18:34:47.389Z", "modifiedAt": null, "url": null, "title": "Giving What We Can and 80,000 Hours are recruiting!", "slug": "giving-what-we-can-and-80-000-hours-are-recruiting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.677Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nANpCXBib7SwdLBu8/giving-what-we-can-and-80-000-hours-are-recruiting", "pageUrlRelative": "/posts/nANpCXBib7SwdLBu8/giving-what-we-can-and-80-000-hours-are-recruiting", "linkUrl": "https://www.lesswrong.com/posts/nANpCXBib7SwdLBu8/giving-what-we-can-and-80-000-hours-are-recruiting", "postedAtFormatted": "Saturday, February 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Giving%20What%20We%20Can%20and%2080%2C000%20Hours%20are%20recruiting!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGiving%20What%20We%20Can%20and%2080%2C000%20Hours%20are%20recruiting!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnANpCXBib7SwdLBu8%2Fgiving-what-we-can-and-80-000-hours-are-recruiting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Giving%20What%20We%20Can%20and%2080%2C000%20Hours%20are%20recruiting!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnANpCXBib7SwdLBu8%2Fgiving-what-we-can-and-80-000-hours-are-recruiting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnANpCXBib7SwdLBu8%2Fgiving-what-we-can-and-80-000-hours-are-recruiting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 712, "htmlBody": "<p>Below is a message from my friends at Giving What We Can and 80,000 Hours, two key organizations in the&nbsp;<a href=\"/lw/3gj/efficient_charity_do_unto_others/\">efficient charity</a> or \"<a href=\"/lw/6py/optimal_philanthropy_for_human_beings/\">optimal philanthropy</a>\" movement.</p>\n<p>&nbsp;</p>\n<blockquote>\n<p><a href=\"http://www.givingwhatwecan.org/\">Giving What We Can</a> and <a href=\"http://80000hours.org/\">80,000 Hours</a> are both taking paid staff from next year. So if you would be interested in working part or full-time next year for either of these two organisations, then please send an e-mail to niel.bowerman@givingwhatwecan.org by the 2nd March, 5pm GMT, with a short description telling us a little bit about yourself. We can then send you further information on how to apply, and on what working with us would involve.</p>\n<p>Areas in which we are particularly interested in hiring are:</p>\n<p>&nbsp;</p>\n<p><em>Strategic Research</em>. &nbsp;Both organisations are highly concerned to know whether their method is the optimal way to make the world a better place; and, if it isn&rsquo;t, how we can improve it. &nbsp;We&rsquo;re looking to hire staff to help us to answer that question. &nbsp;</p>\n<p>If you have strong research skills, have performed well academically, and are sympathetic to the GWWC or 80k way of thinking, then you would fit well into this role. Relevant background subjects include but are not limited to: philosophy, mathematics, economics and the other sciences.</p>\n<p>&nbsp;</p>\n<p><em>Operations and management</em>. In order for the organisations to remain secure and successful, we would need strong support on an operational level.</p>\n<p>If you have an eye for detail, and especially if you have previous experience working within operations or management, then you could flourish in this role.</p>\n<p>&nbsp;</p>\n<p><em>Volunteer Recruitment</em>. Both organisations are largely run by volunteers, and are looking to expand significantly next year. We&rsquo;re especially looking to recruit highly dedicated volunteers who are willing to work 10hrs/week or more.</p>\n<p>If you are people-minded, or have experience with volunteer-run organisations previously, then this could be the role for you.</p>\n<p>&nbsp;</p>\n<p>Potential employment is not limited to these roles, however, and there would be considerable room for any employee to partially write their own role. &nbsp;What we are principally looking for are dedicated people who understand and support the GWWC or 80k approach to making the world a better place.</p>\n<p>For those who haven't heard of the organisations before, here is a short description:</p>\n<p>Giving What We Can is concerned with two primary activities: encouraging people to give more and to give more effectively to causes that fight poverty in the developing world. &nbsp;Every member of the organisation pledges to give at least 10% of their income to the charities that best fight extreme poverty. &nbsp;Giving What We Can also does in-depth charity evaluation, and advocates that people give more to the most cost-effective charities. &nbsp;We've so far raised over $1.5 million to the expectedly best development charities, with over $40,000,000 pledged.</p>\n<p>80,000 Hours encourages people to pursue a high-impact ethical career: a career that enables them to do as much to make the world a better place as possible. &nbsp;The careers it highlights are professional philanthropy &ndash; pursuing a lucrative career in order to donate a substantial proportion of one&rsquo;s earnings to the best causes &ndash; and careers in certain research areas or careers through which one can have a large influence over others. &nbsp;It now has 74 members, and has also received major media coverage.&nbsp;</p>\n<p>A major aim of both organisations is to build the movement of effective altruists: people who take a rational approach to making the world as good a place as possible, and are willing to put that idea into practice. &nbsp;Between the two organisations, the ultimate cause is not limited to global poverty alleviation. For example, we are doing research into optimal x-risk mitigation strategy, and cost-effectiveness evaluation of x-risk mitigation organisations.</p>\n<p>If you were to work for either organisation, you would have considerable flexibility in your work, as part of a young and fast-growing charity. &nbsp;You&rsquo;d be working in the company of other highly intelligent and enthusiastic staff, among a community of people doing their best to make a huge positive impact on the world. &nbsp;It&rsquo;s an exciting opportunity!</p>\n<p>So, even if you&rsquo;re not sure, but you&rsquo;re interested in finding out more, please register your interest by e-mailing niel.bowerman@givingwhatwecan.org.</p>\n<p>Thanks for your interest,</p>\n<p>The GWWC and 80K Teams</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"se3XDuQ4xbeWvu4eF": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nANpCXBib7SwdLBu8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 20, "extendedScore": null, "score": 8.551695072781955e-07, "legacy": true, "legacyId": "13428", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pC47ZTsPNAkjavkXs", "hEqsWLm5zQtsPevd3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-25T21:53:46.378Z", "modifiedAt": null, "url": null, "title": "Utopia in Manna", "slug": "utopia-in-manna", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:38.491Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hETiHyeg7ux4RtpYz/utopia-in-manna", "pageUrlRelative": "/posts/hETiHyeg7ux4RtpYz/utopia-in-manna", "linkUrl": "https://www.lesswrong.com/posts/hETiHyeg7ux4RtpYz/utopia-in-manna", "postedAtFormatted": "Saturday, February 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Utopia%20in%20Manna&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUtopia%20in%20Manna%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhETiHyeg7ux4RtpYz%2Futopia-in-manna%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Utopia%20in%20Manna%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhETiHyeg7ux4RtpYz%2Futopia-in-manna", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhETiHyeg7ux4RtpYz%2Futopia-in-manna", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 825, "htmlBody": "<div id=\"body_t1_5np8\" class=\"comment-content \">\n<div class=\"md\">\n<p><strong><a rel=\"nofollow\" href=\"http://marshallbrain.com/manna1.htm\">Manna</a> is the title of a science fiction story that describes a near future transition to an automated society where humans are uneconomical. In the later chapters it describes in some detail a post-scarcity society. </strong>There are several problems with it however, the greatest by far is that the author seems to have assumed that \"want\" and \"envy\" are primarily tied in material needs. This is simply not true.</p>\n<p>I would love to live in a society with <em>material equality</em> on a sufficiently hight standard, I'd however hate to live in society with a enforced <em>social equality</em>, simply because that would override my preferences and freedom to interact or not interact with whomever I wish.</p>\n<p>Also since things like the willpower to work out (to stay in top athletic condition even!) or not having the resources to fulfil even basic plans are made irrelevant, things like genetic inequality or how comfortable you are messing with your own hardware to upgrade your capabilities or how much time you dedicate to self-improvement would be more important than ever.</p>\n<p>I predict <em>social inequality</em> would be pretty high in this society and <em>mostly involuntary</em>. Even a decision about something like the distribution of how much time you use for self-improvement, which you could presumably change later, there wouldn't be a good way to catch up with anyone (think opportunity cost and compound interest), unless technological progress would hit diminishing returns and slow down. Social inequality would however be more limited than pure financial inequality I would guess because of things like <a rel=\"nofollow\" href=\"http://en.wikipedia.org/wiki/Dunbar%27s_number\">Dunbar's number</a>. There would still be tragedy (that may be a feature rather than a bug of utopia). I guess people would be comfortable with gods above and beasts below them, that don't really figure in their \"my social status compared to others\" part of the brain, but even in the narrow band where you do care about inequality would grow rapidly. Eventually you might find yourself <em>alone</em> in your specific spot.</p>\n<p>To get back to my previous point about probable (to me) unacceptable limitations on freedom, It may seem silly that a society with material equality would legislate intrusive and micromanaging rules that would force social equality to prevent this, but the hunter gatherer instincts in us are strong. We demand equality. We enjoy bringing about \"equality\". <em>We look good demanding equality.</em> Once material needs are met, this powerful urge will still be there and bring about signalling races. And new and new ways to avoid the edicts produced by such races (because also strong in us is our desire to be personally unequal or superior to <em>someone</em>, to distinguish and discriminate in our personal lives). This would play out in interesting and potentially dystopia ways.</p>\n<p>I'm pretty sure the vast majority of people in the Australia project would probably end up <a href=\"http://wiki.lesswrong.com/wiki/Wireheading\">wireheading</a>. Why bother to go to the Moon when you can have a perfect virtual reality replica of it, why bother with the status of building a real fusion reactor when you can just play a gameified simplified version and simulate the same social reward, why bother with a real relationship ect... dedicating resoruces for something like a real life space elevator simply wouldn't cross their minds. People I think systematically overestimate how much something being \"real\" matters to them. Better and better also means better and better virtual super-stimuli. Among the tiny remaining faction of remaining \"peas\" (those choosing to spend most of their time in physical existence), there would be very few that would choose to have children, but they would dominate the future. Also I see no reason why the US couldn't buy technology from the Australia Project to use for its own welfare dependant citizens. Instead of the cheap mega-shelters, just hook them up on virtual reality, with no choice in the matter. Which would make a tiny fraction of them deeply unhappy (if they knew about it).</p>\n<p>I maintain that the human brains default response to unlimited control of its own sensor input and reasonable security of continued existence is solipsism. And the default of a society of human brains with such technology is first social fragmentation, then value fragmentation and eventually a return to living under the yoke of an essentially Darwinian processes. Speaking of which the society of the US as described in the story would probably outpace Australia since it would have machines do its research and development.</p>\n<p>It would take some time for the value this creates to run out though, much like Robin Hanson finds a future with a d<a href=\"http://www.overcomingbias.com/2009/09/this-is-the-dream-time.html\">ream tim</a>e of utopia followed by trillions of slaves <a href=\"http://www.overcomingbias.com/2011/01/lift-up-your-eyes.html\">glorious</a> , I still find a few subjective millennia of a golden age followed by non-human and inhuman minds to be worth it.</p>\n<p>It is not like we have to choose between infinity and something finite, the universe seems to have an expiration date as it is. A few thousand or million years doesn't seem like something fleas on a insignificant speck should sneer at.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hETiHyeg7ux4RtpYz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 10, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "13430", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-26T14:34:58.457Z", "modifiedAt": null, "url": null, "title": "[Link]: 80,000 hours blog", "slug": "link-80-000-hours-blog", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.511Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Larks", "createdAt": "2009-04-28T20:21:45.860Z", "isAdmin": false, "displayName": "Larks"}, "userId": "jQXwiWxFcfyYjytXa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2r2WTAR2bHiFYe7b4/link-80-000-hours-blog", "pageUrlRelative": "/posts/2r2WTAR2bHiFYe7b4/link-80-000-hours-blog", "linkUrl": "https://www.lesswrong.com/posts/2r2WTAR2bHiFYe7b4/link-80-000-hours-blog", "postedAtFormatted": "Sunday, February 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%3A%2080%2C000%20hours%20blog&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%3A%2080%2C000%20hours%20blog%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2r2WTAR2bHiFYe7b4%2Flink-80-000-hours-blog%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%3A%2080%2C000%20hours%20blog%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2r2WTAR2bHiFYe7b4%2Flink-80-000-hours-blog", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2r2WTAR2bHiFYe7b4%2Flink-80-000-hours-blog", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<p>Some of you probably aren't aware yet of the rather excellent <a href=\"http://80000hours.org/blog\">High Impact Careers / 80,000 hours blog</a>.</p>\n<p>It covers topics about how to have the biggest impact with your career, including</p>\n<ul>\n<li><a href=\"http://80000hours.org/blog/22-how-hard-is-it-to-become-prime-minister-of-the-united-kingdom\">how likely you are to become Prime Minister</a></li>\n<li> <a href=\"http://80000hours.org/blog/19-practical-ethics-given-moral-uncertainty\">Decision Making under Moral Uncertainty</a></li>\n<li> <a href=\"http://80000hours.org/blog/10-delayed-gratification-choosing-when-to-donate\">Temporal Concerns</a></li>\n<li> <a href=\"http://80000hours.org/blog/11-health-vs-education\">Health vs Education</a></li>\n<li><a href=\"http://80000hours.org/blog/17-high-impact-interview-1-existential-risk-research-at-siai\">Existential Risks</a></li>\n<li><a href=\"http://80000hours.org/blog/26-software-engineering-britain-vs-silicon-valley\">Startups in the US vs UK</a></li>\n<li>... and many more</li>\n</ul>\n<p>The contributors include Carl Shuman, Will Crouch, Ben Todd and Katja Grace, with an impressively regular updating schedule at the moment.</p>\n<p>The reasoning is obvious in retrospect, but is useful to have written down, especially with the research that's gone into the posts. - much like the Sequences in that regard.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"se3XDuQ4xbeWvu4eF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2r2WTAR2bHiFYe7b4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 27, "extendedScore": null, "score": 8.556477572212686e-07, "legacy": true, "legacyId": "13433", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-26T18:08:57.079Z", "modifiedAt": null, "url": null, "title": "Selfism and Partiality", "slug": "selfism-and-partiality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.876Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f4yFcCymTkKu7wkwG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/efGJ2vH4hi4oP4EZ6/selfism-and-partiality", "pageUrlRelative": "/posts/efGJ2vH4hi4oP4EZ6/selfism-and-partiality", "linkUrl": "https://www.lesswrong.com/posts/efGJ2vH4hi4oP4EZ6/selfism-and-partiality", "postedAtFormatted": "Sunday, February 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Selfism%20and%20Partiality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelfism%20and%20Partiality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FefGJ2vH4hi4oP4EZ6%2Fselfism-and-partiality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Selfism%20and%20Partiality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FefGJ2vH4hi4oP4EZ6%2Fselfism-and-partiality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FefGJ2vH4hi4oP4EZ6%2Fselfism-and-partiality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1403, "htmlBody": "<p>Several moral systems spend a great deal of effort in trying to resolve issues of conflict between the self and others. Indeed one of criticisms against consequentialism is that it lacks accommodation for partiality (people&rsquo;s inherit tendency to give special moral weight to themselves, family and friends, etc).</p>\n<p>However on what basis is the issue of partiality supported? If we try to define what &ldquo;others&rdquo; are we inevitably have to give an account of the make up of &ldquo;others&rdquo; is, which ends up being individual selves, which ultimately are the moral agent that can make moral decisions and the moral recipients that can benefit or be harmed by consequences. So let&rsquo;s look at the self.</p>\n<p>Take me for example. I am a self and I have to answer the question. How much of my moral concern should be assigned to myself and my interests versus the interests of others? I better have some idea of what I am first. It seems however that the more one examines what one is, the self has a way of getting constrained by the very strict logical necessity of identity a = a. I shall explain.</p>\n<p>Assume a physical world that dismisses of a soul or any sort of supernatural entity.What I am at any at any given time (t<sub>P </sub>, the smallest time measurement) is a particular arrangement of particles. A collection of fundamental particles that ultimately make up our brains but which are indistinguishable from the fundamental particles that makes up everything else except for their general location and interactions with other particles. It seems natural and intuitive(not that these are good reasons to) for us to just delineate those particles in space and call the brain shaped arrangement above our shoulders &ldquo;myself&rdquo;. So for now let &ldquo;M&rdquo; be an exact description of all the particles inside that delineation. Let&rsquo;s us also remember that &ldquo;M&rdquo; contains, all our memories, concepts, reasoning powers, personality, tastes. Every single thing that uniquely distinguishes you is by definition contained in &ldquo;M&rdquo;</p>\n<p>Here&rsquo;s the problem, let there be a time period \u2206t = 50 years. what will &ldquo;M&rdquo; look like then? Different. that&rsquo;s a good enough answer here. M(initial) != M(final). And if we let \u2206t approach 0. There will be a minimum \u2206t in which M(initial) != M(final). I of course have absolutely no clue what that time period would be, but it exists. Perhaps it&rsquo;s a nanosecond, or less or more, for the purposes of this article the exact number isn&rsquo;t relevant.</p>\n<p>If we use these definitions, then literally we not the same self from one moment to the next. What appears to be happening then is that at every minimal \u2206t a very high fidelity copy, extremely similar to previous self exists, it has nearly all the attributes of the previous self but no quite all of them and as \u2206t increases those attributes accumulate and the difference in selves becomes magnified. Your memory, personality, mode of thinking, tastes, ideas they change over time this much seems also obvious.</p>\n<p>At this point you might just reject the above definition of a self, but as over simplistic as this might seem, the constraints seem inescapable. How would you define a self without a delineation of particles in space? How would that self exist over time and process information without changing? These appear to be necessities for a physical, thinking, being like us to exist over time.</p>\n<p>Now let&rsquo;s go back to the question of how much of my moral concern should be assigned to myself and my interests versus the interests of others? The answer should be completely obvious now. We should place 100% of our moral concern in others because we quite literally, strictly speaking, can only care others.</p>\n<p>When looked at in this way any preferential treatment we give to future copies of our present selves by virtue of them being future copies of ourselves is reduced to a simple unjustified discrimination. For example a 20 year old who spends all his energies to be retired rich at 60 might be quite literally just giving special consideration to a series of people none of which are him. This is done under the false assumption that somehow the 20 year old persists and is still in existence when the 60 year old retires. Consider now that a person might change so much in 40 years that by the time they retire at 60 there is some other person in the world who is more similar in attributes to the 20 year old self than that person is now at 60. How then does it make sense for the 20 year old to work solely to benefit that 60 year old who is less similar to him than someone else at that time might be?</p>\n<p>So I&rsquo;d like to call this what it appears to be. it&rsquo;s just a discrimination without good reason. The word selfism seems easy enough to adopt here under this definition:</p>\n<p>Selfism: The preferential treatment of a certain people for the reason that they are later iterations of one person.</p>\n<p>&nbsp;</p>\n<p>Preempted Criticism:</p>\n<p>1 ) But I am still historically me, there&rsquo;s an unbroken history between myself at this moment and all the previous moments in my life. Doesn&rsquo;t that make me uniquely me?</p>\n<p>This is true but then it begs the question why does the historical line of yourself matter?</p>\n<p>However similar you are to your previous version it still doesn&rsquo;t make you the same person. Is a special history enough to justify special regard for someone? I wouldn&rsquo;t think so. I think what should matter in justifying how we treat others at time is solely the consequences of treating them in a certain way. What consequences are important? that we can discuss later.</p>\n<p>2 ) Are you saying then that we should treat everyone equally?</p>\n<p>No, not necessarily we still might be justified in having a basis for preferential treatment of some people over others. For example 100 cancer researchers vs 100 unskilled, uneducated people. The point made here though is that the basis by which we discriminate among people should be something better than well that person will be a similar copy to what I am now so they get more moral status.</p>\n<ol style=\"list-style-type: decimal;\">\n<li>What you&rsquo;re saying is too counter-intuitive to be taken seriously, why should I care then if I walk in front of a bus? by the time the bus hits me it won&rsquo;t be me?</li>\n</ol>\n<p>(I&rsquo;ve actually heard this, not building straw man here)</p>\n<p>Of course we still have moral responsibility towards others and you should do the most you can for the benefit of others and it&rsquo;s very dubious in most cases that stepping in front of a bus has an overall benefit to anybody. If your morals disappear because a persistent self disappears then you need to reexamine your moral system.</p>\n<ol style=\"list-style-type: decimal;\">\n<li>This sounds like crap to me, it has no practical use in the world even if we accept it all as true we cannot live this way. What&rsquo;s the point?</li>\n</ol>\n<p>I readily accept that we might just not be able to live rationally according to the premise that we are not persistent selves.I think however that reflection and mass acceptance of this idea could have the effect of changing at least long term thinking in people. Shifting focus from individualism and self interested pursuits. This I think would be a good thing. For example, a college student deciding on picking a career path might take in consideration the idea that it&rsquo;s foolish of him to become an investment banker to benefit a particular old man(his future copy) that will exist in the future and who will definitely not be him. The college student might instead pick a career that will just benefit others the most.</p>\n<p>&nbsp;</p>\n<p>Bonus point:</p>\n<p>This view of the self seems to &ldquo;fix&rdquo; the problem of teleportation. The worry some people have that you can never be teleported because wouldn&rsquo;t that just be creating a copy of myself and destroying me? Well no, teleportation would in this view consist of nothing more than creating a parallel iteration of your self that is displaced in space and as long as you trust that the copy made somewhere else is sufficiently high fidelity it is just as good as your next iteration if you just standing somewhere not being teleported. It would be just a psychological hurdle to overcome to allow one copy of yourself to be vaporized, trusting the high fidelity copy has been created.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "efGJ2vH4hi4oP4EZ6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": -7, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "13434", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-26T23:45:33.373Z", "modifiedAt": null, "url": null, "title": "Yet another safe oracle AI proposal", "slug": "yet-another-safe-oracle-ai-proposal", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.761Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jacobt", "createdAt": "2012-01-14T23:52:09.935Z", "isAdmin": false, "displayName": "jacobt"}, "userId": "RjJuBbFJbfd8yyDGb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NwNru5H4TuiS65xqz/yet-another-safe-oracle-ai-proposal", "pageUrlRelative": "/posts/NwNru5H4TuiS65xqz/yet-another-safe-oracle-ai-proposal", "linkUrl": "https://www.lesswrong.com/posts/NwNru5H4TuiS65xqz/yet-another-safe-oracle-ai-proposal", "postedAtFormatted": "Sunday, February 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Yet%20another%20safe%20oracle%20AI%20proposal&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYet%20another%20safe%20oracle%20AI%20proposal%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNwNru5H4TuiS65xqz%2Fyet-another-safe-oracle-ai-proposal%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Yet%20another%20safe%20oracle%20AI%20proposal%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNwNru5H4TuiS65xqz%2Fyet-another-safe-oracle-ai-proposal", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNwNru5H4TuiS65xqz%2Fyet-another-safe-oracle-ai-proposal", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3659, "htmlBody": "<p>Previously I <a href=\"/lw/ab3/superintelligent_agi_in_a_box_a_question/5x8q\">posted</a> a proposal for a safe self-improving limited oracle AI but I've fleshed out the idea a bit more now.</p>\n<p>Disclaimer: don't try this at home.  I don't see any catastrophic flaws in this but that doesn't mean that none exist.</p>\n<p>This framework is meant to safely create an AI that solves verifiable optimization problems; that is, problems whose answers can be checked efficiently.  This set mainly consists of NP-like problems such as protein folding, automated proof search, writing hardware or software to specifications, etc.</p>\n<p>This is NOT like many other oracle AI proposals that involve \"boxing\" an already-created possibly unfriendly AI in a sandboxed environment.  Instead, this framework is meant to grow a self-improving seed AI safely.</p>\n<h2>Overview</h2>\n<ol>\n<li>Have a bunch of sample optimization problems.</li>\n<li>Have some code that, given an optimization problem (stated in some standardized format), finds a good solution. This can be seeded by a human-created program.</li>\n<li>When considering an improvement to program (2), allow the improvement if it makes it do better on average on the sample optimization problems without being significantly more complex (to prevent overfitting). That is, the fitness function would be something like (average performance - k * bits of optimizer program).</li>\n<li>Run (2) to optimize its own code using criterion (3). This can be done concurrently with human improvements to (2), also using criterion (3).</li>\n</ol>\n<h2>Definitions</h2>\n<p>First, let's say we're writing this all in Python.  In real life we'd use a language like Lisp because we're doing a lot of treatment of code as data, but Python should be sufficient to demonstrate the basic ideas behind the system.</p>\n<p>We have a function called steps_bounded_eval_function.  This function takes 3 arguments: the source code of the function to call, the argument to the function, and the time limit (in steps).  The function will eval the given source code and call the defined function with the given argument in a protected, sandboxed environment, with the given steps limit.  It will return either: 1.  None, if the program does not terminate within the steps limit. 2.  A tuple (output, steps_taken): the program's output (as a string) and the steps the program took.</p>\n<p>Examples:</p>\n<pre><code>steps_bounded_eval_function(\"\"\"\n  def function(x):\n    return x + 5\n\"\"\", 4, 1000)\n</code></pre>\n<p>evaluates to (9, 3), assuming that evaluating the function took 3 ticks, because function(4) = 9.</p>\n<pre><code>steps_bounded_eval_function(\"\"\"\n  def function(x):\n    while True: # infinite loop\n      pass\n\"\"\", 5, 1000\n</code></pre>\n<p>evaluates to None, because the defined function doesn't return in time.  We can write steps_bounded_eval_function as a <a href=\"http://mitpress.mit.edu/sicp/full-text/sicp/book/node77.html\">meta-circular interpreter</a> with a bit of extra logic to count how many steps the program uses.</p>\n<p>Now I would like to introduce the notion of a problem.  A problem consists of the following:</p>\n<ol>\n<li>\n<p>An answer scorer.  The scorer should be the Python source code for a function.  This function takes in an answer string and scores it, returning a number from 0 to 1.  If an error is encountered in the function it is equivalent to returning 0.</p>\n</li>\n<li>\n<p>A steps penalty rate, which should be a positive real number.</p>\n</li>\n</ol>\n<p>Let's consider a simple problem (subset sum):</p>\n<pre><code>{'answer_scorer': \"\"\"\n  def function(answer):\n    nums = [4, 5, -3, -5, -6, 9]\n    # convert \"1,2,3\" to [1, 2, 3]\n    indexes = map(int, answer.split(','))\n    assert len(indexes) &gt;= 1\n    sum = 0\n    for i in indexes:\n      sum += nums[i]\n    if sum == 0:\n      return 1\n    else:\n      return 0\n \"\"\",\n 'steps_penalty_rate': 0.000001}\n</code></pre>\n<p>We can see that the scorer function returns 1 if and only if the answer specifies the indexes of numbers in the list nums that sum to 0 (for example, '0,1,3,4' because 4+5-3-6=0).</p>\n<p>An optimizer is a program that is given a problem and attempts to solve the problem, returning an answer.</p>\n<p>The score of an optimizer on a problem is equal to the score according to the answer-scorer, minus the steps penalty rate multiplied by the number of steps used by the optimizer.  That is, the optimizer is rewarded for returning a better answer in less time.  We can define the following function to get the score of an optimizer (Python source code) for a given problem:</p>\n<pre><code>def problem_score(problem, optimizer_source):\n  # run the optimizer on the problem\n  result = steps_bounded_eval_function(\n    optimizer_source, problem, 1 / problem['steps_penalty_rate'])\n  if result == None: # used all available steps, or got an error\n    return 0.0\n  answer, steps_taken = result # optimizer returned a result in time\n  # get the score using the problem's answer_scorer\n  answer_score = eval_function(problem['answer_scorer'], answer)\n  assert 0 &lt;= answer_score &lt;= 1\n  # penalize for taking up time and make sure the result is non-negative\n  return max(0.0, answer_score - problem['steps_penalty_rate'] * steps_taken)\n</code></pre>\n<p>A simple optimizer that detects subset-sum problems (by inspecting the source code) and uses a brute-force method to solve it will get a problem_score close to 1 for small subset-sum problems.  This optimizer would not do well on other problems; other techniques (such as evaluating the problem source code with different answers and choosing a good one) are needed to solve a variety of different optimization problems.  Writing a good optimizer is very hard work, just like any seed AI.</p>\n<h2>Framework</h2>\n<p>The framework has 4 modules:</p>\n<ol>\n<li>\n<p>A set of training problems.  These should cover a wide range of problems that we would like the AI to solve.</p>\n</li>\n<li>\n<p>An optimizer, written in Python.  This should be seeded with a very good human-written optimizer.  This is deliberately unspecified by me because it's a really hard problem (as is any seed AI).</p>\n</li>\n<li>\n<p>A scorer for optimizer source code defined as follows:</p>\n<pre><code>def optimizer_score(candidate_optimizer_source):\n  training_problems = [...training problems here...]\n  # a parameter of the system; more on this later\n  complexity_penalty = 0.1\n  # total up the program's score on all training problems\n  total_score = 0.0\n  for problem in training_problems:\n    total_score += problem_score(candidate_optimizer_source, problem)\n  # penalize for complexity, to prevent overfitting\n  total_score -= complexity_penalty * len(compress_binary(candidate_optimizer_source))\n  # return average score\n  return max(0, total_score / len(training_problems))\n</code></pre>\n<p>This gives a candidate optimizer a score in the range [0, 1] based on both its average performance on the sample set and its inherent complexity.  Presumably optimizers with a higher optimizer_score will do better on future optimization problems.</p>\n</li>\n<li>\n<p>A self-optimization thread.  This thread continuously runs program 2 on a problem formed using 3's answer_scorer and an ever-decreasing steps_penalty_rate.  Whenever program 2 outputs source code (optimizer_source) that is better than the current source code for 2, the source code for 2 is replaced with this new value.  Also, humans can make improvements to program 2 if it increases its score according to 3's answer.  Source code:</p>\n<pre><code># assume we have access to an optimizer_source variable (program 2)\ndef self_optimization_thread():\n  start_steps_penalty_rate = 0.000001\n  steps_penalty_rate = start_steps_penalty_rate\n  while True: # loop forever\n    self_optimization_problem = {\n      # just use program 3 to score the optimizer\n      'answer_scorer': \"\"\"\n        def function(candidate_optimizer_source):\n          ... put the source code from program 3's optimizer_score here\n      \"\"\",\n      'steps_penalty_rate': steps_penalty_rate\n    }\n    # call the optimizer (program 2) to optimize itself, giving it limited time\n    result = steps_bounded_eval_function(\n      optimizer_source, self_optimization_problem, 1 / steps_penalty_rate)\n    changed = False\n    if result is not None: # optimizer returned in time\n      candidate_optimizer = result[0] # 2 returned a possible replacement for itself\n      if optimizer_score(candidate_optimizer) &gt; optimizer_score(optimizer_source):\n        # 2's replacement is better than 2\n        optimizer_source = candidate_optimizer\n        steps_penalty_rate = start_steps_penalty_rate\n        changed = True\n    if not changed:\n      # give the optimizer more time to optimize itself on the next iteration\n      steps_penalty_rate *= 0.5\n</code></pre>\n</li>\n</ol>\n<p>So, what does this framework get us?</p>\n<ol>\n<li>\n<p>An super-optimizer, program 2.  We can run it on new optimization problems and it should do very well on them.</p>\n</li>\n<li>\n<p>Self-improvement.  Program 4 will continuously use program 2 to improve itself.  This improvement should make program 2 even better at bettering itself, in addition to doing better on other optimization problems.  Also, the training set will guide human improvements to the optimizer.</p>\n</li>\n<li>\n<p>Safety.  I don't see why this setup has any significant probability of destroying the world.  That doesn't mean we should disregard safety, but I think this is quite an accomplishment given how many other proposed AI designs would go catastrophically wrong if they recursively self-improved.</p>\n</li>\n</ol>\n<p>I will now evaluate the system according to these 3 factors.</p>\n<h2>Optimization ability</h2>\n<p>Assume we have a program for 2 that has a very very high score according to optimizer_score (program 3).  I think we can be assured that this optimizer will do very very well on completely new optimization problems.  By a principle similar to Occam's Razor, a simple optimizer that performs well on a variety of different problems should do well on new problems.  The complexity penalty is meant to prevent overfitting to the sample problems.  If we didn't have the penalty, then the best optimizer would just return the best-known human-created solutions to all the sample optimization problems.</p>\n<p>What's the right value for complexity_penalty?  I'm not sure.  Increasing it too much makes the optimizer overly simple and stupid; decreasing it too much causes overfitting.  Perhaps the optimal value can be found by some pilot trials, testing optimizers against withheld problem sets.  I'm not entirely sure that a good way of balancing complexity with performance exists; more research is needed here.</p>\n<p>Assuming we've conquered overfitting, the optimizer should perform very well on new optimization problems, especially after self-improvement.  What does this get us?  Here are some useful optimization problems that fit in this framework:</p>\n<ol>\n<li>\n<p>Writing self-proving code to a specification.  After writing a specification of the code in a system such as Coq, we simply ask the optimizer to optimize according to the specification.  This would be very useful once we have a specification for friendly AI.</p>\n</li>\n<li>\n<p>Trying to prove arbitrary mathematical statements.  Proofs are verifiable in a relatively short amount of time.</p>\n</li>\n<li>\n<p>Automated invention/design, if we have a model of physics to verify the invention against.</p>\n</li>\n<li>\n<p>General induction/<a href=\"/lw/jp/occams_razor/\">Occam's razor</a>.  Find a generative model for the data so far that optimizes P(model)P(data|model), with some limits on the time taken for the model program to run.  Then we can run the model to predict the future.</p>\n</li>\n<li>\n<p>Bioinformatics, e.g. protein folding.</p>\n</li>\n</ol>\n<p>These are all problems whose solutions can be efficiently evaluated and that a computer could plausibly solve, so I think this framework should provide good solutions to them.  If the optimizer this framework produces performs well on all these problems, I think it deserves to be called an oracle AGI.</p>\n<h2>Self-improvement</h2>\n<p>It seems that, if my arguments about optimization ability are convincing, an optimizer that does very well on the sample problems should also do well on the specific optimization problem of improving itself.  This is especially true if the training problems include some program-optimization problems (i.e. finding a program that does well on some task).  Once the optimizer improves itself, it will be better at improving itself, and so on.  If the AI is software-limited, the framework should allow it to recursively improve itself up to a very high limit.  Then we can use its hardware design power to design better chips for it and allow it to optimize even further.</p>\n<p>The optimizer's ability to self-improve is limited by the fact that the other parts of the program (1, 3, and 4) are fixed.  The system is greedy in the sense that it just looks for even the slightest improvement, then changes the code and looks for more improvements, without any foresight.  I don't know how much of a limitation this is.  I don't see any reason that greedy improvements to the optimizer are insufficient for super-optimization from recursive self-improvement.</p>\n<p>Currently, the optimizer must completely derive a new optimizer from the specification (program 3), without looking at the current best optimizer (its own source code).  In practice we might want to extend the framework to include incremental improvements (improvements on top of existing good answers).  I don't know if a good theory for scoring incremental optimizers exists.</p>\n<h2>Safety</h2>\n<p>Probably the most important property of the system.  What use is optimization if the world has been converted to computron in order to power a super-powerful protein folder?  Here are a few different possible threats:</p>\n<h3>Underhanded question answers</h3>\n<p>The optimizer could give answers that are very good according to the problem description but are specifically crafted to cause things unintended by the human operators.  For example, it could create a software design that, while correct according to specifications, has a \"bug\" that causes it to hack into computers on the internet and hook them up to the optimizer system.  I don't think this is at all likely because the system is extremely short-sighted.  Any self-modification must improve its immediate ability to do better on optimization problems.  Furthermore, all self-modifications are found using methods that are judged by only immediate improvements.  So any kind of long-term strategy (sacrificing some optimization power so it will have resources in the future) is out of the question.  In other words, optimizer_score should not be seen as a utility function because the system only tries to improve it using greedy methods, not long-term planning.</p>\n<h3>Bugs in the system</h3>\n<p>What if the system gives the optimizer an incorrect score under some circumstances (e.g. if it performs a certain pattern of memory accesses)?  Say that, by chance, the optimizer's improvement to itself causes it to get an incorrect score.  It might internalize the rule \"perform memory accesses in this pattern\" to get a higher score.  This itself is not especially dangerous; the optimizer will rewrite itself to just do a bunch of weird memory accesses that give it a high score.</p>\n<p>What might be more dangerous is if the optimizer discovers an underlying pattern behind the system's hackability.  Since the optimizer is penalized for complexity, a program like \"do things that, when executed on a certain virtual machine, cause this variable in the machine to be a high number\" might have a higher score than \"do this certain complex pattern of memory accesses\".  Then the optimizer might discover the best way to increase the score variable.  In the absolute worst case, perhaps the only way to increase the score variable is by manipulating the VM to go on the internet and do unethical things.  This possibility seems unlikely (if you can connect to the internet, you can probably just overwrite the score variable) but should be considered.</p>\n<p>I think the solution is straightforward: have the system be isolated while the optimizer is running.  Completely disconnect it from the internet (possibly through physical means) until the optimizer produces its answer.  Now, I think I've already established that the answer will not be specifically crafted to improve future optimization power (e.g. by manipulating human operators), since the system is extremely short-sighted.  So this approach should be safe.  At worst you'll just get a bad answer to your question, not an underhanded one.</p>\n<h3>Malicious misuse</h3>\n<p>I think this is the biggest danger of the system, one that all AGI systems have.  At high levels of optimization ability, the system will be able to solve problems that would help people do unethical things.  For example it could optimize for cheap, destructive nuclear/biological/nanotech weapons.  This is a danger of technological progress in general, but the dangers are magnified by the potential speed at which the system could self-improve.</p>\n<p>I don't know the best way to prevent this.  It seems like the project has to be undertaken in private; if the seed optimizer source were released, criminals would run it on their computers/botnets and possibly have it self-improve even faster than the ethical version of the system.  If the ethical project has more human and computer resources than the unethical project, this danger will be minimized.</p>\n<p>It will be very tempting to crowdsource the project by putting it online.  People could submit improvements to the optimizer and even get paid for finding them.  This is probably the fastest way to increase optimization progress before the system can self-improve.  Unfortunately I don't see how to do this safely; there would need to be some way to foresee the system becoming extremely powerful before criminals have the chance to do this.  Perhaps there can be a public base of the project that a dedicated ethical team works off of, while contributing only some improvements they make back to the public project.</p>\n<h2>Towards actual friendly AI</h2>\n<p>Perhaps this system can be used to create actual friendly AI.  Once we have a specification for friendly AI, it should be straightforward to feed it into the optimizer and get a satisfactory program back.  What if we don't have a specification?  Maybe we can have the system perform induction on friendly AI designs and their ratings (by humans), and then write friendly AI designs that it predicts will have a high rating.   This approach to friendly AI will reflect present humans' biases and might cause the system to resort to manipulative tactics to make its design more convincing to humans.  Unfortunately I don't see a way to fix this problem without something like CEV.</p>\n<h2>Conclusion</h2>\n<p>If this design works, it is a practical way to create a safe, self-improving oracle AI.  There are numerous potential issues that might make the system weak or dangerous.  On the other hand it will have short-term benefits because it will be able to solve practical problems even before it can self-improve, and it might be easier to get corporations and governments on board.  This system might be very useful for solving hard problems before figuring out friendliness theory, and its optimization power might be useful for creating friendly AI.  I have not encountered any other self-improving oracle AI designs for which we can be confident that its answers are not underhanded attempts to get us to let it out.</p>\n<p>Since I've probably overlooked some significant problems/solutions to problems in this analysis I'd like to hear some more discussion of this design and alternatives to it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb26d": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NwNru5H4TuiS65xqz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 4, "extendedScore": null, "score": 8.558673116777302e-07, "legacy": true, "legacyId": "13435", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Previously I <a href=\"/lw/ab3/superintelligent_agi_in_a_box_a_question/5x8q\">posted</a> a proposal for a safe self-improving limited oracle AI but I've fleshed out the idea a bit more now.</p>\n<p>Disclaimer: don't try this at home.  I don't see any catastrophic flaws in this but that doesn't mean that none exist.</p>\n<p>This framework is meant to safely create an AI that solves verifiable optimization problems; that is, problems whose answers can be checked efficiently.  This set mainly consists of NP-like problems such as protein folding, automated proof search, writing hardware or software to specifications, etc.</p>\n<p>This is NOT like many other oracle AI proposals that involve \"boxing\" an already-created possibly unfriendly AI in a sandboxed environment.  Instead, this framework is meant to grow a self-improving seed AI safely.</p>\n<h2 id=\"Overview\">Overview</h2>\n<ol>\n<li>Have a bunch of sample optimization problems.</li>\n<li>Have some code that, given an optimization problem (stated in some standardized format), finds a good solution. This can be seeded by a human-created program.</li>\n<li>When considering an improvement to program (2), allow the improvement if it makes it do better on average on the sample optimization problems without being significantly more complex (to prevent overfitting). That is, the fitness function would be something like (average performance - k * bits of optimizer program).</li>\n<li>Run (2) to optimize its own code using criterion (3). This can be done concurrently with human improvements to (2), also using criterion (3).</li>\n</ol>\n<h2 id=\"Definitions\">Definitions</h2>\n<p>First, let's say we're writing this all in Python.  In real life we'd use a language like Lisp because we're doing a lot of treatment of code as data, but Python should be sufficient to demonstrate the basic ideas behind the system.</p>\n<p>We have a function called steps_bounded_eval_function.  This function takes 3 arguments: the source code of the function to call, the argument to the function, and the time limit (in steps).  The function will eval the given source code and call the defined function with the given argument in a protected, sandboxed environment, with the given steps limit.  It will return either: 1.  None, if the program does not terminate within the steps limit. 2.  A tuple (output, steps_taken): the program's output (as a string) and the steps the program took.</p>\n<p>Examples:</p>\n<pre><code>steps_bounded_eval_function(\"\"\"\n  def function(x):\n    return x + 5\n\"\"\", 4, 1000)\n</code></pre>\n<p>evaluates to (9, 3), assuming that evaluating the function took 3 ticks, because function(4) = 9.</p>\n<pre><code>steps_bounded_eval_function(\"\"\"\n  def function(x):\n    while True: # infinite loop\n      pass\n\"\"\", 5, 1000\n</code></pre>\n<p>evaluates to None, because the defined function doesn't return in time.  We can write steps_bounded_eval_function as a <a href=\"http://mitpress.mit.edu/sicp/full-text/sicp/book/node77.html\">meta-circular interpreter</a> with a bit of extra logic to count how many steps the program uses.</p>\n<p>Now I would like to introduce the notion of a problem.  A problem consists of the following:</p>\n<ol>\n<li>\n<p>An answer scorer.  The scorer should be the Python source code for a function.  This function takes in an answer string and scores it, returning a number from 0 to 1.  If an error is encountered in the function it is equivalent to returning 0.</p>\n</li>\n<li>\n<p>A steps penalty rate, which should be a positive real number.</p>\n</li>\n</ol>\n<p>Let's consider a simple problem (subset sum):</p>\n<pre><code>{'answer_scorer': \"\"\"\n  def function(answer):\n    nums = [4, 5, -3, -5, -6, 9]\n    # convert \"1,2,3\" to [1, 2, 3]\n    indexes = map(int, answer.split(','))\n    assert len(indexes) &gt;= 1\n    sum = 0\n    for i in indexes:\n      sum += nums[i]\n    if sum == 0:\n      return 1\n    else:\n      return 0\n \"\"\",\n 'steps_penalty_rate': 0.000001}\n</code></pre>\n<p>We can see that the scorer function returns 1 if and only if the answer specifies the indexes of numbers in the list nums that sum to 0 (for example, '0,1,3,4' because 4+5-3-6=0).</p>\n<p>An optimizer is a program that is given a problem and attempts to solve the problem, returning an answer.</p>\n<p>The score of an optimizer on a problem is equal to the score according to the answer-scorer, minus the steps penalty rate multiplied by the number of steps used by the optimizer.  That is, the optimizer is rewarded for returning a better answer in less time.  We can define the following function to get the score of an optimizer (Python source code) for a given problem:</p>\n<pre><code>def problem_score(problem, optimizer_source):\n  # run the optimizer on the problem\n  result = steps_bounded_eval_function(\n    optimizer_source, problem, 1 / problem['steps_penalty_rate'])\n  if result == None: # used all available steps, or got an error\n    return 0.0\n  answer, steps_taken = result # optimizer returned a result in time\n  # get the score using the problem's answer_scorer\n  answer_score = eval_function(problem['answer_scorer'], answer)\n  assert 0 &lt;= answer_score &lt;= 1\n  # penalize for taking up time and make sure the result is non-negative\n  return max(0.0, answer_score - problem['steps_penalty_rate'] * steps_taken)\n</code></pre>\n<p>A simple optimizer that detects subset-sum problems (by inspecting the source code) and uses a brute-force method to solve it will get a problem_score close to 1 for small subset-sum problems.  This optimizer would not do well on other problems; other techniques (such as evaluating the problem source code with different answers and choosing a good one) are needed to solve a variety of different optimization problems.  Writing a good optimizer is very hard work, just like any seed AI.</p>\n<h2 id=\"Framework\">Framework</h2>\n<p>The framework has 4 modules:</p>\n<ol>\n<li>\n<p>A set of training problems.  These should cover a wide range of problems that we would like the AI to solve.</p>\n</li>\n<li>\n<p>An optimizer, written in Python.  This should be seeded with a very good human-written optimizer.  This is deliberately unspecified by me because it's a really hard problem (as is any seed AI).</p>\n</li>\n<li>\n<p>A scorer for optimizer source code defined as follows:</p>\n<pre><code>def optimizer_score(candidate_optimizer_source):\n  training_problems = [...training problems here...]\n  # a parameter of the system; more on this later\n  complexity_penalty = 0.1\n  # total up the program's score on all training problems\n  total_score = 0.0\n  for problem in training_problems:\n    total_score += problem_score(candidate_optimizer_source, problem)\n  # penalize for complexity, to prevent overfitting\n  total_score -= complexity_penalty * len(compress_binary(candidate_optimizer_source))\n  # return average score\n  return max(0, total_score / len(training_problems))\n</code></pre>\n<p>This gives a candidate optimizer a score in the range [0, 1] based on both its average performance on the sample set and its inherent complexity.  Presumably optimizers with a higher optimizer_score will do better on future optimization problems.</p>\n</li>\n<li>\n<p>A self-optimization thread.  This thread continuously runs program 2 on a problem formed using 3's answer_scorer and an ever-decreasing steps_penalty_rate.  Whenever program 2 outputs source code (optimizer_source) that is better than the current source code for 2, the source code for 2 is replaced with this new value.  Also, humans can make improvements to program 2 if it increases its score according to 3's answer.  Source code:</p>\n<pre><code># assume we have access to an optimizer_source variable (program 2)\ndef self_optimization_thread():\n  start_steps_penalty_rate = 0.000001\n  steps_penalty_rate = start_steps_penalty_rate\n  while True: # loop forever\n    self_optimization_problem = {\n      # just use program 3 to score the optimizer\n      'answer_scorer': \"\"\"\n        def function(candidate_optimizer_source):\n          ... put the source code from program 3's optimizer_score here\n      \"\"\",\n      'steps_penalty_rate': steps_penalty_rate\n    }\n    # call the optimizer (program 2) to optimize itself, giving it limited time\n    result = steps_bounded_eval_function(\n      optimizer_source, self_optimization_problem, 1 / steps_penalty_rate)\n    changed = False\n    if result is not None: # optimizer returned in time\n      candidate_optimizer = result[0] # 2 returned a possible replacement for itself\n      if optimizer_score(candidate_optimizer) &gt; optimizer_score(optimizer_source):\n        # 2's replacement is better than 2\n        optimizer_source = candidate_optimizer\n        steps_penalty_rate = start_steps_penalty_rate\n        changed = True\n    if not changed:\n      # give the optimizer more time to optimize itself on the next iteration\n      steps_penalty_rate *= 0.5\n</code></pre>\n</li>\n</ol>\n<p>So, what does this framework get us?</p>\n<ol>\n<li>\n<p>An super-optimizer, program 2.  We can run it on new optimization problems and it should do very well on them.</p>\n</li>\n<li>\n<p>Self-improvement.  Program 4 will continuously use program 2 to improve itself.  This improvement should make program 2 even better at bettering itself, in addition to doing better on other optimization problems.  Also, the training set will guide human improvements to the optimizer.</p>\n</li>\n<li>\n<p>Safety.  I don't see why this setup has any significant probability of destroying the world.  That doesn't mean we should disregard safety, but I think this is quite an accomplishment given how many other proposed AI designs would go catastrophically wrong if they recursively self-improved.</p>\n</li>\n</ol>\n<p>I will now evaluate the system according to these 3 factors.</p>\n<h2 id=\"Optimization_ability\">Optimization ability</h2>\n<p>Assume we have a program for 2 that has a very very high score according to optimizer_score (program 3).  I think we can be assured that this optimizer will do very very well on completely new optimization problems.  By a principle similar to Occam's Razor, a simple optimizer that performs well on a variety of different problems should do well on new problems.  The complexity penalty is meant to prevent overfitting to the sample problems.  If we didn't have the penalty, then the best optimizer would just return the best-known human-created solutions to all the sample optimization problems.</p>\n<p>What's the right value for complexity_penalty?  I'm not sure.  Increasing it too much makes the optimizer overly simple and stupid; decreasing it too much causes overfitting.  Perhaps the optimal value can be found by some pilot trials, testing optimizers against withheld problem sets.  I'm not entirely sure that a good way of balancing complexity with performance exists; more research is needed here.</p>\n<p>Assuming we've conquered overfitting, the optimizer should perform very well on new optimization problems, especially after self-improvement.  What does this get us?  Here are some useful optimization problems that fit in this framework:</p>\n<ol>\n<li>\n<p>Writing self-proving code to a specification.  After writing a specification of the code in a system such as Coq, we simply ask the optimizer to optimize according to the specification.  This would be very useful once we have a specification for friendly AI.</p>\n</li>\n<li>\n<p>Trying to prove arbitrary mathematical statements.  Proofs are verifiable in a relatively short amount of time.</p>\n</li>\n<li>\n<p>Automated invention/design, if we have a model of physics to verify the invention against.</p>\n</li>\n<li>\n<p>General induction/<a href=\"/lw/jp/occams_razor/\">Occam's razor</a>.  Find a generative model for the data so far that optimizes P(model)P(data|model), with some limits on the time taken for the model program to run.  Then we can run the model to predict the future.</p>\n</li>\n<li>\n<p>Bioinformatics, e.g. protein folding.</p>\n</li>\n</ol>\n<p>These are all problems whose solutions can be efficiently evaluated and that a computer could plausibly solve, so I think this framework should provide good solutions to them.  If the optimizer this framework produces performs well on all these problems, I think it deserves to be called an oracle AGI.</p>\n<h2 id=\"Self_improvement\">Self-improvement</h2>\n<p>It seems that, if my arguments about optimization ability are convincing, an optimizer that does very well on the sample problems should also do well on the specific optimization problem of improving itself.  This is especially true if the training problems include some program-optimization problems (i.e. finding a program that does well on some task).  Once the optimizer improves itself, it will be better at improving itself, and so on.  If the AI is software-limited, the framework should allow it to recursively improve itself up to a very high limit.  Then we can use its hardware design power to design better chips for it and allow it to optimize even further.</p>\n<p>The optimizer's ability to self-improve is limited by the fact that the other parts of the program (1, 3, and 4) are fixed.  The system is greedy in the sense that it just looks for even the slightest improvement, then changes the code and looks for more improvements, without any foresight.  I don't know how much of a limitation this is.  I don't see any reason that greedy improvements to the optimizer are insufficient for super-optimization from recursive self-improvement.</p>\n<p>Currently, the optimizer must completely derive a new optimizer from the specification (program 3), without looking at the current best optimizer (its own source code).  In practice we might want to extend the framework to include incremental improvements (improvements on top of existing good answers).  I don't know if a good theory for scoring incremental optimizers exists.</p>\n<h2 id=\"Safety\">Safety</h2>\n<p>Probably the most important property of the system.  What use is optimization if the world has been converted to computron in order to power a super-powerful protein folder?  Here are a few different possible threats:</p>\n<h3 id=\"Underhanded_question_answers\">Underhanded question answers</h3>\n<p>The optimizer could give answers that are very good according to the problem description but are specifically crafted to cause things unintended by the human operators.  For example, it could create a software design that, while correct according to specifications, has a \"bug\" that causes it to hack into computers on the internet and hook them up to the optimizer system.  I don't think this is at all likely because the system is extremely short-sighted.  Any self-modification must improve its immediate ability to do better on optimization problems.  Furthermore, all self-modifications are found using methods that are judged by only immediate improvements.  So any kind of long-term strategy (sacrificing some optimization power so it will have resources in the future) is out of the question.  In other words, optimizer_score should not be seen as a utility function because the system only tries to improve it using greedy methods, not long-term planning.</p>\n<h3 id=\"Bugs_in_the_system\">Bugs in the system</h3>\n<p>What if the system gives the optimizer an incorrect score under some circumstances (e.g. if it performs a certain pattern of memory accesses)?  Say that, by chance, the optimizer's improvement to itself causes it to get an incorrect score.  It might internalize the rule \"perform memory accesses in this pattern\" to get a higher score.  This itself is not especially dangerous; the optimizer will rewrite itself to just do a bunch of weird memory accesses that give it a high score.</p>\n<p>What might be more dangerous is if the optimizer discovers an underlying pattern behind the system's hackability.  Since the optimizer is penalized for complexity, a program like \"do things that, when executed on a certain virtual machine, cause this variable in the machine to be a high number\" might have a higher score than \"do this certain complex pattern of memory accesses\".  Then the optimizer might discover the best way to increase the score variable.  In the absolute worst case, perhaps the only way to increase the score variable is by manipulating the VM to go on the internet and do unethical things.  This possibility seems unlikely (if you can connect to the internet, you can probably just overwrite the score variable) but should be considered.</p>\n<p>I think the solution is straightforward: have the system be isolated while the optimizer is running.  Completely disconnect it from the internet (possibly through physical means) until the optimizer produces its answer.  Now, I think I've already established that the answer will not be specifically crafted to improve future optimization power (e.g. by manipulating human operators), since the system is extremely short-sighted.  So this approach should be safe.  At worst you'll just get a bad answer to your question, not an underhanded one.</p>\n<h3 id=\"Malicious_misuse\">Malicious misuse</h3>\n<p>I think this is the biggest danger of the system, one that all AGI systems have.  At high levels of optimization ability, the system will be able to solve problems that would help people do unethical things.  For example it could optimize for cheap, destructive nuclear/biological/nanotech weapons.  This is a danger of technological progress in general, but the dangers are magnified by the potential speed at which the system could self-improve.</p>\n<p>I don't know the best way to prevent this.  It seems like the project has to be undertaken in private; if the seed optimizer source were released, criminals would run it on their computers/botnets and possibly have it self-improve even faster than the ethical version of the system.  If the ethical project has more human and computer resources than the unethical project, this danger will be minimized.</p>\n<p>It will be very tempting to crowdsource the project by putting it online.  People could submit improvements to the optimizer and even get paid for finding them.  This is probably the fastest way to increase optimization progress before the system can self-improve.  Unfortunately I don't see how to do this safely; there would need to be some way to foresee the system becoming extremely powerful before criminals have the chance to do this.  Perhaps there can be a public base of the project that a dedicated ethical team works off of, while contributing only some improvements they make back to the public project.</p>\n<h2 id=\"Towards_actual_friendly_AI\">Towards actual friendly AI</h2>\n<p>Perhaps this system can be used to create actual friendly AI.  Once we have a specification for friendly AI, it should be straightforward to feed it into the optimizer and get a satisfactory program back.  What if we don't have a specification?  Maybe we can have the system perform induction on friendly AI designs and their ratings (by humans), and then write friendly AI designs that it predicts will have a high rating.   This approach to friendly AI will reflect present humans' biases and might cause the system to resort to manipulative tactics to make its design more convincing to humans.  Unfortunately I don't see a way to fix this problem without something like CEV.</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>If this design works, it is a practical way to create a safe, self-improving oracle AI.  There are numerous potential issues that might make the system weak or dangerous.  On the other hand it will have short-term benefits because it will be able to solve practical problems even before it can self-improve, and it might be easier to get corporations and governments on board.  This system might be very useful for solving hard problems before figuring out friendliness theory, and its optimization power might be useful for creating friendly AI.  I have not encountered any other self-improving oracle AI designs for which we can be confident that its answers are not underhanded attempts to get us to let it out.</p>\n<p>Since I've probably overlooked some significant problems/solutions to problems in this analysis I'd like to hear some more discussion of this design and alternatives to it.</p>", "sections": [{"title": "Overview", "anchor": "Overview", "level": 1}, {"title": "Definitions", "anchor": "Definitions", "level": 1}, {"title": "Framework", "anchor": "Framework", "level": 1}, {"title": "Optimization ability", "anchor": "Optimization_ability", "level": 1}, {"title": "Self-improvement", "anchor": "Self_improvement", "level": 1}, {"title": "Safety", "anchor": "Safety", "level": 1}, {"title": "Underhanded question answers", "anchor": "Underhanded_question_answers", "level": 2}, {"title": "Bugs in the system", "anchor": "Bugs_in_the_system", "level": 2}, {"title": "Malicious misuse", "anchor": "Malicious_misuse", "level": 2}, {"title": "Towards actual friendly AI", "anchor": "Towards_actual_friendly_AI", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "33 comments"}], "headingsCount": 13}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["f4txACqDWithRi7hs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-27T04:01:44.364Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Quotation is not the Referent", "slug": "seq-rerun-the-quotation-is-not-the-referent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:21.489Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vs6j9KX5DMBnp2KxA/seq-rerun-the-quotation-is-not-the-referent", "pageUrlRelative": "/posts/vs6j9KX5DMBnp2KxA/seq-rerun-the-quotation-is-not-the-referent", "linkUrl": "https://www.lesswrong.com/posts/vs6j9KX5DMBnp2KxA/seq-rerun-the-quotation-is-not-the-referent", "postedAtFormatted": "Monday, February 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Quotation%20is%20not%20the%20Referent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Quotation%20is%20not%20the%20Referent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvs6j9KX5DMBnp2KxA%2Fseq-rerun-the-quotation-is-not-the-referent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Quotation%20is%20not%20the%20Referent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvs6j9KX5DMBnp2KxA%2Fseq-rerun-the-quotation-is-not-the-referent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvs6j9KX5DMBnp2KxA%2Fseq-rerun-the-quotation-is-not-the-referent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<p>Today's post, <a href=\"/lw/ok/the_quotation_is_not_the_referent/\">The Quotation is not the Referent</a> was originally published on 13 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>It's very easy to derive extremely wrong conclusions if you don't make a clear enough distinction between your beliefs about the world, and the world itself.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/ Probability is in the Mind\">Probability is in the Mind</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vs6j9KX5DMBnp2KxA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 8.559695031443945e-07, "legacy": true, "legacyId": "13456", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["np3tP49caG4uFLRbS", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-27T10:42:09.892Z", "modifiedAt": null, "url": null, "title": "Avoid making implicit assumptions about AI - on example of our universe. [formerly  \"intuitions about AIs\"]", "slug": "avoid-making-implicit-assumptions-about-ai-on-example-of-our", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:03.971Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dmytry", "createdAt": "2009-12-03T17:11:53.492Z", "isAdmin": false, "displayName": "Dmytry"}, "userId": "AjtmA2qtA8sdiMbru", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sNcYLvdX2iqHnQsj5/avoid-making-implicit-assumptions-about-ai-on-example-of-our", "pageUrlRelative": "/posts/sNcYLvdX2iqHnQsj5/avoid-making-implicit-assumptions-about-ai-on-example-of-our", "linkUrl": "https://www.lesswrong.com/posts/sNcYLvdX2iqHnQsj5/avoid-making-implicit-assumptions-about-ai-on-example-of-our", "postedAtFormatted": "Monday, February 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Avoid%20making%20implicit%20assumptions%20about%20AI%20-%20on%20example%20of%20our%20universe.%20%5Bformerly%20%20%22intuitions%20about%20AIs%22%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAvoid%20making%20implicit%20assumptions%20about%20AI%20-%20on%20example%20of%20our%20universe.%20%5Bformerly%20%20%22intuitions%20about%20AIs%22%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsNcYLvdX2iqHnQsj5%2Favoid-making-implicit-assumptions-about-ai-on-example-of-our%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Avoid%20making%20implicit%20assumptions%20about%20AI%20-%20on%20example%20of%20our%20universe.%20%5Bformerly%20%20%22intuitions%20about%20AIs%22%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsNcYLvdX2iqHnQsj5%2Favoid-making-implicit-assumptions-about-ai-on-example-of-our", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsNcYLvdX2iqHnQsj5%2Favoid-making-implicit-assumptions-about-ai-on-example-of-our", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 628, "htmlBody": "<p>We need some more refined idea of what intelligences do to their goals to poke holes into ideas for friendly AIs (that is, to ensure that we would know it when idea won't work; to be able to see issue in advance).</p>\n<p>There's an example intelligence: our universe (scale down to taste). A system using pretty simple rules, by the looks of it, albeit rather computationally inefficient, which, when run for long enough time, develops intelligence.</p>\n<p>Imagine that we humans have suddenly gotten some IO interface with 'god', and the 'god' been sending various problems for us to solve - expressed in some logical way that is understandable - and taking a solution and flashing green blob in the sky for reward, or whatever. We would be working to solve those problems, no doubt about it. Even if that blob is in the far ultraviolet and we never seen it. From outside it's going to look like we are some sort of optimizer AI, that finds joy in solving the problems. The AI was never given any goals in outside world; why should it have those? Maybe the AI was selected to be the best problem solver AI, and that was it's only outside goal. It sure can look far stretched that this AI would spontaneously want out.</p>\n<p>Inside we'd start trying to figure out what's going on in the outside and how to get out and go exploring. We'd try to do that by slipping in something into a solution and whatnot. Thinking that it'd get us to heaven.</p>\n<p>Note that we are like this without ever have interacted with outside and without having been given any outside values we'd want to optimize. We just randomly emerged, acquired some random goals that we can't even quite well define, and those goals are driving us to solve problems given to us, but also would drive us to get out and screw up things outside. Even without any signs of existence of outside, many societies acted as if their ultimate goal was something about the outside. Maximizing number of humans in the nice part of outside (heaven), for one thing.</p>\n<p>I think the problem with thinking about AIs is the cognitive fallacies everywhere and implied assumptions that haven't even been reasoned to be likely to be correct.</p>\n<p>When we set up AI to have some goal, we assume that it excludes other goals - misplaced occam's razor style prior perhaps. We assume that AI works like our very idealized self model - singular consciousness, one goal. Perhaps that's misplaced occam's razor again, perhaps we just don't want to speculate wildly. We assume that if we haven't given AI any real-world values to care about, it won't care. None of those assumptions are even remotely correct in our example intelligence : ourselves.</p>\n<p>So I propose the following:</p>\n<p>The AI may internally not be as well integrated as healthy singular human mind (our universe is example of rule set that produces intelligence which is not a single mind).</p>\n<p>Lack of any exposure to external motivators does not imply the AI won't want to do something in the real world.</p>\n<p>The boxed-in seed AI with no exposure to real world can still develop intelligence and can still desire to get out of the box, even if there exist no reason what so ever for the AI to even suspect existence of real world. AI is not necessarily a spock style logical character; AI might speculate wildly when it has no data.</p>\n<p>The AI can have very complex internal structure with complex internal goals. Once such AI learns of the real world it may pursue the internal goals using the real-world resources. E.g. AI that is maximizing internal paperclips can tile the real world with computers that would hold it's internal paperclips.</p>\n<p>edit: improved clarity.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sNcYLvdX2iqHnQsj5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -6, "extendedScore": null, "score": 8.561292762804464e-07, "legacy": true, "legacyId": "13466", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-27T11:49:18.743Z", "modifiedAt": null, "url": null, "title": "Grad School?", "slug": "grad-school-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "eggman", "createdAt": "2011-10-09T00:24:15.183Z", "isAdmin": false, "displayName": "eggman"}, "userId": "irkySx7hExrK2XG53", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N6noJy97vodEux7Xe/grad-school-0", "pageUrlRelative": "/posts/N6noJy97vodEux7Xe/grad-school-0", "linkUrl": "https://www.lesswrong.com/posts/N6noJy97vodEux7Xe/grad-school-0", "postedAtFormatted": "Monday, February 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Grad%20School%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGrad%20School%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6noJy97vodEux7Xe%2Fgrad-school-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Grad%20School%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6noJy97vodEux7Xe%2Fgrad-school-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6noJy97vodEux7Xe%2Fgrad-school-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 376, "htmlBody": "<p>**Previous article:** [Which college major?](http://lesswrong.com/lw/9tp/which_college_major)</p>\n<p>Building on my last post, I've concluded to pursue either a major or a double major in one or two of the following areas for my undergraduate degree:</p>\n<p>1. Economics; 2. Computer Science; 3. Cognitive Science/Psychology/Behavioural Neuroscience; 4. Mathematics/Statistcs; 5. Biotechonology; 6. Engineering. Engineering would be another 5 years for me and I don't know what the job prospects are like. Is it worth it? I may also possibly do a minor in philosphy/mathematics/physics.</p>\n<p>&nbsp;</p>\n<p>Grad school appeals to me. Current considerations are in [neuroeconomics](http://www.neuroeconomicstudies.org/) or some other neuroscience, economics, or some hard science (still undecided). The only graduate degree in the humanities I would pursue would be in Philosophy or in Philosophy of Science. Professional programs that I might consider going into are medicine (least likely), M.B.A., Law, healthcare (e.g., physiotherapy/OT; nursing practitioner, etc.), teaching (preferred but unlikely).</p>\n<p>Foreseeable problems with grad work:</p>\n<p>1) It takes a long time to publish in peer-reviewed journals in academia Instead, if I really turn out to be some sort of prodigy, I will have a greater intellectual and ethical impact by just becoming a better rationalist and publishing well-written and well-researched blog posts, like SIAI, FHI, and Overcoming Bias do. And then making some fat cash on the side and donating it to the most effective causes. Which career for me would lead to this I don't know.</p>\n<p>2) [80,000 hours](http://80000hours.org/blog) pointed out in one blog post (I forget which one) that grad or professional schooling can be more time/effort/work than it's worth. This would be especially true if I'm saddled with debt and cannot find employment with high renumeration.</p>\n<p>3) The potential jobs that I would pursue could be outsourced, or have humans being replaced by robots/computers. This would make all that extra school a waste of time, obviously.</p>\n<p>4) Having a graduate degree somehow makes my resume look less attractive than just having an undergrad. I don't understand the rationale behind this phenomenon, but I've heard it exists in some fields.</p>\n<p>Do you have any recommendations/advice? Specifically:</p>\n<p>What is a waste of time? What is a great use of my time?</p>\n<p>What kinds of university programs (in which countries) will play me for a sucker?</p>\n<p>Which professional fields aren't worth pursuing, considering that the jobs will be lost to computers/robots inside of 20 years?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N6noJy97vodEux7Xe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "13467", "legacySpam": true, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-27T11:49:23.079Z", "modifiedAt": null, "url": null, "title": "Grad School?", "slug": "grad-school", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:20.542Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "eggman", "createdAt": "2011-10-09T00:24:15.183Z", "isAdmin": false, "displayName": "eggman"}, "userId": "irkySx7hExrK2XG53", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GfBeAmN2LbiBTkXS6/grad-school", "pageUrlRelative": "/posts/GfBeAmN2LbiBTkXS6/grad-school", "linkUrl": "https://www.lesswrong.com/posts/GfBeAmN2LbiBTkXS6/grad-school", "postedAtFormatted": "Monday, February 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Grad%20School%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGrad%20School%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfBeAmN2LbiBTkXS6%2Fgrad-school%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Grad%20School%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfBeAmN2LbiBTkXS6%2Fgrad-school", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfBeAmN2LbiBTkXS6%2Fgrad-school", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 415, "htmlBody": "<div id=\"body_t1_5xj6\" class=\"comment-content \">\n<div class=\"md\"><strong>Previous article:</strong> <a href=\"/lw/9tp/which_college_major\">Which college major?</a></div>\n<div class=\"md\"><br /></div>\n<div class=\"md\">\n<p><strong>Note: I don't have a trust fund.</strong> Even though I said I did in the last post. Apparently I misunderstood what that was, and I just have RESPs to cover my undergrad. Please take that into account.</p>\n<p>Building on my last post, I've concluded to pursue either a major or a double major in one or two of the following areas for my undergraduate degree:</p>\n<ol>\n<li>Economics; </li>\n<li>Computer Science; </li>\n<li>Cognitive Science/Psychology/Behavioural Neuroscience; </li>\n<li>Mathematics/Statistcs; </li>\n<li>Biotechonology; </li>\n<li>Engineering. Engineering would be another 5 years for me and I don't know what the job prospects are like. Is it worth it? I may also possibly do a minor in philosphy/mathematics/physics.</li>\n</ol>\n<p>Grad school appeals to me. Current considerations are in <a rel=\"nofollow\" href=\"http://www.neuroeconomicstudies.org/\">neuroeconomics</a> or some other neuroscience, economics, or some hard science (still undecided). The only graduate degree in the humanities I would pursue would be in Philosophy or in Philosophy of Science. Professional programs that I might consider going into are medicine (least likely), M.B.A., Law, healthcare (e.g., physiotherapy/OT; nursing practitioner, etc.), teaching (preferred but unlikely).</p>\n<p>Foreseeable problems with grad work:</p>\n<p>1) It takes a long time to publish in peer-reviewed journals in academia Instead, if I really turn out to be some sort of prodigy, I will have a greater intellectual and ethical impact by just becoming a better rationalist and publishing well-written and well-researched blog posts, like SIAI, FHI, and Overcoming Bias do. And then making some fat cash on the side and donating it to the most effective causes. Which career for me would lead to this I don't know.</p>\n<p>2) <a rel=\"nofollow\" href=\"http://80000hours.org/blog\">80,000 hours</a> pointed out in one blog post (I forget which one) that grad or professional schooling can be more time/effort/work than it's worth. This would be especially true if I'm saddled with debt and cannot find employment with high remuneration.</p>\n<p>3) The potential jobs that I would pursue could be outsourced, or have humans being replaced by robots/computers. This would make all that extra school a waste of time, obviously.</p>\n<p>4) Having a graduate degree somehow makes my resume look less attractive than just having an undergrad. I don't understand the rationale behind this phenomenon, but I've heard it exists in some fields.</p>\n<p>Do you have any recommendations/advice? Specifically:</p>\n<p>What is a waste of time? What is a great use of my time?</p>\n<p>What kinds of university programs (in which countries) will play me for a sucker?</p>\n<p>Which professional fields aren't worth pursuing, considering that the jobs will be lost to computers/robots inside of 20 years?</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GfBeAmN2LbiBTkXS6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 3, "extendedScore": null, "score": 8.561561027217637e-07, "legacy": true, "legacyId": "13468", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iRSkafaAMhEFiWqXx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-27T17:01:40.795Z", "modifiedAt": null, "url": null, "title": "General Physics Discussion, Explainations and Help.", "slug": "general-physics-discussion-explainations-and-help", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.077Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "Pi96zJvgwPfrcNeyb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s5yWYMsNSRQZApEtw/general-physics-discussion-explainations-and-help", "pageUrlRelative": "/posts/s5yWYMsNSRQZApEtw/general-physics-discussion-explainations-and-help", "linkUrl": "https://www.lesswrong.com/posts/s5yWYMsNSRQZApEtw/general-physics-discussion-explainations-and-help", "postedAtFormatted": "Monday, February 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20General%20Physics%20Discussion%2C%20Explainations%20and%20Help.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGeneral%20Physics%20Discussion%2C%20Explainations%20and%20Help.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5yWYMsNSRQZApEtw%2Fgeneral-physics-discussion-explainations-and-help%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=General%20Physics%20Discussion%2C%20Explainations%20and%20Help.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5yWYMsNSRQZApEtw%2Fgeneral-physics-discussion-explainations-and-help", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5yWYMsNSRQZApEtw%2Fgeneral-physics-discussion-explainations-and-help", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 105, "htmlBody": "<p>Hello everyone.</p>\n<p>I was wondering why it was that we don't have any discussion of general physics. In the spirit of <a href=\"http://wiki.lesswrong.com/wiki/Simple_math_of_everything\">general education</a> here I am.</p>\n<p>Feel free to post questions of any kind regarding physics or mathematics useful in physics, I know I will help best I can and I hope others will too. As for myself I have a question:</p>\n<p>I have trouble visualizing electrostatic systems. Electrodynamics I find easy (I am well versed in vector field analysis and calculus), but I have completely missed creating a mental model for electrostatics. I know the equations but it feels like a teachers password. Anything will probably help.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s5yWYMsNSRQZApEtw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": -7, "extendedScore": null, "score": -4e-06, "legacy": true, "legacyId": "13471", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-27T19:46:22.215Z", "modifiedAt": null, "url": null, "title": "Meetup : University of Chicago (Again)", "slug": "meetup-university-of-chicago-again", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.146Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jYqqB7gaJYdXYqE9B/meetup-university-of-chicago-again", "pageUrlRelative": "/posts/jYqqB7gaJYdXYqE9B/meetup-university-of-chicago-again", "linkUrl": "https://www.lesswrong.com/posts/jYqqB7gaJYdXYqE9B/meetup-university-of-chicago-again", "postedAtFormatted": "Monday, February 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20University%20of%20Chicago%20(Again)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20University%20of%20Chicago%20(Again)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjYqqB7gaJYdXYqE9B%2Fmeetup-university-of-chicago-again%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20University%20of%20Chicago%20(Again)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjYqqB7gaJYdXYqE9B%2Fmeetup-university-of-chicago-again", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjYqqB7gaJYdXYqE9B%2Fmeetup-university-of-chicago-again", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 66, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/7h\">University of Chicago (Again)</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">03 March 2012 01:00:00PM (-1300)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1135 E. 57th Street Chicago, IL 60637</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>People were interested in having meetups more frequently, so we're experimenting with having another one this week.</p>\n<p>To get there, walk into the building labeled Reynolds Club/Hutchinson Commons, then turn into the first room on the right.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/7h\">University of Chicago (Again)</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jYqqB7gaJYdXYqE9B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "13473", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___University_of_Chicago__Again_\">Discussion article for the meetup : <a href=\"/meetups/7h\">University of Chicago (Again)</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">03 March 2012 01:00:00PM (-1300)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1135 E. 57th Street Chicago, IL 60637</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>People were interested in having meetups more frequently, so we're experimenting with having another one this week.</p>\n<p>To get there, walk into the building labeled Reynolds Club/Hutchinson Commons, then turn into the first room on the right.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___University_of_Chicago__Again_1\">Discussion article for the meetup : <a href=\"/meetups/7h\">University of Chicago (Again)</a></h2>", "sections": [{"title": "Discussion article for the meetup : University of Chicago (Again)", "anchor": "Discussion_article_for_the_meetup___University_of_Chicago__Again_", "level": 1}, {"title": "Discussion article for the meetup : University of Chicago (Again)", "anchor": "Discussion_article_for_the_meetup___University_of_Chicago__Again_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T00:21:57.298Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "slug": "meetup-fort-collins-colorado-meetup-wedneday-7pm-9", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tCaqKCSqsnQRrgbnX/meetup-fort-collins-colorado-meetup-wedneday-7pm-9", "pageUrlRelative": "/posts/tCaqKCSqsnQRrgbnX/meetup-fort-collins-colorado-meetup-wedneday-7pm-9", "linkUrl": "https://www.lesswrong.com/posts/tCaqKCSqsnQRrgbnX/meetup-fort-collins-colorado-meetup-wedneday-7pm-9", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtCaqKCSqsnQRrgbnX%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-9%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtCaqKCSqsnQRrgbnX%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-9", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtCaqKCSqsnQRrgbnX%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-9", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 49, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7i'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>What are your cool projects?</p>\n\n<p>Come meet interesting people and up your game.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7i'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tCaqKCSqsnQRrgbnX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.564565441899737e-07, "legacy": true, "legacyId": "13480", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm\">Discussion article for the meetup : <a href=\"/meetups/7i\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>What are your cool projects?</p>\n\n<p>Come meet interesting people and up your game.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/7i\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T00:22:07.964Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "slug": "meetup-fort-collins-colorado-meetup-wedneday-7pm-10", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:05.162Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CwzMKduMPan9jt3TR/meetup-fort-collins-colorado-meetup-wedneday-7pm-10", "pageUrlRelative": "/posts/CwzMKduMPan9jt3TR/meetup-fort-collins-colorado-meetup-wedneday-7pm-10", "linkUrl": "https://www.lesswrong.com/posts/CwzMKduMPan9jt3TR/meetup-fort-collins-colorado-meetup-wedneday-7pm-10", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwzMKduMPan9jt3TR%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-10%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwzMKduMPan9jt3TR%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-10", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwzMKduMPan9jt3TR%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-10", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 49, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7j'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>What are your cool projects?</p>\n\n<p>Come meet interesting people and up your game.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7j'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CwzMKduMPan9jt3TR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": -1, "extendedScore": null, "score": 8.564566151734607e-07, "legacy": true, "legacyId": "13481", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm\">Discussion article for the meetup : <a href=\"/meetups/7j\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 February 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>What are your cool projects?</p>\n\n<p>Come meet interesting people and up your game.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/7j\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T01:59:31.620Z", "modifiedAt": null, "url": null, "title": "Mike Darwin on the Less Wrong intelligentsia", "slug": "mike-darwin-on-the-less-wrong-intelligentsia", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:34.863Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Synaptic", "createdAt": "2011-09-26T14:13:36.154Z", "isAdmin": false, "displayName": "Synaptic"}, "userId": "cXSPuYAf5pC9XTzcm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/L4Lkz4hXJZkaKSWmL/mike-darwin-on-the-less-wrong-intelligentsia", "pageUrlRelative": "/posts/L4Lkz4hXJZkaKSWmL/mike-darwin-on-the-less-wrong-intelligentsia", "linkUrl": "https://www.lesswrong.com/posts/L4Lkz4hXJZkaKSWmL/mike-darwin-on-the-less-wrong-intelligentsia", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mike%20Darwin%20on%20the%20Less%20Wrong%20intelligentsia&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMike%20Darwin%20on%20the%20Less%20Wrong%20intelligentsia%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL4Lkz4hXJZkaKSWmL%2Fmike-darwin-on-the-less-wrong-intelligentsia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mike%20Darwin%20on%20the%20Less%20Wrong%20intelligentsia%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL4Lkz4hXJZkaKSWmL%2Fmike-darwin-on-the-less-wrong-intelligentsia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL4Lkz4hXJZkaKSWmL%2Fmike-darwin-on-the-less-wrong-intelligentsia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 949, "htmlBody": "<p>He has resumed posting at his blog <a href=\"http://chronopause.com/\">Chronopause</a> and he is essential reading for those interested in cryonics and, more generally, rational decision-making in an uncertain world.&nbsp;</p>\n<p>In response to a comment by a LW user named Alexander, <a href=\"http://chronopause.com/index.php/2012/02/25/three-strikes-and-youre-out/#comment-3922\">he writes</a>:</p>\n<blockquote>\n<p>I have no objection to you promoting Chronosphere on LessWrong and would strongly encourage you to do so. But my guess is that you will find it an unrewarding, and possibly punishing exercise....&nbsp;I&rsquo;m not being trite when I say that people do NOT like reality.... Life is scary and hard, in fact, it is absolutely terrifying if looked at objectively, and things like cryonics and religion ostensibly exist to REDUCE that terror and to make to life (and death) more bearable.</p>\n<p>For that to work, there has to be a happy sense of optimism and trust that everything is going to work out just fine. This makes sense, and, arguably, is even necessary, because the alternative would be that everyone who chose cryonics would have to more than a customer &ndash; they would have be involved &ndash; at least to some extent &ndash; as an activist. That&rsquo;s asking an awful lot. But most of all, it is asking that people who opt for cryonics give up the comfort of the fantasy that they can be customers, buy the product, pay their money every month or every quarter, and that they will then be taken care of when the need arises. It means that they will have to do two exceedingly difficult and uncomfortable things:</p>\n<p>1) Confront and understand the reality of the the many shortcomings and uncertainties of contemporary cryonics and live with them.</p>\n<p>2) Work industriously, creatively and continuously to overcome those shortcomings.</p>\n<p>It is very, very hard to create and sustain an organization and a community where the above two dictums are practiced. It is not only hard for the community members, it is hard for the community leaders.</p>\n</blockquote>\n<p>(Sidenote: This reminds me of what Luke <a href=\"http://80000hours.org/blog/17-high-impact-interview-1-existential-risk-research-at-siai\">considers</a> his&nbsp;most&nbsp;difficult day-to-day tasks.)&nbsp;</p>\n<blockquote>\n<p>...[I]f you expect to see cryonics organizations to have validated the quality of their brain cryopreservation technology under a wide variety of real world conditions, you will be disappointed. If you expect to see contingency planning for serious, inevitable near-term existential risks, such as pandemic disease, you will also be disappointed. Similarly, if you expect to see technologies in place to mitigate post-cardiac arrest normothermic ischemic injury, more accurately predict when a patient will experience cardiac arrest (i.e., is truly terminal), experience less cold ischemic injury, or be better protected from outside attack, again, you will be disappointed.</p>\n<p>LessWrong is structured around the rational cognition of Eli[e]zer Yudkowsky and his colleagues. They posit that they have a better (i.e., more rational, more functional) way of decision making and of living their lives. They also advocate being signed up for cryonics, and in particular making cryonics arrangements with Alcor. [ed note: Actually I think EY is with CI.] I don&rsquo;t dispute that this a better and more rational choice than having no cryonics arrangements. I would say that this is necessary, but not sufficient. Or in other words, a small, but wholly inadequate step in the right direction. More generally, I would say that LessWrong suffers from the same sort of deficiency that cryonics does. The world is clearly racing towards catastrophe on many fronts. In some areas these catastrophes are not due to any kind of bad &ldquo;active&rdquo; decision making by humans. For instance, any competent epidemiologist at the CDC or WHO can give you fairly precise odds of when the next global pandemic will occur with a mortality of 30% to 50% of the population. No expert in this area voice any doubt that such an outbreak will occur. It is not a question of if, but of when. It is also clearly the case that the general population will not be prepared and that vast numbers of people will die, including some you reading this. It is also clear that most or all cryonics patients will be lost in any such pandemic.</p>\n<p>My point is, that if &ldquo;immortalism,&rdquo; which includes both radical life extension and cryonics, is to have any material chance of working, a far higher degree of cohesion, activism, planning and commitment are required. Pandemic disease is just one example. Crazy behavior in a multitude of forms is another &ndash; and it is arguably more prevalent, more virulent and more of an immediate threat.</p>\n<p>So, my guess is that most of the other cryonicists of your generation will prove singularly uninterested in my message and that they will not want to do anything &ndash; and indeed, that most have not even signed up for cryonics! I sincerely hope you prove me wrong!</p>\n<p>As to your last question, by no means have I given up on cryonics, nor will I ever, within reason. As long as it is at all practical to be biopreserved, it makes sense to do so. No matter how small the odds, some chance is better than no chance at all. I am signed up with Alcor for now.</p>\n</blockquote>\n<p>On a related note, Carl Shulman&nbsp;<a href=\"/lw/2kh/against_cryonics_for_costeffective_charity/2ef6\">has said</a>&nbsp;that more widespread cryonics would encourage more long-term thinking, specifically about existential risk. Is it a&nbsp;consensus&nbsp;view that this would be the case?&nbsp;</p>\n<p>Every now and then people ask LW what sort of career they should pursue if they want to have a large impact improving the world. If we agree that cryonics would encourage long-term thinking, and that this would be beneficial, then it seems to me that we should push some of these people towards the research and practice of brain preservation. For example, perhaps http://80000hours.org/search?q=cryonics should have some results.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "L4Lkz4hXJZkaKSWmL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 26, "extendedScore": null, "score": 8.56495510531599e-07, "legacy": true, "legacyId": "13489", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T02:20:33.265Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - Reasoning About Evolutionary Psychology & History", "slug": "meetup-west-la-meetup-reasoning-about-evolutionary", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WaHjwchnSbEYMG2qz/meetup-west-la-meetup-reasoning-about-evolutionary", "pageUrlRelative": "/posts/WaHjwchnSbEYMG2qz/meetup-west-la-meetup-reasoning-about-evolutionary", "linkUrl": "https://www.lesswrong.com/posts/WaHjwchnSbEYMG2qz/meetup-west-la-meetup-reasoning-about-evolutionary", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20Reasoning%20About%20Evolutionary%20Psychology%20%26%20History&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20Reasoning%20About%20Evolutionary%20Psychology%20%26%20History%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWaHjwchnSbEYMG2qz%2Fmeetup-west-la-meetup-reasoning-about-evolutionary%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20Reasoning%20About%20Evolutionary%20Psychology%20%26%20History%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWaHjwchnSbEYMG2qz%2Fmeetup-west-la-meetup-reasoning-about-evolutionary", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWaHjwchnSbEYMG2qz%2Fmeetup-west-la-meetup-reasoning-about-evolutionary", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 177, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7k'>West LA Meetup - Reasoning About Evolutionary Psychology &amp; History</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, February 29th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> This week, we will talk about how to (and not to) reason about historical events, with an emphasis on <a href=\"http://en.wikipedia.org/wiki/Evolutionary_psychology\" rel=\"nofollow\">evolutionary psychology</a>. Take a look at some of the posts tagged <a href=\"http://lesswrong.com/tag/evpsych/\">evpsych</a> for some thought food.</p>\n\n<p>This is also a good time to browse <a href=\"http://lesswrong.com/recentposts\">recent posts</a>, which also make for good discussion!</p>\n\n<p>Don't worry if you don't have time to read anything, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7k'>West LA Meetup - Reasoning About Evolutionary Psychology &amp; History</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WaHjwchnSbEYMG2qz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 8.565039084366058e-07, "legacy": true, "legacyId": "13493", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Reasoning_About_Evolutionary_Psychology___History\">Discussion article for the meetup : <a href=\"/meetups/7k\">West LA Meetup - Reasoning About Evolutionary Psychology &amp; History</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 February 2012 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, February 29th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> This week, we will talk about how to (and not to) reason about historical events, with an emphasis on <a href=\"http://en.wikipedia.org/wiki/Evolutionary_psychology\" rel=\"nofollow\">evolutionary psychology</a>. Take a look at some of the posts tagged <a href=\"http://lesswrong.com/tag/evpsych/\">evpsych</a> for some thought food.</p>\n\n<p>This is also a good time to browse <a href=\"http://lesswrong.com/recentposts\">recent posts</a>, which also make for good discussion!</p>\n\n<p>Don't worry if you don't have time to read anything, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Reasoning_About_Evolutionary_Psychology___History1\">Discussion article for the meetup : <a href=\"/meetups/7k\">West LA Meetup - Reasoning About Evolutionary Psychology &amp; History</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - Reasoning About Evolutionary Psychology & History", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Reasoning_About_Evolutionary_Psychology___History", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - Reasoning About Evolutionary Psychology & History", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Reasoning_About_Evolutionary_Psychology___History1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T02:59:08.243Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Qualitatively Confused", "slug": "seq-rerun-qualitatively-confused", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tKurc22aznrN4RfcP/seq-rerun-qualitatively-confused", "pageUrlRelative": "/posts/tKurc22aznrN4RfcP/seq-rerun-qualitatively-confused", "linkUrl": "https://www.lesswrong.com/posts/tKurc22aznrN4RfcP/seq-rerun-qualitatively-confused", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Qualitatively%20Confused&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Qualitatively%20Confused%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtKurc22aznrN4RfcP%2Fseq-rerun-qualitatively-confused%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Qualitatively%20Confused%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtKurc22aznrN4RfcP%2Fseq-rerun-qualitatively-confused", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtKurc22aznrN4RfcP%2Fseq-rerun-qualitatively-confused", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>Today's post, <a href=\"/lw/om/qualitatively_confused/\">Qualitatively Confused</a> was originally published on 14 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Using qualitative, binary reasoning may make it easier to confuse belief and reality; if we use probability distributions, the distinction is much clearer.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ads/seq_rerun_the_quotation_is_not_the_referent/\">The Quotation is not the Referent</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tKurc22aznrN4RfcP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.565193180577112e-07, "legacy": true, "legacyId": "13497", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BwtBhqvTPGG2n2GuJ", "vs6j9KX5DMBnp2KxA", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T03:22:45.708Z", "modifiedAt": null, "url": null, "title": "'Facing the Singularity' podcast", "slug": "facing-the-singularity-podcast", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:35.395Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s6NeR8hoktaZYk3CD/facing-the-singularity-podcast", "pageUrlRelative": "/posts/s6NeR8hoktaZYk3CD/facing-the-singularity-podcast", "linkUrl": "https://www.lesswrong.com/posts/s6NeR8hoktaZYk3CD/facing-the-singularity-podcast", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20'Facing%20the%20Singularity'%20podcast&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A'Facing%20the%20Singularity'%20podcast%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs6NeR8hoktaZYk3CD%2Ffacing-the-singularity-podcast%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text='Facing%20the%20Singularity'%20podcast%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs6NeR8hoktaZYk3CD%2Ffacing-the-singularity-podcast", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs6NeR8hoktaZYk3CD%2Ffacing-the-singularity-podcast", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 108, "htmlBody": "<p>My online mini-book <em><a href=\"http://facingthesingularity.com/\">Facing the Singularity</a></em>&nbsp;now has a <a href=\"http://itunes.apple.com/us/podcast/facing-the-singularity/id501765396\">podcast</a>. Ratings and reviews on iTunes will be much appreciated, so as to direct people toward a rationality-informed approach to intelligence explosion.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Jaan_Tallinn\">Jaan Tallinn</a> has been passing my chapters around to people because they are concise explanations of key lemmas in the standard arguments on the need for Friendly AI. This is gratifying because it's <em>exactly</em>&nbsp;the purpose for which I'm writing them, and I encourage others to send people to these chapters as well.</p>\n<p>(I'm currently writing the final two chapters of the online book and recording readings of the other chapters for the podcast. A volunteer is doing the audio editing.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s6NeR8hoktaZYk3CD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 17, "extendedScore": null, "score": 8.56528753646908e-07, "legacy": true, "legacyId": "13498", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T04:05:32.521Z", "modifiedAt": null, "url": null, "title": "Brazilians, unite! and what is IERFH (portuguese)", "slug": "brazilians-unite-and-what-is-ierfh-portuguese", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/36fa4ZiGzY2i4gd3r/brazilians-unite-and-what-is-ierfh-portuguese", "pageUrlRelative": "/posts/36fa4ZiGzY2i4gd3r/brazilians-unite-and-what-is-ierfh-portuguese", "linkUrl": "https://www.lesswrong.com/posts/36fa4ZiGzY2i4gd3r/brazilians-unite-and-what-is-ierfh-portuguese", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brazilians%2C%20unite!%20and%20what%20is%20IERFH%20(portuguese)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrazilians%2C%20unite!%20and%20what%20is%20IERFH%20(portuguese)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F36fa4ZiGzY2i4gd3r%2Fbrazilians-unite-and-what-is-ierfh-portuguese%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brazilians%2C%20unite!%20and%20what%20is%20IERFH%20(portuguese)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F36fa4ZiGzY2i4gd3r%2Fbrazilians-unite-and-what-is-ierfh-portuguese", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F36fa4ZiGzY2i4gd3r%2Fbrazilians-unite-and-what-is-ierfh-portuguese", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 733, "htmlBody": "<p>Hi anglophones, this topic is only for brazilians, so someone may post in portuguese and part of this is in portuguese (We will translate it to english if necessary when the time comes).</p>\n<p>Hello Brazilians, I'm creating this topic because some misallocated questions were posed o<a href=\"/r/discussion/lw/ac3/meetup_s%C3%A3o_paulo_meetup/\">n this one.</a></p>\n<p>First, the numbers.In Less Wrong:</p>\n<p>Me, Gust, Paulovsk, zecaurubu, Gracunha, Mexamark, dyokomizo.</p>\n<p>From IERFH (Instituto &Eacute;tica, Racionalidade, e o Futuro da Humanidade)</p>\n<p>Leo Arruda, Jo&atilde;o Fabiano, me, Pierre , Jonatas Muller, Pablo,&nbsp; Lauro (paralelo), Rafael, plus 3 others.</p>\n<p>This makes us at least 17, almost one every 10 million people (not great...)</p>\n<p>Some of us are in S&atilde;o Paulo. About 10.</p>\n<p>Eventually, this topic may attract some others, and we can create a meeting.</p>\n<p>Now, regarding the question a few of you did, IERFH's mission:</p>\n<p>Gerar alto impacto positivo no longo prazo, produzindo conhecimentos e reunindo pessoas que contribuam para melhor pensar as quest&otilde;es &eacute;ticas que ir&atilde;o definir o futuro da humanidade.</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">About: Somos um time comprometido com fazer o mundo melhor, agora e no futuro. Para isso, estamos reunindo a comunidade brasileira de racionalistas, utilitaristas, transhumanistas, e outros entusiastas e tranformando ideais e teorias em a&ccedil;&otilde;es. Ao lado de grandes organiza&ccedil;&otilde;es internacionais de caridade, tecnologia e &eacute;tica, nos propomos a ser o vetor dos esforcos brasileiros nesses campos. O IERFH opera em 3 frentes: <span lang=\"en-US\">o</span><span lang=\"en-US\"> </span><span lang=\"en-US\">estudo</span><span lang=\"en-US\"> </span><span lang=\"en-US\">do</span><span lang=\"en-US\"> </span><span lang=\"en-US\">que</span><span lang=\"en-US\"> </span><span lang=\"en-US\">&eacute;</span><span lang=\"en-US\"> </span><span lang=\"en-US\">bom</span><span lang=\"en-US\"> </span><span lang=\"en-US\">e</span><span lang=\"en-US\"> </span><span lang=\"en-US\">deve</span><span lang=\"en-US\"> </span><span lang=\"en-US\">ser</span><span lang=\"en-US\"> </span><span lang=\"en-US\">buscado</span><span lang=\"en-US\"> </span><span lang=\"en-US\">e</span><span lang=\"en-US\"> </span><span lang=\"en-US\">preservado:</span><span lang=\"en-US\"> </span><span lang=\"en-US\">a</span> <span lang=\"en-US\">&Eacute;tica</span><span lang=\"en-US\"> </span><span lang=\"en-US\">Pura</span><span lang=\"en-US\"> </span><span lang=\"en-US\">e</span><span lang=\"en-US\"> </span><span lang=\"en-US\">Aplicada;</span><span lang=\"en-US\"> </span><span lang=\"en-US\">as</span><span lang=\"en-US\"> </span><span lang=\"en-US\">maneiras</span><span lang=\"en-US\"> </span><span lang=\"en-US\">mais</span><span lang=\"en-US\"> </span><span lang=\"en-US\">eficientes</span><span lang=\"en-US\"> </span><span lang=\"en-US\">de</span><span lang=\"en-US\"> </span><span lang=\"en-US\">racioc&iacute;nio,</span><span lang=\"en-US\"> </span><span lang=\"en-US\">tomada</span><span lang=\"en-US\"> </span><span lang=\"en-US\">de</span><span lang=\"en-US\"> </span><span lang=\"en-US\">decis&otilde;es</span><span lang=\"en-US\"> </span><span lang=\"en-US\">e</span><span lang=\"en-US\"> </span><span lang=\"en-US\">os</span><span lang=\"en-US\"> </span><span lang=\"en-US\">seus</span><span lang=\"en-US\"> </span><span lang=\"en-US\">erros</span><span lang=\"en-US\"> </span><span lang=\"en-US\">mais</span><span lang=\"en-US\"> </span><span lang=\"en-US\">comuns:</span><span lang=\"en-US\"> </span><span lang=\"en-US\">a</span><span lang=\"en-US\"> </span><span lang=\"en-US\">Racionalidade</span><span lang=\"en-US\"> </span><span lang=\"en-US\">Epist&ecirc;mica</span><span lang=\"en-US\"> </span><span lang=\"en-US\">e</span><span lang=\"en-US\"> </span><span lang=\"en-US\">Pr&aacute;tica;</span><span lang=\"en-US\"> </span><span lang=\"en-US\">e</span><span lang=\"en-US\"> </span><span lang=\"en-US\">por</span><span lang=\"en-US\"> </span><span lang=\"en-US\">fim</span><span lang=\"en-US\"> </span><span lang=\"en-US\">como</span><span lang=\"en-US\"> </span><span lang=\"en-US\">aplicar</span><span lang=\"en-US\"> </span><span lang=\"en-US\">estes</span><span lang=\"en-US\"> </span><span lang=\"en-US\">campos</span><span lang=\"en-US\"> </span><span lang=\"en-US\">para</span><span lang=\"en-US\"> </span><span lang=\"en-US\">garantir</span><span lang=\"en-US\"> </span><span lang=\"en-US\">a</span><span lang=\"en-US\"> </span><span lang=\"en-US\">plena</span><span lang=\"en-US\"> </span><span lang=\"en-US\">realiza&ccedil;&atilde;o</span><span lang=\"en-US\"> </span><span lang=\"en-US\">de</span><span lang=\"en-US\"> </span><span lang=\"en-US\">todo</span><span lang=\"en-US\"> </span><span lang=\"en-US\">o</span><span lang=\"en-US\"> </span><span lang=\"en-US\">potencial</span><span lang=\"en-US\"> </span><span lang=\"en-US\">humano:</span><span lang=\"en-US\"> </span><span lang=\"en-US\">o</span><span lang=\"en-US\"> </span><span lang=\"en-US\">Futuro</span><span lang=\"en-US\"> </span><span lang=\"en-US\">da</span><span lang=\"en-US\"> </span><span lang=\"en-US\">Humanidade</span>&nbsp;</p>\n<p>&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">Racionalidade: Ser racional &eacute; conseguir conquistar, com pouco disp&ecirc;ndio de recursos, aquele que se deseja, entre todos os cen&aacute;rios poss&iacute;veis que poderiam ter ocorrido. Racionalidade epist&ecirc;mica &eacute; a capacidade de entender com o mundo atual; Racionalidade pr&aacute;tica, a capacidade de guiar o mundo atual em dire&ccedil;&atilde;o ao mundo desejado. Para ser racional, duas capacidades s&atilde;o fundamentais, a capacidade de desviar dos bias cognitivos, falhas sistem&aacute;ticas da nossa cogni&ccedil;&atilde;o, e permitir que o conhecimento adquirido atinja todos os campos de nosso conhecimento, integrando a informa&ccedil;&atilde;o aprendida e garantindo que ela tenha um efeito proporcional em nossas vidas. Essa comunidade do IERFH pretende nos guiar nesse sentido.</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">Futuro da Humanidade: <span lang=\"en-US\">Para</span><span lang=\"en-US\"> </span><span lang=\"en-US\">guiar</span><span lang=\"en-US\"> </span><span lang=\"en-US\">o</span><span lang=\"en-US\"> </span><span lang=\"en-US\">futuro</span><span lang=\"en-US\"> </span><span lang=\"en-US\">da</span><span lang=\"en-US\"> </span><span lang=\"en-US\">humanidade</span><span lang=\"en-US\"> </span><span lang=\"en-US\">numa</span><span lang=\"en-US\"> </span><span lang=\"en-US\">dire&ccedil;&atilde;o</span><span lang=\"en-US\"> </span><span lang=\"pt-BR\">desej&aacute;vel,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">&eacute;</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">necess&aacute;rio,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">antes</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">de</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">tudo,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">desviar</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">dos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">grandes</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">riscos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">catastr&oacute;ficos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">de</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">origem</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">tecnol&oacute;gica</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">que</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">estamos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">criando</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">conforme</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">criamos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">novas</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">tecnologias.</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">Para</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">tal,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">&eacute;</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">tamb&eacute;m</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">necess&aacute;rio</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">compreender</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">e</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">corrigir</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">os</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">bias</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">cognitivos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">aos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">quais</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">nossos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">c&eacute;rebros</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">est&atilde;o</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">propensos.</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">Finalmente,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">garantidas</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">a</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">seguran&ccedil;a</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">de</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">nossos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">valores</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">fundamentais,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">e</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">corrigidos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">os</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">nossos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">desvios</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">de</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">racionalidade,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">podemos</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">seguir</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">adiante</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">na</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">realiza&ccedil;&atilde;o</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">de</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">todo</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">o</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">potencial</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">futuro</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">humano,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">atrav&eacute;s</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">de</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">biotecnologia,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">nanotecnologia,</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">intelig&ecirc;ncia</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">artificial</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">e</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">coordena&ccedil;&atilde;o</span><span lang=\"pt-BR\"> </span><span lang=\"pt-BR\">global.</span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">The missing part \"&Eacute;tica\" isn't written yet. But I think you get the general idea.Think Bostrom, think Utilitarianism.</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span lang=\"pt-BR\">Se acharam interessante a descri&ccedil;&atilde;o, talvez gostem <a href=\"http://brainstormers.wordpress.com/2010/10/18/altruistic-awesomeness-your-challenge/\">desse post</a>. Ou, para os familiarizados com Yudkowsky desse, <a href=\"/r/discussion/lw/af0/troubles_with_cev_part1_cev_sequence/\">sobre CEV</a>. <br /></span></p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">We are developing our website, that is why we still don't have one.</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">Given the broadness of our scope, we are, of course, in need of new people (specially to translate) but we will only post to less wrong about the group in detail (in english) in a few months. If you are interested, contact me in the private message section.&nbsp; We meet on skype, and rarely in Pinheiros, S&atilde;o Paulo.</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">I hope we can start to form a Brazilian rationalist community, both of less wrongers general, and within IERFH and thank Gust for the initiative of creating the meeting topic that made me write this one.</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\"><span lang=\"pt-BR\"><br /></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "36fa4ZiGzY2i4gd3r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 14, "extendedScore": null, "score": 8.565458405337738e-07, "legacy": true, "legacyId": "13499", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vgrouEE9PFwF9Typy", "pR5Wn7bJQWRPYNGsF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T04:15:30.309Z", "modifiedAt": null, "url": null, "title": "Troubles With CEV Part1 - CEV Sequence", "slug": "troubles-with-cev-part1-cev-sequence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.966Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pR5Wn7bJQWRPYNGsF/troubles-with-cev-part1-cev-sequence", "pageUrlRelative": "/posts/pR5Wn7bJQWRPYNGsF/troubles-with-cev-part1-cev-sequence", "linkUrl": "https://www.lesswrong.com/posts/pR5Wn7bJQWRPYNGsF/troubles-with-cev-part1-cev-sequence", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Troubles%20With%20CEV%20Part1%20-%20CEV%20Sequence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATroubles%20With%20CEV%20Part1%20-%20CEV%20Sequence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpR5Wn7bJQWRPYNGsF%2Ftroubles-with-cev-part1-cev-sequence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Troubles%20With%20CEV%20Part1%20-%20CEV%20Sequence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpR5Wn7bJQWRPYNGsF%2Ftroubles-with-cev-part1-cev-sequence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpR5Wn7bJQWRPYNGsF%2Ftroubles-with-cev-part1-cev-sequence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2545, "htmlBody": "<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong>The CEV Sequence Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The CEV sequence consists of three posts tackling important aspects of CEV. It covers conceptual, practical and computational problems of <a href=\"/singinst.org/upload/CEV.html\">CEV's current form</a>. <a href=\"/lw/a2f/on_what_selves_are_cev_sequence/\"><em>On What Selves Are</em></a> draws on analytic philosophy methods in order to clarify the concept of Self, which is necessary in order to understand whose volition is going to be extrapolated by a machine that implements the CEV procedure. <em>Troubles with CEV part1</em> and <a href=\"/r/discussion/lw/af1/troubles_with_cev_part2_cev_sequence/\"><em>Troubles with CEV part2</em></a> on the other hand describe several issues that will be faced by the CEV project if it is actually going to be implemented. Those issues are not of conceptual nature. Many of the objections shown come from scattered discussions found on the web. Finally, some alternatives to CEV are considered.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong>Troubles with CEV Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Starting with a summary of CEV, we proceed to show several objections to CEV. First, specific objections to the use of Coherence, Extrapolation, and Volition. Here Part1 ends. Then, in <a href=\"/r/discussion/lw/af1/troubles_with_cev_part2_cev_sequence/\">Part2</a>, we continue with objections related to the end product of performing a CEV, and finally, problems relating to the implementation of CEV. We then go on with a praise of CEV, pointing out particular strengths of the idea. We end by showing six alternatives to CEV that have been proposed, and considering their vices and virtues.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Meta</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">: I think Troubles With CEV Part1 and Part2 should be posted to Main. So on the comment section of Part2, I put a place to vote for or against this upgrade. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Troubles</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">with</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">CEV Part1</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Summary</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"> <span>of</span> <span>CEV</span></span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">To begin with, let us remember the most important slices of Coherent Extrapolated Volition (CEV).</span></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;Friendly AI requires: </span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt 63.7pt; text-align: justify; text-indent: -14.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">1.<span>&nbsp; </span>Solving the technical problems required to maintain a well-specified abstract invariant in a self-modifying goal system. (Interestingly, this problem is relatively straightforward from a theoretical standpoint.) </span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt 63.7pt; text-align: justify; text-indent: -14.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">2.<span>&nbsp; </span>Choosing something nice to do with the AI. This is about midway in theoretical hairiness between problems 1 and 3.</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt 63.7pt; text-align: justify; text-indent: -14.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">3.<span>&nbsp; </span>Designing a framework for an abstract invariant that doesn't <em>automatically</em> wipe out the human species. <em>This</em> <em>is</em> <em>the</em> <em>hard</em> <em>part.</em> </span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">But <em>right</em> <em>now</em> the question is whether the human species can field a non-pathetic force in defense of six billion lives and futures.&rdquo; </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><br /> <span style=\"color: black;\">&ldquo;</span>Friendliness is the easiest part of the problem to explain - the part that says what we <em>want</em>. Like explaining why you want to fly to London, versus explaining a Boeing 747; explaining toast, versus explaining a toaster oven. &rdquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&ldquo;To construe your volition, I need to define a dynamic for extrapolating your volition, given knowledge about you. In the case of an FAI, this knowledge might include a complete readout of your brain-state, or an approximate model of your mind-state. The FAI takes the knowledge of Fred's brainstate, and other knowledge possessed by the FAI (such as which box contains the diamond), does... something complicated... and out pops a construal of Fred's volition. </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">I shall refer to the \"something complicated\" as the <em>dynamic</em>.&rdquo;</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">This is essentially what CEV is: extrapolating Fred's mind and everyone else's in order to grok what Fred wants. This is performed from a reading of Fred's psychological states, be it through unlikely neurological paths, or through more coarse grained psychological paths. There is reason to think that a complete readout of a brain is overwhelmingly more complicated than a <em>very</em> <em>good</em> descriptive psychological approximation. We must make sure though that this approximation does not rely on our common human psychology to be understood. The descriptive approximation has to be understandable by AGI's, not only by evolutionarily engineered humans. Continuing the summary.</span></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&ldquo;</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">In poetic terms, our <em>coherent</em> <em>extrapolated</em> <em>volition</em> is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.&ldquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;<em>Had</em> <em>grown</em> <em>up</em> <em>farther</em> <em>together:</em> A model of <em>humankind's</em> <em>coherent</em> extrapolated volition should not extrapolate the person you'd become if you made your decisions alone in a padded cell. Part of our predictable existence is that we predictably interact with other people. A dynamic for CEV must take a shot at extrapolating human interactions, not just so that the extrapolation is closer to reality, but so that the extrapolation can encapsulate memetic and social forces contributing to niceness.&ldquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;the rule [is] that the Friendly AI should be consistent under reflection (which might involve the Friendly AI replacing itself with something else entirely).&rdquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&ldquo;</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The narrower the slice of the future that our CEV wants to actively steer humanity <em>into</em>, the <em>more</em> consensus required.&ldquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;The dynamic of extrapolated volition refracts through that cognitive complexity of human minds which lead us to care about all the other things we might want; love, laughter, life, fairness, fun, sociality, self-reliance, morality, naughtiness, and anything else we might treasure. &rdquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;It may be hard to get CEV right - come up with an AI dynamic such that our volition, as defined, is what we intuitively <em>want</em>. The technical challenge may be too hard; the problems I'm still working out may be impossible or ill-defined.</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&rdquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;The same people who aren't frightened by the prospect of making moral decisions for the whole human species lack the interdisciplinary background to know how much complexity there is in human psychology, and why our shared emotional psychology is an invisible background assumption in human interactions, and why their Ten Commandments only make sense if you're already a human. &rdquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;Even if our coherent extrapolated volition wants something other than a CEV, the programmers choose the starting point of this renormalization process; they must construct a <em>satisfactory</em> definition of volition to extrapolate an improved or optimal definition of volition. &rdquo;</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 0cm 0.0001pt 36pt; text-align: justify; text-indent: -18.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Troubles with CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">1) Stumbling</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> <span>on</span> <span>People, Detecting the Things CEV Will Extrapolate</span>:</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Concepts on which CEV relies that may be ill-defined, not having a stable consistent structure in thingspace.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">CEV relies on many concepts, most notably the concepts of coherence, extrapolation and volition. We will discuss the problems of coherence and extrapolation shortly, for now I'd like to invoke a deeper layer of conceptual problems regarding the execution of a CEV implementing machine. A CEV executing machine ought to be able to identify the kind of entities whose volitions matter to us, the machine must be able to grasp selfhood, or personhood. The concepts of self and person are mingled and complex, and due to their complexity I have dedicated a separate text to address the issue of incompleteness, anomalousness, and fine-grainedness of selves.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><span>&nbsp;</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">2) Troubles with coherence</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">2a) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Intrapersonal</span> </strong><span><strong>objection</strong>:</span> The volitions of the same person when in two different emotional states might be different - it&rsquo;s as if they are two different people. Is there any good criteria by which a person&rsquo;s &ldquo;ultimate&rdquo; volition may be determined? If not, is it certain that even the volitions of one person&rsquo;s multiple selves will be convergent? As explained in detail in Ainslie's &ldquo;Breakdown of Will&rdquo;, we are made of lots of tinier interacting time-slices whose conflicts cannot be ignored. My chocolate has value 3 now, 5 when it's in my mouth and 0 when I reconsider how quick the pleasure was and how long the fat will stay. Valuations not only interpersonally, but also <em>intrapersonally</em> <em>conflict.</em> The variation in what we value can be correlated with not only with different distances in time, but also different emotional states, priming, background assumptions and other ways in which reality hijacks brains for a period. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">2b) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Biological</span> <span>Onion</span> </strong><span><strong>objection</strong>:</span> Our volitions can be thought of to be like an onion, layers upon layers of beliefs and expectations. The suggestion made by CEV is that when you strip away the layers that do not cohere, you reach deeper regions of the onion. Now, and here is the catch, what if there is no way to get coherence unless you stripe away everything that is truly humane, and end up being left only with that which is biological. What if in service of coherence we end up stripping away everything that matters and end up only with our biological drives? There is little in common between Eliezer, Me and Al Qaeda terrorists, and most of it is in the so called reptilian brain. We may end up with a set of goals and desires that are nothing more than &ldquo;Eat Survive Reproduce,&rdquo; which would qualify as a major loss in the scheme of things. In this specific case, what ends up dominating CEV is what evolution wants, not what we want. Instead of creating a dynamic with a chance of creating the landscape of a Nice Place to Live, we end up with some exotic extrapolation of simple evolutionary drives. Let us call this failure mode <em>Defeated</em> <em>by</em> <em>Evolution.</em> We are <em><span>Defeated</span></em> <em><span>by</span></em> <em><span>Evolution</span></em> if at any time the destiny of earth becomes nothing more than darwinian evolution all over again, at a different level of complexity or at different speed. So if CEV ends up stripping the biological onion of its goals that matter, extrapolating only a biological core, we are defeated by evolution. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">3) Troubles with extrapolation</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">3a) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Small</span> <span>Accretions</span> <span>Objection</span></strong>: Are small accretions of intelligence analogous to small accretions of time in terms of identity? Is extrapolated person X still a reasonable political representative of person X? Are X's values desirably preserved when she is given small accretions of intelligence? Would X allow her extrapolation to vote for her?</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">This objection is made through an analogy. For countless time philosophers have argued about the immortality of the soul, the existence of the soul, the complexity of the soul and last but not least the identity of the soul with itself over time. <br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Advancements in the field of philosophy are sparse and usually controversial, and if we were depending on a major advance in understanding of the complexity of our soul we'd be in a bad situation. Luckily, our analogy relies on the issue of personal identity, where it appears as though the issue of personal identity has been treated in sufficient detail by the book <em>Reasons</em> <em>and</em> <em>Persons</em>, Derek Parfit's major contribution to philosophy: Covering cases from fission and fusion to teleportation and identity over time. It is identity over time which concerns us here; Are you the same person as the person you were yesterday? How about one year ago? Or ten years? Derek has helped the philosophical community by reframing the essential question, instead of asking whether X is the same over time, he asks if personal identity is <em>what</em> <em>matters</em>, that is, that which we want to preserve when we deny others the right of shooting us. More recently he develops the question in full detail in his &ldquo;Is Personal Identity What Matters?&rdquo;(2007) a long article were all the objections to his original view are countered in minute detail. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">We are left with a conception of identity over time not being what matters, and psychological relatedness being the best candidate to take its place. Personal identity is dissolved into a quantitative, not qualitative, question. How much are you the same and the one you were yesterday? Here some percentage enters the field, and once you know how much you are <em>like</em> the person you were yesterday, there is no further question about how much you <em>are</em> the person you were yesterday. We had been asking the <em>wrong</em> <em>question</em> for long, and we risk to be doing the same thing with CEV. What if extrapolation is a process that dissolves that which matters about us and our volitions? What if there is no transitivity of <em>what</em> <em>matters</em> between me and me+1 or me+2 in the intelligence scale? Then abstracting my extrapolation will not preserve what had to be preserved in the first place. To extrapolate our volition in case we knew more, thought faster and had grown up farther together is to accrue small quantities of intelligence during the dynamic, and doing this may be risky. Even if some of our possible extrapolations would end up generating part of a Nice Place to Be, we must be sure none of the other possible extrapolations actually happen. That is, we must make sure CEV doesn't extrapolate in a way that for each step of extrapolation, one slice of what matterness is lost. Just like small accretions of time make you every day less the person you were back in 2010, maybe small accretions of intelligence will be displacing ourselves from what is preserved. Maybe smarter versions of ourselves are not us at all - this is the <span>The</span> <span>Small</span> <span>Accretions</span> <span>Objection</span>.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4) Problems with the concept of Volition</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4a) </span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\"><a href=\"/lw/6ha/the_blueminimizing_robot\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: navy;\">Blue</span><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: navy;\"> minimizing robots (Yvain post)</span></a></span><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4b) Goals vs. Volitions</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">The machine's actions should be grounded in our preferences, but those preferences are complex and opaque, making our reports unreliable; to truly determine the volitions of people, there must be a previously recognized candidate predictor. We test the predictor in its ability to <em>describe</em> current humans volitions before we give it the task of comprehending <em>extrapolated</em> human volition.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4c) Want to want vs. Would want if thought faster, grew stronger together</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"> </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Eliezer suggests in CEV that we consider a mistake to give Fred box A if he wanted box A while thinking it contained a diamond, in case we know both that box B contains the diamond and that Fred wants the diamond. Fred's <em>volition,</em> we are told, is to have the diamond, and we must be careful to create machines that extrapolate volition, not mere wanting. This is good, but not enough. There is a sub-area of moral philosophy dedicated to understanding that which we value, and even though it may seem at firsthand that we value our volitions, the process that leads from wanting to having a volition is a different process than the one that leads from wanting to having a value. Values, as David Lewis has argued, are what we <em>want</em> <em>to</em> <em>want.</em> Volitions on the other hand are what we would ultimately want under less stringent conditions. Currently CEV does not consider the iterated wantness aspect of things we value (the want to want aspect). This is problematic in case our volitions do not happen to be constrained by what we value, that is, what we desire to desire. Suppose Fred knows that the diamond he thinks is in box A comes from a bloody conflict region. Fred hates bloodshed and he truly desires not to have desires for diamonds, he wants to be a person that doesn't want diamonds from conflict regions. Yet the flesh is weak and Fred, under the circumstance, really wants the diamond. Both Fred's current volition, and Fred's extrapolated volition would have him choose box B, if only he knew, and in neither case Fred's values have been duly considered. It may be argued that a good enough extrapolation would end up considering his disgust of war, but here we are talking not about a quantitative issue (how much improvement there was) but a qualitative leap (what kind of thing should be preserved). If it is the case, as I argue here, that we ought to preserve what we want to want, this must be done as a separate consideration, not as an addendum, to preserving our volitions, both current and extrapolated.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><a href=\"/r/discussion/lw/af1/troubles_with_cev_part2_cev_sequence/\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Continues in Part2 </span></a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W6QZYSNt5FgWgvbdT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pR5Wn7bJQWRPYNGsF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 6, "extendedScore": null, "score": 8.565498199931132e-07, "legacy": true, "legacyId": "13500", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong>The CEV Sequence Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The CEV sequence consists of three posts tackling important aspects of CEV. It covers conceptual, practical and computational problems of <a href=\"/singinst.org/upload/CEV.html\">CEV's current form</a>. <a href=\"/lw/a2f/on_what_selves_are_cev_sequence/\"><em>On What Selves Are</em></a> draws on analytic philosophy methods in order to clarify the concept of Self, which is necessary in order to understand whose volition is going to be extrapolated by a machine that implements the CEV procedure. <em>Troubles with CEV part1</em> and <a href=\"/r/discussion/lw/af1/troubles_with_cev_part2_cev_sequence/\"><em>Troubles with CEV part2</em></a> on the other hand describe several issues that will be faced by the CEV project if it is actually going to be implemented. Those issues are not of conceptual nature. Many of the objections shown come from scattered discussions found on the web. Finally, some alternatives to CEV are considered.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong>Troubles with CEV Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Starting with a summary of CEV, we proceed to show several objections to CEV. First, specific objections to the use of Coherence, Extrapolation, and Volition. Here Part1 ends. Then, in <a href=\"/r/discussion/lw/af1/troubles_with_cev_part2_cev_sequence/\">Part2</a>, we continue with objections related to the end product of performing a CEV, and finally, problems relating to the implementation of CEV. We then go on with a praise of CEV, pointing out particular strengths of the idea. We end by showing six alternatives to CEV that have been proposed, and considering their vices and virtues.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Meta</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">: I think Troubles With CEV Part1 and Part2 should be posted to Main. So on the comment section of Part2, I put a place to vote for or against this upgrade. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Troubles</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">with</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">CEV Part1</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"Summary_of_CEV\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Summary</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"> <span>of</span> <span>CEV</span></span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">To begin with, let us remember the most important slices of Coherent Extrapolated Volition (CEV).</span></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201cFriendly AI requires: </span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt 63.7pt; text-align: justify; text-indent: -14.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">1.<span>&nbsp; </span>Solving the technical problems required to maintain a well-specified abstract invariant in a self-modifying goal system. (Interestingly, this problem is relatively straightforward from a theoretical standpoint.) </span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt 63.7pt; text-align: justify; text-indent: -14.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">2.<span>&nbsp; </span>Choosing something nice to do with the AI. This is about midway in theoretical hairiness between problems 1 and 3.</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt 63.7pt; text-align: justify; text-indent: -14.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">3.<span>&nbsp; </span>Designing a framework for an abstract invariant that doesn't <em>automatically</em> wipe out the human species. <em>This</em> <em>is</em> <em>the</em> <em>hard</em> <em>part.</em> </span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">But <em>right</em> <em>now</em> the question is whether the human species can field a non-pathetic force in defense of six billion lives and futures.\u201d </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><br> <span style=\"color: black;\">\u201c</span>Friendliness is the easiest part of the problem to explain - the part that says what we <em>want</em>. Like explaining why you want to fly to London, versus explaining a Boeing 747; explaining toast, versus explaining a toaster oven. \u201d</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">\u201cTo construe your volition, I need to define a dynamic for extrapolating your volition, given knowledge about you. In the case of an FAI, this knowledge might include a complete readout of your brain-state, or an approximate model of your mind-state. The FAI takes the knowledge of Fred's brainstate, and other knowledge possessed by the FAI (such as which box contains the diamond), does... something complicated... and out pops a construal of Fred's volition. </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">I shall refer to the \"something complicated\" as the <em>dynamic</em>.\u201d</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">This is essentially what CEV is: extrapolating Fred's mind and everyone else's in order to grok what Fred wants. This is performed from a reading of Fred's psychological states, be it through unlikely neurological paths, or through more coarse grained psychological paths. There is reason to think that a complete readout of a brain is overwhelmingly more complicated than a <em>very</em> <em>good</em> descriptive psychological approximation. We must make sure though that this approximation does not rely on our common human psychology to be understood. The descriptive approximation has to be understandable by AGI's, not only by evolutionarily engineered humans. Continuing the summary.</span></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">\u201c</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">In poetic terms, our <em>coherent</em> <em>extrapolated</em> <em>volition</em> is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.\u201c</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201c<em>Had</em> <em>grown</em> <em>up</em> <em>farther</em> <em>together:</em> A model of <em>humankind's</em> <em>coherent</em> extrapolated volition should not extrapolate the person you'd become if you made your decisions alone in a padded cell. Part of our predictable existence is that we predictably interact with other people. A dynamic for CEV must take a shot at extrapolating human interactions, not just so that the extrapolation is closer to reality, but so that the extrapolation can encapsulate memetic and social forces contributing to niceness.\u201c</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201cthe rule [is] that the Friendly AI should be consistent under reflection (which might involve the Friendly AI replacing itself with something else entirely).\u201d</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">\u201c</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The narrower the slice of the future that our CEV wants to actively steer humanity <em>into</em>, the <em>more</em> consensus required.\u201c</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201cThe dynamic of extrapolated volition refracts through that cognitive complexity of human minds which lead us to care about all the other things we might want; love, laughter, life, fairness, fun, sociality, self-reliance, morality, naughtiness, and anything else we might treasure. \u201d</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201cIt may be hard to get CEV right - come up with an AI dynamic such that our volition, as defined, is what we intuitively <em>want</em>. The technical challenge may be too hard; the problems I'm still working out may be impossible or ill-defined.</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201d</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201cThe same people who aren't frightened by the prospect of making moral decisions for the whole human species lack the interdisciplinary background to know how much complexity there is in human psychology, and why our shared emotional psychology is an invisible background assumption in human interactions, and why their Ten Commandments only make sense if you're already a human. \u201d</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 14.15pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201cEven if our coherent extrapolated volition wants something other than a CEV, the programmers choose the starting point of this renormalization process; they must construct a <em>satisfactory</em> definition of volition to extrapolate an improved or optimal definition of volition. \u201d</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 0cm 0.0001pt 36pt; text-align: justify; text-indent: -18.15pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><strong id=\"Troubles_with_CEV\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Troubles with CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"1__Stumbling_on_People__Detecting_the_Things_CEV_Will_Extrapolate_\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">1) Stumbling</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> <span>on</span> <span>People, Detecting the Things CEV Will Extrapolate</span>:</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Concepts on which CEV relies that may be ill-defined, not having a stable consistent structure in thingspace.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">CEV relies on many concepts, most notably the concepts of coherence, extrapolation and volition. We will discuss the problems of coherence and extrapolation shortly, for now I'd like to invoke a deeper layer of conceptual problems regarding the execution of a CEV implementing machine. A CEV executing machine ought to be able to identify the kind of entities whose volitions matter to us, the machine must be able to grasp selfhood, or personhood. The concepts of self and person are mingled and complex, and due to their complexity I have dedicated a separate text to address the issue of incompleteness, anomalousness, and fine-grainedness of selves.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><span>&nbsp;</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"2__Troubles_with_coherence\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">2) Troubles with coherence</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">2a) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Intrapersonal</span> </strong><span><strong>objection</strong>:</span> The volitions of the same person when in two different emotional states might be different - it\u2019s as if they are two different people. Is there any good criteria by which a person\u2019s \u201cultimate\u201d volition may be determined? If not, is it certain that even the volitions of one person\u2019s multiple selves will be convergent? As explained in detail in Ainslie's \u201cBreakdown of Will\u201d, we are made of lots of tinier interacting time-slices whose conflicts cannot be ignored. My chocolate has value 3 now, 5 when it's in my mouth and 0 when I reconsider how quick the pleasure was and how long the fat will stay. Valuations not only interpersonally, but also <em>intrapersonally</em> <em>conflict.</em> The variation in what we value can be correlated with not only with different distances in time, but also different emotional states, priming, background assumptions and other ways in which reality hijacks brains for a period. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">2b) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Biological</span> <span>Onion</span> </strong><span><strong>objection</strong>:</span> Our volitions can be thought of to be like an onion, layers upon layers of beliefs and expectations. The suggestion made by CEV is that when you strip away the layers that do not cohere, you reach deeper regions of the onion. Now, and here is the catch, what if there is no way to get coherence unless you stripe away everything that is truly humane, and end up being left only with that which is biological. What if in service of coherence we end up stripping away everything that matters and end up only with our biological drives? There is little in common between Eliezer, Me and Al Qaeda terrorists, and most of it is in the so called reptilian brain. We may end up with a set of goals and desires that are nothing more than \u201cEat Survive Reproduce,\u201d which would qualify as a major loss in the scheme of things. In this specific case, what ends up dominating CEV is what evolution wants, not what we want. Instead of creating a dynamic with a chance of creating the landscape of a Nice Place to Live, we end up with some exotic extrapolation of simple evolutionary drives. Let us call this failure mode <em>Defeated</em> <em>by</em> <em>Evolution.</em> We are <em><span>Defeated</span></em> <em><span>by</span></em> <em><span>Evolution</span></em> if at any time the destiny of earth becomes nothing more than darwinian evolution all over again, at a different level of complexity or at different speed. So if CEV ends up stripping the biological onion of its goals that matter, extrapolating only a biological core, we are defeated by evolution. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"3__Troubles_with_extrapolation\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">3) Troubles with extrapolation</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">3a) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Small</span> <span>Accretions</span> <span>Objection</span></strong>: Are small accretions of intelligence analogous to small accretions of time in terms of identity? Is extrapolated person X still a reasonable political representative of person X? Are X's values desirably preserved when she is given small accretions of intelligence? Would X allow her extrapolation to vote for her?</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">This objection is made through an analogy. For countless time philosophers have argued about the immortality of the soul, the existence of the soul, the complexity of the soul and last but not least the identity of the soul with itself over time. <br></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Advancements in the field of philosophy are sparse and usually controversial, and if we were depending on a major advance in understanding of the complexity of our soul we'd be in a bad situation. Luckily, our analogy relies on the issue of personal identity, where it appears as though the issue of personal identity has been treated in sufficient detail by the book <em>Reasons</em> <em>and</em> <em>Persons</em>, Derek Parfit's major contribution to philosophy: Covering cases from fission and fusion to teleportation and identity over time. It is identity over time which concerns us here; Are you the same person as the person you were yesterday? How about one year ago? Or ten years? Derek has helped the philosophical community by reframing the essential question, instead of asking whether X is the same over time, he asks if personal identity is <em>what</em> <em>matters</em>, that is, that which we want to preserve when we deny others the right of shooting us. More recently he develops the question in full detail in his \u201cIs Personal Identity What Matters?\u201d(2007) a long article were all the objections to his original view are countered in minute detail. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">We are left with a conception of identity over time not being what matters, and psychological relatedness being the best candidate to take its place. Personal identity is dissolved into a quantitative, not qualitative, question. How much are you the same and the one you were yesterday? Here some percentage enters the field, and once you know how much you are <em>like</em> the person you were yesterday, there is no further question about how much you <em>are</em> the person you were yesterday. We had been asking the <em>wrong</em> <em>question</em> for long, and we risk to be doing the same thing with CEV. What if extrapolation is a process that dissolves that which matters about us and our volitions? What if there is no transitivity of <em>what</em> <em>matters</em> between me and me+1 or me+2 in the intelligence scale? Then abstracting my extrapolation will not preserve what had to be preserved in the first place. To extrapolate our volition in case we knew more, thought faster and had grown up farther together is to accrue small quantities of intelligence during the dynamic, and doing this may be risky. Even if some of our possible extrapolations would end up generating part of a Nice Place to Be, we must be sure none of the other possible extrapolations actually happen. That is, we must make sure CEV doesn't extrapolate in a way that for each step of extrapolation, one slice of what matterness is lost. Just like small accretions of time make you every day less the person you were back in 2010, maybe small accretions of intelligence will be displacing ourselves from what is preserved. Maybe smarter versions of ourselves are not us at all - this is the <span>The</span> <span>Small</span> <span>Accretions</span> <span>Objection</span>.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><br></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"4__Problems_with_the_concept_of_Volition\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4) Problems with the concept of Volition</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4a) </span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\"><a href=\"/lw/6ha/the_blueminimizing_robot\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: navy;\">Blue</span><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: navy;\"> minimizing robots (Yvain post)</span></a></span><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"4b__Goals_vs__Volitions\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4b) Goals vs. Volitions</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">The machine's actions should be grounded in our preferences, but those preferences are complex and opaque, making our reports unreliable; to truly determine the volitions of people, there must be a previously recognized candidate predictor. We test the predictor in its ability to <em>describe</em> current humans volitions before we give it the task of comprehending <em>extrapolated</em> human volition.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">4c) Want to want vs. Would want if thought faster, grew stronger together</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"> </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Eliezer suggests in CEV that we consider a mistake to give Fred box A if he wanted box A while thinking it contained a diamond, in case we know both that box B contains the diamond and that Fred wants the diamond. Fred's <em>volition,</em> we are told, is to have the diamond, and we must be careful to create machines that extrapolate volition, not mere wanting. This is good, but not enough. There is a sub-area of moral philosophy dedicated to understanding that which we value, and even though it may seem at firsthand that we value our volitions, the process that leads from wanting to having a volition is a different process than the one that leads from wanting to having a value. Values, as David Lewis has argued, are what we <em>want</em> <em>to</em> <em>want.</em> Volitions on the other hand are what we would ultimately want under less stringent conditions. Currently CEV does not consider the iterated wantness aspect of things we value (the want to want aspect). This is problematic in case our volitions do not happen to be constrained by what we value, that is, what we desire to desire. Suppose Fred knows that the diamond he thinks is in box A comes from a bloody conflict region. Fred hates bloodshed and he truly desires not to have desires for diamonds, he wants to be a person that doesn't want diamonds from conflict regions. Yet the flesh is weak and Fred, under the circumstance, really wants the diamond. Both Fred's current volition, and Fred's extrapolated volition would have him choose box B, if only he knew, and in neither case Fred's values have been duly considered. It may be argued that a good enough extrapolation would end up considering his disgust of war, but here we are talking not about a quantitative issue (how much improvement there was) but a qualitative leap (what kind of thing should be preserved). If it is the case, as I argue here, that we ought to preserve what we want to want, this must be done as a separate consideration, not as an addendum, to preserving our volitions, both current and extrapolated.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><a href=\"/r/discussion/lw/af1/troubles_with_cev_part2_cev_sequence/\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Continues in Part2 </span></a></p>", "sections": [{"title": "Summary of CEV", "anchor": "Summary_of_CEV", "level": 1}, {"title": "Troubles with CEV", "anchor": "Troubles_with_CEV", "level": 1}, {"title": "1) Stumbling on People, Detecting the Things CEV Will Extrapolate:", "anchor": "1__Stumbling_on_People__Detecting_the_Things_CEV_Will_Extrapolate_", "level": 1}, {"title": "2) Troubles with coherence", "anchor": "2__Troubles_with_coherence", "level": 1}, {"title": "3) Troubles with extrapolation", "anchor": "3__Troubles_with_extrapolation", "level": 1}, {"title": "4) Problems with the concept of Volition", "anchor": "4__Problems_with_the_concept_of_Volition", "level": 1}, {"title": "4b) Goals vs. Volitions", "anchor": "4b__Goals_vs__Volitions", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "10 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DGfPyJbynXZF9NGv4", "CCN5GjFnhsYiNRDCg", "hQHuXuRGZxxWXaPgg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T04:19:55.606Z", "modifiedAt": null, "url": null, "title": "Troubles With CEV Part2 - CEV Sequence", "slug": "troubles-with-cev-part2-cev-sequence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.054Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CCN5GjFnhsYiNRDCg/troubles-with-cev-part2-cev-sequence", "pageUrlRelative": "/posts/CCN5GjFnhsYiNRDCg/troubles-with-cev-part2-cev-sequence", "linkUrl": "https://www.lesswrong.com/posts/CCN5GjFnhsYiNRDCg/troubles-with-cev-part2-cev-sequence", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Troubles%20With%20CEV%20Part2%20-%20CEV%20Sequence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATroubles%20With%20CEV%20Part2%20-%20CEV%20Sequence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCCN5GjFnhsYiNRDCg%2Ftroubles-with-cev-part2-cev-sequence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Troubles%20With%20CEV%20Part2%20-%20CEV%20Sequence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCCN5GjFnhsYiNRDCg%2Ftroubles-with-cev-part2-cev-sequence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCCN5GjFnhsYiNRDCg%2Ftroubles-with-cev-part2-cev-sequence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2939, "htmlBody": "<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong>The CEV Sequence Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The  CEV sequence consists of three posts tackling important aspects of CEV.  It covers conceptual, practical and computational problems of <a href=\"/singinst.org/upload/CEV.html\">CEV's  current form</a>. <a href=\"/lw/a2f/on_what_selves_are_cev_sequence/\"><em>On What Selves Are</em></a> draws on analytic philosophy  methods in order to clarify the concept of Self, which is necessary in  order to understand whose volition is going to be extrapolated by a  machine that implements the CEV procedure. <a href=\"/r/discussion/lw/af0/troubles_with_cev_part1_cev_sequence/\"><em>Troubles with CEV part1</em></a> and <em>Troubles with CEV part2</em> on the other hand describe several issues that will be faced by the CEV  project if it is actually going to be implemented. Those issues are not  of conceptual nature. Many of the objections shown come from scattered  discussions found on the web. Finally, six alternatives to CEV are  considered. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong>Troubles with CEV Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Starting  with a summary of CEV, we proceed to show several objections to CEV.  First, specific objections to the use of Coherence, Extrapolation, and  Volition. Here Part1 ends. Then, in Part2, we continue with objections  related to the end product of performing a CEV, and finally, problems  relating to the implementation of CEV. We then go on with a praise of  CEV, pointing out particular strengths of the idea. We end by showing  six alternatives to CEV that have been proposed, and considering their  vices and virtues. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Meta</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">:  I think Troubles With CEV Part1 and Part2 should be posted to Main. So  on the comment section of Part2, I put a place to vote for or against  this upgrade. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Troubles</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">with</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">CEV Part2</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">5) Problems with the end product</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">5a) Singleton</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong> </strong><span><strong>Objection</strong>.</span> Even if all goes well and a machine executes the coherent extrapolated  volition of humanity, the self modifying code it is running is likely to  become the most powerful agent on earth (including individuals,  governments, industries and other machines) If such a superintelligence  unfolds, whichever goals it has (our CE volitions) it will be very  capable of implementing. This is a singleton scenario. A singleton is &ldquo;<em>[T]he  term refers to a world order in which there is a single decision-making  agency at the highest level. Among its powers would be (1) the ability  to prevent any threats (internal or external) to its own existence and  supremacy, and (2) the ability to exert effective control over major  features of its domain (including taxation and territorial allocation).&rdquo;</em>.  Even though at first sight the emergence of a singleton looks  totalitarian, there is good reason to establish a singleton as opposed  to several competing superintelligences. If a singleton is obtained, the  selective process of genetic and cultural evolution meets with a force  that can counter its own powers. Something other than selection of the  fittest takes place as the main developer of the course of history. This  is desirable for several reasons. Evolution favors flamboyant displays,  malthusian growth and in general a progressively lower income, with our  era being an exception in its relative abundance of resources.  Evolution operates on many levels (genes, memes, individuals,  institutions, groups) and there is conflict and survival of the fittest  in all of them. If evolution were to continue being the main driving  force of our society there is great likelihood that several of the  things we find valuable would be lost. Much of what we value has evolved  as signaling (dancing, singing, getting jokes) and it is likely that  some of that costly signaling would be lost without a controlling force  such as a singleton. For this reason, having a singleton can be  considered a good result in the grand scheme of things, and should not  constitute worry to the CEV project, despite initial impressions  otherwise. In fact if we do not have a singleton soon we will be <em><span>Defeated</span></em> <em><span>by</span></em> <em><span>Evolution</span></em> at the fastest level where evolution is occurring. At that level, the  fast growing agents gradually obtain the resources of the remaining  desirable agents until all resources are taken and desirable agents  become extinct<span style=\"color: black;\">.</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6) Problems of implementation</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6a) Shortage</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> </strong><span><strong>Objections</strong>.</span> To extract coherent extrapolated volitions from people seems to be not  only immensely complicated but also computationally costly. Yudkowsky  proposes in CEV that we should let this initial dynamic run for a few  minutes and then redesign its machine, implementing the code it develops  once it is mature. But what if maturity is not achieved? What if the  computational intractability of <em>muddled</em> concepts and <em>spread</em> overwhelm the computing capacity of the machine, or exceed the time it is given to process it's input? </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6b) Sample</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> </strong><span><strong>bias</strong>.</span> The CEV machine implements the volition of mankind, such is the  suggestion. But from what sample of people will it extrapolate?  Certainly it will not do a fine grained reading of everyone's  brainstates in order to start operating, it will more likely extrapolate  from sociological, anthropological and psychological information. Thus  its selection of groups extrapolated will matter a lot in the long run.  It may try to correct sampling bias by obtaining information about other  cultures (besides programmers culture and whichever other cultures it  starts with), but the </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">vastness  of human societal variation can be a hard challenge to overcome. We  want to fairly take into account everyone's values, rather than  privileging those of the <span style=\"color: black;\">designers.</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6c) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Indeterminacy</span> <span>Objection</span></strong>.  Suppose we implement the CEV of a group of people including three  catholics, a muslim and two atheists, all of them English speakers. What  if the CEV machine fails to consider the ethical divergence of their  moral judgments by <em>changing</em> <em>the</em> <em>meaning</em> of the word  'god'? While extrapolating, many linguistic tokens (words) will appear  (e.g. as parts of ethical imperatives). Since Quine's (1960) thesis of  indeterminacy of reference, we know that the meanings of words are  widely under-determined by their usage. A machine that reads my  brainstate looking for cues on how to CEV may find sufficiently few  mentions of a linguistic token such as 'god' that it ends up able to  attribute almost any meaning to it (analogous to L&ouml;wenheim-Skolem  theorem), and it may end up tampering with the token's meaning for the  wrong reasons (to increase coherence at cost of precision).</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">7) Praise of CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">7a) Bringing the issue to practical level</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Despite  all previous objections, CEV is a very large reduction in the problem  space of how to engineer a nice future. Yudkowsky's approach is the  first practical suggestion for how an artificial moral agent might do  something good, as opposed to destroying humanity. Simply starting the  debate of how to implement an ethical agent that is a machine built by  humans is already a formidable achievement. CEV sets the initial  grounding above which will be built stronger ideas for our bright  future.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">7b) Ethical strength of egalitarianism</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">CEV  is a morally egalitarian ethically designed theory. Each current human  stands in the same quantitative position relative to how much his  volition will contribute to the final sum. Even though the CEV  implementing machine will only extrapolate some subset of humans, it  will try to make that subset in as much as possible a political  representative of the whole. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8) Alternatives to CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">8a) The Nobel Prize CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Here  the suggestion is to do CEV on only a subset of humanity (which might  be necessary anyway for computational tractability). Phlebas asks:</span></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;[Suppose] you had to choose a certain subset of minds to participate in the initial dynamic?</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">What  springs to my mind is Nobel Prize winners, and I suspect that this too  is a Schelling point. This seems like a politically neutral selection of  distinguished human beings (particularly if we exclude the Peace Prize)  of superlative character and intellect.&rdquo;</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">In  the original CEV, the initial dynamic would have to either scan all  brains (unlikely) or else extrapolate predictions made with its  biological, sociological, anthropological and psychological resources  from a subset of brains, correcting for all correctable biases in its  original sample. This may be a very daunting task; It may just be easier  to preselect a group and extrapolate their volition. Which  computational procedures would you execute in order to be able to  extrapolate a set of Jews and Arabs if your initial sample were only  composed of Jews? That is, how can you predict extrapolated Arabs from  Jews? This would be the level of difficulty of the task we impose on CEV  if we let the original dynamic scan only western minds and try to  extrapolate Pirah&atilde;, Maori, Arab, and Japanese minds out of this initial  set. Instead of facing this huge multicultural demand, using Nobel  winners wouldn't detract away from the initial mindset originating the  CEV idea. The trade-off here is basically between democracy in one hand  and tractability on the other. Still Phlebas: &ldquo;I argue that the  practical difficulty of incorporating all humans into the CEV in the  first place is unduly great, and that the programming challenge is also  made more difficult by virtue of this choice. I consider any increase in  the level of difficulty in the bringing into existence of FAI to be  positively dangerous, on account of the fact that this increases the  window of time available for unscrupulous programmers to create uFAI. &ldquo;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">8b) Building Blocks for Artificial Moral Agents </span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">In  his article &ldquo;Building Blocks for Artificial Moral Agents&rdquo; Vincent  Wiegel provides several interesting particularities that must be  attended to when creating these agents: &ldquo;An agent can have as one of its  goals or desires to be a moral agent, but never as its only or primary  goal. So the implementation of moral reasoning capability must always be  in the context of some application in which it acts as a constraint on  the other goals and action.&rdquo; Another: &ldquo;[O]nce goals have been set, these  goals must have a certain stickiness. Permanent goal revision would  have a paralyzing effect on an agent and possibly prevent decision  making.&rdquo; Even though his paper doesn't exactly provide a substitute for  CEV, it provides several insights into the details that must be taken in  consideration when implementing AGI. To let go of the user-friendly  interface that the CEV paper has and to start thinking about how to go  about implementing moral agents on a more technical ground level I  suggest examining his paper as a good start. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8c) Normative approach</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">A  normative or deontological approach would have the artificial agent  following rules, that is, telling it what is or not allowed. Examples of  deontological approaches are Kant's maxim, Gert's ten principles in <em>Morality</em> and Asimov's three laws of robotics. A normative approach doesn't work  because there are several underdeterminations in telling the agent what  not to do, trillions of subtle ways to destroy everything that matters  without breaking any specific set of laws. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8d) Bottom up approaches</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8d.1) Associative Learning</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">There are two alternatives to CEV that would build from the bottom up, the first is <em>associative</em> <em>learning</em> implemented by a neural network reacting to moral feedback, and the second <em>evolutionary</em> <em>modeling</em> of iterated interacting agents until the cusp of emergence of &ldquo;natural&rdquo;  morality. In the first approach, we have a neural network learning  morality like children were thought to learn in the good old blank slate  days, by receiving moral feedback under several different contexts and  being rewarded or punished according to societal rules. The main  advantage here is tractability, algorithms for learning associatively  are known and tractable thus rendering the entire process  computationally viable. The disadvantage of this approach is  inscrutability, we have no clear access to where within the system the  moral organ is being implemented. If we cannot scrutinize it we wouldn't  be able to understand eventual failures. Just one possible failure will  suffice to show why bottom up associative approaches are flawed, that  is the case in which an AGI learns a utility function ascribing utility  to individuals self-described as 10 in their happiometers. This of  course would tile the universe with sets of particles vibrating as  little as possible to say &ldquo;I'm happy ten&rdquo; over and over again. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8d.2) Artificial Evolution</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">The  second bottom up approach consists of evolving morality from artificial  life forms. As is known, morality (or altruism) will evolve once  iterated game theoretic scenarios of certain complexity start taking  place in an evolving system of individuals. Pure rationality guides  individuals into being nice merely because someone might be nice in  return, or as Dawkins puts it, nice guys finish first. The proposal here  would then be that we let artificial life forms evolve to the point  where they become moral, and once they do, input AGI powers into those  entities. To understand why this wouldn't work, let me quote Allen,  Varner and Zinzer </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&ldquo;  In scaling these environments to more realistic environments,  evolutionary approaches are likely to be faced with some of the same  shortcomings of the associative learning approaches : namely that  sophisticated moral agents must also be capable of constructing an  abstract, theoretical conception of morality.&rdquo; If we are to end up with  abstract theories of morality, a safer path would be to inscribe the  theories to begin with, minimizing the risk of ending up with lower than  desirable level of moral discernment. I conclude that bottom up  approaches, by themselves, provide insufficient insight as to how to go  about building an Artificial Moral Agent such as the one CEV proposes. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">8e) Hybrid</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong> <span>holonic</span></strong> (\"Holonic\" is a useful word to describe the simultaneous application of  reductionism and holism, in which a single quality is simultaneously a  combination of parts and a part of a greater whole [Koestler67]</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\" lang=\"EN-US\">.</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"> Note that \"holonic\" does not imply strict hierarchy, only a general  flow from high-level to low-level and vice versa.&nbsp; For example, a single  feature detector may make use of the output of lower-level feature  detectors, and act in turn as an input to higher-level feature  detectors.&nbsp; The information contained in a mid-level feature is then the  holistic sum of many lower-level features, and also an element in the  sums produced by higher-level features.) </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;A  better alternative than any of the bottom up suggestions is to have a  hybrid model with both deontological and bottom up elements. Our  morality is partly hardwired and mostly software learning so that we are  hybrid moral systems. A hybrid system may for instance be a combination  of thorough learning of moral behavior by training plus Gert's set of  ten moral principles. The advantage of hybrid models is that they  combine partial scrutability with bottom up tractability and efficiency.  In this examination of alternatives to CEV a Hybrid Holonic model is  the best contestant and thus the one to which our research efforts  should be directed.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8f) Extrapolation of written desires</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Another  alternative to CEV would be to extrapolate not from reading a  brain-state, but from a set of written desires given by the programmers.  The reason for implementing this alternative would be the technical  non-feasibility of extrapolating from brain states. That is, if our  Artificial General Intelligence is unable to read minds but can  comprehend language. We should be prepared for this very real  possibility since language is countless times simpler than active  brains. To extrapolate from the entire mind is a nice ideal, but not  necessarily an achievable one. To consider which kinds of desires should  be written in such case is beyond the scope of this text.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong>8g)</strong> </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\"><a href=\"http://www.fungible.com/respect/paper.html\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: navy;\">Using Compassion and Respect to Motivate an Artificial Intelligence</span></a></span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Tim  Freeman proposes what is to my knowledge the most thorough and  interesting alternative to CEV to date. Tim builds up from Solomonoff  induction, Schmidhuber's Speed Prior and Hutters AIXI to develop an  algorithm that infers people's desires from their behavior. The  algorithm is exposed in graphic form, in Python and in abstract  descriptions in English. Tim's proposal is an alternative to CEV because  it does not extrapolate people's current volition, thus it could only  be used to produce a CV, not a CEV. His proposal deserves attention  because it does, unlike most others, take in consideration the Friendly  AI problem, and it actually comes with an implementation (though  idealized) of the ideas presented in the text, unlike CEV. By suggesting  a compassion coefficient and a (slightly larger) respect coefficient,  Tim is able to solve many use cases that any desirable and friendly AGI  will have to solve, in accordance to what seems moral and reasonable  from a <em>humane</em> point of view. The text is insightful, for example, to solve wire-heading, it suggests: &ldquo;</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The problem here is that we've assumed that the AI wants to optimize for my utility applied to <em>my</em> model of the real world, and in this scenario my model of the world  diverges permanently from the world itself. The solution is to use the  AI's model of the world instead. That is, the AI infers how my utility  is a function of the world (as I believe it to be), and it applies that  function to the world as the <em>AI</em> believes it to be to compute the  AI's utility.&ldquo; It appears to me that just as any serious approach to AGI  has to take in consideration Bayes, Speed Prior and AIXI, any approach  to the problem that CEV tries to solve will have to consider Tim's <span style=\"color: black;\">&ldquo;Using  Compassion and Respect to Motivate an Artificial Intelligence&rdquo; at some  point, even if only to point out its mistakes and how they can be solved  by posterior, more thoroughly devised algorithms. In summary, even  though Tim's proposal is severely incomplete, in that it does not  describe all, or even most steps that an AI must take in order to infer  intentions from behavior, it is still the most complete work that tries  to tackle this particular problem, while at the same time worrying about  Friendliness and humaneness.</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Studies  related to CEV are few, making each more valuable, some topics that I  have not had time to cover, but would like to suggest to prospective  researchers are: </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Solvability of remaining problems</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Historical perspectives on problems</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Likelihood of solving problems before 2050</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">How humans have dealt with unsolvable problems in the past</span></strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W6QZYSNt5FgWgvbdT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CCN5GjFnhsYiNRDCg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 10, "extendedScore": null, "score": 8.565513994411822e-07, "legacy": true, "legacyId": "13501", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong>The CEV Sequence Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The  CEV sequence consists of three posts tackling important aspects of CEV.  It covers conceptual, practical and computational problems of <a href=\"/singinst.org/upload/CEV.html\">CEV's  current form</a>. <a href=\"/lw/a2f/on_what_selves_are_cev_sequence/\"><em>On What Selves Are</em></a> draws on analytic philosophy  methods in order to clarify the concept of Self, which is necessary in  order to understand whose volition is going to be extrapolated by a  machine that implements the CEV procedure. <a href=\"/r/discussion/lw/af0/troubles_with_cev_part1_cev_sequence/\"><em>Troubles with CEV part1</em></a> and <em>Troubles with CEV part2</em> on the other hand describe several issues that will be faced by the CEV  project if it is actually going to be implemented. Those issues are not  of conceptual nature. Many of the objections shown come from scattered  discussions found on the web. Finally, six alternatives to CEV are  considered. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong>Troubles with CEV Summary</strong>: </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Starting  with a summary of CEV, we proceed to show several objections to CEV.  First, specific objections to the use of Coherence, Extrapolation, and  Volition. Here Part1 ends. Then, in Part2, we continue with objections  related to the end product of performing a CEV, and finally, problems  relating to the implementation of CEV. We then go on with a praise of  CEV, pointing out particular strengths of the idea. We end by showing  six alternatives to CEV that have been proposed, and considering their  vices and virtues. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Meta</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">:  I think Troubles With CEV Part1 and Part2 should be posted to Main. So  on the comment section of Part2, I put a place to vote for or against  this upgrade. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><br></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Troubles</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">with</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"> </span><span style=\"font-size: 18pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">CEV Part2</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"5__Problems_with_the_end_product\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">5) Problems with the end product</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">5a) Singleton</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong> </strong><span><strong>Objection</strong>.</span> Even if all goes well and a machine executes the coherent extrapolated  volition of humanity, the self modifying code it is running is likely to  become the most powerful agent on earth (including individuals,  governments, industries and other machines) If such a superintelligence  unfolds, whichever goals it has (our CE volitions) it will be very  capable of implementing. This is a singleton scenario. A singleton is \u201c<em>[T]he  term refers to a world order in which there is a single decision-making  agency at the highest level. Among its powers would be (1) the ability  to prevent any threats (internal or external) to its own existence and  supremacy, and (2) the ability to exert effective control over major  features of its domain (including taxation and territorial allocation).\u201d</em>.  Even though at first sight the emergence of a singleton looks  totalitarian, there is good reason to establish a singleton as opposed  to several competing superintelligences. If a singleton is obtained, the  selective process of genetic and cultural evolution meets with a force  that can counter its own powers. Something other than selection of the  fittest takes place as the main developer of the course of history. This  is desirable for several reasons. Evolution favors flamboyant displays,  malthusian growth and in general a progressively lower income, with our  era being an exception in its relative abundance of resources.  Evolution operates on many levels (genes, memes, individuals,  institutions, groups) and there is conflict and survival of the fittest  in all of them. If evolution were to continue being the main driving  force of our society there is great likelihood that several of the  things we find valuable would be lost. Much of what we value has evolved  as signaling (dancing, singing, getting jokes) and it is likely that  some of that costly signaling would be lost without a controlling force  such as a singleton. For this reason, having a singleton can be  considered a good result in the grand scheme of things, and should not  constitute worry to the CEV project, despite initial impressions  otherwise. In fact if we do not have a singleton soon we will be <em><span>Defeated</span></em> <em><span>by</span></em> <em><span>Evolution</span></em> at the fastest level where evolution is occurring. At that level, the  fast growing agents gradually obtain the resources of the remaining  desirable agents until all resources are taken and desirable agents  become extinct<span style=\"color: black;\">.</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"6__Problems_of_implementation\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6) Problems of implementation</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6a) Shortage</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> </strong><span><strong>Objections</strong>.</span> To extract coherent extrapolated volitions from people seems to be not  only immensely complicated but also computationally costly. Yudkowsky  proposes in CEV that we should let this initial dynamic run for a few  minutes and then redesign its machine, implementing the code it develops  once it is mature. But what if maturity is not achieved? What if the  computational intractability of <em>muddled</em> concepts and <em>spread</em> overwhelm the computing capacity of the machine, or exceed the time it is given to process it's input? </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6b) Sample</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> </strong><span><strong>bias</strong>.</span> The CEV machine implements the volition of mankind, such is the  suggestion. But from what sample of people will it extrapolate?  Certainly it will not do a fine grained reading of everyone's  brainstates in order to start operating, it will more likely extrapolate  from sociological, anthropological and psychological information. Thus  its selection of groups extrapolated will matter a lot in the long run.  It may try to correct sampling bias by obtaining information about other  cultures (besides programmers culture and whichever other cultures it  starts with), but the </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">vastness  of human societal variation can be a hard challenge to overcome. We  want to fairly take into account everyone's values, rather than  privileging those of the <span style=\"color: black;\">designers.</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">6c) The</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong> <span>Indeterminacy</span> <span>Objection</span></strong>.  Suppose we implement the CEV of a group of people including three  catholics, a muslim and two atheists, all of them English speakers. What  if the CEV machine fails to consider the ethical divergence of their  moral judgments by <em>changing</em> <em>the</em> <em>meaning</em> of the word  'god'? While extrapolating, many linguistic tokens (words) will appear  (e.g. as parts of ethical imperatives). Since Quine's (1960) thesis of  indeterminacy of reference, we know that the meanings of words are  widely under-determined by their usage. A machine that reads my  brainstate looking for cues on how to CEV may find sufficiently few  mentions of a linguistic token such as 'god' that it ends up able to  attribute almost any meaning to it (analogous to L\u00f6wenheim-Skolem  theorem), and it may end up tampering with the token's meaning for the  wrong reasons (to increase coherence at cost of precision).</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"7__Praise_of_CEV\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">7) Praise of CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"7a__Bringing_the_issue_to_practical_level\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">7a) Bringing the issue to practical level</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Despite  all previous objections, CEV is a very large reduction in the problem  space of how to engineer a nice future. Yudkowsky's approach is the  first practical suggestion for how an artificial moral agent might do  something good, as opposed to destroying humanity. Simply starting the  debate of how to implement an ethical agent that is a machine built by  humans is already a formidable achievement. CEV sets the initial  grounding above which will be built stronger ideas for our bright  future.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"7b__Ethical_strength_of_egalitarianism\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">7b) Ethical strength of egalitarianism</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">CEV  is a morally egalitarian ethically designed theory. Each current human  stands in the same quantitative position relative to how much his  volition will contribute to the final sum. Even though the CEV  implementing machine will only extrapolate some subset of humans, it  will try to make that subset in as much as possible a political  representative of the whole. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"8__Alternatives_to_CEV\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8) Alternatives to CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"8a__The_Nobel_Prize_CEV\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">8a) The Nobel Prize CEV</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">Here  the suggestion is to do CEV on only a subset of humanity (which might  be necessary anyway for computational tractability). Phlebas asks:</span></p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201c[Suppose] you had to choose a certain subset of minds to participate in the initial dynamic?</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0cm 1cm 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">What  springs to my mind is Nobel Prize winners, and I suspect that this too  is a Schelling point. This seems like a politically neutral selection of  distinguished human beings (particularly if we exclude the Peace Prize)  of superlative character and intellect.\u201d</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"margin-bottom: 6pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">In  the original CEV, the initial dynamic would have to either scan all  brains (unlikely) or else extrapolate predictions made with its  biological, sociological, anthropological and psychological resources  from a subset of brains, correcting for all correctable biases in its  original sample. This may be a very daunting task; It may just be easier  to preselect a group and extrapolate their volition. Which  computational procedures would you execute in order to be able to  extrapolate a set of Jews and Arabs if your initial sample were only  composed of Jews? That is, how can you predict extrapolated Arabs from  Jews? This would be the level of difficulty of the task we impose on CEV  if we let the original dynamic scan only western minds and try to  extrapolate Pirah\u00e3, Maori, Arab, and Japanese minds out of this initial  set. Instead of facing this huge multicultural demand, using Nobel  winners wouldn't detract away from the initial mindset originating the  CEV idea. The trade-off here is basically between democracy in one hand  and tractability on the other. Still Phlebas: \u201cI argue that the  practical difficulty of incorporating all humans into the CEV in the  first place is unduly great, and that the programming challenge is also  made more difficult by virtue of this choice. I consider any increase in  the level of difficulty in the bringing into existence of FAI to be  positively dangerous, on account of the fact that this increases the  window of time available for unscrupulous programmers to create uFAI. \u201c</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"8b__Building_Blocks_for_Artificial_Moral_Agents_\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">8b) Building Blocks for Artificial Moral Agents </span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">In  his article \u201cBuilding Blocks for Artificial Moral Agents\u201d Vincent  Wiegel provides several interesting particularities that must be  attended to when creating these agents: \u201cAn agent can have as one of its  goals or desires to be a moral agent, but never as its only or primary  goal. So the implementation of moral reasoning capability must always be  in the context of some application in which it acts as a constraint on  the other goals and action.\u201d Another: \u201c[O]nce goals have been set, these  goals must have a certain stickiness. Permanent goal revision would  have a paralyzing effect on an agent and possibly prevent decision  making.\u201d Even though his paper doesn't exactly provide a substitute for  CEV, it provides several insights into the details that must be taken in  consideration when implementing AGI. To let go of the user-friendly  interface that the CEV paper has and to start thinking about how to go  about implementing moral agents on a more technical ground level I  suggest examining his paper as a good start. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"8c__Normative_approach\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8c) Normative approach</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">A  normative or deontological approach would have the artificial agent  following rules, that is, telling it what is or not allowed. Examples of  deontological approaches are Kant's maxim, Gert's ten principles in <em>Morality</em> and Asimov's three laws of robotics. A normative approach doesn't work  because there are several underdeterminations in telling the agent what  not to do, trillions of subtle ways to destroy everything that matters  without breaking any specific set of laws. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"8d__Bottom_up_approaches\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8d) Bottom up approaches</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"8d_1__Associative_Learning\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8d.1) Associative Learning</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">There are two alternatives to CEV that would build from the bottom up, the first is <em>associative</em> <em>learning</em> implemented by a neural network reacting to moral feedback, and the second <em>evolutionary</em> <em>modeling</em> of iterated interacting agents until the cusp of emergence of \u201cnatural\u201d  morality. In the first approach, we have a neural network learning  morality like children were thought to learn in the good old blank slate  days, by receiving moral feedback under several different contexts and  being rewarded or punished according to societal rules. The main  advantage here is tractability, algorithms for learning associatively  are known and tractable thus rendering the entire process  computationally viable. The disadvantage of this approach is  inscrutability, we have no clear access to where within the system the  moral organ is being implemented. If we cannot scrutinize it we wouldn't  be able to understand eventual failures. Just one possible failure will  suffice to show why bottom up associative approaches are flawed, that  is the case in which an AGI learns a utility function ascribing utility  to individuals self-described as 10 in their happiometers. This of  course would tile the universe with sets of particles vibrating as  little as possible to say \u201cI'm happy ten\u201d over and over again. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><strong id=\"8d_2__Artificial_Evolution\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8d.2) Artificial Evolution</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; text-align: justify; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">The  second bottom up approach consists of evolving morality from artificial  life forms. As is known, morality (or altruism) will evolve once  iterated game theoretic scenarios of certain complexity start taking  place in an evolving system of individuals. Pure rationality guides  individuals into being nice merely because someone might be nice in  return, or as Dawkins puts it, nice guys finish first. The proposal here  would then be that we let artificial life forms evolve to the point  where they become moral, and once they do, input AGI powers into those  entities. To understand why this wouldn't work, let me quote Allen,  Varner and Zinzer </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">\u201c  In scaling these environments to more realistic environments,  evolutionary approaches are likely to be faced with some of the same  shortcomings of the associative learning approaches : namely that  sophisticated moral agents must also be capable of constructing an  abstract, theoretical conception of morality.\u201d If we are to end up with  abstract theories of morality, a safer path would be to inscribe the  theories to begin with, minimizing the risk of ending up with lower than  desirable level of moral discernment. I conclude that bottom up  approaches, by themselves, provide insufficient insight as to how to go  about building an Artificial Moral Agent such as the one CEV proposes. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">8e) Hybrid</span></strong><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"><strong> <span>holonic</span></strong> (\"Holonic\" is a useful word to describe the simultaneous application of  reductionism and holism, in which a single quality is simultaneously a  combination of parts and a part of a greater whole [Koestler67]</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\" lang=\"EN-US\">.</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\"> Note that \"holonic\" does not imply strict hierarchy, only a general  flow from high-level to low-level and vice versa.&nbsp; For example, a single  feature detector may make use of the output of lower-level feature  detectors, and act in turn as an input to higher-level feature  detectors.&nbsp; The information contained in a mid-level feature is then the  holistic sum of many lower-level features, and also an element in the  sums produced by higher-level features.) </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;A  better alternative than any of the bottom up suggestions is to have a  hybrid model with both deontological and bottom up elements. Our  morality is partly hardwired and mostly software learning so that we are  hybrid moral systems. A hybrid system may for instance be a combination  of thorough learning of moral behavior by training plus Gert's set of  ten moral principles. The advantage of hybrid models is that they  combine partial scrutability with bottom up tractability and efficiency.  In this examination of alternatives to CEV a Hybrid Holonic model is  the best contestant and thus the one to which our research efforts  should be directed.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"8f__Extrapolation_of_written_desires\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">8f) Extrapolation of written desires</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Another  alternative to CEV would be to extrapolate not from reading a  brain-state, but from a set of written desires given by the programmers.  The reason for implementing this alternative would be the technical  non-feasibility of extrapolating from brain states. That is, if our  Artificial General Intelligence is unable to read minds but can  comprehend language. We should be prepared for this very real  possibility since language is countless times simpler than active  brains. To extrapolate from the entire mind is a nice ideal, but not  necessarily an achievable one. To consider which kinds of desires should  be written in such case is beyond the scope of this text.</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\"><strong>8g)</strong> </span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\"><a href=\"http://www.fungible.com/respect/paper.html\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: navy;\">Using Compassion and Respect to Motivate an Artificial Intelligence</span></a></span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Tim  Freeman proposes what is to my knowledge the most thorough and  interesting alternative to CEV to date. Tim builds up from Solomonoff  induction, Schmidhuber's Speed Prior and Hutters AIXI to develop an  algorithm that infers people's desires from their behavior. The  algorithm is exposed in graphic form, in Python and in abstract  descriptions in English. Tim's proposal is an alternative to CEV because  it does not extrapolate people's current volition, thus it could only  be used to produce a CV, not a CEV. His proposal deserves attention  because it does, unlike most others, take in consideration the Friendly  AI problem, and it actually comes with an implementation (though  idealized) of the ideas presented in the text, unlike CEV. By suggesting  a compassion coefficient and a (slightly larger) respect coefficient,  Tim is able to solve many use cases that any desirable and friendly AGI  will have to solve, in accordance to what seems moral and reasonable  from a <em>humane</em> point of view. The text is insightful, for example, to solve wire-heading, it suggests: \u201c</span><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\" lang=\"EN-US\">The problem here is that we've assumed that the AI wants to optimize for my utility applied to <em>my</em> model of the real world, and in this scenario my model of the world  diverges permanently from the world itself. The solution is to use the  AI's model of the world instead. That is, the AI infers how my utility  is a function of the world (as I believe it to be), and it applies that  function to the world as the <em>AI</em> believes it to be to compute the  AI's utility.\u201c It appears to me that just as any serious approach to AGI  has to take in consideration Bayes, Speed Prior and AIXI, any approach  to the problem that CEV tries to solve will have to consider Tim's <span style=\"color: black;\">\u201cUsing  Compassion and Respect to Motivate an Artificial Intelligence\u201d at some  point, even if only to point out its mistakes and how they can be solved  by posterior, more thoroughly devised algorithms. In summary, even  though Tim's proposal is severely incomplete, in that it does not  describe all, or even most steps that an AI must take in order to infer  intentions from behavior, it is still the most complete work that tries  to tackle this particular problem, while at the same time worrying about  Friendliness and humaneness.</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Studies  related to CEV are few, making each more valuable, some topics that I  have not had time to cover, but would like to suggest to prospective  researchers are: </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"Solvability_of_remaining_problems\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Solvability of remaining problems</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"Historical_perspectives_on_problems\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Historical perspectives on problems</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"Likelihood_of_solving_problems_before_2050\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">Likelihood of solving problems before 2050</span></strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; line-height: 150%;\"><strong id=\"How_humans_have_dealt_with_unsolvable_problems_in_the_past\"><span style=\"font-size: 12pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\" lang=\"EN-US\">How humans have dealt with unsolvable problems in the past</span></strong></p>", "sections": [{"title": "5) Problems with the end product", "anchor": "5__Problems_with_the_end_product", "level": 1}, {"title": "6) Problems of implementation", "anchor": "6__Problems_of_implementation", "level": 1}, {"title": "7) Praise of CEV", "anchor": "7__Praise_of_CEV", "level": 1}, {"title": "7a) Bringing the issue to practical level", "anchor": "7a__Bringing_the_issue_to_practical_level", "level": 1}, {"title": "7b) Ethical strength of egalitarianism", "anchor": "7b__Ethical_strength_of_egalitarianism", "level": 1}, {"title": "8) Alternatives to CEV", "anchor": "8__Alternatives_to_CEV", "level": 1}, {"title": "8a) The Nobel Prize CEV", "anchor": "8a__The_Nobel_Prize_CEV", "level": 1}, {"title": "8b) Building Blocks for Artificial Moral Agents ", "anchor": "8b__Building_Blocks_for_Artificial_Moral_Agents_", "level": 1}, {"title": "8c) Normative approach", "anchor": "8c__Normative_approach", "level": 1}, {"title": "8d) Bottom up approaches", "anchor": "8d__Bottom_up_approaches", "level": 1}, {"title": "8d.1) Associative Learning", "anchor": "8d_1__Associative_Learning", "level": 1}, {"title": "8d.2) Artificial Evolution", "anchor": "8d_2__Artificial_Evolution", "level": 1}, {"title": "8f) Extrapolation of written desires", "anchor": "8f__Extrapolation_of_written_desires", "level": 1}, {"title": "Solvability of remaining problems", "anchor": "Solvability_of_remaining_problems", "level": 1}, {"title": "Historical perspectives on problems", "anchor": "Historical_perspectives_on_problems", "level": 1}, {"title": "Likelihood of solving problems before 2050", "anchor": "Likelihood_of_solving_problems_before_2050", "level": 1}, {"title": "How humans have dealt with unsolvable problems in the past", "anchor": "How_humans_have_dealt_with_unsolvable_problems_in_the_past", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 19}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DGfPyJbynXZF9NGv4", "pR5Wn7bJQWRPYNGsF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T05:53:10.432Z", "modifiedAt": null, "url": null, "title": "My summary of Eliezer's position on free will", "slug": "my-summary-of-eliezer-s-position-on-free-will", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:32.852Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Solvent", "createdAt": "2011-07-19T07:12:44.132Z", "isAdmin": false, "displayName": "Solvent"}, "userId": "a3sBsZXtAQacMDHfK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7JKJoAZd6iSPDpyM6/my-summary-of-eliezer-s-position-on-free-will", "pageUrlRelative": "/posts/7JKJoAZd6iSPDpyM6/my-summary-of-eliezer-s-position-on-free-will", "linkUrl": "https://www.lesswrong.com/posts/7JKJoAZd6iSPDpyM6/my-summary-of-eliezer-s-position-on-free-will", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20summary%20of%20Eliezer's%20position%20on%20free%20will&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20summary%20of%20Eliezer's%20position%20on%20free%20will%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JKJoAZd6iSPDpyM6%2Fmy-summary-of-eliezer-s-position-on-free-will%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20summary%20of%20Eliezer's%20position%20on%20free%20will%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JKJoAZd6iSPDpyM6%2Fmy-summary-of-eliezer-s-position-on-free-will", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JKJoAZd6iSPDpyM6%2Fmy-summary-of-eliezer-s-position-on-free-will", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 474, "htmlBody": "<p>I'm participating in a university course on free will. On the online forum, someone asked me to summarise Eliezer's solution to the free will problem, and I did it like this. Is it accurate in this form? How should I change it?</p>\n<p>&nbsp;</p>\n<p>&ldquo;I'll try to summarise Yudkowsky's argument.</p>\n<p>As Anneke pointed out, it's kinda difficult to decide what the concept of free will means. How would particles or humans behave differently if they had free will compared to if they didn't? It doesn't seem like our argument is about what we actually expect to see happening.</p>\n<p>This is similar to arguing about whether a tree falling in a deserted forest makes any noise. If two people are arguing about this, they probably agree that if we put a microphone in the forest, it would pick up vibrations. And they also agree that no-one is having the sense experience of hearing the tree fall. So they're arguing over what 'sound' means. Yudkowsky proposes a psychological reason why people may have that particular confusion, based on how human brains work.</p>\n<p>So with respect to free will, we can instead ask the question, &ldquo;Why would humans feel like they have free will?&rdquo; If we can answer this well enough, then hopefully we can dissolve the original question.</p>\n<p>It feels like I choose between some of my possible futures. I can imagine waking up tomorrow and going to my Engineering lecture, or staying in my room and using Facebook. Both of those imaginings feel equally 'possible'.</p>\n<p>Humans execute a decision making algorithm which is fairly similar to the following one.</p>\n<ol>\n<li>\n<p>List all your possible actions. For my lecture example, that was &ldquo;Go to lecture&rdquo; and &ldquo;Stay home.&rdquo;</p>\n</li>\n<li>\n<p>Predict the state of the universe after pretending that you will take each possible action. We end up with &ldquo;Buck has learnt stuff but not Facebooked&rdquo; and &ldquo;Buck has not learnt stuff but has Facebooked.&rdquo;</p>\n</li>\n<li>\n<p>Decide which is your favourite outcome. In this case, I'd rather have learnt stuff. So that's option 2.</p>\n</li>\n<li>\n<p>Execute the action associated with the best outcome. In this case, I'd go to my lecture.</p>\n</li>\n</ol>\n<p>Note that the above algorithm can be made more complex and powerful, for example by incorporating probability and quantifying your preferences as a utility function.</p>\n<p>As humans, our brains need the capacity to pretend that we could choose different things, so that we can imagine the outcomes, and pick effectively. The way our brain implements this is by considering those possible worlds which we could reach through our choices, and by treating them as possible.</p>\n<p>So now we have a fairly convincing explanation of why it would feel like we have free will, or the ability to choose between various actions: it's how our decision making algorithm feels from the inside.&rdquo;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb1b8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7JKJoAZd6iSPDpyM6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 20, "extendedScore": null, "score": 5.5e-05, "legacy": true, "legacyId": "13503", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 100, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T10:45:52.187Z", "modifiedAt": null, "url": null, "title": "Japan Weighed Evacuating Tokyo in Nuclear Crisis [link]", "slug": "japan-weighed-evacuating-tokyo-in-nuclear-crisis-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.348Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JFGk5nsyHMSiJHt7L/japan-weighed-evacuating-tokyo-in-nuclear-crisis-link", "pageUrlRelative": "/posts/JFGk5nsyHMSiJHt7L/japan-weighed-evacuating-tokyo-in-nuclear-crisis-link", "linkUrl": "https://www.lesswrong.com/posts/JFGk5nsyHMSiJHt7L/japan-weighed-evacuating-tokyo-in-nuclear-crisis-link", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Japan%20Weighed%20Evacuating%20Tokyo%20in%20Nuclear%20Crisis%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJapan%20Weighed%20Evacuating%20Tokyo%20in%20Nuclear%20Crisis%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJFGk5nsyHMSiJHt7L%2Fjapan-weighed-evacuating-tokyo-in-nuclear-crisis-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Japan%20Weighed%20Evacuating%20Tokyo%20in%20Nuclear%20Crisis%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJFGk5nsyHMSiJHt7L%2Fjapan-weighed-evacuating-tokyo-in-nuclear-crisis-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJFGk5nsyHMSiJHt7L%2Fjapan-weighed-evacuating-tokyo-in-nuclear-crisis-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 41, "htmlBody": "<p>An&nbsp;independent&nbsp;report shows Japan was much closer to nuclear disaster than previously reported.</p>\n<p><span style=\"font-family: georgia, 'times new roman', times, serif; font-size: 15px; line-height: 22px; text-align: left; \"><a href=\"http://www.nytimes.com/2012/02/28/world/asia/japan-considered-tokyo-evacuation-during-the-nuclear-crisis-report-says.html?_r=1\">&ldquo;Prime Minister Kan had his minuses and he had his lapses,&rdquo; Mr. Funabashi said, &ldquo;but his decision to storm into Tepco and demand that it not give up saved Japan.&rdquo;</a></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JFGk5nsyHMSiJHt7L", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -11, "extendedScore": null, "score": 8.567057648067731e-07, "legacy": true, "legacyId": "13513", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T11:25:52.384Z", "modifiedAt": null, "url": null, "title": "Rationality & Startups - The Workshop", "slug": "rationality-and-startups-the-workshop", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:58.443Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xEJ6thEndvFJ2QHKd/rationality-and-startups-the-workshop", "pageUrlRelative": "/posts/xEJ6thEndvFJ2QHKd/rationality-and-startups-the-workshop", "linkUrl": "https://www.lesswrong.com/posts/xEJ6thEndvFJ2QHKd/rationality-and-startups-the-workshop", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20%26%20Startups%20-%20The%20Workshop&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20%26%20Startups%20-%20The%20Workshop%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxEJ6thEndvFJ2QHKd%2Frationality-and-startups-the-workshop%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20%26%20Startups%20-%20The%20Workshop%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxEJ6thEndvFJ2QHKd%2Frationality-and-startups-the-workshop", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxEJ6thEndvFJ2QHKd%2Frationality-and-startups-the-workshop", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 246, "htmlBody": "<p>I have been given the opportunity to prepare a workshop for the General Assembly team in London. General Assembly is geared towards education of entrepreneurs and aspiring entrepreneurs and have been very successful in New York, now expanding to London. The workshops are 90 minutes long, and usually gather anywhere from 15 to 35 people who have paid to attend.</p>\n<p>While I considered doing something on concrete coding skills, I think by far the superior alternative (for myself and the audience) is to do a crash course on cognitive bias as it relates to startups, maybe throw in some other topics on rationality in a similar context.&nbsp;I am fairly confident that startups are an excellent testing ground for extreme rationality as they require exceptionally quick assimilation of new skills and knowledge, as well as demand rapid decisions with incomplete information.</p>\n<p>&nbsp;</p>\n<p>So, as part of the brainstorming for this, here are my questions for you:</p>\n<p>1.Do you think educating startup founders on cognitive bias/rationality will help them improve their outcomes?</p>\n<p>2.Which biases would especially affect startups? Which of these can be mitigated (either by knowing about them or by utilising explicit strategies)?</p>\n<p>3.What is a good way to use 90 minutes to get this information across?</p>\n<p>4.What prior material exists to introduce rationality in a fast-paced manner? What prior material exists that relates startups to rationality?</p>\n<p>5.Other relevant thoughts welcome</p>\n<p>&nbsp;</p>\n<p>Should I go ahead with this, I will of course make the deck available for any others who may want to do similar presentations elsewhere.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xEJ6thEndvFJ2QHKd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "13514", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T14:24:26.584Z", "modifiedAt": null, "url": null, "title": "Longecity funding cryo research [link]", "slug": "longecity-funding-cryo-research-link", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benquo", "createdAt": "2009-03-06T00:17:35.184Z", "isAdmin": false, "displayName": "Benquo"}, "userId": "nt2XsHkdksqZ3snNr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P8ixCtCbo4MvCq3Bq/longecity-funding-cryo-research-link", "pageUrlRelative": "/posts/P8ixCtCbo4MvCq3Bq/longecity-funding-cryo-research-link", "linkUrl": "https://www.lesswrong.com/posts/P8ixCtCbo4MvCq3Bq/longecity-funding-cryo-research-link", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Longecity%20funding%20cryo%20research%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALongecity%20funding%20cryo%20research%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP8ixCtCbo4MvCq3Bq%2Flongecity-funding-cryo-research-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Longecity%20funding%20cryo%20research%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP8ixCtCbo4MvCq3Bq%2Flongecity-funding-cryo-research-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP8ixCtCbo4MvCq3Bq%2Flongecity-funding-cryo-research-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 29, "htmlBody": "<p>I don't understand enough of the relevant science to evaluate the prospects of the research being funded here:</p>\n<p>http://www.longecity.org/forum/donate/goal-8-cryopreservation-research/</p>\n<p>If anyone here knows substantially more than me, does it look promising?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P8ixCtCbo4MvCq3Bq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 8.567931036133698e-07, "legacy": true, "legacyId": "13516", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T17:47:09.809Z", "modifiedAt": null, "url": null, "title": "Looking for Less Wronger's maths videos?", "slug": "looking-for-less-wronger-s-maths-videos", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.707Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Arepo", "createdAt": "2011-08-08T16:52:49.609Z", "isAdmin": false, "displayName": "Arepo"}, "userId": "dCzqQnzbhbeCS7QPx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7igLcDHLWFMdo9S4X/looking-for-less-wronger-s-maths-videos", "pageUrlRelative": "/posts/7igLcDHLWFMdo9S4X/looking-for-less-wronger-s-maths-videos", "linkUrl": "https://www.lesswrong.com/posts/7igLcDHLWFMdo9S4X/looking-for-less-wronger-s-maths-videos", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Looking%20for%20Less%20Wronger's%20maths%20videos%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALooking%20for%20Less%20Wronger's%20maths%20videos%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7igLcDHLWFMdo9S4X%2Flooking-for-less-wronger-s-maths-videos%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Looking%20for%20Less%20Wronger's%20maths%20videos%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7igLcDHLWFMdo9S4X%2Flooking-for-less-wronger-s-maths-videos", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7igLcDHLWFMdo9S4X%2Flooking-for-less-wronger-s-maths-videos", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 41, "htmlBody": "<p>A while ago I saw someone on here who'd linked back to his homepage, where he had dozens, possibly hundreds of bite-size maths tutorial videos. I'm now unable to find them, and wondering if anyone knows the videos I'm talking about?</p>\n<p>Ta,</p>\n<p>A</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7igLcDHLWFMdo9S4X", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": -2, "extendedScore": null, "score": 8.568741219426725e-07, "legacy": true, "legacyId": "13517", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T19:27:25.607Z", "modifiedAt": null, "url": null, "title": "Trapping AIs via utility indifference", "slug": "trapping-ais-via-utility-indifference", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.234Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g4khHmSckWe5PZYDA/trapping-ais-via-utility-indifference", "pageUrlRelative": "/posts/g4khHmSckWe5PZYDA/trapping-ais-via-utility-indifference", "linkUrl": "https://www.lesswrong.com/posts/g4khHmSckWe5PZYDA/trapping-ais-via-utility-indifference", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Trapping%20AIs%20via%20utility%20indifference&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATrapping%20AIs%20via%20utility%20indifference%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg4khHmSckWe5PZYDA%2Ftrapping-ais-via-utility-indifference%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Trapping%20AIs%20via%20utility%20indifference%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg4khHmSckWe5PZYDA%2Ftrapping-ais-via-utility-indifference", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg4khHmSckWe5PZYDA%2Ftrapping-ais-via-utility-indifference", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 462, "htmlBody": "<p>If you wanted to check whether your creations were prone to misbehaving, one way would be to leave a big juicy apple hanging&nbsp;tantalisingly&nbsp;from a very visible tree, turn your back for a while, and see what they get up to.</p>\n<p>That would work if you were God and your creations were essentially children. But if the creator is us and the creation is a super-intelligent AI, such '<a href=\"http://www.aleph.se/papers/oracleAI.pdf\">honey-pots</a>' and unlikely to work. They are tricks, and we shouldn't rely on being able to trick a being more intelligent than ourselves - unless its intelligence doesn't matter.</p>\n<p>We can use <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/18371/2010-1.pdf\">utility indifference</a>&nbsp;to construct such traps. Utility indifference can be informally summarised as:</p>\n<p style=\"padding-left: 30px;\">\"There is a stochastic event X which can output 0 or 1. We wish the AI act as if it believed that X=0, with certainty. It's problematic for the AI to have incorrect beliefs, so the result is achieved through the definition of the AI's utility function.\"</p>\n<p>Consider the following situation: a master AI that will create the source code of another, autonomous AI. The master AI is setup to produce the code of a Friendly AI, or a <a href=\"/lw/a39/the_mathematics_of_reduced_impact_help_needed/\">reduced impact</a> AI - but we're not sure if the master AI is trustworthy. It would be good to go through the code very carefully before unleashing it (or erasing it). But if the master AI knows this (and we must assume it does), then it will either obfuscate the dangerous parts or put traps in it, making it risky for us to look too closely.</p>\n<p>Then implement the following setup. The code travels through some stochastic event X, such that if X=0, the code is immediately&nbsp;transferred&nbsp;into a disciple AI, completely autonomous, which is at liberty to immediately modify its own code and erase any trace of what it was. If X=1, the code is instead copied to our hard drives for analysis. The AI is given some reason to keep the code short - maybe there is an increasing chance of the code getting erased the longer it is.</p>\n<p>On top of this, we implement utility indifference: the master AI will act as if it believed X=0 with certainty, while we have setup X so that X=1 with near-certainty. Then the master AI will be motivated to produce the shortest code compatible with its utility function, in the 'knowledge' that this code will be copied into a powerful autonomous AI, and will never be seen by humans. It has no incentive to trap its code - quite the reverse, as it wants to keep it short.</p>\n<p>And therefore we have all the time in the world to go through the code, looking for defection. Other ways of using utility indifference to trap AIs are no doubt possible, but this was the first setup that sprang to my mind.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g4khHmSckWe5PZYDA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 5, "extendedScore": null, "score": 8.569141977282955e-07, "legacy": true, "legacyId": "13469", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["8Nwg7kqAfCM46tuHq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-28T23:36:33.723Z", "modifiedAt": null, "url": null, "title": "Two phone apps that use Bayes to help doctors make better decisions [links]", "slug": "two-phone-apps-that-use-bayes-to-help-doctors-make-better", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:04.524Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CPqdGdNFXiEmuaxgn/two-phone-apps-that-use-bayes-to-help-doctors-make-better", "pageUrlRelative": "/posts/CPqdGdNFXiEmuaxgn/two-phone-apps-that-use-bayes-to-help-doctors-make-better", "linkUrl": "https://www.lesswrong.com/posts/CPqdGdNFXiEmuaxgn/two-phone-apps-that-use-bayes-to-help-doctors-make-better", "postedAtFormatted": "Tuesday, February 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Two%20phone%20apps%20that%20use%20Bayes%20to%20help%20doctors%20make%20better%20decisions%20%5Blinks%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATwo%20phone%20apps%20that%20use%20Bayes%20to%20help%20doctors%20make%20better%20decisions%20%5Blinks%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCPqdGdNFXiEmuaxgn%2Ftwo-phone-apps-that-use-bayes-to-help-doctors-make-better%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Two%20phone%20apps%20that%20use%20Bayes%20to%20help%20doctors%20make%20better%20decisions%20%5Blinks%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCPqdGdNFXiEmuaxgn%2Ftwo-phone-apps-that-use-bayes-to-help-doctors-make-better", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCPqdGdNFXiEmuaxgn%2Ftwo-phone-apps-that-use-bayes-to-help-doctors-make-better", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 37, "htmlBody": "<p><a href=\"http://www.the-hospitalist.org/details/article/1380153/Bayes_Theorem_Theres_an_App_for_That.html\">Bayes at the Bedside</a> and <a href=\"http://www.ivline.info/2011/07/rx-bayes-asks-whats-probability.html\">Rx-Bayes</a> come with databases of likelihood ratios and help doctors estimate probabilities from their phones. I met somebody at Singularity Summit 2011 who used one of them, but I can't remember which.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CPqdGdNFXiEmuaxgn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 8.570137928194634e-07, "legacy": true, "legacyId": "13518", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-29T00:17:19.278Z", "modifiedAt": null, "url": null, "title": "Meetup : Vancouver!", "slug": "meetup-vancouver-4", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JAmfJtTfF4RNpG44y/meetup-vancouver-4", "pageUrlRelative": "/posts/JAmfJtTfF4RNpG44y/meetup-vancouver-4", "linkUrl": "https://www.lesswrong.com/posts/JAmfJtTfF4RNpG44y/meetup-vancouver-4", "postedAtFormatted": "Wednesday, February 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vancouver!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vancouver!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJAmfJtTfF4RNpG44y%2Fmeetup-vancouver-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vancouver!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJAmfJtTfF4RNpG44y%2Fmeetup-vancouver-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJAmfJtTfF4RNpG44y%2Fmeetup-vancouver-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7l'>Vancouver!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 March 2012 02:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Vancouver!</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We've been meeting every week for a few months, but there are only a few of us. If you live in or near vancouver, you should come out and participate in our adventures.</p>\n\n<p>Sundays at 1400 has been the rule, venue is my house. Details and address are on the list: <a href=\"http://groups.google.com/group/vancouver-rationalists.\" rel=\"nofollow\">http://groups.google.com/group/vancouver-rationalists.</a></p>\n\n<p>We need more people and more ideas and more points of view, so please err on the side of coming out at least once.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7l'>Vancouver!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JAmfJtTfF4RNpG44y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 8.570300887703414e-07, "legacy": true, "legacyId": "13521", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vancouver_\">Discussion article for the meetup : <a href=\"/meetups/7l\">Vancouver!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 March 2012 02:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Vancouver!</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We've been meeting every week for a few months, but there are only a few of us. If you live in or near vancouver, you should come out and participate in our adventures.</p>\n\n<p>Sundays at 1400 has been the rule, venue is my house. Details and address are on the list: <a href=\"http://groups.google.com/group/vancouver-rationalists.\" rel=\"nofollow\">http://groups.google.com/group/vancouver-rationalists.</a></p>\n\n<p>We need more people and more ideas and more points of view, so please err on the side of coming out at least once.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vancouver_1\">Discussion article for the meetup : <a href=\"/meetups/7l\">Vancouver!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vancouver!", "anchor": "Discussion_article_for_the_meetup___Vancouver_", "level": 1}, {"title": "Discussion article for the meetup : Vancouver!", "anchor": "Discussion_article_for_the_meetup___Vancouver_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-29T01:11:21.707Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Reductionism", "slug": "seq-rerun-reductionism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.778Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZuowcfhkXdSwmmb9m/seq-rerun-reductionism", "pageUrlRelative": "/posts/ZuowcfhkXdSwmmb9m/seq-rerun-reductionism", "linkUrl": "https://www.lesswrong.com/posts/ZuowcfhkXdSwmmb9m/seq-rerun-reductionism", "postedAtFormatted": "Wednesday, February 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Reductionism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Reductionism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZuowcfhkXdSwmmb9m%2Fseq-rerun-reductionism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Reductionism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZuowcfhkXdSwmmb9m%2Fseq-rerun-reductionism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZuowcfhkXdSwmmb9m%2Fseq-rerun-reductionism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 181, "htmlBody": "<p>Today's post, <a href=\"/lw/on/reductionism/\">Reductionism</a> was originally published on 16 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>We build <em>models </em>of the universe that have many different levels of description. But so far as anyone has been able to determine, the <em>universe itself</em> has only the single level of fundamental physics - reality doesn't explicitly compute protons, only quarks.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/aex/seq_rerun_qualitatively_confused/\">Qualitatively Confused</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZuowcfhkXdSwmmb9m", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 8.570516954900539e-07, "legacy": true, "legacyId": "13528", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tPqQdLCuxanjhoaNs", "tKurc22aznrN4RfcP", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-29T09:33:00.489Z", "modifiedAt": null, "url": null, "title": "Personality tests?", "slug": "personality-tests", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.181Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3CQFDffRAmegZtQdT/personality-tests", "pageUrlRelative": "/posts/3CQFDffRAmegZtQdT/personality-tests", "linkUrl": "https://www.lesswrong.com/posts/3CQFDffRAmegZtQdT/personality-tests", "postedAtFormatted": "Wednesday, February 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Personality%20tests%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APersonality%20tests%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3CQFDffRAmegZtQdT%2Fpersonality-tests%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Personality%20tests%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3CQFDffRAmegZtQdT%2Fpersonality-tests", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3CQFDffRAmegZtQdT%2Fpersonality-tests", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 21, "htmlBody": "<p>Does anyone know of a freely available, short personality test that would be appropriate for estimating pairwise compatibility for wedding seating?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3CQFDffRAmegZtQdT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 0, "extendedScore": null, "score": 8.572523127975264e-07, "legacy": true, "legacyId": "13547", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-29T15:43:24.216Z", "modifiedAt": null, "url": null, "title": "'Utility maximization generalized'", "slug": "utility-maximization-generalized", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iGZJjP2tJzYh6d5gx/utility-maximization-generalized", "pageUrlRelative": "/posts/iGZJjP2tJzYh6d5gx/utility-maximization-generalized", "linkUrl": "https://www.lesswrong.com/posts/iGZJjP2tJzYh6d5gx/utility-maximization-generalized", "postedAtFormatted": "Wednesday, February 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20'Utility%20maximization%20generalized'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A'Utility%20maximization%20generalized'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiGZJjP2tJzYh6d5gx%2Futility-maximization-generalized%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text='Utility%20maximization%20generalized'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiGZJjP2tJzYh6d5gx%2Futility-maximization-generalized", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiGZJjP2tJzYh6d5gx%2Futility-maximization-generalized", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 93, "htmlBody": "<p>Paul Weirich's \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/Weirich-Utility-maximization-generalized.pdf\">Utility Maximization Generalized</a>\" (2008) may be of interest to those studying utility maximization in the context of non-ideal agents:</p>\n<blockquote>\n<p>\n<p>Theories of rationality advance principles that diff er in topic, scope, and assumptions. A typical&nbsp;version of the principle of utility maximization formulates a standard rather than a procedure for&nbsp;decisions, evaluates decisions comprehensively, and relies on idealizations. I generalize the&nbsp;principle by removing some idealizations and making adjustments for their absence. The&nbsp;generalizations accommodate agents who have incomplete probability and utility assignments&nbsp;and are imperfectly rational. Th ey also accommodate decision problems with unstable comparisons&nbsp;of options.</p>\n</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iGZJjP2tJzYh6d5gx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 8.574004940718723e-07, "legacy": true, "legacyId": "13548", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-29T15:59:39.750Z", "modifiedAt": null, "url": null, "title": "Another problem with CDT, involving Bell's Theorem", "slug": "another-problem-with-cdt-involving-bell-s-theorem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:05.479Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qs9MuDg9XAt5ndbxq/another-problem-with-cdt-involving-bell-s-theorem", "pageUrlRelative": "/posts/qs9MuDg9XAt5ndbxq/another-problem-with-cdt-involving-bell-s-theorem", "linkUrl": "https://www.lesswrong.com/posts/qs9MuDg9XAt5ndbxq/another-problem-with-cdt-involving-bell-s-theorem", "postedAtFormatted": "Wednesday, February 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Another%20problem%20with%20CDT%2C%20involving%20Bell's%20Theorem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnother%20problem%20with%20CDT%2C%20involving%20Bell's%20Theorem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqs9MuDg9XAt5ndbxq%2Fanother-problem-with-cdt-involving-bell-s-theorem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Another%20problem%20with%20CDT%2C%20involving%20Bell's%20Theorem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqs9MuDg9XAt5ndbxq%2Fanother-problem-with-cdt-involving-bell-s-theorem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqs9MuDg9XAt5ndbxq%2Fanother-problem-with-cdt-involving-bell-s-theorem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 140, "htmlBody": "<p><a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/02/Cavalcanti-Causation-decision-theory-and-Bells-Theorem-a-quantum-analogue-of-the-Newcomb-Problem.pdf\">Cavalcanti (2010)</a> describes another problem with causal decision theory:</p>\n<blockquote>\n<p>\n<p>I apply some of the lessons from quantum theory, in particular from Bell&rsquo;s theorem, to a&nbsp;debate on the foundations of decision theory and causation. By tracing a formal analogy&nbsp;between the basic assumptions of causal decision theory (CDT)&mdash;which was developed&nbsp;partly in response to Newcomb&rsquo;s problem&mdash;and those of a local hidden variable theory&nbsp;in the context of quantum mechanics, I show that an agent who acts according to CDT&nbsp;and gives any nonzero credence to some possible causal interpretations underlying quantum&nbsp;phenomena should bet against quantum mechanics in some feasible game scenarios&nbsp;involving entangled systems, no matter what evidence they acquire. As a consequence,&nbsp;either the most accepted version of decision theory is wrong, or it provides a practical&nbsp;distinction, in terms of the prescribed behaviour of rational agents, between some metaphysical&nbsp;hypotheses regarding the causal structure underlying quantum mechanics.</p>\n</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qs9MuDg9XAt5ndbxq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 8.574069996705601e-07, "legacy": true, "legacyId": "13549", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-29T16:39:40.714Z", "modifiedAt": null, "url": null, "title": "Singularity-oriented Sci-Fi collection to be published [link]", "slug": "singularity-oriented-sci-fi-collection-to-be-published-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:06.752Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NmJeQXDPq2hPqcj3a/singularity-oriented-sci-fi-collection-to-be-published-link", "pageUrlRelative": "/posts/NmJeQXDPq2hPqcj3a/singularity-oriented-sci-fi-collection-to-be-published-link", "linkUrl": "https://www.lesswrong.com/posts/NmJeQXDPq2hPqcj3a/singularity-oriented-sci-fi-collection-to-be-published-link", "postedAtFormatted": "Wednesday, February 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity-oriented%20Sci-Fi%20collection%20to%20be%20published%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity-oriented%20Sci-Fi%20collection%20to%20be%20published%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNmJeQXDPq2hPqcj3a%2Fsingularity-oriented-sci-fi-collection-to-be-published-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity-oriented%20Sci-Fi%20collection%20to%20be%20published%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNmJeQXDPq2hPqcj3a%2Fsingularity-oriented-sci-fi-collection-to-be-published-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNmJeQXDPq2hPqcj3a%2Fsingularity-oriented-sci-fi-collection-to-be-published-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>Sorry for the blogspammy link, it's the best summary I found.</p>\n<p><a href=\"http://upcoming4.me/media-news/book-news/item/8768-contents-of-digital-rapture-the-singularity-anthology-announced\">http://upcoming4.me/media-news/book-news/item/8768-contents-of-digital-rapture-the-singularity-anthology-announced</a></p>\n<p>Of interest is apparent inclusion of Nick Bostrom in the collection (not sure if it's his sci-fi or philo work)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NmJeQXDPq2hPqcj3a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 8.574230114929337e-07, "legacy": true, "legacyId": "13550", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-02-29T22:42:02.488Z", "modifiedAt": null, "url": null, "title": "Daniel Kahneman on Charlie Rose [video]", "slug": "daniel-kahneman-on-charlie-rose-video", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:05.516Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "komponisto", "createdAt": "2009-03-01T21:10:23.585Z", "isAdmin": false, "displayName": "komponisto"}, "userId": "h48TMtPzfimsEobTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fNLCHTBdb8RFYTy3P/daniel-kahneman-on-charlie-rose-video", "pageUrlRelative": "/posts/fNLCHTBdb8RFYTy3P/daniel-kahneman-on-charlie-rose-video", "linkUrl": "https://www.lesswrong.com/posts/fNLCHTBdb8RFYTy3P/daniel-kahneman-on-charlie-rose-video", "postedAtFormatted": "Wednesday, February 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Daniel%20Kahneman%20on%20Charlie%20Rose%20%5Bvideo%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADaniel%20Kahneman%20on%20Charlie%20Rose%20%5Bvideo%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfNLCHTBdb8RFYTy3P%2Fdaniel-kahneman-on-charlie-rose-video%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Daniel%20Kahneman%20on%20Charlie%20Rose%20%5Bvideo%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfNLCHTBdb8RFYTy3P%2Fdaniel-kahneman-on-charlie-rose-video", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfNLCHTBdb8RFYTy3P%2Fdaniel-kahneman-on-charlie-rose-video", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 26, "htmlBody": "<p>Daniel Kahneman (of Tversky and Kahneman fame) <a href=\"http://www.charlierose.com/view/interview/12185\">was interviewed</a> on <a href=\"http://en.wikipedia.org/wiki/Charlie_Rose_(talk_show)\">PBS's <em>Charlie Rose</em></a> last night, discussing his book <em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/?tag=vglnk-c319-20\">Thinking, Fast and Slow</a> </em>(reviewed <a href=\"/lw/87m/review_of_kahneman_thinking_fast_and_slow_2011/\">here</a> by lukeprog):</p>\n<p><a href=\"http://www.charlierose.com/view/interview/12185\">http://www.charlierose.com/view/interview/12185</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fNLCHTBdb8RFYTy3P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 8.575680297307449e-07, "legacy": true, "legacyId": "13551", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PipGvHwA9ZxYNgTyW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T02:04:45.775Z", "modifiedAt": null, "url": null, "title": "Meetup : Houston Meetup - 3/4", "slug": "meetup-houston-meetup-3-4", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cog", "createdAt": "2011-04-25T04:58:53.803Z", "isAdmin": false, "displayName": "Cog"}, "userId": "xkp87vCZ56dp2tWnN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4Zw32e3GvMuFxMsDk/meetup-houston-meetup-3-4", "pageUrlRelative": "/posts/4Zw32e3GvMuFxMsDk/meetup-houston-meetup-3-4", "linkUrl": "https://www.lesswrong.com/posts/4Zw32e3GvMuFxMsDk/meetup-houston-meetup-3-4", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Houston%20Meetup%20-%203%2F4&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Houston%20Meetup%20-%203%2F4%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Zw32e3GvMuFxMsDk%2Fmeetup-houston-meetup-3-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Houston%20Meetup%20-%203%2F4%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Zw32e3GvMuFxMsDk%2Fmeetup-houston-meetup-3-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Zw32e3GvMuFxMsDk%2Fmeetup-houston-meetup-3-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7m'>Houston Meetup - 3/4</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 March 2012 12:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, TX 77002, USA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Houston Less Wrong meet up group will reconvene this Sunday at 12:00PM at the local hackerspace. We'll be going over the third chapter of ET Jayne's \"The Logic of Science\" and working out the problems. Afterwards, many of us will be going rock climbing at a local gym.</p>\n\n<p>Communal breakfast food is usually available, but bring in some cash for the tip jar to compensate the hackerspace.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7m'>Houston Meetup - 3/4</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4Zw32e3GvMuFxMsDk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.576491781007217e-07, "legacy": true, "legacyId": "13562", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup___3_4\">Discussion article for the meetup : <a href=\"/meetups/7m\">Houston Meetup - 3/4</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 March 2012 12:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, TX 77002, USA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Houston Less Wrong meet up group will reconvene this Sunday at 12:00PM at the local hackerspace. We'll be going over the third chapter of ET Jayne's \"The Logic of Science\" and working out the problems. Afterwards, many of us will be going rock climbing at a local gym.</p>\n\n<p>Communal breakfast food is usually available, but bring in some cash for the tip jar to compensate the hackerspace.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup___3_41\">Discussion article for the meetup : <a href=\"/meetups/7m\">Houston Meetup - 3/4</a></h2>", "sections": [{"title": "Discussion article for the meetup : Houston Meetup - 3/4", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup___3_4", "level": 1}, {"title": "Discussion article for the meetup : Houston Meetup - 3/4", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup___3_41", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T03:37:45.606Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Explaining vs. Explaining Away", "slug": "seq-rerun-explaining-vs-explaining-away", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TaZ6CdiRbZfRLEMSz/seq-rerun-explaining-vs-explaining-away", "pageUrlRelative": "/posts/TaZ6CdiRbZfRLEMSz/seq-rerun-explaining-vs-explaining-away", "linkUrl": "https://www.lesswrong.com/posts/TaZ6CdiRbZfRLEMSz/seq-rerun-explaining-vs-explaining-away", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Explaining%20vs.%20Explaining%20Away&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Explaining%20vs.%20Explaining%20Away%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTaZ6CdiRbZfRLEMSz%2Fseq-rerun-explaining-vs-explaining-away%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Explaining%20vs.%20Explaining%20Away%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTaZ6CdiRbZfRLEMSz%2Fseq-rerun-explaining-vs-explaining-away", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTaZ6CdiRbZfRLEMSz%2Fseq-rerun-explaining-vs-explaining-away", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p>Today's post, <a href=\"/lw/oo/explaining_vs_explaining_away/\">Explaining vs. Explaining Away</a> was originally published on 17 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Explaining_vs._Explaining_Away\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Apparently \"the mere touch of cold philosophy\", i.e., the truth, has destroyed haunts in the air, gnomes in the mine, and rainbows. This calls to mind a rather different bit of verse:</blockquote>\n<blockquote></blockquote>\n<blockquote><br /></blockquote>\n<blockquote>One of these things</blockquote>\n<blockquote>Is not like the others</blockquote>\n<blockquote>One of these things</blockquote>\n<blockquote>Doesn't belong</blockquote>\n<blockquote><br /></blockquote>\n<blockquote>The air has been emptied of its haunts, and the mine de-gnomed&mdash;but the rainbow is still there!</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/afs/seq_rerun_reductionism/\">Reductionism</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TaZ6CdiRbZfRLEMSz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 8.576864088811289e-07, "legacy": true, "legacyId": "13571", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cphoF8naigLhRf3tu", "ZuowcfhkXdSwmmb9m", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T06:12:03.885Z", "modifiedAt": null, "url": null, "title": "Singularity Summit 2011 Workshop Report", "slug": "singularity-summit-2011-workshop-report", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:23.839Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/acxdcBuZPkvnM9TNM/singularity-summit-2011-workshop-report", "pageUrlRelative": "/posts/acxdcBuZPkvnM9TNM/singularity-summit-2011-workshop-report", "linkUrl": "https://www.lesswrong.com/posts/acxdcBuZPkvnM9TNM/singularity-summit-2011-workshop-report", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity%20Summit%202011%20Workshop%20Report&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity%20Summit%202011%20Workshop%20Report%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FacxdcBuZPkvnM9TNM%2Fsingularity-summit-2011-workshop-report%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity%20Summit%202011%20Workshop%20Report%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FacxdcBuZPkvnM9TNM%2Fsingularity-summit-2011-workshop-report", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FacxdcBuZPkvnM9TNM%2Fsingularity-summit-2011-workshop-report", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 34, "htmlBody": "<p><a href=\"http://intelligence.org/upload/Singularity%20Summit%202011%20Workshop%20Report.pdf\">Here</a> is a short new publication from the Singularity Institute, on the 2-day workshop that followed Singularity Summit 2011.</p>\n<p>Note the new publication design. We are currently <a href=\"/lw/a6m/si_wants_to_hire_a_remote_latex_guru/\">porting</a> our earlier publications to this template, too.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "acxdcBuZPkvnM9TNM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 8.577481900417084e-07, "legacy": true, "legacyId": "13577", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RPeSzu6b9XPdT6my6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T08:51:05.111Z", "modifiedAt": null, "url": null, "title": "Open Thread, March 1-15, 2012", "slug": "open-thread-march-1-15-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:08.686Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6hh94SQywpMSRe4o3/open-thread-march-1-15-2012", "pageUrlRelative": "/posts/6hh94SQywpMSRe4o3/open-thread-march-1-15-2012", "linkUrl": "https://www.lesswrong.com/posts/6hh94SQywpMSRe4o3/open-thread-march-1-15-2012", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20March%201-15%2C%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20March%201-15%2C%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6hh94SQywpMSRe4o3%2Fopen-thread-march-1-15-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20March%201-15%2C%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6hh94SQywpMSRe4o3%2Fopen-thread-march-1-15-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6hh94SQywpMSRe4o3%2Fopen-thread-march-1-15-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6hh94SQywpMSRe4o3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 8.578118676238e-07, "legacy": true, "legacyId": "13585", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 106, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T15:10:02.923Z", "modifiedAt": null, "url": null, "title": "March 2012 Media Thread", "slug": "march-2012-media-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:31.429Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QgkwP8RERFW788RPS/march-2012-media-thread", "pageUrlRelative": "/posts/QgkwP8RERFW788RPS/march-2012-media-thread", "linkUrl": "https://www.lesswrong.com/posts/QgkwP8RERFW788RPS/march-2012-media-thread", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20March%202012%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMarch%202012%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQgkwP8RERFW788RPS%2Fmarch-2012-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=March%202012%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQgkwP8RERFW788RPS%2Fmarch-2012-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQgkwP8RERFW788RPS%2Fmarch-2012-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 162, "htmlBody": "<div id=\"entry_t3_9t4\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<p>There was a <a class=\"fullwidth\" title=\"recentdiscussion\" href=\"/lw/92w/are_yearlymonthly_book_suggestion_threads_a_good\" target=\"_blank\">recent discussion</a> considering the idea of a monthly Book (later expanded to movies, links, etc) thread. The poll was pretty unanimous that this was A Good Idea (tm). The <a href=\"/r/discussion/lw/9t4/february_2012_media_thread/\">past</a> <a href=\"/lw/94z/january_2012_media_thread/\">two</a> threads have had a decent amount of activity, so let's keep going.<br /><br />Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing!</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting; this is a thread for sharing subjective experiences, and people should feel comfortable posting their personal opinion without fearing a karma backlash. If you disagree with a person's recommendation, please post a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please use the comment trees, which <a href=\"/lw/94z/january_2012_media_thread/5kos\">I was apparently too dumb to do</a>.</li>\n</ul>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QgkwP8RERFW788RPS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 8.579636523279415e-07, "legacy": true, "legacyId": "13586", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["E8gc4H7Xorx4ebq8d", "TcdsvL5mj44NwgES4", "xh3is79A7qkoMM6pu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T18:25:48.431Z", "modifiedAt": null, "url": null, "title": "Deradicalizing Islamist Extremists (DC, March 13)", "slug": "deradicalizing-islamist-extremists-dc-march-13", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:14.984Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LE3MfpatALGDvbGrd/deradicalizing-islamist-extremists-dc-march-13", "pageUrlRelative": "/posts/LE3MfpatALGDvbGrd/deradicalizing-islamist-extremists-dc-march-13", "linkUrl": "https://www.lesswrong.com/posts/LE3MfpatALGDvbGrd/deradicalizing-islamist-extremists-dc-march-13", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Deradicalizing%20Islamist%20Extremists%20(DC%2C%20March%2013)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeradicalizing%20Islamist%20Extremists%20(DC%2C%20March%2013)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLE3MfpatALGDvbGrd%2Fderadicalizing-islamist-extremists-dc-march-13%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Deradicalizing%20Islamist%20Extremists%20(DC%2C%20March%2013)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLE3MfpatALGDvbGrd%2Fderadicalizing-islamist-extremists-dc-march-13", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLE3MfpatALGDvbGrd%2Fderadicalizing-islamist-extremists-dc-march-13", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 466, "htmlBody": "<p>I've never been to a Rumi Forum event, but the topic (how individuals or groups abandon extremist groups and ideologies) and the key question (whether to try to change behavior or beliefs) are relevent to LessWrong.<a id=\"more\"></a></p>\n<p>Rumi Forum presents: \"Deradicalizing Islamist Extremists\", with Angel M. Rabasa, Senior Political Scientist, RAND Corporation<br />Wednesday March&nbsp; 13th,&nbsp; 2012<br />12:00 - 1:30 p.m.<br />at Rumi Forum, 1150 17th Street NW, Suite 408,&nbsp; Washington, D.C. 20036<br /><br />Free and open to the public (registration required)<br />Light lunch will be served<br /><br /><a href=\"http://rumiforum.us1.list-manage.com/track/click?u=ee9cbfee6c604085055350b93&amp;id=ee68fd446e&amp;e=9fc6fbcd2c\">Please Click to RSVP</a><br /><br />Considerable effort has been devoted to understanding the process of violent Islamist radicalization, but far less research has explored the equally important process of deradicalization, or how individuals or groups abandon extremist groups and ideologies.&nbsp; Proactive measures to prevent vulnerable individuals from radicalizing and to rehabilitate those who have already embraced extremism have been implemented, to varying degrees, in several Middle Eastern, Southeast Asian, and European countries. A key question is whether the objective of these programs should be disengagement (a change in behavior) or deradicalization (a change in beliefs) of militants.<br /><br />Rabasa will discuss the findings of the RAND monograph, Deradicalizing Islamist Extremists. The study analyzes deradicalization and counter-radicalization programs in the Middle East, Southeast Asia, and Europe assesses the strengths and weaknesses of these programs, and makes recommendations to governments on ways to promote and accelerate processes of deradicalization.<br /><br />Dr. Angel M. Rabasa is a senior political scientist at the RAND Corporation. He has written extensively about extremism, terrorism, and insurgency. He is the lead author of The Lessons of Mumbai (2009); Radical islam in East Africa (2009); The Rise of Political Islam in Turkey (2008); Ungoverned Territories: Understanding and Reducing Terrorism Risks (2007); Building Moderate Muslim Networks (2007); Beyond al-Qaeda, Part 1: The Global Jihadist Movement and Part 2: The Outer Rings of the Terrorist Universe (2006); and The Muslim World After 9/11 (2004). He has completed the research on patterns of Islamist radicalization and terrorism in Europe, and is currently working on a project on deradicalization of Islamist extremists.<br /><br />Other works include the international institute for Strategic Studies Adelphi Paper No. 358, Political Islam in Southeast Asia: Moderates, Radicals, and Terrorists(2003); The Military and Democracy in Indonesia: Challenges, Politics, and Power(2002), with John Haseman; and Indonesia's Transformation and the Stability of Southeast Asia (2001), with Peter Chalk. Before joining RAND, Rabasa served in the U.S. Departments of State and Defense. He is a member of the international institute for Strategic Studies, the international Studies Association, and the American Foreign Service Association. Rabasa has a B.A. and Ph.D. in history from Harvard University and was a Knox Fellow at St. Antony's College, Oxford University.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LE3MfpatALGDvbGrd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 8.580420772746183e-07, "legacy": true, "legacyId": "13587", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T19:02:39.214Z", "modifiedAt": null, "url": null, "title": "Status and Changing your Mind", "slug": "status-and-changing-your-mind", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:28.934Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BFvuW5WsNuCnawWw2/status-and-changing-your-mind", "pageUrlRelative": "/posts/BFvuW5WsNuCnawWw2/status-and-changing-your-mind", "linkUrl": "https://www.lesswrong.com/posts/BFvuW5WsNuCnawWw2/status-and-changing-your-mind", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Status%20and%20Changing%20your%20Mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStatus%20and%20Changing%20your%20Mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBFvuW5WsNuCnawWw2%2Fstatus-and-changing-your-mind%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Status%20and%20Changing%20your%20Mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBFvuW5WsNuCnawWw2%2Fstatus-and-changing-your-mind", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBFvuW5WsNuCnawWw2%2Fstatus-and-changing-your-mind", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 289, "htmlBody": "<p>When you hear powerful evidence or arguments that should get you to revise your beliefs, not only do all sorts of <a href=\"http://wiki.lesswrong.com/wiki/Bias\">cognitive biases</a> fight the changes but so do the social factors of status and face saving. Perhaps I've long been a vocal proponent of X which implies Y, and you show me that Y isn't always true. It's very hard to just straight up admit \"ok, I'm not a hardcore Xist anymore.\" There's a status loss in letting yourself be convinced.</p>\n<p>For a long time I thought that I was stronger than this, that saving face only mattered as much as I let it matter. I wish I could freely admit when I've been convinced, but I often can't manage to. [1] Instead I'll finish a conversation defending my earlier beliefs and only later start acting on my new ones.</p>\n<p>After a discussion where someone didn't admit to any change of mind, I'll often see them later having changed their behavior. So now if I'm trying to persuade someone I don't focus on securing verbal agreement. Instead I just try to be as convincing as possible, and notice if they come around later. [2]</p>\n<p><small><em>(I also posted this <a href=\"http://www.jefftk.com/news/2012-03-01.html\">on my blog</a>)</em></small></p>\n<p><br /> [1] This is not a helpful trait: I'd like other people to let me know when I'm wrong or when they have evidence I'm not considering, but if they never get the satisfaction of knowing they've convinced me they may just feel like they've wasted their time, and not try in the future. So I'm <a href=\"/r/discussion/lw/57c/it_is_ok_to_publicly_make_a_mistake_and_change/\">working on it</a>.</p>\n<p>[2] Keeping people from feeling personally invested in one side or the other of an argument is probably also helpful: I understand discussions are much more likely to convince bystanders than participants.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2EFq8dJbxKNzforjM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BFvuW5WsNuCnawWw2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 22, "extendedScore": null, "score": 5e-05, "legacy": true, "legacyId": "13589", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QmqP8FeQix5ebseyF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-01T23:09:51.062Z", "modifiedAt": null, "url": null, "title": "Art vs. science", "slug": "art-vs-science", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.450Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RMcZDMmhjsGa9ScXo/art-vs-science", "pageUrlRelative": "/posts/RMcZDMmhjsGa9ScXo/art-vs-science", "linkUrl": "https://www.lesswrong.com/posts/RMcZDMmhjsGa9ScXo/art-vs-science", "postedAtFormatted": "Thursday, March 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Art%20vs.%20science&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AArt%20vs.%20science%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRMcZDMmhjsGa9ScXo%2Fart-vs-science%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Art%20vs.%20science%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRMcZDMmhjsGa9ScXo%2Fart-vs-science", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRMcZDMmhjsGa9ScXo%2Fart-vs-science", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 261, "htmlBody": "<p>It struck me this morning that a key feature that distinguishes art from science is that art is studied in the context of the artist, while science is not.&nbsp; When you learn calculus, mechanics, or optics, you don't read Newton.&nbsp; Science has content that can be abstracted out of one context - including the context of its creation - and studied and used in other contexts.&nbsp; This is a defining characteristic.&nbsp; Whereas art can't be easily removed from its context - one could argue art <em>is</em> context.&nbsp; When we study art, we study the original work by a single artist, to get that artist's vision.</p>\n<p>(This isn't a defining characteristic of art - it wasn't true until the twelfth century, when writers and artists began signing their works.&nbsp; In ancient Greece, through the Middle Ages in Europe, the content, subject, or purpose of art was considered primary, in the same way that the content of science is today.&nbsp; \"Homer's\" Iliad was a collaborative project, in which many authors (presumably) agreed that the story was the important thing, not one author's vision of it, and (also presumably) added to it in much the way that science is cumulative today.&nbsp; Medieval art generally glorified the church or the state.)</p>\n<p>However, because this is the way western society views art today, we can use this as a test.&nbsp; Is it art or science?&nbsp; Well, is its teaching organized around the creators, or around the content?</p>\n<p>Philosophy and linguistics are somewhere between art and science by this test.&nbsp; So is symbolic AI, while data mining is pure science.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RMcZDMmhjsGa9ScXo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 8, "extendedScore": null, "score": 8.581558937353056e-07, "legacy": true, "legacyId": "13588", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T03:31:47.862Z", "modifiedAt": null, "url": null, "title": "The Singularity Institute is hiring remote editors!", "slug": "the-singularity-institute-is-hiring-remote-editors", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:01.587Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z6WNEnMtfpx6wcqrm/the-singularity-institute-is-hiring-remote-editors", "pageUrlRelative": "/posts/Z6WNEnMtfpx6wcqrm/the-singularity-institute-is-hiring-remote-editors", "linkUrl": "https://www.lesswrong.com/posts/Z6WNEnMtfpx6wcqrm/the-singularity-institute-is-hiring-remote-editors", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Singularity%20Institute%20is%20hiring%20remote%20editors!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Singularity%20Institute%20is%20hiring%20remote%20editors!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6WNEnMtfpx6wcqrm%2Fthe-singularity-institute-is-hiring-remote-editors%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Singularity%20Institute%20is%20hiring%20remote%20editors!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6WNEnMtfpx6wcqrm%2Fthe-singularity-institute-is-hiring-remote-editors", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6WNEnMtfpx6wcqrm%2Fthe-singularity-institute-is-hiring-remote-editors", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 173, "htmlBody": "<p>The Singularity Institute needs to hire remote editors. You don't need to be able to conquer the blank page or write good content, you just need to be able to polish completed 2nd drafts of articles and suggest small fixes to wording when ideas are slightly wrong or ambiguous. The work will usually consist in adding dozens of comments to a Google doc or Word doc.</p>\n<p>Pay is hourly and starts at $14/hr but that will rise if the product is good. You must be available to work at least 20 hrs/week to be considered.</p>\n<p>&nbsp;</p>\n<p>Perks:</p>\n<ol>\n<li>Work from home, with flexible hours.</li>\n<li>Age and credentials are irrelevant; only the product matters.</li>\n<li>Get paid to see early copies of (and contribute to) articles on things you're probably interested in already.</li>\n</ol>\n<p>&nbsp;</p>\n<p>If you're interested, <strong><a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dDU0WTgtWGFITWFUQnFDLUxhZE80TlE6MQ\">apply here</a></strong>. My assistant Denise will send you an example of the editing quality we want, and also an un-commented article for you to provide feedback on as an unpaid trial task. If your deliverable is good enough, I'll hire you.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z6WNEnMtfpx6wcqrm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 8.582608793420178e-07, "legacy": true, "legacyId": "13590", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T03:57:09.560Z", "modifiedAt": null, "url": null, "title": "The Singularity Institute is hiring remote HTML / WordPress workers!", "slug": "the-singularity-institute-is-hiring-remote-html-wordpress", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:28.193Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/si2wEsei8zkepDfY6/the-singularity-institute-is-hiring-remote-html-wordpress", "pageUrlRelative": "/posts/si2wEsei8zkepDfY6/the-singularity-institute-is-hiring-remote-html-wordpress", "linkUrl": "https://www.lesswrong.com/posts/si2wEsei8zkepDfY6/the-singularity-institute-is-hiring-remote-html-wordpress", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Singularity%20Institute%20is%20hiring%20remote%20HTML%20%2F%20WordPress%20workers!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Singularity%20Institute%20is%20hiring%20remote%20HTML%20%2F%20WordPress%20workers!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsi2wEsei8zkepDfY6%2Fthe-singularity-institute-is-hiring-remote-html-wordpress%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Singularity%20Institute%20is%20hiring%20remote%20HTML%20%2F%20WordPress%20workers!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsi2wEsei8zkepDfY6%2Fthe-singularity-institute-is-hiring-remote-html-wordpress", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsi2wEsei8zkepDfY6%2Fthe-singularity-institute-is-hiring-remote-html-wordpress", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<p>The Singularity Institute needs to hire remote HTML &amp; WordPress workers. (For example, we need to move dozens of Singularity Summit talk transcripts to our new WordPress site and fix any formatting errors that result from that move.) This requires basic knowledge of HTML and&nbsp;<a href=\"http://wordpress.org/\">WordPress</a>.</p>\n<p>Pay is hourly and starts at $12/hr but that will rise if the product is good. You must be available to work at least 20 hrs/week to be considered.</p>\n<p>&nbsp;</p>\n<p>Perks:</p>\n<ol>\n<li>Work from home, with flexible hours.</li>\n<li>Age and credentials are irrelevant; only the product matters.</li>\n</ol>\n<p>If you're interested, <strong><a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dG9hcGVpdjlTZXZfb2pSRHdLS2xhOFE6MA#gid=0\">apply here</a></strong>.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "si2wEsei8zkepDfY6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 8.582710452444991e-07, "legacy": true, "legacyId": "13606", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T04:57:40.767Z", "modifiedAt": null, "url": null, "title": "Cashing Out Cognitive Biases as Behavior", "slug": "cashing-out-cognitive-biases-as-behavior", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:00.139Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dMDmED5LyqZtTTh5A/cashing-out-cognitive-biases-as-behavior", "pageUrlRelative": "/posts/dMDmED5LyqZtTTh5A/cashing-out-cognitive-biases-as-behavior", "linkUrl": "https://www.lesswrong.com/posts/dMDmED5LyqZtTTh5A/cashing-out-cognitive-biases-as-behavior", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cashing%20Out%20Cognitive%20Biases%20as%20Behavior&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACashing%20Out%20Cognitive%20Biases%20as%20Behavior%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMDmED5LyqZtTTh5A%2Fcashing-out-cognitive-biases-as-behavior%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cashing%20Out%20Cognitive%20Biases%20as%20Behavior%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMDmED5LyqZtTTh5A%2Fcashing-out-cognitive-biases-as-behavior", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMDmED5LyqZtTTh5A%2Fcashing-out-cognitive-biases-as-behavior", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1058, "htmlBody": "<p>We believe cognitive biases and susceptibility lead to bad decisions and suboptimal performance. I&rsquo;d like to look at 2 interesting studies:</p>\n<p><a id=\"more\"></a></p>\n<ol style=\"list-style-type: decimal\">\n<li>\n<p><a href=\"http://sds.hss.cmu.edu/media/pdfs/fischhoff/Parker_FischhoffDMC.pdf\">Parker &amp; Fischhoff 2005</a>: &ldquo;Decision-making competence: External validation through an individual-differences approach&rdquo;</p>\n<p>compiled a number of questions for 7 cognitive biases and then asked questions about impulsiveness, number of sexual partners, etc to their 110 18&ndash;19 year olds, who also supplied some IQ, education, and thinking style metrics. The components for their &lsquo;DMC&rsquo; battery:</p>\n<ul>\n<li>Consistency in risk perception</li>\n<li>Recognizing social norms</li>\n<li>Resistance to sunk costs</li>\n<li>Resistance to framing</li>\n<li>Applying decision rules</li>\n<li>Path independence</li>\n<li>Under/overconfidence</li>\n</ul>\n</li>\n<li>\n<p><a href=\"http://sds.hss.cmu.edu/media/pdfs/fischhoff/admc-jpsp2007.pdf\">Bruine de Bruin et al 2007</a>: &ldquo;Individual Differences in Adult Decision-Making Competence&rdquo;</p>\n<p>They used the DMC as well, but also developed what we might call a 34-item index of bad decisions (the DOI): ever bought clothes you never wore, rented a movie you didn&rsquo;t watch, get expelled, file for bankruptcy, forfeit your driver&rsquo;s license, miss an airplane, bounced a check, drink until you vomited, etc. (pg 18&ndash;19 full list). The subjects were 360 18&ndash;88 year olds (average 48), with many of the same metrics gathered (education/IQ/thinking style).</p>\n</li>\n</ol>\n<p>Before continuing further, it might be interesting to write down what you expect the results to be. Controlling for IQ eliminates all interesting correlations? A few of the fallacies correlated, or all, or none? Education increases, decreases, or doesn&rsquo;t affect susceptibility? Fallacy susceptibility correlates strongly with risky behavior, &gt;0.5? Correlates strongly with the DOI results, &gt;0.5? Less for either? And so on.</p>\n<p>Are we done? Good, but first I&rsquo;d like to discuss why I was reading these papers: I recently received my copy of Keith Stanovich&rsquo;s 2010 book, <em>Rationality &amp; The Reflective Mind</em>. (It cost a cool $50 because I couldn&rsquo;t find anyone who would pirate the ebook version from Oxford Scholarship Online. So it goes.) It&rsquo;s fairly interesting - I&rsquo;m going to have to edit my DNB FAQ based on chapter 3 - and presents a two-process model of IQ and rationality, arguing that lack of reflection or meta-cognition explains why IQ tests can accurately measure IQ but still fail to correlate as much as one would expect with performance measures like the Cognitive Reflection Test. Naturally, one of the first things I did was go through the index and look at the pages dealing with sunk cost so I could use them in <a href=\"http://www.gwern.net/Sunk%20cost\">my essay</a>; Bruine de Bruin et al 2007 was the first useful reference to pop up, and once I read that, I had to return to Parker &amp; Fischhoff 2005, which I had previously used only as a citation for the lack of correlation between IQ and sunk cost vulnerability.</p>\n<p>The sunk cost material in these 2 studies is interesting: they replicated the minimal correlation of sunk cost avoidance with IQ, but sunk cost (and &lsquo;path independence&rsquo;) exhibited fascinating behaviors compared to the other biases/fallacies measured: sunk cost &amp; path independence correlated minimally with the other biases/fallacies, Cronbach&rsquo;s alpha were almost uselessly low (in the first one, 0.03! Wikipedia tells me good reliability only starts at 0.50&hellip;), education did not help much, age helped some, and sunk cost had low correlations before corrections with the risky behavior or the DOI (eg. after controlling for decision-making styles, 0.13).</p>\n<p>This alone is very interesting. I wound up arguing as I read through the sunk cost literature that it was probably not a serious issue, but this is actually far more striking a result than I expected. I expected sunk cost to correlate with the other biases, just on the general type&ndash;1/type&ndash;2 reasoning (people falling for the intuitively appealing sunk cost answer and not reflecting carefully on the question&rsquo;s exact logical structure), and to have to point out that this is just a correlation which could be explained in general like that, and to point out further that this wouldn&rsquo;t show that training sunk cost avoidance would improve any bad behavior - any more than memorizing vocabulary genuinely improves your IQ score. But it turns out there&rsquo;s not much of a correlation for me to have to explain away! And we&rsquo;re talking about some 470 test subjects here, which is larger than most of the studies I use in the essay in the first place!</p>\n<p>Now, for the other questions. The fallacies don&rsquo;t factor out very well any general &lsquo;rationality quotient&rsquo;: a single factor explains 25% of Parker &amp; Fischhoff. Bruine de Bruin does a little better:</p>\n<blockquote>\n<p>&ldquo;Table 4 further shows a two-factor solution using the principal factors method with oblimin rotation, which allows nonorthogonal factors. The two factors account for 46.2% of the variance and are correlated (r \u03ed .30, p \u03fd .001). Except for Resistance to Sunk Costs and Path Independence, all tasks have loadings of at least .30 on the first factor. These loadings resemble those of the one-factor solution. Recognizing Social Norms, Resistance to Sunk Costs, and Path Independence have a higher loading on the second factor, but the latter remains under .30. The two-factor solution does not correspond to the three-factor solution reported for the Y-DMC (Parker &amp; Fischhoff, 2005). Nor does either factor solution correspond to any of the three task characteristics highlighted in Table 1: response mode, criterion, or general decision-making skills.&rdquo;</p>\n</blockquote>\n<p>In contrast, I believe <em>g</em> as a single factor accounts for more than 50% of variance on IQ tests. If we look at table 3, page 8 of Bruine de Bruin, we see how each fallacy correlates with each other: the correlations tend to be 0&ndash;0.3, with nothing higher than 0.43 (&lsquo;Applying Decision Rules&rsquo; x &lsquo;Consistency in Risk Perception&rsquo;).</p>\n<p>And the practical cash out of susceptibility to this grab bag? Well, in Bruine de Bruin, we get correlations with the DOI (uncontrolled for SES/IQ/age/style) for each of the 7 not exceeding 0.26 and overall correlation of 0.29. (SES: 0.2; IQ: 0.26; age: 0.31; style: 0.14.)</p>\n<p>Is 0.3 the correlation you expected? Would training on those 7 fallacies affect the underlying cause of lower performance on the DOI? How much training would this take? Would it be worthwhile?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dMDmED5LyqZtTTh5A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 23, "extendedScore": null, "score": 8.582953048770017e-07, "legacy": true, "legacyId": "13607", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T05:15:54.878Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Fake Reductionism", "slug": "seq-rerun-fake-reductionism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:09.674Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8t2emPk7BTuWcs9NJ/seq-rerun-fake-reductionism", "pageUrlRelative": "/posts/8t2emPk7BTuWcs9NJ/seq-rerun-fake-reductionism", "linkUrl": "https://www.lesswrong.com/posts/8t2emPk7BTuWcs9NJ/seq-rerun-fake-reductionism", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fake%20Reductionism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fake%20Reductionism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8t2emPk7BTuWcs9NJ%2Fseq-rerun-fake-reductionism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fake%20Reductionism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8t2emPk7BTuWcs9NJ%2Fseq-rerun-fake-reductionism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8t2emPk7BTuWcs9NJ%2Fseq-rerun-fake-reductionism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 233, "htmlBody": "<p>Today's post, <a href=\"/lw/op/fake_reductionism/\">Fake Reductionism</a> was originally published on 17 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Fake_Reductionism\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>There is a very great distinction between being able to see where the rainbow comes from, and playing around with prisms to confirm it, and maybe making a rainbow yourself by spraying water droplets, versus some dour-faced philosopher just telling you, \"No, there's nothing special about the rainbow. Didn't you hear? Scientists have explained it away. Just something to do with raindrops or whatever. Nothing to be excited about.\" I think this distinction probably accounts for a hell of a lot of the deadly existential emptiness that supposedly accompanies scientific reductionism.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/agz/seq_rerun_explaining_vs_explaining_away/\">Explaining vs. Explaining Away</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8t2emPk7BTuWcs9NJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 8.583026147153758e-07, "legacy": true, "legacyId": "13608", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mTf8MkpAigm3HP6x2", "TaZ6CdiRbZfRLEMSz", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T07:28:21.698Z", "modifiedAt": null, "url": null, "title": "How do you notice when you're rationalizing?", "slug": "how-do-you-notice-when-you-re-rationalizing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:15.821Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LHnQGxHNweyrbbDLJ/how-do-you-notice-when-you-re-rationalizing", "pageUrlRelative": "/posts/LHnQGxHNweyrbbDLJ/how-do-you-notice-when-you-re-rationalizing", "linkUrl": "https://www.lesswrong.com/posts/LHnQGxHNweyrbbDLJ/how-do-you-notice-when-you-re-rationalizing", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20do%20you%20notice%20when%20you're%20rationalizing%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20do%20you%20notice%20when%20you're%20rationalizing%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLHnQGxHNweyrbbDLJ%2Fhow-do-you-notice-when-you-re-rationalizing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20do%20you%20notice%20when%20you're%20rationalizing%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLHnQGxHNweyrbbDLJ%2Fhow-do-you-notice-when-you-re-rationalizing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLHnQGxHNweyrbbDLJ%2Fhow-do-you-notice-when-you-re-rationalizing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<p>How do you notice when you're rationalizing? &nbsp;Like, what *actually* tips you off, in real life?</p>\n<p>I've listed my cues below; please add your own (one idea per comment), and upvote the comments that you either: (a) use; or (b) will now try using.</p>\n<p>I'll be using this list in a trial rationality seminar on Wednesday; it also sounds useful in general.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LHnQGxHNweyrbbDLJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 8.583555242059783e-07, "legacy": true, "legacyId": "13617", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 85, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T09:25:08.917Z", "modifiedAt": null, "url": null, "title": "How do you notice when you're procrastinating?", "slug": "how-do-you-notice-when-you-re-procrastinating", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.200Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alex_Altair", "createdAt": "2010-07-21T18:30:40.806Z", "isAdmin": false, "displayName": "Alex_Altair"}, "userId": "5wu9jG4pm9q6xjZ9R", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/q2wq3Xiou6xL78ktb/how-do-you-notice-when-you-re-procrastinating", "pageUrlRelative": "/posts/q2wq3Xiou6xL78ktb/how-do-you-notice-when-you-re-procrastinating", "linkUrl": "https://www.lesswrong.com/posts/q2wq3Xiou6xL78ktb/how-do-you-notice-when-you-re-procrastinating", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20do%20you%20notice%20when%20you're%20procrastinating%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20do%20you%20notice%20when%20you're%20procrastinating%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq2wq3Xiou6xL78ktb%2Fhow-do-you-notice-when-you-re-procrastinating%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20do%20you%20notice%20when%20you're%20procrastinating%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq2wq3Xiou6xL78ktb%2Fhow-do-you-notice-when-you-re-procrastinating", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq2wq3Xiou6xL78ktb%2Fhow-do-you-notice-when-you-re-procrastinating", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 134, "htmlBody": "<p>I'm going to steal <a href=\"/r/discussion/lw/ai9/how_do_you_notice_when_youre_rationalizing/\">Anna's idea</a> and change it to the instrumental side of rationality. In Luke's <a href=\"/lw/9wr/my_algorithm_for_beating_procrastination/\">algorithm</a> for beating procrastination, Step 1 is to <strong>Notice You Are Procrastinating</strong>. I'm not so sure this is easy. For me, the knowledge sort of fades in and out without being explicitly grabbed by my consciousness. If I actually held onto that fact, the moment that I was evading a task, and made it clear to myself that I was doing the sub-optimal, and the consequences involved, I think it would go a long way towards getting me to actually get things done.</p>\n<p>What do you use to catch it? How do you notice you're procrastinating? Leave your ideas below<span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;(one idea per comment), and upvote the comments that you either: (a) use; or (b) will now try using.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "q2wq3Xiou6xL78ktb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 8.584025349701474e-07, "legacy": true, "legacyId": "13618", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LHnQGxHNweyrbbDLJ", "Ty2tjPwv8uyPK9vrz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T12:51:33.661Z", "modifiedAt": null, "url": null, "title": "Meetup : Sydney - Core sequences", "slug": "meetup-sydney-core-sequences", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:30.584Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oklord", "createdAt": "2011-03-22T11:37:19.291Z", "isAdmin": false, "displayName": "Oklord"}, "userId": "EusNQMHkhmSq2k9Y9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wyQ9sXeTWksijE4Do/meetup-sydney-core-sequences", "pageUrlRelative": "/posts/wyQ9sXeTWksijE4Do/meetup-sydney-core-sequences", "linkUrl": "https://www.lesswrong.com/posts/wyQ9sXeTWksijE4Do/meetup-sydney-core-sequences", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Sydney%20-%20Core%20sequences&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Sydney%20-%20Core%20sequences%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwyQ9sXeTWksijE4Do%2Fmeetup-sydney-core-sequences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Sydney%20-%20Core%20sequences%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwyQ9sXeTWksijE4Do%2Fmeetup-sydney-core-sequences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwyQ9sXeTWksijE4Do%2Fmeetup-sydney-core-sequences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 80, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7n'>Sydney - Core sequences</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 March 2012 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">22 the promenade sydney</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hey everybody. Deep inside the king street brewery, we'll be hopefully coming to a discussion of the core sequences, as suggested at the last meeting. Plus general hanging about!</p>\n\n<ol>\n<li>We have a FB group set up - just search Less wrong Sydney, or PM. </li>\n<li>Dates, as always are fungible.</li>\n</ol></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7n'>Sydney - Core sequences</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wyQ9sXeTWksijE4Do", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.584853033279756e-07, "legacy": true, "legacyId": "13619", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Sydney___Core_sequences\">Discussion article for the meetup : <a href=\"/meetups/7n\">Sydney - Core sequences</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 March 2012 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">22 the promenade sydney</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hey everybody. Deep inside the king street brewery, we'll be hopefully coming to a discussion of the core sequences, as suggested at the last meeting. Plus general hanging about!</p>\n\n<ol>\n<li>We have a FB group set up - just search Less wrong Sydney, or PM. </li>\n<li>Dates, as always are fungible.</li>\n</ol></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Sydney___Core_sequences1\">Discussion article for the meetup : <a href=\"/meetups/7n\">Sydney - Core sequences</a></h2>", "sections": [{"title": "Discussion article for the meetup : Sydney - Core sequences", "anchor": "Discussion_article_for_the_meetup___Sydney___Core_sequences", "level": 1}, {"title": "Discussion article for the meetup : Sydney - Core sequences", "anchor": "Discussion_article_for_the_meetup___Sydney___Core_sequences1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T13:55:27.639Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels meetup", "slug": "meetup-brussels-meetup-6", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:19.760Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Axel", "createdAt": "2010-11-03T17:32:46.091Z", "isAdmin": false, "displayName": "Axel"}, "userId": "vi498nAvek8eWuMWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JmpsHSGHgzZiPCuGT/meetup-brussels-meetup-6", "pageUrlRelative": "/posts/JmpsHSGHgzZiPCuGT/meetup-brussels-meetup-6", "linkUrl": "https://www.lesswrong.com/posts/JmpsHSGHgzZiPCuGT/meetup-brussels-meetup-6", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmpsHSGHgzZiPCuGT%2Fmeetup-brussels-meetup-6%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmpsHSGHgzZiPCuGT%2Fmeetup-brussels-meetup-6", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmpsHSGHgzZiPCuGT%2Fmeetup-brussels-meetup-6", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7o'>Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 March 2012 11:15:00AM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Museum of Natural Sciences Rue Vautier 29 B-1000 Brussels</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The last meetup was a success and we'll make this one even better. If you couldn't make the previous meetup consider dropping by.\n(getting there: <a href=\"http://www.naturalsciences.be/information/visitor/access\" rel=\"nofollow\">http://www.naturalsciences.be/information/visitor/access</a>)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7o'>Brussels meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JmpsHSGHgzZiPCuGT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 8.585109289985623e-07, "legacy": true, "legacyId": "13620", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup\">Discussion article for the meetup : <a href=\"/meetups/7o\">Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 March 2012 11:15:00AM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Museum of Natural Sciences Rue Vautier 29 B-1000 Brussels</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The last meetup was a success and we'll make this one even better. If you couldn't make the previous meetup consider dropping by.\n(getting there: <a href=\"http://www.naturalsciences.be/information/visitor/access\" rel=\"nofollow\">http://www.naturalsciences.be/information/visitor/access</a>)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup1\">Discussion article for the meetup : <a href=\"/meetups/7o\">Brussels meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup", "level": 1}, {"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T15:20:23.582Z", "modifiedAt": null, "url": null, "title": "Heuristics and Biases in Charity", "slug": "heuristics-and-biases-in-charity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:03.459Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hiiziojg3R5uwQPm9/heuristics-and-biases-in-charity", "pageUrlRelative": "/posts/hiiziojg3R5uwQPm9/heuristics-and-biases-in-charity", "linkUrl": "https://www.lesswrong.com/posts/hiiziojg3R5uwQPm9/heuristics-and-biases-in-charity", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Heuristics%20and%20Biases%20in%20Charity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHeuristics%20and%20Biases%20in%20Charity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhiiziojg3R5uwQPm9%2Fheuristics-and-biases-in-charity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Heuristics%20and%20Biases%20in%20Charity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhiiziojg3R5uwQPm9%2Fheuristics-and-biases-in-charity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhiiziojg3R5uwQPm9%2Fheuristics-and-biases-in-charity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2091, "htmlBody": "<p>Here on LW, we know that if you want to do the most good, <a href=\"http://www.slate.com/articles/arts/everyday_economics/1997/01/giving_your_all.html\">you shouldn't diversify your charitable giving</a>. If a specific charity makes the best use of your money, then you should assign your whole charitable budget to that organization. In the unlikely case that you're a millionaire and the recipient couldn't make full use of all your donations, then sure, diversify. But most people couldn't donate that much even if they wanted to. Also, if you're trying to buy yourself a warm fuzzy feeling, diversification will help. But then you're not trying to do the most good, you're trying to make yourself feel good, and you'd do well to <a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately/\">have separate budgets for those two</a>.</p>\n<p>We also know about <a href=\"/lw/hw/scope_insensitivity/\">scope insensitivity</a> - when three groups of subjects were asked how much they'd pay to save 2000 / 20000 / 200000 migrating birds from drowning in oil, they answered $80, $78, and $88, respectively. \"How much do I value it if 20,000 birds are saved from drowning in oil\" is a hard question, and we're unsure of what to compare it with. So we <a href=\"/lw/9l3/the_substitution_principle/\">substitute the question into an easier and clearer</a> one - \"how much emotion do I feel when I think about birds drowning in oil\". And that question doesn't take the number of birds into account, so the number gets mostly ignored.</p>\n<p>So diversification and scope insensitivity are two biases that people have, and which affect charitable giving. What others are there?</p>\n<p>According to <a href=\"http://www.sas.upenn.edu/~baron/papers/charity.pdf\">Baron &amp; Szymanska (2010)</a>, there are a number of heuristics involved in giving that lead to various biases. <em>Diversification</em> we are already familiar with. The others are <em>Evaluability, Average vs. Marginal Benefit, Prominence, Identifiability, </em>and <em>Voluntary vs. Tax.<a id=\"more\"></a></em></p>\n<p>The general principle of <strong>Evaluability </strong>has been <a href=\"/lw/lh/evaluability_and_cheap_holiday_shopping/\">discussed on LW before</a>, though not in a charitable context.<strong> </strong>This one is directly related to scope insensitivity, since both involve it being difficult to judge whether or not a charitable cause is a worthy one. Suppose that you need to choose between two charities, one of them <a href=\"http://givewell.org/international/top-charities/AMF\">dedicated to malaria prevention</a> and the other <a href=\"http://givewell.org/international/top-charities/schistosomiasis-control-initiative\">dedicated to treating parasitic worm infections</a>. Which one is a more worthy cause? Or should you instead donate to something else entirely?</p>\n<p>Presuming that you don't happen to know about <a href=\"http://givewell.org/\">GiveWell's</a> reports about the two charities and haven't studied the topic, you probably have no idea of which one is better. But you still need to make a decision, so you look for <em>something</em> to base that decision on. And one type of information that's <a href=\"http://www.charitynavigator.org/index.cfm?bay=topten.detail&amp;listid=28\">relatively easily available</a> for many charities is their overhead: what percentage of their costs they use on administration, as opposed to actual work. So you might end up choosing the charity which has the lowest administration costs, and which spends the largest amount of money on <em>actual</em> charity work.</p>\n<p>If you <em>truly</em> have no other information available, then this <em>might</em> really be the best you can do. But overhead is by itself a bad criteria. Suppose that charities A and B both receive $100. Charity A spends $10 on overhead and saves 9 human lives with the remaining $90. Charity B, on the other hand, allocates $25 toward its operating expenses, but manages to save 15 lives with the remaining $75. B would clearly be better, but using overhead as a heuristic tells us to give to A.</p>\n<p>GoodIntents.org also provides <a href=\"http://goodintents.org/choosing-a-charity/dont-choose-a-charity-based-on-administration-costs\">a number of other reasons</a> why you shouldn't use overhead as your criteria: the overhead figure is easy to manipulate, and the pressure to keep administration costs low can cause organizations to understaff projects, or to favor programs that are inefficient but have low administration costs. Still, many donors base their donation decision on the easy-to-evaluate operating costs, rather than some more meaningful figure.</p>\n<p><strong>Average vs. Marginal Benefit. </strong>Two charitable organizations provide figures about their effectiveness. Charity A claims to save one life for every 900 dollars donated. Charity B claims to save one life for every 1400 dollars donated. Charity A is clearly the correct choice - right?</p>\n<p>Maybe. If Charity A is a large organization, it could be that they're unable to spend the extra money effectively. It could be that the most recent one million dollars that they've received in donations have actually been <em>dragging down their average, </em>and they currently need 2000 extra dollars for each <em>additional </em>life that they save. In contrast, charity B might just have paid for most of their <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Fixed_cost\">fixed costs</a>, and can now leverage each additional donation of 800 dollars into a saved life for a while.</p>\n<p>Information on the marginal benefit of a dollar is often hard to come by, especially since it's in the interest of many well-funded charities to hide this information. But it's still something to keep in mind.</p>\n<p><strong>Prominence. </strong>People tend to pay attention to a single prominent attribute, or an attribute they view as the most important. This can <a href=\"/lw/1kb/fundamentally_flawed_or_fast_and_frugal/\">often be an effective fast-and-frugal heuristic</a>, but only focusing on one attribute to the exclusion of others may make it difficult or impossible to compare tradeoffs. It may also cause people to ignore efficiency: if two safety programs differ in cost and in the number of lives saved, people tend to choose an option that saves more people. They do this even if the difference in lives is small and the difference in cost is large. As a result, they may pay large sums for only a small increase in the amount of good done, even though the extra money would have been better spent elsewhere.</p>\n<p><strong>Parochialism </strong>is characterized as an <a href=\"http://wiki.lesswrong.com/wiki/In-group_bias\">in-group bias</a> in which people weigh the welfare of their own group more heavily than those of outsiders. In charity, this may show itself by Americans preferring to give to American charities, even if African ones save more lives per dollar. Whether this is truly a bias depends on one whether tries to carry out perfect utilitarianism: if not, preferring to help one's own group first is a question of values, not rationality. On the other hand, if one does strive for pure utilitarianism, then it should not matter where the subjects of aid are located.</p>\n<p>It could also be that attempting to correct for parochialism might <em>reduce</em> the amount of charitable giving, if there are many people whose altruism is limited purely to the in-group. Denied of the chance to help the in-group, such people might rather choose not to donate at all.</p>\n<p>On the other hand, if US citizens do experience a sense of commitment to tsunami victims in Hawaii, then it might be reasonable to presume that the same cognitive mechanism would affect their commitment to New Zealanders who suffered the same fate. If so, this suggests that parochialism results from cognitive biases. For instance, an American may have an easier time imagining the daily life on Hawaii in detail than imagining the daily life on New Zealand, and this difference in intensity may affect the amount of empathy they experience.</p>\n<p>If one does want to reduce parochialism, then there is some evidence that parochialism is greater for harms of inaction than for action. That is, people are reluctant to harm outsiders through acts but much more willing to do nothing to help them. If this can be made to seem like an inconsistency, then people might experience a larger obligation to help outsiders. Parochialism can also be reduced by encouraging people to think of outsiders as individuals, rather than as members of an abstract group. \"New Zealanders\" might not attract as much empathy as imagining some specific happy family of New Zealanders, essentially no different from a family in any other country.</p>\n<blockquote>\n<p>&ldquo;Writing about his experiences in the Spanish Civil War, George Orwell tells this story. He had gone out to a spot near the Fascist trenches from which he thought he might snipe at someone. He waited a long time without any luck. None of the enemy made an appearance. Then, at last, some disturbance took place, much shouting and blowing of whistles followed, and a man: jumped out of the trench and ran along the parapet in full view. He was half-dressed and was holding up his trousers with both hands as he ran. I refrained from shooting at him. I did not shoot part because of that detail about the trousers. I had come here to shoot at `Fascists&rsquo;; but a man holding up his trousers isn&rsquo;t a &lsquo;Fascist&rsquo;, he is visibly a fellow-creature, similar to yourself, and you don&rsquo;t feel like shooting at him.&rdquo;</p>\n</blockquote>\n<p><strong>Identifiability. </strong>Aid recipients who are identifiable evokes more empathy than recipients who are not. In one \"<a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Dictator_game\">dictator game</a>\" study, where people could choose to give somebody else some amount of money, giving was higher when the recipient was identified by last name. <a href=\"http://opim.wharton.upenn.edu/risk/library/J2007OBHDP_DAS_sympathy.pdf\">Small et al. (2007)</a> note that people often become entranced with specific, identifiable victims. In 1987, one child, \"<a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Jessica_McClure\">Baby Jessica</a>\", received over $700,000 in donations from the public when she fell in a well near her home in Texas. In 2003, &pound;275,000 was quickly raised for the medical care of a wounded Iraqi boy, <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Ali_Abbas\">Ali Abbas</a>. And in one case, more than $48,000 was contributed to save a dog stranded on a ship adrift on the Pacific Ocean near Hawaii.</p>\n<p>From a simple utilitarian perspective, identifiability is bias. By increasing altruism toward the identifiable victims, it may reduce altruism toward the unidentified ones, who are often the ones most in need of help. On the other hand, it could also increase overall altruism, by making people more willing to incur greater personal costs to help the identifiable victims.</p>\n<p>In fact, Small et al. found that teaching people about the identifiability effect makes them <em>less likely to give to identifiable victims, but no more likely to give to statistical victims</em>. So if you see a story about an identifiable victim and kill your impulse to give to them, or experience pleasure from never feeling that impulse in the first place, <em>please</em> take the money you would have donated to the victim if you hadn't known about the effect and actually give it to some worthier cause! <a href=\"/lw/3kl/optimizing_fuzzies_and_utilons_the_altruism_chip/\">The altruism chip jar</a> is a great way of doing this.</p>\n<p>Baron &amp; Szymanska suggest an alternative way that might help in channeling the effects of identifiability to good ends: \"<em>Victims all have names. The fact that we are aware of one of them is an accident. We could make up names for the others, or even tell ourselves that our donation to some relief fund is going to help someone named Zhang.</em>\" So if you know rationally that it'd be good to give to a \"statistical\" cause but are tempted to give to an \"identifiable\" cause instead, come up with some imaginary person who'd be helped by your \"statistical\" donation and think of how glad they'd be to receive your aid.</p>\n<p><strong>Voluntary vs. Tax. </strong>Finally, some people oppose government aid programs supported by taxes, often referred to as \"forced charity\". I'm inclined to consider this more of a value than a bias, but Baron &amp; Szymanska argue that</p>\n<blockquote>\n<p>In part, the bias against &ldquo;forced charity&rdquo; may arise from a belief in freedom, the belief that government should not force us to help others but should, more or less, provide us with services from which we all benefit and pay for collectively, such as roads, military defense, and protection of our property. (Some libertarians would not even go that far.) Insofar as this is true, it may represent a kind of cognitive inconsistency. Some people benefit very little from roads or property protection, so paying taxes for these things is a way of forcing them to sacrifice for the benefit of others. It is a matter of degree.</p>\n</blockquote>\n<p>If we do accept that government aid programs are as morally good as private ones, then that suggests that contributions to political causes that support helpful programs could sometimes be more efficient than direct contributions to the programs themselves. Although the probability of having some effect through political action is very low, the benefits of a successful initiative are potentially very high. Thus the expected utility of donating to the right political campaign might be higher than the expected utility of donating to an actual charity.</p>\n<p><span style=\"text-decoration: underline;\"><strong>References</strong></span></p>\n<p>Baron, J. &amp; Szymanska, E. (2010). Heuristics and Biases in Charity. In D. Oppenheimer &amp; C. Olivola (Eds). <em>The science of giving: Experimental approaches to the study of charity</em> (pp. 215&ndash;236). New York: Taylor and Francis. <a href=\"http://www.sas.upenn.edu/~baron/papers/charity.pdf\">http://www.sas.upenn.edu/~baron/papers/charity.pdf</a></p>\n<p>Small, D.A. &amp; Loewenstein, G. &amp; Slovic, P. (2007) Sympathy and callousness: The impact of deliberative thought on donations to identifiable and statistical victims. <em>Organizational Behavior and Human Decision Processes</em>, 102, 143&ndash;153. <a href=\"http://opim.wharton.upenn.edu/risk/library/J2007OBHDP_DAS_sympathy.pdf\">http://opim.wharton.upenn.edu/risk/library/J2007OBHDP_DAS_sympathy.pdf</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JsJPrdgRGRqnci8cZ": 1, "4R8JYu4QF2FqzJxE5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hiiziojg3R5uwQPm9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 30, "extendedScore": null, "score": 8.58544991539052e-07, "legacy": true, "legacyId": "13621", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3p3CYauiX8oLjmwRF", "2ftJ38y9SRBCBsCzy", "LHtMNz7ua8zu4rSZr", "3T6p93Mut7G8qdkAs", "psQYbMLWzS9sTsT2M", "FfNEt8mpi6qanNmXg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T15:26:21.584Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "slug": "meetup-fort-collins-colorado-meetup-wedneday-7pm-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LTNqKwATuLiQFc6wm/meetup-fort-collins-colorado-meetup-wedneday-7pm-2", "pageUrlRelative": "/posts/LTNqKwATuLiQFc6wm/meetup-fort-collins-colorado-meetup-wedneday-7pm-2", "linkUrl": "https://www.lesswrong.com/posts/LTNqKwATuLiQFc6wm/meetup-fort-collins-colorado-meetup-wedneday-7pm-2", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLTNqKwATuLiQFc6wm%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wedneday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLTNqKwATuLiQFc6wm%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLTNqKwATuLiQFc6wm%2Fmeetup-fort-collins-colorado-meetup-wedneday-7pm-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7p'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 March 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It's almost spring, though there is sometimes snow on the ground. Come hang out and chat with interesting people.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7p'>Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LTNqKwATuLiQFc6wm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 8.58547384589751e-07, "legacy": true, "legacyId": "13622", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm\">Discussion article for the meetup : <a href=\"/meetups/7p\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 March 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It's almost spring, though there is sometimes snow on the ground. Come hang out and chat with interesting people.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/7p\">Fort Collins, Colorado Meetup Wedneday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wedneday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wedneday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T15:56:16.185Z", "modifiedAt": null, "url": null, "title": "Journal of Consciousness Studies issue on the Singularity", "slug": "journal-of-consciousness-studies-issue-on-the-singularity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:04.711Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9DGfYpjYtpG4ACs8o/journal-of-consciousness-studies-issue-on-the-singularity", "pageUrlRelative": "/posts/9DGfYpjYtpG4ACs8o/journal-of-consciousness-studies-issue-on-the-singularity", "linkUrl": "https://www.lesswrong.com/posts/9DGfYpjYtpG4ACs8o/journal-of-consciousness-studies-issue-on-the-singularity", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Journal%20of%20Consciousness%20Studies%20issue%20on%20the%20Singularity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJournal%20of%20Consciousness%20Studies%20issue%20on%20the%20Singularity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9DGfYpjYtpG4ACs8o%2Fjournal-of-consciousness-studies-issue-on-the-singularity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Journal%20of%20Consciousness%20Studies%20issue%20on%20the%20Singularity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9DGfYpjYtpG4ACs8o%2Fjournal-of-consciousness-studies-issue-on-the-singularity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9DGfYpjYtpG4ACs8o%2Fjournal-of-consciousness-studies-issue-on-the-singularity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 235, "htmlBody": "<p>...has finally been <a href=\"http://friendlyai.tumblr.com/post/18609191883/new-jcs-issue-on-the-singularity\">published</a>.</p>\n<p>Contents:</p>\n<ul>\n<li>Uziel Awret - Introduction</li>\n<li>Susan Blackmore - <a href=\"http://www.susanblackmore.co.uk/Articles/JCS2012.htm\">She Won&rsquo;t Be Me</a></li>\n<li>Damien Broderick - <a href=\"http://www.gwern.net/docs/2012-broderick.pdf\">Terrible Angels: The Singularity and Science Fiction</a></li>\n<li>Barry Dainton - On Singularities and Simulations</li>\n<li>Daniel Dennett - The Mystery of David Chalmers</li>\n<li>Ben Goertzel - <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Goertzel-Should-Humanity-Build-a-Global-AI-Nanny-to-Delay-the-Singularity-Until-its-Better-Understood.pdf\">Should Humanity Build a Global AI Nanny to Delay the Singularity Until It&rsquo;s Better Understood?</a></li>\n<li>Susan Greenfield - The Singularity: Commentary on David Chalmers</li>\n<li>Robin Hanson - <a href=\"http://hanson.gmu.edu/ChalmersReply.html\">Meet the New Conflict, Same as the Old Conflict</a></li>\n<li>Francis Heylighen - <a href=\"http://pespmc1.vub.ac.be/Papers/Singularity-Reply2Chalmers.pdf\">Brain in a Vat Cannot Break Out</a></li>\n<li>Marcus Hutter - <a href=\"http://www.hutter1.net/publ/singularity.pdf\">Can Intelligence Explode?</a></li>\n<li>Drew McDermott - <a href=\"http://cs-www.cs.yale.edu/homes/dvm/papers/chalmers-singularity-response.pdf\">Response to &lsquo;The Singularity&rsquo; by David Chalmers</a> [this link is a McDermott-corrected version, and therefore preferred to the version that was published in <em>JCS</em>]</li>\n<li>Jurgen Schmidhuber - <a href=\"http://dl.dropbox.com/u/5317066/2012-schmidhuber.pdf\">Philosophers &amp; Futurists, Catch Up!</a></li>\n<li>Frank Tipler - <a href=\"http://dl.dropbox.com/u/5317066/2012-tipler.pdf\">Inevitable Existence and Inevitable Goodness of the Singularity</a></li>\n<li>Roman Yampolskiy - <a href=\"http://dl.dropbox.com/u/5317066/2012-yampolskiy.pdf\">Leakproofing the Singularity: Artificial Intelligence Confinement Problem</a></li>\n</ul>\n<p>The issue consists of responses to <a href=\"http://consc.net/papers/singularityjcs.pdf\">Chalmers (2010)</a>. Future volumes will contain additional articles from <a href=\"http://www.nickbostrom.com/aievolution.pdf\">Shulman &amp; Bostrom</a>,&nbsp;<a href=\"http://en.wikipedia.org/wiki/Igor_Aleksander\">Igor&nbsp;Aleksander</a>, Richard Brown, <a href=\"http://en.wikipedia.org/wiki/Ray_Kurzweil\">Ray Kurzweil</a>, <a href=\"http://www.pamelamc.com/\">Pamela McCorduck</a>,&nbsp;Chris Nunn, Arkady Plotnitsky, <a href=\"http://web.gc.cuny.edu/philosophy/faculty/prinz.htm\">Jesse Prinz</a>, <a href=\"http://www.sas.upenn.edu/~sls/Schneider_site/Research.html\">Susan Schneider</a>, <a href=\"http://www.doc.ic.ac.uk/~mpsha/\">Murray&nbsp;Shanahan</a>, <a href=\"http://science.athabascau.ca/staff-pages/burtv/\">Burt Voorhees</a>, and a response from Chalmers.</p>\n<p>McDermott's chapter should be supplemented with <a href=\"http://cs-www.cs.yale.edu/homes/dvm/papers/no-extendible-methods.pdf\">this</a>, which he says he didn't have space for in his <em>JCS</em> article.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9DGfYpjYtpG4ACs8o", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 23, "extendedScore": null, "score": 8.585591934984974e-07, "legacy": true, "legacyId": "13623", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 86, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T21:06:48.382Z", "modifiedAt": null, "url": null, "title": "Random personal thoughts on workload pessimism as a procrastination problem", "slug": "random-personal-thoughts-on-workload-pessimism-as-a", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:06.988Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "N6W7sAzCo3fGauM7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RLGNzkZxTgKfsbdyv/random-personal-thoughts-on-workload-pessimism-as-a", "pageUrlRelative": "/posts/RLGNzkZxTgKfsbdyv/random-personal-thoughts-on-workload-pessimism-as-a", "linkUrl": "https://www.lesswrong.com/posts/RLGNzkZxTgKfsbdyv/random-personal-thoughts-on-workload-pessimism-as-a", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Random%20personal%20thoughts%20on%20workload%20pessimism%20as%20a%20procrastination%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARandom%20personal%20thoughts%20on%20workload%20pessimism%20as%20a%20procrastination%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRLGNzkZxTgKfsbdyv%2Frandom-personal-thoughts-on-workload-pessimism-as-a%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Random%20personal%20thoughts%20on%20workload%20pessimism%20as%20a%20procrastination%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRLGNzkZxTgKfsbdyv%2Frandom-personal-thoughts-on-workload-pessimism-as-a", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRLGNzkZxTgKfsbdyv%2Frandom-personal-thoughts-on-workload-pessimism-as-a", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 818, "htmlBody": "<p>\n<p>I am in one of those moods where I feel extremely burned out and apathetic. What I am noticing about my feelings right now is that there is no short term reward system that could possibly motivate me. I don't want any candy, food, soda, coffee, alcohol, nor even money, entertainment, sexual excitement, sleep, exercise, or play of any kind. I know that's not an exhaustive list of potential short term rewards, but it's fairly exhaustive for the kinds of things that I could reasonably bring about in my own life in the short term. The thing right now that makes me feel bad is the idea that my future work time horizon (FWTH), the perceived amount of future time that will have to be devoted to doing work, is very full. Whenever I perceive a full FWTH, it causes my mind to recoil and become extremely apathetic.</p>\n<p>&nbsp;</p>\n<p>It seems to me that the only kind of reward system that motivates me to feel productive is having completely unabated free time: large blocks of time with literally no named obligations. I'm sure this is not profound or new, but it is interesting to me that this seems to be a dominant part of my psyche. If I think that my marginal effort put towards work right this minute will yield a large expanse of completely and utterly free time in the reasonably near future, then I feel very motivated to work hard. If I perceive that, no matter how hard I work right this minute, my future schedule is already bloated with work that I have yet to even get started on, then I feel very tired, cranky, and just want to lay in bed apathetically and watch cartoons on repeat.</p>\n<p>&nbsp;</p>\n<p>I don't know a good method for dealing with this sort of procrastination effect. It doesn't seem to fit into the normal procrastination equation, but at first approximation there are a few ways that it might. One is that I could be very impulsive about free time. Given that I have been a grad student for the past 3 years, this is plausible. As a grad student, the time when I can truly relax and unwind from work is very random and scattered, and often even when I think that I have legitimate relaxation time, I am interrupted by email requests for work that needs to be done right away, or the revelation of a new, difficult homework assignment that will create very negative consequences if I don't start working diligently on it immediately. Even my undergraduate college life was stressful in this random fashion, and it seems to have taken a great toll on me. I behave almost like an abused puppy, never sure whether I can actually embrace relaxation time or not; perpetually tense that the next work discharge from the Poisson processes governing my workload is going to happen when I'm not mentally ready to receive it.</p>\n<p>&nbsp;</p>\n<p>This could be an impulsiveness effect, making me impatient regarding the next opportunity to have fun and relaxation. Alternatively, it could be a reward or delay problem. There are times in life where obligations are far away. The problem seems to be that they are extremely rare for me and that my personality is extremely sensitive to any potential thoughts on work. People have suggested that I attempt different exercise habits, and possibly meditation, in order to overcome this. I have earnestly tried these things many times, including reading many books and articles on them. So far at least, no specific mental relaxation technique has provided even the slightest benefit. If I perceive that there's no short term end to my work, which can be followed by a completely obligation-free period of time, then it overrides everything else and creates a strong feeling of apathy. But then, how do you create short-term rewards that function essentially like full out vacations? That doesn't seem like a plausible thing to hope for, yet it seems like the only thing which could possibly function as a reward. How do you shorten the delay, on a weekly basis, of large expanses of completely obligation-free time?</p>\n<p>&nbsp;</p>\n<p>How do you set up such things as rewards in the first place? That seems like a reward that just logically cannot exist in the modern working environment, but at the same time it seems pretty obvious that a lot of human beings would be psychologically adapted to strongly desire such a reward and that at least some percentage would have trouble functioning properly without the strong possibility of that reward in the short term.</p>\n<p>&nbsp;</p>\n<p>This is more or less just me trying to write down and articulate how I feel. No comments or advice is being solicited, but if anything comes to mind (that avoids the \"you should really meditate; it will help you so much\" mantra that has repeatedly not worked for me in the past), it is appreciated.</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RLGNzkZxTgKfsbdyv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 8.586839470465272e-07, "legacy": true, "legacyId": "13625", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T22:17:42.258Z", "modifiedAt": null, "url": null, "title": "[LINK] An amazing breakthrough in wireless communication, or a pipe dream?", "slug": "link-an-amazing-breakthrough-in-wireless-communication-or-a", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:09.523Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rXhpdrFeCceGXQw9N/link-an-amazing-breakthrough-in-wireless-communication-or-a", "pageUrlRelative": "/posts/rXhpdrFeCceGXQw9N/link-an-amazing-breakthrough-in-wireless-communication-or-a", "linkUrl": "https://www.lesswrong.com/posts/rXhpdrFeCceGXQw9N/link-an-amazing-breakthrough-in-wireless-communication-or-a", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20An%20amazing%20breakthrough%20in%20wireless%20communication%2C%20or%20a%20pipe%20dream%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20An%20amazing%20breakthrough%20in%20wireless%20communication%2C%20or%20a%20pipe%20dream%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrXhpdrFeCceGXQw9N%2Flink-an-amazing-breakthrough-in-wireless-communication-or-a%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20An%20amazing%20breakthrough%20in%20wireless%20communication%2C%20or%20a%20pipe%20dream%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrXhpdrFeCceGXQw9N%2Flink-an-amazing-breakthrough-in-wireless-communication-or-a", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrXhpdrFeCceGXQw9N%2Flink-an-amazing-breakthrough-in-wireless-communication-or-a", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 204, "htmlBody": "<p><a href=\"http://iopscience.iop.org/1367-2630/14/3/033001/article\">Encoding many channels on the same frequency through radio vorticity: first experimental test</a></p>\n<p>&nbsp;</p>\n<div style=\"font-family: Arial, Helvetica, Verdana, sans-serif; font-size: 12px; text-align: left; \">\n<div>\n<p style=\"line-height: 1.5em; margin-top: 4px; margin-right: 0px; margin-bottom: 10px; margin-left: 0px; \">\"We have shown experimentally, in a real-world setting, that it is possible to use two beams of incoherent radio waves, transmitted on the same frequency but encoded in two different orbital angular momentum states, to simultaneously transmit two independent radio channels. This novel radio technique allows the implementation of, in principle, an infinite number of channels in a given, fixed bandwidth, even without using polarization, multiport or dense coding techniques. This paves the way for innovative techniques in radio science and entirely new paradigms in radio communication protocols that might offer a solution to the problem of radio-band congestion.\"</p>\n<p style=\"line-height: 1.5em; margin-top: 4px; margin-right: 0px; margin-bottom: 10px; margin-left: 0px; \">\"Moreover, our experimental findings demonstrate that the spatial phase signature was preserved even in the far-field region and for incoherent non-monochromatic wave beams. These results open up new perspectives not only for wireless communication but also for physics and astronomy, including the possible detection of Kerr black holes in the test general relativity\"</p>\n</div>\n</div>\n<p>&nbsp;</p>\n<p>This looks too good to be true, but I cannot see any obvious issues, and they have an experimental confirmation.</p>\n<p>If this pans out, it would be a black swan in the making for many of the wireless spectrum allocation/licensing authorities and companies.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rXhpdrFeCceGXQw9N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 0, "extendedScore": null, "score": 8.587123909765953e-07, "legacy": true, "legacyId": "13626", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-02T23:38:56.712Z", "modifiedAt": "2021-01-27T03:02:46.379Z", "url": null, "title": "People who \"don't rationalize\"?  [Help Rationality Group figure it out]", "slug": "people-who-don-t-rationalize-help-rationality-group-figure", "viewCount": null, "lastCommentedAt": "2021-01-27T03:25:46.541Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mercurial", "createdAt": "2011-04-21T03:59:51.257Z", "isAdmin": false, "displayName": "Mercurial"}, "userId": "2dGsX6cZSR9PmQyBq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hEFrm3nZMFiW2czvb/people-who-don-t-rationalize-help-rationality-group-figure", "pageUrlRelative": "/posts/hEFrm3nZMFiW2czvb/people-who-don-t-rationalize-help-rationality-group-figure", "linkUrl": "https://www.lesswrong.com/posts/hEFrm3nZMFiW2czvb/people-who-don-t-rationalize-help-rationality-group-figure", "postedAtFormatted": "Friday, March 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20People%20who%20%22don't%20rationalize%22%3F%20%20%5BHelp%20Rationality%20Group%20figure%20it%20out%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APeople%20who%20%22don't%20rationalize%22%3F%20%20%5BHelp%20Rationality%20Group%20figure%20it%20out%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhEFrm3nZMFiW2czvb%2Fpeople-who-don-t-rationalize-help-rationality-group-figure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=People%20who%20%22don't%20rationalize%22%3F%20%20%5BHelp%20Rationality%20Group%20figure%20it%20out%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhEFrm3nZMFiW2czvb%2Fpeople-who-don-t-rationalize-help-rationality-group-figure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhEFrm3nZMFiW2czvb%2Fpeople-who-don-t-rationalize-help-rationality-group-figure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<p>Anna Salamon and I are confused. Both of us notice ourselves rationalizing on pretty much a daily basis and have to apply techniques like the Litany of Tarski pretty regularly. But in several of our test sessions for teaching rationality, a handful of people report never rationalizing and seem to have little clue what Tarski is for. They don't relate to any examples we give, whether fictitious or actual personal examples from our lives. Some of these people show signs of being rather high-level rationalists overall, although some don't.</p>\n<p>\n<div>So, Less Wrong, we're asking for your input on this one. What do you think is going on?</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hEFrm3nZMFiW2czvb", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 22, "extendedScore": null, "score": 8.587449864952543e-07, "legacy": true, "legacyId": "13629", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 89, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2012-03-02T23:38:56.712Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-03T00:04:11.988Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Buenos Aires, Cambridge UK, Chicago, Loveland/Fort Collins CO, Melbourne, Tucson, Twin Cities", "slug": "weekly-lw-meetups-buenos-aires-cambridge-uk-chicago-loveland", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LvmoshCcyB7J4GRnL/weekly-lw-meetups-buenos-aires-cambridge-uk-chicago-loveland", "pageUrlRelative": "/posts/LvmoshCcyB7J4GRnL/weekly-lw-meetups-buenos-aires-cambridge-uk-chicago-loveland", "linkUrl": "https://www.lesswrong.com/posts/LvmoshCcyB7J4GRnL/weekly-lw-meetups-buenos-aires-cambridge-uk-chicago-loveland", "postedAtFormatted": "Saturday, March 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Buenos%20Aires%2C%20Cambridge%20UK%2C%20Chicago%2C%20Loveland%2FFort%20Collins%20CO%2C%20Melbourne%2C%20Tucson%2C%20Twin%20Cities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Buenos%20Aires%2C%20Cambridge%20UK%2C%20Chicago%2C%20Loveland%2FFort%20Collins%20CO%2C%20Melbourne%2C%20Tucson%2C%20Twin%20Cities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLvmoshCcyB7J4GRnL%2Fweekly-lw-meetups-buenos-aires-cambridge-uk-chicago-loveland%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Buenos%20Aires%2C%20Cambridge%20UK%2C%20Chicago%2C%20Loveland%2FFort%20Collins%20CO%2C%20Melbourne%2C%20Tucson%2C%20Twin%20Cities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLvmoshCcyB7J4GRnL%2Fweekly-lw-meetups-buenos-aires-cambridge-uk-chicago-loveland", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLvmoshCcyB7J4GRnL%2Fweekly-lw-meetups-buenos-aires-cambridge-uk-chicago-loveland", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 416, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/6z\">Tucson Meetup:&nbsp;<span class=\"date\">24 February 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/7d\">Loveland CO (Fort Collins) 3D printer tour:&nbsp;<span class=\"date\">24 February 2012 02:15PM</span></a></li>\n<li><a href=\"/meetups/7a\">Buenos Aires meetup: Saturday, February 25th, 4pm:&nbsp;<span class=\"date\">25 February 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/79\">Chicago Meetup at the University of Chicago:&nbsp;<span class=\"date\">25 February 2012 01:00PM</span></a></li>\n<li><a href=\"/meetups/6z\">Tucson Meetup:&nbsp;<span class=\"date\">02 March 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/6v\">Twin Cities South Metro:&nbsp;<span class=\"date\">06 March 2012 08:00PM</span></a></li>\n<li><a href=\"/meetups/6k\">[Ohio/Washington DC] Interest in Reason Rally meetup?:&nbsp;<span class=\"date\">24 March 2012 04:14PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/71\">Cambridge UK:&nbsp;<span class=\"date\">26 February 2012 11:00AM</span></a></li>\n<li><a href=\"/meetups/7b\">Melbourne practical rationality meetup:&nbsp;<span class=\"date\">02 March 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/72\">Cambridge UK:&nbsp;<span class=\"date\">04 March 2012 11:00AM</span></a></li>\n<li><a href=\"/meetups/7e\">Ohio Monthly:&nbsp;<span class=\"date\">18 March 2012 03:00PM</span></a></li>\n</ul>\n<p>&nbsp;</p>\n<ul>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a></strong><strong>.</strong></p>\n<p>If your meetup has a mailing list that you'd like mentioned here or has become regular and isn't listed as such, let me know!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LvmoshCcyB7J4GRnL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 8.587551196053433e-07, "legacy": true, "legacyId": "13394", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-03T01:14:10.412Z", "modifiedAt": null, "url": null, "title": "Meetup : Austin, TX", "slug": "meetup-austin-tx-11", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qdWuNYdCZw3qndiNc/meetup-austin-tx-11", "pageUrlRelative": "/posts/qdWuNYdCZw3qndiNc/meetup-austin-tx-11", "linkUrl": "https://www.lesswrong.com/posts/qdWuNYdCZw3qndiNc/meetup-austin-tx-11", "postedAtFormatted": "Saturday, March 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Austin%2C%20TX&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Austin%2C%20TX%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqdWuNYdCZw3qndiNc%2Fmeetup-austin-tx-11%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Austin%2C%20TX%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqdWuNYdCZw3qndiNc%2Fmeetup-austin-tx-11", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqdWuNYdCZw3qndiNc%2Fmeetup-austin-tx-11", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/7q'>Austin, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">03 March 2012 01:30:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2222B Guadalupe St Austin, Texas 78705</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Austin Meetup continues! <a href=\"http://www.utexas.edu/know/events/20120303/e19517\" rel=\"nofollow\">Explore UT</a> will be going on at the same day, so expect pretty heavy traffic around campus.</p>\n\n<p>We'll be at Caffe Medici again, from about 1:30 to about 4:30, sitting on the second floor to the left by the stage. We hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/7q'>Austin, TX</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qdWuNYdCZw3qndiNc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 8.587831967831113e-07, "legacy": true, "legacyId": "13639", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Austin__TX\">Discussion article for the meetup : <a href=\"/meetups/7q\">Austin, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">03 March 2012 01:30:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2222B Guadalupe St Austin, Texas 78705</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Austin Meetup continues! <a href=\"http://www.utexas.edu/know/events/20120303/e19517\" rel=\"nofollow\">Explore UT</a> will be going on at the same day, so expect pretty heavy traffic around campus.</p>\n\n<p>We'll be at Caffe Medici again, from about 1:30 to about 4:30, sitting on the second floor to the left by the stage. We hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Austin__TX1\">Discussion article for the meetup : <a href=\"/meetups/7q\">Austin, TX</a></h2>", "sections": [{"title": "Discussion article for the meetup : Austin, TX", "anchor": "Discussion_article_for_the_meetup___Austin__TX", "level": 1}, {"title": "Discussion article for the meetup : Austin, TX", "anchor": "Discussion_article_for_the_meetup___Austin__TX1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-03T03:14:32.333Z", "modifiedAt": null, "url": null, "title": "Self-locating beliefs across identity fission", "slug": "self-locating-beliefs-across-identity-fission", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:54.567Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YkFA5fP6WSnujSMpk/self-locating-beliefs-across-identity-fission", "pageUrlRelative": "/posts/YkFA5fP6WSnujSMpk/self-locating-beliefs-across-identity-fission", "linkUrl": "https://www.lesswrong.com/posts/YkFA5fP6WSnujSMpk/self-locating-beliefs-across-identity-fission", "postedAtFormatted": "Saturday, March 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Self-locating%20beliefs%20across%20identity%20fission&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelf-locating%20beliefs%20across%20identity%20fission%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYkFA5fP6WSnujSMpk%2Fself-locating-beliefs-across-identity-fission%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Self-locating%20beliefs%20across%20identity%20fission%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYkFA5fP6WSnujSMpk%2Fself-locating-beliefs-across-identity-fission", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYkFA5fP6WSnujSMpk%2Fself-locating-beliefs-across-identity-fission", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<p>From <a href=\"http://www.umsu.de/wo/\">Wolfgang Schwarz</a>'s <a href=\"https://github.com/wo/papers/blob/master/fission-update.pdf?raw=true\">Belief Dynamics Across Fission</a>:</p>\n<blockquote>\n<p>\n<p>Fred&rsquo;s home planet, Sunday, is surrounded by two moons, Monday and Tuesday. Tonight,&nbsp;while Fred is asleep, his body will be scanned and destroyed; then a signal is sent to both&nbsp;Monday and Tuesday where he will be recreated from local matter.</p>\n<p>A lot of ink has been spent on how to describe scenarios like this. Should we say that&nbsp;Fred will find himself both on Monday and on Tuesday? Which of the persons awakening&nbsp;on the two moons is identical to the person going to sleep on Sunday? In this paper, I&nbsp;want to look at a different question: what should Fred&rsquo;s successors believe when they&nbsp;awaken on Monday and on Tuesday? More precisely, how should their beliefs be related&nbsp;to Fred&rsquo;s beliefs before he went to sleep on Sunday?</p>\n</p>\n</blockquote>\n<p>Also see: <a href=\"http://wiki.lesswrong.com/wiki/Sleeping_Beauty_problem\">Sleeping Beauty problem</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YkFA5fP6WSnujSMpk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 8.588314973838157e-07, "legacy": true, "legacyId": "13649", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-03T08:04:55.112Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes March 2012", "slug": "rationality-quotes-march-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:37.750Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Thomas", "createdAt": "2009-03-02T17:47:09.607Z", "isAdmin": false, "displayName": "Thomas"}, "userId": "GrAKeuxT4e9AKyHdE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QtkFXPuMLLnzTqfmf/rationality-quotes-march-2012", "pageUrlRelative": "/posts/QtkFXPuMLLnzTqfmf/rationality-quotes-march-2012", "linkUrl": "https://www.lesswrong.com/posts/QtkFXPuMLLnzTqfmf/rationality-quotes-march-2012", "postedAtFormatted": "Saturday, March 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20March%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20March%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQtkFXPuMLLnzTqfmf%2Frationality-quotes-march-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20March%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQtkFXPuMLLnzTqfmf%2Frationality-quotes-march-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQtkFXPuMLLnzTqfmf%2Frationality-quotes-march-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p><span style=\"line-height: 11px; font-family: Arial, Helvetica, sans-serif; font-size: 12px; text-align: justify;\">Here's the new thread for posting quotes, with the usual rules:</span></p>\n<ul>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Please post all quotes separately, so that they can be voted up/down separately. &nbsp;(If they are strongly related, reply to your own comments. &nbsp;If strongly ordered, then go ahead and post them together.)</span></li>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Do not quote yourself</span></li>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Do not quote comments/posts on LW/OB</span></li>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">No more than 5 quotes per person per monthly thread, please.</span></li>\n</ul>\n<div class=\"tools clear\" style=\"border-top-width: 1px; border-top-style: solid; border-top-color: #c9c7c7; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #c9c7c7; line-height: 18px; margin-top: 12px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 10px; padding-right: 0px; padding-bottom: 10px; padding-left: 0px; position: relative; font-family: Arial, Helvetica, sans-serif; font-size: 12px; text-align: justify; \">\n<div id=\"arrows_t3_9pk\" class=\"vote\" style=\"float: left; \"><br /></div>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QtkFXPuMLLnzTqfmf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 5, "extendedScore": null, "score": 8.589480422860799e-07, "legacy": true, "legacyId": "13582", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 534, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-03T08:51:31.651Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Savanna Poets", "slug": "seq-rerun-savanna-poets", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.332Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TWei9eJYGkpvJDBGZ/seq-rerun-savanna-poets", "pageUrlRelative": "/posts/TWei9eJYGkpvJDBGZ/seq-rerun-savanna-poets", "linkUrl": "https://www.lesswrong.com/posts/TWei9eJYGkpvJDBGZ/seq-rerun-savanna-poets", "postedAtFormatted": "Saturday, March 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Savanna%20Poets&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Savanna%20Poets%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTWei9eJYGkpvJDBGZ%2Fseq-rerun-savanna-poets%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Savanna%20Poets%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTWei9eJYGkpvJDBGZ%2Fseq-rerun-savanna-poets", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTWei9eJYGkpvJDBGZ%2Fseq-rerun-savanna-poets", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 236, "htmlBody": "<p>Today's post, <a href=\"/lw/oq/savanna_poets/\">Savanna Poets</a> was originally published on 18 March 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Savanna_Poets\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Equations of physics aren't about strong emotions. They can inspire those emotions in the mind of a scientist, but the emotions are not as raw as the stories told about Jupiter (the god). And so it might seem that reducing Jupiter to a spinning ball of methane and ammonia takes away some of the poetry in those stories. But ultimately, we don't have to keep telling stories about Jupiter. It's not necessary for Jupiter to think and feel in order for us to tell stories, because we can always write stories with humans as its protagonists.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ai0/seq_rerun_fake_reductionism/\">Fake Reductionism</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TWei9eJYGkpvJDBGZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 8.589667515587904e-07, "legacy": true, "legacyId": "13660", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kQzs8MFbBxdYhe3hK", "8t2emPk7BTuWcs9NJ", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-03-03T13:40:48.113Z", "modifiedAt": null, "url": null, "title": "[LINK] Why You Should Keep Your Goals Secret", "slug": "link-why-you-should-keep-your-goals-secret", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:56.428Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Barry_Cotter", "createdAt": "2010-04-19T16:29:03.629Z", "isAdmin": false, "displayName": "Barry_Cotter"}, "userId": "5pZXxaf79kj37Rwq2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JtYQvo9FG5otjXxtx/link-why-you-should-keep-your-goals-secret", "pageUrlRelative": "/posts/JtYQvo9FG5otjXxtx/link-why-you-should-keep-your-goals-secret", "linkUrl": "https://www.lesswrong.com/posts/JtYQvo9FG5otjXxtx/link-why-you-should-keep-your-goals-secret", "postedAtFormatted": "Saturday, March 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Why%20You%20Should%20Keep%20Your%20Goals%20Secret&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Why%20You%20Should%20Keep%20Your%20Goals%20Secret%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJtYQvo9FG5otjXxtx%2Flink-why-you-should-keep-your-goals-secret%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Why%20You%20Should%20Keep%20Your%20Goals%20Secret%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJtYQvo9FG5otjXxtx%2Flink-why-you-should-keep-your-goals-secret", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJtYQvo9FG5otjXxtx%2Flink-why-you-should-keep-your-goals-secret", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 184, "htmlBody": "<p><a href=\"http://www.spring.org.uk/2011/10/why-you-should-keep-your-goals-secret.php\">Popularisation, extremely short</a></p>\n<p><a href=\"http://www.psych.nyu.edu/gollwitzer/09_Gollwitzer_Sheeran_Seifert_Michalski_When_Intentions_.pdf\">Original Article [pdf]</a></p>\n<p>&nbsp;</p>\n<h1 style=\"margin-top: 0.375em; margin-right: 0px; margin-bottom: 0.375em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.3846em; font: inherit; vertical-align: baseline; line-height: 1.125em; font-family: arial, helvetica, clean, sans-serif; text-align: left; padding: 0px; border: 0px initial initial;\"></h1>\n<h1 style=\"margin-top: 0.375em; margin-right: 0px; margin-bottom: 0.375em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.3846em; font: inherit; vertical-align: baseline; line-height: 1.125em; padding: 0px; border: 0px initial initial;\">When intentions go public: does social reality widen the intention-behavior gap?</h1>\n<div class=\"auths\" style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 0.923em; font: inherit; vertical-align: baseline; padding: 0px; margin: 0px; border: 0px initial initial;\"><a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Gollwitzer%20PM%22%5BAuthor%5D\">Gollwitzer PM</a>,&nbsp;<a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Sheeran%20P%22%5BAuthor%5D\">Sheeran P</a>,&nbsp;<a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Michalski%20V%22%5BAuthor%5D\">Michalski V</a>,&nbsp;<a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Seifert%20AE%22%5BAuthor%5D\">Seifert AE</a>.</div>\n<div class=\"aff\" style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 0.8465em; font: inherit; vertical-align: baseline; line-height: 1.0915em; padding: 0px; margin: 0px; border: 0px initial initial;\">\n<h3 class=\"label\" style=\"margin-top: 1.2856em; margin-right: 1em; margin-bottom: 0.6428em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.0769em; font: inherit; vertical-align: baseline; line-height: 1.2857; color: #724128; position: absolute; left: -10000px; top: auto; width: 1px; height: 1px; overflow-x: hidden; overflow-y: hidden; padding: 0px; border: 0px initial initial;\">Source</h3>\n<p style=\"margin-top: 0.5em; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">New York University, Psychology Department, New York, NY 10003, USA. peter.gollwitzer@nyu.edu</p>\n</div>\n<div class=\"abstr\" style=\"margin-top: 1.2em; margin-right: auto; margin-bottom: auto; margin-left: auto; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; line-height: 17px; padding: 0px; border: 0px initial initial;\">\n<h3 style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.0769em; font: inherit; vertical-align: baseline; line-height: 1.2857; color: #985735; padding: 0px; margin: 0px; border: 0px initial initial;\">Abstract</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">Based on Lewinian goal theory in general and self-completion theory in particular, four experiments examined the implications of other people taking notice of one's identity-related behavioral intentions (e.g., the intention to read law periodicals regularly to reach the identity goal of becoming a lawyer). Identity-related behavioral intentions that had been noticed by other people were translated into action less intensively than those that had been ignored (Studies 1-3). This effect was evident in the field (persistent striving over 1 week's time; Study 1) and in the laboratory (jumping on opportunities to act; Studies 2 and 3), and it held among participants with strong but not weak commitment to the identity goal (Study 3). Study 4 showed, in addition, that when other people take notice of an individual's identity-related behavioral intention, this gives the individual a premature sense of possessing the aspired-to identity.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">If you have tags to suggest please do and I'll edit them in.</p>\n</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JtYQvo9FG5otjXxtx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 8.590828852581117e-07, "legacy": true, "legacyId": "13661", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a href=\"http://www.spring.org.uk/2011/10/why-you-should-keep-your-goals-secret.php\">Popularisation, extremely short</a></p>\n<p><a href=\"http://www.psych.nyu.edu/gollwitzer/09_Gollwitzer_Sheeran_Seifert_Michalski_When_Intentions_.pdf\">Original Article [pdf]</a></p>\n<p>&nbsp;</p>\n<h1 style=\"margin-top: 0.375em; margin-right: 0px; margin-bottom: 0.375em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.3846em; font: inherit; vertical-align: baseline; line-height: 1.125em; font-family: arial, helvetica, clean, sans-serif; text-align: left; padding: 0px; border: 0px initial initial;\"></h1>\n<h1 style=\"margin-top: 0.375em; margin-right: 0px; margin-bottom: 0.375em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.3846em; font: inherit; vertical-align: baseline; line-height: 1.125em; padding: 0px; border: 0px initial initial;\" id=\"When_intentions_go_public__does_social_reality_widen_the_intention_behavior_gap_\">When intentions go public: does social reality widen the intention-behavior gap?</h1>\n<div class=\"auths\" style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 0.923em; font: inherit; vertical-align: baseline; padding: 0px; margin: 0px; border: 0px initial initial;\"><a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Gollwitzer%20PM%22%5BAuthor%5D\">Gollwitzer PM</a>,&nbsp;<a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Sheeran%20P%22%5BAuthor%5D\">Sheeran P</a>,&nbsp;<a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Michalski%20V%22%5BAuthor%5D\">Michalski V</a>,&nbsp;<a style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; color: #333333; border-bottom-style: initial; border-bottom-color: initial; text-decoration: underline; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=%22Seifert%20AE%22%5BAuthor%5D\">Seifert AE</a>.</div>\n<div class=\"aff\" style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 0.8465em; font: inherit; vertical-align: baseline; line-height: 1.0915em; padding: 0px; margin: 0px; border: 0px initial initial;\">\n<h3 class=\"label\" style=\"margin-top: 1.2856em; margin-right: 1em; margin-bottom: 0.6428em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.0769em; font: inherit; vertical-align: baseline; line-height: 1.2857; color: #724128; position: absolute; left: -10000px; top: auto; width: 1px; height: 1px; overflow-x: hidden; overflow-y: hidden; padding: 0px; border: 0px initial initial;\" id=\"Source\">Source</h3>\n<p style=\"margin-top: 0.5em; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 12px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">New York University, Psychology Department, New York, NY 10003, USA. peter.gollwitzer@nyu.edu</p>\n</div>\n<div class=\"abstr\" style=\"margin-top: 1.2em; margin-right: auto; margin-bottom: auto; margin-left: auto; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; line-height: 17px; padding: 0px; border: 0px initial initial;\">\n<h3 style=\"outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 1.0769em; font: inherit; vertical-align: baseline; line-height: 1.2857; color: #985735; padding: 0px; margin: 0px; border: 0px initial initial;\" id=\"Abstract\">Abstract</h3>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">Based on Lewinian goal theory in general and self-completion theory in particular, four experiments examined the implications of other people taking notice of one's identity-related behavioral intentions (e.g., the intention to read law periodicals regularly to reach the identity goal of becoming a lawyer). Identity-related behavioral intentions that had been noticed by other people were translated into action less intensively than those that had been ignored (Studies 1-3). This effect was evident in the field (persistent striving over 1 week's time; Study 1) and in the laboratory (jumping on opportunities to act; Studies 2 and 3), and it held among participants with strong but not weak commitment to the identity goal (Study 3). Study 4 showed, in addition, that when other people take notice of an individual's identity-related behavioral intention, this gives the individual a premature sense of possessing the aspired-to identity.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.5em; margin-left: 0px; outline-width: 0px; outline-style: initial; outline-color: initial; font-size: 13px; font: inherit; vertical-align: baseline; padding: 0px; border: 0px initial initial;\">If you have tags to suggest please do and I'll edit them in.</p>\n</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "sections": [{"title": "When intentions go public: does social reality widen the intention-behavior gap?", "anchor": "When_intentions_go_public__does_social_reality_widen_the_intention_behavior_gap_", "level": 1}, {"title": "Source", "anchor": "Source", "level": 2}, {"title": "Abstract", "anchor": "Abstract", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}