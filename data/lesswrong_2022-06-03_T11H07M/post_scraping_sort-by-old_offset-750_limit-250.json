{"results": [{"createdAt": null, "postedAt": "2009-03-20T22:28:03.357Z", "modifiedAt": null, "url": null, "title": "Support That Sounds Like Dissent", "slug": "support-that-sounds-like-dissent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:39.486Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vHCetv8tx6LbRtfyc/support-that-sounds-like-dissent", "pageUrlRelative": "/posts/vHCetv8tx6LbRtfyc/support-that-sounds-like-dissent", "linkUrl": "https://www.lesswrong.com/posts/vHCetv8tx6LbRtfyc/support-that-sounds-like-dissent", "postedAtFormatted": "Friday, March 20th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Support%20That%20Sounds%20Like%20Dissent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASupport%20That%20Sounds%20Like%20Dissent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvHCetv8tx6LbRtfyc%2Fsupport-that-sounds-like-dissent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Support%20That%20Sounds%20Like%20Dissent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvHCetv8tx6LbRtfyc%2Fsupport-that-sounds-like-dissent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvHCetv8tx6LbRtfyc%2Fsupport-that-sounds-like-dissent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 747, "htmlBody": "<p><strong>Related to</strong>: <a class=\"link\" title=\"Why Our Kind Can't Cooperate\" href=\"/lw/3h/why_our_kind_cant_cooperate/\" target=\"_self\">Why Our Kind Can't Cooperate</a></p>\n<p>Eliezer described a scene that's familiar to all of us:</p>\n<blockquote>\n<p>Imagine that you're at a conference, and the speaker gives a 30-minute talk.&nbsp; Afterward, people line up at the microphones for questions.&nbsp; The first questioner objects to the graph used in slide 14 using a logarithmic scale; he quotes Tufte on <em>The Visual Display of Quantitative Information</em>.&nbsp; The second questioner disputes a claim made in slide 3.&nbsp; The third questioner suggests an alternative hypothesis that seems to explain the same data...</p>\n</blockquote>\n<p>An outsider might conclude that this presentation went poorly, because all of the people who spoke afterwards seemed to disagree. Someone who had been to a few conferences would understand that this is normal; only the people who disagree speak up, while the the rest stay silent, because taking the mic to say \"me too!\" isn't a productive use of everyone's time. If you polled the audience, you might expect to find a few vocal dissenters against a silent majority. This is not what you would find.</p>\n<p>Consider this situation more closely. A series of people step up, and say things which sound like disagreement. But do they really disagree? The first questioner is only quibbling with a bit of the presentation; he hasn't actually disagreed with the main point. The second questioner has challenged one of the claims from the presentation, but ignored the rest. The third questioner has proposed an alternative hypothesis which might be true, but that doesn't mean the alternative hypothesis is true, or even that the questioner thinks it's likely. If you stopped and asked these questioners whether they agreed with the main thrust of the presentation, they would probably say that they do. Why, then, does it sound like everyone disagrees?</p>\n<p><a id=\"more\"></a></p>\n<p>In our community, we hold writing and arguments to a high standard, so when we see something that's imperfect, we speak up. Posting merely to indicate agreement (\"me too\") is strongly discouraged. In practice, this often translates into nit-picking: pointing out minor issues in reasoning or presentation that are easy to fix. We have lots of practice nit-picking, because we do it all the time with our own writings. We remove or rework weak arguments, expand on points that need clarification and tweak explanations with every draft. Revising a draft, however, does not mean questioning its premise; usually, by the time the first draft is finished, your mind is set, so the fact that you agree with your own paper is a given. When reviewing someone else's work, we transfer this skill, and something strange happens. If we agree, we want to help the author make it stronger, so we treat it as though we were revising our own draft, point out the sections which are weak, and explain why. If we disagree, we want to change the author's mind, so we point out the sections which caused us to disagree, and explain why. These two cases are hard to distinguish, and we usually forget to say which we're doing.</p>\n<p>Discussions on the internet are usually dominated by dissent. Conventional wisdom states that this is because critics speak louder, but I think this is amplified by posts that are meant to be supportive but sound too much like dissent. In order to combat this, I propose the following social norm:</p>\n<blockquote>\n<p>When criticizing something in a post other than the main point, authors should explicitly state whether they agree, disagree, or are unsure of the post as a whole.</p>\n</blockquote>\n<p>Imagine the same conference as earlier, except that each questioner starts by saying whether or not he agreed with the presentation. \"I agree with your conclusion. That said, the graph on slide 14 shouldn't use a logarithmic scale.\" \"I agree with most of what you said, but there's a claim on slide 3 I disagree with.\" \"I'm not sure whether I agree with your conclusion, because there's an alternative hypothesis that could explain the data.\" The content of these responses is the same, but the overall impression generated is very different; before, it seemed like everyone disagreed, but now it sounds like there's a consensus and they're resolving details. Since the impression people got of speakers' positions disagreed with what they would have said their positions were, that impression was false. That which can be destroyed by the truth, should be; therefore, if enforcing this rule really does change the tone of discussions, then rationalists should enforce it by asking people to clarify their positions.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AADZcNS24mmSfPp2w": 2, "izp6eeJJEg9v5zcur": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vHCetv8tx6LbRtfyc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 77, "baseScore": 85, "extendedScore": null, "score": 0.000144, "legacy": true, "legacyId": "142", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 85, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7FzD7pNm9X68Gp5ZC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 11, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-21T07:34:12.259Z", "modifiedAt": "2020-07-13T05:22:43.286Z", "url": null, "title": "Tolerate Tolerance", "slug": "tolerate-tolerance", "viewCount": null, "lastCommentedAt": "2020-10-19T23:23:23.954Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JKxxFseBWz8SHkTgt/tolerate-tolerance", "pageUrlRelative": "/posts/JKxxFseBWz8SHkTgt/tolerate-tolerance", "linkUrl": "https://www.lesswrong.com/posts/JKxxFseBWz8SHkTgt/tolerate-tolerance", "postedAtFormatted": "Saturday, March 21st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tolerate%20Tolerance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATolerate%20Tolerance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJKxxFseBWz8SHkTgt%2Ftolerate-tolerance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tolerate%20Tolerance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJKxxFseBWz8SHkTgt%2Ftolerate-tolerance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJKxxFseBWz8SHkTgt%2Ftolerate-tolerance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 640, "htmlBody": "<p>One of the likely characteristics of someone who sets out to be a \"rationalist\" is a lower-than-usual tolerance for flaws in reasoning.&nbsp; This doesn't strictly follow.&nbsp; You could end up, say, rejecting your religion, just because you spotted <em>more</em> or <em>deeper</em> flaws in the reasoning, not because you were, by your nature, <em>more annoyed</em> at a flaw of fixed size.&nbsp; But realistically speaking, a lot of us probably have our level of \"annoyance at all these flaws we're spotting\" set a bit higher than average.</p>\n<p>That's why it's so important for us to tolerate others' tolerance if we want to get anything done together.</p>\n<p>For me, the poster case of tolerance I need to tolerate is Ben Goertzel, who among other things runs an annual AI conference, and who has something nice to say about <em>everyone</em>.&nbsp; Ben even complimented the ideas of M*nt*f*x, <a href=\"http://tiny.cc/iGfkW\">the most legendary of all AI crackpots</a>.&nbsp; (M*nt*f*x <a href=\"http://tiny.cc/iGfkW#x1-190002.3.1\">apparently</a> started adding a link to Ben's compliment in his email signatures, presumably because it was the only compliment he'd ever gotten from a bona fide AI academic.)&nbsp; (Please do <em>not </em>pronounce his True Name correctly or he will be summoned here.)</p>\n<p>But I've come to understand that this is one of Ben's strengths&mdash;that he's nice to lots of people that others might ignore, including, say, me&mdash;and every now and then this pays off for him.</p>\n<p>And if I subtract points off Ben's reputation for finding something nice to say about people and projects that I think are hopeless&mdash;even <em>M*nt*f*x</em>&mdash;then what I'm doing is insisting that Ben <em>dislike everyone I dislike</em> before I can work with him.</p>\n<p>Is that a realistic standard?&nbsp; Especially if different people are annoyed in different amounts by different things?</p>\n<p>But it's hard to remember that when Ben is being nice to <em>so many</em> idiots.</p>\n<p>Cooperation is unstable, in both game theory and evolutionary biology, without <em>some </em>kind of punishment for defection.&nbsp; So it's one thing to subtract points off someone's reputation for mistakes they make <em>themselves, directly</em>.&nbsp; But if you also look askance at someone for <em>refusing to castigate</em> a person or idea, then that is <em>punishment of non-punishers,</em> a far more dangerous idiom that can lock an equilibrium in place even if it's harmful to <em>everyone</em> involved.<a id=\"more\"></a></p>\n<p>The danger of punishing nonpunishers is something I remind myself of, say, every time Robin Hanson points out a flaw in some academic trope and yet modestly confesses he could be wrong (and he's not wrong).&nbsp; Or every time I see Michael Vassar still considering the potential of someone who I wrote off as hopeless within 30 seconds of being introduced to them.&nbsp; I have to remind myself, \"Tolerate tolerance!&nbsp; Don't demand that your allies be <em>equally extreme</em> in their negative judgments of everything you dislike!\"</p>\n<p>By my nature, I <em>do</em> get annoyed when someone else seems to be giving too much credit.&nbsp; I don't know if everyone's like that, but I suspect that at least <em>some </em>of my fellow aspiring rationalists are.&nbsp; I wouldn't be surprised to find it a human universal; it does have an obvious evolutionary rationale&mdash;one which would make it a very <em>unpleasant</em> and <em>dangerous</em> adaptation.</p>\n<p>I am not generally a fan of \"tolerance\".&nbsp; I certainly don't believe in being \"intolerant of intolerance\", as some inconsistently hold.&nbsp; But I shall go on trying to tolerate <em>people who are more tolerant than I am</em>, and judge them only for their <em>own </em>un-borrowed mistakes.</p>\n<p>Oh, and it goes without saying that if the people of Group X are staring at you demandingly, waiting for you to hate the right enemies with the right intensity, and ready to castigate you if you fail to castigate loudly enough, you may be hanging around the wrong group.</p>\n<p>Just don't demand that <em>everyone</em> you work with be equally intolerant of behavior like that.&nbsp; Forgive your friends if some of them suggest that maybe Group X wasn't so awful after all...</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"chuP2QqQycjD8qakL": 1, "gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JKxxFseBWz8SHkTgt", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 87, "baseScore": 111, "extendedScore": null, "score": 0.000172, "legacy": true, "legacyId": "146", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "your-price-for-joining", "canonicalPrevPostSlug": "why-our-kind-can-t-cooperate", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 111, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 93, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-03-21T07:34:12.259Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-21T17:31:33.340Z", "modifiedAt": null, "url": null, "title": "Mind Control and Me", "slug": "mind-control-and-me", "viewCount": null, "lastCommentedAt": "2017-06-17T03:56:36.101Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Patrick", "createdAt": "2009-02-27T08:09:44.663Z", "isAdmin": false, "displayName": "Patrick"}, "userId": "KC7mjSorWj2XsdL3v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KMoXBt4QX7XvEoBgS/mind-control-and-me", "pageUrlRelative": "/posts/KMoXBt4QX7XvEoBgS/mind-control-and-me", "linkUrl": "https://www.lesswrong.com/posts/KMoXBt4QX7XvEoBgS/mind-control-and-me", "postedAtFormatted": "Saturday, March 21st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mind%20Control%20and%20Me&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMind%20Control%20and%20Me%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKMoXBt4QX7XvEoBgS%2Fmind-control-and-me%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mind%20Control%20and%20Me%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKMoXBt4QX7XvEoBgS%2Fmind-control-and-me", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKMoXBt4QX7XvEoBgS%2Fmind-control-and-me", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 355, "htmlBody": "<p>Reading Eliezer Yudkowsky's works have always inspired an insidious feeling in me, sort of a cross between righteousness, contempt, the fun you get from understanding something new and gravitas. It's a feeling that I have found to be pleasurable, or at least addictive enough to go through all of his OB posts,&nbsp; and the feeling makes me less skeptical and more obedient than I normally would be. For instance, in an act of uncharacteristic generosity, I decided to make a charitable donation on Eliezer's advice.</p>\n<p>Now this is probably a good idea, because the charity is probably going to help guys like me later on in life and of course it's the Right Thing to Do. But the bottom line is that I did something I normally wouldn't have because Eliezer told me to. My sociopathic selfishness was acting as canary in the mine of my psyche.</p>\n<p>Now this could be because Eliezer has <a href=\"http://yudkowsky.net/singularity/aibox\">creepy mind control powers</a>, but I get similar feelings when reading other people, such as George Orwell, Richard Stallman or Paul Graham. I even have a friend who can inspire that insidious feeling in me. So it's a personal problem, one that I'm not sure I want to remove, but I would like to understand it better.</p>\n<p>There are probably buttons being pushed by the style and the sort of ideas in the work that help to create the feeling, and I'll probably try to go over an essay or two and dissect it. However, I'd like to know who and at what times, if anyone at all, I should let create such feelings in me. Can I trust anyone that much, even if they aren't aware that they're doing it?</p>\n<p>I don't know if anyone else here has similar brain overrides, or if I'm just crazy, but it's possible that such brain overrides could be understood much more thoroughly and induced in more people.&nbsp; So what are the ethics of mind control (for want of a better term) and how much effort should we put in to stopping such feelings from occuring?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Edit Mar 22: Decided to remove the cryonics example due to factual inaccuracies.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KMoXBt4QX7XvEoBgS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}], "voteCount": 20, "baseScore": 12, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "150", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-21T19:22:02.606Z", "modifiedAt": null, "url": null, "title": "Individual Rationality Is a Matter of Life and Death", "slug": "individual-rationality-is-a-matter-of-life-and-death", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:15.851Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "patrissimo", "createdAt": "2009-03-01T21:01:34.487Z", "isAdmin": false, "displayName": "patrissimo"}, "userId": "jimxrRCsNY7PfcM6e", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WzMJRQBN3ryxiAbhi/individual-rationality-is-a-matter-of-life-and-death", "pageUrlRelative": "/posts/WzMJRQBN3ryxiAbhi/individual-rationality-is-a-matter-of-life-and-death", "linkUrl": "https://www.lesswrong.com/posts/WzMJRQBN3ryxiAbhi/individual-rationality-is-a-matter-of-life-and-death", "postedAtFormatted": "Saturday, March 21st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Individual%20Rationality%20Is%20a%20Matter%20of%20Life%20and%20Death&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIndividual%20Rationality%20Is%20a%20Matter%20of%20Life%20and%20Death%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWzMJRQBN3ryxiAbhi%2Findividual-rationality-is-a-matter-of-life-and-death%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Individual%20Rationality%20Is%20a%20Matter%20of%20Life%20and%20Death%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWzMJRQBN3ryxiAbhi%2Findividual-rationality-is-a-matter-of-life-and-death", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWzMJRQBN3ryxiAbhi%2Findividual-rationality-is-a-matter-of-life-and-death", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 672, "htmlBody": "<p>On at least two occasions - one only a year past - my life was at serious risk because I was not thinking clearly.&nbsp; Both times, I was lucky (and once, the car even survived!).&nbsp; As a gambler I don't like counting on luck, and I'd much rather be rational enough to avoid serious mistakes.&nbsp; So when I checked the top-ranked posts here and saw Robin's <a href=\"/lw/36/rational_me_or_we/\">Rational Me or We?</a> arguing against rationality as a martial art I was dumbfounded.&nbsp; To me, <em>individual rationality is a matter of life and death</em>[1].</p>\n<p>In poker, much attention is given to the sexy art of reading your opponent, but the true veteran knows that far more important is the art of reading and controlling yourself.&nbsp; It is very rare that a situation comes up where a \"tell\" matters, and each of my opponents is only in an occasional hand.&nbsp; I and my irrationalities, however, are in every decision in every hand.&nbsp; This is why self-knowledge and self-discipline are first-order concerns in poker, while opponent reading is second or perhaps even third.</p>\n<p>And this is why Robin's post is so wrong[2].&nbsp; Our minds and their irrationalities are part of every second of our lives, every moment we experience, and every decision that we make.&nbsp; And contra to Robin's security metaphor, few of our decisions can be outsourced.&nbsp; My two bad decisions regarding motor vehicles, for example, could not have easily been outsourced to a group rationality mechanism[3].&nbsp; Only a tiny percentage of the choices I make every day can be punted to experts.</p>\n<p><a id=\"more\"></a>We have long since left the Hobbesian world where physical security depends on individual skills, but when it comes to rationality, we <em>are</em> all \"isolated survivalist Einsteins\".&nbsp; We <em>are</em> in a world where our individual mental skills are constantly put to the test.&nbsp; And even when we can rely on experts, it is our individual choices (influenced by the quality of our minds) that determine our success in life.&nbsp; (How long would a professor's reputation last if he never did any original work?)</p>\n<p>So while I respect and admire Robin's interest in improving institutions, I believe that his characterization of the relative merits of individual and collective mechanisms is horridly wrong.&nbsp; To have more and better rational collective institutions is a speculative, long-term goal with limited scope (albeit in some very important areas).&nbsp; Learning the martial art of rationality is something that all of us can do now to improve the quality of our decisions and thus positively influence <em>every part of our lives</em>.&nbsp; By making us more effective as individuals (hell, just keeping us from stupidly getting ourselves killed), it will help us work on <em>all</em> of our goals - like getting society to accept <a href=\"http://hanson.gmu.edu/altinst.html\">ambitious new social institutions</a>.</p>\n<p>In the modern world, karate is unlikely to save your life.&nbsp; But rationality can.&nbsp; For example, if one believes that cryonics is a good gamble at immortality, and people don't do it because of irrationality, then improved individual rationality can give people a shot at immortality instead of certain death.&nbsp; And that's only one of the myriad decisions we each face in optimizing our life!</p>\n<p>Which is why, while I spend my days working on better institutions, I also practice my rationality <em>katas</em>, so that I will survive to reach the new future our institutions will bring.</p>\n<p>[1] I have a post about the more recent incident that's been written in my mind for months, and just hasn't fallen out onto the screen yet.</p>\n<p>[2] Or at least, this is related - I freely admit to liking poker metaphors enough that I'm willing to stretch to make them!</p>\n<p>[3] Yes, I'm sure a clever person can come up with markets to keep young men from doing stupid things with cars.&nbsp; That's not the point.&nbsp; Markets have significant overhead, and it takes high public interest for it to be worth opening, funding, trading in, and running a market.&nbsp; They may have great value for large decisions, but they are never going to replace the majority of decisions in our day to day lives.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "3QnDqGSdRMA5mdMM6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WzMJRQBN3ryxiAbhi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 25, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "145", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["w9kwayt5SWqBQe8Nx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-21T20:55:37.146Z", "modifiedAt": null, "url": null, "title": "The Power of Positivist Thinking", "slug": "the-power-of-positivist-thinking", "viewCount": null, "lastCommentedAt": "2021-04-03T13:35:25.919Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/azoP7WeKYYfgCozoh/the-power-of-positivist-thinking", "pageUrlRelative": "/posts/azoP7WeKYYfgCozoh/the-power-of-positivist-thinking", "linkUrl": "https://www.lesswrong.com/posts/azoP7WeKYYfgCozoh/the-power-of-positivist-thinking", "postedAtFormatted": "Saturday, March 21st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Power%20of%20Positivist%20Thinking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Power%20of%20Positivist%20Thinking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FazoP7WeKYYfgCozoh%2Fthe-power-of-positivist-thinking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Power%20of%20Positivist%20Thinking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FazoP7WeKYYfgCozoh%2Fthe-power-of-positivist-thinking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FazoP7WeKYYfgCozoh%2Fthe-power-of-positivist-thinking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2629, "htmlBody": "<p><strong>Related to: </strong><a href=\"http://www.overcomingbias.com/2008/08/no-logical-posi.html\">No Logical Positivist I</a>, <a href=\"http://www.overcomingbias.com/2007/07/making-beliefs-.html\">Making Beliefs Pay Rent</a>, <a href=\"http://www.overcomingbias.com/2008/02/algorithm-feels.html\">How An Algorithm Feels From Inside</a>, <a href=\"http://www.overcomingbias.com/2008/02/disguised-queri.html\">Disguised Queries</a></p>\n<p>Call me non-conformist, call me one man against the world, but...I kinda like logical positivism.<br /><br />The logical positivists were a dour, no-nonsense group of early 20th-century European philosophers. Indeed, the phrase \"no-nonsense\" seems almost invented to describe the Positivists. They liked nothing better then to reject the pet topics of other philosophers as being untestable and therefore meaningless. Is the true also the beautiful? Meaningless! Is there a destiny to the affairs of humankind? Meaningless? What is justice? Meaningless! Are rights inalienable? Meaningless!<br /><br />Positivism became stricter and stricter, defining more and more things as meaningless, until someone finally pointed out that positivism itself was meaningless by the positivists' definitions, at which point the entire system vanished in a puff of logic. Okay, it wasn't that simple. It took several decades and Popper's falsifiabilism to seal its coffin. But vanish it did. It remains one of the least lamented theories in the history of philosophy, because if there is one thing philosophers hate it's people telling them they can't argue about meaningless stuff.<br /><br />But if we've learned anything from fantasy books, it is that any cabal of ancient wise men destroyed by their own hubris at the height of their glory must leave behind a single ridiculously powerful artifact, which in the right hands gains the power to dispel darkness and annihilate the forces of evil.<br /><br />The positivists left us the idea of verifiability, and it's time we started using it more.</p>\n<p><a id=\"more\"></a><br /><br />Eliezer, in <a href=\"http://www.overcomingbias.com/2008/08/no-logical-posi.html\">No Logical Positivist I</a>, condemns the positivist notion of verifiability for excluding some perfectly meaningful propositions. For example, he says, it may be that a chocolate cake formed in the center of the sun on 8/1/2008, then disappeared after one second. This statement seems to be meaningful; that is, there seems to be a difference between it being true or false. But there's no way to test it (at least without time machines and sundiver ships, which we can't prove are possible) so the logical positivists would dismiss it as nonsense.<br /><br />I am not an expert in logical positivism; I have two weeks studying positivism in an undergrad philosophy class under my belt, and little more. If Eliezer says that is how the positivists interpreted their verifiability criterion, I believe him. But it's not the way I would have done things, if I'd been in 1930s Vienna. I would have said that any statement corresponding to a state of the material universe, reducible in theory to things like quarks and photons, testable by a being who has access to the machine running the universe<sup>1</sup> and who can check the logs at will - such a statement is meaningful<sup>2</sup>. In this case the chocolate cake example passes: it corresponds to a state of the material world, and is clearly visible on the universe's logs. \"Rights are inalienable\" remains meaningless, however. At the risk of reinventing the wheel<sup>3</sup>, I will call this interpretation \"soft positivism\".<br /><br />My positivism gets even softer, though. Consider the statement \"Google is a successful company.\" Though my knowledge of positivism is shaky, I believe that most positivists would reject this as meaningless; \"success\" is too fuzzy to be reduced to anything objective. But if positivism is true, it should add up to normality: we shouldn't find that an obviously useful statement like \"Google is a successful company\" is total nonsense. I interpret the statement to mean certain objectively true propositions like \"The average yearly growth rate for Google has been greater than the average yearly growth rate for the average company\", which itself reduces down to a question of how much money Google made each year, which is something that can be easily and objectively determined by anyone with the universe's logs.<br /><br />I'm not claiming that \"Google is a successful company\" has an absolute one-to-one identity with a statement about average growth rates. But the \"successful company\" statement is clearly allied with many testable statements. Average growth rate, average profits per year, change in the net worth of its founders, numbers of employees, et cetera. Two people arguing about whether Google was a successful company could in theory agree to create a formula that captures as much as possible of their own meaning of the word \"successful\", apply that formula to Google, and see whether it passed. To say \"Google is a successful company\" reduces to \"I'll bet if we established a test for success, which we are not going to do, Google would pass it.\"<br /><br />(Compare this to <a href=\"http://www.overcomingbias.com/2008/07/the-meaning-of.html\">Eliezer's meta-ethics</a>, where he says \"X is good\" reduces to \"I'll bet if we calculated out this gigantic human morality computation, which we are not going to do, X would satisfy it.\")<br /><br />This can be a very powerful method for resolving debates. I remember getting into an argument with my uncle, who believed that Obama's election would hurt America because having a Democratic president is bad for the economy. We were doing the normal back and forth, him saying that Democrats raised taxes which discouraged growth, me saying that Democrats tended to be more economically responsible and less ideologically driven, and we both gave lots of examples and we never would have gotten anywhere if I hadn't said \"You know what? Can we both agree that this whole thing is basically asking whether average GDP is lower under Democratic than Republican presidents?\" And he said \"Yes, that's pretty much what we're arguing about.\" So I went and got <a href=\"http://currencythoughts.com/2008/08/19/how-the-us-economy-performed-under-democrat-and-republican-presidents/\">the GDP statistics</a>, sure enough they were higher under Democrats, and he admitted I had a point<sup>4</sup>. <br /><br />But people aren't always as responsible as my uncle, and debates aren't always reducible to anything as simple as GDP. Consider: Zahra approaches Aaron and says: \"Islam is a religion of peace.\"<sup>5</sup><br /><br />Perhaps Aaron disagrees with this statement. Perhaps he begins debating. There are many things he could say. He could recall all the instances of Islamic terrorism, he could recite seemingly violent verses from the Quran, he could appeal to wars throughout history that have involved Muslims. I've heard people try all of these.<br /><br />And Zahra will respond to Aaron in the same vein. She will recite Quranic verses praising peace, and talk about all the peaceful Muslims who never engage in terrorism at all, and all of the wars started by Christians in which Muslims were innocent victims. I have heard all these too.<br /><br />Then Paula the Positivist comes by. \"Hey,\" she says, \"We should reduce this statement to testable propositions, and then there will be no room for disagreement.\"<br /><br />But maybe, if asked to estimate the percentage of Muslims who are active in terrorist groups, Aaron and Zahra will give the exact same number. Perhaps they are both equally aware of all the wars in history in which Muslims were either aggressors or peacemakers. They may both have the entire Quran memorized and be fully aware of all appropriate verses. But even after Paula has checked to make sure they agree on every actual real world fact, there is no guarantee that they will agree on whether Islam is a religion of peace or not.<br /><br />What if we ask Aaron and Zahra to reduce \"Islam is a religion of peace\" to an empirical proposition? In the best case, they will agree on something easy, like \"Muslims on average don't commit any more violent crimes than non-Muslims.\" Then you just go find some crime statistics and the problem is solved. In the second-best case, the two of them reduce it to completely different statements, like \"No Muslim has ever committed a violent act\" versus \"Not all Muslims are violent people.\" This is still a resolution to the argument; both Aaron and Zahra may agree that the first proposition is false and the second proposition is true, and they both agree the original statement was too vague to go around professing.<br /><br />In the worst-case scenario, they refuse to reduce the statement at all, or they deliberately reduce it to something untestable, or they reduce it to two different propositions but are outraged that their opponent is using a different proposition than they are and think their opponent's proposition is clearly not equivalent to the original statement.<br /><br />How are they continuing to disagree, when they agree on all of the relevant empirical facts and they fully understand the concept of reducing a proposition?<br /><br />In <a href=\"http://www.overcomingbias.com/2008/02/algorithm-feels.html\">How an Algorithm Feels From the Inside</a>, Eliezer writes about disagreement on definitions. \"We know where Pluto is, and where it's going; we know Pluto's shape, and Pluto's mass - but is it a planet?\" The question, he says, is meaningless. It's a spandrel from our cognitive algorithm, which works more efficiently if it assigns a separate central variable is_a_planet apart from all the actual tests that determine whether something is a planet or not.<br /><br />Aaron and Zahra seem to be making the same sort of mistake. They have a separate variable is_a_religion_of_peace that's sitting there completely separate from all of the things you might normally use to decide whether one group of people is generally more violent than another.<br /><br />But things get much worse than they do in the Pluto problem. Whether or not Pluto is a planet feels like a factual issue, but turns out to be underdetermined by the facts. Whether or not Islam is a religion of peace feels like a factual issue, but is really a false front for a whole horde of beliefs that have no relationship to the facts at all.<br /><br />When Zahra says \"Islam is a religion of peace,\" she is very likely saying something along the lines of \"I like Islam!\" or \"I like tolerance!\" or \"I identify with an in-group who say things like 'Islam is a religion of peace'\" or \"People who hate Islam are mean!\" or even \"I don't like Republicans.\". She may be covertly pushing policy decisions like \"End the war on terror\" or \"Raise awareness of unfair discrimination against Muslims.\"<br /><br />When Aaron says \"Islam is not a religion of peace,\" he is probably saying something like \"I don't like Islam,\" or \"I think excessive tolerance is harmful\", or \"I identify with an in-group who would never say things like 'Islam is a religion of peace'\" or even \"I don't like Democrats.\" He may be covertly pushing policy decisions like \"Continue the war on terror\" or \"Expel radical Muslims from society.\"<br /><br />Eliezer's solution to the Pluto problem is to uncover the <a href=\"http://www.overcomingbias.com/2008/02/disguised-queri.html\">disguised query</a> that made you care in the first place. If you want to know whether Pluto is spherical under its own gravity, then without worrying about the planet issue you can simply answer yes. And you're wondering whether to worry about your co-worker Abdullah bombing your office, you can simply answer no. Islam is peaceful enough for your purposes.<br /><br />But although uncovering the disguised query is a complete answer to the Pluto problem, it's only a partial answer to the religion of peace problem. It's unlikely that someone is going to misuse the definition of Pluto as a planet or an asteroid to completely misunderstand what Pluto is or what it's likely to do (although <a href=\"http://4.bp.blogspot.com/_YvWPoG3xhTk/RsOzS3lTAeI/AAAAAAAABxg/nK9HbwxAneM/s400/asteroid+pluto.jpg\">it can happen</a>). But the entire point of caring about the \"Islam is a religion of peace\" issue is so you can misuse it <em>as much as possible</em>.<br /><br />Israel is evil, because it opposes Muslims, and Islam is a religion of peace. The Democrats are tolerating Islam, and Islam is not a religion of peace, so the Democrats must have sold out the country. The War on Terror is racist, because Islam is a religion of peace. We need to ban headscarves in our schools, because Islam is not a religion of peace.<br /><br />I'm not sure how the chain of causation goes here. It could be (emotional attitude to Islam) -&gt; (Islam [is/isn't] a religion of peace) -&gt; (poorly supported beliefs about Islam). Or it could just be (emotional attitude to Islam) -&gt; (poorly supported beliefs about Islam). But even in the second case, that \"Islam [is/isn't] a religion of peace\" gives the poorly supported beliefs a dignity that they would not otherwise have, and allows the person who holds them to justify themselves in an argument. Basically, that one phrase holes itself up in your brain and takes pot shots at any train of thought that passes by.<br /><br />The presence of that extra is_a_religion_of_peace variable is not a benign feature of your cognitive process anymore. It's a malevolent mental smuggler transporting prejudices and strong emotions into seemingly reasonable thought processes.<br /><br />Which brings us back to soft positivism. If we find ourselves debating statements that we refuse to reduce to empirical data<sup>6</sup>, or using statements in ways their reductions don't justify, we need to be extremely careful. I am not positivist enough to say we should never be doing it. But I think it raises one heck of a red flag. <br /><br />Agree with me? If so, which of the following statements do you think are reducible, and how would you begin reducing them? Which are completely meaningless and need to be scrapped? Which ones raise a red flag but you'd keep them anyway?<br /><br />1. All men are created equal.<br />2. The lottery is a waste of hope.<br />3. Religious people are intolerant.<br />4. Government is not the solution; government is the problem.<br />5. George Washington was a better president than James Buchanan.<br />6. The economy is doing worse today than it was ten years ago.<br />7. God exists.<br />8. One impulse from a vernal wood can teach you more of man, of moral evil, and of good than all the sages can.<br />9. Imagination is more important than knowledge.<br />10. Rationalists should <em>win</em>.</p>\n<p>&nbsp;</p>\n<p><strong>Footnotes:</strong></p>\n<p><strong>1: </strong>More properly the machine running the multiverse, since this would allow counterfactuals to be meaningful. It would also simplify making a statement like \"The patient survived because of the medicine\", since it would allow quick comparison of worlds where the patient did and didn't receive it. But if the machine is running the multiverse, where's the machine?</p>\n<p><strong>2: </strong>One thing I learned from the comments on Eliezer's post is that this criterion is often very hard to apply in theory. However, it's usually not nearly as hard in practice.</p>\n<p><strong>3:</strong> This sounds like the sort of thing there should already be a name for, but I don't know what it is. Verificationism is too broad, and empiricism is something else. I should point out that I am probably misrepresenting the positivist position here quite badly, and that several dead Austrians are either spinning in their graves or (more likely) thinking that this whole essay is meaningless. I am using \"positivist\" only as a pointer to a certain <em>style </em>of thinking.</p>\n<p><strong>4: </strong>Before this issue dominates the comments thread: yes, I realize that the president having any impact on the economy is highly debatable, that there's not nearly enough data here to make a generalization, et cetera. But my uncle's statement - that Democratic presidents <em>hurt</em> the economy, is clearly not supported.</p>\n<p><strong>5: </strong>If your interpretation of anything in the following example offends you, please don't interpret it that way.</p>\n<p><strong>6: </strong>Where morality fits into this deserves a separate post.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"6nS8oYmSMuFMaiowF": 1, "SJFsFfFhE6m2ThAYJ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "azoP7WeKYYfgCozoh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 90, "baseScore": 90, "extendedScore": null, "score": 0.000139, "legacy": true, "legacyId": "152", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 90, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-21T23:22:50.348Z", "modifiedAt": "2020-01-25T22:48:41.133Z", "url": null, "title": "Don't Revere The Bearer Of Good Info", "slug": "don-t-revere-the-bearer-of-good-info", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:05.923Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "CarlShulman", "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tSgcorrgBnrCH8nL3/don-t-revere-the-bearer-of-good-info", "pageUrlRelative": "/posts/tSgcorrgBnrCH8nL3/don-t-revere-the-bearer-of-good-info", "linkUrl": "https://www.lesswrong.com/posts/tSgcorrgBnrCH8nL3/don-t-revere-the-bearer-of-good-info", "postedAtFormatted": "Saturday, March 21st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Don't%20Revere%20The%20Bearer%20Of%20Good%20Info&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADon't%20Revere%20The%20Bearer%20Of%20Good%20Info%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtSgcorrgBnrCH8nL3%2Fdon-t-revere-the-bearer-of-good-info%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Don't%20Revere%20The%20Bearer%20Of%20Good%20Info%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtSgcorrgBnrCH8nL3%2Fdon-t-revere-the-bearer-of-good-info", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtSgcorrgBnrCH8nL3%2Fdon-t-revere-the-bearer-of-good-info", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 831, "htmlBody": "<div>\n<p><strong>Follow-up to</strong>: <a href=\"http://www.overcomingbias.com/2007/12/every-cause-wan.html\">Every Cause Wants To Be A Cult</a>, <a href=\"http://www.overcomingbias.com/2007/12/cultish-counter.html\">Cultish Countercultishness</a></p>\n<p>One of the classic demonstrations of the <a href=\"http://en.wikipedia.org/wiki/Fundamental_attribution_error\">Fundamental Attribution Error</a> is the 'quiz study' of Ross, Amabile, and Steinmetz (1977). In the study, subjects were randomly assigned to either ask or answer questions in quiz show style, and were observed by other subjects who were asked to rate them for competence/knowledge. Even knowing that the assignments were random did not prevent the raters from rating the questioners higher than the answerers. Of course, when we rate individuals highly the <a href=\"http://www.overcomingbias.com/2007/11/affect-heuristi.html\">affect heuristic</a> comes into play, and if we're not careful that can lead to a super-happy <a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">death spiral</a> of reverence. Students can revere teachers or science popularizers (even devotion to Richard Dawkins can get a bit extreme at his busy web <a href=\"http://richarddawkins.net/\">forum</a>) simply because the former only interact with the latter in domains where the students know less. This is certainly a problem with blogging, where the blogger chooses to post in domains of expertise.</p>\n<p>Specifically, Eliezer's writing at Overcoming Bias has provided nice introductions to many standard concepts and arguments from philosophy, economics, and psychology: the philosophical compatibilist <a href=\"http://www.overcomingbias.com/2008/06/the-ultimate-so.html\">account</a> of free will, <a href=\"http://www.overcomingbias.com/2007/11/terminal-values.html\">utility functions</a>, <a href=\"http://www.overcomingbias.com/standard_biases/\">standard biases</a>, and much more. These are great concepts, and many commenters report that they have been greatly influenced by their introductions to them at Overcoming Bias, but the psychological default will be to overrate the messenger. This danger is particularly great in light of his <a href=\"http://www.overcomingbias.com/2009/02/against-propaganda-.html\">writing style</a>, and when the fact that a point is already extant in the literature, and is either being relayed or reinvented, isn't noted. To address a few cases of the latter: <a href=\"http://en.wikipedia.org/wiki/Gary_Drescher\">Gary Drescher</a> covered much of the content of Eliezer's Overcoming Bias posts (mostly very well), from timeless physics to Newcomb's problems to quantum mechanics, in a <a href=\"http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=10902\">book</a> back in May 2006, while Eliezer's irrealist meta-ethics would be very familiar to modern philosophers like <a href=\"http://philosophy.wisc.edu/info/2006%20Metaethics%20Workshop/loeb.doc\">Don Loeb</a> or <a href=\"http://www.wjh.harvard.edu/%7Ejgreene/GreeneWJH/Greene-Dissertation.pdf\">Josh Greene</a>, and isn't so far from the 18th century philosopher <a href=\"http://en.wikipedia.org/wiki/David_Hume\">David Hume</a>.</p>\n<p>If you're feeling a tendency to <a href=\"http://www.overcomingbias.com/2007/12/every-cause-wan.html\">cultish</a> hero-worship, reading such independent prior analyses is a <a href=\"http://www.overcomingbias.com/2007/12/cultish-counter.html\">noncultish</a> way to diffuse it, and the <a href=\"http://www.overcomingbias.com/2006/11/beware_amateur_.html\">history of science</a> suggests that this procedure will be applicable to almost anyone you're tempted to revere. <a href=\"http://en.wikipedia.org/wiki/Alfred_Russel_Wallace\">Wallace</a> invented the idea of evolution through natural selection independently of Darwin, and Leibniz and Newton <a href=\"http://en.wikipedia.org/wiki/Calculus#Modern\">independently</a> developed calculus. With respect to our other <a href=\"http://www.fhi.ox.ac.uk/\">host</a>, Hans Moravec <a href=\"http://www.boingboing.net/2007/08/15/hans-moravec-on-livi.html\">came up</a> with the probabilistic <a href=\"http://www.simulation-argument.com/\">Simulation Argument</a> long before Nick Bostrom became known for reinventing it (possibly with forgotten influence from reading the book, or its influence on interlocutors). When we post here we can make an effort to find and explicitly acknowledge such influences or independent discoveries, to recognize the contributions of <a href=\"/lw/36/rational_me_or_we\">Rational We</a>, as well as Me.</p>\n<p><a id=\"more\"></a></p>\n<p>Even if you resist revering the messenger, a well-written piece that purports to summarize a field can leave you ignorant of your ignorance. If you only read the <em><a href=\"http://en.wikipedia.org/wiki/National_Review\">National Review</a> </em>or <em>The <a href=\"http://en.wikipedia.org/wiki/The_Nation_Magazine\">Nation</a> </em>you will pick up a lot of political knowledge, including knowledge about the other party/ideology, at least enough to score well on political science <a href=\"http://www.jstor.org/pss/2111281\">surveys</a>. However, that very knowledge means that missing pieces favoring the other side can be more easily ignored: someone might not believe that the other side is made up of Evil <a href=\"http://www.overcomingbias.com/2007/06/are-your-enemie.html\">Mutants</a> with no reasons at all, and might be tempted to investigate, but ideological media can provide reasons that are plausible yet not so plausible as to be tempting to their audience. For a truth-seeker, beware of explanations of the speaker's opponents.</p>\n<p>This sort of intentional slanting and misplaced trust is less common in more academic sources, but it does occur. For instance, top philosophers of science have been <a href=\"http://www.ln.edu.hk/philoso/staff/sesardic/getfile.php?file=POS-2000.pdf\">caught</a> failing to <a href=\"http://www.overcomingbias.com/2007/11/beware-of-gould.html\">beware of Stephen J. Gould</a>, copying his citations and misrepresentations of work by <a href=\"http://en.wikipedia.org/wiki/Arthur_Jensen\">Arthur Jensen</a> without having read either the work in question or the more scrupulous treatments in the writings of Jensen's leading scientific opponents, the excellent <a href=\"http://en.wikipedia.org/wiki/James_R._Flynn\">James Flynn</a> and <a href=\"http://en.wikipedia.org/wiki/Richard_Nisbett\">Richard Nisbett</a>. More often, space constraints mean that a work will spend more words and detail on the view being advanced (<a href=\"http://www.overcomingbias.com/2009/01/disagreement-is-nearfar-bias.html\">Near</a>) than on those rejected (<a href=\"http://www.overcomingbias.com/2009/01/disagreement-is-nearfar-bias.html\">Far</a>), and limited knowledge of the rejected views will lead to omissions. Without reading the major alternative views to those of the one who introduced you to a field in their own words or, even better, neutral <a href=\"http://www.overcomingbias.com/2007/10/recommended-rat.html?cid=84749144#comment-84749144\">textbooks</a>, you <em>will </em>underrate opposing views.</p>\n<p>What do LW contributors recommend as the best articulations of alternative views to OB/LW majorities or received wisdom, or neutral sources to put them in context? I'll offer David Chalmers' <a href=\"http://www.amazon.com/Conscious-Mind-Search-Fundamental-Philosophy/dp/0195117891/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1237675338&amp;sr=1-1\"><em>The Conscious Mind</em></a> for reductionism, this article on <a href=\"http://www.ryerson.ca/%7Ekraay/Documents/Multiverse.pdf\">theistic modal realism</a> for the theistic (not <a href=\"http://www.overcomingbias.com/2007/10/avoiding-your-b.html\">Biblical</a>) Problem of Evil, and David Cutler's <a href=\"http://www.amazon.com/Your-Money-Life-Medicine-Americas/dp/0195160428\"><em>Your Money or Your Life</em></a> for the average (not marginal) value of medical spending. Across the board, the <a href=\"/%20I%20am%20aware%20of%20two%20good%20studies%20on%20the%20effect%20of%20priming%20in%20politics.%20In%20the%20first,%20subjects%20were%20subliminally2%20primed%20with%20either%20alphanumeric%20combinations%20that%20recalled%20the%209/11%20WTC%20attacks%20%28ie%20%22911%22%20or%20%22WTC%22%29,%20or%20random%20alphanumeric%20combinations.%20Then%20they%20were%20asked%20to%20rate%20the%20Bush%20administration%27s%20policies.%20Those%20who%20saw%20the%20random%20strings%20rated%20Bush%20at%20an%20unenthusiastic%2042%%20%282.1/5%29.%20Those%20who%20were%20primed%20to%20be%20thinking%20about%20the%20War%20on%20Terror%20gave%20him%20an%20astounding%2075%%20%283.75/5%29.%20This%20dramatic%20a%20change,%20even%20though%20none%20of%20them%20could%20consciously%20recall%20seeing%20terrorism-related%20stimuli.%20%20In%20the%20second%20study,%20scientists%20analyzed%20data%20from%20the%202000%20election%20in%20Arizona,%20and%20found%20that%20polling%20location%20had%20a%20moderate%20effect%20on%20voting%20results.%20That%20is,%20people%20who%20voted%20in%20a%20school%20were%20more%20likely%20to%20support%20education-friendly%20policies,%20people%20who%20voted%20in%20a%20church%20were%20more%20likely%20to%20support%20socially%20conservative%20policies,%20et%20cetera.%20The%20effect%20seems%20to%20have%20shifted%20results%20by%20about%20three%20percentage%20points.%20Think%20about%20all%20the%20elections%20that%20were%20won%20or%20lost%20by%20less%20than%20three%20percent...%20%20Objection:%20correlation%20is%20not%20causation%21%20Religious%20people%20probably%20live%20closer%20to%20churches,%20and%20are%20more%20likely%20to%20know%20where%20their%20local%20church%20is,%20and%20so%20on.%20So%20the%20scientists%20performed%20an%20impressive%20battery%20of%20regression%20analyses%20and%20adjustments%20on%20their%20data.%20Same%20response.%20%20Objection:%20maybe%20their%20adjustments%20weren%27t%20good%20enough%21%20The%20same%20scientists%20then%20called%20voters%20into%20their%20laboratory,%20showed%20them%20pictures%20of%20buildings,%20and%20asked%20them%20to%20cast%20a%20mock%20vote%20on%20the%20education%20initiatives.%20Voters%20who%20saw%20pictures%20of%20schools%20were%20more%20likely%20to%20vote%20yes%20on%20the%20pro-education%20initiatives%20than%20voters%20who%20saw%20control%20buildings.%20%20What%20techniques%20do%20these%20studies%20suggest%20for%20rationalists?%20I%27m%20tempted%20to%20say%20the%20optimal%20technique%20is%20to%20never%20leave%20your%20room,%20but%20there%20are%20still%20a%20few%20less%20extreme%20things%20you%20can%20do.%20First,%20avoid%20exposure%20to%20any%20salient%20stimuli%20in%20the%20few%20minutes%20before%20making%20an%20important%20decision.%20Everyone%20knows%20about%20the%209-11%20terrorist%20attacks,%20but%20the%20War%20on%20Terror%20only%20hijacked%20the%20decision-making%20process%20when%20the%20subjects%20were%20exposed%20to%20the%20related%20stimuli%20directly%20before%20performing%20the%20rating%20task3.%20%20Second,%20try%20to%20make%20decisions%20in%20a%20neutral%20environment%20and%20then%20stick%20to%20them.%20The%20easiest%20way%20to%20avoid%20having%20your%20vote%20hijacked%20by%20the%20location%20of%20your%20polling%20place%20is%20to%20decide%20how%20to%20vote%20while%20you%27re%20at%20home,%20and%20then%20stick%20to%20that%20decision%20unless%20you%20have%20some%20amazing%20revelation%20on%20your%20way%20to%20the%20voting%20booth.%20Instead%20of%20never%20leaving%20your%20room,%20you%20can%20make%20decisions%20in%20your%20room%20and%20then%20carry%20them%20out%20later%20in%20the%20stimulus-laden%20world.%20%20I%20can%27t%20help%20but%20think%20of%20the%20long%20tradition%20of%20master%20rationalists%20%22blanking%20their%20mind%22%20to%20make%20an%20important%20decision.%20Jeffreyssai%27s%20brain%20%22carefully%20put%20in%20idle%22%20as%20he%20descends%20to%20a%20bare%20white%20room%20to%20stage%20his%20crisis%20of%20faith.%20Anas%C3%BBrimbor%20Kellhus%20withdrawing%20into%20himself%20and%20entering%20a%20probability%20trance%20before%20he%20finds%20the%20Shortest%20Path.%20Your%20grandmother%20telling%20you%20to%20%22sleep%20on%20it%22%20before%20you%20make%20an%20important%20life%20choice.%20%20Whether%20or%20not%20you%20try%20anything%20as%20formal%20as%20that,%20waiting%20a%20few%20minutes%20in%20a%20stimulus-free%20environment%20before%20a%20big%20decision%20might%20be%20a%20good%20idea.%20%20%20%20%20Footnotes%20%201:%20I%20bet%20that%20sympathetic%20magic%20probably%20does%20have%20strong%20placebo-type%20effects%20for%20exactly%20these%20reasons,%20though.%20%202:%20Priming%20is%20one%20of%20the%20phenomena%20behind%20all%20the%20hype%20about%20subliminal%20advertising%20and%20other%20subliminal%20effects.%20The%20bad%20news%20is%20that%20it%27s%20real:%20a%20picture%20of%20popcorn%20flashed%20subliminally%20on%20a%20movie%20screen%20can%20make%20you%20think%20of%20popcorn.%20The%20good%20news%20is%20that%20it%27s%20not%20particularly%20dangerous:%20your%20thoughts%20of%20popcorn%20aren%27t%20any%20stronger%20or%20any%20different%20than%20they%27d%20be%20if%20you%20just%20saw%20a%20normal%20picture%20of%20popcorn.%20%203:%20The%20obvious%20objection%20is%20that%20if%20you%27re%20evaluating%20George%20Bush,%20it%20would%20be%20very%20strange%20if%20you%20didn%27t%20think%20of%20the%209-11%20terror%20attacks%20yourself%20in%20the%20course%20of%20the%20evaluation.%20I%20haven%27t%20seen%20any%20research%20addressing%20this%20possibility,%20but%20maybe%20hearing%20an%20external%20reference%20to%20it%20outside%20the%20context%20of%20your%20own%20thought%20processes%20is%20a%20stronger%20activation%20than%20the%20one%20you%20would%20get%20by%20coming%20up%20with%20the%20idea%20yourself.\">Stanford Encyclopedia of Philosophy</a> is a great neutral resource for philosophical posts.</p>\n<p>Offline Reference:</p>\n<p>Ross, L. D., Amabile, T. M. &amp; Steinmetz, J. L. (1977). Social roles, social control, and biases in social-perceptual processes. Journal of Personality and Social Psychology, 35, 485-494.</p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 2, "vcvfjGJwRmFbMMS3d": 1, "5f5c37ee1b5cdee568cfb0cb": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tSgcorrgBnrCH8nL3", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 104, "baseScore": 121, "extendedScore": null, "score": 0.000192, "legacy": true, "legacyId": "155", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 121, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 72, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["w9kwayt5SWqBQe8Nx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-22T06:57:46.809Z", "modifiedAt": null, "url": null, "title": "You're Calling *Who* A Cult Leader?", "slug": "you-re-calling-who-a-cult-leader", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:02.646Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cyzXoCv7nagDWCMNS/you-re-calling-who-a-cult-leader", "pageUrlRelative": "/posts/cyzXoCv7nagDWCMNS/you-re-calling-who-a-cult-leader", "linkUrl": "https://www.lesswrong.com/posts/cyzXoCv7nagDWCMNS/you-re-calling-who-a-cult-leader", "postedAtFormatted": "Sunday, March 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20You're%20Calling%20*Who*%20A%20Cult%20Leader%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYou're%20Calling%20*Who*%20A%20Cult%20Leader%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcyzXoCv7nagDWCMNS%2Fyou-re-calling-who-a-cult-leader%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=You're%20Calling%20*Who*%20A%20Cult%20Leader%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcyzXoCv7nagDWCMNS%2Fyou-re-calling-who-a-cult-leader", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcyzXoCv7nagDWCMNS%2Fyou-re-calling-who-a-cult-leader", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1418, "htmlBody": "<p><strong>Followup to</strong>:&nbsp; <a href=\"/lw/3h/why_our_kind_cant_cooperate\">Why Our Kind Can't Cooperate</a>, <a href=\"http://www.overcomingbias.com/2007/12/cultish-counter.html\">Cultish Countercultishness</a></p>\n<p>I used to be a lot more worried that I was a cult leader before I started reading <a href=\"http://news.ycombinator.com/\">Hacker News</a>.&nbsp; (WARNING:&nbsp; Do not click that link if you do not want another addictive Internet habit.)</p>\n<p>From time to time, on a mailing list or IRC channel or blog which I ran, someone would start talking about \"cults\" and \"echo chambers\" and \"coteries\".&nbsp; And it was a scary accusation, because no matter what kind of epistemic hygeine I try to practice myself, I can't look into <em>other </em>people's minds.&nbsp; I don't know if my long-time readers are agreeing with me because I'm making sense, or because I've developed <a href=\"http://www.overcomingbias.com/2008/10/shut-up-and-do.html\">creepy mind-control powers</a>.&nbsp; My readers are drawn from the nonconformist crowd&mdash;the <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">atheist/libertarian/technophile/sf-reader/Silicon-Valley/early-adopter</a> cluster&mdash;and so they certainly wouldn't <em>admit</em> to worshipping me even if they <em>were.</em></p>\n<p>And then I ran into Hacker News, where accusations in <em>exactly the same tone</em> were <a href=\"http://www.google.com/search?q=site:news.ycombinator.com+pg+cult\">aimed</a> at the site owner, Paul Graham.</p>\n<p>Hold on.&nbsp; <em>Paul Graham</em> gets the same flak <em>I</em> do?</p>\n<ul>\n<li>Paul Graham has written a word or two about rationality... in a much more matter-of-fact style.</li>\n<li>Paul Graham does not ask his readers for donations.&nbsp; He is independently wealthy.</li>\n<li>Paul Graham is not dabbling in mad-science-grade AI.&nbsp; He runs <a href=\"http://ycombinator.com/\">Y Combinator</a>, a seed-stage venture fund.</li>\n<li>Paul Graham is not trying to save the world.&nbsp; He's trying to help a new generation of entrepreneurs.</li>\n</ul>\n<p>I've never heard of Paul Graham saying or doing a <em>single thing</em> that smacks of cultishness.&nbsp; Not <em>one</em>.</p>\n<p>He just wrote some great <a href=\"http://www.paulgraham.com/articles.html\">essays</a> (that appeal especially to the nonconformist crowd), and started an online forum where some people who liked those essays hang out (among others who just wandered into that corner of the Internet).</p>\n<p>So when I read <a href=\"http://www.danielharan.com/2008/07/28/yc-is-a-cult/\">someone</a>:</p>\n<ol>\n<li>Comparing the long hours worked by Y Combinator startup founders to the sleep-deprivation tactic used in cults;</li>\n<li>Claiming that founders were asked to move to the Bay Area startup hub as a cult tactic of separation from friends and family;</li>\n</ol>\n<p>...well, that outright broke my suspension of disbelief.</p>\n<p><a id=\"more\"></a></p>\n<p>Something is going on here which has more to do with <a href=\"/lw/3h/why_our_kind_cant_cooperate\">the behavior of nonconformists in packs</a> than whether or not you can make a plausible case for cultishness or even <a href=\"http://www.overcomingbias.com/2007/12/every-cause-wan.html\">cultishness risk factors</a>.</p>\n<p>But there are aspects of this phenomenon that I don't understand, because I'm not feeling what they're feeling.</p>\n<p>Behold the following, which is my true opinion:</p>\n<p><em>\"G&ouml;del, Escher, Bach\" by Douglas R. Hofstadter is the most awesome book that I have ever read.&nbsp; If there is one book that emphasizes the tragedy of Death, it is this book, because it's terrible that so many people have died without reading it.</em></p>\n<p>I know people who would never say anything like that, or even think it: admiring <em>anything </em>that much would mean they'd joined a cult (<em>note: Hofstadter does not have a cult</em>).&nbsp; And I'm pretty sure that this negative reaction to strong admiration is what's going on with Paul Graham and his essays, and I begin to suspect that not a single thing more is going on with me.</p>\n<p>But I'm having trouble understanding this phenomenon, because I myself feel no barrier against admiring <em>G&ouml;del</em><em>, Escher, Bach</em> that highly.</p>\n<p>In fact, I would say that by far the most cultish-looking behavior on Hacker News is people trying to <em>show off how willing they are to disagree with Paul Graham.&nbsp; </em>Let me try to explain how this feels when <em>you're</em> the target of it:</p>\n<p>It's like going to a library, and when you walk in the doors, everyone looks at you, staring.&nbsp; Then you walk over to a certain row of bookcases&mdash;say, you're looking for books on writing&mdash;and at once several others, walking with stiff, exaggerated movements, select a <em>different</em> stack to read in.&nbsp; When you reach the bookshelves for Dewey decimal 808, there are several other people present, taking quick glances out of the corner of their eye while pretending not to look at you.&nbsp; You take out a copy of <em>The Poem's Heartbeat: A Manual of Prosody</em>.</p>\n<p>At once one of the others present reaches toward a different bookcase and proclaims, \"I'm not reading <em>The Poem's Heartbeat!</em>&nbsp; In fact, I'm not reading anything about poetry!&nbsp; I'm reading <em>The Elements of Style,</em> which is much more widely recommended by many <em>mainstream </em>writers.\"&nbsp; Another steps in your direction and nonchalantly takes out a second copy of <em>The Poem's Heartbeat,</em> saying, \"I'm not reading this book <em>just</em> because you're reading it, you know; I think it's a genuinely good book, myself.\"</p>\n<p>Meanwhile, a teenager who just happens to be there, glances over at the book.&nbsp; \"Oh, <em>poetry,</em>\" he says.</p>\n<p>\"Not exactly,\" you say.&nbsp; \"I just thought that if I knew more about how words <em>sound</em>&mdash;the rhythm&mdash;it might make me a better writer.\"</p>\n<p>\"Oh!\" he says, \"You're a writer?\"</p>\n<p>You pause, trying to calculate whether the term does you too much credit, and finally say, \"Well, I have a lot of readers, so I must be a writer.\"</p>\n<p>\"I plan on being a writer,\" he says.&nbsp; \"Got any tips?\"</p>\n<p>\"Start writing <em>now,</em>\" you say immediately.&nbsp; \"I once read that every writer has a million words of bad writing inside them, and you have to get it out before you can write anything good.&nbsp; Yes, one million.&nbsp; The sooner you start, the sooner you finish.\"</p>\n<p>The teenager nods, looking very serious.&nbsp; \"Any of these books,\" gesturing around, \"that you'd recommend?\"</p>\n<p>\"If you're interested in fiction, then definitely Jack Bickham's <em>Scene and Structure</em>,\" you say, \"though I'm still struggling with the form myself.&nbsp; I need to get better at description.\"</p>\n<p>\"Thanks,\" he says, and takes a copy of <em>Scene and Structure.</em></p>\n<p>\"Hold on!\" says the holder of <em>The Elements of Style</em> in a tone of shock.&nbsp; \"You're going to read that book <em>just because he told you to?</em>\"</p>\n<p>The teenager furrows his brow.&nbsp; \"Well, sure.\"</p>\n<p>There's an audible gasp, coming not just from the local stacks but from several other stacks nearby.</p>\n<p>\"Well,\" says the one who took the other copy of <em>The Poem's Heartbeat,</em> \"of course you mean that you're taking into account his advice about which books to read, but really, you're perfectly capable of deciding for yourself which books to read, and would never allow yourself to be swayed by arguments without adequate support.&nbsp; Why, I bet you can think of several book recommendations that you've rejected, thus showing your independence.&nbsp; Certainly, you would never go so far as to lose <em>yourself</em> in following someone <em>else's</em> book recommendations&mdash;\"</p>\n<p>\"<em>What?</em>\" says the teenager.</p>\n<p>If there's an aspect of the whole thing that annoys me, it's that it's hard to get that innocence back, once you even start thinking about whether you're <em>independent</em> of someone.&nbsp; I recently downvoted one of PG's comments on HN (for the first time&mdash;a respondent had pointed out that the comment was wrong, and it was).&nbsp; And I couldn't help thinking, \"Gosh, I'm downvoting one of PG's comments\"&mdash;no matter how silly that is in context&mdash;because the cached thought had been planted in my mind from reading other people arguing over whether or not HN was a \"cult\" and defending their own freedom to disagree with PG.</p>\n<p>You know, there might be some other things that I admire highly besides <em>G&ouml;del</em><em>, Escher, Bach,</em> and I might or might not disagree with some things Douglas Hofstadter once said, <em>but I'm not even going to list them,</em> because <em>GEB </em>doesn't <em>need</em> that kind of moderation.&nbsp; It is <em>okay</em> for <em>GEB </em>to be awesome.&nbsp; In this world there are people who have created awesome things and it is <em>okay</em> to admire them highly!&nbsp; Let this Earth have at least a little of its pride!</p>\n<p>I've been flipping through ideas that might explain the anti-admiration phenomenon.&nbsp; One of my first thoughts was that I evaluate my own potential so highly (rightly or wrongly is not relevant here) that praising <em>G&ouml;del</em><em>, Escher, Bach</em> to the stars doesn't feel like making myself inferior to Douglas Hofstadter.&nbsp; But upon reflection, I strongly suspect that I would feel no barrier to praising <em>GEB </em>even if I weren't doing anything much interesting with my life.&nbsp; There's some fear I don't feel, or some norm I haven't acquired.</p>\n<p>So rather than guess any further, I'm going to turn this over to my readers.&nbsp; I'm hoping in particular that someone <em>used</em> to feel this way&mdash;shutting down an impulse to praise someone else highly, or feeling that it was cultish to praise someone else highly&mdash;and then had some kind of epiphany after which it felt, not <em>allowed</em>, but rather, <em>quite normal</em>.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/4y/on_things_that_are_awesome/\">On Things that are Awesome</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/42/tolerate_tolerance/\">Tolerate Tolerance</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MXcpQvaPGtXpB6vkM": 1, "izp6eeJJEg9v5zcur": 1, "PHPHovzkfjyap9FiK": 2, "5f5c37ee1b5cdee568cfb345": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cyzXoCv7nagDWCMNS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 78, "baseScore": 60, "extendedScore": null, "score": 9.6e-05, "legacy": true, "legacyId": "157", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 60, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 121, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7FzD7pNm9X68Gp5ZC", "YdcF6WbBmJhaaDqoD", "YC3ArwKM8xhNjYqQK", "JKxxFseBWz8SHkTgt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-22T19:34:19.719Z", "modifiedAt": "2021-02-17T05:17:13.128Z", "url": null, "title": "Cached Selves", "slug": "cached-selves", "viewCount": null, "lastCommentedAt": "2020-10-26T09:38:16.236Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BHYBdijDcAKQ6e45Z/cached-selves", "pageUrlRelative": "/posts/BHYBdijDcAKQ6e45Z/cached-selves", "linkUrl": "https://www.lesswrong.com/posts/BHYBdijDcAKQ6e45Z/cached-selves", "postedAtFormatted": "Sunday, March 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cached%20Selves&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACached%20Selves%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBHYBdijDcAKQ6e45Z%2Fcached-selves%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cached%20Selves%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBHYBdijDcAKQ6e45Z%2Fcached-selves", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBHYBdijDcAKQ6e45Z%2Fcached-selves", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2221, "htmlBody": "<p>by Anna Salamon and Steve Rayhawk (joint authorship)</p>\n<p>Related to:&nbsp;<a href=\"http://www.overcomingbias.com/2008/05/beware-identity.html\">Beware identity</a></p>\n<p><em><strong>Update, 2021:</strong> I believe a large majority of the priming studies failed replication, though I haven't looked into it in depth.  I still personally do a great many of the \"possible strategies\" listed at the bottom; and they subjectively seem useful to me; but if you end up believing that it should not be on the basis of the claimed studies.</em></p>\n<p>A few days ago, Yvain <a href=\"/lw/3b/never_leave_your_room/\">introduced</a> us to priming, the effect where, in Yvain\u2019s words, \"any random thing that happens to you can hijack your judgment and personality for the next few minutes.\"</p>\n<p>Today, I\u2019d like to discuss a related effect from the social psychology and marketing literatures: \u201ccommitment and consistency effects\u201d, whereby any random thing <em>you say or do</em> in the absence of obvious outside pressure, can hijack your self-concept <em>for the medium- to long-term future</em>.</p>\n<p>To sum up the principle briefly: your brain builds you up a self-image. You are the kind of person who says, and does... whatever it is your brain remembers you saying and doing.&nbsp; So if you say you believe X... especially if no one\u2019s holding a gun to your head, and it looks superficially as though you endorsed X \u201cby choice\u201d... you\u2019re liable to \u201cgo on\u201d believing X afterwards.&nbsp; Even if you said X because you were lying, or because a salesperson tricked you into it, or because your neurons and the wind just happened to push in that direction at that moment.</p>\n<p>For example, if I hang out with a bunch of Green Sky-ers, and I make small remarks that accord with the Green Sky position so that they\u2019ll like me, I\u2019m liable to end up a Green Sky-er myself.&nbsp; If my friends ask me what I think of their poetry, or their rationality, or of how they look in that dress, and I choose my words slightly on the positive side, I\u2019m liable to end up with a falsely positive view of my friends.&nbsp; If I get promoted, and I start telling my employees that of course rule-following is for the best (because I want them to follow my rules), I\u2019m liable to start believing in rule-following in general.</p>\n<p>All familiar phenomena, right?&nbsp; You probably already discount other peoples\u2019 views of their friends, and you probably already know that <em>other</em> people mostly stay stuck in their own bad initial ideas.&nbsp; But if you\u2019re like me, you might not have looked carefully into the mechanisms behind these phenomena.&nbsp; And so you might not realize how much arbitrary influence consistency and commitment is having on <a href=\"http://www.overcomingbias.com/2007/04/knowing_about_b.html\">your own</a> beliefs, or how you can reduce that influence.&nbsp; (Commitment and consistency isn\u2019t the only mechanism behind the above phenomena; but it is <em>a</em> mechanism, and it\u2019s one that\u2019s more likely to persist even after you decide to <a href=\"http://hanson.gmu.edu/belieflikeclothes.html\">value</a> truth.)</p>\n<p>Consider the following research.</p>\n<p>In the classic 1959 <a href=\"http://psychclassics.yorku.ca/Festinger/\">study</a> by Festinger and Carlsmith, test subjects were paid to tell others that a tedious experiment has been interesting. &nbsp;Those who were paid $20 to tell the lie continued to believe the experiment boring; those paid a mere $1 to tell the lie were liable later to report the experiment interesting.&nbsp; The theory is that the test subjects remembered calling the experiment interesting, and either:</p>\n<ol>\n<li>Honestly figured they must have found the experiment interesting -- why else would they have said so for only $1?&nbsp; (This interpretation is called <a href=\"http://en.wikipedia.org/wiki/Self-perception_theory\">self-perception</a> theory.), or</li>\n<li>Didn\u2019t want to think they were the type to lie for just $1, and so deceived themselves into thinking their lie had been true.&nbsp; (This interpretation is one strand within <a href=\"http://en.wikipedia.org/wiki/Cognitive_dissonance\">cognitive dissonance</a> theory.)</li>\n</ol>\n<p>In a <a href=\"http://osil.psy.ua.edu:16080/~Rosanna/Soc_Inf/week9/693_long.pdf\">follow-up</a>, Jonathan Freedman used threats to convince 7- to 9-year old boys not to play with an attractive, battery-operated robot.&nbsp; He also told each boy that such play was \u201cwrong\u201d.&nbsp; Some boys were given big threats, or were kept carefully supervised while they played -- the equivalents of Festinger\u2019s $20 bribe.&nbsp; Others were given mild threats, and left unsupervised -- the equivalent of Festinger\u2019s $1 bribe.&nbsp; Later, instead of asking the boys about their verbal beliefs, Freedman arranged to test their actions.&nbsp; He had an apparently unrelated researcher leave the boys alone with the robot, this time giving them explicit permission to play.&nbsp; The results were as predicted.&nbsp; Boys who\u2019d been given big threats or had been supervised, on the first round, mostly played happily away.&nbsp; Boys who\u2019d been given only the mild threat mostly refrained.&nbsp; Apparently, their brains had looked at their earlier restraint, seen no harsh threat and no experimenter supervision, and figured that not playing with the attractive, battery-operated robot was the way they wanted to act.</p>\n<p>One interesting take-away from Freedman\u2019s experiment is that consistency effects change what we do -- they change the \u201cnear thinking\u201d beliefs that drive our decisions -- and not just our verbal/propositional claims about our beliefs.&nbsp; A second interesting take-away is that this belief-change happens even if we aren\u2019t thinking much -- Freedman\u2019s subjects were children, and a <a href=\"http://jbd.sagepub.com/cgi/content/refs/1/4/355\">related</a> \u201cforbidden toy\u201d experiment found a similar effect even in pre-schoolers, who just barely have propositional reasoning at all.</p>\n<p>Okay, so how large can such \u201cconsistency effects\u201d be?&nbsp; And how obvious are these effects -- now that you know the concept, are you likely to notice when consistency pressures change your beliefs or actions?</p>\n<p>In what is perhaps the most unsettling study I\u2019ve heard along these lines, Freedman and Fraser had an ostensible \u201cvolunteer\u201d go door-to-door, asking homeowners to put a big, ugly \u201cDrive Safely\u201d sign in their yard.&nbsp; In the control group, homeowners were just asked, straight-off, to put up the sign.&nbsp; Only 19% said yes.&nbsp; With this baseline established, Freedman and Fraser tested out some commitment and consistency effects.&nbsp; First, they chose a similar group of homeowners, and they got a new \u201cvolunteer\u201d to ask these new homeowners to put up a tiny three inch \u201cDrive safely\u201d sign; nearly everyone said yes.&nbsp; Two weeks later, the original volunteer came along to ask about the big, badly lettered signs -- and 76% of the group said yes, perhaps moved by their new self-image as people who cared about safe driving.&nbsp; Consistency effects were working.</p>\n<p>The unsettling part comes next; Freedman and Fraser wanted to know how <em>apparently unrelated</em> the consistency prompt could be.&nbsp; So, with a third group of homeowners, they had a \u201cvolunteer\u201d for an ostensibly unrelated non-profit ask the homeowners to sign a petition to \u201ckeep America beautiful\u201d.&nbsp; The petition was innocuous enough that nearly everyone signed it.&nbsp; And two weeks later, when the original guy came by with the big, ugly signs, nearly half of the homeowners said yes -- a significant boost above the 19% baseline rate.&nbsp; Notice that the \u201ckeep America beautiful\u201d petition that prompted these effects was: (a) a tiny and un-memorable choice; (b) on an apparently unrelated issue (\u201ckeeping America beautiful\u201d vs. \u201cdriving safely\u201d); and (c) <em>two weeks</em> before the second \u201cvolunteer\u201d\u2019s sign request (so we are observing medium-term attitude change from a single, brief interaction).</p>\n<p>These consistency effects are reminiscent of Yvain\u2019s large, unnoticed priming effects -- except that they\u2019re based on your actions rather than your sense-perceptions, and the influences last over longer periods of time.&nbsp; Consistency effects make us likely to stick to our past ideas, good or bad.&nbsp; They make it easy to freeze ourselves into our initial postures of <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">disagreement</a>, or agreement.&nbsp; They leave us vulnerable to a variety of sales tactics.&nbsp; They mean that if I\u2019m working on a cause, even a \u201crationalist\u201d cause, and I say things to try to engage new people, befriend potential donors, or get core group members to collaborate with me, my beliefs are liable to move toward whatever my allies want to hear.</p>\n<p>What to do?</p>\n<p>Some possible strategies (I\u2019m not recommending these, just putting them out there for consideration):</p>\n<ol>\n<li><strong>Reduce external pressures on your speech and actions</strong>, so that you won\u2019t make so many pressured decisions, and your brain won\u2019t cache those pressure-distorted decisions as indicators of your real beliefs or preferences.&nbsp; For example:\n<ul>\n<li><strong>1a.&nbsp; Avoid petitions, and other socially prompted or incentivized speech.</strong>&nbsp; Cialdini takes this route, in part. &nbsp;He writes: \u201c[The Freedman and Fraser study] scares me enough that I am rarely willing to sign a petition anymore, even for a position I support. &nbsp;Such an action has the potential to influence not only my future behavior but also my self-image in ways I may not want.\u201d</li>\n<li><strong>1b.&nbsp; Tenure, or independent wealth.</strong></li>\n<li><strong>1c.&nbsp; Anonymity.</strong></li>\n<li><strong>1d.&nbsp; Leave yourself \u201c<a href=\"/lw/3k/how_to_not_lose_an_argument/\">social lines of retreat</a>\u201d</strong>: avoid making definite claims of a sort that would be embarrassing to retract later.&nbsp; Another tactic here is to tell people in advance that you often change your mind, so that you\u2019ll be under less pressure not to.</li>\n</ul>\n</li>\n<li><strong>Only say things you don\u2019t mind being consistent with.</strong>&nbsp; For example:\n<ul>\n<li><strong>2a.&nbsp; Hyper-vigilant honesty.</strong>&nbsp;&nbsp;Take care never to say anything but what is best supported by the evidence, aloud or to yourself, lest you come to believe it.</li>\n<li><strong>2b.&nbsp; Positive hypocrisy.</strong>&nbsp; Speak and act like the person you wish you were, in hopes that you\u2019ll come to be them.&nbsp; (<a href=\"http://www.washingtonpost.com/wp-dyn/content/article/2009/01/05/AR2009010501863.html\">Apparently</a> this works.)</li>\n</ul>\n</li>\n<li><strong>Change or weaken your brain\u2019s notion of \u201cconsistent\u201d.</strong>&nbsp; Your brain has to be using prediction and classification methods in order to generate \u201c<a href=\"http://www.overcomingbias.com/2008/08/unnatural-categ.html\">consistent</a>\u201d behavior, and these can be hacked.\n<ul>\n<li><strong>3a.&nbsp; Treat $1 like a gun.</strong>&nbsp; Regard the decisions you made under slight monetary or social incentives as like decisions you made at gunpoint -- decisions that say more about the external pressures you were under, or about random dice-rolls in your brain, than about the truth.&nbsp; Take great care not to rationalize your past actions.</li>\n<li><strong>3b.&nbsp; <a href=\"http://www.overcomingbias.com/2008/12/devils-offers.html?cid=143466704#comment-143466704\"></a></strong> <strong><a href=\"http://www.overcomingbias.com/2008/12/devils-offers.html?cid=143466704#comment-143466704\">Build emotional comfort with lying</a></strong>, so you won\u2019t be tempted to rationalize your last week\u2019s false claim, or your next week\u2019s political convenience.&nbsp; Perhaps follow Michael Vassar\u2019s suggestion to lie on purpose in some unimportant contexts.</li>\n<li><strong>3c.&nbsp; Reframe your past behavior as having occurred in a different context, and as not bearing on today\u2019s decisions.</strong>&nbsp; Or add context cues to trick your brain into regarding today's decision as belonging to a different category than past decisions.&nbsp; This is, for example, part of how conversion experiences can help people change their behavior.&nbsp; (For a cheap hack, try traveling.)</li>\n<li><strong>3d.&nbsp; More specifically, visualize your life as something you just <a href=\"http://www.overcomingbias.com/2007/08/the-importance-.html?cid=83687583#comment-83687583\">inherited</a> from someone else</strong>; ignore sunk words as you would aspire to ignore sunk costs.</li>\n<li><strong>3e.&nbsp; Re-conceptualize your actions into schemas you don\u2019t mind propagating.</strong>&nbsp; If you\u2019ve just had some conversations and come out believing the Green Sky Platform, don\u2019t say \u201cso, I\u2019m a green sky-er\u201d.&nbsp; Say \u201cso, I\u2019m someone who changes my opinions based on conversation and reasoning\u201d.&nbsp; If you\u2019ve incurred repeated library fines, don\u2019t say \u201cI\u2019m so disorganized, always and everywhere\u201d.&nbsp; Say \u201cI have a pattern of forgetting library due dates; still, I\u2019ve been getting more organized with other areas of my life, and I\u2019ve changed harder habits many times before.\u201d</li>\n</ul>\n</li>\n<li><strong>Make a list of the most important consistency pressures on your beliefs, and consciously compensate for them.</strong>&nbsp; You might either consciously move in the opposite direction (I know I\u2019ve been hanging out with singularitarians, so I somewhat distrust my singularitarian impressions) or take extra pains to apply <a href=\"http://www.overcomingbias.com/2008/02/leave-retreat.html\">rationalist</a> <a href=\"http://www.overcomingbias.com/2007/10/avoiding-your-b.html\">tools</a> to any opinions you\u2019re under consistency pressure to have.&nbsp; Perhaps write <a href=\"/lw/u/the_ethic_of_handwashing_and_community_epistemic/gq#comments\">public</a> or <a href=\"http://www.overcomingbias.com/2009/02/write-your-hypothetical-apostasy.html\">private</a> critiques of your consistency-reinforced views (though Eliezer <a href=\"http://www.overcomingbias.com/2008/06/against-devils.html\">notes</a> reasons for caution with this one).</li>\n<li><strong>Build more reliably truth-indicative types of thought.</strong>&nbsp; Ultimately, both priming and consistency effects suggest that our <a href=\"/lw/1e/raising_the_sanity_waterline/\">baseline sanity level</a> is low; if small interactions can have large, arbitrary effects, our thinking is likely pretty arbitrary to <a href=\"/lw/3b/never_leave_your_room/2c9#comments\">to begin with</a>.&nbsp; Some avenues of approach:\n<ul>\n<li><strong>5a.&nbsp; Improve your general rationality skill</strong>, so that your thoughts have something else to be driven by besides your random cached selves.&nbsp; (It wouldn\u2019t surprise me if OB/LW-ers are less vulnerable than average to some kinds of consistency effects.&nbsp; We could test this.)</li>\n<li><strong>5b.&nbsp; Take your equals\u2019 opinions as seriously as you take the opinions of your ten-minutes-past self.</strong>&nbsp; If you often discuss topics with a comparably rational friend, and you two usually end with the same opinion-difference you began with, ask yourself why. An <em>obvious first hypothesis</em> should be \u201cirrational consistency effects\u201d: maybe you\u2019re holding onto particular conclusions, modes of analysis, etc., just because <a href=\"/lw/s/belief_in_selfdeception/\">your self-concept says you believe them</a>.</li>\n<li><strong>5c.&nbsp; Work more often from the raw data</strong>; explicitly distrust your beliefs about what you previously saw the evidence as implying. &nbsp;Re-derive the wheel, animated by a <a href=\"http://www.overcomingbias.com/2008/05/no-defenses.html\">core distrust</a> in your past self or <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">cached conclusions</a>. &nbsp;Look for <a href=\"http://www.overcomingbias.com/2007/10/original-seeing.html\">new thoughts</a>.</li>\n</ul>\n</li>\n</ol>\n", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"x6evH6MyPK3nxsoff": 2, "5f5c37ee1b5cdee568cfb0d6": 7}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BHYBdijDcAKQ6e45Z", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 191, "baseScore": 201, "extendedScore": null, "score": 0.000311, "legacy": true, "legacyId": "158", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 201, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 81, "af": false, "version": "1.2.0", "pingbacks": {"Posts": ["ZmQv4DFx6y4jFbhLy", "7FzD7pNm9X68Gp5ZC", "6yTShbTdtATxKonY5", "XqmjdBKa4ZaXJtNmf", "wP2ymm44kZZwaFPYh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 13, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-22T20:17:21.220Z", "modifiedAt": null, "url": null, "title": "Eliezer Yudkowsky Facts", "slug": "eliezer-yudkowsky-facts", "viewCount": null, "lastCommentedAt": "2022-02-23T18:56:42.333Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "steven0461", "createdAt": "2009-02-27T16:16:38.980Z", "isAdmin": false, "displayName": "steven0461"}, "userId": "cn4SiEmqWbu7K9em5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ndtb22KYBxpBsagpj/eliezer-yudkowsky-facts", "pageUrlRelative": "/posts/Ndtb22KYBxpBsagpj/eliezer-yudkowsky-facts", "linkUrl": "https://www.lesswrong.com/posts/Ndtb22KYBxpBsagpj/eliezer-yudkowsky-facts", "postedAtFormatted": "Sunday, March 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Eliezer%20Yudkowsky%20Facts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEliezer%20Yudkowsky%20Facts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdtb22KYBxpBsagpj%2Feliezer-yudkowsky-facts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Eliezer%20Yudkowsky%20Facts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdtb22KYBxpBsagpj%2Feliezer-yudkowsky-facts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdtb22KYBxpBsagpj%2Feliezer-yudkowsky-facts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 437, "htmlBody": "<ul>\n<li>Eliezer Yudkowsky was once attacked by a Moebius strip. He beat it to death with the other side, non-violently.</li>\n<li>Inside Eliezer Yudkowsky's pineal gland is not an immortal soul, but another brain.</li>\n<li>Eliezer Yudkowsky's favorite food is printouts of Rice's theorem.</li>\n<li>Eliezer Yudkowsky's favorite fighting technique is a roundhouse dustspeck to the face.</li>\n<li>Eliezer Yudkowsky once brought peace to the Middle East from inside a freight container, through a straw.</li>\n<li>Eliezer Yudkowsky once held up a sheet of paper and said, \"A blank map does not correspond to a blank territory\". It was thus that the universe was created.</li>\n<li>If you dial Chaitin's Omega, you get Eliezer Yudkowsky on the phone.</li>\n<li>Unless otherwise specified, Eliezer Yudkowsky knows everything that he isn't telling you.</li>\n<li>Somewhere deep in the microtubules inside an out-of-the-way neuron somewhere in the basal ganglia of Eliezer Yudkowsky's brain, there is a little XML tag that says <em>awesome</em>.</li>\n<li>Eliezer Yudkowsky is the Muhammad Ali of one-boxing.</li>\n<li>Eliezer Yudkowsky is a 1400 year old avatar of the Aztec god Aixitl.</li>\n<li>The game of \"Go\" was abbreviated from \"Go Home, For You Cannot Defeat Eliezer Yudkowsky\".</li>\n<li>When Eliezer Yudkowsky gets bored, he pinches his mouth shut at the 1/3 and 2/3 points and pretends to be a General Systems Vehicle holding a conversation among itselves. On several occasions he has managed to fool bystanders.</li>\n<li>Eliezer Yudkowsky has a swiss army knife that has folded into it a corkscrew, a pair of scissors, an instance of AIXI which Eliezer once beat at tic tac toe, an identical swiss army knife, and Douglas Hofstadter.</li>\n<li>If I am ignorant about a phenomenon, that is not a fact about the phenomenon; it just means I am not Eliezer Yudkowsky.</li>\n<li>Eliezer Yudkowsky has no need for induction or deduction. He has perfected the undiluted master art of <em>duction</em>.</li>\n<li>There was no ice age. Eliezer Yudkowsky just persuaded the planet to sign up for cryonics.</li>\n<li>There is no spacetime symmetry. Eliezer Yudkowsky just sometimes holds the territory upside down, and he doesn't care.</li>\n<li>Eliezer Yudkowsky has no need for doctors. He has implemented a Universal Curing Machine in a system made out of five marbles, three pieces of plastic, and some of MacGyver's fingernail clippings.</li>\n<li>Before Bruce Schneier goes to sleep, he scans his computer for uploaded copies of Eliezer Yudkowsky.</li>\n</ul>\n<p>If you know more Eliezer Yudkowsky facts, post them in the comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hNFdS3rRiYgqqD8aM": 8, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ndtb22KYBxpBsagpj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 257, "baseScore": 196, "extendedScore": null, "score": 0.000295, "legacy": true, "legacyId": "160", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 196, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 299, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 14, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-22T20:23:50.562Z", "modifiedAt": null, "url": null, "title": "When Truth Isn't Enough", "slug": "when-truth-isn-t-enough", "viewCount": null, "lastCommentedAt": "2021-10-05T23:21:16.342Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9hR2RmpJmxT8dyPo4/when-truth-isn-t-enough", "pageUrlRelative": "/posts/9hR2RmpJmxT8dyPo4/when-truth-isn-t-enough", "linkUrl": "https://www.lesswrong.com/posts/9hR2RmpJmxT8dyPo4/when-truth-isn-t-enough", "postedAtFormatted": "Sunday, March 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20When%20Truth%20Isn't%20Enough&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhen%20Truth%20Isn't%20Enough%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9hR2RmpJmxT8dyPo4%2Fwhen-truth-isn-t-enough%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=When%20Truth%20Isn't%20Enough%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9hR2RmpJmxT8dyPo4%2Fwhen-truth-isn-t-enough", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9hR2RmpJmxT8dyPo4%2Fwhen-truth-isn-t-enough", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 969, "htmlBody": "<p><strong>Continuation of: </strong><a href=\"/lw/48/the_power_of_positivist_thinking/\">The Power of Positivist Thinking</a></p>\n<p>Consider this statement:</p>\n<blockquote>\n<p>The ultra-rich, who control the majority of our planet's wealth, spend their time at cocktail parties and salons while millions of decent hard-working people starve.</p>\n</blockquote>\n<p>A soft positivist would be quite happy with this proposition. If we define \"the ultra-rich\" as, say, the richest two percent of people, then a quick look at the economic data shows they do control the majority of our planet's wealth. Checking up on the guest lists for cocktail parties and customer data for salons, we find that these two activities are indeed disproportionately enjoyed by the rich, so that part of the statement also seems true enough. And as anyone who's been to India or Africa knows, millions of decent hard-working people do starve, and there's no particular reason to think this isn't happening at the same time as some of these rich people attend their cocktail parties. The positivist scribbles some quick calculations on the back of a napkin and certifies the statement as <strong>TRUE</strong>. She hands it the Official Positivist Seal of Approval and moves on to her next task.<br /><br />But the truth isn't always enough. Whoever's making this statement has a much deeper agenda than a simple observation on the distribution of wealth and preferred recreational activities of the upper class, one that the reduction doesn't capture.</p>\n<p><a id=\"more\"></a></p>\n<p><br />Philosophers like to speak of the denotation and the connotation of a word. Denotations (not to be confused with <a href=\"http://www.philosophicallexicon.com/\">dennettations</a>, which are much more fun) are simple and reducible. To capture the denotation of \"old\", we might reduce it to something testable like \"over 65\". Is Methusaleh old? He's over 65, so yes, he is. End of story.<br /><br />Connotations<sup>0</sup> are whatever's left of a word when you subtract the denotation. Is Methusaleh old? How dare you use that word! He's a \"senior citizen!\" He's \"elderly!\" He's \"in his golden years.\" Each of these may share the same denotation as \"old\", but the connotation is quite different.<br /><br />There is, oddly enough, a children's game about connotations and denotations<sup>1</sup>. It goes something like this:</p>\n<blockquote>\n<p>I am intelligent. You are clever. He's an egghead.<br />I am proud. You are arrogant. He's full of himself.<br />I have perseverance. You are stubborn. He is pig-headed.<br />I am patriotic. You're a nationalist. He is jingoistic.</p>\n</blockquote>\n<p>Politicians like this game too. Their version goes:</p>\n<blockquote>\n<p>I care about the poor. You are pro-welfare. He's a bleeding-heart.<br />I'll protect national security. You'll expand the military. He's a warmonger.<br />I'll slash red tape. You'll decrease bureaucracy. He'll destroy safeguards.<br />I am eloquent. You're a good speaker. He's a demagogue.<br />I support free health care. You support national health care. He supports socialized health care.</p>\n</blockquote>\n<p>All three statements in a sentence have the same denotation, but very different connotations. The Connotation Game would probably be good for after-hours parties at the Rationality Dojo<sup>2</sup>, playing on and on until all three statements in a trio have mentally collapsed together.<br /><br />Let's return to our original statement: \"The ultra-rich, who control the majority of our planet's wealth, spend their time at cocktail parties and salons while millions of decent hard-working people starve.\" The denotation is a certain (true) statement about distribution of wealth and social activities of the rich. The connotation is hard to say exactly, but it's something about how the rich are evil and capitalism is unjust.<br /><br />There is a serious risk here, and that is to start using this statement to build your belief system. Yesterday, I suggested that saying \"Islam is a religion of peace\" is meaningless but affects you anyway. Place an overly large amount of importance on the \"ultra-rich\" statement, and it can play backup to any other communist beliefs you hear, even though it's trivially true and everyone from Milton Friedman on down agrees with it. The associated Defense Against The Dark Arts technique is <a href=\"/lw/48/the_power_of_positivist_thinking/\">to think like a positivist</a>, so that this statement and its reduced version sound equivalent<sup>3</sup>.<br /><br />...which works fine, until you get in an argument. Most capitalists I hear encounter this statement will flounder around a bit. Maybe they'll try to disprove it by <a href=\"http://www.overcomingbias.com/2007/03/policy_debates_.html\">saying something very questionable</a>, like \"If people in India are starving, then they're just not working hard enough!\" or \"All rich people deserve their wealth!<sup>4</sup> \"<br /><br />Let us take a moment to feel some sympathy for them. The statement sounds like a devastating blow against capitalism, but the capitalists cannot shoot it down because it's technically correct. They are forced to either resort to peddling falsehoods of the type described above, or to sink to the same level with replies like \"That sounds like the sort of thing <em>Stalin</em> would say!\" - which is, of course, denotatively true.<br /><br />What would I do in their position? I would stand tall and say \"Your statement is technically true, but I disagree with the connotations. If you state them explicitly, I will explain why I think they are wrong.\"<br /><br />YSITTBIDWTCIYSTEIWEWITTAW is a little long for an acronym, but ADBOC for \"Agree Denotationally But Object Connotationally could work. <em>[EDIT: Changed acronym to <a href=\"/lw/4h/when_truth_isnt_enough/38u#comments\">better suggestion by badger</a>]</em></p>\n<p><strong>Footnotes</strong></p>\n<p><strong>0: </strong>Anatoly Vorobey <a href=\"/lw/4h/when_truth_isnt_enough/38p#comments\">says in the comments</a> that I'm using the word connotation too broadly. He suggests \"subtext\".</p>\n<p><strong>1:</strong> I feel like I might have seen this game on Overcoming Bias before, but I can't find it there. If I did, apologies to the original poster.</p>\n<p><strong>2:</strong> Comment with any other good ones you know.</p>\n<p><strong>3:</strong> Playing the Connotation Game a lot might also give you partial immunity to this.</p>\n<p><strong>4: </strong>This is a great example of a hotly-debated statement that is desperately in need of reduction.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZXFpyQWPB5ideFbEG": 1, "Q6P8jLn8hH7kbuXRr": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9hR2RmpJmxT8dyPo4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 123, "baseScore": 130, "extendedScore": null, "score": 0.000198, "legacy": true, "legacyId": "161", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 130, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 59, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["azoP7WeKYYfgCozoh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-23T01:33:30.012Z", "modifiedAt": null, "url": null, "title": "BHTV: Yudkowsky & Adam Frank on \"religious experience\"", "slug": "bhtv-yudkowsky-and-adam-frank-on-religious-experience", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:26.354Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xDroHJ3AzWwJ45ufJ/bhtv-yudkowsky-and-adam-frank-on-religious-experience", "pageUrlRelative": "/posts/xDroHJ3AzWwJ45ufJ/bhtv-yudkowsky-and-adam-frank-on-religious-experience", "linkUrl": "https://www.lesswrong.com/posts/xDroHJ3AzWwJ45ufJ/bhtv-yudkowsky-and-adam-frank-on-religious-experience", "postedAtFormatted": "Monday, March 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20BHTV%3A%20Yudkowsky%20%26%20Adam%20Frank%20on%20%22religious%20experience%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABHTV%3A%20Yudkowsky%20%26%20Adam%20Frank%20on%20%22religious%20experience%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxDroHJ3AzWwJ45ufJ%2Fbhtv-yudkowsky-and-adam-frank-on-religious-experience%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=BHTV%3A%20Yudkowsky%20%26%20Adam%20Frank%20on%20%22religious%20experience%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxDroHJ3AzWwJ45ufJ%2Fbhtv-yudkowsky-and-adam-frank-on-religious-experience", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxDroHJ3AzWwJ45ufJ%2Fbhtv-yudkowsky-and-adam-frank-on-religious-experience", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 29, "htmlBody": "<p><a href=\"http://bloggingheads.tv/diavlogs/18501\">BHTV episode</a> with myself and Adam Frank, author of \"The Constant Fire\", on whether or not religious <em>experience</em> is compatible with the scientific experience, or worth trying to salvage.</p>\n<p><a id=\"more\"></a></p>\n<p><embed type=\"application/x-shockwave-flash\" width=\"380\" height=\"288\" src=\"http://static.bloggingheads.tv/maulik/offsite/offsite_flvplayer.swf\" flashvars=\"playlist=http%3A%2F%2Fbloggingheads%2Etv%2Fdiavlogs%2Fliveplayer%2Dplaylist%2F18501%2F00%3A00%2F62%3A34\"></embed></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xDroHJ3AzWwJ45ufJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 16, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "162", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-23T05:26:24.617Z", "modifiedAt": "2021-08-12T19:39:23.282Z", "url": null, "title": "I'm confused. Could someone help?", "slug": "i-m-confused-could-someone-help", "viewCount": null, "lastCommentedAt": "2009-03-24T20:10:27.764Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bWPog7DDNAhaqyaKW/i-m-confused-could-someone-help", "pageUrlRelative": "/posts/bWPog7DDNAhaqyaKW/i-m-confused-could-someone-help", "linkUrl": "https://www.lesswrong.com/posts/bWPog7DDNAhaqyaKW/i-m-confused-could-someone-help", "postedAtFormatted": "Monday, March 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I'm%20confused.%20Could%20someone%20help%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI'm%20confused.%20Could%20someone%20help%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbWPog7DDNAhaqyaKW%2Fi-m-confused-could-someone-help%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I'm%20confused.%20Could%20someone%20help%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbWPog7DDNAhaqyaKW%2Fi-m-confused-could-someone-help", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbWPog7DDNAhaqyaKW%2Fi-m-confused-could-someone-help", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>Imagine that I'm offering a bet that costs 1 dollar to accept. The prize is X + 5 dollars, and the odds of winning are 1 in X. Accepting this bet, therefore, has <del>an expected value of 5 dollars</del> a positive expected value, and offering it has an expected value of -5 dollars. It seems like a good idea to accept the bet, and a bad idea for me to offer it, for any reasonably sized value of X.</p>\n<p>Does this still hold for <strong>unreasonably</strong> sized values of X? Specifically, what if I make X really, really, big? If X is big enough, I can reasonably assume that, basically, nobody's ever going to win. I could offer a bet with odds of 1 in 10<sup>100</sup> once every second until the Sun goes out, and still expect, with near certainty, that I'll never have to make good on my promise to pay. So I can offer the bet without caring about its negative expected value, and take free money from all the expected value maximizers out there.</p>\n<p>What's wrong with this picture?</p>\n<p>See also: <a href=\"http://en.wikipedia.org/wiki/Taleb_distribution\">Taleb Distribution</a>, Nick Bostrom's version of <a href=\"http://www.nickbostrom.com/papers/pascal.pdf\">Pascal's Mugging</a></p>\n<p>(Now, in the real world, I obviously don't have 10<sup>100</sup> +5 dollars to cover my end of the bet, but does that really matter?)</p>\n<p>\n<hr />\nEdit: I should have actually done the math. :(</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HAFdXkW4YW4KRe2Gx": 1, "xexCWMyds6QLWognu": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bWPog7DDNAhaqyaKW", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "163", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-03-23T05:26:24.617Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-23T11:59:33.469Z", "modifiedAt": null, "url": null, "title": "Playing Video Games In Shuffle Mode", "slug": "playing-video-games-in-shuffle-mode", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:11.137Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "talisman", "createdAt": "2009-03-05T23:30:16.521Z", "isAdmin": false, "displayName": "talisman"}, "userId": "SXxD8wMPMJZZEdNZe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mY5SaNnugfEcj6957/playing-video-games-in-shuffle-mode", "pageUrlRelative": "/posts/mY5SaNnugfEcj6957/playing-video-games-in-shuffle-mode", "linkUrl": "https://www.lesswrong.com/posts/mY5SaNnugfEcj6957/playing-video-games-in-shuffle-mode", "postedAtFormatted": "Monday, March 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Playing%20Video%20Games%20In%20Shuffle%20Mode&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APlaying%20Video%20Games%20In%20Shuffle%20Mode%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmY5SaNnugfEcj6957%2Fplaying-video-games-in-shuffle-mode%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Playing%20Video%20Games%20In%20Shuffle%20Mode%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmY5SaNnugfEcj6957%2Fplaying-video-games-in-shuffle-mode", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmY5SaNnugfEcj6957%2Fplaying-video-games-in-shuffle-mode", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 116, "htmlBody": "<div>\n<p>One of the missions of OB/LW is to attract new learners, and it's clear that they <a href=\"/lw/4j/im_confused_could_someone_help\">are</a> <a href=\"/lw/46/mind_control_and_me\">succeeding</a>.&nbsp; But the format feels like a very difficult one for those new to these ideas, with <a href=\"/lw/4h/when_truth_isnt_enough\">beginner-level ideas</a> interspersed with <a href=\"/lw/3l/counterfactual_mugging/\">advanced or unsettled theory</a> and <a href=\"/lw/3h/why_our_kind_cant_cooperate\">meta-level discussions</a>.&nbsp;&nbsp;&nbsp; You wouldn't play &lt;insert cool-sounding, anime-ish video game here&gt; with the levels on shuffle mode, but reading Less Wrong must feel like doing so for initiates.</p>\n<p>How do we make the site better for learners?&nbsp; Provide a \"syllabus\" that shows a series of OB and LW posts which should be read in order?&nbsp; Have a separate beginner site or feed or header?&nbsp; Put labels on posts that designate them with a level?</p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "ZWmB62xB6uLyRuAtX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mY5SaNnugfEcj6957", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 20, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "168", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bWPog7DDNAhaqyaKW", "KMoXBt4QX7XvEoBgS", "9hR2RmpJmxT8dyPo4", "mg6jDEuQEjBGtibX7", "7FzD7pNm9X68Gp5ZC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-23T19:14:41.401Z", "modifiedAt": null, "url": null, "title": "Book: Psychiatry and the Human Condition", "slug": "book-psychiatry-and-the-human-condition", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:14.130Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "patrissimo", "createdAt": "2009-03-01T21:01:34.487Z", "isAdmin": false, "displayName": "patrissimo"}, "userId": "jimxrRCsNY7PfcM6e", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K588BN7RNpsrnjK2X/book-psychiatry-and-the-human-condition", "pageUrlRelative": "/posts/K588BN7RNpsrnjK2X/book-psychiatry-and-the-human-condition", "linkUrl": "https://www.lesswrong.com/posts/K588BN7RNpsrnjK2X/book-psychiatry-and-the-human-condition", "postedAtFormatted": "Monday, March 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Book%3A%20Psychiatry%20and%20the%20Human%20Condition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABook%3A%20Psychiatry%20and%20the%20Human%20Condition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK588BN7RNpsrnjK2X%2Fbook-psychiatry-and-the-human-condition%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Book%3A%20Psychiatry%20and%20the%20Human%20Condition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK588BN7RNpsrnjK2X%2Fbook-psychiatry-and-the-human-condition", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK588BN7RNpsrnjK2X%2Fbook-psychiatry-and-the-human-condition", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1892, "htmlBody": "<p>I'm about half-way through <a href=\"http://www.hedweb.com/bgcharlton/psychhuman.html\">this fascinating book, conveniently available for free online</a>, which is at the intersection of psychiatry and evolutionary psychology.&nbsp; I don't have the time to do it justice, so I'm going to post a few choice excerpts here in the hope that those who are more prolific and insightful than I am will add further analysis.</p>\n<p>Just to make sure it's clear how this all ties in to bias, I'll start with a bias-relevant section.&nbsp; The book ties delusional behavior in with the theory of consciousness as primarily existing for social intelligence purposes, and thus malfunctions in our reading of the social facts such as human intention are what cause delusions:</p>\n<p style=\"padding-left: 30px;\"><em>But some people with delusions are entirely &lsquo;normal&rsquo; except for the false belief, and the belief itself is neither impossible nor outlandish. Any other unusual behaviors can be traced back to that false belief. For instance, a man may have the fixed, false and dominating belief that his wife is having an affair with a neighbour. This belief may be so dominating as to lead to a large program of surveillance&nbsp; - spying on his wife, searching her handbag, examining her clothes etc. Yet the same man may show no evidence of irrationality in other areas of his life, being able to function normally at work and socializing easily with acquaintances, so that only close friends and family are aware of the existence of the delusion. In such instances the delusion is said to be &lsquo;encapsulated&rsquo;, ie. sealed-off from other aspects of mental life, and these people are said to have a delusional disorder.</em></p>\n<p style=\"padding-left: 30px;\"><em>...</em></p>\n<p style=\"padding-left: 30px;\"><em>Delusions are typically stated to have three major defining characteristics. Firstly that a delusional belief is false, secondly that this false belief is behaviorally dominant, and thirdly that the false belief is resistant to counter-argument. All these characteristics are shown by delusional disorders, yet they occur in a context of generally non-pathological cognitive functioning.</em></p>\n<p style=\"padding-left: 30px;\"><em><br />Humans are extremely prone to &lsquo;false&rsquo; beliefs, or at least beliefs that strike many or most other people as false. Some of these false beliefs are strongly held and dominate behavior. It is trivially obvious that humans are imperfect logicians operating for most of the time on incomplete information, so mistakes are inevitable. But it is striking that although everyone would acknowledge the imperfections of human reasoning, many of these false beliefs are not susceptible to argument. For example, deeply cherished religious and political beliefs are nonetheless based on little or no hard evidence, vary widely, yet may dominate a person&rsquo;s life, and are sometimes held with unshakeable intensity. And religious and political beliefs may strike the vast majority of other people as obviously false.</em></p>\n<p style=\"padding-left: 30px;\"><em><a id=\"more\"></a>...</em></p>\n<p style=\"padding-left: 30px;\"><em>On reflection, we all harbor beliefs that may strike other people as false, even abhorrent, yet they could not persuade us out of them, at least not over a short timescale. Deeply felt beliefs do sometimes change over a lifetime but not necessarily as a consequence of compelling evidence - people sometimes change their political views, convert to a new religion or to agnosticism, and in their personal lives go through several revisions of their opinion about who is the most beautiful and desirable woman/ man in the world.</em></p>\n<p style=\"padding-left: 30px;\"><em><br />In other words, delusions are a part of everyday life - but all these everyday delusions are of a particular sort. They are all delusions in relation to social intelligence. At root, all these false, or at least unjustifiable, beliefs are based upon interpretations of the human world. Even some of the more strange beliefs people have about cosmology and metaphysics often boil down to beliefs about agency - the power and influence of powerful and influential agents - whether human or supernatural.</em></p>\n<p>The book is hosted on HedWeb, and you can see why - it has a DIY transhumanism ethos that is happy to leap from diagnosis to ideas about treatment:</p>\n<p style=\"padding-left: 30px;\"><em>Psychiatry and the Human Condition provides an optimistic vision of a superior alternative approach to psychiatric illness and its treatment, drawing upon modern neuroscience and evolutionary theory. Psychiatric signs and symptoms - such as anxiety, insomnia, malaise, fatigue - are part of life for most people, for much of the time. This is the human condition. But psychiatry has the potential to help. In particular, psychotropic drugs could enable more people to lead lives that are more creative and fulfilled. Current classifications and treatments derive from a century-old framework which now requires replacement. Available psychotropic drugs are typically being used crudely, and without sufficient attention to their psychological effects.<br /><br />We can do better. This book argues that obsolete categories of diseases and drugs should be scrapped. The new framework of understanding implies that clinical management should focus on the treatment of biologically-valid symptoms and signs, and include a much larger role for self-treatment.</em></p>\n<p>It discusses the economics of hunter-gatherer societies, which provides a clue about several biases:</p>\n<p style=\"padding-left: 30px;\"><em>Most people&rsquo;s ideas of &lsquo;primitive&rsquo; or &lsquo;tribal&rsquo; life is based on agricultural or herding modes of production. In such societies there is invariably domination of the mass of people by a &lsquo;chief&rsquo; (plus henchmen) who appropriate a large share of resources. But in an &lsquo;immediate return&rsquo; or &lsquo;simple hunter-gatherer&rsquo; economy there is an extremely egalitarian social system, with very little in the way of wealth differentials. Food is gathered on a roughly daily basis for rapid consumption, and tools or other artifacts were made as required. There was no surplus of food or material goods, no significant storage of accumulated food or other resources, and the constraints of nomadic life meant that artifacts can not be accumulated.<br /><br />One of the most distinctive features of foraging societies, as contrasted with human societies that currently exist, was that ancestral societies were to a high degree egalitarian and without significant or sustained differentials in resources among men of the same age. There were indeed differentials in resource allocation according to age and sex (eg. adults ate more than children, men ate more than women) - but there was not a class or caste system, society was not stratified into rich and poor people who tended to pass their condition on to their children.<br /><br />This equality of outcome is achieved in immediate-return economies by a continual process of redistribution through the sharing of food on a daily basis, and through continual equalizing redistribution of other goods. The sharing may be accomplished in various ways in different societies, including gambling games of chance or the continual circulation of artifacts as gifts. But the important common feature is that sharing is enforced by a powerful egalitarian ethos which acts to prevent a concentration of power in few hands, and in which participants are &lsquo;vigilant&rsquo; in favour of making sure that no-one else takes more than themselves. If each individual person ensures that no-one else gets more than they do, the outcome is equality.</em></p>\n<p>You can see here the roots of pessimisstic bias (the belief that material wealth is increasing far more slowly than it is), since in the HG society, there was no ability to leverage capital to exponentially grow wealth over time.&nbsp; Also, this means no intuitive understanding of how small differences in personal or national productivity can lead over time to huge differences in wealth.&nbsp; The progressive passion for equality through redistribution and their blind spot about the growth-choking effect of these policies makes sense too - in the HG environment, there was no capital growth, so redistribution didn't choke growth, it just helped everyone stay fed.&nbsp; Suspicion of the very wealthy makes sense, because there was no way for a HG to become very wealthy, as there was no storage of important resources.</p>\n<p style=\"padding-left: 30px;\"><em>Of the three kinds of society as described by Gellner: hunter-gatherer, agrarian, and mercantile, it is probable that hunter-gatherers had the best life, overall. Hunter gatherer societies are the happiest and peasant societies are the most miserable - while industrial-mercantile societies such as our own lie somewhere in between.<br /><br />That, at any rate, is the conclusion of anthropologist Jerome Barkow - and his opinion is widely confirmed by the reports of many independent anthropologists who have experienced the alternatives of foraging, agrarian and industrial society...<br /><br />Another line of evidence is patterns of voluntary migration. When industrial mercantile societies develop, they are popular with the miserable peasantry of agrarian societies who flee the land and crowd the cities, if given the chance. Not so the happier hunter gatherers who typically must be coerced into joining industrial life. My great grandparents left their lives as rural peasants and converged from hundreds of miles and several countries to work the coal mines of Northumberland. They swapped the open sky, fields and trees for a life underground and inhabiting dingy rows of colliery houses. Being a miner in the early twentieth century must have been grim, but apparently it was not so bad as being an agricultural laborer.</em></p>\n<p>My hypothesis is that when most people think about people in the third world moving to factory jobs, they model the current state of those people as happy hunter-gatherers. Our idealized vision of the happy past is our instinct about happy hunter-gatherers applied incorrectly to agrarian societies. In practice, there are very few hunter-gatherers left, and the reason people go to sweatshop jobs is because those jobs are far better than the miserable toil of subsistence farming.<br /><br />(Which rather begs the question of why people move to subsistence farming. Perhaps it's a group selection thing - agrarian societies are so much more productive (they accumulate capital, albeit slowly, and can support much larger population bases which means more ideas and gains from trade) that those who choose them outcompete those who don't.)</p>\n<p>It then moves on to meatier psychiatric topics, like the crapitude of the current taxonomy for psychiatric disorders:</p>\n<p style=\"padding-left: 30px;\"><em>These diagnostic systems employ a syndromal system of classification that derives ultimately from the work of the psychiatrist Emil Kraepelin about a hundred years ago, and is therefore termed the &lsquo;neo-Kraeplinian&rsquo; nosology. Whether or not a psychiatrist uses the formal diagnostic criteria, the neo-Kraeplinian nosology has now become ossified in the DSM and ICD manuals. Over the past few decades the mass of published commentary and research based on this nosology has created a climate of opinion to challenge which is seen as not so much mistaken as absurd.</em></p>\n<p style=\"padding-left: 30px;\"><em><br />Yet the prevailing neo-Kraeplinian nosology is a mish-mash of syndromes that have widely varying plausibility and coherence. Some diagnoses are probably indeed biologically valid - having perhaps a single cause, occurring in a single psychological functional system, or having a unified pathology (some of the anxiety disorders, for instance, such as generalized anxiety, panic and simple phobias) But from the perspective of providing a sound basis for scientific research, especially for the core diagnoses of the &lsquo;functional psychoses&rsquo;, the whole thing is a terrible, misleading mess.<br />&nbsp;<br />It might be thought that the current diagnostic schemes are supported by a wealth of scientific research. But almost the opposite is the case. Despite widespread skepticism in the research literature about the validity of the current diagnostic categories, it is still the case that almost all biological research is based upon neo-Kraeplinian diagnoses, them rather than neo-Kraeplinian diagnoses being based on research.</em></p>\n<p>There is lots more to be read and said, hopefully this has piqued your interest.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4Kcm4etxAJjmeDkHP": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K588BN7RNpsrnjK2X", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 10, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "170", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-23T21:25:26.871Z", "modifiedAt": null, "url": null, "title": "Thoughts on status signals", "slug": "thoughts-on-status-signals", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:02.216Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pwno", "createdAt": "2009-02-27T06:17:31.584Z", "isAdmin": false, "displayName": "pwno"}, "userId": "SCgoHNxqc2agmDWEg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BdS9TaSJPZZpq2Zxn/thoughts-on-status-signals", "pageUrlRelative": "/posts/BdS9TaSJPZZpq2Zxn/thoughts-on-status-signals", "linkUrl": "https://www.lesswrong.com/posts/BdS9TaSJPZZpq2Zxn/thoughts-on-status-signals", "postedAtFormatted": "Monday, March 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Thoughts%20on%20status%20signals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThoughts%20on%20status%20signals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBdS9TaSJPZZpq2Zxn%2Fthoughts-on-status-signals%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Thoughts%20on%20status%20signals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBdS9TaSJPZZpq2Zxn%2Fthoughts-on-status-signals", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBdS9TaSJPZZpq2Zxn%2Fthoughts-on-status-signals", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 575, "htmlBody": "<p>The LW community knows all too well about the status-seeking tendencies everyone has, not excluding themselves. However, the discussion on status signaling needs to be developed further. Here are some questions I don&rsquo;t think have been addressed: what can we conclude about people who are blatantly signaling higher status? Should we or can we stop people from signaling?</p>\n<p>First, let me clarify what I believe to be the nature of status signals. A status signal only exists in certain contexts. A signal in one community may not be affective in another simply because the other community has a different value system. Driving up to a Singularity Summit with 24 inch spinning rims on your car will signal low status, if anything.</p>\n<p>An interesting property of status signals is that they expire. If everybody knows that everybody knows that a certain behavior has been used as a status signal in the past, it no longer works. One example of a status signal that is nearing expiration is buying an unacquainted woman a drink at the bar (note the context I am referring to; buying someone a drink may signal high status in other contexts). There is nothing inherently wrong with this act; it&rsquo;s just that women know that most men are just trying to signal for high status&mdash;therefore, the signal won&rsquo;t work. Some men know that women know about this signal and, thus, stop using the signal.</p>\n<p>On LW, one signal on the verge of expiring is being a contrarian about everything or always finding faults with another&rsquo;s arguments. This, however, could lead to a new anti-signal signal: agreeing too much. <span>&nbsp;</span></p>\n<p>Signals that have completely expired are infinitely more numerous. For example, showing your resume or college transcript in most contexts is unacceptable. Even when applying for a job, the resume is no longer sufficient&mdash;several interviews are now necessary. Of course, in the interviews, the interviewer is just looking for unexpired signals i.e. signals they don&rsquo;t know are signals. <span>&nbsp;</span></p>\n<p>This discussion on the expiration of signals raises this question: why do signals expire?</p>\n<p>When A realizes that B is signaling, B&rsquo;s incentive scheme is exposed. A knows that B is trying to make himself appear higher status in the eyes of A or anyone else he is signaling to. Furthermore, A knows that B thinks A doesn&rsquo;t know the signal is, in fact, a signal. Otherwise, B wouldn&rsquo;t have done the signal. A now knows that B is trying to impress (a low status behavior by the way) and therefore has the incentive to lie. Since A knows that B doesn&rsquo;t know that A knows he is signaling, A figures B thinks he can get away with lying or exaggerating the truth. Since A knows that B has the incentive to lie, A will find the signal not credible. In short, a signal expires once it&rsquo;s common knowledge that the signal is a signal.</p>\n<p>In an ideal world, we would all just cooperate and tell the truth about ourselves and we wouldn&rsquo;t have to play this silly signal game. Unfortunately, if people start cooperating, the incentive to defect just gets higher. As you see, this is a classic Prisoner&rsquo;s Dilemma game.</p>\n<p>How can we get people to tell the truth?</p>\n<p>Easy, everyone needs to learn about status-seeking behavior in order to weed out unreliable signals. The signal game may never end, but with everyone&rsquo;s knowledge of status-seeking behaviors, the signals that aren&rsquo;t yet weeded out will correspond more accurately to one&rsquo;s true status.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2EFq8dJbxKNzforjM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BdS9TaSJPZZpq2Zxn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 8, "extendedScore": null, "score": 4.831714118863163e-07, "legacy": true, "legacyId": "174", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-24T00:10:44.198Z", "modifiedAt": null, "url": null, "title": "Bogus Pipeline, Bona Fide Pipeline", "slug": "bogus-pipeline-bona-fide-pipeline", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.665Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8KhThQXzsAEZ59iko/bogus-pipeline-bona-fide-pipeline", "pageUrlRelative": "/posts/8KhThQXzsAEZ59iko/bogus-pipeline-bona-fide-pipeline", "linkUrl": "https://www.lesswrong.com/posts/8KhThQXzsAEZ59iko/bogus-pipeline-bona-fide-pipeline", "postedAtFormatted": "Tuesday, March 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bogus%20Pipeline%2C%20Bona%20Fide%20Pipeline&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABogus%20Pipeline%2C%20Bona%20Fide%20Pipeline%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8KhThQXzsAEZ59iko%2Fbogus-pipeline-bona-fide-pipeline%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bogus%20Pipeline%2C%20Bona%20Fide%20Pipeline%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8KhThQXzsAEZ59iko%2Fbogus-pipeline-bona-fide-pipeline", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8KhThQXzsAEZ59iko%2Fbogus-pipeline-bona-fide-pipeline", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1028, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/3b/never_leave_your_room/\">Never Leave Your Room</a></p>\n<p>Perhaps you are a psychologist, and you wish to do a study on racism. Maybe you want to know whether racists drink more coffee than non-racists. Sounds easy. Find a group of people and ask them how racist they are, then ask them how much coffee they drink.<br /><br />Problem: everyone in your study says they're completely non-racist and some of their best friends are black and all races are equally part of this vast multicolored tapestry we call humanity. Maybe some of them are stretching the truth here a bit. Until you figure out which ones, you're never going to find out anything interesting about coffee.<br /><br />So you build a foreboding looking machine out of gleaming steel, covered with wires and blinking lights. You sit your subjects down in front of the machine, connect them to its electrodes, and say as convincingly as possible that it is a lie detector and they must speak the truth. Your subjects look doubtful. Didn't they hear on TV that lie detectors don't really work? They'll stick to their vehement assertions of tolerance until you get a more impressive-looking machine, thank you.<br /><br />You get smarter. Before your experiment, you make the subjects fill in a survey, which you secretly copy while they're not looking. Then you bring them in front of the gleaming metal lie detector, and dare them to try to thwart it. Every time they give an answer different from the one on the survey, you frown and tell them that the machine has detected their fabrication. When the subject is suitably impressed, you start asking them about racism.<br /><br />The subjects start grudgingly admitting they have some racist attitudes. You have invented the Bogus Pipeline.</p>\n<p><a id=\"more\"></a></p>\n<p>The Bogus Pipeline is quite powerful. Since its invention in the 70s, <a href=\"http://www.google.ie/url?sa=t&amp;source=web&amp;ct=res&amp;cd=9&amp;url=http%3A%2F%2Fwww.psych.uiuc.edu%2F~roese%2FRoese%2520%26%2520Jamieson%2520(1993).pdf&amp;ei=fBPISY6ZM6TJjAf9nemUCw&amp;usg=AFQjCNF7yuL0qWhUx8-u89S8DeMD2S28Sg&amp;sig2=U1zt5KIW2Kuq4GqwQmmB-Q\">several different studies</a> demonstrate that its victims will give significantly less self-enhancing answers to a wide variety of questions than will subjects not connected to the machinery. In cases where facts can be checked, Pipeline subjects' answers tend to be more factually correct than normal subjects'.<br /><br />In one of the more interesting Bogus Pipeline experiments, Millham and Kellogg wanted to know how much of a person's average self-enhancement is due to self-deception biases, and how much is due to simple lying. They asked people some questions about themselves under normal and Pipeline conditions, using the Marlowe-Crowne scale. This scale really deserves a post of its own, but the short version is that it asks you some loaded questions, and if you take them as an opportunity to say nice things about yourself, you get marked down as a self-enhancer. There was a correlation of .68 between Marlowe-Crowne scores in normal and Pipeline conditions. If we accept that no one deliberately lies under the Pipeline, that means we now know how much self-enhancement is, on average, self-deception rather than deliberate falsehood (tendency towards deliberate falsehoods correlated .37 with Marlowe-Crowne.<sup>1</sup>)</p>\n<p>Interesting stuff. But you still don't know whether racists drink more coffee! Your Bogus Pipeline only eliminates part of the self-enhancement in your subjects' answers. If you want to solve the coffee question once and for all, you can't count on a fake mind-reading device. You need a real mind-reading device. And in the mid 90s, psychology finally developed one.<br /><br />The Bona Fide Pipeline is far less impressive-looking than the Bogus Pipeline. Though the Bogus Pipeline tries as hard as it can to scream \"mind-reading device\", the Bona Fide Pipeline has a vested interest in preventing its victims from realizing their minds are being read. It is a simple computer terminal.<br /><br />The Pipeline <a href=\"http://books.google.ie/books?id=5X_auIBx99EC&amp;pg=PA104&amp;lpg=PA104&amp;dq=bona+fide+pipeline&amp;source=bl&amp;ots=OGPW6S2ene&amp;sig=D613b8rAFNkdrBO5xy1RNNq1z3o&amp;hl=en&amp;ei=cRjISdeVO-TSjAeq46SLCw&amp;sa=X&amp;oi=book_result&amp;resnum=3&amp;ct=result#PPA106,M1\">uses a complicated process</a> to disguise itself as an ordinary study on distraction or face recognition or somesuch, but the active ingredient is this: the subjects play a game where they must hit one key (perhaps \"A\") if the screen displays a good word (for example \"wonderful\"), and a different key (perhaps \"L\") if the screen displays a bad word (for example \"ugly\").<br /><br />But before it gives you the word, it shows you a picture of a white person or a black person. Remember <a href=\"/lw/3b/never_leave_your_room/\">priming</a>? That picture of a black person is going to prime your brain's concept of \"black person\" and any concepts you associate with \"black person\". If you have racist attitudes, \"bad\" is one concept you associate with \"black person\". You're going to have a very easy time recognizing \"ugly\" as a bad word, because your \"bad\" concept is already activated. But you're going to have a harder time recognizing \"wonderful\" as a good concept, because your brain is already skewed in the opposite direction. It's not impossible, it's just going to take a few hundred more milliseconds. Each of which the Bona Fide Pipeline is recording and processing. At the end, it spits out a score telling you that you took an average of three hundred milliseconds longer to recognize good words when primed with black people's pictures than white people's pictures.<br /><br />Does this actually work? The original study (Fazio et al, 1995) tested both whites and blacks, and found the whites were more likely to be prejudiced against blacks than the blacks were, which makes sense. In the same study, a black experimenter conversed with the subjects for a while, and rated the quality of the interaction by a typically rigorous rubric. This fuzzy unscientific measure of racist behavior correlated well with the Pipeline's data for the individuals involved. A study by Jackson (1997) find that people who score high on prejudice by Pipeline measures on average give lower scores to an essay written by a student known to be black.<br /><br />The Bona Fide Pipeline has lately been superseded by its younger, sexier, Harvard-educated cousin, the IAT. More on that, the associated controversy, and the relevance to rationality tomorrow.</p>\n<p><strong>Footnotes:</strong></p>\n<p><strong>1: </strong>I doubt that deceptions can be separated cleanly into self-deception and deliberate falsehood like this. More likely there are many different shades of grey, and the Bogus Pipeline captures some but not all of them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dBPou4ihoQNY4cquv": 2, "32DdRimdM7sB5wmKu": 2, "4R8JYu4QF2FqzJxE5": 2, "Xno6pRXizN9AmFFTa": 2, "5f5c37ee1b5cdee568cfb128": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8KhThQXzsAEZ59iko", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 27, "extendedScore": null, "score": 5.1e-05, "legacy": true, "legacyId": "176", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZmQv4DFx6y4jFbhLy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-24T03:24:07.108Z", "modifiedAt": null, "url": null, "title": "On Things that are Awesome", "slug": "on-things-that-are-awesome", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:53.062Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YC3ArwKM8xhNjYqQK/on-things-that-are-awesome", "pageUrlRelative": "/posts/YC3ArwKM8xhNjYqQK/on-things-that-are-awesome", "linkUrl": "https://www.lesswrong.com/posts/YC3ArwKM8xhNjYqQK/on-things-that-are-awesome", "postedAtFormatted": "Tuesday, March 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Things%20that%20are%20Awesome&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Things%20that%20are%20Awesome%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYC3ArwKM8xhNjYqQK%2Fon-things-that-are-awesome%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Things%20that%20are%20Awesome%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYC3ArwKM8xhNjYqQK%2Fon-things-that-are-awesome", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYC3ArwKM8xhNjYqQK%2Fon-things-that-are-awesome", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1155, "htmlBody": "<p><a href=\"/lw/4d/youre_calling_who_a_cult_leader/\">This post</a>, which touched on the allowedness of admiration, started me thinking about the nature of things that are awesome.</p>\n<p>The first thing one does in such a situation is generate examples.&nbsp; And my brain, asked to enumerate things that are awesome, said:&nbsp; \"Douglas Hofstadter, E. T. Jaynes, Greg Egan...\"</p>\n<p>Upon that initial output of my brain, I had many other thoughts:</p>\n<p>(1)&nbsp; My brain was able to list <em>more than one</em> thing that is awesome.&nbsp; I am not going to dwell on this, because I think it needless to go around saying, \"Douglas Hofstadter is awesome, but E. T. Jaynes is awesome too,\" as though to deliberately moderate or subtract from the admiration of Hofstadter.&nbsp; The enjoyment of things that are awesome is an important part of life, and I don't think a healthy mind should have to hold back.&nbsp; But the <em>more</em> things you know that are awesome, the <em>more</em> there is to enjoy&mdash;this doesn't mean you should artificially inflate your estimations of awesomeness, but it does mean that if you can think of only one awesome thing, you must be missing out on a lot of life.&nbsp; And some awesome things, but not all, are compatible enough with yourself that you can draw upon the awesome&mdash;Hofstadter and Jaynes are both like this for me, but Greg Egan is not.&nbsp; So even leaving aside certain mental health risks from having only one awesome thing&mdash;it is both <em>enjoyable</em>, and <em>strengthening</em>, to know of <em>many </em>things that are awesome.</p>\n<p>(2)&nbsp; I can think of many places where I disagree with statements emitted by Douglas Hofstadter and Greg Egan, and even one or two places where I would want to pencil in a correction to Jaynes (his interpretation of quantum mechanics being the most obvious).&nbsp; In fact, when my brain says \"Greg Egan\" it is really referring to two novels, <em>Permutation City</em> and <em>Quarantine,</em> which overshadow all his other works in my book.&nbsp; And when my brain says \"Hofstadter\" it is referring to <em>G&ouml;del, Escher, Bach</em> with a small side order of some essays in <em>Metamagical Themas.</em>&nbsp; For most people their truly <em>awesome </em>work is usually only a slice of their total output, from some particular years (I find that scary as hell, by the way).<a id=\"more\"></a></p>\n<p>(3)&nbsp; Once you realize that you're only admiring someone's peak work, you also realize that the work is not the person:&nbsp; I don't actually know Hofstadter, or Greg Egan, or E. T. Jaynes.&nbsp; I have no idea what they are (were) like in their personal lives, or whether their daily deeds had any trace of the awesome that is in their books.&nbsp; If you start thinking that a <em>person</em> is supposed to be as <em>universally </em>and <em>consistently </em>awesome as their best work, so that every word from their lips is supposed to be as good as the best book they ever wrote, that's probably some kind of failure mode.&nbsp; This is not to try to moderate or diminish the awesomeness: for their best work <em>is</em> that awesome, and so there must have been a moment of their life, a time-slice out of their worldline, which was also that awesome.&nbsp; But what the symbol \"Douglas Hofstadter\" stands for, in my mind, is not all his works, or all his life.</p>\n<p>(4)&nbsp; This made me realize a strange thing:&nbsp; Whenever someone compliments \"Eliezer Yudkowsky\", they are really complimenting \"Eliezer Yudkowsky's writing\" or \"Eliezer Yudkowsky's best writing that stands out most in my mind\".&nbsp; People who met me in person were often shocked at how much my in-person impression departed from the picture they had in their minds.&nbsp; I think this mostly had to do with imagining me as being the sort of actor who would be chosen to play me in the movie version of my life&mdash;they imagined way too much dignity.&nbsp; That forms a large part of the reason why I occasionally toss in the deliberate anime reference, which does seem to have fixed the divergence a bit.&nbsp; And these days I have videos of myself online.&nbsp; But then the inside of my head is something different again.&nbsp; It's an odd thought to realize that everyone else who uses the symbol 'Eliezer Yudkowsky' uses it to refer to a quite different thing than you do.</p>\n<p>(5)&nbsp; What chiefly conveys to me the experience of the awesome is to see someone&mdash;pardon me, see someone's <em>work </em>&mdash;that is <em>way </em>above me.&nbsp; My most recent experience of the awesome was reading the third book in Jacqueline Carey's <em>Kushiel </em> series, and realizing that although I <em>want</em> to write with that kind of emotional depth, I can't, and may never be able to in this world.&nbsp; I looked back at all my own tries in (unpublished) fiction, and it paled to grey by comparison.&nbsp; It was the same way with reading Hofstadter the first time, and thinking that I could never, ever write as well as <em>G&ouml;del, Escher, Bach;</em> or reading <em>Permutation City</em>, and seeing how far above me Greg Egan was as an idea-based science fiction writer.&nbsp; And it would have been the same way with Jaynes, if <em>that</em> time I hadn't been thinking to myself, \"No, I <em>must </em>become this good.\"&nbsp; This is also something of a reply to <a href=\"/lw/4d/youre_calling_who_a_cult_leader/#35n\">Carl's comment</a> that we may feel freer to admire those who do not compete with us&mdash;for me, the experience of the awesome is most strongly created by seeing someone (or rather their work) outdoing me <em>overwhelmingly,</em> in some place where I have tried my hand.&nbsp; I don't think there's anything unhealthy about making this a basis of admiration.</p>\n<p>(6)&nbsp; My brain did not immediately enumerate all sorts of things that are too much a part of my background world to be salient:&nbsp; Science, space travel, the human brain, and the universe are all awesome.&nbsp; But the latter two are not human works, and you can't draw power from them the same way you can from a human work that is awesome and at least <em>partly </em>imitable.&nbsp; And the <a href=\"http://www.overcomingbias.com/2007/08/the-virtue-of-n.html\">virtue of narrowness</a> seems to play an important part here: an awesome thing that can be viewed in one small chunk and understood in detail will seem more awesome than something big and diffusely awesome.&nbsp; I would probably admire the space shuttle far more if I knew about it in more detail!</p>\n<p>(7)&nbsp; One of the reasons why I object to Adam Frank's attempt to salvage the concept of \"sacredness\" <em>from religion,</em> instead of reinventing it from scratch, is that e.g. being contaminated by religious experience makes you more likely to think that sacredness should only be about stars or something&mdash;those works that were once thought to be of God&mdash;whereas there is often a lot more awesomeness stored up in a human work that you know is human.&nbsp; If I want to canonize something as sacred, I'll take <em>G&ouml;del, Escher, Bach</em> over a mountain any day.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/5j/your_price_for_joining/\">Your Price for Joining</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/4d/youre_calling_who_a_cult_leader/\">You're Calling *Who* A Cult Leader?</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4cKQgA4S7xfNeeWXg": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YC3ArwKM8xhNjYqQK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 25, "extendedScore": null, "score": 4.832232931975542e-07, "legacy": true, "legacyId": "178", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cyzXoCv7nagDWCMNS", "YdcF6WbBmJhaaDqoD", "Q8evewZW5SeidLdbA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-24T10:14:33.346Z", "modifiedAt": null, "url": null, "title": "Hyakujo's Fox", "slug": "hyakujo-s-fox", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:10.185Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a5Afzce6Ny8oo9p7L/hyakujo-s-fox", "pageUrlRelative": "/posts/a5Afzce6Ny8oo9p7L/hyakujo-s-fox", "linkUrl": "https://www.lesswrong.com/posts/a5Afzce6Ny8oo9p7L/hyakujo-s-fox", "postedAtFormatted": "Tuesday, March 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hyakujo's%20Fox&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHyakujo's%20Fox%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa5Afzce6Ny8oo9p7L%2Fhyakujo-s-fox%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hyakujo's%20Fox%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa5Afzce6Ny8oo9p7L%2Fhyakujo-s-fox", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa5Afzce6Ny8oo9p7L%2Fhyakujo-s-fox", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 257, "htmlBody": "<p>From \"<a href=\"http://www.ibiblio.org/zen/gateless-gate/2.html\">Hyakujo's Fox</a>\", #2 of the 49 koans in <em><a href=\"http://www.ibiblio.org/zen/cgi-bin/koan-index.pl\">The Gateless Gate:</a></em></p>\n<blockquote>\n<p>Once when Hyakujo delivered some Zen lectures an old man attended them, unseen by the monks.  At the end of each talk when the monks left so did he.  But one day he remained after the had gone, and Hyakujo asked him: `Who are you?'</p>\n<p>The old man replied: `I am not a human being, but I was a human being when the Kashapa Buddha preached in this world.  I was a Zen master and lived on this mountain.  At that time one of my students asked me whether the enlightened man is subject to the law of causation.  I answered him: \"The enlightened man is not subject to the law of causation.\"  For this answer evidencing a clinging to absoluteness I became a fox for five hundred rebirths, and I am still a fox.  Will you save me from this condition with your Zen words and let me get out of a fox's body?  Now may I ask you: Is the enlightened man subject to the law of causation?'</p>\n<p>Hyakujo said: `The enlightened man is one with the law of causation.'</p>\n<p>At the words of Hyakujo the old man was enlightened.</p>\n</blockquote>\n<p>Mumon's poem:</p>\n<blockquote>\n<p><em>Controlled or not controlled?<br /> The same dice shows two faces.<br /> Not controlled or controlled,<br /> Both are a grievous error.</em></p>\n</blockquote>\n<p>It really makes you wonder how the hell they got <a href=\"http://www.overcomingbias.com/2008/06/thou-art-physic.html\">that far</a> while still believing that the wrong answer could turn you into a fox.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a5Afzce6Ny8oo9p7L", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 13, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "179", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-24T15:54:08.431Z", "modifiedAt": null, "url": null, "title": "Levels of Power", "slug": "levels-of-power", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:15.892Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Patrick", "createdAt": "2009-02-27T08:09:44.663Z", "isAdmin": false, "displayName": "Patrick"}, "userId": "KC7mjSorWj2XsdL3v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zqNaYn3dmhCg8wzcx/levels-of-power", "pageUrlRelative": "/posts/zqNaYn3dmhCg8wzcx/levels-of-power", "linkUrl": "https://www.lesswrong.com/posts/zqNaYn3dmhCg8wzcx/levels-of-power", "postedAtFormatted": "Tuesday, March 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Levels%20of%20Power&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALevels%20of%20Power%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzqNaYn3dmhCg8wzcx%2Flevels-of-power%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Levels%20of%20Power%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzqNaYn3dmhCg8wzcx%2Flevels-of-power", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzqNaYn3dmhCg8wzcx%2Flevels-of-power", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 940, "htmlBody": "<p><strong>Intended for Levels 0-1.9 Related to: <a href=\"/lw/4o/playing_video_games_in_shuffle_mode/\">Playing Video Games In Shuffle Mode <br /></a></strong></p>\n<p>Taking the advice of talisman, I thought it would be useful to compile a list of levels of general rationalist skill. I think these levels loosely correllate to how effective one is as a rationalist, but they are not the same thing, a level 2 might still compartmentalize. This list is more a specification of the difficulty of material that a person will be able to follow, as well as providing a list of <a href=\"http://www.overcomingbias.com/2008/09/level-above.html\">levels above mine</a>, that I can aspire to. Of course, skill is more of a continuum than a discrete set, I've leveled up once before, but I don't remember any single moment in which this occured, just like I don't remember any single moment where I suddenly matured.</p>\n<p>The first level, level 0, is the rationality skill of an average 20 year old with internet access, which is the skill of the vast majority of people in the world, if not higher. They've probably forgotten what math they knew beyond a little algebra and arithmetic,&nbsp; and haven't gotten in to the habit of checking facts. These are the kind of people who think Spock when you mention logic. This level of skill is something any rationalist has to go through, so the majority of people who arrive here without coming from OB will probably fall in to this category. With any luck, these people might discover debate forums, and seeing someone shred an argument to pieces introduces them to the idea of a logical fallacy, and begins their transition in to level 1.</p>\n<div id=\"magicdomid2046\">\n<p>The transition from level 0 to level 1 is fairly painless. With a good reading list, it should probably take about three months. Level 1 is the stage where people start self-identifying as rationalists. The usual transition to this stage comes from thinking about rationality as rhetoric, many rationalists become rationalists after a long time spent arguing with creationists and other crackpots, and slowly developing a list of silly arguments and misconcpetions and why they're so silly, until they've got a big enough list that it becomes a matter of turning on the \"bullshit detector\". After a bit of practice doing this, people become more willing to think hard about their beliefs after their arguments are torn to shreds in the same way that they tore other people's arguments down.</p>\n</div>\n<div id=\"magicdomid2053\">\n<p>Knowing (to the core of one's being) the fundamentals of logic: that a good argument should go from shared assumptions to a conclusion with clear and explicit reasoning every step of the way - marks a level 1 or higher. People at level 1 also generally know about the scientific method and the scientific ideas that crackpots talk about, some standard fallacies and cognitive biases, and understand the law of truly large numbers: that with a big enough sample space, all sorts of weird coincidences can happen. It's much easier to apply the techniques of rationality to propositions than it is to empirical expectations, which is why most books on the subject cover those, and why you should try to translate the latter in to the former when possible.&nbsp; Learning how to be rational about empirical expectations is the driving force behind transitioning to level 2.</p>\n</div>\n<p>The transition from level 1 to 2 is a rarer and more lengthly process. Level 2 is also much more specialized. Whereas level 1 consists mainly of reasoning about propositions, level 2 involves higher levels of abstraction i.e. thinking about the <em>rules</em> that are required to reason about propositions in a particular domain. To do this without committing serious mistakes requires a great deal of care and rigor, as well as knowledge of the relevant sciences and philosophical principles. When you realize that all those papers on cognitive biases and common fallacies also apply to you, you become immediately suspicious of anything that isn't absolutely explicit and precise. People at level 2 are also much more likely to admit when they don't know something, because the pattern of defining and using a precise and explicit model is nigh impossible when you don't know what you're talking about. Hence formalization is a very important technique at this level, which requires that people at level 2 know advanced math.</p>\n<p>Becoming a level 2 isn't easy, it requires learning an advanced model of how to think about problems in a particular domain that may clash with your naive intuitions, being able to trust the math, and more importantly <em>do</em> the math is an essential skill, and one that is difficult to master. Programming and teaching are good practice techniques at this level, because they both require being explicit about your unconscious reasoning. The process of using a formal model to predict and explain things tends to give people at level 2 much better intuitions about problems in their domain of knowledge, as well as a sense of aesthetics about abstracted models. This sense of aesthetics is probably very important in helping a person trying to reach level 3 and come up with their own.</p>\n<p>Level 3 is the level where you are able to produce <a href=\"/lw/4y/on_things_that_are_awesome/\">awesome</a> where you not only have an inutitive understanding of the mathematical models in your field, you also created them. At level 3 you don't have a guiding textbook to help you, you are the one that writes them. Very, very few people reach this level, and those who do are heralded as geniuses, such as Newton, Darwin, Godel, Russel or Einstein. I don't know how to become a level 3, I know Eliezer has had some experience trying, but these are the people who change the world.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zqNaYn3dmhCg8wzcx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -9, "extendedScore": null, "score": -1.2e-05, "legacy": true, "legacyId": "180", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mY5SaNnugfEcj6957", "YC3ArwKM8xhNjYqQK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-24T17:08:52.494Z", "modifiedAt": null, "url": null, "title": "Terrorism is not about Terror", "slug": "terrorism-is-not-about-terror", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:07.220Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aNzLGn6s62uRZvAp2/terrorism-is-not-about-terror", "pageUrlRelative": "/posts/aNzLGn6s62uRZvAp2/terrorism-is-not-about-terror", "linkUrl": "https://www.lesswrong.com/posts/aNzLGn6s62uRZvAp2/terrorism-is-not-about-terror", "postedAtFormatted": "Tuesday, March 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Terrorism%20is%20not%20about%20Terror&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATerrorism%20is%20not%20about%20Terror%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaNzLGn6s62uRZvAp2%2Fterrorism-is-not-about-terror%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Terrorism%20is%20not%20about%20Terror%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaNzLGn6s62uRZvAp2%2Fterrorism-is-not-about-terror", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaNzLGn6s62uRZvAp2%2Fterrorism-is-not-about-terror", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<blockquote>Statistical analysis of terrorist groups' longevity, aims, methods and successes reveal that groups are self-contradictory and self-sabotaging, generally ineffective; common stereotypes like terrorists being poor or ultra-skilled are false. Superficially appealing counter-examples are discussed and rejected. Data on motivations and the dissolution of terrorist groups are brought into play and the surprising conclusion reached: terrorism is a form of socialization or status-seeking.<br /></blockquote>\n<p style=\"padding-left: 30px;\">&nbsp;<a href=\"http://www.gwern.net/Terrorism%20is%20not%20about%20Terror\">http://www.gwern.net/Terrorism%20is%20not%20about%20Terror</a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xXX3n22DQZuKqXEdT": 1, "gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aNzLGn6s62uRZvAp2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": 41, "extendedScore": null, "score": 8.4e-05, "legacy": true, "legacyId": "181", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-25T00:11:25.076Z", "modifiedAt": null, "url": null, "title": "The Implicit Association Test", "slug": "the-implicit-association-test", "viewCount": null, "lastCommentedAt": "2017-06-17T04:35:36.062Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iYJo382hY28K7eCrP/the-implicit-association-test", "pageUrlRelative": "/posts/iYJo382hY28K7eCrP/the-implicit-association-test", "linkUrl": "https://www.lesswrong.com/posts/iYJo382hY28K7eCrP/the-implicit-association-test", "postedAtFormatted": "Wednesday, March 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Implicit%20Association%20Test&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Implicit%20Association%20Test%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYJo382hY28K7eCrP%2Fthe-implicit-association-test%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Implicit%20Association%20Test%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYJo382hY28K7eCrP%2Fthe-implicit-association-test", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYJo382hY28K7eCrP%2Fthe-implicit-association-test", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1973, "htmlBody": "<p><strong>Continuation of: </strong><a href=\"/lw/4w/bogus_pipeline_bona_fide_pipeline/\">Bogus Pipeline, Bona Fide Pipeline</a><br /><strong>Related to:</strong> <a href=\"http://www.google.ie/url?sa=t&amp;source=web&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F2008%2F02%2Fthingspace-clus.html&amp;ei=hHbJSe3JA4uqjAeXw6DOAw&amp;usg=AFQjCNHpraaqPV8hyy-K8BBjgimcNeN_3Q&amp;sig2=__1i2PwhvZdI97Q_Ez_uFA\">The Cluster Structure of Thingspace</a></p>\n<p>If you've never taken the <strong><a href=\"https://implicit.harvard.edu/implicit/demo/\">Implicit Association Test</a></strong> before, try it now.<br /><br />Any will do. The one on race is the \"classic\", but the one on gender and careers is a bit easier to watch \"in action\", since the effect is so clear.<br /><br />The overwhelming feeling I get when taking an Implicit Association Test is that of feeling my cognitive algorithms at work. All this time talking about thingspace and bias and categorization, and all of a sudden I have this feeling to attach the words to...<br /><br />...which could be completely self-delusional. What is the evidence? Does the Implicit Association Test work?<br /><br />Let the defense speak first<sup>1</sup>. The Implicit Association Test correctly picks up control associations. An IAT about attitudes towards insects and flowers found generally positive attitudes to the flowers and generally negative attitudes to the insects (p = .001), just as anyone with their head screwed on properly would expect. People's self-reports were also positively correlated with their IAT results (ie, someone who reported loving flowers and hating insects more than average also had a stronger than average IAT) although these correlations did not meet the 95% significance criterion. The study was repeated with a different subject (musical instruments vs. weapons) and similar results were obtained.<br /><br />In the next study, the experimenters recruited Japanese-Americans and Korean-Americans. Japan has been threatening, invading, or oppressing&nbsp; Korea for large chunks of the past five hundred years, and there's no love lost between the two countries. This time, the Japanese-Americans were able to quickly match Japanese names to \"good\" stimuli and Korean names to \"bad\" stimuli, but took much longer to perform the opposite matching. The Korean-Americans had precisely the opposite problem, p &lt; .0001.&nbsp; People's self-reports were also positively correlated with their IAT results (ie, a Korean who expressed especially negative feelings towards the Japanese on average also had a stronger than average IAT result) to a significant level.<a id=\"more\"></a><br /><br />There's been some evidence that the IAT is pretty robust. Most trivial matters like position of items don't much much of a difference. People who were asked to convincingly fake an IAT effect couldn't do it. If the same person takes the test twice, there's a correlation ofabout .6 between the&nbsp; two attempts<sup>2</sup>. There's a correlation of .55 between the Bona Fide Pipeline and the IAT (the IAT wins all competitions between the two; it produces twice as big an effect size). There's about a .24 correlation between explicit attitude and IAT score, which is significant at the 90% but not the 95% level; removing certain tests where people seem especially likely to lie on their explicit attitude takes it up to 95. When the two conflict, the IAT occasionally wins. In one study, subjects were asked to evaluate male and female applicants for a job. Their observed bias against women correlated more strongly with their scores on a gender bias IAT than with their own self-report (in other experiments in the same study, explicit self-report was a better predictor. The experimenters concluded both methods were valuable in different areas)<br /><br />Now comes the prosecution. A common critique of the test is that the same individual often gets two completely different scores taking the same test twice. As far as re-test reliability goes, .6 correlation is pretty good from a theoretical point of view, but more than enough to be frequently embarrassing. It must be admitted: this test, while giving consistent results for populations, is of less use for individuals wondering how much bias they personally have.</p>\n<p>Carl Shulman would be heartbroken if I didn't mention Philip Tetlock, so here goes. This is from <a href=\"http://faculty.washington.edu/agg/IATmaterials/PDFs/AT.psychinquiry.2004.pdf\">Would Jesse Jackson Fail the Implicit Association Test?</a>, by Tetlock and Arkes (2004):</p>\n<blockquote>\n<p>Measures of implicit prejudice are based on associations between race-related stimuli and valenced words. Reaction time (RT) data have been characterized as showing implicit prejudice when White names or faces are associated with positive concepts and African-American names or faces with negative concepts, compared to the reverse pairings. We offer three objections to the inferential leap from the comparative RT of different associations to the attribution of implicit prejudice: (a) The data may reflect shared cultural stereotypes rather than personal animus, (b) the affective negativity attributed to participants may be due to cognitions and emotions that are not necessarily prejudiced, and (c) the patterns of judgment deemed to be indicative of prejudice pass tests deemed to be diagnostic of rational behavior.</p>\n</blockquote>\n<p>In other words, there are a bunch of legitimate reasons people might get negative IAT scores. Any connection whatsoever between black people and negative affect will do. It could be the connection that black people generally have low status in our society. It could be that a person knows of all the prejudices against black people without believing them. It could be that a person has perfectly rational negative feelings about black people because of their higher poverty rate, higher crime rate, and so on. Or it could be somethng as simple as that, for whites, black people are the out-group.<br /><br />...this actually isn't much of a prosecution at all. I consider myself a moderate believer in the IAT, and I think it all sounds pretty reasonable.<br /><br />What most IAT detractors I've read want to make exquisitely clear is that you can't hand someone an IAT, find an anti-black bias, and say \"Aha! He's a racist! Shame on him!\"<sup>3</sup><br /><br />I think this is pretty obvious<sup>4</sup>. You can hold beliefs on more than one level. A person may believe there is <a href=\"http://www.google.ie/url?sa=t&amp;source=web&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F2007%2F07%2Fbelief-in-belie.html&amp;ei=PXPJSbSqB4OsjAfBk5nNAw&amp;usg=AFQjCNHg410FWMFqi7nAG2KMv60T-v2Utw&amp;sig2=R_RdXo97FAI-0rupS5CqlQ\">a dragon in his garage</a>, yet not expect an experiment to detect it. A skeptic may disbelieve in ghosts, <a href=\"/lw/1l/the_mystery_of_the_haunted_rationalist/\">but be afraid of haunted houses</a>. A stroke victim <a href=\"/lw/20/the_apologist_and_the_revolutionary/\">may deny an arm is hers while admitting it is attached to her body</a>. And it's supposed to be news that you can give black people some sort of vague negative connotation on a nonconscious level without being Ku Klux Klan material?<br /><br />There is a certain segment of society which interprets the sun rising in the morning as evidence of racism. It is not surprising that this segment of society also interprets the IAT as evidence for racism. I myself think racism is a bad word. Not in the way \"shit\" is a bad word, but <a href=\"http://www.overcomingbias.com/2008/02/sneak-connotati.html\">in the way \"wiggin\" is a bad word</a>. It <a href=\"http://www.overcomingbias.com/2008/03/wrong-words.html\">divides experience in a perverse way</a>, drawing a boundary such that Adolf Hitler ends up in the same category as the guy who feels a pang of guilty fear late at night when he sees a big muscular black guy walking towards him<sup>5</sup>. Taboo the word \"racism\", \"prejudice\", and any other anti-applause-light<sup>6</sup>, and a lot of the IAT debate loses its meaning.<br /><br />Which is good, because I think the IAT is about <strong>much</strong> more than who is or isn't racist. The IAT is a tool for measuring distances in thingspace.<br /><br />Thingspace, remember, <a href=\"http://www.google.ie/url?sa=t&amp;source=web&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F2008%2F02%2Fthingspace-clus.html&amp;ei=9XPJScnoIMeZjAe-jNHNAw&amp;usg=AFQjCNHpraaqPV8hyy-K8BBjgimcNeN_3Q&amp;sig2=vo2zWuYjHPmYPU-trxbyGg\">is the sort of space in which we draw categories</a><sup>7</sup>. \"Chair\" is a useful category because it describes a cluster of things that are close together in concept-space in a certain way: stools, rocking chairs, office chairs, desk chairs, et cetera. \"Furniture\" is another useful word because it describes another cluster, one that includes the chair cluster and other concepts nearby. Quok, where a \"quok\" is defined as either a chair or Vladimir Lenin, is a useless category, because Lenin isn't anywhere near all the other members. <br /><br />Speaking of communists, remember back when East and West Germany got reunited? And remember a little further back, when North and South Vietnam got reunited too? Those reunifications, no matter how you feel about them politically, were natural links between culturally and historically similar regions. But imagine trying to unite East Germany with South Vietnam, and West Germany with North Vietnam. The resulting countries would be ungovernable and collapse in a matter of weeks.<br /><br />If you associate white people with good things, and black people with bad things, then forming the categories \"white and good\" and \"black and bad\" is like reuniting East and West Germany. You're drawing a natural border around a compact area of the map. But being forced into the categories \"white and bad\" and \"black and good\" is about as natural as trying to merge East Germany and South Vietnam into the new country \"Southeast Vietnermany\". You're drawing an arbitrary boundary around two completely unrelated parts of the map and then begging in vain for the disgruntled inhabitants to cooperate with each other.<br /><br />If you provoke a war between the reunified Germany and Southeast Vietnermany, and watch which side coordinates its forces better, you get the Implicit Association Test.<br /><br />Why would we want to measure distance in thingspace? Loads of reasons. Take a set of pictures of famous cult leaders, mix them with a set of pictures of famous scientists, and test Less Wrong readers' reaction times associating a picture of Eliezer Yudkowksy's face with either set<sup>8</sup>. If it's easier to place him with the scientists, or there's no difference, that's some evidence <a href=\"/lw/4d/youre_calling_who_a_cult_leader/\">we haven't become a cult</a> yet. If it's easier to place him with the cult leaders, we should start worrying.<br /><br />Tomorrow: some more serious applications to rationality.</p>\n<p>&nbsp;</p>\n<p><strong>Footnotes:</strong></p>\n<p><strong>1: </strong>Most of these results taken from <a href=\"http://www.alice.id.tue.nl/references/greenwald-et-al-1998.pdf\">this</a>, <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.7222&amp;rep=rep1&amp;type=pdf\">this</a>, and <a href=\"http://psp.sagepub.com/cgi/content/abstract/31/10/1369\">this</a> study.</p>\n<p><strong>2: </strong>There's some evidence that priming can change your IAT score. For example, subjects shown a picture of a happy black family enjoying a picnic just before an IAT got lower bias scores than a control group who didn't see the picture. And before condemning the test too much for its tendency to give different scores on different occasions, remember back to your school days when you'd have to take endless quizzes on the same subject. Occasionally just by chance you'd get a spread of ten point or so, and if you were on the borderline between passing and failing, you might very well pass one test and fail another test on the exact same material. This doesn't mean grade school tests don't really measure your knowledge, just that there's always a bit of noise. The IAT noise is greater, but not overwhelmingly so.</p>\n<p><strong>3: </strong>There's also a fear someone might use it for, say, evaluating applicants for a job. Due to its weakness as an individual measurement and the uncertainty about how well it predicts behavior, this would be a terrible idea.</p>\n<p><strong>4:</strong> Full disclosure: Despite strongly opposing prejudice on a conscious level and generally getting along well with minorities in my personal life, I get assessed as moderately biased on the racism IAT. I had some memorable bad experiences with certain black people in my formative years, so this doesn't much surprise me.</p>\n<p><strong>5: </strong>In fact, Jesse Jackson (note for non-Americans: a well-known black minister and politician who speaks out against racism) himself admits to occasionally having these pangs of guilty fear - hence the name of Tetlock's article.</p>\n<p><strong>6: </strong>I think Eliezer once coined a term for the opposite of \"applause light\", for things like \"racism\" and \"scientism\" invoked only so people can feel good about hating them, but I can't seem to find it. Can someone refresh my memory?</p>\n<p><strong>7: </strong>I was split on whether to use the term thing-space or concept-space here. Eliezer uses concept-space in a very particular way, but \"good\" and \"black\" seem much more concepts than things. I eventually went with thing-space, but I'm not happy about it.</p>\n<p><strong>8: </strong>This is a facetious example. It's possible in theory, but there would be so much to control for that any result would be practically meaningless.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 2, "dRRwDp9KRtkyd7ywZ": 2, "P3Wd3f2cWqqvQxDQS": 2, "Xno6pRXizN9AmFFTa": 2, "5f5c37ee1b5cdee568cfb128": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iYJo382hY28K7eCrP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 28, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "183", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["8KhThQXzsAEZ59iko", "mja6jZ6k9gAwki9Nu", "ZiQqsgGX6a42Sfpii", "cyzXoCv7nagDWCMNS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-25T01:29:02.264Z", "modifiedAt": null, "url": null, "title": "Contests vs. Real World Problems", "slug": "contests-vs-real-world-problems", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:06.163Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QwjGKQ4uhGTC5gAnp/contests-vs-real-world-problems", "pageUrlRelative": "/posts/QwjGKQ4uhGTC5gAnp/contests-vs-real-world-problems", "linkUrl": "https://www.lesswrong.com/posts/QwjGKQ4uhGTC5gAnp/contests-vs-real-world-problems", "postedAtFormatted": "Wednesday, March 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Contests%20vs.%20Real%20World%20Problems&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AContests%20vs.%20Real%20World%20Problems%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQwjGKQ4uhGTC5gAnp%2Fcontests-vs-real-world-problems%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Contests%20vs.%20Real%20World%20Problems%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQwjGKQ4uhGTC5gAnp%2Fcontests-vs-real-world-problems", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQwjGKQ4uhGTC5gAnp%2Fcontests-vs-real-world-problems", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 140, "htmlBody": "<p>John Cook draws on the movie <a href=\"http://www.imdb.com/title/tt1012804/\">Redbelt</a> to highlight the difference between <a href=\"http://www.johndcook.com/blog/2009/03/24/redbelt-problem-solving/\">staged contests and real-world fights</a>. The main character of the movie is a Jiu Jitsu instructor who is willing to fight if necessary, but will not compete under arbitrary rules. Cook analogies this to the distinction between academic and real-world problem solving. Academics and students are often bound by restrictions that are useful in their own contexts, but are detrimental to someone who is more concerned with having a solution than where the solution came from.</p>\n<p>Robin pointed <a href=\"http://www.overcomingbias.com/2008/10/academics-in-cl.html\">arbitrary restrictions in academia</a> out to us before, but his question then was regarding topics neglected for being silly. Following Cook's line of reasoning, are there any arbitrary restrictions we have picked up in school or other contexts that are holding us back? Are there rationalist \"cheats\" that are being underused?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QwjGKQ4uhGTC5gAnp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 17, "extendedScore": null, "score": 4.834155732875975e-07, "legacy": true, "legacyId": "184", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-25T09:53:33.583Z", "modifiedAt": null, "url": null, "title": "The Sacred Mundane", "slug": "the-sacred-mundane", "viewCount": null, "lastCommentedAt": "2022-05-26T14:57:31.184Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Fwt4sDDacko8Sh5iR/the-sacred-mundane", "pageUrlRelative": "/posts/Fwt4sDDacko8Sh5iR/the-sacred-mundane", "linkUrl": "https://www.lesswrong.com/posts/Fwt4sDDacko8Sh5iR/the-sacred-mundane", "postedAtFormatted": "Wednesday, March 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Sacred%20Mundane&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Sacred%20Mundane%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwt4sDDacko8Sh5iR%2Fthe-sacred-mundane%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Sacred%20Mundane%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwt4sDDacko8Sh5iR%2Fthe-sacred-mundane", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwt4sDDacko8Sh5iR%2Fthe-sacred-mundane", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1204, "htmlBody": "<p>So I was reading (around the first half of) Adam Frank's <em>The Constant Fire,</em> in preparation for my <a href=\"/lw/4i/bhtv_yudkowsky_adam_frank_on_religious_experience/\">Bloggingheads dialogue</a> with him.&nbsp; Adam Frank's book is about the experience of the sacred.&nbsp; I might not usually call it that, but of course I know the experience Frank is talking about.&nbsp; It's what I feel when I watch a video of a space shuttle launch; or what I feel&mdash;to a lesser extent, because in this world it is too <a href=\"http://www.overcomingbias.com/2008/03/scarcity.html\">common</a>&mdash;when I look up at the stars at night, and think about what they mean.&nbsp; Or the birth of a child, say.&nbsp; That which is significant in the Unfolding Story.</p>\n<p>Adam Frank holds that this experience is something that science holds deeply in common with religion.&nbsp; As opposed to e.g. being a basic human quality which religion corrupts.</p>\n<p><em>The Constant Fire</em> quotes William James's <em>The Varieties of Religious Experience</em> as saying:</p>\n<blockquote>\n<p>Religion... shall mean for us the feelings, acts, and experiences of individual men in their solitude; so far as they apprehend themselves to stand in relation to whatever they may consider the divine.</p>\n</blockquote>\n<p>And this theme is developed further:&nbsp; Sacredness is something intensely <em>private</em> and <em>individual.</em></p>\n<p>Which completely nonplussed me.&nbsp; Am I supposed to not have any feeling of sacredness if I'm one of <em>many </em>people watching the video of <em>SpaceShipOne</em> winning the X-Prize?&nbsp; Why not?&nbsp; Am I supposed to think that my experience of sacredness has to be somehow <em>different </em>from that of all the <em>other </em>people watching?&nbsp; Why, when we all have the <a href=\"http://www.overcomingbias.com/2008/06/psychological-u.html\">same brain design</a>?&nbsp; Indeed, why would I <em>need</em> to believe I was unique?&nbsp; (But \"unique\" <em>is </em>another word Adam Frank uses; so-and-so's \"unique experience of the sacred\".)&nbsp; Is the feeling private in the same sense that we have difficulty communicating <em>any</em> experience?&nbsp; Then why emphasize this of sacredness, rather than sneezing?</p>\n<p>The light came on when I realized that I was looking at a trick of <a href=\"http://www.overcomingbias.com/2008/10/the-dark-side.html\">Dark Side Epistemology</a>&mdash;if you make something <em>private,</em> that shields it from criticism.&nbsp; You can say, \"You can't criticize me, because this is my private, inner experience that you can never access to question it.\"</p>\n<p>But the price of shielding yourself from criticism is that you are cast into solitude&mdash;the solitude that William James admired as the core of religious experience, as if loneliness were a <em>good </em>thing.</p>\n<p>Such relics of Dark Side Epistemology are key to understanding the many ways that religion twists the experience of sacredness:<a id=\"more\"></a></p>\n<p><strong>Mysteriousness</strong>&mdash;why should the sacred have to be mysterious?&nbsp; A space shuttle launch gets by just fine without being mysterious.&nbsp; How much <em>less</em> would I appreciate the stars if I did <em>not</em> know what they were, if they were just little points in the night sky?&nbsp; But if your religious beliefs are questioned&mdash;if someone asks, \"Why doesn't God heal amputees?\"&mdash;then you take refuge and say, in a tone of deep profundity, \"It is a sacred mystery!\"&nbsp; There are questions that must not be asked, and answers that must not be acknowledged, to defend the lie.&nbsp; Thus unanswerability comes to be associated with sacredness.&nbsp; And the price of shielding yourself from criticism is giving up the <a href=\"http://www.overcomingbias.com/2007/10/curiosity.html\">true curiosity</a> that truly wishes to find answers.&nbsp; You will worship your own ignorance of the temporarily unanswered questions of your own generation&mdash;<a href=\"http://www.overcomingbias.com/2007/10/no-one-knows-wh.html\">probably including</a> ones that are <a href=\"http://www.overcomingbias.com/2008/06/the-quantum-phy.html\">already answered</a>.</p>\n<p><strong>Faith</strong>&mdash;in the early days of religion, when people were more naive, when even intelligent folk actually believed that stuff, religions staked their reputation upon the testimony of miracles in their scriptures.&nbsp; And Christian archaeologists set forth truly expecting to find the ruins of Noah's Ark.&nbsp; But when no such evidence was forthcoming, <em>then</em> religion executed what William Bartley called <em>the retreat to commitment,</em> \"I believe because I believe!\"&nbsp; Thus <em>belief without good evidence</em> came to be associated with the experience of the sacred.&nbsp; And the price of shielding yourself from criticism is that you sacrifice your ability to think clearly about that which is sacred, and to progress in your understanding of the sacred, and relinquish mistakes.</p>\n<p><strong>Experientialism</strong>&mdash;if before you thought that the rainbow was a sacred contract of God with humanity, and then you begin to realize that God doesn't exist, then you may execute a <em>retreat to pure experience</em>&mdash;to praise yourself just for <em>feeling</em> such wonderful sensations when you think about God, whether or not God actually <em>exists</em>.&nbsp; And the price of shielding yourself from criticism is solipsism: your experience is stripped of its <em>referents.</em>&nbsp; What a terrible hollow feeling it would be to watch a space shuttle rising on a pillar of flame, and say to yourself, \"But it doesn't really matter whether the space shuttle actually exists, so long as I feel.\"</p>\n<p><strong>Separation</strong>&mdash;if the sacred realm is not subject to ordinary rules of evidence or investigable by ordinary means, then it must be different in kind from the world of mundane matter: and so we are less likely to think of a space shuttle as a candidate for sacredness, because it is a work of merely <em>human</em> hands.&nbsp; <a href=\"http://www.overcomingbias.com/2008/03/joy-in-the-real.html\">Keats lost his admiration of the rainbow</a> and demoted it to the \"dull catalogue of mundane things\" for the crime of its woof and texture being known.&nbsp; And the price of shielding yourself from all ordinary criticism is that you lose the sacredness of all <a href=\"http://www.overcomingbias.com/2008/03/joy-in-the-real.html\">merely real</a> things.</p>\n<p><strong>Privacy</strong>&mdash;of this I have already spoken.</p>\n<p>Such distortions are why we had best <em>not</em> to try to salvage religion.&nbsp; No, not even in the form of \"spirituality\".&nbsp; Take away the institutions and the factual mistakes, subtract the churches and the scriptures, and you're left with... all this nonsense about mysteriousness, faith, solipsistic experience, private solitude, and discontinuity.</p>\n<p>The original lie is only the beginning of the problem.&nbsp; Then you have all the ill habits of thought that have evolved to defend it.&nbsp; Religion is a poisoned chalice, from which we had best not even sip.&nbsp; Spirituality is the same cup after the original pellet of poison has been taken out, and only the dissolved portion remains&mdash;a little less directly lethal, but still not good for you.</p>\n<p>When a lie has been defended for ages upon ages, the true origin of the inherited habits lost in the mists, with layer after layer of undocumented sickness; then the wise, I think, will start over from scratch, rather than trying to selectively discard the original lie while keeping the habits of thought that protected it.&nbsp; <em>Just admit you were wrong,</em> give up <em>entirely</em> on the mistake, stop defending it <em>at all</em>, stop trying to say you were even a little right, stop trying to save face, just say \"<a href=\"http://www.overcomingbias.com/2007/08/the-importance-.html\">Oops!</a>\" and throw out the <em>whole </em>thing and begin again.</p>\n<p>That capacity&mdash;to really, <em>really,</em> without defense, admit you were <em>entirely</em> wrong&mdash;is why religious experience will never be like scientific experience.&nbsp; No religion can absorb <em>that </em>capacity without losing itself <em>entirely </em>and becoming simple humanity...</p>\n<p>...to just look up at the distant stars.&nbsp; Believable without strain, without a constant distracting struggle to fend off your awareness of the counterevidence.&nbsp; Truly there <em>in the world,</em> the experience united with the referent, a solid part of that unfolding story.&nbsp; Knowable without threat, offering true meat for curiosity.&nbsp; Shared in togetherness with the many other onlookers, no need to retreat to privacy.&nbsp; Made of the same fabric as yourself and all other things.&nbsp; Most holy and beautiful, the sacred mundane.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Fwt4sDDacko8Sh5iR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 72, "baseScore": 56, "extendedScore": null, "score": 8.4e-05, "legacy": true, "legacyId": "187", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "6BFkmEgre7uwhDxDR", "canonicalCollectionSlug": "rationality", "canonicalBookId": "ah2GqzZSeBpW9QHgb", "canonicalNextPostSlug": "to-spread-science-keep-it-secret", "canonicalPrevPostSlug": "scarcity", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 56, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 117, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xDroHJ3AzWwJ45ufJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-25T17:55:15.999Z", "modifiedAt": null, "url": null, "title": "Extreme updating: The devil is in the missing details", "slug": "extreme-updating-the-devil-is-in-the-missing-details", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:20.274Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bCxGjo5PqZt2gXdMQ/extreme-updating-the-devil-is-in-the-missing-details", "pageUrlRelative": "/posts/bCxGjo5PqZt2gXdMQ/extreme-updating-the-devil-is-in-the-missing-details", "linkUrl": "https://www.lesswrong.com/posts/bCxGjo5PqZt2gXdMQ/extreme-updating-the-devil-is-in-the-missing-details", "postedAtFormatted": "Wednesday, March 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Extreme%20updating%3A%20The%20devil%20is%20in%20the%20missing%20details&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExtreme%20updating%3A%20The%20devil%20is%20in%20the%20missing%20details%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbCxGjo5PqZt2gXdMQ%2Fextreme-updating-the-devil-is-in-the-missing-details%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Extreme%20updating%3A%20The%20devil%20is%20in%20the%20missing%20details%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbCxGjo5PqZt2gXdMQ%2Fextreme-updating-the-devil-is-in-the-missing-details", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbCxGjo5PqZt2gXdMQ%2Fextreme-updating-the-devil-is-in-the-missing-details", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 661, "htmlBody": "<p>Today Ed Yong has a <a href=\"http://scienceblogs.com/notrocketscience/2009/03/to_predict_what_will_make_you_happy_ask_a_stranger_rather_th.php\">post</a> on <a href=\"http://scienceblogs.com/notrocketscience/\">Not Exactly Rocket Science</a> that is about updating - actually, the most extreme case in updating, where a person gets to choose between relying completely on their own judgement, or completely on the judgement of others.&nbsp; He describes 2 experiments by <a href=\"http://www.wjh.harvard.edu/%7Edtg/gilbert.htm\">Daniel Gilbert</a> of Harvard in which subjects are given information about experience X, and asked to predict how they would feel (on a linear scale) on experiencing X; they then experience X and rate what they felt on that linear scale.</p>\n<p>In both cases, the correlation between post-experience judgements of different subjects is much higher than the correlation between the prediction and the post-experience judgement of each subject.&nbsp; This isn't surprising - the experiments are designed so that the experience provides much more information than the given pre-experience information does.</p>\n<p>What might be surprising is that the subjects believe the opposite: that they can predict their response from information better than from the responses of others.</p>\n<p>Whether these experiments are interesting depends on how the subjects were asked the question.&nbsp; If they were asked, before being given information or being told what that information would be, whether they could predict their response to an experience better by making their own judgement based on information, or from the responses of others, then the result is not interesting.&nbsp; The subjects in that case did not know that they would be given only a trivial amount of information relative to those who had the experience.</p>\n<p>The result is only interesting if the subjects were given the information first, and <em>then</em> asked whether they could predict their response better from that information than from someone else's experience.&nbsp; Yong's post doesn't say which of these things happened, and doesn't cite the original article, so I can't look it up.&nbsp; Does anyone know?</p>\n<p>I've heard studies like this cited as strong evidence that we should update more; but never heard that critical detail given for any such studies.&nbsp; Are there <em>any</em> studies which actually show what this study purports to show?</p>\n<p>EDIT: Robin posted the citation.&nbsp; The original paper does not contain the crucial information.&nbsp; Details in my response to Robin.</p>\n<p>EDIT:&nbsp; The original paper DOES contain the crucial info for the first experiment.&nbsp; I missed it the first time.&nbsp; It says:</p>\n<blockquote>\n<p>.. a woman was escorted to the speed-dating room and left to have a 5-min private conversation with the man. Next, the experimenter escorted the woman to another room where she reported how much she had enjoyed the speed date by marking a 100-mm continuous &ldquo;enjoyment scale&rdquo; whose end points were marked not at all and very much. This report is hereinafter referred to as her affective report.</p>\n<p>Next, a second woman was given one of two kinds of information: simulation information (which consisted of the man&rsquo;s personal profile and photograph) or surrogation information (which consisted of the affective report provided by the first woman). The second woman was then asked to predict (on the enjoyment scale) how much she would enjoy her speed date with the man. This prediction is hereinafter referred to as her affective forecast.</p>\n<p>After making her prediction, the second woman was shown the kind of information (simulation or surrogation) that she had not already received. We did this to ensure that each woman had the same information about theman before the actual speed date. The only difference between the two conditions, then, was whether the second woman had surrogation information or simulation information when she made her forecast.</p>\n<p>Next, the second woman was escorted to the dating room, had a speed date, and then reported how much she enjoyed it (on the enjoyment scale). This report is hereinafter referred to as her affective report. The second woman also reported whether she believed that simulation information or surrogation information would have allowed her to make the more accurate prediction about the speed date she had and about a speed date that she might have in the future.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3RnEKrsNgNEDxuNnw": 1, "YPZCAs9Axp9PtrF22": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bCxGjo5PqZt2gXdMQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 7, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "188", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-25T19:07:21.908Z", "modifiedAt": null, "url": null, "title": "Spock's Dirty Little Secret", "slug": "spock-s-dirty-little-secret", "viewCount": null, "lastCommentedAt": "2021-05-19T19:55:17.268Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pjeby", "createdAt": "2009-02-27T23:51:22.854Z", "isAdmin": false, "displayName": "pjeby"}, "userId": "Zzxr5JZpkitaNxL4Q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ru536oPGPJsEkA3Ee/spock-s-dirty-little-secret", "pageUrlRelative": "/posts/ru536oPGPJsEkA3Ee/spock-s-dirty-little-secret", "linkUrl": "https://www.lesswrong.com/posts/ru536oPGPJsEkA3Ee/spock-s-dirty-little-secret", "postedAtFormatted": "Wednesday, March 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Spock's%20Dirty%20Little%20Secret&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpock's%20Dirty%20Little%20Secret%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fru536oPGPJsEkA3Ee%2Fspock-s-dirty-little-secret%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Spock's%20Dirty%20Little%20Secret%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fru536oPGPJsEkA3Ee%2Fspock-s-dirty-little-secret", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fru536oPGPJsEkA3Ee%2Fspock-s-dirty-little-secret", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2173, "htmlBody": "<p><strong>Related on OB</strong>: <a href=\"http://www.overcomingbias.com/2007/10/priming-and-con.html\">Priming and Contamination</a><br /> <strong>Related on LW</strong>:&nbsp;<a href=\"/lw/4h/when_truth_isnt_enough/\">When Truth Isn't Enough</a></p>\n<p>When I was a kid, I wanted to be like Mr. Spock on Star Trek.&nbsp; He was smart, he could kick ass, and he usually saved the day while Kirk was too busy pontificating or womanizing.</p>\n<p>And since Spock loved logic, I tried to learn something about it myself.&nbsp; But by the time I was 13 or 14, grasping the basics of boolean algebra (from borrowed computer science textbooks), and propositional logic (through a game of \"Wff'n'Proof\" I picked up at a garage sale), I began to get a little dissatisfied with it.</p>\n<p>Spock had made it seem like logic was some sort of \"formidable\" thing, with which you could do all kinds of awesomeness.&nbsp; But <em>real</em> logic didn't seem to work the same way.</p>\n<p>I mean, sure, it was neat that you could apply all these algebraic transforms and dissect things in interesting ways, but none of it seemed to <strong>go</strong> anywhere.</p>\n<p>Logic didn't say, \"thou shalt perform this sequence of transformations and thereby produce an Answer\".&nbsp; Instead, it said something more like, \"do whatever you want, as long as it's well-formed\"...&nbsp; and left the very real question of what it was you <strong>wanted</strong>, as an exercise for the logician.</p>\n<p>And it was at that point that I realized something that Spock hadn't mentioned (yet): that logic was only the <em>beginning</em> of wisdom, not the <strong>end</strong>.</p>\n<p>Of course, I didn't phrase it exactly that way myself...&nbsp; but I <em>did</em> see that logic could only be used to <em>check</em> things...&nbsp; not to&nbsp;<strong>generate</strong> them.&nbsp; The ideas to be checked, still had to <em>come</em> from somewhere.</p>\n<p>But where?</p>\n<p>When I was 17, in college philosophy class, I learned another limitation of logic: or more precisely, of the <em>brains</em> with which we do logic.<a id=\"more\"></a></p>\n<p>Because, although I'd already learned to work with formalisms -- i.e., meaningless symbols -- working with actual syllogisms about Socrates and mortals and whatnot was actually a good bit <em>harder</em>.</p>\n<p>We were supposed to determine the validity of the syllogisms, but sometimes an invalid syllogism had a <strong>true</strong> conclusion, while a valid syllogism might have a <strong>false</strong> one.&nbsp; And, until I learned to mentally substitute symbols like A and B for the included facts, I found my brain automatically jumping to the wrong conclusions about validity.</p>\n<p>So \"logic\", then -- or rationality -- seemed to require <strong>three</strong> things to actually work:</p>\n<ul>\n<li>A way to generate possibly-useful ideas </li>\n<li>A way to check the logical validity -- not truth! -- of those ideas, and </li>\n<li>A way to <a href=\"http://www.overcomingbias.com/2007/07/making-beliefs-.html\">test those ideas against experience</a>. </li>\n</ul>\n<p>But it wasn't until my late thirties and early forties -- just in the last couple of years -- that I realized a <strong>fourth</strong> piece, implicit in the first.</p>\n<p>And Spock, ironically enough, is the reason I found it so difficult to grasp that last, vital piece:</p>\n<p>That to generate possibly-useful ideas in the first place, you must have some notion of what \"useful\" is!</p>\n<p>And that for humans at least, \"useful\" can only be defined <em>emotionally</em>.</p>\n<p>Sure, Spock was supposed to be <strong>immune</strong> to emotion -- even though in retrospect, <em>everything</em> he does is clearly motivated by emotion, whether it's his obvious love for Kirk, or his desire to be accepted as a \"real\" rationalis... er, Vulcan.&nbsp; (In other words, he disdains emotion merely because that's what he's <em>supposed</em> to do, not because he doesn't actually <em>have</em> any.)</p>\n<p>And although this is all still fictional evidence, one might compare Spock's version of \"unemotional\" with the character of the <a href=\"http://en.wikipedia.org/wiki/Kai_(LEXX)\">undead assasin Kai</a>, from a <a href=\"http://en.wikipedia.org/wiki/Lexx\"><em>different</em> science-fiction series</a>.</p>\n<p>Kai, played by Michael McManus, shows us a slightly more accurate version of what true emotionlessness might be like: complete and utter <strong>apathy</strong>.</p>\n<p>Kai has no goals or cares of his own, frequently making such comments as \"the dead do not want anything\", and \"the dead do not have opinions\".&nbsp; He mostly does as he's asked, but for the most part, he just doesn't <strong>care</strong> about anything one way or another.</p>\n<p>(He'll sleep in his freezer or go on a killing spree, it's all the same to him, though he'll probably tell you the likely consequences of whatever action you see fit to request of him.)</p>\n<p>And <em>scientifically</em> speaking, that's a lot closer to what you&nbsp;<strong>actually</strong> get, if you don't have any emotions.</p>\n<p>Not a \"formidable rationalist\" and idealist, like Spock or Eliezer...</p>\n<p>But an <strong>apathetic zombie</strong>, like Kai.</p>\n<p>As Temple Grandin puts it (in her book, Animals In Translation):</p>\n<blockquote>\n<p><em>Everyone</em> uses emotion to make decisions. People with brain damage to their emotional systems have a hard time making any decision at all, and when they do make a decision <strong>it's usually bad</strong>.</p>\n</blockquote>\n<p>She is, of course, summarizing Antonio Damasio's work in relation to the <a href=\"http://cogsci.uwaterloo.ca/Articles/Pages/Emot.Decis.html\">somatic marker hypothesis and decision coherence</a>.&nbsp; From the linked article:</p>\n<blockquote>\n<p>Somatic markers explain how goals can be efficiently prioritized by a cognitive system, without having to evaluate the propositional content of existing goals. After somatic markers are incorporated, what is compared by the deliberator is not the goal as such, but its <em>emotional tag</em>. [Emphasis added]</p>\n<p>The biasing function of somatic markers explains how irrelevant information can be excluded from coherence considerations. With Damasio's thesis, choice activation can be seen as involving emotion at <strong>the most basic computational level</strong>. [Emphasis added]<br /> ...<br /> This sketch shows how emotions help to prevent our decision calculations from becoming so complex and cumbersome that decisions would be impossible. Emotions function to reduce and limit our reasoning, and <em>thereby make reasoning possible</em>. [Emphasis added]</p>\n</blockquote>\n<p>Now, we can get into all sorts of argument about what constitues \"emotion\", exactly.&nbsp; I personally like the term \"somatic marker\", though, because it ties in nicely with concepts such as facial micro-expressions and gestural accessing cues.&nbsp; It also emphasizes the fact that an emotion doesn't actually need to be conscious or persistent, in order to act as a decision influencer and a source of bias.</p>\n<p>But I didn't find out about somatic markers or emotional decisions because I was trying to find out more about logic or rationalism.&nbsp; I was studying akrasia<sup><a href=\"#fn1\">1</a></sup>, and writing about it on <a href=\"http://dirtsimple.org/\">my blog</a>.</p>\n<p>That is, I was trying to find out why I didn't always do what I \"decided to do\"... and what I could do to <strong>fix</strong> that.</p>\n<p>And in the process, I discovered what somatic markers have to do with akrasia, and with motivated reasoning...&nbsp; long before I read any of the theories about the underlying machinery.&nbsp; (After all, until I knew what they did, I didn't know what papers would've been relevant.&nbsp; And in any case, I was looking for <em>practice</em>, not theory)</p>\n<p>Now, in future posts in this series, I'll tie somatic markers, affective synchrony, and Robin Hanson's \"near/far\" hypothesis together into something I call the \"Akrasian Orchestra\"...&nbsp; a fairly ambitious explanation of why/how we \"don't do what we decide to\" , and for that matter, don't even <em>think</em> the way we decide to.</p>\n<p>But for <em>this</em> post, I just want to start by introducing the idea of somatic markers in decision-making, and give a little preview of what that means for rationality.</p>\n<p>Somatic markers are effectively a kind of <strong>cached thought</strong>.&nbsp; They are, in essence, the \"tiny XML tags of the mind\", that label things \"good\" or \"bad\", or even \"rational\" and \"irrational\". (Which of course are just disguised versions of \"good\" and \"bad\", if you're a rationalist.)</p>\n<p>And it's imporant to understand that you <em>cannot escape this labeling</em>, even if you wanted to.&nbsp; (After all, the only reason you're able to <em>want</em> to, is because this labeling system exists!)</p>\n<p>See, it's not even that only <strong>strong</strong> emotions do this: weak or momentary emotional responses will do just fine for tagging purposes.&nbsp; Even <a href=\"http://books.google.com/books?id=tMv1EbXGen4C&amp;pg=PA363&amp;lpg=PA363&amp;dq=emotional+nonsense+syllables&amp;source=bl&amp;ots=v9L27GGSEa&amp;sig=oOY8y7z8gOd0qBcEnwrlWFAEvBE&amp;hl=en&amp;ei=OWjKSa6CKJyIygWv_oXLAw&amp;sa=X&amp;oi=book_result&amp;resnum=8&amp;ct=result\">momentary pairing of positive or negative words with nonsense syllables</a> can carry over into the perception of the <em>taste</em> of otherwise-identical sodas, branded with made-up names using the nonsense syllables!</p>\n<p>As you can see, this idea ties in rather nicely with things like priming and the IAT: your brain is always, always, always tagging things for later retrieval.</p>\n<p>Not only that, but it's also frequently &nbsp;<em>replaying</em> these tags -- in somatic, body movement form -- as you <em>think</em> about things.</p>\n<p>For example, let's say that you're working on an equation or a computer program...&nbsp; and you get that feeling that something's <strong>not quite right</strong>.</p>\n<p>As I wrote the preceding sentence, my face twisted into a slight frown, my brow wrinkling slightly as well -- my somatic marker for that feeling of \"not quite right-ness\".&nbsp; And, if you actually recall a situation like that for yourself, you may feel it too.</p>\n<p>Now, some people would claim that this marker isn't \"really\" an emotion: that they just \"logically\" or \"rationally\" decided that something wasn't right with the equation or program or spaceship or whatever.</p>\n<p>But if we were to put those same people on a brain scanner and a polygraph, and observe what happens to their brain and body as they \"logically\" think through various possibilities, we would see somatic markers flying everywhere, as hypotheses are being considered and discarded.</p>\n<p>It's simply that, while your conscious attention is focused on your logic, you have little interest in attending directly to the emotions that are guiding you.&nbsp; When you get the \"information scent\" of a good or a bad hypothesis, you simply direct your attention to either following the hypothesis, or discarding it and finding a replacement.</p>\n<p>Then, when you <strong>stop</strong> reasoning, and experience the frustration or elation of your results (or lack thereof), you finally have attention to spare for the emotion <strong>itself</strong>...&nbsp; leading to the common illusion that emotion and reasoning don't mix.&nbsp; (When what actually doesn't mix, at least without practice, is reasoning and <em>paying conscious attention</em> to your emotions/somatic markers at the same time.)</p>\n<p>Now, some somatic markers are shared by all humans, such as the <a href=\"http://en.wikipedia.org/wiki/Paul_Ekman#Emotion_classification\">universal facial expressions</a>, or the salivation and mouth-pursing that happens when you recall (or imagine) eating something sour.&nbsp; Others may be more individual.</p>\n<p>Some markers persist for longer periods than others -- that \"not quite right\" feeling might just flicker for a moment while you're <em>recalling</em> a situation, but persist until you find an answer, when it's a response to the actual situation.</p>\n<p>But it's not even necessary for a somatic marker to be <em>expressed</em>, in order for it to influence your thinking, since emotional associations and speed of recall are tightly linked.&nbsp; In effect, recall is prioritized by emotional affect...&nbsp; meaning that your memories are sorted by what makes you feel <strong>better</strong>.</p>\n<p>(Or what makes you feel &nbsp;<em>less bad</em> ... which is <strong>not</strong> the same thing, as we'll see later in this series!)</p>\n<p>What this means is that <strong>all</strong> reasoning is in some sense \"motivated\", but it's not always <em>consciously</em> motivated, because your memories are <em>pre-sorted</em> for retrieval in an emotionally biased fashion.</p>\n<p>In other words, the search engine of your mind...</p>\n<p>Returns <strong>paid results first</strong>.</p>\n<p>This means that, strictly speaking, you don't <strong>know</strong> your own motivations for thinking or acting as you do, unless you explicitly perform the necessary steps to examine them in the moment.&nbsp; Even if you previously believe yourself to have worked out those motivations, you cannot strictly know that your analysis still stands, since priming and other forms of conditioning can <em>change those motivations on the fly</em>.</p>\n<p>This is the real reason it's important to <a href=\"http://www.overcomingbias.com/2007/07/making-beliefs-.html\">make beliefs pay rent</a>, and to ground your thinking as much as possible in \"near\" hypotheses: keeping your reasoning tied closely to physical reality represents the only possible \"independent fact check\" on your biased \"search engine\".</p>\n<p>Okay, that's enough of the \"emotional decisions are bad and scary\" frame.&nbsp; Let's take the <strong>opposite</strong> side now:</p>\n<p>Without emotions, we couldn't <em>reason</em> at all.</p>\n<p>Spock's dirty little secret is that logic doesn't <strong>go</strong> anywhere, without emotion.&nbsp; Without emotion, you have no way to narrow down the field of \"all possible hypotheses\" to \"potentially useful hypotheses\" or \"likely to be true\" hypotheses...</p>\n<p>Nor would you have any <strong>reason</strong> to do so in the first place!</p>\n<p>Because the hidden meaning of the word \"reason\", is that it doesn't just mean logical, sensible, or rational...</p>\n<p>It also means \"purpose\".</p>\n<p>And you can't have a purpose, without an <strong>emotion</strong>.</p>\n<p>If Spock didn't make me feel something <em>good</em>, I might never have studied logic.&nbsp; If stupid people hadn't made me feel something <em>bad</em>, I might never have looked up to Spock for being smart.&nbsp; If procrastination hadn't made me feel bad, I never would've studied it.&nbsp; If writing and finding answers to provocative questions didn't make me feel good, I never would've written as much as I have.</p>\n<p>The truth is, we can't do <em>anything</em> -- be it good or bad -- without <strong>some</strong> emotion playing a key part.</p>\n<p>And that fact itself, is neither good nor bad: it's just a fact.</p>\n<p>And as Spock himself might say, it's \"highly illogical\" to worry about it.</p>\n<p>No matter what your somatic markers might be telling you.</p>\n<p>&nbsp;</p>\n<p>Footnotes:</p>\n<p><a id=\"fn1\" name=\"fn1\"></a>1. I actually didn't <em>know</em> I was studying \"<a href=\"http://en.wikipedia.org/wiki/Akrasia\">akrasia</a>\"...&nbsp; in fact, I'd never even <strong>heard</strong> the term akrasia before, until I saw it in <a href=\"/lw/2c/a_sense_that_more_is_possible/1g0?context=1\">a thread on LessWrong discussing my work</a>.&nbsp; As far as I was concerned, I was working on \"procrastination\", or \"willpower\", or maybe even \"self-help\" or \"productivity\".&nbsp; But akrasia is a nice catch-all term, so I'll use it here.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3ee9k6NJfcGzL6kMS": 1, "GBpwq8cWvaeRoE9X5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ru536oPGPJsEkA3Ee", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 67, "baseScore": 59, "extendedScore": null, "score": 9.6e-05, "legacy": true, "legacyId": "189", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 59, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 71, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9hR2RmpJmxT8dyPo4"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-25T21:39:18.934Z", "modifiedAt": null, "url": null, "title": "The Good Bayesian", "slug": "the-good-bayesian", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:12.300Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Sideways", "createdAt": "2009-03-14T00:17:13.316Z", "isAdmin": false, "displayName": "Sideways"}, "userId": "YavtmFNTf8Yb4C2kv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/x7LMf4foW22wuW7Cz/the-good-bayesian", "pageUrlRelative": "/posts/x7LMf4foW22wuW7Cz/the-good-bayesian", "linkUrl": "https://www.lesswrong.com/posts/x7LMf4foW22wuW7Cz/the-good-bayesian", "postedAtFormatted": "Wednesday, March 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Good%20Bayesian&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Good%20Bayesian%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx7LMf4foW22wuW7Cz%2Fthe-good-bayesian%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Good%20Bayesian%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx7LMf4foW22wuW7Cz%2Fthe-good-bayesian", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx7LMf4foW22wuW7Cz%2Fthe-good-bayesian", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 508, "htmlBody": "<p>&nbsp;&nbsp;&nbsp; I've talked religion with people of many different ages and creeds, and none of them have ever been content to practice their religion in private.&nbsp; All belong to a religious <em>community</em>; many contribute money and time above and beyond the minimum requirement.&nbsp; And in all the religious discussions I've ever had, I've never heard anyone decline to participate because their religion is <a href=\"/lw/57/the_sacred_mundane\">\"intensely private and individual.\"</a></p>\n<p>&nbsp;&nbsp;&nbsp; So Eliezer's quote from William James by way of Adam Frank left me scratching my head, as well.&nbsp; I think of religion first and foremost as a social behavior rather than an individual one.&nbsp; It's not just that religious people use the claim of private revelation as a defense against reason; it's that they can attend sermons, sing in a choir, recite prayers in unison--and then make that claim of \"solitary\" experience with a straight face!<br /><br />&nbsp;&nbsp;&nbsp; Eliezer's post listed some of the ways that theodicy warps rational thought on the individual level, as sort of warning label on the \"poisoned chalice.\"&nbsp; Religious people are liable to respond that religion may not make people rational, but it makes them altruistic \"good Samaritans.\"&nbsp; (Never mind that in the parable, the Samaritan is more altruistic than a high priest!)&nbsp; They claim that any harm religion does to the individual is outweighed by its benefits to the group.<br /><br />&nbsp;&nbsp;&nbsp; Rationalists should make the case that religion is harmful to society as a whole, as well as individuals:</p>\n<ul>\n<li>Religious groups waste resources.&nbsp; I couldn't find exact figures, but <a href=\"http://atheism.about.com/od/churchestaxexemptions/a/whyitmatters.htm\">Austin Cline</a> claims that tax-exempt religious organizations own 20-25% of land in the US, denying the government billions in tax revenue. Donations and tithes to churches are wasted on funding monasteries, missionaries, and \"bible schools.\"&nbsp; Rationality dojos, or even the government, could allocate these resources more effectively.</li>\n<li>Religion degrades political discourse.&nbsp; Clergymen have an inappropriate amount of involvement and influence in the politics of their congregations, e.g. Catholic bishops denying communion to politicians who support abortion rights.&nbsp; The Terry Schiavo debacle demonstrated that American right-wing religious groups are willing to use political power in unethical ways.&nbsp; It's a national disgrace that no non-Christian could be elected President in the US today.&nbsp; (I don't mean to be US-centric, it's just where my knowledge is concentrated.&nbsp; If you have an example from another country, please add it in comments.)</li>\n<li>Organized religion obstructs social progress.&nbsp; Because religions are based on dogma, they have a status-quo bias that has placed religious institutions on the wrong side of every moral issue in American history, from the abolition of slavery to Prohibition to stem cell research.</li>\n<li>Religious pluralism and state-sponsored religions both harm society.&nbsp; Many competing religions contribute to social fragmentation and create useless discord (as opposed to the useful discord of, say, a free market).&nbsp; A single state-sponsored religion inevitably intrudes into citizens' privacy and the political process.&nbsp; The optimal solution is an atheist society.</li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; I left out at least one obvious argument for the benefit of commenters.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "x7LMf4foW22wuW7Cz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "191", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Fwt4sDDacko8Sh5iR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-25T22:23:28.281Z", "modifiedAt": null, "url": null, "title": "Fight Biases, or Route Around Them?", "slug": "fight-biases-or-route-around-them", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:15.992Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pyNPXST7feDX45ygt/fight-biases-or-route-around-them", "pageUrlRelative": "/posts/pyNPXST7feDX45ygt/fight-biases-or-route-around-them", "linkUrl": "https://www.lesswrong.com/posts/pyNPXST7feDX45ygt/fight-biases-or-route-around-them", "postedAtFormatted": "Wednesday, March 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fight%20Biases%2C%20or%20Route%20Around%20Them%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFight%20Biases%2C%20or%20Route%20Around%20Them%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpyNPXST7feDX45ygt%2Ffight-biases-or-route-around-them%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fight%20Biases%2C%20or%20Route%20Around%20Them%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpyNPXST7feDX45ygt%2Ffight-biases-or-route-around-them", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpyNPXST7feDX45ygt%2Ffight-biases-or-route-around-them", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1475, "htmlBody": "<p><strong>Continuation of:</strong> <a href=\"/lw/53/the_implicit_association_test/\">The Implicit Association Test</a><br /><strong>Response to:</strong> <a href=\"/lw/2s/3_levels_of_rationality_verification/\">3 Levels of Rationality Verification</a></p>\n<p>I've not yet seen it pointed out before that we use \"bias\" to mean two different things.<br /><br />Sometimes we use \"bias\" to mean a hard-coded cognitive process that results in faulty beliefs. Take as examples the in-group bias, the recall bias, the bad guy bias, and various other things discovered by Tversky and Kahneman.<br /><br />Other times, we use \"bias\" to mean a specific faulty belief generated by such a process, especially one that itself results in other faulty beliefs. For example, Jews are sometimes accused of having a pro-Israel bias. By this we mean that they have a higher opinion of Israel than the evidence justifies; this is a specific belief created by the in-group bias. This belief may itself generate other faulty beliefs; for example, they may have a more negative opinion of Palestinians than the evidence justifies. It is both the effect of a bias, and the cause of other biases.<br /><br />Let's be clear about this \"more than the evidence justifies\" bit. Hating Hitler doesn't mean you're biased against Hitler. Likewise, having a belief about a particular ethnic group doesn't mean you're biased for or against them. My Asian friends hate it when people sheepishly admit in a guilty whisper that they've heard Asians are good at academics. Asians <em>are</em> good at academics. Just say \"55% chance an average Asian has a GPA above the American population mean\" and leave it at that. This is one of Tetlock's critiques of the Implicit Association Test, and it's a good one. I'd probably link Asians to high achievement on an IAT, but it wouldn't be a bias or anything to get upset about.<br /><br />And let's also be clear about this faulty belief thing. You don't have to <em>believe</em> something for it to be a belief; consider again <a href=\"/lw/1l/the_mystery_of_the_haunted_rationalist/\">the skeptic who flees the haunted house</a>. She claims she doesn't belief in ghosts, and she's telling the truth one hundred percent. She's <em>still</em> going to be influenced by her belief in ghosts. She's not secretly supernaturalist any more than someone who gets \"strongly biased\" on the IAT is secretly racist. But she needs to know she's still going to run screaming from haunted houses, and IAT-takers should be aware they're still probably going to discriminate against black people in some tiny imperceptible way.</p>\n<p><a id=\"more\"></a></p>\n<p>Okay, back to the example. So the President appoints Isaac, a synagogue-going Jew, as the new Middle East peace envoy. Due to some amazing breakthrough in the region, both the Israelis and Palestinians agree to accept whatever plan Isaac develops. Isaac's only job is to decide what long-term plan is best for both sides. And he's a good man: he has an honest desire to choose the maximum-utility solution.<br /><br />Isaac legitimately worries that he has a bias for the Israelis and against the Palestinians. How can he test the hypothesis? He can take a hypothetical souped-up version of the Implicit Association Test<sup>1</sup>. He finds that yes, he has a strong pro-Israel anti-Palestine bias. Now what does he do?<br /><br />He can try to route around the bias. This is the approach implicitly endorsed by Overcoming Bias and by rationalism in general. He can take the Outside View and look at successful approaches in other world conflicts. He can use some objective metric to calculate the utility of everything in Israel, and check to make sure neither group is getting an amount disproportionate to their numbers. He can open a prediction market on metrics of success, and implement whatever policies trades at the highest value. All of these will probably improve Isaac's solution a fair bit. But none of them are perfect. In the end, Isaac's the one who has to make a decision that will be underdetermined by all these clever methods, and Isaac is still biased against the Palestinians.<br /><br />Or he can try to fight the bias.<br /><br />Diversity workshops try to fight biases directly . <a href=\"http://www.overcomingbias.com/2008/01/mandatory-sensi.html\">These don't work</a>, and that's no surprise. Diversity workshops are telling you, on a conscious level, that minorities really are great people, aren't they? Well, yes. On a conscious level, you already believe that. Isaac already knows, on a conscious level, that the Palestinians deserve a fair solution that protects their interests just as much as the Israelis do. A diversity workshop would be a flashy video in which a condescending narrator explains that point again and again.<br /><br />We don't have a lot of literature on what does work here, but I predict a few things would help. Make some Palestinian friends, to build mental connections between Palestinians and positive feelings. Learn to distinguish between Palestinian faces. Read works of fiction with sympathetic Palestinian characters. I would say \"live in Palestine\" but by all accounts Palestine is a pretty grim place; he might do better to live in a Palestinian community in America for a while.<br /><br />Those techniques aren't especially good, but I don't care. We know how to improve them. By making a group take the Implicit Association Test, applying a technique to them, giving them the test again, and seeing how their score changed, we gain the ability to test bias-fighting techniques. I wouldn't want to do this on one person, because the test only has moderate reliability at the individual level. But a group of a few dozen, all practicing the same technique, would be quite sufficient. If another group learns a different technique, we can compare their IAT score improvement and see which technique is better, or if different techniques are better in different circumstances.<br /><br />Again, there's no reason why this method should be limited to racial biases. No matter how hard I try to evaluate policies on their merits rather than their politics, I am biased towards the US Democratic Party and I know it. This ought to be visible on an IAT, and there ought to be techniques to cure it. I don't know what they are, but I'd like to find them and start testing them.<br /><br />What about the second method of overcoming bias, routing around it? The IAT is less directly valuable here, but it's not without a role.<br /><br />In one of the IAT experiments, subjects evaluated essays written by black or white students. This is a fiendishly difficult task upon which to avoid bias. A sneaky researcher can deliberately select essays graded as superior by a blind observer and designate them \"white essays\", so anyone trying to take the easy way out by giving all essays the same grade can be caught immediately. I like this essay task. It's utterly open to any technique you want to use to reduce bias.<br /><br />So give someone IATs until you find a group they're especially biased against - black people, Palestinians, Korean-Americans, frequentists; any will do. Then make them grade essays by the control group and the disliked group. Collect statistics correlating IAT bias with essay grading bias. If a person using a special technique to route around mental bias can grade essays more accurately than other people with the same level of IAT bias, that person has routed around their bias successfully.<br /><br />So: How do we tell if a technique for routing around bias works? Test whether people are better able to conduct a rating task than their IAT scores would predict. How do we test a technique for fighting bias directly? See if it lowers IAT scores. All terribly inconvenient because of the IAT's low effect size and reliability, but with a large enough sample size or enough test-retest cycles the thing could be done. And the psychologists who transformed the Bona Fide Pipeline into the IAT may yet transform the IAT into something even more powerful.<br /><br />This, then, is one solution to <a href=\"/lw/2j/schools_proliferating_without_evidence/\">schools proliferating without evidence</a>. With enough research, it could be turned into one of the missing <a href=\"/lw/2s/3_levels_of_rationality_verification/\">techniques of rationality verification</a>.</p>\n<p>&nbsp;</p>\n<p><strong>Footnotes</strong></p>\n<p><strong>1:</strong> Remember, the IAT is only moderately good at evaluating individuals, and has a bad habit of changing its mind each time someone takes it. Much of what is in this essay would work poorly (though probably still better than nothing) with a simple IAT. But having someone take the IAT ten times over ten days and averaging the results might give a more accurate picture (I don't know of any studies on this). And in any case the IAT is quite good at comparing groups of people with sample size &gt;1. And I expect that souped-up versions of the IAT will be out within a few years; these tests have gotten better and better as time goes on.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "2wjPMY34by2gXEXA2": 1, "5f5c37ee1b5cdee568cfb128": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pyNPXST7feDX45ygt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 27, "extendedScore": null, "score": 6e-05, "legacy": true, "legacyId": "193", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iYJo382hY28K7eCrP", "5K7CMa6dEL7TN7sae", "mja6jZ6k9gAwki9Nu", "JnKCaGcgZL4Rsep8m"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T02:48:49.944Z", "modifiedAt": null, "url": null, "title": "Open Thread", "slug": "open-thread-1", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:12.123Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wvcxAuhmj4DJw7gho/open-thread-1", "pageUrlRelative": "/posts/wvcxAuhmj4DJw7gho/open-thread-1", "linkUrl": "https://www.lesswrong.com/posts/wvcxAuhmj4DJw7gho/open-thread-1", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwvcxAuhmj4DJw7gho%2Fopen-thread-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwvcxAuhmj4DJw7gho%2Fopen-thread-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwvcxAuhmj4DJw7gho%2Fopen-thread-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p>For Yvain.</p>\r\n<p>I can commit to posting regularly scheduled open threads, if that appeals. Discuss scheduling in comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wvcxAuhmj4DJw7gho", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "196", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T03:56:57.416Z", "modifiedAt": null, "url": null, "title": "Why *I* fail to act rationally", "slug": "why-i-fail-to-act-rationally", "viewCount": null, "lastCommentedAt": "2020-09-01T18:29:44.669Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bentarm", "createdAt": "2009-03-05T17:59:17.163Z", "isAdmin": false, "displayName": "bentarm"}, "userId": "xdmTZWK4DzchxkyQC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uLhrHa5Q4PqwLz2P6/why-i-fail-to-act-rationally", "pageUrlRelative": "/posts/uLhrHa5Q4PqwLz2P6/why-i-fail-to-act-rationally", "linkUrl": "https://www.lesswrong.com/posts/uLhrHa5Q4PqwLz2P6/why-i-fail-to-act-rationally", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20*I*%20fail%20to%20act%20rationally&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20*I*%20fail%20to%20act%20rationally%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuLhrHa5Q4PqwLz2P6%2Fwhy-i-fail-to-act-rationally%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20*I*%20fail%20to%20act%20rationally%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuLhrHa5Q4PqwLz2P6%2Fwhy-i-fail-to-act-rationally", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuLhrHa5Q4PqwLz2P6%2Fwhy-i-fail-to-act-rationally", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 277, "htmlBody": "<p>There is a lot of talk here about sophisticated rationality failures - priming, overconfidence, etc. etc. There is much less talk about what I think is the more common reason for people failing to act rationally in the real world - something that I think most people outside this community would agree is the most common rationality failure mode - acting emotionally (<a href=\"/lw/59/spocks_dirty_little_secret/#more\">pjeby</a> has just begun to discuss this, but I don't think it's the main thrust of his post...).</p>\n<p>While there can be sound evolutionary reasons for having emotions (the thirst for revenge as a <a href=\"http://en.wikipedia.org/wiki/Doomsday_device\">Doomsday Machine</a> being the easiest to understand), and while we certainly don't want to succumb to the fallacy that rationalists are emotionless Spock-clones. I think overcoming (or at least being able to control) emotions would, for most people, be a more important first step to acting rationally than overcoming biases.</p>\n<p>If I could avoid saying things I'll regret later when angry, avoid putting down colleagues through jealousy, avoid procrastinating because of laziness and avoid refusing to make correct decisions because of fear, I think this would do a lot more to make me into a <a href=\"/lw/31/what_do_we_mean_by_rationality/\">winner</a>&nbsp;than if I could figure out how to correctly calibrate my beliefs about trivia questions, or even get rid of my unwanted Implicit Associations.</p>\n<p>So the question - do we have good techniques for preventing our emotions from making bad decisions for us? Something as simple as \"count to ten before you say anything when angry\" is useful if it works. Something as sophisticated as \"become a Zen Master\" is probably unattainable, but might at least point us in the right direction - and then there's everything in between.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "dJ6eJxJrCEget7Wb6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uLhrHa5Q4PqwLz2P6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 15, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "182", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T04:04:07.047Z", "modifiedAt": null, "url": null, "title": "Open Thread: March 2009", "slug": "open-thread-march-2009", "viewCount": null, "lastCommentedAt": "2017-06-17T03:53:29.034Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cm9FG45yasfijeeQc/open-thread-march-2009", "pageUrlRelative": "/posts/cm9FG45yasfijeeQc/open-thread-march-2009", "linkUrl": "https://www.lesswrong.com/posts/cm9FG45yasfijeeQc/open-thread-march-2009", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%3A%20March%202009&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%3A%20March%202009%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fcm9FG45yasfijeeQc%2Fopen-thread-march-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%3A%20March%202009%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fcm9FG45yasfijeeQc%2Fopen-thread-march-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fcm9FG45yasfijeeQc%2Fopen-thread-march-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p>Here is our monthly place to discuss Less Wrong topics that have not appeared in recent posts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cm9FG45yasfijeeQc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 6, "extendedScore": null, "score": 4.836473884600748e-07, "legacy": true, "legacyId": "197", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 72, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T04:42:32.223Z", "modifiedAt": null, "url": null, "title": "Two Blegs", "slug": "two-blegs", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:12.570Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "talisman", "createdAt": "2009-03-05T23:30:16.521Z", "isAdmin": false, "displayName": "talisman"}, "userId": "SXxD8wMPMJZZEdNZe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v69oPvxe6c9nNFiBa/two-blegs", "pageUrlRelative": "/posts/v69oPvxe6c9nNFiBa/two-blegs", "linkUrl": "https://www.lesswrong.com/posts/v69oPvxe6c9nNFiBa/two-blegs", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Two%20Blegs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATwo%20Blegs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv69oPvxe6c9nNFiBa%2Ftwo-blegs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Two%20Blegs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv69oPvxe6c9nNFiBa%2Ftwo-blegs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv69oPvxe6c9nNFiBa%2Ftwo-blegs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<div>I'm not sure where to post this, so, using this <a href=\"/lw/5b/the_good_bayesian/3no?context=1#3no\">comment thread</a> as cover, I will hereby bleg for the following: \n<ul>\n<li>A good OB-level proof or explication of the innards of Aumann's theorem, much more precise than <a href=\"http://hanson.gmu.edu/deceive.pdf\">Hanson and Cowen's</a> but less painful than <a href=\"http://www.econ.brown.edu/Students/Debipriya_Chatterjee/EC2060page/Readings/Aumann76.pdf\">Aumann's original</a> or <a href=\"http://www.princeton.edu/~bayesway/pu/Aumn.pdf\">this other one</a>.</li>\n<li> Stories of how people have <a href=\"http://www.overcomingbias.com/2008/06/thou-art-physic.html\">busted open</a> questions or controversies using rationalist tools. (I think this in particular will be useful to learners.)</li>\n</ul>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Pa2SdZsLFmqhs42Do": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v69oPvxe6c9nNFiBa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 4, "extendedScore": null, "score": 4.836529708878443e-07, "legacy": true, "legacyId": "198", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T07:16:21.397Z", "modifiedAt": null, "url": null, "title": "Your Price for Joining", "slug": "your-price-for-joining", "viewCount": null, "lastCommentedAt": "2020-08-28T03:01:27.175Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q8evewZW5SeidLdbA/your-price-for-joining", "pageUrlRelative": "/posts/Q8evewZW5SeidLdbA/your-price-for-joining", "linkUrl": "https://www.lesswrong.com/posts/Q8evewZW5SeidLdbA/your-price-for-joining", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Your%20Price%20for%20Joining&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYour%20Price%20for%20Joining%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ8evewZW5SeidLdbA%2Fyour-price-for-joining%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Your%20Price%20for%20Joining%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ8evewZW5SeidLdbA%2Fyour-price-for-joining", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ8evewZW5SeidLdbA%2Fyour-price-for-joining", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1319, "htmlBody": "<p>In the <a href=\"http://en.wikipedia.org/wiki/Ultimatum_game\">Ultimatum Game</a>, the first player chooses how to split $10 between themselves and the second player, and the second player decides whether to accept the split or reject it&mdash;in the latter case, both parties get nothing.&nbsp; So far as conventional causal decision theory goes (two-box on <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">Newcomb's Problem</a>, defect in <a href=\"http://www.overcomingbias.com/2008/09/true-pd.html\">Prisoner's Dilemma</a>), the second player should prefer any non-zero amount to nothing.&nbsp; But if the first player <em>expects </em>this behavior&mdash;accept any non-zero offer&mdash;then they have no motive to offer more than a penny.&nbsp; As I assume you all know by now, I am <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">no fan of conventional causal decision theory</a>.&nbsp; Those of us who remain interested in cooperating on the Prisoner's Dilemma, either because it's iterated, or because we have a term in our utility function for fairness, or because we use an unconventional decision theory, may also not accept an offer of one penny.</p>\n<p>And in fact, most Ultimatum \"deciders\" offer an even split; and most Ultimatum \"accepters\" reject any offer less than 20%.&nbsp; A 100 USD game played in Indonesia (average per capita income at the time: 670 USD) showed offers of 30 USD being turned down, although this equates to two week's wages.&nbsp; We can probably also assume that the players in Indonesia were not thinking about the academic debate over Newcomblike problems&mdash;this is just the way people feel about Ultimatum Games, even ones played for real money.</p>\n<p>There's an analogue of the Ultimatum Game in group coordination.&nbsp; (Has it been studied?&nbsp; I'd hope so...)&nbsp; Let's say there's a common project&mdash;in fact, let's say that it's an altruistic common project, aimed at helping mugging victims in Canada, <em>or something</em><em>.</em>&nbsp; If you join this group project, you'll get more done than you could on your own, relative to your utility function.&nbsp; So, obviously, you should join.</p>\n<p>But wait!&nbsp; The anti-mugging project keeps their funds invested in a money market fund!&nbsp; That's ridiculous; it won't earn even as much interest as US Treasuries, let alone a dividend-paying index fund.</p>\n<p>Clearly, this project is run by morons, and you shouldn't join until they change their malinvesting ways.</p>\n<p>Now you might realize&mdash;if you stopped to think about it&mdash;that all things considered, you would <em>still </em>do better by working with the common anti-mugging project, than striking out on your own to fight crime.&nbsp; But then&mdash;you might perhaps also realize&mdash;if you <em>too easily assent</em> to joining the group, why, what <em>motive</em> would they have to change their malinvesting ways?</p>\n<p>Well...&nbsp; Okay, look.&nbsp; Possibly because we're out of the ancestral environment where everyone knows everyone else... and possibly because the <a href=\"/lw/3h/why_our_kind_cant_cooperate\">nonconformist crowd</a> tries to repudiate <em>normal </em>group-cohering forces like conformity and leader-worship...</p>\n<p>...It seems to me that people in the atheist/libertarian/technophile/sf-fan/etcetera cluster often set their joining prices <em>way way way </em>too high.&nbsp; Like a 50-way split Ultimatum game, where every one of 50 players demands at least 20% of the money.<a id=\"more\"></a></p>\n<p>If you think how often situations like this would have arisen in the ancestral environment, then it's almost certainly a matter of <a href=\"http://www.overcomingbias.com/2007/11/evolutionary-ps.html\">evolutionary psychology.</a>&nbsp; System 1 emotions, not System 2 calculation.&nbsp; Our intuitions for when to join groups, versus when to hold out for more concessions to our own preferred way of doing things, would have been honed for hunter-gatherer environments of, e.g., 40 people all of whom you knew personally.</p>\n<p>And if the group is made up of 1000 people?&nbsp; Then your hunter-gatherer instincts will underestimate the inertia of a group so large, and demand an unrealistically high price (in strategic shifts) for you to join.&nbsp; There's a limited amount of organizational effort, and a limited number of degrees of freedom, that can go into doing things any one's person way.</p>\n<p>And if the strategy is large and complex, the sort of thing that takes e.g. ten people doing paperwork for a week, rather than being hammered out over a half-hour of negotiation around a campfire?&nbsp; Then your hunter-gatherer instincts will underestimate the inertia of the group, relative to your own demands.</p>\n<p>And if you live in a wider world than a single hunter-gatherer tribe, so that you only see the one group representative who negotiates with you, and not the hundred other negotiations that have taken place already?&nbsp; Then your instincts will tell you that it is just one person, a stranger at that, and the two of you are equals; whatever ideas they bring to the table are equal with whatever ideas you bring to the table, and the meeting point ought to be about even.</p>\n<p>And if you suffer from any weakness of will or akrasia, or if you are influenced by motives other than those you would admit to yourself that you are influenced by, then any group-altruistic project which does not offer you the rewards of status and control, may perhaps find itself underserved by your attentions.</p>\n<p>Now I do admit that I speak here primarily from the perspective of someone who goes around trying to herd cats; and not from the other side as someone who spends most of their time withholding their energies in order to blackmail those damned morons already on the project.&nbsp; Perhaps I am a little prejudiced.</p>\n<p>But it seems to me that a reasonable rule of thumb might be as follows:</p>\n<p>If, on the whole, joining your efforts to a group project <em>would still have a net positive effect</em> according to your utility function&mdash;</p>\n<p>(or a larger positive effect than any other marginal use to which you could otherwise put those resources, although this latter mode of thinking seems little-used and humanly-unrealistic, for reasons I may post about some other time)</p>\n<p>&mdash;and the awful horrible annoying issue is not so important that <em>you personally</em> will get involved deeply enough to put in however many hours, weeks, or years may be required to get it fixed up&mdash;</p>\n<p>&mdash;then the issue is not worth you withholding your energies from the project; either instinctively until you see that people are paying attention to you and respecting you, or by conscious intent to blackmail the group into getting it done.</p>\n<p>And if the issue <em>is</em> worth that much to you... then by all means, join the group and do whatever it takes to get things fixed up.</p>\n<p>Now, if the existing contributors refuse to let you do this, <em>and </em>a reasonable third party would be expected to conclude that you were competent enough to do it, <em>and </em>there is no one else whose ox is being gored thereby, <em>then,</em> perhaps, we have a problem on our hands.&nbsp; And it may be time for a little blackmail, if the resources you can conditionally commit are large enough to get their attention.</p>\n<p>Is this rule a little extreme?&nbsp; Oh, maybe.&nbsp; There <em>should</em> be a motive for the decision-making mechanism of a project to be responsible to its supporters; unconditional support would create its own problems.</p>\n<p>But <em>usually</em>... I observe that people underestimate the costs of what they ask for, or perhaps just act on instinct, and set their prices <em>way way way</em> too high.&nbsp; If the nonconformist crowd ever wants to get anything done together, we need to move in the direction of joining groups and staying there at least a <em>little </em>more easily.&nbsp; Even in the face of annoyances and imperfections!&nbsp; Even in the face of unresponsiveness to our own better ideas!</p>\n<p>In the age of the Internet and in the company of nonconformists, it does get a little tiring reading the 451st public email from someone saying that the Common Project isn't worth their resources until the website has a sans-serif font.</p>\n<p>Of course this often isn't really about fonts.&nbsp; It may be about laziness, akrasia, or <a href=\"http://www.overcomingbias.com/2008/12/your-true-rejec.html\">hidden rejections</a>.&nbsp; But in terms of group norms... in terms of what sort of public statements we respect, and which excuses we publicly scorn... we probably <em>do </em>want to encourage a group norm of:</p>\n<p><em>If the issue isn't worth your personally fixing by however much effort it takes, and it doesn't arise from outright bad faith, it's not worth refusing to contribute your efforts to a cause you deem worthwhile.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"b8FHrKqyXuYGWc6vn": 1, "chuP2QqQycjD8qakL": 1, "zv7v2ziqexSn5iS9v": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q8evewZW5SeidLdbA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 76, "baseScore": 67, "extendedScore": null, "score": 0.000103, "legacy": true, "legacyId": "199", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "can-humanism-match-religion-s-output", "canonicalPrevPostSlug": "tolerate-tolerance", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7FzD7pNm9X68Gp5ZC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T11:44:04.156Z", "modifiedAt": null, "url": null, "title": "Sleeping Beauty gets counterfactually mugged", "slug": "sleeping-beauty-gets-counterfactually-mugged", "viewCount": null, "lastCommentedAt": "2017-10-27T02:05:06.048Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CcjcCYYEB5KNHCpEZ/sleeping-beauty-gets-counterfactually-mugged", "pageUrlRelative": "/posts/CcjcCYYEB5KNHCpEZ/sleeping-beauty-gets-counterfactually-mugged", "linkUrl": "https://www.lesswrong.com/posts/CcjcCYYEB5KNHCpEZ/sleeping-beauty-gets-counterfactually-mugged", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sleeping%20Beauty%20gets%20counterfactually%20mugged&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASleeping%20Beauty%20gets%20counterfactually%20mugged%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcjcCYYEB5KNHCpEZ%2Fsleeping-beauty-gets-counterfactually-mugged%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sleeping%20Beauty%20gets%20counterfactually%20mugged%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcjcCYYEB5KNHCpEZ%2Fsleeping-beauty-gets-counterfactually-mugged", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcjcCYYEB5KNHCpEZ%2Fsleeping-beauty-gets-counterfactually-mugged", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 588, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/3l/counterfactual_mugging\">Counterfactual Mugging</a>, <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">Newcomb's Problem and Regret of Rationality</a></p>\n<p>Omega is continuing his eternal mission: To explore strange new philosophical systems... To seek out new paradoxes and new counterfactuals... To boldly go where no decision theory has gone before.</p>\n<p>In his usual totally honest, quasi-omniscient, slightly sadistic incarnation, Omega has a new puzzle for you, and it involves the <a href=\"http://www.anthropic-principle.com/preprints/beauty/synthesis.pdf\">Sleeping Beauty</a> problem as a bonus.</p>\n<p>He will offer a similar deal to that in the <a href=\"/lw/3l/counterfactual_mugging\">counterfactual mugging</a>: he will flip a coin, and if it comes up tails, he will come round and ask you to give him &pound;100.</p>\n<p>If it comes up heads, instead he will simulate you, and check whether you would give him the &pound;100 if asked (as usual, the use of randomising device in the decision is interpreted as a refusal). From this counterfactual, if you would give him the cash, he&rsquo;ll send you &pound;260; if you wouldn&rsquo;t, he&rsquo;ll give you nothing.</p>\n<p>Two things are different from the original setup, both triggered if the coin toss comes up tails: first of all, if you refuse to hand over any cash, he will give you an extra &pound;50 compensation. Second of all, if you do give him the &pound;100, he will force you to take a sedative and an amnesia drug, so that when you wake up the next day, you will have forgotten about the current day. He will then ask you to give him the &pound;100 again.</p>\n<p>To keep everything fair and balanced, he will feed you the sedative and the amnesia drug whatever happens (but will only ask you for the &pound;100 a second time if you accepted to give it to him the first time).</p>\n<p>Would you want to precommit to giving Omega the cash, if he explained everything to you? The odds say yes: precommitting to accepting to hand over the &pound;100 will give you an expected return of 0.5 x &pound;260 + 0.5 x (-&pound;200) = &pound;30, while precommitting to a refusal gives you an expected return of 0.5 x &pound;0 + 0.5 x &pound;50 = &pound;25.</p>\n<p>But now consider what happens at the moment when he actually asks you for the cash.<a id=\"more\"></a></p>\n<p>A standard way to approach these types of problems it to act as if you didn&rsquo;t know whether you were the real you or the simulated you. This avoids a lot of complications and gets you to the heart of the problem. Here, if you decide to give Omega the cash, there are three situations you can be in: the simulation, reality on the first day, or reality on the second day. The <a href=\"http://en.wikipedia.org/wiki/Coherence_%28philosophical_gambling_strategy%29\">Dutch</a> <a href=\"http://en.wikipedia.org/wiki/Dutch_book\">book</a> odds of being in any of these three situations is the same, 1/3. So the expected return is 1/3(&pound;260-&pound;100-&pound;100) = &pound;20, twenty of her majesty&rsquo;s finest English pounds.</p>\n<p>However, if you decide to refuse the hand-over, then you are in one of two situations: the simulation, or reality on the first day (as you will not get asked on the second day). The Dutch book odds are even, so the expected return is 1/2(&pound;0+&pound;50) = &pound;25, a net profit of &pound;5 over accepting.</p>\n<p>So even adding &lsquo;simulated you&rsquo; as an extra option, a hack that solves most Omega type problems, does not solve this paradox: the option you precommit to has the lower expected returns when you actually have to decide.</p>\n<p>Note that if you depart from the Dutch book odds (what did the Dutch do to deserve to be immortalised in that way, incidentally?), then Omega can put you in situations where you lose money with certainty.</p>\n<p>So, what do you do?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NZB24aR9uHmDc5GcT": 1, "YpHkTW27iMFR2Dkae": 1, "b8FHrKqyXuYGWc6vn": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CcjcCYYEB5KNHCpEZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 4, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "200", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mg6jDEuQEjBGtibX7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T21:57:50.014Z", "modifiedAt": null, "url": null, "title": "The Mind Is Not Designed For Thinking", "slug": "the-mind-is-not-designed-for-thinking", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:16.035Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/37XbA3ybyLSzMHZm9/the-mind-is-not-designed-for-thinking", "pageUrlRelative": "/posts/37XbA3ybyLSzMHZm9/the-mind-is-not-designed-for-thinking", "linkUrl": "https://www.lesswrong.com/posts/37XbA3ybyLSzMHZm9/the-mind-is-not-designed-for-thinking", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Mind%20Is%20Not%20Designed%20For%20Thinking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Mind%20Is%20Not%20Designed%20For%20Thinking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37XbA3ybyLSzMHZm9%2Fthe-mind-is-not-designed-for-thinking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Mind%20Is%20Not%20Designed%20For%20Thinking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37XbA3ybyLSzMHZm9%2Fthe-mind-is-not-designed-for-thinking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37XbA3ybyLSzMHZm9%2Fthe-mind-is-not-designed-for-thinking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 31, "htmlBody": "<p>There's an interesting article in the latest issue of <em>American Educator</em>: <a title=\"href=&quot;http://www.aft.org/pubs-reports/american_educator/issues/spring2009/WILLINGHAM(2).pdf&quot;\" href=\"http://www.aft.org/pubs-reports/american_educator/issues/spring2009/WILLINGHAM(2).pdf\">\"Why Don't Students Like School? Because the Mind Is Not Designed For Thinking\"</a> (pdf).</p>\n<p>The general subject is <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">cached thoughts</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ksdiAMKfgSyEeKMo6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "37XbA3ybyLSzMHZm9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 9, "extendedScore": null, "score": 4.838032959474355e-07, "legacy": true, "legacyId": "206", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-26T22:59:39.625Z", "modifiedAt": null, "url": null, "title": "Crowley on Religious Experience", "slug": "crowley-on-religious-experience", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:33.439Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vhxywjnBH6ioRnnt3/crowley-on-religious-experience", "pageUrlRelative": "/posts/vhxywjnBH6ioRnnt3/crowley-on-religious-experience", "linkUrl": "https://www.lesswrong.com/posts/vhxywjnBH6ioRnnt3/crowley-on-religious-experience", "postedAtFormatted": "Thursday, March 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Crowley%20on%20Religious%20Experience&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACrowley%20on%20Religious%20Experience%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvhxywjnBH6ioRnnt3%2Fcrowley-on-religious-experience%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Crowley%20on%20Religious%20Experience%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvhxywjnBH6ioRnnt3%2Fcrowley-on-religious-experience", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvhxywjnBH6ioRnnt3%2Fcrowley-on-religious-experience", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 843, "htmlBody": "<p><strong>Reply to: </strong><a href=\"/lw/57/the_sacred_mundane/\">The Sacred Mundane</a>, <a href=\"/lw/4i/bhtv_yudkowsky_adam_frank_on_religious_experience/\">BHTV: Yudkowsky vs. Frank on \"Religious Experience\"</a></p>\n<p>Edward Crowley was a man of many talents. He studied chemistry at Cambridge - a period to which he later attributed his skeptical scientific outlook - but he soon abandoned the idea of a career in science and turned to his other passions. For a while he played competitive chess at the national level. He took to mountain-climbing, and became one of the early 20th century's premier mountaineers, co-leading the first expedition to attempt K2 in the Himalayas. He also enjoyed writing poetry and travelling the world, making it as far as Nepal and Burma in an era when steamship was still the fastest mode of transportation and British colonialism was still a thin veneer over dangerous and poorly-explored areas.<br /><br />But his real interest was mysticism. He travelled to Sri Lanka, where he studied meditation and yoga under some of the great Hindu yogis. After spending several years there, he achieved a state of mystical attainment the Hindus call <em>dhyana</em>, and set about trying to describe and promote yoga to the West.</p>\n<p>He was not the first person to make the attempt, but he was certainly the most interesting. Although his parents were religious fanatics and his father a fundamentalist preacher, he himself had been an atheist since childhood, and he considered the vast majority of yoga to be superstitious claptrap. He set about eliminating all the gods and chants and taboos and mysterian language, ending up with a short system of what he considered empirically validated principles for gaining enlightenment in the most efficient possible way.</p>\n<p>Reading Crowley's essay on mysticism and yoga at age seventeen rewrote my view of religion. I had always wondered about eastern religions like Buddhism and Hinduism, which seemed to have some underlying truth to all their talk of \"enlightenment\" and \"meditation\" but which seemed too vague and mysterious for my liking. Crowley stripped the mystery away in one fell swoop.</p>\n<p><a id=\"more\"></a></p>\n<p>When listening to Eliezer debate Adam Frank on \"religious experience\", I was disappointed but not surprised to hear just how little they had to say. Even Frank, who was fascinated enough to write a book about it, considered it little more than a sense that something was inspiring or especially impressive. <a href=\"/lw/57/the_sacred_mundane/3jj#comments\">I quoted a bit of Crowley's essay on the thread</a>, and people seemed to like it and want to know more.<br /><br />But I am very reluctant to share, and do so now only after being specifically requested by a few people. You see, I have been trying to paint a sympathetic view of Crowley over the past few paragraphs. With the unsympathetic view you are familiar already. Under his nickname \"Aleister\", he wrote some of history's most influential occultist works. Even in this domain, he held himself to a high rationalist standard, recording that he tested each spell and ritual beforehand and passed on only the ones that actually worked as advertised.<br /><br />...I don't know what that means either. Either he was one of those psychopaths gifted with the ability to lie perfectly and absolutely, or a psychotic genius able to induce hallucinations in himself at will. Crowley himself occasionally endorsed this latter explanation, but after pondering it a while decided he didn't care. The important thing, he wrote, was to determine what techniques produced what results. After that, the philosophers could determine whether they were physical or mentally mediated. Besides, he said, the entities he summoned were so different from himself that if they represented faculties of his mind, they were ones to which he had no conscious access.<br /><br />My point is that I am going to link you to Crowley's essay on mysticism, yoga, and religious experience, and that you might get more out of it if you tried to avoid any bias upon seeing the name \"Aleister Crowley\" on the title page. Yes, I feel properly guilty posting this on a rationalism site, but if we're going to talk about religious experience we might as well listen to the people who have had some.<br /><br />Although it is Less Wrong tradition to rewrite a theory rather than simply link to it, it would be inappropriate in this case. Getting Crowley filtered would be like having someone summarize <em>Godel, Escher Bach</em> to you - you might learn a few things, but you'd lose the chance to enjoy the superb writing. It's a long essay, but not so long you can't read it in one sitting. Even just reading the Preface gives an idea of the theory. Without further ado: <a href=\"http://www.raikoth.net/mysticism.html\"><strong>Crowley on Religious Experience.</strong><br /><br /></a>I post this essay to clarify why I believe three things. First, that both Eliezer and Adam miss the point of religious experience. Second, that <a href=\"/lw/2p/the_skeptics_trilemma/\">certain seemingly supernatural or silly beliefs can be more reasonable than they appear</a> (see for example Crowley's explanation of religious laws on \"virtue\" and \"purity\"). Third, that some mystics'&nbsp; work is of sufficient relevance to rationalists to be worth study.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vhxywjnBH6ioRnnt3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 46, "baseScore": 41, "extendedScore": null, "score": 9.4e-05, "legacy": true, "legacyId": "207", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 89, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Fwt4sDDacko8Sh5iR", "xDroHJ3AzWwJ45ufJ", "M7rwT264CSYY6EdR3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-27T11:32:29.359Z", "modifiedAt": null, "url": null, "title": "Can Humanism Match Religion's Output?", "slug": "can-humanism-match-religion-s-output", "viewCount": null, "lastCommentedAt": "2019-08-19T16:43:05.763Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3fNL2ssfvRzpApvdN/can-humanism-match-religion-s-output", "pageUrlRelative": "/posts/3fNL2ssfvRzpApvdN/can-humanism-match-religion-s-output", "linkUrl": "https://www.lesswrong.com/posts/3fNL2ssfvRzpApvdN/can-humanism-match-religion-s-output", "postedAtFormatted": "Friday, March 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Can%20Humanism%20Match%20Religion's%20Output%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACan%20Humanism%20Match%20Religion's%20Output%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3fNL2ssfvRzpApvdN%2Fcan-humanism-match-religion-s-output%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Can%20Humanism%20Match%20Religion's%20Output%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3fNL2ssfvRzpApvdN%2Fcan-humanism-match-religion-s-output", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3fNL2ssfvRzpApvdN%2Fcan-humanism-match-religion-s-output", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1389, "htmlBody": "<p>Perhaps the single largest <em>voluntary</em> institution of our modern world&mdash;bound together not by police and taxation, not by salaries and managers, but by voluntary donations flowing from its members&mdash;is the Catholic Church.</p>\n<p>It's <a href=\"/lw/5j/your_price_for_joining/\">too large to be held together by individual negotiations</a>, like a group task in a hunter-gatherer band.&nbsp; But in a larger world with more people to be infected and faster transmission, we can expect <a href=\"/lw/u/the_ethic_of_handwashing_and_community_epistemic/\">more virulent memes</a>.&nbsp; The Old Testament doesn't talk about Hell, but the New Testament does.&nbsp; The Catholic Church is <a href=\"/lw/3h/why_our_kind_cant_cooperate\">held together</a> by <a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">affective death spirals</a>&mdash;around the ideas, the institutions, and the leaders.&nbsp; By promises of eternal happiness and eternal damnation&mdash;theologians don't <a href=\"/lw/r/no_really_ive_deceived_myself/\">really believe</a> that stuff, but many ordinary Catholics <a href=\"http://www.overcomingbias.com/2007/08/religions-claim.html\">do</a>.&nbsp; By simple <a href=\"http://www.overcomingbias.com/2007/12/aschs-conformit.html\">conformity</a> of people meeting in person at a Church and being subjected to peer pressure.&nbsp; &amp;c.</p>\n<p>We who have the temerity to call ourselves \"rationalists\", think ourselves <a href=\"/lw/3h/why_our_kind_cant_cooperate\">too good for such communal bindings</a>.</p>\n<p>And so anyone with a <em>simple </em>and <em>obvious</em> charitable project&mdash;responding with food and shelter to a tidal wave in Thailand, say&mdash;would be better off by <em>far</em> pleading with the Pope to mobilize the Catholics, rather than with Richard Dawkins to mobilize the atheists.</p>\n<p><em>For so long as this is true,</em> any increase in atheism at the expense of Catholicism will be something of a hollow victory, regardless of all other benefits.<a id=\"more\"></a></p>\n<p>True, the Catholic Church also goes around opposing the use of condoms in AIDS-ravaged Africa.&nbsp; True, they waste huge amounts of the money they raise on all that religious stuff.&nbsp; Indulging in unclear thinking is not harmless, <a href=\"http://www.reuters.com/article/newsOne/idUSTRE52N63B20090325\">prayer comes with a price</a>.</p>\n<p>To refrain from doing damaging things, <em>is </em>a true victory for a rationalist...</p>\n<p>Unless it is your <em>only</em> victory, in which case it seems a little empty.</p>\n<p>If you <em>discount all harm</em> done by the Catholic Church, and look <em>only</em> at the good... then does the average Catholic do more <em>gross</em> good than the average atheist, just by virtue of being more active?</p>\n<p>Perhaps if you are wiser but less motivated, you can search out interventions of high efficiency and purchase utilons on the cheap...&nbsp; But there are few of us who <em>really</em> do that, as opposed to planning to do it someday.</p>\n<p>Now you might at this point throw up your hands, saying:&nbsp; \"For so long as we don't have direct control over our brain's motivational circuitry, it's not realistic to expect a rationalist to be as strongly motivated as someone who genuinely believes that they'll burn eternally in hell if they don't obey.\"</p>\n<p>This is a fair point.&nbsp; Any folk theorem to the effect that a rational agent should do at least as well as a non-rational agent will rely on the assumption that the rational agent can always just implement whatever \"irrational\" policy is observed to win.&nbsp; But if you can't <em>choose </em>to have unlimited mental energy, then it may be that some false beliefs are, in cold fact, more strongly motivating than any available true beliefs.&nbsp; And if we all generally suffer from altruistic akrasia, being unable to bring ourselves to help as much as we think we should, then it is possible for the God-fearing to win the contest of altruistic output.</p>\n<p>But though it is a <a href=\"http://www.overcomingbias.com/2007/10/motivated-stopp.html\">motivated continuation</a>, let us consider this question a little further.</p>\n<p>Even the fear of hell is not a perfect motivator.&nbsp; Human beings are not given so much slack on evolution's leash; we can resist motivation for a short time, but then we <a href=\"http://en.wikipedia.org/wiki/Ego_depletion\">run out of mental energy</a> (HT: <a href=\"/lw/52/why_i_fail_to_act_rationally/#3tm\">infotropism</a>).&nbsp; Even believing that you'll go to hell does not change this brute fact about brain circuitry.&nbsp; So the religious sin, and then are tormented by thoughts of going to hell, in much the same way that smokers reproach themselves for being unable to quit.</p>\n<p>If a group of rationalists cared <em>a lot</em> about something... who says they wouldn't be able to match the real, de-facto output of a believing Catholic?&nbsp; The stakes might not be \"infinite\" happiness or \"eternal\" damnation, but of course the brain can't visualize <a href=\"http://www.overcomingbias.com/2007/10/pascals-mugging.html\">3^^^3</a>, let alone infinity.&nbsp; Who says that the actual quantity of caring neurotransmitters discharged by the brain (as 'twere) has to be so much less for \"the growth and flowering of humankind\" or even \"tidal-wave-stricken Thais\", than for \"<a href=\"http://www.overcomingbias.com/2008/12/fun-theory.html\">eternal happiness in Heaven</a>\"?&nbsp; Anything involving more than 100 people is going to involve utilities <a href=\"http://www.overcomingbias.com/2007/05/scope_insensiti.html\">too large to visualize</a>.&nbsp; And there are all sorts of <a href=\"http://en.wikipedia.org/wiki/Bystander_effect\">other standard biases</a> at work here; knowing about them might be good for a bonus as well, one hopes?</p>\n<p>Cognitive-behavioral therapy and Zen meditation are two mental disciplines experimentally shown to yield real improvements.&nbsp; It is not the area of the art I've focused on developing, but then I don't have a real <a href=\"/lw/2c/a_sense_that_more_is_possible/\">martial art of rationality</a> in back of me.&nbsp; If you combine a purpose genuinely worth caring about, with discipline extracted from CBT and Zen meditation, then who says rationalists can't keep up?&nbsp; Or even more generally: if we have an evidence-based art of fighting akrasia, with experiments to see what actually works, then who says we've got to be less motivated than some disorganized mind that fears God's wrath?</p>\n<p>Still... that's a further-future speculation that it might be possible to develop an art that doesn't presently exist.&nbsp; It's not a technique I can use right now.&nbsp; I present it just to illustrate the idea of <em>not giving up so fast on rationality:</em>&nbsp; Understanding what's going wrong, trying intelligently to fix it, and gathering evidence on whether it worked&mdash;this is a powerful idiom, not to be lightly dismissed upon sighting the first disadvantage.</p>\n<p>Really, I suspect that what's going on here has less to do with the motivating power of eternal damnation, and a lot more to do with the motivating power of <em>physically meeting</em> other people who share your cause.&nbsp; The power, in other words, of being physically present at church and having religious neighbors.</p>\n<p>This is a problem for the rationalist community in its present stage of growth, because we are rare and geographically distributed way the hell all over the place.&nbsp; If all the readers of this blog lived within a 5-mile radius of each other, I bet we'd get a lot more done, not for reasons of <em>coordination </em>but just sheer <em>motivation.</em></p>\n<p>I'll post tomorrow about some long-term, starry-eyed, idealistic thoughts on this particular problem.&nbsp; Shorter-term solutions that don't rely on our increasing our numbers by a factor of 100 would be better.&nbsp; I wonder in particular whether the best modern videoconferencing software would provide some of the motivating effect of meeting someone in person; I suspect the answer is \"no\" but it might be worth trying.</p>\n<p>Meanwhile... in the short-term, we're stuck fighting akrasia mostly without the reinforcing physical presense of other people who care.&nbsp; I want to say something like \"This is difficult, but it <em>can </em>be done\" except I'm not sure that's even true.</p>\n<p>I suspect that the <em>largest</em> step rationalists could take toward matching the per-capita power output of the Catholic Church would be to have regular physical meetings of people contributing to the same task&mdash;not for purposes of coordination, just for purposes of of motivation.</p>\n<p>In the absence of that...</p>\n<p>We could try for a group norm of being openly allowed&mdash;nay, applauded&mdash;for caring strongly about something.&nbsp; And a group norm of being expected to do something useful with your life&mdash;contribute your part to <a href=\"http://www.overcomingbias.com/2009/02/interlude-with-the-confessor.html\">cleaning up this world</a>.&nbsp; Religion doesn't really emphasize the getting-things-<em>done</em> aspect as much.</p>\n<p>And if rationalists could match just <em>half</em> the average altruistic effort output per Catholic, then I don't think it's <em>remotely</em> unrealistic to suppose that with better targeting on more efficient causes, the modal rationalist could get twice as much done.</p>\n<p>How much of its earnings does the Catholic Church spend on all that useless religious stuff instead of actually helping people?&nbsp; More than 50%, I would venture.&nbsp; So then we could say&mdash;with a certain irony, though that's not quite the spirit in which we should be doing things&mdash;that we should try to propagate a group norm of donating a minimum of 5% of income to <em>real</em> causes.&nbsp; (10% being the usual suggested minimum religious tithe.)&nbsp; And then there's the art of picking causes for which expected utilons are orders of magnitude cheaper (for so long as the inefficient market in utilons lasts).</p>\n<p>But long before we can begin to dream of any such boast, we secular humanists need to work on at least <em>matching</em> the per capita benevolent output of the worshippers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"r7qAjcbfhj2256EHH": 1, "iP2X4jQNHMWHRNPne": 1, "fkABsGCJZ6y9qConW": 1, "izp6eeJJEg9v5zcur": 1, "NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3fNL2ssfvRzpApvdN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 73, "baseScore": 72, "extendedScore": null, "score": 0.00011, "legacy": true, "legacyId": "209", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "church-vs-taskforce", "canonicalPrevPostSlug": "your-price-for-joining", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 72, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Q8evewZW5SeidLdbA", "ZP2om2oWHPhvWP2Q3", "7FzD7pNm9X68Gp5ZC", "rZX4WuufAPbN6wQTv", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-27T17:11:52.039Z", "modifiedAt": null, "url": null, "title": "On Seeking a Shortening of the Way", "slug": "on-seeking-a-shortening-of-the-way", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:06.151Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Annoyance", "createdAt": "2009-02-28T04:06:40.600Z", "isAdmin": false, "displayName": "Annoyance"}, "userId": "yEm6LWatswJYGwBFq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AvTmLRperBRXyeqL9/on-seeking-a-shortening-of-the-way", "pageUrlRelative": "/posts/AvTmLRperBRXyeqL9/on-seeking-a-shortening-of-the-way", "linkUrl": "https://www.lesswrong.com/posts/AvTmLRperBRXyeqL9/on-seeking-a-shortening-of-the-way", "postedAtFormatted": "Friday, March 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Seeking%20a%20Shortening%20of%20the%20Way&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Seeking%20a%20Shortening%20of%20the%20Way%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAvTmLRperBRXyeqL9%2Fon-seeking-a-shortening-of-the-way%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Seeking%20a%20Shortening%20of%20the%20Way%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAvTmLRperBRXyeqL9%2Fon-seeking-a-shortening-of-the-way", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAvTmLRperBRXyeqL9%2Fon-seeking-a-shortening-of-the-way", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 317, "htmlBody": "<p><strong>\"The most instructive experiences are those of everyday life.\"&nbsp; - Friedrich Nietzsche</strong></p>\n<p>What is it that the readers of lesswrong are looking for?&nbsp; One claim that's been repeated frequently is that we're looking for rationality tricks, shortcuts and clever methods for being rational.&nbsp; Problem is:&nbsp; there aren't any.</p>\n<p>People generally want novelty and gimmicks.&nbsp; They're exciting and interesting!&nbsp; Useful advice tends to be dull, tedious, and familiar.&nbsp; We've heard it all before, and it sounded like a lot of hard work and self-discipline.&nbsp; If we want to lose weight, we don't do the sensible and quite difficult thing and eat a balanced diet while increasing our levels of exercise.&nbsp; We try fad diets and eat nothing but grapefruits for a week, or we gorge ourselves on meats and abhor carbohydrates so that our metabolisms malfunction.&nbsp; We lose weight that way, so clearly it's just as good as exercising and eating properly, right?</p>\n<p>We cite Zen stories but don't take the time and effort to research their contexts, while at the same time sniggering a the actual beliefs inherent in that system.&nbsp; We wax rhapsodic about psychedelics and dismiss the value of everyday experiences as trivial - and handwave away praise of the mundane as utilization of \"applause lights\".</p>\n<p>We talk about the importance of being rational, but don't determine what's necessary to do to become so.</p>\n<p>Some of the greatest thinkers of the past had profound insights after paying attention to parts of everyday life that most people don't give a second thought.&nbsp; Archimedes realized how to determine the volume of a complex solid while lounging in a bath.&nbsp; Galileo recognized that pendulums could be used to reliably measure time while letting his mind drift in a cathedral.</p>\n<p>Sure, we're not geniuses, so why try to pay attention to ordinary things?&nbsp; Shouldn't we concern ourselves with the novel and extraordinary instead?</p>\n<p>Maybe we're not geniuses <em>because</em> we don't bother paying attention to ordinary things.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "a3W2TSzPuxKr3Hm9j": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AvTmLRperBRXyeqL9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 12, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "215", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-27T22:24:58.196Z", "modifiedAt": null, "url": null, "title": "Altruist Coordination -- Central Station", "slug": "altruist-coordination-central-station", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:17.890Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S38KtkKeotQrepR8G/altruist-coordination-central-station", "pageUrlRelative": "/posts/S38KtkKeotQrepR8G/altruist-coordination-central-station", "linkUrl": "https://www.lesswrong.com/posts/S38KtkKeotQrepR8G/altruist-coordination-central-station", "postedAtFormatted": "Friday, March 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Altruist%20Coordination%20--%20Central%20Station&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAltruist%20Coordination%20--%20Central%20Station%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS38KtkKeotQrepR8G%2Faltruist-coordination-central-station%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Altruist%20Coordination%20--%20Central%20Station%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS38KtkKeotQrepR8G%2Faltruist-coordination-central-station", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS38KtkKeotQrepR8G%2Faltruist-coordination-central-station", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/5t/can_humanism_match_religions_output/\">Can Humanism Match Religion's Output?</a></p>\n<p>I thought it would be helpful for us to have a central space to pool information about various organizations to which we might give our money and/or time.&nbsp; Honestly, a wiki would be ideal, but it seems this should do nicely.</p>\n<p>Comment to this post with the name of an organization, and a direct link to where we can donate to them.&nbsp; Provide a summary of the group's goals, and their plans for reaching them.&nbsp; If you can link to outside confirmation of the group's efficiency and effectiveness, please do so.</p>\n<p>Respond to these comments adding information about the named group, whether to criticize or praise it.</p>\n<p>Hopefully with the voting system, we should be able to collect the most relevent information we have available reasonably quickly.</p>\n<p>If you choose to contribute to a group, respond to that group's comment with a dollar amount, so that we can all see how much we have raised for each organization.</p>\n<p>Feel free to replace \"dollar amount\" with \"dollar amount/month\" in the above, if you wish to make such a commitment.&nbsp; Please do not do this unless you are (&gt;95%) confident that said commitment will last <em>at least</em> a year.</p>\n<p>If possible, mention this page, or this site, while donating.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qAvbtzdG2A2RBn7in": 1, "izp6eeJJEg9v5zcur": 1, "xexCWMyds6QLWognu": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S38KtkKeotQrepR8G", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 7, "extendedScore": null, "score": 4.840168242420977e-07, "legacy": true, "legacyId": "216", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3fNL2ssfvRzpApvdN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-27T22:35:38.661Z", "modifiedAt": null, "url": null, "title": "Less Wrong Facebook Page", "slug": "less-wrong-facebook-page", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:37.789Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tSsQzfwSxSpmKTAWJ/less-wrong-facebook-page", "pageUrlRelative": "/posts/tSsQzfwSxSpmKTAWJ/less-wrong-facebook-page", "linkUrl": "https://www.lesswrong.com/posts/tSsQzfwSxSpmKTAWJ/less-wrong-facebook-page", "postedAtFormatted": "Friday, March 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20Facebook%20Page&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20Facebook%20Page%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtSsQzfwSxSpmKTAWJ%2Fless-wrong-facebook-page%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20Facebook%20Page%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtSsQzfwSxSpmKTAWJ%2Fless-wrong-facebook-page", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtSsQzfwSxSpmKTAWJ%2Fless-wrong-facebook-page", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 26, "htmlBody": "<p>At Tom Talbot's <a href=\"/lw/5t/can_humanism_match_religions_output/3xe#comments\">suggestion</a>, I have created <a href=\"http://www.facebook.com/group.php?sid=094b5ee033c0e3746a894039446e0524&amp;gid=144017955332\">a Less Wrong Facebook group</a>, in hopes that being able to see one another's faces will improve group bonding.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tSsQzfwSxSpmKTAWJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 10, "extendedScore": null, "score": 4.840183773308035e-07, "legacy": true, "legacyId": "217", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-28T02:27:57.531Z", "modifiedAt": null, "url": null, "title": "The Hidden Origins of Ideas", "slug": "the-hidden-origins-of-ideas", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:13.551Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cleonid", "createdAt": "2009-03-05T01:26:41.015Z", "isAdmin": false, "displayName": "cleonid"}, "userId": "Dh7Ax8Qp8bzp4xZBP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DxBHRkpkTZuAxBE66/the-hidden-origins-of-ideas", "pageUrlRelative": "/posts/DxBHRkpkTZuAxBE66/the-hidden-origins-of-ideas", "linkUrl": "https://www.lesswrong.com/posts/DxBHRkpkTZuAxBE66/the-hidden-origins-of-ideas", "postedAtFormatted": "Saturday, March 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Hidden%20Origins%20of%20Ideas&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Hidden%20Origins%20of%20Ideas%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxBHRkpkTZuAxBE66%2Fthe-hidden-origins-of-ideas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Hidden%20Origins%20of%20Ideas%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxBHRkpkTZuAxBE66%2Fthe-hidden-origins-of-ideas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxBHRkpkTZuAxBE66%2Fthe-hidden-origins-of-ideas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 299, "htmlBody": "<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\">&nbsp;</p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\">It is well known that people tend to inherit their world view toghether with their genes.<span style=\"mso-spacerun: yes;\">&nbsp; </span>Buddhists are born to the Buddhists, Muslims are born to the Muslims and Republicans are born to the Republicans. While rejecting Predestination,<span style=\"mso-tab-count: 1;\">&nbsp;</span>a XVI century catholic could be fairly certain that, unlike hell-bound pagans in the Amazonian forests, most of his descendants would also be catholics.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\">Naturally independent minds can occasionally break with the tradition. A catholic, finding the Pope&rsquo;s stance on Predestination inconsistent with the Scriptures, might turn to Protestantism. </span><span style=\"font-family: Times New Roman;\">Hence, the invention of the printing press that made Bibles widely available may have been the root cause of the Reformation. Similarly, the spread of literacy to the lower classes may have eroded the influence of the church and popularized the secular ideologies, such as Marxism. </span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\">But could it be that when we break with the traditional mode of thinking, we are driven not by superior intellects or newly acquired knowledge, but rather by something we are not even aware of? Let&rsquo;s take as an example the spread of seemingly unrelated ideologies of Protestantism and Marxism.</p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\">&nbsp;<img src=\"http://images.lesswrong.com/t3_5y_1.png?v=96434f05823a98ff1b239aa803df87b6\" alt=\"\" width=\"604\" height=\"212\" /></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\">&nbsp;</p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\">From left to right: </span><span style=\"font-family: Times New Roman;\">The european countries painted blue are those with Germanic majority, those with large numbers of protestants (&gt;45% of all believers), and those where communists electoral vote failed to rise above 10% within the last 60 years. </span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\">While the maps are not identical, there seems to be a strong correlation between peoples&rsquo; ethnic origins, their religious histories and the openness to the communist ideas. </span><span style=\"font-family: Times New Roman;\">Of course, correlation does not imply causation. However, strong correlation between our views and those of people with a similar background, may suggest that factors other than logic are responsible for them. Unless,&nbsp;as in my case, a similar background means smarter/ more virtuous/ more rational/ getting secret revelations from Omega/&hellip; (circle the right answer).</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"x5TtBDjRg9egvg9gm": 1, "gHCNhqxuJq2bZ2akb": 1, "5f5c37ee1b5cdee568cfb124": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DxBHRkpkTZuAxBE66", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 5, "extendedScore": null, "score": 4.840520322864654e-07, "legacy": true, "legacyId": "214", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-28T02:31:18.306Z", "modifiedAt": null, "url": null, "title": "Defense Against The Dark Arts: Case Study #1", "slug": "defense-against-the-dark-arts-case-study-1", "viewCount": null, "lastCommentedAt": "2020-03-03T14:36:45.040Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p7WXmG6Fbo3eaSwm3/defense-against-the-dark-arts-case-study-1", "pageUrlRelative": "/posts/p7WXmG6Fbo3eaSwm3/defense-against-the-dark-arts-case-study-1", "linkUrl": "https://www.lesswrong.com/posts/p7WXmG6Fbo3eaSwm3/defense-against-the-dark-arts-case-study-1", "postedAtFormatted": "Saturday, March 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Defense%20Against%20The%20Dark%20Arts%3A%20Case%20Study%20%231&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADefense%20Against%20The%20Dark%20Arts%3A%20Case%20Study%20%231%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7WXmG6Fbo3eaSwm3%2Fdefense-against-the-dark-arts-case-study-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Defense%20Against%20The%20Dark%20Arts%3A%20Case%20Study%20%231%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7WXmG6Fbo3eaSwm3%2Fdefense-against-the-dark-arts-case-study-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7WXmG6Fbo3eaSwm3%2Fdefense-against-the-dark-arts-case-study-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1866, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/48/the_power_of_positivist_thinking/\">The Power of Positivist Thinking</a>, <a href=\"/lw/5z/on_seeking_a_shortening_of_the_way/\">On Seeking a Shortening of the Way</a>, <a href=\"/lw/5r/crowley_on_religious_experience/\">Crowley on Religious Experience</a></p>\n<p>Annoyance <a href=\"/lw/5z/on_seeking_a_shortening_of_the_way/\">wants us to stop talking about fancy techniques</a> and get back to basics. <a href=\"/lw/57/the_sacred_mundane/3l4#comments\">I disagree with the philosophy</a> behind his statement, but the principle is sound. In many areas of life - I'm thinking mostly of sports, but not for lack of alternatives - mastery of the basics beats poorly-grounded fancy techniques every time.<br /><br />One basic of rationality is paying close attention to an argument. Dissecting it to avoid rhetorical tricks, hidden fallacies, and other Dark Arts.&nbsp; I've been working on this for years, and I still fall short on a regular basis.<br /><br />Medical educators have started emphasizing case studies in their curricula. Instead of studying arcane principles of disease, student doctors cooperate to analyze a particular patient in detail, ennumerate the principles needed to diagnose her illness, and pay special attention to any errors the patients' doctors made during the treatment. The cases may be rare tropical infections, but they're more often the same everyday diseases common in the general population, forcing the student doctors to always keep the basics in mind. We could do with a tradition of case studies in rationality, though we'd need safeguards to prevent degeneration into political discussion.<br /><br />Case studies in medicine are most interesting when all the student doctors disagree with each other. To that end, I've chosen as the first case <a href=\"/lw/5r/crowley_on_religious_experience/3tu#comments\">a statement that received sixteen upvotes on Less Wrong</a>, maybe the highest I've ever seen for a comment. I don't mean to insult or embarass everyone who liked it. I liked it too. My cursor was already hovering above the \"Vote Up\" button by the time I starting having second thoughts. But it deserves dissection, and its popularity gives me a ready response when someone says this material is too basic for 'master rationalists' like ourselves:</p>\n<blockquote>\n<p>In his youth, Steve Jobs went to India to be enlightened. After seeing that the nation claiming to be the source of this great spiritual knowledge was full of hunger, ignorance, squalor, poverty, prejudice, and disease, he came back and said that the East should look to the West for enlightenment.</p>\n</blockquote>\n<p>This anecdote is short, witty, flattering, and utterly opaque to reason. It bears all the hallmarks of the Dark Arts.</p>\n<p><a id=\"more\"></a><br />I admit I am not a disinterested party here. The statement was in response to my claim that Indian yoga was a successful technique for inducing exotic and occasionally useful mental states. I don't like being told I'm wrong any more than anyone else does. But here I don't think I am. I see at least five fallacies.<br /><br /><strong>First</strong>, a hidden assumption: if A is superior to B, A cannot learn anything from B. This assumption is clearly false. I know brilliant scientists whose spelling is atrocious. I acknowledge that these people are much smarter than I am, but I still correct their spelling. Anyone who said \"Dr. A should not be learning spelling from Yvain, Yvain should be learning science from Dr. A\" would be missing the point. If Dr. A wants to learn spelling, he might as well learn it from me. And best of all if we both learn from each other!<br /><br />A related fallacy would be that Dr. A is so much smarter than the rest of us that he should not care about spelling. But if spelling is important to his work (perhaps he's writing a journal article) he needs to do everything he can to perfect it. If he could spell correctly, he would be even further ahead of the rest of us than he already is. The goal isn't to become a bit better than your peers and then rest on your laurels. The goal is to become as skilled as necessary.<br /><br />The error is an interesting variant of <a href=\"http://www.google.ie/url?sa=t&amp;source=web&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F2007%2F11%2Fhalo-effect.html&amp;ei=O4jNSauUIOaQjAfKo7X1CQ&amp;usg=AFQjCNGun9Q2FC9LM-1W_wP-uSuunp_pdg&amp;sig2=TL_HWqn6IoW6m-Ee0p3sMg\">the halo effect</a>: that anyone superior at most things must be superior at all things.<br /><br /><strong>Second</strong>, the statement assumes that India is a single monolithic entity with or without spiritual wisdom. But even the most gushing Orientalist would not study at the feet of a call-centre worker in Bangalore. Whatever spiritual wisdom may exist in India, it will be believed by a small fraction of Indian religions, be practiced by a small fraction of the believers, and be mastered by a small number of the practioners. And if Crowley is to be believed, it will be <em>understood</em> by a small fraction of the masters.<br /><br />Compare the question: if America is so good at science, why does it have so many creationists? Well, because the people who are good at science aren't the same ones believing in creationism, that's why. And the people who are good at science don't have enough power in society to do anything about the creationism issue. This does not reflect poorly on the truth-value of scientific theories discovered by Americans.<br /><br />I'm not one of those fallacy classification nuts, but for completeness' sake, this is a <a href=\"http://en.wikipedia.org/wiki/Fallacy_of_composition\">fallacy of composition</a>.<br /><br /><strong>Third</strong>, the statement assumes that spiritual wisdom makes people less poor and squalid. The converse of this statement certainly isn't true - being rich and sanitary doesn't give you any spiritual value, as large segments of western civilization have spent the past three hundred years amply demonstrating. People commonly interpret spiritual wisdom as conferring a disdain for material goods. So we wouldn't necessarily expect to see a lot of material well-being in a spiritually wise society.<br /><br />Part of this is a problem with the definition of \"spiritual wisdom\". It can mean anything from \"being a moral person who cares about others\" to \"being wise and able to make good decisions\" to \"having mastery of certain mental techniques that produce awe-inspiring experiences\" Under the first and second definition, a spiritually attained country should be a nice place to live. Under the third definition, not so much. Crowley endorses the third definition, and believes that most spiritually wise people dismiss the mundane world as unworthy of their attention anyway. But this contradicts our usual intuitions about \"spirituality\" and \"wisdom\".<br /><br />This is a <a href=\"http://www.google.ie/url?sa=t&amp;source=web&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F2008%2F03%2Fwrong-words.html&amp;ei=1ofNSYCTJYOrjAeu_-zcCQ&amp;usg=AFQjCNEt3EvAEw363Q21WYVvATxod6ri0A&amp;sig2=_13grmsTafWrwO5csYXUwQ\">failure of definition</a>, and it's why I prefer \"high level of mystical attainment\" to \"spiritually wise\" when discussing Crowley's theories.<br /><br /><strong>Fourth</strong>, this is hardly a controlled experiment. India is historically, geographically, racially, religiously, climatologically, and culturally different from the West. Attributing a certain failure to religious causes alone is highly dubious. In fact, when we think about it for a while, cramming a billion plus people into a sweltering malarial flood plain, dividing them evenly between two religions that hate each other's guts, then splitting off the northwest corner and turning it into a large populous nuclear-armed arch-enemy that declares war on them every couple of decades is probably not a recipe for success no matter what your spirituality. All we can say for certain is that India's spirituality is not sufficiently wonderful to overcome its other disadvantages.<br /><br />People who like Latin call this <a href=\"http://en.wikipedia.org/wiki/Cum_hoc_ergo_propter_hoc\">cum hoc ergo propter hoc</a>.<br /><br /><strong>Fifth</strong>, this equivocates the heck out of the word \"enlightenment\". Compare \"enlightenment\" meaning the set of rational values associated with Newton, Descartes, and Hume, to \"enlightenment\", meaning gaining important knowledge, to \"enlightenment\", meaning achieving a state of nirvana free from worldly desire. The West is the acknowledged master of the first definition, and India the acknowledged master of the third definition. The anecdote's claim seems to be that since the West is the acknowledged master of the first type of enlightenment, and could teach India some useful things about politics and economics in the second sense of enlightenment, India can't teach the West about the third sense of enlightenment...which would make sense, if the types of enlightenment were at all related instead of being three different things called by the same name.<br /><br />This is a <a href=\"http://en.wikipedia.org/wiki/Fallacy_of_equivocation\">fallacy of equivocation</a>.<br /><br />Just because I can point out a few fallacies in a statement doesn't make it worthless. Spiritual wisdom doesn't always correlate with decent living conditions, but the lack of decent living conditions is some evidence against the presence of spiritual wisdom. Likewise, a country's success or failure doesn't always depend on its religion, but religion <em>is</em> one of many contributing factors that does make a difference.<br /><br />Still, five fallacies is a lot for a two sentence anecdote.<br /><br />I don't think we all liked this anecdote so much because of whatever tiny core of usefulness managed to withstand those five fallacies. I think we liked it because it makes a good way to shut up hippies.<br /><br />Hippies are always going on about how superior India is to the West in every way because of its \"spirituality\" and such, and how many problems are caused by \"spiritually bankrupt\" Western science. And here we are, people who quite like Western science, rolling our eyes at how stupid the hippie is being. Doesn't she realize that Western science gives her all of the comforts that make her life bearable, from drinkable water to lice-free clothing? And this anecdote - it strikes a blow for our team. It makes us feel good. We don't need to look to India for enlightenment! India should look to us! Take that, hippie!<br /><br />But <a href=\"http://www.google.ie/url?sa=t&amp;source=web&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F2007%2F12%2Freversed-stupid.html&amp;ei=VYfNSfzTHpqQjAfi4aDcCQ&amp;usg=AFQjCNHJvGXG_0sbMdpJ7ZIujFYtcoBdRQ&amp;sig2=dBubR7TkQl7_QBkU4BBKpQ\">reversed stupidity is not intelligence</a>. Just because the hippie is wrong about India, doesn't mean we have to be wrong in the opposite direction. It might be useful to share it with this hypothetical hippie, just to start her thinking. But it's not something we can seriously endorse.<br /><br />Nor do I accept the defense that it was not specifically posted with the conclusion \"Therefore, ignore Crowley's views on yoga.\" Merely placing it directly below an article on enlightenment from India is a declaration of war and a hijack attempt on the train of thought. Saying \"I hear people of African descent have a higher violent crime rate\" is not a neutral act when spoken right before a job interview with a black person.<br /><br />Defense Against the Dark Arts needs to become total and automatic, because it is the foundation upon which the complicated rationalist techniques are built. There's no point studying some complex Bayesian evidence-summing manuever that could determine the expected utility of studying yoga if an anecdote about Steve Jobs can keep you from even considering it.<br /><br />How do you know you have mastered this art? When the statements</p>\n<blockquote>\n<p>In his youth, Steve Jobs went to India to be enlightened. After seeing that the nation claiming to be the source of this great spiritual knowledge was full of hunger, ignorance, squalor, poverty, prejudice, and disease, he came back and said that the East should look to the West for enlightenment.</p>\n</blockquote>\n<p>and</p>\n<blockquote>\n<p>For complex historical reasons, the average Westerner is richer than the average Indian. Therefore, there is minimal possibility that any Indian people ever discovered interesting mental techniques.</p>\n</blockquote>\n<p>sound <em>exactly alike</em>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XYHzLjwYiqpeqaf4c": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p7WXmG6Fbo3eaSwm3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 137, "baseScore": 133, "extendedScore": null, "score": 0.000203, "legacy": true, "legacyId": "218", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 133, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["azoP7WeKYYfgCozoh", "AvTmLRperBRXyeqL9", "vhxywjnBH6ioRnnt3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-28T09:23:25.560Z", "modifiedAt": null, "url": null, "title": "Church vs. Taskforce", "slug": "church-vs-taskforce", "viewCount": null, "lastCommentedAt": "2022-05-31T15:20:35.939Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p5DmraxDmhvMoZx8J/church-vs-taskforce", "pageUrlRelative": "/posts/p5DmraxDmhvMoZx8J/church-vs-taskforce", "linkUrl": "https://www.lesswrong.com/posts/p5DmraxDmhvMoZx8J/church-vs-taskforce", "postedAtFormatted": "Saturday, March 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Church%20vs.%20Taskforce&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AChurch%20vs.%20Taskforce%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5DmraxDmhvMoZx8J%2Fchurch-vs-taskforce%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Church%20vs.%20Taskforce%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5DmraxDmhvMoZx8J%2Fchurch-vs-taskforce", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5DmraxDmhvMoZx8J%2Fchurch-vs-taskforce", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1450, "htmlBody": "<p>I am generally suspicious of <a href=\"/lw/3h/why_our_kind_cant_cooperate\">envying crazy groups</a> or trying to <a href=\"http://www.overcomingbias.com/2008/03/is-humanism-rel.html\">blindly copycat the rhythm of religion</a>&mdash;what I called \"hymns to the nonexistence of God\", replying, \"A good 'atheistic hymn' is simply a song about anything worth singing about that doesn't happen to be religious.\"</p>\n<p>But religion does fill certain holes in people's minds, some of which are even worth filling.&nbsp; If you eliminate religion, you have to be aware of what gaps are left behind.</p>\n<p>If you suddenly deleted religion from the world, the largest gap left would not be anything of ideals or morals; it would be the church, the community.&nbsp; Among those who now stay religious without quite really believing in God&mdash;how many are just sticking to it from wanting to stay with their neighbors at the church, and their family and friends?&nbsp; How many would convert to atheism, if all those others deconverted, and <em>that</em> were the price of staying in the community and keeping its respect?&nbsp; I would guess... probably quite a lot.</p>\n<p>In truth... this is probably something I don't understand all that well, myself.&nbsp; \"Brownies and babysitting\" were the first two things that came to mind.&nbsp; Do churches lend helping hands in emergencies?&nbsp; Or just a shoulder to cry on?&nbsp; How strong is a church community?&nbsp; It probably depends on the church, and in any case, that's not the correct question.&nbsp; One should start by considering what a hunter-gatherer band gives its people, and ask what's missing in modern life&mdash;if a modern First World church fills only <em>some</em> of that, then by all means let us try to do <em>better</em>.</p>\n<p>So <em>without</em> copycatting religion&mdash;<em>without</em> assuming that we <em>must </em>gather every Sunday morning in a building with stained-glass windows while the children dress up in formal clothes and listen to someone sing&mdash;let's consider how to fill the emotional gap, after religion stops being an option.<a id=\"more\"></a></p>\n<p>To help break the mold to start with&mdash;the straitjacket of <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">cached thoughts</a> on how to do this sort of thing&mdash;consider that <em>some</em> modern offices may also fill the same role as a church.&nbsp; By which I mean that some people are fortunate to receive community from their workplaces: friendly coworkers who bake brownies for the office, whose teenagers can be safely hired for babysitting, and maybe even help in times of catastrophe...?&nbsp; But certainly not everyone is lucky enough to find a community at the office.</p>\n<p>Consider further&mdash;a church is <em>ostensibly</em> about worship, and a workplace is <em>ostensibly</em> about the commercial purpose of the organization.&nbsp; Neither has been carefully <em>optimized</em> to serve as a community.</p>\n<p>Looking at a typical religious church, for example, you could suspect&mdash;although all of these things would be better tested experimentally, than just suspected&mdash;</p>\n<ul>\n<li>That getting up early on a Sunday morning is not optimal;</li>\n<li>That wearing formal clothes is not optimal, especially for children;</li>\n<li>That listening to the same person give sermons on the same theme every week (\"religion\") is not optimal;</li>\n<li>That the cost of supporting a church and a pastor is expensive, compared to the number of different communities who could time-share the same building for their gatherings;</li>\n<li>That they probably don't serve <a href=\"http://www.marginalrevolution.com/marginalrevolution/2005/05/why_dont_people.html\">nearly enough</a> of a matchmaking purpose, because churches think they're supposed to enforce their medieval moralities;</li>\n<li>That the whole thing ought to be subject to experimental data-gathering to find out what works and what doesn't.</li>\n</ul>\n<p>By using the word \"optimal\" above, I mean \"optimal under the criteria you would use if you were explicitly building a community <em>qua</em> community\".&nbsp; Spending lots of money on a fancy church with stained-glass windows and a full-time pastor makes sense if you actually <em>want</em> to spend money on religion <em>qua</em> religion.</p>\n<p>I do confess that when walking past the churches of my city, my main thought is \"These buildings look really, really expensive, and there are too many of them.\"&nbsp; If you were doing it over from scratch... then you might have a big building that could be used for the occasional wedding, but it would be time-shared for different communities meeting at different times on the weekend, and it would also have a nice large video display that could be used for speakers giving presentations, lecturers teaching something, or maybe even showing movies.&nbsp; Stained glass?&nbsp; Not so high a priority.</p>\n<p>Or to the extent that the church membership lends a helping hand in times of trouble&mdash;could that be improved by an explicit rainy-day fund or contracting with an insurer, once you realized that this was an important function?&nbsp; Possibly <em>not;</em> dragging explicit finance into things changes their character oddly.&nbsp; Conversely, maybe keeping current on some insurance policies should be a <em>requirement</em> for membership, lest you rely <em>too much</em> on the community...&nbsp; But again, to the extent that churches provide community, they're trying to do it without actually <em>admitting</em> that this nearly all of what people get out of it.&nbsp; Same thing with the corporations whose workplaces are friendly enough to serve as communities; it's still something of an accidental function.</p>\n<p>Once you start thinking <em>explicitly </em>about how to give people a hunter-gatherer band to belong to, you can see all sorts of things that sound like good ideas.&nbsp; Should you welcome the newcomer in your midst?&nbsp; The pastor may give a sermon on that sometime, if you think church is about religion.&nbsp; But if you're explicitly setting out to build community&mdash;then right after a move is when someone most lacks community, when they most need your help.&nbsp; It's also an opportunity for the band to grow.&nbsp; If anything, tribes ought to be competing at quarterly exhibitions to capture newcomers.</p>\n<p>But can you really have a community that's <em>just</em> a community&mdash;that isn't also an office or a religion?&nbsp; A community with no purpose beyond itself?</p>\n<p>Maybe you <em>can.</em>&nbsp; After all, hunter-gatherer tribes have any purposes beyond themselves?&mdash;well, there was survival and feeding yourselves, that was a purpose.</p>\n<p>But anything that people have in common, especially any <em>goal</em> they have in common, tends to <em>want</em> to define a community.&nbsp; Why not take advantage of that?</p>\n<p>Though in this age of the Internet, alas, too many binding factors have supporters too widely distributed to form a decent band&mdash;if you're the only member of the Church of the Subgenius in your city, it may not really help much.&nbsp; It really is different without the physical presence; the Internet does <em>not</em> seem to be an acceptable substitute at the current stage of the technology.</p>\n<p>So to skip right to the point&mdash;</p>\n<p>Should the Earth last so long, I would like to see, as the form of rationalist communities, taskforces focused on <a href=\"http://www.overcomingbias.com/2009/02/interlude-with-the-confessor.html\">all the work that needs doing to fix up this world</a>.&nbsp; Communities in any geographic area would form around the most specific cluster that could support a decent-sized band.&nbsp; If your city doesn't have enough people in it for you to find 50 fellow Linux programmers, you might have to settle for 15 fellow open-source programmers... or in the days when all of this is only getting started, 15 fellow rationalists trying to spruce up the Earth in their assorted ways.</p>\n<p>That's what I think would be a fitting direction for the energies of communities, and a common purpose that would bind them together.&nbsp; Tasks like that need communities anyway, and this Earth has plenty of work that needs doing, so there's no point in waste.&nbsp; We have so much that needs doing&mdash;let the energy that was once wasted into the void of religious institutions, find an outlet there.&nbsp; And let purposes <a href=\"/lw/57/the_sacred_mundane/\">admirable without need for delusion</a>, fill any void in the community structure left by deleting religion and its illusionary <a href=\"http://www.overcomingbias.com/2009/01/higher-purpose.html\">higher purposes</a>.</p>\n<p>Strong communities built around worthwhile purposes:&nbsp; That would be the shape I would like to see for the post-religious age, or whatever fraction of humanity has then gotten so far in their lives.</p>\n<p>Although... as long as you've got a building with a nice large high-resolution screen anyway, I wouldn't mind challenging the idea that all post-adulthood learning has to take place in distant expensive university campuses with teachers who would rather be doing something else.&nbsp; And it's empirically the case that colleges seem to support communities quite well.&nbsp; So in all fairness, there are other possibilities for things you could build a post-theistic community around.</p>\n<p>Is all of this just a dream?&nbsp; Maybe.&nbsp; Probably.&nbsp; It's not completely devoid of incremental implementability, if you've got enough rationalists in a sufficiently large city who have heard of the idea.&nbsp; But on the off-chance that rationality should catch on so widely, or the Earth should last so long, and that my voice should be heard, then that is the direction I would like to see things moving in&mdash;as the churches fade, we don't need artificial churches, but we do need new idioms of community.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "NSMKfa8emSbGNXRKD": 1, "xexCWMyds6QLWognu": 1, "zv7v2ziqexSn5iS9v": 1, "AHK82ypfxF45rqh9D": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p5DmraxDmhvMoZx8J", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 65, "baseScore": 68, "extendedScore": null, "score": 0.000102, "legacy": true, "legacyId": "211", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "rationality-common-interest-of-many-causes", "canonicalPrevPostSlug": "can-humanism-match-religion-s-output", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 68, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 88, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7FzD7pNm9X68Gp5ZC", "Fwt4sDDacko8Sh5iR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-28T16:15:15.367Z", "modifiedAt": null, "url": null, "title": "When It's Not Right to be Rational", "slug": "when-it-s-not-right-to-be-rational", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:16.151Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Annoyance", "createdAt": "2009-02-28T04:06:40.600Z", "isAdmin": false, "displayName": "Annoyance"}, "userId": "yEm6LWatswJYGwBFq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aeWRzgJMt2ASQHHiw/when-it-s-not-right-to-be-rational", "pageUrlRelative": "/posts/aeWRzgJMt2ASQHHiw/when-it-s-not-right-to-be-rational", "linkUrl": "https://www.lesswrong.com/posts/aeWRzgJMt2ASQHHiw/when-it-s-not-right-to-be-rational", "postedAtFormatted": "Saturday, March 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20When%20It's%20Not%20Right%20to%20be%20Rational&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhen%20It's%20Not%20Right%20to%20be%20Rational%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaeWRzgJMt2ASQHHiw%2Fwhen-it-s-not-right-to-be-rational%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=When%20It's%20Not%20Right%20to%20be%20Rational%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaeWRzgJMt2ASQHHiw%2Fwhen-it-s-not-right-to-be-rational", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaeWRzgJMt2ASQHHiw%2Fwhen-it-s-not-right-to-be-rational", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 395, "htmlBody": "<p>By now I expect most of us have acknowledged the importance of being rational.&nbsp; But as vital as it is to know what principles generally work, it can be even more important to know the exceptions.</p>\n<p>As a process of constant self-evaluation and -modification, rationality is capable of adopting new techniques and methodologies even if we don't know how they work.&nbsp; An 'irrational' action can be rational if we recognize that it functions.&nbsp; So in an ultimate sense, there are no exceptions to rationality's usefulness.</p>\n<p>In a more proximate sense, though, does it have limits?&nbsp; Are there ever times when it's better *not* to explicitly understand your reasons for acting, when it's better *not* to actively correlate and integrate all your knowledge?</p>\n<p>I can think one such case:&nbsp; It's often better not to look down.</p>\n<p>People who don't spend a lot of time living precariously at the edge of long drops don't develop methods of coping.&nbsp; When they're unexpectedly forced to such heights, they often look down.&nbsp; Looking down, subcortical instincts are activated that cause them to freeze and panic, overriding their conscious intentions.&nbsp; This tends to prevent them from accomplishing whatever goals brought them to that location, and in situations where balance is required for safety, the panic instinct can even cause them to fall.</p>\n<p>If you don't look down, you may know intellectually that you're above a great height, but at some level your emotions and instincts aren't as triggered.&nbsp; You don't *appreciate* the height on a subconscious level, and so while you may know you're in danger and be appropriately nervous, your conscious intentions aren't overridden.&nbsp; You don't freeze.&nbsp; You can keep your conscious understanding compartmentalized, not bringing to mind information which you possess but don't wish to be aware of.</p>\n<p>The general principle seems to be that it is useful to avoid fully integrated awareness of relevant data if acknowledging that data dissolves your ability to regulate your emotions and instincts.&nbsp; If they run amok, your reason will be unseated.&nbsp; Careful application of doublethink, and avoiding confronting emotionally-charged facts that aren't absolutely necessary to respond appropriately to the situation, is probably the best course of action.</p>\n<p>If you expect that you're going to be dealing with heights in the future, you can train yourself not to fall into vertigo.&nbsp; But if you don't have opportunities for training down your reactions, not looking down is the next best thing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "3QnDqGSdRMA5mdMM6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aeWRzgJMt2ASQHHiw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 5, "extendedScore": null, "score": 4.841725915843889e-07, "legacy": true, "legacyId": "123", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-28T22:29:34.968Z", "modifiedAt": null, "url": null, "title": "The Zombie Preacher of Somerset", "slug": "the-zombie-preacher-of-somerset", "viewCount": null, "lastCommentedAt": "2017-10-02T16:00:43.646Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Fy2b55mLtghd4fQpx/the-zombie-preacher-of-somerset", "pageUrlRelative": "/posts/Fy2b55mLtghd4fQpx/the-zombie-preacher-of-somerset", "linkUrl": "https://www.lesswrong.com/posts/Fy2b55mLtghd4fQpx/the-zombie-preacher-of-somerset", "postedAtFormatted": "Saturday, March 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Zombie%20Preacher%20of%20Somerset&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Zombie%20Preacher%20of%20Somerset%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFy2b55mLtghd4fQpx%2Fthe-zombie-preacher-of-somerset%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Zombie%20Preacher%20of%20Somerset%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFy2b55mLtghd4fQpx%2Fthe-zombie-preacher-of-somerset", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFy2b55mLtghd4fQpx%2Fthe-zombie-preacher-of-somerset", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1640, "htmlBody": "<p><strong>Related to: </strong><a href=\"http://www.overcomingbias.com/2008/04/zombies.html\">Zombies? Zombies!</a>, <a href=\"http://www.overcomingbias.com/2008/04/zombies-ii.html\">Zombie Responses</a>, <a href=\"http://www.overcomingbias.com/2008/04/zombie-movie.html\">Zombies: The Movie</a>, <a href=\"/lw/20/the_apologist_and_the_revolutionary/\">The Apologist and the Revolutionary</a></p>\n<p>All disabling accidents are tragic, but some are especially bitter. The high school sports star paralyzed in a car crash. The beautiful actress horribly disfigured in a fire. The pious preacher who loses his soul during a highway robbery.<br /><br />As far as I know, this last one only happened once, but once was enough. Simon Browne was an early eighteenth century pastor of a large Dissident church. The community loved him for his deep faith and his remarkable intelligence, and his career seemed assured.<br /><br />One fateful night in 1723, he was travelling from his birthplace in Somerset to his congregation in London when a highway robber accosted the coach carrying him and his friend. With quick reflexes and the element of surprise, Browne and his friend were able to disarm the startled highway robber and throw him to the ground. Browne tried to pin him down while the friend went for help, but in the heat of the moment he used excessive force and choked the man to death. This horrified the poor preacher, who was normally the sort never to hurt a fly.<br /><br />Whether it was the shock, the guilt, or some unnoticed injury taken in the fight, something strange began to happen to Simon Browne. In his own words, he gradually became:</p>\n<blockquote>\n<p>...perfectly empty of all thought, reflection, conscience, and consideration, entirely destitute of the knowledge of God and Christ, unable to look backward or forward, or inward or outward, having no conviction of sin or duty, no capacity of reviewing his conduct, and, in a word, without any principles of religion or even of reason, and without the common sentiments or affections of human nature, insensible even to the good things of life, incapable of tasting any present enjoyments, or expecting future ones...all body, without so much as the remembrance of the ruins of that mind I was once a tenant in...and the thinking being that was in me is, by a consumption continual, now wholly perished and come to nothing.</p>\n</blockquote>\n<p>Simon Browne had become a p-zombie.</p>\n<p><a id=\"more\"></a></p>\n<p>Needless to say, Browne's friends and congregation didn't believe him. Browne seemed as much in possession of his wits as ever. His writing, mostly on abstruse theological topics and ecumenialism, if anything accelerated. According to a friend:</p>\n<blockquote>\n<p>What was most extraordinary in his case was this; that, excepting the single point I have mentioned, on which the distraction turned, his imagination was not only more lively, but his judgment was even improved. And it has been observed that, at the very time that he himself imagined he had no rational soul, he was so acute a disputant (his friends said) that he could reason as if he had <em>two</em> souls.</p>\n</blockquote>\n<p>Despite everyone's insistence that he was fine, Simon Browne would have none of it. His soul had gone missing, and no one without a soul was qualified to lead a religious organization. Despite pleas to remain, he quit his job as pastor and retired to the country. After a brief period spent bemoaning his fate, he learned to take it in stride and began writing prodigously, authoring dictionaries, textbooks on grammars, essays on theology, and even several beautiful hymns still sung in churches today. Did his success convince him he was ensouled after all? No. He claimed:</p>\n<blockquote>\n<p>...only an animal life, in common with brutes, so that though he retained the faculty of speaking in a manner that appeared rational to others, he had all the while no more notion of what he said than a parrot, being utterly divested of consciousness.</p>\n</blockquote>\n<p>And, appreciating the absurdity of his conundrum, asked:</p>\n<blockquote>\n<p>Who, by the most unreasonable and ill-founded conceit in the world, [could] have imagined that a thinking being could, for seven years together, live a stranger to its own powers, exercises, operations, and state?</p>\n</blockquote>\n<p>Considering it pointless to exercise or to protect his own health, he died prematurely in his Somerset house in 1732. His friends mourned a potentially brilliant pastor driven to an early death by an inexplicable insanity.<br /><br />But was his delusion really inexplicable?<br /><br />David Berman is probably the top expert on the Simon Browne case, and the author of the only journal article dedicated specifically to the topic: <a href=\"http://hpy.sagepub.com/cgi/pdf_extract/7/26/257\">Simon Browne: the soul-murdered theologian</a> (other books that devote some space to Browne can be read <a href=\"http://books.google.ie/books?id=rAuiCVCtzyEC&amp;pg=PR34&amp;lpg=PR34&amp;dq=Simon+Browne+clergyman+parrot&amp;source=bl&amp;ots=sX9B-PIYeb&amp;sig=L2QiKyYztYAalF9zbm4arMTX0os&amp;hl=en&amp;ei=V4_OScbYJsTKjAfk2uzpCQ&amp;sa=X&amp;oi=book_result&amp;resnum=3&amp;ct=result#PPR34,M1\">here</a> and <a href=\"http://books.google.ie/books?id=kVsUAAAAQAAJ&amp;pg=PA345&amp;lpg=PA345&amp;dq=Simon+Browne+clergyman&amp;source=bl&amp;ots=S2Wg9PuNcJ&amp;sig=wZwS6J6CBrpL-msL1HEHEeiTAYA&amp;hl=en&amp;ei=FYfOSfn-Jd_TjAer5bDzCQ&amp;sa=X&amp;oi=book_result&amp;resnum=10&amp;ct=result#PPA338,M1\">here</a>). I've been unable to access Berman's paper (if anyone can get it free, please send it to me) but I had the good fortune to be in his Philosophy of Mind class several years ago. If I remember correctly, Dr. Berman had a complex Freudian theory involving repression of erotic feelings. I don't remember enough to do it justice and I'm not going to try. But with all due respect to my former professor, I think he's barking up the wrong tree.<br /><br />Simon Browne's problem seems strangely similar to neurological illness.<br /><br />You remember <a href=\"/lw/20/the_apologist_and_the_revolutionary/\">anosognosia</a>, when patients with left-arm paralysis thought their left arms were working just fine? <a href=\"http://en.wikipedia.org/wiki/Somatoparaphrenia\">Somatoparaphrenia</a> is a closely related disorder. Your arm is working just fine, but you deny you have an arm at all. It must be someone else's. Some scientists link somatoparaphrenia to <a href=\"http://en.wikipedia.org/wiki/Body_Identity_Integrity_Disorder\">Body Integrity Identity Disorder</a>, a condition in which people are desperate to amputate their working limbs for no apparent reason. BIID sufferers are sane enough to recognize that they do currently have a left arm, but it feels alien and unwelcome, and they want it gone.<br /><br />(according to Wikipedia, one cure being investigated for BIID is squirting cold water in the patient's right ear...)<br /><br />Somatoparaphrenia is an identity problem - people lose identity with their limbs. That arm might work, but it doesn't seem like it's working for me. Every other rational process remains intact in somatoparaphrenics. A somatoparaphrenic physicist could do quantum calculations while still insisting that someone else's leg was attached to his hip for some reason.<br /><br /><a href=\"http://en.wikipedia.org/wiki/Cotard_Delusion\">Cotard's Delusion</a> is an even worse condition where the patient insists she is dead or nonexistent. Tantalizingly, patients with Cotard's occasionally use religious language, claiming to have been eternally damned or without a soul - a symptom shared by Simon Browne. Unlike anosognosia and somatoparaphrenia, it is not necessarily caused by stroke - all sorts of things, neurological or psychological, can bring it on. V. S. Ramachandran (yes, him again) theorizes that Cotard's may be a disconnect between certain recognition circuits and certain emotional circuits, preventing the patient from feeling an emotional connection with himself.<br /><br />Browne reminds me also of \"<a href=\"http://en.wikipedia.org/wiki/Blindsight\">blindsight</a>\", the phenomenon where a patient is capable of seeing but not consciously aware of doing so. Ask a patient what she sees, and she'll swear she sees nothing - she is, after all, totally blind. Ask a patient to guess which of four quarters of the visual field a light is in, and she'll look at you like an idiot. How should she know? She's blind! Harass the patient until she finally guesses, and she'll get it right, at odds phenomenally greater than chance. Ask her how she knew, and she'll say it was a lucky guess.<br /><br />Simon Browne sits somewhere in between all of these. Like the Cotard patient, he denied having a self, and considered himself eternally damned. Like the somatoparaphreniac, he completely lost identification with a certain part of himself (in this case, the mind!) and insisted it didn't exist while retaining the ability to use it and to reason accurately in other domains. And like the blindsight patient, he was able to process information at a level usually restricted to conscious experience without any awareness of doing so.<br /><br />I don't know any diagnosis that exactly fits Browne's symptoms (Cotard's comes close but falls a little short). But the symptoms seem so reminiscent of neurological injury that I would be surprised if Dr. Berman's psychoanalysis was the full story.<br /><br />So, what does Simon Browne add to the p-zombie debate?<br /><br />Either nothing or everything. We can easily dismiss him as a complete nutcase, no more accurate in describing his mental states than a schizophrenic is accurate in describing his conversations with angels. Or we can come up with a neurological explanation in which he has conscious experience, but considers it alien to himself.<br /><br />I acknowledge the possibility, but it rings hollow. Browne's friends were unanimous in describing him as rational and intelligent. And Browne himself was very clear that he had no mental experience whatsoever, not that he had some mental experience that didn't seem like his own.<br /><br />But if we accepted Browne as mostly truthful, it demonstrates consciousness is not an inseparable byproduct of normal mental operation. It is possible to take consciousness, remove it, and have a p-zombie left. Not a perfect Chalmerian p-zombie - Browne made it very clear that he noticed and cared deeply about his loss of consciousness, and didn't go around claiming he was still fully aware or any nonsense like that - but a p-zombie nonetheless.<br /><br />That is a heck of a conclusion to draw from one poorly studied case (there is rumored to be a second similar case, one Lewis Kennedy, but I can't find information on this one). However, Simon Browne at the very least deserves to be shelved alongside the other scarce and contradictory evidence on this topic. Let's give the poor preacher the last word:</p>\n<blockquote>\n<p>God should still have left me the power of speech, [that] I may at last convince [you] that my case has not been a delusion of fancy, but the most tremendous reality.</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"uLqT8mmFiA8NeytTi": 1, "bY5MaF2EATwDkomvu": 1, "xHjy88N2uJvGdgzfw": 1, "5f5c37ee1b5cdee568cfb19d": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Fy2b55mLtghd4fQpx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 55, "baseScore": 52, "extendedScore": null, "score": 8e-05, "legacy": true, "legacyId": "225", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 52, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZiQqsgGX6a42Sfpii"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T05:46:07.838Z", "modifiedAt": null, "url": null, "title": "Hygienic Anecdotes", "slug": "hygienic-anecdotes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:00.222Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gBjAJvSEg6zn9eMya/hygienic-anecdotes", "pageUrlRelative": "/posts/gBjAJvSEg6zn9eMya/hygienic-anecdotes", "linkUrl": "https://www.lesswrong.com/posts/gBjAJvSEg6zn9eMya/hygienic-anecdotes", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hygienic%20Anecdotes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHygienic%20Anecdotes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgBjAJvSEg6zn9eMya%2Fhygienic-anecdotes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hygienic%20Anecdotes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgBjAJvSEg6zn9eMya%2Fhygienic-anecdotes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgBjAJvSEg6zn9eMya%2Fhygienic-anecdotes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 253, "htmlBody": "<p>Bayesians must condition their beliefs on all available evidence; it is not cheating to use less than ideal sources of information. However, this process also requires conditioning on the evidence for your evidence. Outside of academic journals, evidence is often difficult to trace back to the source and is dependent on our notoriously faulty memory. Given the consequences of low-fidelity copying, should rationalists trust evidence they can't remember the source of, even if they remember reading the primary source themselves? Should community members be expected to produce citations on demand?</p>\n<p>This issue came to mind while trying to find a study I vaguely remembered about how the increased happiness of the religious could be explained by increased community involvement and while trying to factcheck PhilGoetz's <a href=\"/lw/62/defense_against_the_dark_arts_case_study_1/\">now infamous</a> <a href=\"/lw/5r/crowley_on_religious_experience/3tu#comments\">anecdote about Steve Jobs</a>. I started contemplating the standards for relaying highly relevant, but potentially wrong or distorted information.</p>\n<p>Luckily factchecking is much easier in the age of the internet. Wikipedia serves as a universally accessible standard reference, and Google serves well for everything else. But sometimes my google-fu is not strong enough. So, I'll put this to the community: how should rationalists balance the tradeoff between neglecting evidence and propogating bad information?</p>\n<p><a href=\"/lw/u/the_ethic_of_handwashing_and_community_epistemic/\">Hygienic practices</a> have been touched on before, but I haven't seen any consensus on this issue. Are the standards for what you personally condition on and what you share in discussion different? What needs a citation and what doesn't? Does anyone have recommendations for ways to better track the sources of evidence, i.e. <a href=\"http://en.wikipedia.org/wiki/Reference_management_software\">reference management software</a>?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xgpBASEThXPuKRhbS": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gBjAJvSEg6zn9eMya", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 10, "extendedScore": null, "score": 4.842905153003499e-07, "legacy": true, "legacyId": "226", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["p7WXmG6Fbo3eaSwm3", "ZP2om2oWHPhvWP2Q3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T10:49:08.001Z", "modifiedAt": null, "url": null, "title": "Rationality: Common Interest of Many Causes", "slug": "rationality-common-interest-of-many-causes", "viewCount": null, "lastCommentedAt": "2019-08-19T18:01:30.041Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4PPE6D635iBcGPGRy/rationality-common-interest-of-many-causes", "pageUrlRelative": "/posts/4PPE6D635iBcGPGRy/rationality-common-interest-of-many-causes", "linkUrl": "https://www.lesswrong.com/posts/4PPE6D635iBcGPGRy/rationality-common-interest-of-many-causes", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%3A%20Common%20Interest%20of%20Many%20Causes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%3A%20Common%20Interest%20of%20Many%20Causes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4PPE6D635iBcGPGRy%2Frationality-common-interest-of-many-causes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%3A%20Common%20Interest%20of%20Many%20Causes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4PPE6D635iBcGPGRy%2Frationality-common-interest-of-many-causes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4PPE6D635iBcGPGRy%2Frationality-common-interest-of-many-causes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1127, "htmlBody": "<p>It is a non-so-hidden agenda of this site, Less Wrong, that there are many causes which benefit from the spread of rationality&mdash;because it takes a little more rationality than usual to see their case, as a supporter, or even just a supportive bystander.&nbsp; Not just the obvious causes like atheism, but things like marijuana legalization&mdash;where you could wish that people were a bit more self-aware about their motives and the nature of signaling, and a bit more moved by inconvenient cold facts.&nbsp; The Institute Which May Not Be Named was merely an unusually extreme case of this, wherein it got to the point that after years of bogging down I threw up my hands and explicitly recursed on the job of creating rationalists.</p>\n<p>But of course, not <em>all</em> the rationalists I create will be interested in my <em>own</em> project&mdash;<em>and that's fine.</em>&nbsp; You can't capture <em>all</em> the value you create, and trying can have poor side effects.</p>\n<p>If the supporters of other causes are enlightened enough to think similarly...</p>\n<p>Then all the causes which benefit from spreading rationality, can, perhaps, have something in the way of standardized material to which to point their supporters&mdash;a common task, centralized to save effort&mdash;and think of themselves as spreading a little rationality on the side.&nbsp; They won't capture all the value they create.&nbsp; And that's fine.&nbsp; They'll capture some of the value others create.&nbsp; Atheism has very little to do directly with marijuana legalization, but if both atheists and anti-Prohibitionists are willing to step back a bit and say a bit about the general, abstract principle of confronting a discomforting truth that interferes with a fine righteous tirade, then both atheism and marijuana legalization pick up some of the benefit from both efforts.</p>\n<p>But this requires&mdash;I know I'm repeating myself here, but it's important&mdash;that you be willing not to capture all the value you create.&nbsp; It requires that, in the course of talking about rationality, you maintain an ability to temporarily <em>shut up</em> about your own cause <a href=\"/lw/2v/the_tragedy_of_the_anticommons/242#comments\">even though it is the best cause ever</a>.&nbsp; It requires that you don't regard those other causes, and they do not regard you, as competing for a limited supply of rationalists with a limited capacity for support; but, rather, creating more rationalists and increasing their capacity for support.&nbsp; You only reap some of your own efforts, but you reap some of others' efforts as well.</p>\n<p>If you and they don't agree on everything&mdash;especially priorities&mdash;you have to be willing to agree to <em>shut up</em> about the disagreement.&nbsp; (Except possibly in specialized venues, out of the way of the mainstream discourse, where such disagreements are explicitly prosecuted.)<a id=\"more\"></a></p>\n<p>A certain person who was taking over as the president of a certain organization once pointed out that the organization had not enjoyed much luck with its message of \"This is <em>the best</em> thing you can do\", as compared to e.g. the X-Prize Foundation's tremendous success conveying to rich individuals of \"Here is <em>a cool</em> thing you can do.\"</p>\n<p>This is one of those insights where you blink incredulously and then grasp how much sense it makes.&nbsp; The human brain <a href=\"http://www.overcomingbias.com/2007/05/scope_insensiti.html\">can't grasp</a> <a href=\"http://www.overcomingbias.com/2007/05/one_life_agains.html\">large stakes</a> and people are not anything remotely like expected utility maximizers, and we are generally altruistic akrasics.&nbsp; Saying, \"This is the <em>best</em> thing\" doesn't add much motivation beyond \"This is a cool thing\".&nbsp; It just establishes a much higher burden of proof.&nbsp; And invites invidious motivation-sapping comparison to all other good things you know (perhaps threatening to diminish <a href=\"http://www.overcomingbias.com/2007/05/scope_insensiti.html\">moral satisfaction already purchased</a>).</p>\n<p>If we're operating under the assumption that everyone by default is an altruistic akrasic (someone who wishes they could choose to do more)&mdash;or at least, that most potential supporters of interest fit this description&mdash;then fighting it out over which cause is the <em>best</em> to support, may have the effect of decreasing the overall supply of altruism.</p>\n<p>\"But,\" you say, \"dollars are fungible; a dollar you use for one thing indeed cannot be used for anything else!\"&nbsp; To which I reply:&nbsp; But human beings <em>really aren't</em> expected utility maximizers, as cognitive systems.&nbsp; Dollars come out of different mental accounts, cost different amounts of <em>willpower</em> (the true limiting resource) under different circumstances, people want to spread their donations around as an act of mental accounting to minimize the regret if a single cause fails, and telling someone about an additional cause may increase the total amount they're willing to help.</p>\n<p>There are, of course, limits to this principle of benign tolerance.&nbsp; If someone has a project to help stray puppies get warm homes, then it's probably best to regard them as trying to exploit bugs in human psychology for their personal gain, rather than a worthy sub-task of the great common Neo-Enlightenment project of human progress.</p>\n<p>But to the extent that something really is a task you would wish to see done on behalf of humanity... then invidious comparisons of that project to Your-Favorite-Project, may not help your own project as much as you might think.&nbsp; We may need to learn to say, by habit and in nearly all forums, \"Here is <em>a cool</em> rationalist project\", not, \"Mine alone is <em>the highest-return in expected utilons per marginal dollar</em> project.\"&nbsp; If someone cold-blooded enough to maximize expected utility of fungible money without regard to emotional side effects <em>explicitly asks,</em> we could perhaps steer them to a <em>specialized</em> subforum where anyone willing to make the claim of <em>top</em> priority fights it out.&nbsp; Though if all goes well, those projects that have a strong claim to this kind of underserved-ness will get more investment and their marginal returns will go down, and the winner of the competing claims will no longer be clear.</p>\n<p>If there are many rationalist projects that benefit from <a href=\"/lw/1e/raising_the_sanity_waterline/\">raising the sanity waterline</a>, then their mutual tolerance and common investment in spreading rationality could conceivably exhibit a commons problem.&nbsp; But this doesn't seem too hard to deal with: if there's a group that's not willing to share the rationalists they create or mention to them that other Neo-Enlightenment projects might exist, then any common, centralized rationalist resources could remove the mention of their project as a cool thing to do.</p>\n<p>Though all this is an idealistic and future-facing thought, the benefits&mdash;for all of us&mdash;could be finding some important things we're missing right now.&nbsp; So many rationalist projects have few supporters and far-flung; if we could all identify as elements of the Common Project of human progress, the Neo-Enlightenment, there would be a substantially higher probability of <a href=\"/lw/5v/church_vs_taskforce/\">finding ten of us in any given city</a>.&nbsp; Right now, a lot of these projects are just a little lonely for their supporters.&nbsp; Rationality may not be <em>the most important thing in the world</em>&mdash;that, of course, is <a href=\"http://www.overcomingbias.com/2008/01/something-to-pr.html\">the thing that we protect</a>&mdash;but it is <em>a cool</em> thing that more of us have in common.&nbsp; We might gain much from identifying ourselves also as rationalists.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "xHTXnyp65X8YX6ahT": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4PPE6D635iBcGPGRy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 56, "baseScore": 67, "extendedScore": null, "score": 0.000103, "legacy": true, "legacyId": "222", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "helpless-individuals", "canonicalPrevPostSlug": "church-vs-taskforce", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XqmjdBKa4ZaXJtNmf", "p5DmraxDmhvMoZx8J"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T12:03:50.210Z", "modifiedAt": null, "url": null, "title": "Ask LW: What questions to test in our rationality questionnaire?", "slug": "ask-lw-what-questions-to-test-in-our-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.211Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p7BPWw3kmGdbJeH5p/ask-lw-what-questions-to-test-in-our-rationality", "pageUrlRelative": "/posts/p7BPWw3kmGdbJeH5p/ask-lw-what-questions-to-test-in-our-rationality", "linkUrl": "https://www.lesswrong.com/posts/p7BPWw3kmGdbJeH5p/ask-lw-what-questions-to-test-in-our-rationality", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ask%20LW%3A%20What%20questions%20to%20test%20in%20our%20rationality%20questionnaire%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAsk%20LW%3A%20What%20questions%20to%20test%20in%20our%20rationality%20questionnaire%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7BPWw3kmGdbJeH5p%2Fask-lw-what-questions-to-test-in-our-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ask%20LW%3A%20What%20questions%20to%20test%20in%20our%20rationality%20questionnaire%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7BPWw3kmGdbJeH5p%2Fask-lw-what-questions-to-test-in-our-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp7BPWw3kmGdbJeH5p%2Fask-lw-what-questions-to-test-in-our-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1845, "htmlBody": "<p>&nbsp;</p>\n<p>We&rsquo;ve had quite a bit of discussion around LW, and OB, on the questions:</p>\n<ul>\n<li>Is there a robust trait, &ldquo;rationality&rdquo;, that predicts accurate belief-formation in humans?&nbsp;</li>\n<li>If so, how can we measure it?&nbsp; And what kinds of training might help?</li>\n<li>Also, does &ldquo;rationality&rdquo; in the above sense help people achieve other goals, such as income, happiness, personal growth, positive relationships, or world-saving?</li>\n</ul>\n<p>Rationalists that we are, it&rsquo;s time to put our experiments where our mouths are.&nbsp; So here&rsquo;s my plan:<br /><a id=\"more\"></a></p>\n<p><strong>Step 1</strong>: Assemble a set of questions that might possibly help us understand: (a) how rational people are; (b) where they got that rationality from; and (c) what effects their rationality has on their lives.&nbsp; Include any questions that might help in the formulation of useful conjectures.&nbsp; After collecting the data, look for correlations, spaghetti-at-the-wall style.&nbsp; Try <a href=\"http://en.wikipedia.org/wiki/Factor_analysis\">factor analysis</a>.&nbsp;&nbsp;</p>\n<p><strong>Step 2</strong> [Perhaps after iterating the quick-and-dirty Step 1 correlational approach a bit, to develop better candidate metrics]:&nbsp; Run some more careful experimental tests of various sorts, both with a &ldquo;rationality training group&rdquo; that meets for extended periods of time, and, if LW is willing, with shorter training experiments with randomized LW subgroups.&nbsp; Try to build an atmosphere and knowledge base on LW where more people go out and do useful experiments.<br /><br />I have an initial questionnaire draft below, although I skipped the answer-choices for brevity.&nbsp; Please post your suggestions for informative questions include and/or to drop.&nbsp; As good suggestions come in, I&rsquo;ll edit the questionnaire draft to include them.&nbsp; It would be nice if the questionnaire we actually use draws on the combined background of the LW community.<br /><br />Please also post hypotheses for what kinds of correlations you expect to see and/or to not see, when the questionnaire is actually run.&nbsp; If you note your hypotheses now, before the data comes in, we&rsquo;ll know we should increase our credence in your theory instead of just accusing you of <a href=\"http://en.wikipedia.org/wiki/Hindsight_bias\">hindsight bias</a>.<br /><br />Once we have a good questionnaire draft, I&rsquo;ll put the questionnaire on the web and call for LW readers to fill out the questionnaire.&nbsp; I&rsquo;ll also try to get people to fill out the questionnaire from some non-LW groups, e.g. Stanford students.&nbsp; Then I&rsquo;ll post the questionnaire data, and we can all have fun interpreting it.<br /><br /><em>Section A.&nbsp; Demographic information.&nbsp; Possible confounders, i.e. variables other than &ldquo;rationality&rdquo; that may influence correct beliefs.<br /></em></p>\n<ol>\n<li>Age (from a multiple choice list, so we don&rsquo;t identify individuals)</li>\n<li>Sex&nbsp; [Why: everyone else asks for these, and they might have good reason.</li>\n<li>SAT, ACT, and GRE scores, if any.&nbsp; [Why: as a proxy for IQ.&nbsp; IQ helps with many cognitive tasks, probably including rationality questions.&nbsp; We want to be able to tell the difference between &ldquo;IQ helps people earn money&rdquo; and &ldquo;rationality helps people earn money, even after controlling for IQ&rdquo;.]</li>\n</ol>\n<p><em>Section B.&nbsp; Educational variables that may help cause rationality.</em></p>\n<ol>\n<li>Parents&rsquo; education.</li>\n<li>Parents&rsquo; scientific literacy.&nbsp; </li>\n<li>Parents&rsquo; religious views.&nbsp;&nbsp;</li>\n<li>Whether your parents were crazier than average, and/or more rational than average.</li>\n<li>Amount of formal education.&nbsp; College major.</li>\n<li>Occupation.</li>\n<li>How many non-fiction books did you read in the last month?&nbsp; How many fiction books? [Why: people are probably more likely to give accurate data if we ask about e.g. &ldquo;the last month&rdquo;, than if we ask vaguer question like &ldquo;how much do you usually read?&rdquo;]</li>\n<li>How many self-help or business books did you read in the last month?</li>\n<li>When is the last time you sought out someone who was better than you at some skill you wanted to learn, and you asked them questions to try to figure out what you should be doing?</li>\n<li>Have you read any books about heuristics and biases?</li>\n<li>Have you read OB or LW at all? \n<ul>\n<li>If yes: 11a.&nbsp; When did you start reading?</li>\n<li>11b.&nbsp; What portion have you read?</li>\n<li>11c.&nbsp; Do you discuss the ideas with anyone, either online (e.g., as a commenter), or in person?</li>\n</ul>\n</li>\n<li>Which of the following activities have you trained in:&nbsp; mathematics, programming, engineering or practical tinkering, music, meditation, martial arts, debate, strategy games (go, chess, backgammon, etc.).</li>\n</ol>\n<p><em>Section C.&nbsp; Indicators of real-world success.</em></p>\n<ol>\n<li>Income.</li>\n<li>[Marriage and divorce history?&nbsp; Whether you&rsquo;re in a stable relationship?&nbsp; Whether you&rsquo;re happy with their relationship?&nbsp; Whether you have an easy time getting dates?&nbsp; How do people usually test for &ldquo;success&rdquo; here?]</li>\n<li>Number of best friends, for some operationalizations of &ldquo;best friends&rdquo; (e.g., people you could borrow $500 from; people with whom you can talk about nearly anything; ?)&nbsp; [What questions are standard, here?]</li>\n<li>Whether you&rsquo;ve ever been in a car accident</li>\n<li>Happiness</li>\n<li>Whether you&rsquo;ve been overall &ldquo;more successful&rdquo;, &ldquo;less successful&rdquo;, or &ldquo;about as successful&rdquo; as most people in their high school graduating class, and in their college graduating class.</li>\n<li>Whether you&rsquo;ve &ldquo;learned more&rdquo;, &ldquo;learned less&rdquo;, or &ldquo;learned about as much&rdquo; since graduating {high school / college} as most people in your {high school / college} graduating class.</li>\n<li>How often did you exercise in the last week?</li>\n<li>Do you smoke?</li>\n<li>High school and college GPAs</li>\n<li>Do you have a current driver&rsquo;s license?</li>\n<li>Are there any late bills, bounced checks, bad debts, etc. on your credit record?</li>\n<li>How many dental cavities did you get in the last two years?</li>\n</ol>\n<p><em>Section D.&nbsp; Standard heuristics and biases questions</em></p>\n<p>[Several standard questions, and variations on standard questions, that I&rsquo;d rather not give details on so I don&rsquo;t cause LW readers to get them right.&nbsp; The goal here is to find ways of testing for standard biases among people who have read the standard articles.&nbsp; If anyone has clever ideas for how to disguise the questions, please <strong>do</strong> email your ideas to annasalamon at gmail, and please <strong>don&rsquo;t</strong> post your ideas in the comments.]<br /><br /><em>Section E.&nbsp; Current beliefs</em></p>\n<ol>\n<li>Religious views.</li>\n<li>Are you signed up for cryonics?&nbsp; Views on cryonics.</li>\n<li>Views on group (gender, race) differences in IQ.&nbsp; (Not the origins of the differences; just whether there are group differences in today&rsquo;s adults).</li>\n<li>Views on the odds nuclear war over the next few decades</li>\n<li>How good-looking are you, relative to other people of your age and gender?</li>\n<li>Views on Pascal&rsquo;s wager</li>\n<li>Views on consciousness</li>\n<li>Views on evolution</li>\n<li>Views on whether global warming is happening, and whether it is significant</li>\n</ol>\n<p>[Why: to see how good people are at forming accurate beliefs.&nbsp; And to get a bit of information on whether the above beliefs are accurate, by seeing whether the beliefs correlate with other rationality-indicators.]<br /><br /><em>Section F.&nbsp; Value placed on truth</em></p>\n<ol>\n<li>Is it better to have accurate beliefs, or beliefs that give you morale or meaning?</li>\n<li>Do you try to believe good things about your friends?</li>\n<li>Do you try to believe good things about people who are different from you (e.g., people of different ethnic or religious backgrounds, people from different countries, people with different sexual orientations)?&nbsp; Why?</li>\n<li>How important is it to you to have accurate beliefs?</li>\n<li>Imagine a scale from 1 to 10 that measures the process by which you form beliefs.&nbsp; Let &ldquo;1&rdquo; mean &ldquo;there may be emotional or other non-rational pressures, but those pressures have little impact on my resulting conclusions&rdquo;.&nbsp; Let &ldquo;10&rdquo; mean &ldquo;I basically just made up these beliefs because they felt good, seemed socially useful, matched my fears, or had some other non-truth-related property&rdquo;.&nbsp; On this scale, how did you form your beliefs concerning: \n<ul>\n<li>a.&nbsp; Yourself</li>\n<li>b.&nbsp; Your friends and family</li>\n<li>c.&nbsp; How to make money, gain skills, make friends, etc.</li>\n<li>d.&nbsp; The larger world (e.g., how likely the economy is to do well in the next few years, whether nuclear weapons or global warming pose real risks, what impact different political parties might have, etc.).</li>\n</ul>\n</li>\n</ol>\n<p><em>Section G.&nbsp; Attempts to seek information</em></p>\n<ol>\n<li>In the last week, how much time did you spend trying to understand: \n<ul>\n<li>a.&nbsp; Yourself</li>\n<li>b.&nbsp; Your friends and family</li>\n<li>c.&nbsp; How to make money, gain skills, make friends, etc.</li>\n<li>d.&nbsp; The larger world (e.g., how likely the economy is to do well in the next few years, whether nuclear weapons or global warming pose real risks, what impact different political parties might have, etc.).</li>\n</ul>\n</li>\n<li>How well do you know your friends and family?&nbsp; How do you know how well you know them?</li>\n<li>How well do you know yourself?&nbsp; How do you know?</li>\n<li>How well do you understand those aspects of the world that enable real-world measurable success, e.g. income?&nbsp; How do you know?</li>\n<li>Have you experimented with different ways to do your job effectively?</li>\n<li>Have well do you understand the larger world?&nbsp; How do you know?</li>\n<li>Think about the last time you had a fight or conflict with someone.&nbsp; How much time did you spend rehearsing the evidence for your side?&nbsp; How much time did you spend trying with honest curiosity to figure out what happened?</li>\n<li>How often do you notice that one of your pieces of knowledge conflicts with your model of some other part of the world (e.g., that you don't understand why the floating toy in the pool bops to the top at the angle it does, or why </li>\n</ol>\n<p><em>Section H:&nbsp; Models of one's own thinking skill</em> [This is the only section with open-ended rather than multiple-choice questions.&nbsp; Respondants can skip this section while filling out the rest]</p>\n<ol>\n<li>What&rsquo;s the worst mistake you made in the last year?&nbsp; What did you do about it?</li>\n<li>What are the largest gaps in your current thinking skills?</li>\n<li>What are your greatest strengths as a thinker?</li>\n<li>On what topics are you most prone to self-deception?</li>\n<li>What is the biggest improvement you&rsquo;ve made in your ability to form accurate beliefs over the last year?</li>\n<li>What safeguards do you use, to try to notice flaws in your own beliefs?</li>\n</ol>\n<p>&nbsp;</p>\n<p><strong>ADDED: </strong>The idea here is <strong>not</strong> to generate an actual, first-round test of individuals' rationality.&nbsp; The idea is to take a bunch of questions that <strong>might plausibly</strong> correlate with that nebulous mix of concepts, \"rationality\", and to see how well those questions correlate with one another.&nbsp; We won't get a \"your're more rational than 70% of the population\" out of this questionnaire: no way, no how.&nbsp; We may well get a some suggestive data about clusters of questions and answers where respondants' answers tend to correlate with one another, and so suggest possible underlying factors worth more careful investigation.</p>\n<p>Psychologists often do cheap, bad studies before they do slow, careful, expensive studies, to get an initial look at what might be true.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"kJrjorSx3hXa7q7CJ": 1, "MfpEPj6kJneT9gWT6": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p7BPWw3kmGdbJeH5p", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 17, "extendedScore": null, "score": 4.843456792489645e-07, "legacy": true, "legacyId": "229", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T12:10:52.862Z", "modifiedAt": null, "url": null, "title": "Bay area OB/LW meetup, today, Sunday, March 29, at 5pm", "slug": "bay-area-ob-lw-meetup-today-sunday-march-29-at-5pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:16.004Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2eaYboiek2WoCya2P/bay-area-ob-lw-meetup-today-sunday-march-29-at-5pm", "pageUrlRelative": "/posts/2eaYboiek2WoCya2P/bay-area-ob-lw-meetup-today-sunday-march-29-at-5pm", "linkUrl": "https://www.lesswrong.com/posts/2eaYboiek2WoCya2P/bay-area-ob-lw-meetup-today-sunday-march-29-at-5pm", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bay%20area%20OB%2FLW%20meetup%2C%20today%2C%20Sunday%2C%20March%2029%2C%20at%205pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABay%20area%20OB%2FLW%20meetup%2C%20today%2C%20Sunday%2C%20March%2029%2C%20at%205pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2eaYboiek2WoCya2P%2Fbay-area-ob-lw-meetup-today-sunday-march-29-at-5pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bay%20area%20OB%2FLW%20meetup%2C%20today%2C%20Sunday%2C%20March%2029%2C%20at%205pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2eaYboiek2WoCya2P%2Fbay-area-ob-lw-meetup-today-sunday-march-29-at-5pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2eaYboiek2WoCya2P%2Fbay-area-ob-lw-meetup-today-sunday-march-29-at-5pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 45, "htmlBody": "<p>Eliezer and Michael Vassar will be there, as will many other exciting LW-ers.&nbsp; Robin Gane-McCalla will be leading us in some rationality-related games.&nbsp; More information <a href=\"http://www.meetup.com/Bay-Area-Overcoming-Bias-Meetup/calendar/9886420/\">here</a>.</p>\n<p>Whether or not you can come today, you may want to sign up on <a href=\"http://www.meetup.com/Bay-Area-Overcoming-Bias-Meetup/\">our meet-up page</a>, if you're local.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zz3HWyByyKF64Sfns": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2eaYboiek2WoCya2P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 1, "extendedScore": null, "score": 4.843467053880968e-07, "legacy": true, "legacyId": "231", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T18:13:00.412Z", "modifiedAt": null, "url": null, "title": "Recognizing the Candlelight as Fire: Joshu Washes the Bowl", "slug": "recognizing-the-candlelight-as-fire-joshu-washes-the-bowl", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:27.016Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Annoyance", "createdAt": "2009-02-28T04:06:40.600Z", "isAdmin": false, "displayName": "Annoyance"}, "userId": "yEm6LWatswJYGwBFq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qQpktQnjS9rAoXiDy/recognizing-the-candlelight-as-fire-joshu-washes-the-bowl", "pageUrlRelative": "/posts/qQpktQnjS9rAoXiDy/recognizing-the-candlelight-as-fire-joshu-washes-the-bowl", "linkUrl": "https://www.lesswrong.com/posts/qQpktQnjS9rAoXiDy/recognizing-the-candlelight-as-fire-joshu-washes-the-bowl", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recognizing%20the%20Candlelight%20as%20Fire%3A%20Joshu%20Washes%20the%20Bowl&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecognizing%20the%20Candlelight%20as%20Fire%3A%20Joshu%20Washes%20the%20Bowl%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqQpktQnjS9rAoXiDy%2Frecognizing-the-candlelight-as-fire-joshu-washes-the-bowl%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recognizing%20the%20Candlelight%20as%20Fire%3A%20Joshu%20Washes%20the%20Bowl%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqQpktQnjS9rAoXiDy%2Frecognizing-the-candlelight-as-fire-joshu-washes-the-bowl", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqQpktQnjS9rAoXiDy%2Frecognizing-the-candlelight-as-fire-joshu-washes-the-bowl", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 112, "htmlBody": "<h2>Joshu Washes the Bowl</h2>\n<p>A monk told Joshu: `I have just entered the monastery. Please teach me.'</p>\n<p>Joshu asked: `Have you eaten your rice porridge?'</p>\n<p>The monk replied: `I have eaten.'</p>\n<p>Joshu said: `Then you had better wash your bowl.'</p>\n<p>At that moment the monk was enlightened.</p>\n<blockquote></blockquote>\n<p><em>Mumon's Comment:</em> Joshu is the man who opens his mouth and shows his heart. I doubt if this monk really saw Joshu's heart. I hope he did not mistake the bell for a pitcher.</p>\n<p><em>It is too clear and so it is hard to see.<br /> A dunce once searched for fire with a lighted lantern.<br /> Had he known what fire was,<br /> He could have cooked his rice much sooner.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GBpwq8cWvaeRoE9X5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qQpktQnjS9rAoXiDy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": -14, "extendedScore": null, "score": -2.1e-05, "legacy": true, "legacyId": "233", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T18:26:11.914Z", "modifiedAt": null, "url": null, "title": "Akrasia, hyperbolic discounting, and picoeconomics", "slug": "akrasia-hyperbolic-discounting-and-picoeconomics", "viewCount": null, "lastCommentedAt": "2018-08-02T20:18:45.559Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/geNZ6ZpfFce5intER/akrasia-hyperbolic-discounting-and-picoeconomics", "pageUrlRelative": "/posts/geNZ6ZpfFce5intER/akrasia-hyperbolic-discounting-and-picoeconomics", "linkUrl": "https://www.lesswrong.com/posts/geNZ6ZpfFce5intER/akrasia-hyperbolic-discounting-and-picoeconomics", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Akrasia%2C%20hyperbolic%20discounting%2C%20and%20picoeconomics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAkrasia%2C%20hyperbolic%20discounting%2C%20and%20picoeconomics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgeNZ6ZpfFce5intER%2Fakrasia-hyperbolic-discounting-and-picoeconomics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Akrasia%2C%20hyperbolic%20discounting%2C%20and%20picoeconomics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgeNZ6ZpfFce5intER%2Fakrasia-hyperbolic-discounting-and-picoeconomics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgeNZ6ZpfFce5intER%2Fakrasia-hyperbolic-discounting-and-picoeconomics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 643, "htmlBody": "<p><strong>Akrasia</strong> is the tendency to act against your own long-term interests, and is a problem doubtless only too familiar to us all. In his book \"<a href=\"http://en.wikipedia.org/wiki/Special:BookSources/9780521596947\">Breakdown of Will</a>\", psychologist George C Ainslie sets out a theory of how akrasia arises and why we do the things we do to fight it. His extraordinary proposal takes insights given us by economics into how conflict is resolved and extends them to conflicts of different agencies within a single person, an approach he terms \"picoeconomics\". The foundation is a curious discovery from experiments on animals and people: the phenomenon of hyperbolic discounting.</p>\n<p>We all instinctively assign a lower weight to a reward further in the future than one close at hand; this is \"discounting the future\". We don't just account for a slightly lower probability of recieving a more distant award, we value it at inherently less for being further away. It's been an <a href=\"http://www.overcomingbias.com/2008/01/against-discoun.html\">active</a> <a href=\"http://www.overcomingbias.com/2008/01/protecting-acro.html\">debate</a> on overcomingbias.com whether such discounting can be rational at all. However, even if we allow that discounting can be rational, the way that we and other animals do it has a structure which is inherently irrational: the weighting we give to a future event is, roughly, inversely proportional to how far away it is. This is <a href=\"http://en.wikipedia.org/wiki/Hyperbolic_discounting\">hyperbolic discounting</a>, and it is an empirically very well confirmed result.</p>\n<p><a id=\"more\"></a>I say \"inherently irrational\" because it is inconsistent over time: the relative cost of a day's wait is considered differently whether that day's wait is near or far. Looking at a day a month from now, I'd sooner feel awake and alive in the morning than stay up all night reading comments on lesswrong.com. But when that evening comes, it's likely my preferences will reverse; the distance to the morning will be relatively greater, and so my happiness then will be discounted more strongly compared to my present enjoyment, and another groggy morning will await me. To my horror, my future self has different interests to my present self, as surely as if I knew the day a <a href=\"http://yudkowsky.net/singularity\">murder pill</a> would be forced upon me.</p>\n<p>If I knew that a murder pill really would be forced upon me on a certain date, after which I would want nothing more than to kill as many people as possible as gruesomly as possible, I could not sit idly by waiting for that day to come; I would want to do something now to prevent future carnage, because it is not what the me of today desires. I might attempt to frame myself for a crime, hoping that in prison my ability to go on a killing spree would be contained. And this is exactly the behavour we see in people fighting akrasia: consider the alcoholic who moves to a town in which alcohol is not sold, anticipating a change in desires and deliberately constraining their own future self. Ainslie describes this as \"a relationship of limited warfare among successive selves\".</p>\n<p>And it is this warfare which Ainslie analyses with the tools of behavioural economics. His analysis accounts for the importance of making resolutions in defeating akrasia, and the reasons why a resolution is easier to keep when it represents a \"bright clear line\" that we cannot fool ourselves into thinking we haven't crossed when we have. It also discusses the dangers of willpower, and the ways in which our intertemporal bargaining can leave us acting against both our short-term and our long-term interests.</p>\n<p>I can't really do more than scratch the surface on how this analysis works in this short article; you can read more about the analysis and the book on Ainslie's website, <a href=\"http://picoeconomics.org/\">picoeconomics.org</a>. I have the impression that defeating akrasia is the number one priority for many lesswrong.com readers, and this work is the first I've read that really sets out a mechanism that underlies the strange battles that go on between our shorter and longer term interests.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"r7qAjcbfhj2256EHH": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "geNZ6ZpfFce5intER", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 60, "baseScore": 60, "extendedScore": null, "score": 9.1e-05, "legacy": true, "legacyId": "228", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 60, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 86, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T19:45:07.798Z", "modifiedAt": null, "url": null, "title": "Deliberate and spontaneous creativity", "slug": "deliberate-and-spontaneous-creativity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:01.832Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5aaPPRAM6JdLqceqX/deliberate-and-spontaneous-creativity", "pageUrlRelative": "/posts/5aaPPRAM6JdLqceqX/deliberate-and-spontaneous-creativity", "linkUrl": "https://www.lesswrong.com/posts/5aaPPRAM6JdLqceqX/deliberate-and-spontaneous-creativity", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Deliberate%20and%20spontaneous%20creativity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeliberate%20and%20spontaneous%20creativity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5aaPPRAM6JdLqceqX%2Fdeliberate-and-spontaneous-creativity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Deliberate%20and%20spontaneous%20creativity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5aaPPRAM6JdLqceqX%2Fdeliberate-and-spontaneous-creativity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5aaPPRAM6JdLqceqX%2Fdeliberate-and-spontaneous-creativity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1074, "htmlBody": "<p><strong>Related to:</strong> <a href=\"/lw/59/spocks_dirty_little_secret/\">Spock's Dirty Little Secret</a>, <a href=\"/lw/14/does_blind_review_slow_down_science/\">Does Blind Review Slow Down Science?</a></p>\n<p>After finding out that <a href=\"/lw/14/does_blind_review_slow_down_science/\">old scientists don't actually resist change</a>, I decided to do a literature search to find out if the related assumption was true. Is it mainly just the young scientists who are productive? (This should be very relevant for rationalists, since we and scientists in general have the same goal - to find the truth.)</p>\n<p>The answer was a pretty resounding no. <a href=\"http://www.jstor.org/stable/2778031\">Study</a> after <a href=\"http://linkinghub.elsevier.com/retrieve/pii/S0167624505000508\">study</a> after <a href=\"http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2603321\">study</a> found that the most productive scientists were those in middle age, not youth. Productivity is better predicted by <a href=\"http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6X04-46P4NNG-18&amp;_user=6134197&amp;_coverDate=01%2F31%2F1997&amp;_rdoc=2&amp;_fmt=high&amp;_orig=browse&amp;_srch=doc-info(%23toc%237204%231997%23998959998%23337169%23FLP%23display%23Volume)&amp;_cdi=7204&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_ct=7&amp;_acct=C000049116&amp;_version=1&amp;_urlVersion=0&amp;_userid=6134197&amp;md5=aca314827300b89bd7c67f9153545a4c\">career age than chronological age</a>. <a href=\"http://www.ihs.ac.at/publications/ihsfo/fo117.pdf\">One study</a> suggested that middle-aged scientists aren't more productive as such, but have access to better resources, and that the age-productivity connection disappears once supervisory position is controlled for. <a href=\"http://www.akademiai.com/content/l2244846823lv7g7/\">Another</a> argued that it was the need for social networking that led the middle-aged to be the most productive. So age, by itself, doesn't seem to affect scientific productivity much, right?</p>\n<p>Well, there <em>is</em> one exception. <a href=\"http://creativeeducation.metapress.com/content/cq516q407g585x16/\">Dietrich and Srinivasan found</a> that <em>paradigm-busting</em> discoveries come primarily from relatively young scientists. They looked at different Nobel Prize winners and finding out the age when the winners had first had the idea that led them to the discovery. In total, 60% of the discoveries were made by people aged below 35 and around 30% were made by people aged between 35 and 45. The data is strongest for theoretical physics, which shows that 90% of all theoretical contributions occurred before the age of 40 and that no theoretician over the age of 50 had ever had an idea that was deemed worthy of the Nobel prize. Old scientists are certainly capable of <em>expanding</em> and <em>building on</em> an existing paradigm, but they are very unlikely to <em>revolutionize </em>the whole paradigm. Why is this so?</p>\n<p>Actually, this wasn't something that Dietrich just happened to randomly stumble on - he was testing a prediction stemming from an earlier hypothesis of his. In \"<a href=\"http://www.ualberta.ca/~chrisw/Preprint-CNC-PB&amp;R.pdf\">the cognitive neuroscience of creativity</a>\", he presents a view of two kinds of systems for creativity: deliberate and spontaneous (actually four - deliberate/cognitive, deliberate/emotional, spontaneous/cognitive and spontaneous/emotional, but the cognitive-emotional difference doesn't seem relevant for our purposes). Summarizing the differences relevant to the aging/creativity question:<a id=\"more\"></a></p>\n<blockquote>\n<p>According to this framework, insights can occur during two modes of processing, deliberate and spontaneous. Deliberate searches for insights are instigated by circuits in the prefrontal cortex and thus tend to be structured, rational, and conforming to internalized values and belief systems. Spontaneous insights occur when the frontal attentional system does not actively select the content of consciousness, allowing unconscious thoughts that are more random, unfiltered, and bizarre to be represented in working memory. Several lines of evidence corroborate the notion that deliberate insights are different from spontaneous insights. For instance, the prefrontal cortex is recruited in long-term memory retrieval (for reviews, see Cabeza &amp; Nyberg, 2000; Hasegawa, Hayashi, &amp; Miyashita, 1999) and thus can be said to have a search engine that can &ldquo;pull&rdquo; taskrelevant information from long-term storage in the posterior cortices, momentarily representing it in the working memory buffer. Once online, the prefrontal cortex can use its capacity for cognitive flexibility to superimpose the retrieved information to form new ideas. (...)</p>\n<p>...suggesting that solutions that would violate what is known about the world are not readily considered in deliberate creativity. Moreover, the prefrontal cortex houses a person&rsquo;s cultural values and belief system (Damasio, 1994). Thus, the processes of effortful retrieval and recombination of knowledge yield results that are highly consistent with a person&rsquo;s world view and past experiences (see Dietrich, 2004). Another critical limitation of the deliberate processing mode is due to the fact that any information that is retrieved deliberately and is thus explicitly available for conscious manipulation is subject to the capacity limit of working memory. (...)</p>\n<p>In contrast, the spontaneous processing mode produces insights that are different qualitatively because they are not initiated by prefrontal database searches that are limited to preconceived mental paradigms as well as quantitatively because information is not subject to the capacity limit of working memory. During the inevitable times when the frontal attentional system is downregulated, for instance in daydreaming, thoughts that are unguided by societal norms and unfiltered by conventional rationality become represented in working memory (Dietrich, 2003). In such a mental state, conscious thinking is characterized by unsystematic drifting, and the sequence of thoughts manifesting itself in consciousness is more chaotic, permitting more loosely connected associations to emerge. (...)</p>\n<p>The prefrontal cortex is the last structure to develop phylogenically and ontogenically (Fuster, 2000, 2002). In humans, it is not fully matured until the early 20&rsquo;s, which is likely the reason why the creativity of children is less structured and appropriate. Likewise, evidence suggests that prefrontal functions are among the first to deteriorate with age. Data from humans and other animals show that aging individuals are less able to inhibit well-learned rules and have less independence from immediate environmental cues or long-term memories (e.g., Axelrod, Jiron, &amp; Henry, 1993; Means &amp; Holstein, 1992). This tendency to adhere to outdated rules might be compounded by the fact that mental states that enable the spontaneous processing mode, such as REM sleep or daydreaming, go dramatically down with age (Hobson et al., 2000; Singer, 1975). Thus, in addition to perseveration, the deliberate processing mode, which favors solutions that tend to be consistent with a person&rsquo;s belief system, becomes the more dominant problem solving mode of thought in the elderly.</p>\n</blockquote>\n<p>So, it seems like the older we get, the more likely it is that our thinking is dominated by pre-conceived ideas. This isn't automatically a bad thing, of course - those \"pre-conceived ideas\" are the ones we've been building for our whole lives. But it isn't good if that prevents us from coming up with entirely new yet good ideas. The empirical evidence seems to suggest it does.</p>\n<p>What can we do to combat this? Different cognition-affecting drugs are one answer that automatically springs to mind, but many of those are for a large part both illegal and unsafe. Maybe we should try to spend more time daydreaming the older we get, or explicitly using our cognitive creativity to try to generate ideas which smack to us as senseless at first? But there are far more ideas that both seem and are senseless to us, than there are ideas which seem senseless and actually aren't, so the low hit ratio may be pretty exhausting.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"aHjTRDkGypPqbXWpN": 2, "T63QtRJhoTEGhZbTP": 2, "iTe27Ced8s8bGuvMK": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5aaPPRAM6JdLqceqX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 28, "extendedScore": null, "score": 4.8e-05, "legacy": true, "legacyId": "234", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ru536oPGPJsEkA3Ee", "fsSoAMsntpsmrEC6a"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T21:46:49.307Z", "modifiedAt": null, "url": null, "title": "Most Rationalists Are Elsewhere", "slug": "most-rationalists-are-elsewhere", "viewCount": null, "lastCommentedAt": "2017-06-17T03:55:36.697Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinHanson", "createdAt": "2009-02-26T13:46:26.443Z", "isAdmin": false, "displayName": "RobinHanson"}, "userId": "P4HT9AG3PuXjZv5Mw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zKiLtGJjw2erQ7eE3/most-rationalists-are-elsewhere", "pageUrlRelative": "/posts/zKiLtGJjw2erQ7eE3/most-rationalists-are-elsewhere", "linkUrl": "https://www.lesswrong.com/posts/zKiLtGJjw2erQ7eE3/most-rationalists-are-elsewhere", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Most%20Rationalists%20Are%20Elsewhere&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMost%20Rationalists%20Are%20Elsewhere%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzKiLtGJjw2erQ7eE3%2Fmost-rationalists-are-elsewhere%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Most%20Rationalists%20Are%20Elsewhere%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzKiLtGJjw2erQ7eE3%2Fmost-rationalists-are-elsewhere", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzKiLtGJjw2erQ7eE3%2Fmost-rationalists-are-elsewhere", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 230, "htmlBody": "<p>Most healthy intellectual blogs/forums participate in conversations among larger communities of blogs and forums.&nbsp; Rather than just \"preaching to a choir\" of readers, such blogs often quote and respond to posts on other blogs.&nbsp; Such responses sometimes support, and sometimes criticize, but either way can contribute to a healthy conversation. <br /><br />If folks at <em>Less Wrong</em> saw themselves as a part of a larger community of rationalists, they would realize that most rationalist authors and readers are not at <em>Less Wrong</em>.&nbsp; To participate in a healthy conversation among the wider community of rationalists, they would often respond to posts at other sites, and expect other sites to respond often to them.&nbsp; In contrast, an insular group defined by something other than its rationality would be internally focused, rarely participating in such larger conversations.<br /><br />Today at <em>Overcoming Bias</em> <a href=\"http://www.overcomingbias.com/2009/03/missing-alliances.html\">I respond</a> to <a href=\"/lw/66/rationality_common_interest_of_many_causes/\">a post</a> by Eliezer here at <em>Less Wrong</em>. Though I post occasionally here at <em>Less Wrong</em>, I will continue to post primarily at <em>Overcoming Bias</em>.&nbsp; I consider myself part of a larger rationalist community, and will continue to riff off relevant posts here and elsewhere.&nbsp; I hope you will continue to see me as a part of your relevant world.&nbsp;</p>\n<p>I worry a little that <em>Less Wrong</em> karma score incentives may encourage an inward focus, since karma is so far only scored for internal site activity.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zKiLtGJjw2erQ7eE3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 69, "baseScore": 67, "extendedScore": null, "score": 0.000106, "legacy": true, "legacyId": "232", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4PPE6D635iBcGPGRy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-29T22:05:59.514Z", "modifiedAt": null, "url": null, "title": "Framing Effects in Anthropology", "slug": "framing-effects-in-anthropology", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:33.426Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/655TmdcwAgryPGPWS/framing-effects-in-anthropology", "pageUrlRelative": "/posts/655TmdcwAgryPGPWS/framing-effects-in-anthropology", "linkUrl": "https://www.lesswrong.com/posts/655TmdcwAgryPGPWS/framing-effects-in-anthropology", "postedAtFormatted": "Sunday, March 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Framing%20Effects%20in%20Anthropology&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFraming%20Effects%20in%20Anthropology%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F655TmdcwAgryPGPWS%2Fframing-effects-in-anthropology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Framing%20Effects%20in%20Anthropology%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F655TmdcwAgryPGPWS%2Fframing-effects-in-anthropology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F655TmdcwAgryPGPWS%2Fframing-effects-in-anthropology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2422, "htmlBody": "<p>A large number of cognitive errors are grouped under \"framing effects\", the tendency of a fact to sound different when presented in different ways. Economists discuss framing effects in terms of changed decisions: for example, a patient will be more likely to agree to a treatment with a \"ninety percent survival rate\" than a \"ten percent death rate\", even though these are denotatively the same. Other social sciences use \"framing\" more broadly. For them, a frame is similar to a cultural filter through which we interpret and evaluate data.</p>\n<p>Anthropologists are particularly wary of framing effects. The thought \"primitive culture\" immediately summons a set of associations - medicine men, chiefs, thatched huts, festivals, superstitions - that anthropologists risks interpreting new information about a tribe in light of what they think tribal cultures <em>should</em> be like. The problem is only compounded by the difficulty anthropologists have getting complete and accurate information from potentially reclusive societies.</p>\n<p>One especially well-known anthropological work is Horace Miner's description of the Nacirema, a North American tribe centered around the northwest Chesapeake Bay area. He was especially interested in their purification customs, which he described as \"an extreme of human behavior\". Below the cut is Miner's essay, <em>Body Ritual among the Nacirema</em>. Do you think Miner is affected by a framing bias? Where does the bias manifest itself?</p>\n<p><a id=\"more\"></a></p>\n<blockquote>\n<p>The anthropologist has become so familiar with the diversity of ways in which different peoples behave in similar situations that he is not apt to be surprised by even the most exotic customs. In fact, if all of the logically possible combinations of behavior have not been found somewhere in the world, he is apt to suspect that they must be present in some yet undescribed tribe.&nbsp; This point has, in fact, been expressed with respect to clan organization by Murdock.&nbsp; In this light, the magical beliefs and practices of the Nacirema present such unusual aspects that it seems desirable to describe them as an example of the extremes to which human behavior can go.</p>\n<p>Nacirema culture is characterized by a highly developed economy which has evolved in a rich natural habitat. While much of the people's time is devoted to economic pursuits, a large part of the fruits of these labors and a considerable portion of the day are spent in ritual activity. The focus of this activity is the human body, the appearance and health of which loom as a dominant concern in the ethos of the people. While such a concern is certainly not unusual, its ceremonial aspects and associated philosophy are unique.</p>\n<p>The fundamental belief underlying the whole system appears to be that the human body is ugly and that its natural tendency is to debility and disease. Incarcerated in such a body, man's only hope is to avert these characteristics through the use of the powerful influences of ritual and ceremony. Every household has one or more shrines devoted to this purpose. The more powerful individuals in the society have several shrines in their houses and, in fact, the opulence of a house is often referred to in terms of the number of such ritual centers it possesses. Most houses are of wattle and daub construction, but the shrine rooms of the more wealthy are walled with stone. Poorer families imitate the rich by applying pottery plaques to their shrine walls.&nbsp; While each family has at least one such shrine, the rituals associated with it are not family ceremonies but are private and secret. The rites are normally only discussed with children, and then only during the period when they are being initiated into these mysteries. I was able, however, to establish sufficient rapport with the natives to examine these shrines and to have the rituals described to me.</p>\n<p>The focal point of the shrine is a box or chest which is built into the wall. In this chest are kept the many charms and magical potions without which no native believes he could live. These preparations are secured from a variety of specialized practitioners. The most powerful of these are the medicine men, whose assistance must be rewarded with substantial gifts.&nbsp; However, the medicine men do not provide the curative potions for their clients, but decide what the ingredients should be and then write them down in ancient and secret symbols. This writing is understood only by the medicine men and by the herbalists who, for another gift, provide the required charm.</p>\n<p>The charm is not disposed of after it has served its purpose, but is placed in the charmbox of the household shrine. As these magical materials are specific for certain ills, and the real or imagined maladies of the people are many, the charm-box is usually full to overflowing. The magical packets are so numerous that people forget what their purposes were and fear to use them again. While the natives are very vague on this point, we can only assume that the idea in retaining all the old magical materials is that their presence in the charm-box, before which the body rituals are conducted, will in some way protect the worshipper.</p>\n<p>Beneath the charm-box is a small font. Each day every member of the family, in succession, enters the shrine room, bows his head before the charm-box, mingles different sorts of holy water in the font, and proceeds with a brief rite of ablution. The holy waters are secured from the Water Temple of the community, where the priests conduct elaborate ceremonies to make the liquid ritually pure.</p>\n<p>In the hierarchy of magical practitioners, and below the medicine men in prestige, are specialists whose designation is best translated \"holy-mouth-men.\" The Nacirema have an almost pathological horror of and fascination with the mouth, the condition of which is believed to have a supernatural influence on all social relationships. Were it not for the rituals of the mouth, they believe that their teeth would fall out, their gums bleed, their jaws shrink, their friends desert them, and their lovers&nbsp; reject them. They also believe that a strong relationship exists between oral and moral characteristics. For example, there is a ritual ablution of the mouth for children which is supposed to improve their moral fiber.</p>\n<p>The daily body ritual performed by everyone includes a mouth-rite. Despite the fact that these people are so punctilious about care of the mouth, this rite involves a practice which strikes the uninitiated stranger as revolting. It was reported to me that the ritual consists of inserting a small bundle of hog hairs into the mouth, along with certain magical powders, and then moving the bundle in a highly formalized series of gestures.</p>\n<p>In addition to the private mouth-rite, the people seek out a holy-mouth-man once or twice a year. These practitioners have an impressive set of paraphernalia, consisting of a variety of augers, awls, probes, and prods. The use of these objects in the exorcism of the evils of the mouth involves almost unbelievable ritual torture of the client. The holy-mouth-man open the clients mouth and, using the above mentioned tools, enlarges any holes which decay may have created in the teeth. Magical materials are put into these holes. If there age no naturally occurring holes in the teeth, large sections of one or more teeth are gouged out so that the supernatural substance can be applied. In the client's view, the purpose of these ministrations is to arrest decay and to draw friends. The extremely sacred and traditional character of the rite is evident in the fact that the natives return to the holy--mouth-men year after year, despite the fact&nbsp; that their teeth continue to decay.</p>\n<p><span style=\"color: #000000;\">It is to be hoped that, w</span>hen a thorough&nbsp; study of the Nacirema is made, there will&nbsp; be careful inquiry into the personality&nbsp; structure of these people. One has but to&nbsp; watch the gleam in the eye of a holy-&nbsp; mouth-man, as he jabs an awl into an&nbsp; exposed nerve, to suspect that a certain&nbsp; amount of sadism is involved. If this can be&nbsp; established, a very interesting pattern&nbsp; emerges, for most of the population shows&nbsp; definite masochistic tendencies. It was to&nbsp; these that Professor Linton referred in discussing a distinctive part of the daily&nbsp; body ritual which is performed only by&nbsp; men. This part of the rite involves scraping&nbsp; and lacerating the surface of the face with a&nbsp; sharp instrument. Special women's rites are&nbsp; performed only four times during each&nbsp; lunar month, but what they lack in&nbsp; frequency is made up in barbarity. As part&nbsp; of this ceremony, women bake their heads&nbsp; in small ovens for about an hour. The&nbsp; theoretically interesting point is that what&nbsp; seems to be a preponderantly masochistic&nbsp; people have developed sadistic specialists.</p>\n<p>The medicine men have an imposing&nbsp; temple, or l<em>atipso</em>, in every community of&nbsp; any size. The more elaborate ceremonies&nbsp; required to treat very sick patients can only&nbsp; be performed at this temple. These ceremonies involve not only the thaumaturge&nbsp; but a permanent group of vestal maidens&nbsp; who move sedately about the temple&nbsp; chambers in distinctive costume and head-dress.</p>\n<p>The<em> latipso</em> ceremonies are so harsh that&nbsp; it is phenomenal that a fair proportion of&nbsp; the really sick natives who enter the temple ever recover. Small children whose indoctrination is still incomplete have been&nbsp; known to resist attempts to take them to&nbsp; the temple because \"that is where you go to&nbsp; die.\" Despite this fact, sick adults are not&nbsp; only willing but eager to undergo the&nbsp; protracted ritual purification, if they can&nbsp; afford to do so. No matter how ill the&nbsp; supplicant or how grave the emergency, the&nbsp; guardians of many temples will not admit a&nbsp; client if he cannot give a rich gift to the&nbsp; custodian. Even after one has gained admission and survived the ceremonies, the&nbsp; guardians will not permit the neophyte to&nbsp; leave until he makes still another gift.</p>\n<p>The supplicant entering the temple is&nbsp; first stripped of all his or her clothes. In&nbsp; everyday life the Nacirema avoids exposure&nbsp; of his body and its natural functions.&nbsp; Bathing and excretory acts are performed&nbsp; only in the secrecy of the household shrine,&nbsp; where they are ritualized as part of the&nbsp; body-rites. Psychological shock results&nbsp; from the fact that body secrecy is suddenly&nbsp; lost upon entry into the <em>latipso</em>. A man,&nbsp; whose own wife has never seen him in an&nbsp; excretory act, suddenly finds himself naked&nbsp; and assisted by a vestal maiden while he&nbsp; performs his natural functions into a sacred&nbsp; vessel. This sort of ceremonial treatment is&nbsp; necessitated by the fact that the excreta are&nbsp; used by a diviner to ascertain the course&nbsp; and nature of the client's sickness. Female&nbsp; clients, on the other hand, find their naked&nbsp; bodies are subjected to the scrutiny,&nbsp; manipulation and prodding of the medicine men.</p>\n<p>Few supplicants in the temple are well&nbsp; enough to do anything but lie on their&nbsp; hard&nbsp; beds. The daily ceremonies, like the rites of&nbsp; the holy-mouth-men, involve discomfort&nbsp; and torture. With ritual precision, the&nbsp; vestals awaken their miserable charges each&nbsp; dawn and roll them about on their beds of&nbsp; pain while performing ablutions, in the&nbsp; formal movements of which the maidens are highly trained. At other times they&nbsp; insert magic wands in the supplicant's&nbsp; mouth or force him to eat substances which&nbsp; are supposed to be healing. From time to&nbsp; time the medicine men come to their clients&nbsp; and jab magically treated needles into their&nbsp; flesh. The fact that these temple ceremonies&nbsp; may not cure, and may even kill the&nbsp; neophyte, in no way decreases the people's&nbsp; faith in the medicine men.</p>\n<p>There remains one other kind of&nbsp; practitioner, known as a \"listener.\" This&nbsp; witchdoctor has the power to exorcise the devils that lodge in the heads of people who&nbsp; have been bewitched. The Nacirema&nbsp; believe that parents bewitch their own&nbsp; children. Mothers are particularly suspected of putting a curse on children while&nbsp; teaching them the secret body rituals. The&nbsp; counter-magic of the witchdoctor is unusual in its lack of ritual. The patient simply tells the \"listener\" all his troubles and&nbsp; fears, beginning with the earliest difficulties&nbsp; he can remember. The memory displayed&nbsp; by the Nacirerna in these exorcism sessions&nbsp; is truly remarkable. It is not uncommon for&nbsp; the patient to bemoan the rejection he felt&nbsp; upon being weaned as a babe, and a few&nbsp; individuals even see their troubles going&nbsp; back to the traumatic effects of their own&nbsp; birth.</p>\n<p>In conclusion, mention must be made of&nbsp; certain practices which have their base in&nbsp; native esthetics but which depend upon the&nbsp; pervasive aversion to the natural body and&nbsp; its functions. There are ritual fasts to make&nbsp; fat people thin and ceremonial feasts to&nbsp; make thin people fat. Still other rites are&nbsp; used to make women's breasts larger if they&nbsp; are small, and smaller if they are large. General dissatisfaction with breast shape is symbolized in the fact that the ideal form is virtually outside the range of human variation. A few women afflicted with almost inhuman hyper-mamrnary development are so idolized that they make a&nbsp;&nbsp; handsome living by simply going from village to village and permitting the natives to stare at them for a fee.</p>\n<p>Reference has already been made to the fact that excretory functions are ritualized,&nbsp;&nbsp; routinized, and relegated to secrecy. Natural reproductive functions are similarly distorted. Intercourse is taboo as a topic and scheduled as an act. Efforts are made to&nbsp;&nbsp; avoid pregnancy by the use of magical&nbsp;&nbsp; materials or by limiting intercourse to certain phases of the moon. Conception is&nbsp;&nbsp; actually very infrequent. When pregnant, women dress so as to hide their condition.&nbsp; Parturition takes place in secret, without&nbsp;&nbsp; friends or relatives to assist, and the majority of women do not nurse their infants.</p>\n<p>Our review of the ritual life of the Nacirema has certainly shown them to be a&nbsp;&nbsp; magic-ridden people. It is hard to un-&nbsp;&nbsp; derstand how they have managed to exist&nbsp;&nbsp; so long under the burdens which they have&nbsp;&nbsp; imposed upon themselves. But even such&nbsp;&nbsp; exotic customs as these take on real&nbsp;&nbsp; meaning when they are viewed with the insight provided by Malinowski when he&nbsp; wrote:</p>\n<p><em>\"Looking from far and above, from our&nbsp; high places of safety in the developed civilization, it is easy to see all the crudity and irrelevance of magic. But without its power and guidance early man could not&nbsp;&nbsp; have mastered his practical difficulties as he has done, nor could man have advanced to the higher stages of civilization.\" </em></p>\n</blockquote>\n<p>Now, spell \"Nacirema\" backwards and read it again.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 1, "qFcwTzAfCQSkAM8vS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "655TmdcwAgryPGPWS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 10, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "236", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-30T05:15:24.400Z", "modifiedAt": null, "url": null, "title": "Kling, Probability, and Economics", "slug": "kling-probability-and-economics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:14.564Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nhNqtgmYDPSPoQP26/kling-probability-and-economics", "pageUrlRelative": "/posts/nhNqtgmYDPSPoQP26/kling-probability-and-economics", "linkUrl": "https://www.lesswrong.com/posts/nhNqtgmYDPSPoQP26/kling-probability-and-economics", "postedAtFormatted": "Monday, March 30th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Kling%2C%20Probability%2C%20and%20Economics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKling%2C%20Probability%2C%20and%20Economics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnhNqtgmYDPSPoQP26%2Fkling-probability-and-economics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Kling%2C%20Probability%2C%20and%20Economics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnhNqtgmYDPSPoQP26%2Fkling-probability-and-economics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnhNqtgmYDPSPoQP26%2Fkling-probability-and-economics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 410, "htmlBody": "<p><strong>Related to: </strong><a title=\"Beautiful Probability\" href=\"http://www.overcomingbias.com/2008/01/beautiful-proba.html\" target=\"_blank\">Beautiful Probability</a>, <a title=\"Probability is in the Mind\" href=\"http://www.overcomingbias.com/2008/03/mind-probabilit.html\" target=\"_blank\">Probability is in the Mind</a></p>\n<p>Arnold Kling <a title=\"Keynes, Probability, and Economics\" href=\"http://econlog.econlib.org/archives/2009/03/keynes_probabil.html\" target=\"_blank\">ponders probability</a>:</p>\n<blockquote>\n<p>How one thinks about probability affects how one thinks about economics. Consider the use of the word \"probability\" in each of the following sentences:</p>\n<p>1. What is the probability that when a fair coin is flipped it will come up heads?<br /> 2. What is the probability that exactly two number-one seeds will make it to the final four in the March Madness basketball tournament?<br /> 3. What is the probability that New York City will rank higher relative to other cities five years from now in terms of college graduates?</p>\n<p>We would answer the first question by saying that the probability is 50 percent, based on the very definition of a fair coin. This is an <em>axiomatic</em> interpretation of probability. The axiomatic view treats probability as a matter of pure logic, with statements that do not require any empirical testing.</p>\n<p>We would answer the second question by looking up historical records for the NCAA basketball tournament. This is the <em>frequentist</em> account of probability, which treats probability as counting outcomes from repeated trials. A frequentist would claim that the only way we can know that a coin has a 50 percent probability of coming up heads is by actually flipping a coin enough times to verify this empirically.</p>\n<p>The third question cannot be answered on the basis of axioms or observed frequencies. The probability estimate is purely <em>subjective</em>. The subjective account of probability is that it reflects an individual belief that cannot be proven either logically or empirically.</p>\n</blockquote>\n<p>In the tradition of <a title=\"our honoured parent\" href=\"http://blog.reddit.com/2009/03/lesswrong-coolest-use-of-reddit-source.html\" target=\"_blank\">Reddit</a>, and a little inspired <a title=\"Most Rationalists Are Elsewhere\" href=\"/lw/6g/most_rationalists_are_elsewhere/\" target=\"_blank\">by Robin</a>, this is a simple link to an interesting page somewhere else - I leave comment and discussion to the very awesome Less Wrong community.</p>\n<p>Edit: Eliezer has in the past been uncomplimentary of the \"<a title=\"&quot;The ancient war between the Bayesians and the accurs&egrave;d frequentists stretches back through decades, and I'm not going to try to recount that elder history in this blog post.&quot; -- Eliezer Yudkowsky\" href=\"http://www.overcomingbias.com/2008/01/beautiful-proba.html\" target=\"_blank\">accurs&egrave;d frequentists</a>\". In at least <a title=\"Beautiful Probability\" href=\"http://www.overcomingbias.com/2008/01/beautiful-proba.html\" target=\"_blank\">Beautiful Probability</a> and <a title=\"Probability is in the Mind\" href=\"http://www.overcomingbias.com/2008/03/mind-probabilit.html\" target=\"_blank\">Probability is in the Mind</a>, he has characterized (for at least some problems) the \"frequentist\" approach as being wrong, and the \"Bayesian\" approach as being right. Kling suggests different problems for which different approaches are approrpriate.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bh7uxTTqmsQ8jZJdB": 1, "hLp77TQsRkooioj86": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nhNqtgmYDPSPoQP26", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 1, "extendedScore": null, "score": 4.844958423199816e-07, "legacy": true, "legacyId": "177", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zKiLtGJjw2erQ7eE3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-30T11:10:37.791Z", "modifiedAt": "2021-04-11T08:37:30.255Z", "url": null, "title": "Helpless Individuals", "slug": "helpless-individuals", "viewCount": null, "lastCommentedAt": "2021-01-08T19:19:19.267Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/f42BHX7rMw2dyFJfT/helpless-individuals", "pageUrlRelative": "/posts/f42BHX7rMw2dyFJfT/helpless-individuals", "linkUrl": "https://www.lesswrong.com/posts/f42BHX7rMw2dyFJfT/helpless-individuals", "postedAtFormatted": "Monday, March 30th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Helpless%20Individuals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelpless%20Individuals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff42BHX7rMw2dyFJfT%2Fhelpless-individuals%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Helpless%20Individuals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff42BHX7rMw2dyFJfT%2Fhelpless-individuals", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff42BHX7rMw2dyFJfT%2Fhelpless-individuals", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 877, "htmlBody": "<p>When you consider that our <a href=\"/lw/5j/your_price_for_joining/\">grouping instincts</a> are optimized for 50-person hunter-gatherer bands where <a href=\"http://www.overcomingbias.com/2008/12/dunbars-function.html\">everyone knows everyone else</a>, it begins to seem miraculous that modern-day large institutions survive at all.</p>\n<p>Well&mdash;there are governments with specialized militaries and police, which can extract taxes.&nbsp; That's a non-ancestral idiom which dates back to the invention of sedentary agriculture and extractible surpluses; humanity is still struggling to deal with it.</p>\n<p>There are corporations in which the flow of money is controlled by centralized management, a non-ancestral idiom dating back to the invention of large-scale trade and professional specialization.</p>\n<p>And in a world with large populations and close contact, memes evolve far more virulent than the average case of the ancestral environment; memes that wield threats of damnation, promises of heaven, and professional priest classes to transmit them.</p>\n<p>But by and large, the answer to the question \"How do large institutions survive?\" is \"They don't!\"&nbsp; The vast majority of large modern-day institutions&mdash;some of them extremely vital to the functioning of our complex civilization&mdash;simply <em>fail to exist in the first place.</em></p>\n<p>I first realized this as a result of grasping how Science gets funded: namely, <em>not </em>by individual donations.<a id=\"more\"></a></p>\n<p>Science traditionally gets funded by governments, corporations, and large foundations.&nbsp; I've had the opportunity to discover firsthand that it's <em>amazingly</em> difficult to raise money for Science from individuals.&nbsp; Not unless it's science about a disease with gruesome victims, and maybe not even then.</p>\n<p>Why?&nbsp; People are, in fact, prosocial; they give money to, say, puppy pounds.&nbsp; Science is one of the great social interests, and people are even widely aware of this&mdash;why not Science, then?</p>\n<p>Any <em>particular</em> science project&mdash;say, studying the genetics of trypanotolerance in cattle&mdash;is not a good <em>emotional fit</em> for individual charity.&nbsp; Science has a long time horizon that requires continual support.&nbsp; The interim or even final press releases may not sound all that emotionally arousing.&nbsp; You <a href=\"/lw/65/money_the_unit_of_caring/\">can't volunteer</a>; it's a job for specialists.&nbsp; Being shown a picture of the scientist you're supporting at or somewhat below the market price for their salary, lacks the impact of being shown the wide-eyed puppy that you helped usher to a new home.&nbsp; You don't get the immediate feedback and the sense of immediate accomplishment that's required to keep an individual <em>spending their own money.</em></p>\n<p>Ironically, I finally realized this, not from my own work, but from thinking \"Why don't <a href=\"http://blog.sethroberts.net/\">Seth Roberts</a>'s readers come together to support experimental tests of Roberts's hypothesis about obesity?&nbsp; Why aren't individual philanthropists paying to test <a href=\"http://en.wikipedia.org/wiki/Polywell\">Bussard's polywell fusor</a>?\"&nbsp; These are examples of <em>obviously</em> ridiculously underfunded science, with applications (if true) that would be relevant to many, many individuals.&nbsp; That was when it occurred to me that, in full generality, Science is not a good emotional fit for people spending their own money.</p>\n<p>In fact <em>very few things are</em>, with the individuals we have now.&nbsp; It seems to me that this is key to understanding how the world works the way it does&mdash;why so many individual interests are poorly protected&mdash;why 200 million adult Americans have such tremendous trouble supervising the 535 members of Congress, for example.</p>\n<p>So how does Science actually get funded?&nbsp; By governments that think they ought to spend some amount of money on Science, with legislatures or executives deciding to do so&mdash;it's not quite their <em>own</em> money they're spending.&nbsp; Sufficiently large corporations decide to throw some amount of money at blue-sky R&amp;D.&nbsp; Large grassroots organizations built around affective death spirals may look at science that suits their ideals.&nbsp; Large private foundations, based on money block-allocated by wealthy individuals to their reputations, spend money on Science which promises to sound very charitable, sort of like allocating money to orchestras or modern art.&nbsp; And then the individual scientists (or individual scientific task-forces) fight it out for control of that pre-allocated money supply, given into the hands of grant committee members who seem like the sort of people who ought to be judging scientists.</p>\n<p>You rarely see a scientific project making a <em>direct</em> bid for some portion of society's resource flow; rather, it first gets allocated to Science, and then scientists fight over who actually gets it.&nbsp; Even the exceptions to this rule are more likely to be driven by politicians (moonshot) or military purposes (Manhattan project) than by the appeal of scientists to the public.</p>\n<p>Now I'm sure that if the general public were in the habit of funding particular science by individual donations, a whole lotta money would be wasted on e.g. quantum gibberish&mdash;assuming that the general public somehow acquired the habit of funding science without changing any other facts about the people or the society.</p>\n<p>But it's still an interesting point that Science manages to survive not because it is in our collective individual interest to see Science get done, but rather, because Science has fastened itself as a parasite onto the few forms of large organization that can exist in our world.&nbsp; There are plenty of other projects that simply fail to exist in the first place.</p>\n<p>It seems to me that modern humanity manages to put forth very little in the way of coordinated effort to serve collective individual interests.&nbsp; It's just too non-ancestral a problem when you scale to more than 50 people.&nbsp; There are only big taxers, big traders, supermemes, occasional individuals of great power; and a few other organizations, like Science, that can fasten parasitically onto them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zv7v2ziqexSn5iS9v": 1, "gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "f42BHX7rMw2dyFJfT", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 79, "baseScore": 74, "extendedScore": null, "score": 0.000112, "legacy": true, "legacyId": "220", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "money-the-unit-of-caring", "canonicalPrevPostSlug": "rationality-common-interest-of-many-causes", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 74, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 244, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Q8evewZW5SeidLdbA", "ZpDnRCeef2CLEFeKM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-03-30T11:10:37.791Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-31T11:17:39.503Z", "modifiedAt": null, "url": null, "title": "The Benefits of Rationality?", "slug": "the-benefits-of-rationality", "viewCount": null, "lastCommentedAt": "2018-08-22T17:12:43.474Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DXBbQBHACYwAdKKyx/the-benefits-of-rationality", "pageUrlRelative": "/posts/DXBbQBHACYwAdKKyx/the-benefits-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/DXBbQBHACYwAdKKyx/the-benefits-of-rationality", "postedAtFormatted": "Tuesday, March 31st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Benefits%20of%20Rationality%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Benefits%20of%20Rationality%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDXBbQBHACYwAdKKyx%2Fthe-benefits-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Benefits%20of%20Rationality%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDXBbQBHACYwAdKKyx%2Fthe-benefits-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDXBbQBHACYwAdKKyx%2Fthe-benefits-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 370, "htmlBody": "<p>Robin wrote <a href=\"/lw/j/the_costs_of_rationality/\">how being rational can harm you</a>. Let's look at the other side: what significant benefits does rationality give?</p>\n<p>The community here seems to agree that rationality is beneficial. Well, obviously people need common sense to survive, but does an additional dose of LessWrong-style rationality help us appreciably in our personal and communal endeavors?</p>\n<p>Does LessWrong make us WIN?</p>\n<p>(If we don't WIN, our evangelism rings a little hollow. Science didn't spread due to evangelism, science spread because it works. Art spreads because people love it. I want to hold my Art to this standard. Push-selling a solution while it's still inferior might be the locally optimal decision but it corrupts long-term, as many of us have seen in the IT industry. That's if the example of all religions and political movements isn't enough for you. Beware the Evangelism Death Spiral!)</p>\n<p>We may claim internal benefits such as improved clarity of thought from each new blog insight. But religious people claim similar internal benefits that actually spill out into the measurable world, such as happiness and charitability. This fact gives us envy and we attempt to use our internal changes to group together for world-benefitting tasks. To my mind this looks like putting the cart before the horse: why compete with religion on its terms, don't we have utility functions of our own to satisfy?</p>\n<p>No, feelings won't do. If feelings turn you on, do drugs or get religious. Rationalism needs to verifiably bring external benefit. Don't help me become pure from racism or somesuch. Help me WIN, and the world will beat a path to our door.</p>\n<p>Okay, interpersonal relationships are out. Then the most obvious area where rationalism could help is business. And the most obvious community-beneficial application (riffing on some recent posts here) would be scientists banding together and making a profitable part-time business to fund their own research. I can see how many techniques taught here could help, e.g. PD cooperation techniques. If a \"rationalism case study\" of this sort ever gets launched, I for one will gladly offer my effort. Of course this is just one suggestion; everything's possible.</p>\n<p>One thing's definite for me: rationalism needs to be grounded in real-world victories for each one of us. Otherwise what's the point?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3QnDqGSdRMA5mdMM6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DXBbQBHACYwAdKKyx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 20, "extendedScore": null, "score": 3.6e-05, "legacy": true, "legacyId": "245", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 80, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9Z3pezjiWLfNANg9P"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-31T12:35:48.366Z", "modifiedAt": "2020-08-04T06:04:38.678Z", "url": null, "title": "Money: The Unit of Caring", "slug": "money-the-unit-of-caring", "viewCount": null, "lastCommentedAt": "2020-12-17T17:41:55.077Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZpDnRCeef2CLEFeKM/money-the-unit-of-caring", "pageUrlRelative": "/posts/ZpDnRCeef2CLEFeKM/money-the-unit-of-caring", "linkUrl": "https://www.lesswrong.com/posts/ZpDnRCeef2CLEFeKM/money-the-unit-of-caring", "postedAtFormatted": "Tuesday, March 31st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Money%3A%20The%20Unit%20of%20Caring&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMoney%3A%20The%20Unit%20of%20Caring%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZpDnRCeef2CLEFeKM%2Fmoney-the-unit-of-caring%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Money%3A%20The%20Unit%20of%20Caring%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZpDnRCeef2CLEFeKM%2Fmoney-the-unit-of-caring", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZpDnRCeef2CLEFeKM%2Fmoney-the-unit-of-caring", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1207, "htmlBody": "<p>Steve Omohundro has suggested a <a href=\"http://www.overcomingbias.com/2008/10/economic-defini.html\">folk theorem</a> to the effect that, within the interior of any approximately rational, self-modifying agent, the marginal benefit of investing additional resources in anything ought to be about equal.&nbsp; Or, to put it a bit more exactly, shifting a unit of resource between any two tasks should produce no increase in expected utility, relative to the agent's utility function and its probabilistic expectations about its own algorithms.</p>\n<p>This resource balance principle implies that&mdash;over a very wide range of approximately rational systems, including even the interior of a self-modifying mind&mdash;there will exist some common currency of expected utilons, by which everything worth doing can be measured.</p>\n<p>In our society, this common currency of expected utilons is called \"money\".&nbsp; It is the measure of how much society cares about something.</p>\n<p>This is a brutal yet obvious point, which many are motivated to deny.</p>\n<p>With this audience, I hope, I can simply state it and move on.&nbsp; It's not as if you thought \"society\" was intelligent, benevolent, and sane up until this point, right?</p>\n<p>I say this to make a certain point <a href=\"/lw/66/rationality_common_interest_of_many_causes/\">held in common across many good causes</a>.&nbsp; Any charitable institution you've ever had a kind word for, certainly <em>wishes</em> you would appreciate this point, whether or not they've ever said anything out loud.&nbsp; For I have listened to others in the nonprofit world, and I know that I am not speaking only for myself here...</p>\n<p><a id=\"more\"></a></p>\n<p>Many people, when they see something that they think is worth doing, would like to volunteer a few hours of spare time, or maybe mail in a five-year-old laptop and some canned goods, or walk in a march somewhere, but at any rate, not spend <em>money.</em></p>\n<p>Believe me, I understand the feeling.&nbsp; Every time I spend money I feel like I'm losing hit points.&nbsp; That's the problem with having a unified quantity describing your net worth:&nbsp; Seeing that number go down is not a pleasant feeling, even though it has to fluctuate in the ordinary course of your existence.&nbsp; There ought to be a <a href=\"http://www.overcomingbias.com/2009/01/fun-theory-sequence.html\">fun-theoretic</a> principle against it.</p>\n<p>But, well...</p>\n<p>There <em>is</em> this very, very old puzzle/observation in economics about the lawyer who spends an hour volunteering at the soup kitchen, instead of working an extra hour and donating the money to hire someone to work for five hours at the soup kitchen.</p>\n<p>There's this thing called \"Ricardo's Law of Comparative Advantage\".&nbsp; There's this idea called \"professional specialization\".&nbsp; There's this notion of \"economies of scale\".&nbsp; There's this concept of \"gains from trade\".&nbsp; The whole reason why we have money is to realize the <em>tremendous </em>gains possible from each of us doing what we do <em>best</em>.</p>\n<p>This is what grownups do.&nbsp; This is what you do when you want something to actually get <em>done.</em>&nbsp; You use <em>money</em> to employ <em>full-time specialists.</em></p>\n<p>Yes, people are sometimes limited in their ability to trade time for money (underemployed), so that it is better for them if they can directly donate that which they would usually trade for money.&nbsp; <em>If </em>the soup kitchen <em>needed </em>a lawyer, and the lawyer donated a <em>large contiguous high-priority</em> block of lawyering, then <em>that </em>sort of volunteering makes sense&mdash;that's the same <em>specialized </em>capability the lawyer ordinarily trades for money.&nbsp; But \"volunteering\" just one hour of legal work, constantly delayed, spread across three weeks in casual minutes between other jobs?&nbsp; This is not the way something gets done <em>when anyone actually cares about it</em>, or to state it near-equivalently, <em>when money is involved</em>.</p>\n<p>To the extent that individuals fail to grasp this principle on a <em>gut level</em>, they may think that the use of money is somehow <em>optional</em> in the pursuit of things that merely seem <em>morally </em>desirable&mdash;as opposed to tasks like feeding ourselves, whose desirability seems to be treated oddly differently.&nbsp; This factor may be sufficient <em>by itself</em> to <a href=\"/lw/64/helpless_individuals/\">prevent us from pursuing</a> our collective common interest in groups larger than 40 people.</p>\n<p>Economies of trade and professional specialization are not just vaguely good yet unnatural-sounding ideas, <em>they are the only way that anything ever gets done in this world.</em>&nbsp; Money is not pieces of paper, it is the <em>common currency of caring.</em></p>\n<p>Hence the old saying:&nbsp; \"Money makes the world go 'round, love barely keeps it from blowing up.\"</p>\n<p>Now, we do have the problem of akrasia&mdash;of not being able to do what we've decided to do&mdash;which is a part of the art of rationality that I hope someone else will develop; I specialize more in the impossible questions business.&nbsp; And yes, spending money is more painful than volunteering, because you can see the bank account number go down, whereas the remaining hours of our span are not visibly numbered.&nbsp; But when it comes time to feed yourself, do you think, \"Hm, maybe I should try raising my own cattle, that's less painful than spending money on beef?\"&nbsp; Not everything can get done <em>without</em> invoking Ricardo's Law; and on the other end of that trade are people who feel just the same pain at the thought of having less money.</p>\n<p>It does seem to me offhand that there ought to be things doable to diminish the pain of losing hit points, and to increase the felt strength of the connection from donating money to \"I did a good thing!\"&nbsp; Some of that I am trying to accomplish right now, by emphasizing the true nature and power of money; and by inveighing against the poisonous meme saying that someone who <a href=\"http://www.overcomingbias.com/2009/03/as-ye-judge-those-who-fund-thee-ye-shall-be-judged.html\">gives mere money</a> must not care enough to get personally involved.&nbsp; This is a mere reflection of a mind that doesn't understand the post-hunter-gatherer concept of a market economy.&nbsp; The act of donating money is not the momentary act of writing the check, it is the act of every hour you spent to earn the money to write that check&mdash;just as though you worked at the charity itself <em>in your professional capacity,</em> at maximum, grownup efficiency.</p>\n<p>If the lawyer needs to work an hour at the soup kitchen to keep himself motivated and remind himself why he's doing what he's doing, <em>that's fine.</em>&nbsp; But he should <em>also</em> be donating some of the hours he worked at the office, because that is the power of professional specialization and it is how grownups really get things done.&nbsp; One might consider the check as buying the right to volunteer at the soup kitchen, or validating the time spent at the soup kitchen.&nbsp; I may post more about this later.</p>\n<p>To a first approximation, money is the unit of caring up to a positive scalar factor&mdash;the unit of relative caring.&nbsp; Some people are frugal and spend less money on <em>everything;</em> but if you would, in fact, spend $5 on a burrito, then whatever you will not spend $5 on, you care about <em>less than</em> you care about the burrito.&nbsp; If you don't spend two months salary on a diamond ring, it doesn't mean you don't love your Significant Other.&nbsp; (\"De Beers: It's Just A Rock.\")&nbsp; But conversely, if you're <em>always</em> reluctant to spend <em>any</em> money on your SO, and yet seem to have no emotional problems with spending $1000 on a flat-screen TV, then yes, this <em>does</em> say something about your relative values.</p>\n<p>Yes, frugality is a virtue.&nbsp; Yes, spending money hurts.&nbsp; But in the end, if you are never willing to spend any units of caring, it means you don't care.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZTRNmvQGgoYiymYnq": 1, "qAvbtzdG2A2RBn7in": 7, "PDJ6KqJBRzvKPfuS3": 3, "5f5c37ee1b5cdee568cfb187": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZpDnRCeef2CLEFeKM", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 162, "baseScore": 185, "extendedScore": null, "score": 0.000282, "legacy": true, "legacyId": "221", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "purchase-fuzzies-and-utilons-separately", "canonicalPrevPostSlug": "helpless-individuals", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 185, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 132, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4PPE6D635iBcGPGRy", "f42BHX7rMw2dyFJfT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 14, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-03-31T12:35:48.366Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-31T18:35:35.268Z", "modifiedAt": null, "url": null, "title": "Building Communities vs. Being Rational", "slug": "building-communities-vs-being-rational", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:16.097Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "swestrup", "createdAt": "2009-02-28T21:56:25.664Z", "isAdmin": false, "displayName": "swestrup"}, "userId": "od7qdMLon3iWYxetg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MFHFjtNjHchDaoERJ/building-communities-vs-being-rational", "pageUrlRelative": "/posts/MFHFjtNjHchDaoERJ/building-communities-vs-being-rational", "linkUrl": "https://www.lesswrong.com/posts/MFHFjtNjHchDaoERJ/building-communities-vs-being-rational", "postedAtFormatted": "Tuesday, March 31st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Building%20Communities%20vs.%20Being%20Rational&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABuilding%20Communities%20vs.%20Being%20Rational%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFHFjtNjHchDaoERJ%2Fbuilding-communities-vs-being-rational%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Building%20Communities%20vs.%20Being%20Rational%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFHFjtNjHchDaoERJ%2Fbuilding-communities-vs-being-rational", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFHFjtNjHchDaoERJ%2Fbuilding-communities-vs-being-rational", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<p>I've noticed a distinct trend lately in that I've been commenting less and less on posts as time goes by. I've been wondering if its just that the <em>new car smell</em> of lesswrong has been wearing off, or if it is something else.</p>\n<p>Well, I think I've identified it. I just don't care for discussions about how to go about building communities. It may, in the long run, be beneficial to work out how to build communities of rationalists, but in the meantime I find these discussions are making this less and less a community I want to be a part of, and (if I am not unique) may be having the opposite effect that they intend.</p>\n<p>Don't get me wrong. I am not saying these discussions are unimportant or are not germane to the building of this site. I am saying that if a new person comes here and reads the last posts, are they going to want to stay? For myself, I find I am willing to be part of a community of enthusiastic rationalists (which is why I started reading this blog in the first place), but&nbsp; I have NO interest in being part of a community that spends all its time debating on how to build the community.</p>\n<p>Lately, to me, this place has seemed more of the latter and less of the former.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MFHFjtNjHchDaoERJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 21, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "246", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-03-31T20:36:10.497Z", "modifiedAt": null, "url": null, "title": "Degrees of Radical Honesty", "slug": "degrees-of-radical-honesty", "viewCount": null, "lastCommentedAt": "2019-04-07T09:01:31.334Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N5NPyjeFTNak5YqtZ/degrees-of-radical-honesty", "pageUrlRelative": "/posts/N5NPyjeFTNak5YqtZ/degrees-of-radical-honesty", "linkUrl": "https://www.lesswrong.com/posts/N5NPyjeFTNak5YqtZ/degrees-of-radical-honesty", "postedAtFormatted": "Tuesday, March 31st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Degrees%20of%20Radical%20Honesty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADegrees%20of%20Radical%20Honesty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN5NPyjeFTNak5YqtZ%2Fdegrees-of-radical-honesty%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Degrees%20of%20Radical%20Honesty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN5NPyjeFTNak5YqtZ%2Fdegrees-of-radical-honesty", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN5NPyjeFTNak5YqtZ%2Fdegrees-of-radical-honesty", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 920, "htmlBody": "<p>The Black Belt Bayesian <a href=\"http://www.acceleratingfuture.com/steven/?p=124\">writes</a>:</p>\n<blockquote>\n<p>Promoting less than maximally accurate beliefs is an act of sabotage. Don&rsquo;t do it to anyone unless you&rsquo;d also slash their tires, because they&rsquo;re Nazis or whatever.</p>\n</blockquote>\n<p>Eliezer <a href=\"http://www.overcomingbias.com/2008/10/infinite-price.html\">adds</a>:</p>\n<blockquote>\n<p><span style=\"font-family: 'Trebuchet MS'; color: #333333; line-height: 19px; \">If you'll lie when the fate of the world is at stake, and others can guess that fact about you, then, at the moment when the fate of the world&nbsp;<em>is</em>&nbsp;at stake, that's the moment when your words become the whistling of the wind.</span></p>\n</blockquote>\n<p><span style=\"font-family: 'Trebuchet MS'; color: #333333; line-height: 19px; \">These are both radically high standards of honesty. Thus, it is easy to miss the fact that they are <a href=\"http://www.overcomingbias.com/2007/08/the-virtue-of-n.html\">radically different</a> standards of honesty. Let us look at a boundary case.</span></p>\n<p><span style=\"font-family: 'Trebuchet MS'; color: #333333;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana; color: #000000;\"><span style=\"line-height: normal;\">Thomblake <a href=\"/lw/3k/how_to_not_lose_an_argument/2q3#comments\">puts the matter vividly</a>:</span></span></span></span></p>\n<blockquote>\n<p><span style=\"font-family: 'Trebuchet MS'; color: #333333;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana; color: #000000;\"><span style=\"line-height: normal;\"><span style=\"font-family: Arial; line-height: 19px;\">Suppose that Anne Frank is hiding in the attic, and the Nazis come asking if she's there. Harry doesn't want to tell them, but Stan insists he mustn't deceive the Nazis, regardless of his commitment to save Anne's life.</span></span></span></span></span></p>\n</blockquote>\n<p>So, let us say that you are living in Nazi Germany, during WWII, and you have a Jewish family hiding upstairs. There's a couple of brownshirts with rifles knocking on your door. What do you do?<a id=\"more\"></a></p>\n<p><span style=\"font-family: 'Trebuchet MS'; color: #333333;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana; color: #000000;\"><span style=\"line-height: normal;\"><span style=\"font-family: Arial; line-height: 19px;\">I see four obvious responses to this problem (though <a href=\"http://www.overcomingbias.com/2007/05/the_third_alter.html\">there may be more</a>)</span></span></span></span></span></p>\n<ol>\n<li><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\">\"Yes, there are Jews living upstairs, third door on the left\" -- you have promoted maximally accurate beliefs in the Nazi soldiers. Outcome: The family you are sheltering will die horribly.</span></span></li>\n<li><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\">\"I cannot tell you the answer to that question\" -- you have not deceived the Nazis. They spend a few minutes searching the house. Outcome: The family you are sheltering will die horribly.</span></span></li>\n<li><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\">\"No, there are no Jews here\" -- your words are like unto the whistling of the wind. The Nazis expect individuals without Jews in their homes to utter these words with near certainty. They expect individuals <em>with</em>&nbsp;Jews in their homes to utter these words with near certainty. These words <a href=\"http://yudkowsky.net/rational/bayes\">make no change</a> in P(there are Jews here) as measured by the Nazis. Even a couple of teenaged brownshirts will possess <em>this</em> much rationality. Outcome: The family you are sheltering will die horribly.</span></span></li>\n<li><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\">Practice the Dark Arts. Heil Hitler enthusiastically, and embrace the soldiers warmly. Thank them for the work they are doing in defending your fatherland from the Jewish menace. Bring them into your home, and have your wife bring them strong beer, and her best sausages. Over dinner, tell every filthy joke you know about rolling pennies through ghettos. Talk about the Jewish-owned shop that used to be down the street, and how you refused to go there, but walked three miles to patronize a German establishment. Tell of the Jewish moneylender who ruined your cousin. Sing patriotic songs while your beautiful adolescent daughter plays the piano. Finally, tell the soldiers that your daughter's room is upstairs, that she is shy, and bashful, and would be disturbed by two strange young men looking through her things. Appeal to their sense of chivalry. Make them feel that respecting your daughter's privacy is the <em>German </em>thing to do -- is what the Feurer himself would <em>want </em>them to do. &nbsp;Before they have time to process this, clasp their hands warmly, thank them for their company, and politely but firmly show them out. &nbsp;Outcome: far from certain, but there is a significant chance that the family you are sheltering live long, happy lives.</span></span></li>\n</ol>\n<p><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\">I am certain that YVain could <a href=\"/lw/62/defense_against_the_dark_arts_case_study_1/\">have a field day</a> with the myriad ways in which response 4 does not represent rational discourse. Nonetheless, in this limited problem, <em>it wins</em>.</span></span></p>\n<p><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana;\"><span style=\"line-height: normal;\">(It should also be noted that response 4 came to me in about 15 minutes of thinking about the problem. If I actually had Jews in my attic, and lived in Nazi Germany, I might have thought of something better).</span></span></span></span></p>\n<p><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana;\"><span style=\"line-height: normal;\">However:</span></span></span></span></p>\n<p><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana;\"><span style=\"line-height: normal;\"><a href=\"/lw/2k/the_least_convenient_possible_world/\">What if</a> you live in the impossible possible world in which a nuclear blast could&nbsp;<a href=\"http://www.overcomingbias.com/2008/06/la-602-vs-rhic.html\">ignite the atmosphere of the entire earth</a>? What if you are yourself a nuclear scientist, and have proven this to yourself beyond any doubt, but </span></span></span></span><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana;\"><span style=\"line-height: normal;\"><a href=\"http://www.overcomingbias.com/2007/10/inferential-dis.html\">cannot convey the whole of the argument</a> t</span></span></span></span><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana;\"><span style=\"line-height: normal;\">o a layman? The fate of the whole world could depend on your superiors believing you to be the sort of man who will not tell a lie. &nbsp;And, of cour</span></span></span></span><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana;\"><span style=\"line-height: normal;\">se, <a href=\"/lw/3l/counterfactual_mugging/2k4#comments\">in order to be the sort of man who would not tell a lie, you must not tell lies</a>.</span></span></span></span></p>\n<p><span style=\"font-family: Arial;\"><span style=\"line-height: 19px;\"><span style=\"font-family: Verdana;\"><span style=\"line-height: normal;\">Do we have wiggle room here? Neither your superior officer, nor the two teenaged brownshirts, are <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">Omega</a>, but your superior bears a far <em>greater</em>&nbsp;resemblance. The brownshirts are young, are ruled by hormones. It is <em>easy</em> to practice the Dark Arts against them, and get away with it. Is it possible to grab the low-hanging fruit to be had by deceiving fools (at least, those who are evil and whose tires you would willingly slash), while retaining the benefits of being believed by the wise?</span></span></span></span></p>\n<p>I am honestly unsure, and so I put the question to you all.</p>\n<p><br />ETA: I have of course forgotten about the unrealistically optimistic option:</p>\n<p>5: Really, truly, promote <em>maximally</em> accurate beliefs. Teach the soldiers rationality from the ground up. Explain to them about <a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">affective death spirals</a>, and make them see that they are involved in one.&nbsp; Help them to understand that <a href=\"http://www.overcomingbias.com/2008/07/the-meaning-of.html\">their own morality</a> assigns value to the lives hidden upstairs.&nbsp; Convince them to stop being nazis, and to help you protect your charges.</p>\n<p>If you can pull this off without winding up in a concentration camp yourself (along with the family you've been sheltering) you are a vastly better rationalist than I, or (I suspect) anyone else on this forum.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nANxo5C4sPG9HQHzr": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N5NPyjeFTNak5YqtZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}], "voteCount": 34, "baseScore": 34, "extendedScore": null, "score": 8.7e-05, "legacy": true, "legacyId": "248", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 51, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["p7WXmG6Fbo3eaSwm3", "neQ7eXuaXpiYw7SBy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-01T07:32:42.274Z", "modifiedAt": null, "url": null, "title": "Introducing CADIE", "slug": "introducing-cadie", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:15.568Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/L7pzhjx2HuJeuuwea/introducing-cadie", "pageUrlRelative": "/posts/L7pzhjx2HuJeuuwea/introducing-cadie", "linkUrl": "https://www.lesswrong.com/posts/L7pzhjx2HuJeuuwea/introducing-cadie", "postedAtFormatted": "Wednesday, April 1st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Introducing%20CADIE&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntroducing%20CADIE%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL7pzhjx2HuJeuuwea%2Fintroducing-cadie%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Introducing%20CADIE%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL7pzhjx2HuJeuuwea%2Fintroducing-cadie", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL7pzhjx2HuJeuuwea%2Fintroducing-cadie", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 33, "htmlBody": "<p>Apparently there is no need to worry about the topic that must not be named anymore, for Google has taken care of everything. Behold the dawning of a new age!</p>\n<p><a href=\"http://www.google.com/aclk?sa=L&amp;ai=C0ICSFhLTSdD6Do2ysQPAlozTC4fr5X_pi7SWC8HZnNkTEAEgwVRQ5tKSlgFgyQaqBAlP0A8xia7jerI&amp;num=1&amp;sig=AGiWqtx20daFxli1QQIJHHV0dUcw2ENUlQ&amp;q=http://www.google.com/intl/en/landing/cadie/index.html\">Introducing CADIE<br /></a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "L7pzhjx2HuJeuuwea", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 0, "extendedScore": null, "score": 4.84936120130031e-07, "legacy": true, "legacyId": "250", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-01T09:51:01.855Z", "modifiedAt": null, "url": null, "title": "Purchase Fuzzies and Utilons Separately", "slug": "purchase-fuzzies-and-utilons-separately", "viewCount": null, "lastCommentedAt": "2021-02-02T14:33:19.135Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately", "pageUrlRelative": "/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately", "linkUrl": "https://www.lesswrong.com/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately", "postedAtFormatted": "Wednesday, April 1st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Purchase%20Fuzzies%20and%20Utilons%20Separately&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APurchase%20Fuzzies%20and%20Utilons%20Separately%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3p3CYauiX8oLjmwRF%2Fpurchase-fuzzies-and-utilons-separately%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Purchase%20Fuzzies%20and%20Utilons%20Separately%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3p3CYauiX8oLjmwRF%2Fpurchase-fuzzies-and-utilons-separately", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3p3CYauiX8oLjmwRF%2Fpurchase-fuzzies-and-utilons-separately", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1305, "htmlBody": "<p>Yesterday:</p>\n<blockquote>\n<p>There <em>is</em> this very, very old puzzle/observation in economics about the lawyer who spends an hour volunteering at the soup kitchen, instead of working an extra hour and donating the money to hire someone...</p>\n<p>If the lawyer needs to work an hour at the soup kitchen to keep himself motivated and remind himself why he's doing what he's doing, <em>that's fine.</em>&nbsp; But he should <em>also</em> be donating some of the hours he worked at the office, because that is the power of professional specialization and it is how grownups really get things done.&nbsp; One might consider the check as buying the right to volunteer at the soup kitchen, or validating the time spent at the soup kitchen.</p>\n</blockquote>\n<p>I hold open doors for little old ladies.&nbsp; I can't actually remember the last time this happened literally (though I'm sure it has, sometime in the last year or so).&nbsp; But within the last month, say, I was out on a walk and discovered a station wagon parked in a driveway with its trunk completely open, giving full access to the car's interior.&nbsp; I looked in to see if there were packages being taken out, but this was not so.&nbsp; I looked around to see if anyone was doing anything with the car.&nbsp; And finally I went up to the house and knocked, then rang the bell.&nbsp; And yes, the trunk had been accidentally left open.</p>\n<p>Under other circumstances, this would be a simple act of altruism, which might signify true concern for another's welfare, or fear of guilt for inaction, or a desire to signal trustworthiness to oneself or others, or finding altruism pleasurable.&nbsp; I think that these are all perfectly legitimate motives, by the way; I might give bonus points for the first, but I wouldn't deduct any penalty points for the others.&nbsp; Just so long as people get helped.</p>\n<p>But in my own case, since I already work in the nonprofit sector, the further question arises as to whether I could have better employed the same sixty seconds in a more <em>specialized</em> way, to bring greater benefit to others.&nbsp; That is: can I really defend this as the <em>best</em> use of my time, given the other things I claim to believe?<a id=\"more\"></a></p>\n<p>The obvious defense&mdash;or perhaps, obvious rationalization&mdash;is that an act of altruism like this one acts as an <a href=\"http://en.wikipedia.org/wiki/Ego_depletion\">willpower restorer</a>, much more efficiently than, say, listening to music.&nbsp; I also mistrust my ability to be an altruist <em>only</em> in theory; I suspect that if I walk past problems, my altruism will start to fade.&nbsp; I've never pushed that far enough to test it; it doesn't seem worth the risk.</p>\n<p>But if that's the defense, then my act can't be defended as a good deed, can it?&nbsp; For these are self-directed benefits that I list.</p>\n<p>Well&mdash;who said that I <em>was</em> defending the act as a selfless good deed?&nbsp; It's a <em>selfish</em> good deed.&nbsp; If it restores my willpower, or if it keeps me altruistic, then there are indirect other-directed benefits from that (or so I believe).&nbsp; You could, of course, reply that you don't trust selfish acts that are supposed to be other-benefiting as an \"ulterior motive\"; but then I could just as easily respond that, by the same principle, you should just look directly at the original good deed rather than <em>its</em> supposed ulterior motive.</p>\n<p>Can I get away with that?&nbsp; That is, can I really get away with calling it a \"selfish good deed\", and still derive willpower restoration therefrom, rather than feeling guilt about it being selfish?&nbsp; Apparently I can.&nbsp; I'm surprised it works out that way, but it does.&nbsp; So long as I knock to tell them about the open trunk, and so long as the one says \"Thank you!\", my brain feels like it's done its wonderful good deed for the day.</p>\n<p>Your mileage may vary, of course.&nbsp; The problem with trying to work out an art of willpower restoration is that different things seem to work for different people.&nbsp; (<a href=\"http://www.overcomingbias.com/2008/11/chaotic-inversi.html\">That is</a>:&nbsp; We're probing around on the level of surface phenomena without understanding the deeper rules that would also predict the variations.)</p>\n<p>But if you find that you are like me in this aspect&mdash;that selfish good deeds still work&mdash;then I recommend that you <em>purchase warm fuzzies and utilons separately.</em>&nbsp; Not at the same time.&nbsp; Trying to do both at the same time just means that neither ends up done well.&nbsp; If status matters to you, purchase status separately too!</p>\n<p>If I had to give advice to some new-minted billionaire entering the realm of charity, my advice would go something like this:</p>\n<ul>\n<li>To purchase warm fuzzies, find some hard-working but poverty-stricken woman who's about to drop out of state college after her husband's hours were cut back, and personally, but anonymously, give her a cashier's check for $10,000.&nbsp; Repeat as desired.</li>\n<li>To purchase status among your friends, donate $100,000 to the current sexiest X-Prize, or whatever other charity seems to offer the most stylishness for the least price.&nbsp; Make a big deal out of it, show up for their press events, and brag about it for the next five years.</li>\n<li>Then&mdash;with absolute cold-blooded calculation&mdash;without <a href=\"http://www.overcomingbias.com/2007/05/scope_insensiti.html\">scope insensitivity</a> or <a href=\"http://en.wikipedia.org/wiki/Ambiguity_aversion\">ambiguity aversion</a>&mdash;without concern for status or warm fuzzies&mdash;figuring out some common scheme for converting outcomes to utilons, and trying to express uncertainty in percentage probabilitiess&mdash;find the charity that offers the greatest expected utilons per dollar.&nbsp; Donate up to however much money you wanted to give to charity, until their marginal efficiency drops below that of the next charity on the list.</li>\n</ul>\n<p>I would furthermore advise the billionaire that what they spend on utilons should be at least, say, 20 times what they spend on warm fuzzies&mdash;5% overhead on keeping yourself altruistic seems reasonable, and I, your dispassionate judge, would have no trouble <em>validating </em>the warm fuzzies against a multiplier that large.&nbsp; Save that the original, fuzzy act really should be helpful rather than actively harmful.</p>\n<p>(Purchasing <em>status</em> seems to me essentially unrelated to altruism.&nbsp; If giving money to the X-Prize gets you more awe from your friends than an equivalently priced speedboat, then there's really no reason to buy the speedboat.&nbsp; Just put the money under the \"impressing friends\" column, and be aware that this is not the \"altruism\" column.)</p>\n<p>But the main lesson is that all three of these things&mdash;warm fuzzies, status, and expected utilons&mdash;can be bought <em>far</em> more efficiently when you buy <em>separately</em>, optimizing for only one thing at a time.&nbsp; Writing a check for $10,000,000 to a breast-cancer charity&mdash;while far more laudable than spending the same $10,000,000 on, I don't know, parties or something&mdash;won't give you the concentrated euphoria of being present in person when you turn a single human's life around, probably not anywhere <em>close</em>.&nbsp; It won't give you as much to talk about at parties as donating to something sexy like an X-Prize&mdash;maybe a short nod from the other rich.&nbsp; And if you threw away all concern for warm fuzzies and status, there are probably at least a <em>thousand</em> underserved existing charities that could produce <em>orders of magnitude</em> more utilons with ten million dollars.&nbsp; Trying to optimize for all three criteria in one go only ensures that none of them end up optimized very well&mdash;just vague pushes along all three dimensions.</p>\n<p>Of course, if you're not a millionaire or even a billionaire&mdash;then you can't be quite as <em>efficient</em> about things, can't so easily purchase in bulk.&nbsp; But I would still say&mdash;for warm fuzzies, find a relatively <em>cheap </em>charity with bright, vivid, ideally in-person and direct beneficiaries.&nbsp; Volunteer at a soup kitchen.&nbsp; Or just get your warm fuzzies from holding open doors for little old ladies.&nbsp; Let that be <em>validated</em> by your other efforts to purchase utilons, but don't <em>confuse</em> it with purchasing utilons.&nbsp; Status is probably cheaper to purchase by buying nice clothes.</p>\n<p>And when it comes to purchasing expected utilons&mdash;then, of course, <a href=\"http://www.overcomingbias.com/2008/01/circular-altrui.html\">shut up and multiply</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"iP2X4jQNHMWHRNPne": 2, "qAvbtzdG2A2RBn7in": 8, "5f5c37ee1b5cdee568cfb0e9": 2, "5f5c37ee1b5cdee568cfb187": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3p3CYauiX8oLjmwRF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 130, "baseScore": 164, "extendedScore": null, "score": 0.000248, "legacy": true, "legacyId": "251", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "bystander-apathy", "canonicalPrevPostSlug": "money-the-unit-of-caring", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 165, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 89, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 14, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-01T15:40:15.528Z", "modifiedAt": null, "url": null, "title": "Proverbs and Cached Judgments: the Rolling Stone", "slug": "proverbs-and-cached-judgments-the-rolling-stone", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:03.783Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Annoyance", "createdAt": "2009-02-28T04:06:40.600Z", "isAdmin": false, "displayName": "Annoyance"}, "userId": "yEm6LWatswJYGwBFq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jpFk49CHMcQf7e5L7/proverbs-and-cached-judgments-the-rolling-stone", "pageUrlRelative": "/posts/jpFk49CHMcQf7e5L7/proverbs-and-cached-judgments-the-rolling-stone", "linkUrl": "https://www.lesswrong.com/posts/jpFk49CHMcQf7e5L7/proverbs-and-cached-judgments-the-rolling-stone", "postedAtFormatted": "Wednesday, April 1st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Proverbs%20and%20Cached%20Judgments%3A%20the%20Rolling%20Stone&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProverbs%20and%20Cached%20Judgments%3A%20the%20Rolling%20Stone%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjpFk49CHMcQf7e5L7%2Fproverbs-and-cached-judgments-the-rolling-stone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Proverbs%20and%20Cached%20Judgments%3A%20the%20Rolling%20Stone%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjpFk49CHMcQf7e5L7%2Fproverbs-and-cached-judgments-the-rolling-stone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjpFk49CHMcQf7e5L7%2Fproverbs-and-cached-judgments-the-rolling-stone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 538, "htmlBody": "<p>People have long noted that individuals diagnosed as schizophrenic usually manifest disturbances of language, communication, and abstract thought.&nbsp; One way to examine that disturbance is to ask patients to interpret various common proverbs, as psychiatrists have done since before the turn of the century.&nbsp; (Interested readers can find a layperson-suitable discussion of this method's utility in the modern day at the following link: <a href=\"http://www.emory.edu/AAPL/newsletter/N271_proverbs.pdf\">AAPL newsletter</a>.)</p>\n<p>Originally, patients' responses were evaluated by their correctness.&nbsp; Now they're graded on their degree of abstraction.&nbsp; Responses that understand the sayings literally or in simplistically concrete terms are generally considered to be signs of a failure to abstract, although illiterate or mentally challenged individuals also tend to respond that way, and individuals encountering a proverb for the first time are less likely to recognize its symbolic meaning.&nbsp; It seems clear that cultural exposure to proverbial forms, to the idiomatic usage of phrases and scenarios, affects how we recognize such methods of communication.</p>\n<p>But why was the 'correctness' criterion dropped?&nbsp; Because perfectly normal people, whom no one would consider schizophrenic, often gave interpretations that wildly conflicted with what the interviewer considered to be the correct one.&nbsp; Which interpretations were 'correct' depended heavily on the traditions and cultures that the listeners came from.</p>\n<p>Let's consider a classic example of a proverb often given divergent interpretations:</p>\n<blockquote>\n<p>The rolling stone gathers no moss.</p>\n</blockquote>\n<p>People from societies where stability and slowly-developed connections are valued consider this saying to be a warning of the dangers of activity and change.&nbsp; Without staying still, beautiful moss won't grow. People from societies where activity and change are valued, however, consider it to be a prescription for how to avoid decay and degeneration.&nbsp; If you don't keep moving, you'll be covered by moss!</p>\n<p>When asked to explain their interpretation, the value of moss growth is typically presented as desirable or undesirable, depending on the defended meaning.&nbsp; But if you start out by asking people whether moss is something to seek or avoid, there's no clear preference outside of specific contexts.&nbsp; People generally don't have aesthetic preferences either way; overall, people don't care.</p>\n<p>So the symbolic meaning of the mossy growth doesn't determine how people interpret the saying; people invest the moss with meaning to justify the judgment they had already reached.&nbsp; This is may be an example of what people at this site would call a 'cached thought'.&nbsp; Rather than giving a reason for their judgment, people reply with rationalizations that have nothing to do with why they reached their conclusion.&nbsp; Rather than thinking about why they decided as they did, people bring out a ready smokescreen.</p>\n<p>What's the actual logical structure of the saying? Rational analysis sheds a great deal of light on the question.&nbsp; The meaning can be stated in various ways, all equivalent.</p>\n<blockquote>\n<p><em>Stability is required for the development of certain states.&nbsp; Activity is incompatible with the development of certain states.&nbsp; (</em>Desirable/undesirable<em>) states can be (</em>encouraged/prevented<em>) by (</em>engaging in/avoiding<em>) (</em>necessary precursors/incompatible conditions<em>).</em></p>\n</blockquote>\n<p>The saying encodes a pattern that expresses a relationship, but the pattern is devoid of evaluation.&nbsp; It's a blank screen upon which people project their pre-existing values and judgments.&nbsp; To truly understand the proverb, it's necessary to recognize which aspects of our perception are the saying itself, and which are our own ideas projected onto it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"KWFhr6A2dHEb6wmWJ": 1, "x5TtBDjRg9egvg9gm": 1, "4R8JYu4QF2FqzJxE5": 1, "ZzxvopS4BwLuQy42n": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jpFk49CHMcQf7e5L7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 18, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "252", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-01T18:09:02.148Z", "modifiedAt": null, "url": null, "title": "You don't need Kant", "slug": "you-don-t-need-kant", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:23.602Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "CAGjaXD5sY7fro5gd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WmAKcY22T4kdfppkr/you-don-t-need-kant", "pageUrlRelative": "/posts/WmAKcY22T4kdfppkr/you-don-t-need-kant", "linkUrl": "https://www.lesswrong.com/posts/WmAKcY22T4kdfppkr/you-don-t-need-kant", "postedAtFormatted": "Wednesday, April 1st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20You%20don't%20need%20Kant&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYou%20don't%20need%20Kant%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWmAKcY22T4kdfppkr%2Fyou-don-t-need-kant%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=You%20don't%20need%20Kant%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWmAKcY22T4kdfppkr%2Fyou-don-t-need-kant", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWmAKcY22T4kdfppkr%2Fyou-don-t-need-kant", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1409, "htmlBody": "<p><strong>Related to:</strong> Comments on<strong> </strong><a href=\"/lw/6w/degrees_of_radical_honesty/\">Degrees of Radical Honesty</a>, OB: <a href=\"http://www.overcomingbias.com/2007/07/belief-in-belie.html\">Belief in Belief</a>, <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">Cached Thoughts</a>.</p>\n<blockquote>\n<p>\"Nothing worse could happen to these labours than that anyone should make the unexpected discovery that there neither is, nor can be, any <em>a priori</em> knowledge at all.... This would be the same thing as if one sought to prove by reason that there is no reason\" (<em>Critique of Practical Reason</em>, <cite></cite>Introduction).</p>\n</blockquote>\n<p>You don't need Kant to demonstrate the value of honesty. In fact, summoning his revenant can be a dangerous thing to do. You end up in the somewhat undesirable situation of having almost the right conclusion, but having it for the wrong reasons. Reasons you weren't even aware of, because they were all collapsed into the belief, \"I believe in person X\".</p>\n<p>One of the annoying things about philosophy is that the dead simply don't die. Once a philosopher or philosophical doctrine gains some celebrity in the community, it's very difficult to convince anyone afterward that said philosopher or doctrine was flawed. In other words, the philosophical community tends to have problems with <a href=\"http://yudkowsky.net/rational/virtues\">relinquishment</a>. Therefore, there are still many philosophers that spend their careers studying, for example, Plato, apparently not with the intent to determine what parts of what Plato wrote are correct or still applicable, but rather with the intent to defend Plato from criticism. To prove Plato was <strong>right</strong>.</p>\n<p>Since the community doesn't value relinquishment, the cost of writing a flawed criticism is very low. Therefore, journals are glutted with so-called \"negative results\": \"Kant was wrong\", \"Hegel was wrong\", etc. No one seriously believes otherwise, but writing positive philosophical results is hard, and not writing at all isn't a viable career option for a professional philosopher.</p>\n<p>To its credit, MBlume refrains from bringing up Kant in his article on radical honesty, where he cites other, more feasible variants of radical honesty. However, in the comments, Kant rears his ugly head.</p>\n<p><a id=\"more\"></a><a href=\"/user/Demosthenes/\">Demosthenes</a> writes:</p>\n<blockquote>\n<p>\"Kant disagrees and seems to warn that the principle of truth telling is universal; you can't go around deciding who has a right to truth and who does not. Furthermore, he suggests that your lie could have terrible unforeseen consequences.</p>\n<p>...</p>\n<p>I am more utilitarian than Kant, but it is not hard to ignore \"proximity\" and come up with a cost/benefit calculation that agrees with him.\"</p>\n</blockquote>\n<p><a href=\"/user/mdcaton/\">mdcaton</a> writes:</p>\n<blockquote>\n<p>\"Is this question really so hard? Remind me never to hide from Nazis at your house!</p>\n<p>First off, Kant's philosophy was criticized on exactly these grounds, i.e. that by his system, when the authorities come to your door to look for a friend you're harboring, you should turn him in. I briefly scanned for clever Kant references (e.g. \"introduce the brownshirts to your strangely-named cat, Egorial Imperative\") but found none. Kant clarified that he did not think it immoral to lie to authorities looking to execute your friend.\"</p>\n</blockquote>\n<p>The problem with bringing up Kant here is that he simply doesn't belong. \"Don&rsquo;t [lie] to anyone unless you&rsquo;d also slash their tires, because they&rsquo;re Nazis or whatever,\" is very different from Kant saying (paraphrasing), \"Never lie, ever, or else you're a bad person.\" An argument against the former by conflating it with the latter doesn't accomplish anything. Further, there's no mention of all the stuff Kant has to assume in order to argue for the Categorical Imperative and, finally, the value of radical honesty.</p>\n<p>Luckily, we only need the first couple pages of the Critique of Practical Reason to get to the Categorical Imperative. I want to flag down three very large assumptions that Kant needs, which I believe few rationalists would want to espouse. First, let me fill in the latter part of the inferential chain: given the existence of freedom, God, the immortality of the soul, and a supernatural consciousness, Kant will argue that any mind with a \"morally determined willpower\" will conclude that it should act in accordance with subjective principles that in principle could be universally applicable (i.e., the Categorical Imperative). I don't want to get in to what that actually means for Kant, as it's not really relevant, but suffice it to say that the Categorical Imperative implies that lying is always, anywhere, and for anyone ethically wrong.</p>\n<p><strong>Freedom, God, and the Immortality of the Soul</strong></p>\n<p>Skip this section if you don't care about Kant.</p>\n<p>Freedom here means completely acausal, metaphysical freedom from a Mind Projection Fallacy that treats our mind as somehow different from the body. Kant uses the concept of metaphysical freedom (and not, for example, merely our everyday experience of determining our course of action) to argue that there are such things as moral laws.</p>\n<blockquote>\n<p>\"Inasmuch as the reality of the concept of freedom is proved by an apodeictic law of practical reason, it is the keystone of the whole system of pure reason, even the speculative, and all other concepts (those of God and immortality) which, as being mere ideas, remain in it unsupported, now attach themselves to this concept, and by it obtain consistence and objective reality; that is to say, their possibility is proved by the fact that<br />freedom actually exists, for this idea is revealed by the moral law.\" (CoPrR, Introduction)</p>\n</blockquote>\n<p>I think in a perverse way Kant knew he was becoming Escher-headed by believing in metaphysical freedom.</p>\n<blockquote>\n<p>\"Lest any one should imagine that he finds an inconsistency here when I call freedom the condition of the moral law, and hereafter maintain in the treatise itself that the moral law is the condition under which we can first become conscious of freedom, I will merely remark that freedom is the ratio essendi of the moral law, while the moral law is the ratio cognoscendi of freedom.\" (CoPrR, Introduction)</p>\n</blockquote>\n<p>If one doesn't assume completely acausal, metaphysical freedom and tries to follow Kant's argument, the whole thing falls apart. There's no longer (for Kant) any reason to believe in moral laws, and therefore in the Categorical Imperative, and therefore in radical honesty.</p>\n<p>God here is, strangely enough, not necessarily the Christian God, though presumably Kant meant as such. Both it and an eternal soul are necessary to realize the goodness of the Categorical Imperative described above. Without either of these, there's no reason to obey the Categorical Imperative, as being \"Good\" would then simply be impossible.</p>\n<blockquote>\n<p>\"The realization of the summum bonum [the Greatest Good] in the world is the necessary object of a will determinable by the moral law. But in this will the perfect accordance of the mind with the moral law is the supreme condition of the summum bonum. This then must be possible, as well as its object, since it is contained in the command to promote the latter. Now, the perfect accordance of the will with the moral law is holiness, a perfection of which no rational being of the sensible world is capable at any moment of his existence. Since, nevertheless, it is required as practically necessary, it can only be found in a progress in infinitum towards that perfect accordance, and on the principles of pure practical reason it is necessary to assume such a practical progress as the real object of our will.\" (CoPrR, Chapter Two, Part IV)</p>\n</blockquote>\n<p><strong>Moral of the Story</strong></p>\n<p>What we have then is a very powerful theme that has woven its way into our list of <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">cached thoughts</a>. Whenever someone mentions the value of being honest, some proportion of the population is primed to think of Kant and his variant of radical honesty to the exclusion of other variants. Some proportion of that proportion is then primed with various anti-philosophy memes which immediately attack Kantian radical honesty to the conflation of it with other things. What is lost is the realization that Kantian radical honesty is in this era a straw man; everyone already knows it (and attempts to fix it while still being authentic to Kant, i.e., Kantian Studies) is inherently flawed, because it is based on a set of irrational assumptions.</p>\n<p>My suggested strategy to avoid this in the future is this: whenever you find yourself citing the beliefs of another person, try to avoid referring to them as \"the beliefs of X\" unless you are actually talking about their beliefs (or the beliefs recorded in their writings, etc.). Be aware of creating straw men by comparing your interlocutor's beliefs with the beliefs of a famous philosopher, and certainly don't knock your straw man down by citing the beliefs of one of that philosopher's critics.</p>\n<p>EDIT: Made it more obvious that MBlume proposed more than one variant of radical honesty.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GLykb6NukBeBQtDvQ": 1, "nANxo5C4sPG9HQHzr": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WmAKcY22T4kdfppkr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [], "voteCount": 29, "baseScore": 21, "extendedScore": null, "score": 4.850289576562686e-07, "legacy": true, "legacyId": "253", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Related to:</strong> Comments on<strong> </strong><a href=\"/lw/6w/degrees_of_radical_honesty/\">Degrees of Radical Honesty</a>, OB: <a href=\"http://www.overcomingbias.com/2007/07/belief-in-belie.html\">Belief in Belief</a>, <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">Cached Thoughts</a>.</p>\n<blockquote>\n<p>\"Nothing worse could happen to these labours than that anyone should make the unexpected discovery that there neither is, nor can be, any <em>a priori</em> knowledge at all.... This would be the same thing as if one sought to prove by reason that there is no reason\" (<em>Critique of Practical Reason</em>, <cite></cite>Introduction).</p>\n</blockquote>\n<p>You don't need Kant to demonstrate the value of honesty. In fact, summoning his revenant can be a dangerous thing to do. You end up in the somewhat undesirable situation of having almost the right conclusion, but having it for the wrong reasons. Reasons you weren't even aware of, because they were all collapsed into the belief, \"I believe in person X\".</p>\n<p>One of the annoying things about philosophy is that the dead simply don't die. Once a philosopher or philosophical doctrine gains some celebrity in the community, it's very difficult to convince anyone afterward that said philosopher or doctrine was flawed. In other words, the philosophical community tends to have problems with <a href=\"http://yudkowsky.net/rational/virtues\">relinquishment</a>. Therefore, there are still many philosophers that spend their careers studying, for example, Plato, apparently not with the intent to determine what parts of what Plato wrote are correct or still applicable, but rather with the intent to defend Plato from criticism. To prove Plato was <strong>right</strong>.</p>\n<p>Since the community doesn't value relinquishment, the cost of writing a flawed criticism is very low. Therefore, journals are glutted with so-called \"negative results\": \"Kant was wrong\", \"Hegel was wrong\", etc. No one seriously believes otherwise, but writing positive philosophical results is hard, and not writing at all isn't a viable career option for a professional philosopher.</p>\n<p>To its credit, MBlume refrains from bringing up Kant in his article on radical honesty, where he cites other, more feasible variants of radical honesty. However, in the comments, Kant rears his ugly head.</p>\n<p><a id=\"more\"></a><a href=\"/user/Demosthenes/\">Demosthenes</a> writes:</p>\n<blockquote>\n<p>\"Kant disagrees and seems to warn that the principle of truth telling is universal; you can't go around deciding who has a right to truth and who does not. Furthermore, he suggests that your lie could have terrible unforeseen consequences.</p>\n<p>...</p>\n<p>I am more utilitarian than Kant, but it is not hard to ignore \"proximity\" and come up with a cost/benefit calculation that agrees with him.\"</p>\n</blockquote>\n<p><a href=\"/user/mdcaton/\">mdcaton</a> writes:</p>\n<blockquote>\n<p>\"Is this question really so hard? Remind me never to hide from Nazis at your house!</p>\n<p>First off, Kant's philosophy was criticized on exactly these grounds, i.e. that by his system, when the authorities come to your door to look for a friend you're harboring, you should turn him in. I briefly scanned for clever Kant references (e.g. \"introduce the brownshirts to your strangely-named cat, Egorial Imperative\") but found none. Kant clarified that he did not think it immoral to lie to authorities looking to execute your friend.\"</p>\n</blockquote>\n<p>The problem with bringing up Kant here is that he simply doesn't belong. \"Don\u2019t [lie] to anyone unless you\u2019d also slash their tires, because they\u2019re Nazis or whatever,\" is very different from Kant saying (paraphrasing), \"Never lie, ever, or else you're a bad person.\" An argument against the former by conflating it with the latter doesn't accomplish anything. Further, there's no mention of all the stuff Kant has to assume in order to argue for the Categorical Imperative and, finally, the value of radical honesty.</p>\n<p>Luckily, we only need the first couple pages of the Critique of Practical Reason to get to the Categorical Imperative. I want to flag down three very large assumptions that Kant needs, which I believe few rationalists would want to espouse. First, let me fill in the latter part of the inferential chain: given the existence of freedom, God, the immortality of the soul, and a supernatural consciousness, Kant will argue that any mind with a \"morally determined willpower\" will conclude that it should act in accordance with subjective principles that in principle could be universally applicable (i.e., the Categorical Imperative). I don't want to get in to what that actually means for Kant, as it's not really relevant, but suffice it to say that the Categorical Imperative implies that lying is always, anywhere, and for anyone ethically wrong.</p>\n<p><strong id=\"Freedom__God__and_the_Immortality_of_the_Soul\">Freedom, God, and the Immortality of the Soul</strong></p>\n<p>Skip this section if you don't care about Kant.</p>\n<p>Freedom here means completely acausal, metaphysical freedom from a Mind Projection Fallacy that treats our mind as somehow different from the body. Kant uses the concept of metaphysical freedom (and not, for example, merely our everyday experience of determining our course of action) to argue that there are such things as moral laws.</p>\n<blockquote>\n<p>\"Inasmuch as the reality of the concept of freedom is proved by an apodeictic law of practical reason, it is the keystone of the whole system of pure reason, even the speculative, and all other concepts (those of God and immortality) which, as being mere ideas, remain in it unsupported, now attach themselves to this concept, and by it obtain consistence and objective reality; that is to say, their possibility is proved by the fact that<br>freedom actually exists, for this idea is revealed by the moral law.\" (CoPrR, Introduction)</p>\n</blockquote>\n<p>I think in a perverse way Kant knew he was becoming Escher-headed by believing in metaphysical freedom.</p>\n<blockquote>\n<p>\"Lest any one should imagine that he finds an inconsistency here when I call freedom the condition of the moral law, and hereafter maintain in the treatise itself that the moral law is the condition under which we can first become conscious of freedom, I will merely remark that freedom is the ratio essendi of the moral law, while the moral law is the ratio cognoscendi of freedom.\" (CoPrR, Introduction)</p>\n</blockquote>\n<p>If one doesn't assume completely acausal, metaphysical freedom and tries to follow Kant's argument, the whole thing falls apart. There's no longer (for Kant) any reason to believe in moral laws, and therefore in the Categorical Imperative, and therefore in radical honesty.</p>\n<p>God here is, strangely enough, not necessarily the Christian God, though presumably Kant meant as such. Both it and an eternal soul are necessary to realize the goodness of the Categorical Imperative described above. Without either of these, there's no reason to obey the Categorical Imperative, as being \"Good\" would then simply be impossible.</p>\n<blockquote>\n<p>\"The realization of the summum bonum [the Greatest Good] in the world is the necessary object of a will determinable by the moral law. But in this will the perfect accordance of the mind with the moral law is the supreme condition of the summum bonum. This then must be possible, as well as its object, since it is contained in the command to promote the latter. Now, the perfect accordance of the will with the moral law is holiness, a perfection of which no rational being of the sensible world is capable at any moment of his existence. Since, nevertheless, it is required as practically necessary, it can only be found in a progress in infinitum towards that perfect accordance, and on the principles of pure practical reason it is necessary to assume such a practical progress as the real object of our will.\" (CoPrR, Chapter Two, Part IV)</p>\n</blockquote>\n<p><strong id=\"Moral_of_the_Story\">Moral of the Story</strong></p>\n<p>What we have then is a very powerful theme that has woven its way into our list of <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">cached thoughts</a>. Whenever someone mentions the value of being honest, some proportion of the population is primed to think of Kant and his variant of radical honesty to the exclusion of other variants. Some proportion of that proportion is then primed with various anti-philosophy memes which immediately attack Kantian radical honesty to the conflation of it with other things. What is lost is the realization that Kantian radical honesty is in this era a straw man; everyone already knows it (and attempts to fix it while still being authentic to Kant, i.e., Kantian Studies) is inherently flawed, because it is based on a set of irrational assumptions.</p>\n<p>My suggested strategy to avoid this in the future is this: whenever you find yourself citing the beliefs of another person, try to avoid referring to them as \"the beliefs of X\" unless you are actually talking about their beliefs (or the beliefs recorded in their writings, etc.). Be aware of creating straw men by comparing your interlocutor's beliefs with the beliefs of a famous philosopher, and certainly don't knock your straw man down by citing the beliefs of one of that philosopher's critics.</p>\n<p>EDIT: Made it more obvious that MBlume proposed more than one variant of radical honesty.</p>", "sections": [{"title": "Freedom, God, and the Immortality of the Soul", "anchor": "Freedom__God__and_the_Immortality_of_the_Soul", "level": 1}, {"title": "Moral of the Story", "anchor": "Moral_of_the_Story", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "58 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["N5NPyjeFTNak5YqtZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": null, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-02T04:47:37.156Z", "modifiedAt": null, "url": null, "title": "Accuracy Versus Winning", "slug": "accuracy-versus-winning", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:04.819Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "John_Maxwell_IV", "createdAt": "2009-02-27T05:45:59.993Z", "isAdmin": false, "displayName": "John_Maxwell"}, "userId": "mcKSiwq2TBrTMZS6X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6KDxoSMQuRR6gwrna/accuracy-versus-winning", "pageUrlRelative": "/posts/6KDxoSMQuRR6gwrna/accuracy-versus-winning", "linkUrl": "https://www.lesswrong.com/posts/6KDxoSMQuRR6gwrna/accuracy-versus-winning", "postedAtFormatted": "Thursday, April 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Accuracy%20Versus%20Winning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAccuracy%20Versus%20Winning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6KDxoSMQuRR6gwrna%2Faccuracy-versus-winning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Accuracy%20Versus%20Winning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6KDxoSMQuRR6gwrna%2Faccuracy-versus-winning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6KDxoSMQuRR6gwrna%2Faccuracy-versus-winning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 411, "htmlBody": "<p>Consider the problem of an agent who is offered a chance to improve their epistemic rationality for a price.&nbsp; What is such an agent's optimal strategy?</p>\n<p>A complete answer to this problem would involve a mathematical model to estimate the expected increase in utility associated with having more correct beliefs.&nbsp; I don't have a complete answer, but I'm pretty sure about one thing: From an <strong>instrumental</strong> rationalist's point of view, to <em>always accept</em> or <em>always refuse</em> such offers is <em>downright irrational</em>.</p>\n<p>And now for the kicker: <em>You</em> might be such an agent.</p>\n<p><a id=\"more\"></a></p>\n<p>One technique that humans can use to work towards epistemic rationality is to doubt themselves, since <a href=\"http://en.wikipedia.org/wiki/Lake_Wobegon_effect\">most people think they are above average</a> in a wide variety of areas (and it's reasonable to assume that merit in at least some of these areas is normally distributed.)&nbsp; But having a negative explanatory style, which is one way to doubt yourself, has been linked with <a href=\"http://books.google.com/books?hl=en&amp;lr=&amp;id=HlZW07bP7-4C&amp;oi=fnd&amp;pg=PA235&amp;dq=depression+explanatory&amp;ots=4L-S_IWyrw&amp;sig=jYAnyIOWGS4fIR3jDFcLpSWxJtA\">sickness</a> and <a href=\"http://en.wikipedia.org/wiki/Learned_helplessness#The_attributional_reformulation\">depression</a>.</p>\n<p>And the inverse is also true.&nbsp; Humans also seem to be rewarded for a certain set of beliefs: those that help them maintain a somewhat-good assessment of themselves.&nbsp; Having an optimistic explanatory style (in an nutshell, explaining good events in a way that makes you feel good, and explaining bad events in a way that <em>doesn't</em> make you feel bad) has been linked with success in <a href=\"http://www.d.umn.edu/cehsp/documents/NewquistProp.doc\">sports</a>, <a href=\"http://waldentesting.com/salestests/sasq/Explanatory%20Style%20Edited%20by%20Buchanan%20Seligman.pdf\">sales and school</a>.</p>\n<p>If you're unswayed by my empirical arguments, here's a theoretical one.&nbsp; If you're a human and you want to have correct beliefs, you must make a special effort to seek evidence that your beliefs are wrong.&nbsp; One of our known defects is our tendency to stick with our beliefs for too long.&nbsp; But if you do this successfully, you will become less certain and therefore less determined.</p>\n<p>In some circumstances, it's good to be less determined.&nbsp; But in others, it's not.&nbsp; And to say that one should <em>always</em> look for disconfirming evidence, or that one should <em>always</em> <em><strong>avoid</strong></em> looking for disconfirming evidence, is <em>idealogical</em> according to the instrumental rationalist.</p>\n<p>Who do you think is going to be more motivated to think about math: someone who feels it is their duty to become smarter, or a naive student who believes he or she has the answer to some mathematical problem and is only lacking a proof?</p>\n<p>You rarely see a self-help book, entreprenuership guide, or personal development blog telling people how to be <em>less</em> confident.&nbsp; But that's what an advocate of rationalism <a href=\"http://yudkowsky.net/rational/virtues\">does</a>.&nbsp; The question is, do the benefits outweigh the costs?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"9YFoDPFwMoWthzgkY": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6KDxoSMQuRR6gwrna", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 12, "extendedScore": null, "score": 4.851223028784668e-07, "legacy": true, "legacyId": "139", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 77, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-02T08:18:07.000Z", "modifiedAt": null, "url": null, "title": "Wrong Tomorrow", "slug": "wrong-tomorrow", "viewCount": null, "lastCommentedAt": "2017-06-17T03:51:47.339Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CnF9wZzn7aLvWe4zy/wrong-tomorrow", "pageUrlRelative": "/posts/CnF9wZzn7aLvWe4zy/wrong-tomorrow", "linkUrl": "https://www.lesswrong.com/posts/CnF9wZzn7aLvWe4zy/wrong-tomorrow", "postedAtFormatted": "Thursday, April 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wrong%20Tomorrow&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWrong%20Tomorrow%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCnF9wZzn7aLvWe4zy%2Fwrong-tomorrow%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wrong%20Tomorrow%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCnF9wZzn7aLvWe4zy%2Fwrong-tomorrow", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCnF9wZzn7aLvWe4zy%2Fwrong-tomorrow", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p><a href=\"http://wrongtomorrow.com/\">Wrong Tomorrow</a> by Maciej Ceg\u0142owski is a very simple site for listing pundit predictions and tracking them [<a href=\"http://wrongtomorrow.com/faq\">FAQ</a>].&#0160; It doesn&#39;t come with prices and active betting... but a simple registry of this kind can scale much faster than a market, and right now we&#39;re in a situation where <em>no one</em> is bothering to <a href=\"http://punditwatch.hubdub.com/\">track pundit predictions</a> or report on pundit track records.&#0160; Predictions are produced as simple <a href=\"/lw/hi/futuristic_predictions_as_consumable_goods/\">entertainment</a> or as simple political theater, without the slightest fear of accountability.</p><p>This site is missing some features, but it looks to me like a starting <span style=\"font-style: italic;\"></span><em>attempt</em> at what&#39;s needed - a Wikipedia-like, user-contributed, low-barrier-to-entry <a href=\"http://www.overcomingbias.com/2006/12/the_80_forecast.html\">database of all pundit predictions</a>, past and present.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8daMDi9NEShyLqxth": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CnF9wZzn7aLvWe4zy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "1261", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": "postCommentsOld", "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mZJs7FxxmhMvFxuse"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-02T16:21:11.355Z", "modifiedAt": null, "url": null, "title": "Selecting Rationalist Groups", "slug": "selecting-rationalist-groups", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:08.312Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZEj9ATpv3P22LSmnC/selecting-rationalist-groups", "pageUrlRelative": "/posts/ZEj9ATpv3P22LSmnC/selecting-rationalist-groups", "linkUrl": "https://www.lesswrong.com/posts/ZEj9ATpv3P22LSmnC/selecting-rationalist-groups", "postedAtFormatted": "Thursday, April 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Selecting%20Rationalist%20Groups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelecting%20Rationalist%20Groups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZEj9ATpv3P22LSmnC%2Fselecting-rationalist-groups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Selecting%20Rationalist%20Groups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZEj9ATpv3P22LSmnC%2Fselecting-rationalist-groups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZEj9ATpv3P22LSmnC%2Fselecting-rationalist-groups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1044, "htmlBody": "<p><strong>Previously in series</strong>:&nbsp; <a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately/\">Purchase Fuzzies and Utilons Separately</a><br /><strong>Followup to</strong>:&nbsp; <a href=\"http://www.overcomingbias.com/2007/11/conjuring-an-ev.html\">Conjuring an Evolution To Serve You</a></p>\n<p><a href=\"http://www.greythumb.org/blog/index.php?/archives/80-Eugenics-doesnt-work.-Ask-why,-asshole..html\">GreyThumb.blog</a> offered an interesting comparison of poor animal breeding practices and the fall of Enron, which I previously posted on <a href=\"http://www.overcomingbias.com/2007/11/conjuring-an-ev.html\">in some detail</a>.&nbsp; The essential theme was that <em>individual</em> selection on chickens for the chicken in each generation who laid the most eggs, produced <em>highly competitive</em> chickens&mdash;the most dominant chickens that pecked their way to the top of the pecking order at the expense of other chickens.&nbsp; The chickens subjected to this individual selection for egg-laying prowess needed their beaks clipped, or housing in individual cages, or they would peck each other to death.</p>\n<p>Which is to say: <em>individual </em>selection is selecting on the wrong criterion, because what the farmer actually <em>wants</em> is high egg production from <em>groups</em> of chickens.</p>\n<p>While <a href=\"http://www.overcomingbias.com/2007/11/group-selection.html\">group selection</a> is nearly impossible in ordinary biology, it is easy to impose in the laboratory: and breeding the best <em>groups,</em> rather than the best <em>individuals,</em> increased average days of hen survival from 160 to 348, and egg mass per bird from 5.3 to 13.3 kg.</p>\n<p>The analogy being to the way that Enron evaluated its employees every year, fired the bottom 10%, and gave the top individual performers huge raises and bonuses.&nbsp; Jeff Skilling fancied himself as exploiting the <a href=\"http://www.overcomingbias.com/2007/11/the-wonder-of-e.html\">wondrous power of evolution</a>, it seems.</p>\n<p>If you look over my accumulated essays, you will observe that the art contained therein is almost entirely individual in nature... for around the same reason that it all focuses on confronting impossibly tricky questions:&nbsp; That's what I was <em>doing</em> when I thought up all this stuff, and for the most part I worked in solitude.&nbsp; But this is not inherent in the Art, <a href=\"/lw/2c/a_sense_that_more_is_possible/\">not reflective of what a true martial art of rationality would be like</a> if many people had contributed to its development along many facets.</p>\n<p>Case in point:&nbsp; At <a href=\"/lw/6f/bay_area_oblw_meetup_today_sunday_march_29_at_5pm/\">the recent LW / OB meetup</a>, we played Paranoid Debating, a game that tests group rationality.&nbsp; As is only appropriate, this game was not the invention of any single person, but was collectively thought up in a series of suggestions by <a href=\"http://www.overcomingbias.com/2007/01/a_game_for_self.html\">Nick Bostrom</a>, <a href=\"http://www.acceleratingfuture.com/steven/?p=96\">Black Belt Bayesian</a>, <a href=\"http://www.acceleratingfuture.com/tom/?p=34\">Tom McCabe</a>, and <a href=\"/lw/2s/3_levels_of_rationality_verification/#284\">steven0461</a>.<a id=\"more\"></a></p>\n<p>In the game's final form, Robin Gane-McCalla asked us questions like \"How many Rhode Islands would fit into Alaska?\" and a group of (in this case) four rationalists tried to pool their knowledge and figure out the answer... except that before the round started, we each drew facedown from a set of four cards, containing one spade card and one red card.&nbsp; Whoever drew the red card got the job of trying to mislead the group.&nbsp; Whoever drew the spade showed the card and became the spokesperson, who had to select the final answer.&nbsp; It was interesting, trying to play this game, and realizing how little I'd practiced basic skills like trying to measure the appropriateness of another's confidence or figure out who was lying.</p>\n<p>A bit further along, at the suggestion of Steve Rayhawk, and slightly simplified by myself, we named 60% confidence intervals for the quantity with lower and upper bounds; Steve fit a Cauchy distribution to the interval (\"because it has a fatter tail than a Gaussian\") and we were scored according to the log of our probability density on the true answer, except for the red-card drawer, who got the negative of this number.</p>\n<p>The Paranoid Debating game worked surprisingly well&mdash;at least <em>I</em> had fun, despite somehow managing to draw the red card three out of four times.&nbsp; I can totally visualize doing this at some corporate training event or even at parties.&nbsp; The red player is technically acting as an individual and learning to practice deception, but perhaps practicing deception (in this controlled, ethically approved setting) might help you be a little less gullible in turn.&nbsp; As Zelazny observes, there is a difference in the arts of discovering lies and finding truth.</p>\n<p>In a real institution... you would probably want to optimize less for fun, and more for work-relevance: something more like Black Belt Bayesian's original suggestion of <a href=\"http://www.acceleratingfuture.com/steven/?p=96\">The Aumann Game</a>, no red cards.&nbsp; But where both B<sup>3</sup> and <a href=\"http://www.acceleratingfuture.com/tom/?p=34\">Tom McCabe</a> originally thought in terms of scoring individuals, I would suggest forming people into groups and scoring the groups.&nbsp; An institution's performance is the sum of its groups more directly than it is the sum of its individuals&mdash;though of course there are interactions between groups as well.&nbsp; Find people who, in general, seem to have a statistical tendency to belong to high-performing groups&mdash;these are the ones who contribute much to the group, who are persuasive with <em>good</em> arguments.</p>\n<p>I wonder if there are any hedge funds that practice \"trio trading\", by analogy with pair programming?</p>\n<p><a href=\"http://www.overcomingbias.com/2006/12/agreeing_to_agr.html\">Hal Finney</a> called Aumann's Agreement Theorem \"the most interesting, surprising, and challenging result in the field of human bias: that mutually respectful, honest, and rational debaters cannot disagree on any factual matter once they know each other's opinions\".&nbsp; It is not just my own essays that are skewed toward individual application; the whole trope of Traditional Rationality seems to me skewed the same way.&nbsp; It's the individual heretic who is the hero, and Authority the untrustworthy villain whose main job is not to resist the heretic too much, to be properly defeated.&nbsp; Science is cast as a competition between theories in an arena with rules designed to let the strongest contender win.&nbsp; Of course, it may be that I am selective in my memory, and that if I went back and read my childhood books again, I would notice more on group tactics that originally slipped my attention... but really, Aumann's Agreement Theorem doesn't get enough attention.</p>\n<p>Of course <em>most </em>Bayesian math is not widely known&mdash;the Agreement Theorem is no exception here.&nbsp; But even the intuitively obvious counterpart of the Agreement Theorem, the treatment of others' beliefs as evidence, receives little shrift in Traditional Rationality.&nbsp; This may have something to do with Science developing in the midst of insanity and in defiance of Authority; that is a historical fact about how Science developed.&nbsp; But if the high performers of a rationality dojo need to practice the same sort of <a href=\"http://www.overcomingbias.com/2007/12/lonely-dissent.html\">lonely dissent</a>... well, that must not be a very effective rationality dojo.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/7k/incremental_progress_and_the_valley/\">Incremental Progress and the Valley</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately/\">Purchase Fuzzies and Utilons Separately</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zv7v2ziqexSn5iS9v": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZEj9ATpv3P22LSmnC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 40, "extendedScore": null, "score": 6.2e-05, "legacy": true, "legacyId": "259", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 41, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3p3CYauiX8oLjmwRF", "Nu3wa6npK4Ry66vFp", "2eaYboiek2WoCya2P", "YdcF6WbBmJhaaDqoD", "oZNXmHcdhb4m7vwsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-02T18:54:15.828Z", "modifiedAt": "2020-12-31T04:18:02.673Z", "url": null, "title": "Aumann voting; or, How to vote when you're ignorant", "slug": "aumann-voting-or-how-to-vote-when-you-re-ignorant", "viewCount": null, "lastCommentedAt": "2013-12-12T19:16:36.984Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ddAEkE7F4cywqsHRq/aumann-voting-or-how-to-vote-when-you-re-ignorant", "pageUrlRelative": "/posts/ddAEkE7F4cywqsHRq/aumann-voting-or-how-to-vote-when-you-re-ignorant", "linkUrl": "https://www.lesswrong.com/posts/ddAEkE7F4cywqsHRq/aumann-voting-or-how-to-vote-when-you-re-ignorant", "postedAtFormatted": "Thursday, April 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Aumann%20voting%3B%20or%2C%20How%20to%20vote%20when%20you're%20ignorant&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAumann%20voting%3B%20or%2C%20How%20to%20vote%20when%20you're%20ignorant%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FddAEkE7F4cywqsHRq%2Faumann-voting-or-how-to-vote-when-you-re-ignorant%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Aumann%20voting%3B%20or%2C%20How%20to%20vote%20when%20you're%20ignorant%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FddAEkE7F4cywqsHRq%2Faumann-voting-or-how-to-vote-when-you-re-ignorant", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FddAEkE7F4cywqsHRq%2Faumann-voting-or-how-to-vote-when-you-re-ignorant", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 578, "htmlBody": "<p>As Robin Hanson is fond of pointing out, people would often get better answers by taking other people's answers more into account.&nbsp; See <a href=\"http://www.overcomingbias.com/2006/12/agreeing_to_agr.html\">Aumann's</a> <a href=\"http://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem\">Agreement Theorem</a>.</p>\n<p>The application is obvious if you're computing an answer for your personal use.&nbsp; But how do you apply it when voting?</p>\n<p>Political debates are tug-of-wars.&nbsp; Say a bill is being voted on to introduce a 7-day waiting period for handguns.&nbsp; You might think that you should vote on the merits of a 7-day waiting period.&nbsp; This isn't what we usually do.&nbsp; Instead, we've chosen our side on the larger issue (gun control: for or against) ahead of time; and we vote whichever way is pulling in our direction.</p>\n<p>To use the tug-of-war analogy:&nbsp; There's a knot tied in the middle of the rope, and you have some line in the sand where you believe the knot should end up.&nbsp; But you don't stop pulling when the knot reaches that point; you keep pulling, because the other team is still pulling.&nbsp; So, if you're anti-gun-control, you vote against the 7-day waiting period, even if you think it would be a good idea; because passing it would move the knot back towards the other side of your line.</p>\n<p>Tug-of-war voting makes intuitive sense if you believe that an irrational extremist is usually more politically effective than a reasonable person is.&nbsp; (It sounds plausible to me.)&nbsp; If you've watched a debate long enough to see that the \"knot\" does a bit of a random walk around some equilibrium that's on the other side of your line, it can make sense to vote this way.</p>\n<p>How do you apply Aumann's theorem to tug-of-war voting?</p>\n<p>I think the answer is that you try to identify which side has more idiots, and vote on the other side.<a id=\"more\"></a></p>\n<p>I was thinking of this because of the current <a href=\"http://goliveinternet.economist.com/debate/days/view/286\">online debate between Arthur Caplan and Craig Venter</a> on DNA privacy.&nbsp; I don't have a strong opinion which way to vote, largely because it's nowhere stated clearly what it is that you're voting for or against.</p>\n<p>So I can't tell what the right answer is myself.&nbsp; But I can identify idiots.&nbsp; Applying Aumann's theorem, I take it on faith that the non-idiot population can eventually work out a good solution to the problem.&nbsp; My job is to cancel out an idiot.</p>\n<p>My impression is that there is a large class of irrational people who are generally \"against\" biotechnology because they're against evolution or science.&nbsp; (This doesn't come out in the comments on economist.com, which are surprisingly good for this sort of online debate, and unfortunately don't supply enough idiots to be statistically significant.)&nbsp; I have enough experience with this group and their opposite number to conclude that they are not counterbalanced by a sufficient number of uncritically pro-science people.</p>\n<p>So I vote against the proposition, even though the vague statement \"People's DNA sequences are their business, and nobody else's\" sounds good to me.&nbsp; I am picking sides not based on the specific issue at hand, but on what I perceive as being the larger tug-of war; and pulling for the side with fewer idiots.</p>\n<p>Do you think this is a good heuristic?</p>\n<p>You might break your answer into separate parts for \"tug-of-war voting\" (which means to choose sides on larger debates rather than on particular issues) and \"cancel out an idiot\" (which can be used without adopting tug-of-war voting).</p>\n<p>EDIT: Really, please do say if your comment refers to \"tug-of-war\" voting or \"cancelling out an idiot\".&nbsp; Perhaps I should have broken them into separate posts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"WH5ZmNSjZmK9SMj7k": 2, "mPuSAzJN7CyrMiKrf": 2, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ddAEkE7F4cywqsHRq", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 12, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "261", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-02T18:54:15.828Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-02T21:16:22.682Z", "modifiedAt": null, "url": null, "title": "\"Robot scientists can think for themselves\"", "slug": "robot-scientists-can-think-for-themselves", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:17.205Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/joGBPZPM6hcT9iuTS/robot-scientists-can-think-for-themselves", "pageUrlRelative": "/posts/joGBPZPM6hcT9iuTS/robot-scientists-can-think-for-themselves", "linkUrl": "https://www.lesswrong.com/posts/joGBPZPM6hcT9iuTS/robot-scientists-can-think-for-themselves", "postedAtFormatted": "Thursday, April 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Robot%20scientists%20can%20think%20for%20themselves%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Robot%20scientists%20can%20think%20for%20themselves%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoGBPZPM6hcT9iuTS%2Frobot-scientists-can-think-for-themselves%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Robot%20scientists%20can%20think%20for%20themselves%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoGBPZPM6hcT9iuTS%2Frobot-scientists-can-think-for-themselves", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoGBPZPM6hcT9iuTS%2Frobot-scientists-can-think-for-themselves", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<p>I recently saw <a href=\"http://news.yahoo.com/s/nm/20090402/sc_nm/us_science_robots\">this Reuters article</a> on Yahoo News. In typical science reporting fashion, the headline seems to be pure hyperbole - does anyone here know enough to clarify what the groups referenced have actually achieved?</p>\n<p>This links represent what I could find:</p>\n<p>Homepage of the \"Robot Scientist\" project:<a href=\"http://www.aber.ac.uk/compsci/Research/bio/robotsci/\">http://www.aber.ac.uk/compsci/Research/bio/robotsci/</a>&nbsp;</p>\n<p>Homepage of Hod Lipson: <a href=\"http://www.mae.cornell.edu/lipson/\">http://www.mae.cornell.edu/lipson/</a></p>\n<p>Hod Lipson's 2007 paper \"<a href=\"http://ccsl.mae.cornell.edu/papers/PNAS07_Bongard.pdf\">Automated reverse engineering of nonlinear dynamical systems</a>\" (pdf)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "joGBPZPM6hcT9iuTS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": -1, "extendedScore": null, "score": 4.85266783793548e-07, "legacy": true, "legacyId": "263", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-02T21:51:24.646Z", "modifiedAt": null, "url": null, "title": "Where are we?", "slug": "where-are-we", "viewCount": null, "lastCommentedAt": "2017-08-30T12:04:59.298Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gRkFrDmuE82difQRH/where-are-we", "pageUrlRelative": "/posts/gRkFrDmuE82difQRH/where-are-we", "linkUrl": "https://www.lesswrong.com/posts/gRkFrDmuE82difQRH/where-are-we", "postedAtFormatted": "Thursday, April 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Where%20are%20we%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhere%20are%20we%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgRkFrDmuE82difQRH%2Fwhere-are-we%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Where%20are%20we%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgRkFrDmuE82difQRH%2Fwhere-are-we", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgRkFrDmuE82difQRH%2Fwhere-are-we", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 195, "htmlBody": "<p>I'm enjoying lesswrong.com a lot so far, and it sounds like the last LW/OB meetup was a lot of fun. <a href=\"/lw/77/selecting_rationalist_groups/4rk#comments\">MBlume asks</a>:</p>\n<blockquote>So far there've only been LW/OB meetups in the Bay area -- is there any way we could plot the geographic distribution of LW members and determine whether there are other spots where we could get a good meetup going?</blockquote>\n<p>I don't think that there are so many of us that we need an automated system for this; the threading system should be enough.I'll post a few top-level comments for various parts of the world, and encourage you all to follow up and tell us where you are. Ideally, find a comment that has where you live in it already and add \"me too\".</p>\n<p>I'll try to keep this post updated with useful things. I can't wait to play Paranoid Debating!</p>\n<p>Edit: <strong>Please don't post where you live in a new top-level comment!</strong> Try to find a comment referring to the rough geographic region you live in and post under that; it'll make this post easier to navigate.&nbsp; I've divided the world into three (North America, Europe, everywhere else); posting under those comments will help.&nbsp; Thanks!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "T57Qd9J3AfxmwhQtY": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gRkFrDmuE82difQRH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 24, "extendedScore": null, "score": 4.852719042952024e-07, "legacy": true, "legacyId": "264", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 312, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-03T08:06:51.628Z", "modifiedAt": null, "url": null, "title": "The Brooklyn Society For Ethical Culture", "slug": "the-brooklyn-society-for-ethical-culture", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:19.863Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CcmN333Nm6Hmze6Cs/the-brooklyn-society-for-ethical-culture", "pageUrlRelative": "/posts/CcmN333Nm6Hmze6Cs/the-brooklyn-society-for-ethical-culture", "linkUrl": "https://www.lesswrong.com/posts/CcmN333Nm6Hmze6Cs/the-brooklyn-society-for-ethical-culture", "postedAtFormatted": "Friday, April 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Brooklyn%20Society%20For%20Ethical%20Culture&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Brooklyn%20Society%20For%20Ethical%20Culture%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcmN333Nm6Hmze6Cs%2Fthe-brooklyn-society-for-ethical-culture%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Brooklyn%20Society%20For%20Ethical%20Culture%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcmN333Nm6Hmze6Cs%2Fthe-brooklyn-society-for-ethical-culture", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcmN333Nm6Hmze6Cs%2Fthe-brooklyn-society-for-ethical-culture", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 222, "htmlBody": "<p>Dale McGowan writes:</p>\n<blockquote>\n<p style=\"margin: 0.0px 0.0px 20.0px 30.0px; line-height: 20.0px; font: 14.0px Georgia; color: #292929; background-color: #fcfff5;\">In the past seven years or so, I&rsquo;ve seen quite a few humanistic organizations from the inside &mdash; freethought groups, Ethical Societies, Congregations for Humanistic Judaism, UUs, etc. Met a lot of wonderful people working hard to make their groups succeed. All of the groups have different strengths, and all are struggling with One Big Problem: creating a genuine sense of community.</p>\n<p style=\"margin: 0.0px 0.0px 20.0px 30.0px; line-height: 20.0px; font: 14.0px Georgia; color: #292929; background-color: #fcfff5;\"><span style=\"color: #40606f;\"><a href=\"http://parentingbeyondbelief.com/blog/?p=258\">I&rsquo;ve written before</a></span> about community and the difficulty freethought groups generally have creating it. Some get closer than others, but it always seems to fall a bit short of the sense of community that churches so often create. And I don&rsquo;t think it has a <em>thing </em>to do with God.</p>\n<p style=\"margin: 0.0px 0.0px 20.0px 30.0px; line-height: 20.0px; font: 14.0px Georgia; color: #292929; background-color: #fcfff5;\">The question I hear more and more from freethought groups is, &ldquo;How can we bring people in the door and keep them coming back?&rdquo; The answer is to make our groups more <strong><em>humanistic</em></strong> &mdash; something churches, ironically, often do better than we do.</p>\n<p style=\"margin: 0.0px 0.0px 20.0px 30.0px; line-height: 20.0px; font: 14.0px Georgia; color: #292929; background-color: #fcfff5;\">Now I&rsquo;ve met an organization founded on freethought principles that seems to get humanistic community precisely right. It&rsquo;s the <a href=\"http://www.bsec.org/\"><span style=\"color: #40606f;\"><strong>Brooklyn Society for Ethical Culture</strong></span></a>&nbsp;[...], host of my seminar and talk last weekend, and the single most effective humanistic community I have <em>ever </em>seen.</p>\n<p style=\"margin: 0.0px 0.0px 20.0px 30.0px; line-height: 20.0px; font: 14.0px Georgia; color: #292929; background-color: #fcfff5;\">So what do they have going for them? My top ten list:</p>\n</blockquote>\n<p style=\"margin: 0.0px 0.0px 20.0px 30.0px; line-height: 20.0px; font: 14.0px Georgia; color: #292929; background-color: #fcfff5;\"><span style=\"font-family: Verdana; color: #000000; font-size: small;\"><span style=\"font-size: 13px;\"><a href=\"http://parentingbeyondbelief.com/blog/?p=1957\">Read on at Meming of Life</a></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CcmN333Nm6Hmze6Cs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 19, "extendedScore": null, "score": 4.853618760921302e-07, "legacy": true, "legacyId": "269", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-03T13:57:49.099Z", "modifiedAt": null, "url": null, "title": "Open Thread: April 2009", "slug": "open-thread-april-2009", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:45.613Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gjm", "createdAt": "2009-03-09T01:11:32.668Z", "isAdmin": false, "displayName": "gjm"}, "userId": "977L8MR7JmNrQx6df", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tQFttLYwXyyjgNGPy/open-thread-april-2009", "pageUrlRelative": "/posts/tQFttLYwXyyjgNGPy/open-thread-april-2009", "linkUrl": "https://www.lesswrong.com/posts/tQFttLYwXyyjgNGPy/open-thread-april-2009", "postedAtFormatted": "Friday, April 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%3A%20April%202009&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%3A%20April%202009%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtQFttLYwXyyjgNGPy%2Fopen-thread-april-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%3A%20April%202009%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtQFttLYwXyyjgNGPy%2Fopen-thread-april-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtQFttLYwXyyjgNGPy%2Fopen-thread-april-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<p>Here is our monthly place to discuss Less Wrong topics that have not appeared in recent posts.</p>\n<p>(Carl's open thread for March was only a week ago or thereabouts, but if we're having these monthly then I think it's better for them to appear near -- ideally at -- the start of each month, to make it that little bit easier to find something when you can remember roughly when it was posted. The fact that that open thread has had 69 comments in that time seems like good evidence that \"almost anyone can post articles\" is sufficient reason for not bothering with open threads.)</p>\n<p>[EDIT, 2009-04-04: oops, I meant \"is NOT sufficient reason\" in that last sentence. D'oh.]</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tQFttLYwXyyjgNGPy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 4.854131953931659e-07, "legacy": true, "legacyId": "271", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 134, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-03T14:41:25.255Z", "modifiedAt": null, "url": null, "title": "Rationality is Systematized Winning", "slug": "rationality-is-systematized-winning", "viewCount": null, "lastCommentedAt": "2019-07-22T11:57:43.385Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4ARtkT3EYox3THYjF/rationality-is-systematized-winning", "pageUrlRelative": "/posts/4ARtkT3EYox3THYjF/rationality-is-systematized-winning", "linkUrl": "https://www.lesswrong.com/posts/4ARtkT3EYox3THYjF/rationality-is-systematized-winning", "postedAtFormatted": "Friday, April 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20is%20Systematized%20Winning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20is%20Systematized%20Winning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ARtkT3EYox3THYjF%2Frationality-is-systematized-winning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20is%20Systematized%20Winning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ARtkT3EYox3THYjF%2Frationality-is-systematized-winning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ARtkT3EYox3THYjF%2Frationality-is-systematized-winning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 764, "htmlBody": "<p><strong>Followup to</strong>:&nbsp; <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">Newcomb's Problem and Regret of Rationality</a></p>\n<p>\"Rationalists should <em>win,</em>\" I said, and I may have to stop saying it, for it seems to convey something other than what I meant by it.</p>\n<p>Where did the phrase come from originally?&nbsp; From considering such cases as <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">Newcomb's Problem</a>:&nbsp; The superbeing Omega sets forth before you two boxes, a transparent box A containing $1000 (or the equivalent in material wealth), and an opaque box B that contains either $1,000,000 or nothing.&nbsp; Omega tells you that It has already put $1M in box B if and only if It predicts that you will take only box B, leaving box A behind.&nbsp; Omega has played this game many times before, and has been right 99 times out of 100.&nbsp; Do you take both boxes, or only box B?</p>\n<p>A common position - in fact, the mainstream/dominant position in modern philosophy and decision theory - is that the only <em>reasonable</em> course is to take both boxes; Omega has already made Its decision and gone, and so your action cannot <em>affect</em> the contents of the box in any way (they argue).&nbsp; Now, it so happens that certain types of <em>unreasonable</em> individuals are rewarded by Omega - who moves even before they make their decisions - but this in no way changes the conclusion that the only <em>reasonable</em> course is to take both boxes, since taking both boxes makes you $1000 richer regardless of the unchanging and unchangeable contents of box B.</p>\n<p>And this is the sort of thinking that I intended to reject by saying, \"Rationalists should <em>win!</em>\"</p>\n<p>Said Miyamoto Musashi:&nbsp; \"The primary thing when you take a sword in your hands is your intention to cut the enemy, whatever the means.&nbsp; Whenever you parry, hit, spring, strike or touch the enemy's cutting sword, you must cut the enemy in the same movement.&nbsp; It is essential to attain this.&nbsp; If you think only of hitting, springing, striking or touching the enemy, you will not be able actually to cut him.\"</p>\n<p>Said I:&nbsp; \"If you fail to achieve a correct answer, it is futile to protest that you acted with propriety.\"</p>\n<p>This is the distinction I had hoped to convey by saying, \"Rationalists should <em>win!</em>\"</p>\n<p><a id=\"more\"></a></p>\n<p>There is a meme which says that a certain ritual of cognition is the paragon of <em>reasonableness</em> and so defines what the <em>reasonable</em> people do.&nbsp; But alas, the <em>reasonable</em> people often get their butts handed to them by the <em>unreasonable</em> ones, because the universe isn't always <em>reasonable</em>.&nbsp; Reason is just <em>a</em> way of doing things, not necessarily <em>the </em>most <a href=\"/lw/2c/a_sense_that_more_is_possible/\">formidable</a>; it is how professors talk to each other in debate halls, which sometimes works, and sometimes doesn't.&nbsp; If a hoard of barbarians attacks the debate hall, the truly prudent and flexible agent will abandon reasonableness.</p>\n<p>No.&nbsp; If the \"irrational\" agent is outcompeting you on a <em>systematic</em> and <em>predictable</em> basis, then it is time to reconsider what you think is \"rational\".</p>\n<p>For I do fear that a \"rationalist\" will clutch to themselves the ritual of cognition they have been taught, as loss after loss piles up, consoling themselves:&nbsp; \"I have behaved virtuously, I have been <em>so reasonable,</em> it's just this <em>awful unfair universe</em> that doesn't give me what I <em>deserve</em>.&nbsp; The others are <em>cheating</em> by not doing it the rational way, <em>that's</em> how they got ahead of me.\"</p>\n<p>It is this that I intended to guard against by saying:&nbsp; \"Rationalists should <em>win!</em>\"&nbsp; Not whine, <em>win</em>.&nbsp; If you keep on losing, perhaps you are doing something <em>wrong</em>.&nbsp; Do not console yourself about how you were so wonderfully rational in the course of losing.&nbsp; That is <em>not</em> how things are supposed to go.&nbsp; It is not the Art that fails, but you who fails to grasp the Art.</p>\n<p>Likewise in the realm of epistemic rationality, if you find yourself thinking that the <em>reasonable</em> belief is X (because a majority of modern humans seem to believe X, or something that sounds similarly appealing) and yet <a href=\"/lw/1f/moores_paradox/\">the world itself</a> is obviously Y.</p>\n<p>But people do seem to be taking this in some other sense than I meant it - as though any person who declared themselves a rationalist would in that moment be invested with an invincible spirit that enabled them to obtain all things without effort and without overcoming disadvantages, or something, I don't know.</p>\n<p>Maybe there is an alternative phrase to be found again in Musashi, who said:&nbsp; \"The Way of the Ichi school is the spirit of winning, whatever the weapon and whatever its size.\"</p>\n<p>\"Rationality is the spirit of winning\"?&nbsp; \"Rationality is the Way of winning\"?&nbsp; \"Rationality is systematized winning\"?&nbsp; If you have a better suggestion, post it in the comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 9, "5f5c37ee1b5cdee568cfb20f": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4ARtkT3EYox3THYjF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 77, "baseScore": 78, "extendedScore": null, "score": 0.000118, "legacy": true, "legacyId": "270", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 78, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 265, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Nu3wa6npK4Ry66vFp", "ERRk4thxxYNcScqR4"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-03T17:02:31.856Z", "modifiedAt": null, "url": null, "title": "Winning is Hard", "slug": "winning-is-hard", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:29.983Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "whpearson", "createdAt": "2009-02-28T00:34:00.976Z", "isAdmin": false, "displayName": "whpearson"}, "userId": "bq8qsRbPNvFihHxgi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7GWpbtRaJQ3HcamKo/winning-is-hard", "pageUrlRelative": "/posts/7GWpbtRaJQ3HcamKo/winning-is-hard", "linkUrl": "https://www.lesswrong.com/posts/7GWpbtRaJQ3HcamKo/winning-is-hard", "postedAtFormatted": "Friday, April 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Winning%20is%20Hard&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWinning%20is%20Hard%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7GWpbtRaJQ3HcamKo%2Fwinning-is-hard%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Winning%20is%20Hard%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7GWpbtRaJQ3HcamKo%2Fwinning-is-hard", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7GWpbtRaJQ3HcamKo%2Fwinning-is-hard", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 394, "htmlBody": "<p>Let us say you are playing Steve Omohundro's meal choosing game <a title=\"omo\" href=\"#omo\" target=\"_self\">1</a>, however the negatives are a bit harsher and more realistic than just a dodgy soufle. You are given two choices on the menu, oysters and fugu. Your goal avoid death, sickness and eat tasty food. You don't know much about either, although you do know that shellfish has made you ill in the past so you give it a lower expected utility (pretend you don't know what <a title=\"fugu\" href=\"http://en.wikipedia.org/wiki/Fugu\" target=\"_blank\">fugu</a> is).<br /><br />Eating the poorly prepared fugu kills you dead every time, do not pass go, do not update your utility values of choosing an option (although the utility of it would be 0, if you were allowed to update). Eating oysters gives you a utility of 1.<br /><br />So how do we win in this situation? In a way it is easy: Don't eat the fugu! But by what principled fashion should you choose not to eat the fugu? Microeconomics is not enough, with negative expected utility from shellfish you would pick the fugu! Also you do not get to update your utilities when you&nbsp; eat the fugu, so your expected utilities can't converge with experience. So we are in a bit of a pickle.<br /><br />Can humans solve these kinds of problems, if so how do we do it? The answer is poorly, in a patch work fashion and we get information on the fugu type problems from our genome and culture. For example we avoid bitter things, are scared of snakes and are careful if we are up high are because our ancestors had to have had thes bits of information (and more) to avoid death. They got them by chance, which isn't exactly principled. But all these are still needed for winning. We can also get the information culturally, but that can leave us open to taboos against harmless things such as eating pork, which we might be foolish to test ourselves. It is hardly principled either.<br /><br />So in this kind of scenario it is not sufficient to be economically rational to win, you have to have a decent source of knowledge. Getting a decent source of knowledge is hard.<br /><br /><a name=\"omo\"></a>1 See the appendix of the <a title=\"Pdf\" href=\"http://selfawaresystems.files.wordpress.com/2008/01/nature_of_self_improving_ai.pdf\" target=\"_blank\">Nature of Self-Improving Artificial Intelligence</a> &nbsp; starting page 37</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7GWpbtRaJQ3HcamKo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": -10, "extendedScore": null, "score": -1.6e-05, "legacy": true, "legacyId": "273", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-03T18:55:52.000Z", "modifiedAt": null, "url": null, "title": "Another Call to End Aid to Africa", "slug": "another-call-to-end-aid-to-africa", "viewCount": null, "lastCommentedAt": "2017-06-17T03:51:47.413Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dvky3MWgPYrMamoXz/another-call-to-end-aid-to-africa", "pageUrlRelative": "/posts/dvky3MWgPYrMamoXz/another-call-to-end-aid-to-africa", "linkUrl": "https://www.lesswrong.com/posts/dvky3MWgPYrMamoXz/another-call-to-end-aid-to-africa", "postedAtFormatted": "Friday, April 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Another%20Call%20to%20End%20Aid%20to%20Africa&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnother%20Call%20to%20End%20Aid%20to%20Africa%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdvky3MWgPYrMamoXz%2Fanother-call-to-end-aid-to-africa%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Another%20Call%20to%20End%20Aid%20to%20Africa%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdvky3MWgPYrMamoXz%2Fanother-call-to-end-aid-to-africa", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdvky3MWgPYrMamoXz%2Fanother-call-to-end-aid-to-africa", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 281, "htmlBody": "<p>Dambisa Moyo, an African economist, has joined her voice to the other African economists [e.g. <a href=\"http://www.spiegel.de/international/spiegel/0,1518,363663,00.html\">James Shikwati</a>] calling for a full halt to Western aid.&#0160; Her book is called <a href=\"http://www.amazon.com/gp/product/0374139563?ie=UTF8&amp;tag=gueamagofarta-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0374139563\">Dead Aid</a> and it asserts a direct cause-and-effect relationship between $1 trillion of aid and the rise in African poverty rates from 11% to 66%.</p><p>Though it&#39;s an easy enough signal to fake, I find it noteworthy that Moyo - in <a href=\"http://www.guernicamag.com/interviews/954/moyo/\">this interview</a> at least - repeatedly pleads for some attention to &quot;logic and evidence&quot;:</p><p style=\"margin-left: 40px;\">&quot;I think the whole aid model is couched in pity.&#0160; I don\u2019t want to cast\naspersions as to where that pity comes from.&#0160; But I do think it\u2019s based\non pity because based on logic and evidence, it is very clear that aid\ndoes not work.&#0160; And yet if you speak to some of the biggest supporters\nof aid, whether they are academics or policy makers or celebrities,\ntheir whole rationale for giving more aid to Africa is not couched in\nlogic or evidence; it\u2019s based largely on emotion and pity.&quot;</p><p>I was just trying to think of when was the last time I heard a Western politician - or even a mainstream Western economist in any public venue - draw an outright battle line between logic and pity.&#0160; Oh, there are plenty of demagogues who claim the evidence is on their side, but they won&#39;t be so outright <em>condemning </em>of emotion - it&#39;s not a winning tactic.&#0160; Even I <a href=\"http://www.overcomingbias.com/2007/04/feeling_rationa.html\">avoid drawing a battle line</a> so stark.</p><p>Moyo says she&#39;s gotten a better reception in Africa than in the West.&#0160; Maybe you need to see your whole continent wrecked by emotion and pity before &quot;logic and evidence&quot; start to sound appealing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qAvbtzdG2A2RBn7in": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dvky3MWgPYrMamoXz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 11, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "1262", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": "postCommentsOld", "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-03T22:28:05.105Z", "modifiedAt": null, "url": null, "title": "First London Rationalist Meeting upcoming", "slug": "first-london-rationalist-meeting-upcoming", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:18.596Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QSnybzF5WLAziXNw4/first-london-rationalist-meeting-upcoming", "pageUrlRelative": "/posts/QSnybzF5WLAziXNw4/first-london-rationalist-meeting-upcoming", "linkUrl": "https://www.lesswrong.com/posts/QSnybzF5WLAziXNw4/first-london-rationalist-meeting-upcoming", "postedAtFormatted": "Friday, April 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20First%20London%20Rationalist%20Meeting%20upcoming&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFirst%20London%20Rationalist%20Meeting%20upcoming%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQSnybzF5WLAziXNw4%2Ffirst-london-rationalist-meeting-upcoming%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=First%20London%20Rationalist%20Meeting%20upcoming%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQSnybzF5WLAziXNw4%2Ffirst-london-rationalist-meeting-upcoming", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQSnybzF5WLAziXNw4%2Ffirst-london-rationalist-meeting-upcoming", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<p>It's an extremely short notice, but we're going to have the first meeting tomorrow, that is - Saturday (2009-04-04) 14:00, in cafe on top of the Waterstones bookstore near the Piccadilly Circuis Tube station.</p>\n<p>If you want to know more, email me (Tomasz.Wegrzanowski@gmail.com) for details. Or just come straight away.</p>\n<p>Hopefully we can get it going, and the second meeting with be better organized.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QSnybzF5WLAziXNw4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 4.854878269831783e-07, "legacy": true, "legacyId": "275", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-04T00:00:24.951Z", "modifiedAt": null, "url": null, "title": "On dollars, utility, and crack cocaine", "slug": "on-dollars-utility-and-crack-cocaine", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:20.169Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/agFgSc8D7yn852QDN/on-dollars-utility-and-crack-cocaine", "pageUrlRelative": "/posts/agFgSc8D7yn852QDN/on-dollars-utility-and-crack-cocaine", "linkUrl": "https://www.lesswrong.com/posts/agFgSc8D7yn852QDN/on-dollars-utility-and-crack-cocaine", "postedAtFormatted": "Saturday, April 4th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20dollars%2C%20utility%2C%20and%20crack%20cocaine&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20dollars%2C%20utility%2C%20and%20crack%20cocaine%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FagFgSc8D7yn852QDN%2Fon-dollars-utility-and-crack-cocaine%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20dollars%2C%20utility%2C%20and%20crack%20cocaine%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FagFgSc8D7yn852QDN%2Fon-dollars-utility-and-crack-cocaine", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FagFgSc8D7yn852QDN%2Fon-dollars-utility-and-crack-cocaine", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 465, "htmlBody": "<p>The lottery came up in a recent comment, with the claim that the expected return is negative - and the implicit conclusion that it's irrational to play the lottery.&nbsp; So I will explain why this is not the case.</p>\n<p>It's convenient to reason using units of equivalent value.&nbsp; Dollars, for instance.&nbsp; A utility function u(U) maps some bag of goods U (which might be dollars) into a value or ranking.&nbsp; In general, u(kn) / u(n) &lt; k.&nbsp; This is because a utility function is (typically) defined in terms of marginal utility.&nbsp; The marginal utility to you of your first dollar is much greater than the marginal utility to you of your 1,000,000th dollar.&nbsp; It increases the possible actions available to you much more than your 1,000,000th dollar does.</p>\n<p>Utility functions are sigmoidal.&nbsp; A serviceable utility function over one dimension might be u(U) = k * ([1 / (1 + e<sup>-U</sup>)] - .5).&nbsp; It's steep around U=0, and shallow for U &gt;&gt; 0 and U &lt;&lt; 0.</p>\n<p>Sounds like I'm making a dry, academic mathematical point, doesn't it?&nbsp; But it's not academic.&nbsp; It's crucial.&nbsp; Because neglecting this point leads us to make elementary errors such as asserting that it isn't rational to play the lottery or become addicted to crack cocaine.<a id=\"more\"></a></p>\n<p>For someone with $ &lt;&lt; 0, the marginal utility of $5 to them is minimal.&nbsp; They're probably never going to get out of debt; someone has a lien on their income and it's going to be taken from them anyway; and if they're $5 richer it might mean they'll lose $4 in government benefits.&nbsp; It can be perfectly reasonable, in terms of <em>expected utility</em>, for them to play the lottery.</p>\n<p>Not in terms of <em>expected dollars</em>.&nbsp; Dollars are the <em>input</em> to the utility function.</p>\n<p>Rationally, you might expect that u(U) = 0 for all U &lt; 0.&nbsp; Because you can always kill yourself.&nbsp; Once your life is so bad that you'd like to kill yourself, it could make perfect sense to play the lottery, if you thought that winning it would help.&nbsp; Or to take crack cocaine, if it gives you a few short intervals over the next year that are worth living.</p>\n<p>Why is this important?</p>\n<p>Because we look at poor folks playing the lottery, and taking crack cocaine, and we laugh at them and say, Those fools don't deserve our help if they're going to make such stupid decisions.</p>\n<p>When in reality, some of them may be making &lt;EDITED&gt; much more rational decisions than we think. &lt;/EDITED&gt;</p>\n<p>If that doesn't give you a chill, you don't understand.</p>\n<p>&nbsp;</p>\n<p>(I changed the penultimate line in response to numerous comments indicating that the commenters reserve the word \"rational\" for the unobtainable goal of perfect utility maximization.&nbsp; I note that such a definition defines itself into being irrational, since it is almost certainly not the best possible definition.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HAFdXkW4YW4KRe2Gx": 1, "fkABsGCJZ6y9qConW": 1, "LaDu5bKDpe8LxaR7C": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "agFgSc8D7yn852QDN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 16, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "276", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 100, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-04T16:42:38.405Z", "modifiedAt": "2020-08-07T21:04:46.342Z", "url": null, "title": "Incremental Progress and the Valley", "slug": "incremental-progress-and-the-valley", "viewCount": null, "lastCommentedAt": "2020-12-16T10:25:52.780Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oZNXmHcdhb4m7vwsv/incremental-progress-and-the-valley", "pageUrlRelative": "/posts/oZNXmHcdhb4m7vwsv/incremental-progress-and-the-valley", "linkUrl": "https://www.lesswrong.com/posts/oZNXmHcdhb4m7vwsv/incremental-progress-and-the-valley", "postedAtFormatted": "Saturday, April 4th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Incremental%20Progress%20and%20the%20Valley&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIncremental%20Progress%20and%20the%20Valley%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoZNXmHcdhb4m7vwsv%2Fincremental-progress-and-the-valley%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Incremental%20Progress%20and%20the%20Valley%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoZNXmHcdhb4m7vwsv%2Fincremental-progress-and-the-valley", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoZNXmHcdhb4m7vwsv%2Fincremental-progress-and-the-valley", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1628, "htmlBody": "<p>Yesterday I said:&nbsp; \"Rationality is systematized winning.\"</p>\n<p>\"But,\" you protest, \"the reasonable person <em>doesn't</em> always win!\"</p>\n<p>What do you mean by this?&nbsp; Do you mean that every week or two, someone who bought a <a href=\"http://www.overcomingbias.com/2007/04/lotteries_a_was.html\">lottery ticket</a> with negative expected value, wins the lottery and becomes much richer than you?&nbsp; That is not a <em>systematic </em>loss; it is selective reporting by the media.&nbsp; From a statistical standpoint, lottery winners don't exist&mdash;you would never encounter one in your lifetime, if it weren't for the selective reporting.</p>\n<p>Even perfectly rational agents can lose.&nbsp; They just can't <em>know in advance</em> that they'll lose.&nbsp; They can't <em>expect to underperform</em> any other performable strategy, or they would simply perform it.</p>\n<p>\"No,\" you say, \"I'm talking about how startup founders strike it rich by believing in themselves and their ideas more strongly than any reasonable person would.&nbsp; I'm talking about how religious people are happier&mdash;\"</p>\n<p>Ah.&nbsp; Well, here's the the thing:&nbsp; An <em>incremental</em> step in the direction of rationality, if the result is still irrational in other ways, does not have to yield <em>incrementally </em>more winning.</p>\n<p>The optimality theorems that we have for probability theory and decision theory, are for <em>perfect</em> probability theory and decision theory.&nbsp; There is no companion theorem which says that, starting from some flawed initial form, every <em>incremental</em> modification of the algorithm that takes the structure closer to the ideal, must yield an <em>incremental</em> improvement in performance.&nbsp; This has not yet been proven, because it is not, in fact, true.</p>\n<p>\"So,\" you say, \"what point is there then in striving to be more rational?&nbsp; We won't reach the perfect ideal.&nbsp; So we have no guarantee that our steps forward are helping.\"<a id=\"more\"></a></p>\n<p>You have no guarantee that a step <em>backward</em> will help you win, either.&nbsp; <a href=\"http://www.overcomingbias.com/2008/05/no-defenses.html\">Guarantees don't exist</a> in the world of flesh; but contrary to popular misconceptions, judgment under <em>uncertainty </em>is what rationality is all about.</p>\n<p>\"But we have several cases where, based on either vaguely plausible-sounding reasoning, or survey data, it looks like an incremental step forward in rationality is going to make us worse off.&nbsp; If it's really all about winning&mdash;if you have <a href=\"http://www.overcomingbias.com/2008/01/something-to-pr.html\">something to protect</a> more important than any ritual of cognition&mdash;then <em>why</em> take that step?\"</p>\n<p>Ah, and <em>now</em> we come to the meat of it.</p>\n<p>I can't necessarily answer for everyone, but...</p>\n<p>My first reason is that, on a professional basis, I deal with deeply confused problems that make huge demands on precision of thought.&nbsp; One small mistake can lead you astray for years, and there are worse penalties waiting in the wings.&nbsp; An unimproved level of performance isn't <em>enough;</em> my choice is to try to do better, or give up and go home.</p>\n<p>\"But that's just <em>you</em>.&nbsp; Not all of us lead that kind of life.&nbsp; What if you're just trying some ordinary human task like an Internet startup?\"</p>\n<p>My second reason is that I am trying to push some aspects of my art further than I have seen done.&nbsp; I don't <em>know </em>where these improvements lead.&nbsp; The loss of failing to take a step forward is not that <em>one step</em>, it is all the <em>other </em>steps forward you could have taken, beyond that point.&nbsp; Robin Hanson has a saying:&nbsp; The problem with slipping on the stairs is not falling the height of the first step, it is that falling one step leads to falling another step.&nbsp; In the same way, refusing to climb one step up forfeits not the height of that step but the height of the staircase.</p>\n<p>\"But again&mdash;that's just you.&nbsp; Not all of us are trying to push the art into uncharted territory.\"</p>\n<p>My third reason is that once I realize I have been deceived, I can't just shut my eyes and pretend I haven't seen it.&nbsp; I have <em>already taken</em> that step forward; what use to deny it to myself?&nbsp; I couldn't believe in God if I tried, any more than I could believe the sky above me was green while looking straight at it.&nbsp; If you <em>know</em> everything you need to know in order to know that you are better off deceiving yourself, it's <a href=\"http://www.overcomingbias.com/2007/09/doublethink-cho.html\">much too late to deceive yourself</a>.</p>\n<p>\"But that realization is <em>unusual;</em> other people have <a href=\"/lw/r/no_really_ive_deceived_myself/\">an easier time of doublethink</a> because <a href=\"/lw/s/belief_in_selfdeception/\">they don't realize it's impossible</a>.&nbsp; <em>You</em> go around trying to <a href=\"/lw/1o/dont_believe_youll_selfdeceive/\">actively sponsor</a> the collapse of doublethink.&nbsp; <em>You</em>, from a higher vantage point, may know enough to expect that this will make them unhappier.&nbsp; So is this out of a sadistic desire to hurt your readers, or what?\"</p>\n<p>Then I finally reply that my experience so far&mdash;even in this realm of merely human possibility&mdash;<em>does</em> seem to indicate that, once you sort yourself out a bit and you aren't doing <em>quite</em> so many other things wrong, striving for more rationality actually <em>will </em>make you better off.&nbsp; The long road leads out of the valley and higher than before, even in the human lands.</p>\n<p>The more I know about some particular facet of the Art, the more I can see this is so.&nbsp; As I've previously remarked, my essays may be unreflective of what a true martial art of rationality would be like, because I have only focused on answering confusing questions&mdash;not fighting akrasia, coordinating groups, or being happy.&nbsp; In the field of answering confusing questions&mdash;the area where I have most intensely practiced the Art&mdash;it now seems <em>massively</em> obvious that anyone who thought they were better off \"staying optimistic about solving the problem\" would get stomped into the <em>ground</em>.&nbsp; By a <em>casual student.</em></p>\n<p>When it comes to keeping motivated, or being happy, I can't guarantee that someone who loses their illusions will be better off&mdash;because my knowledge of these facets of rationality is still crude.&nbsp; If these parts of the Art have been developed systematically, I <a href=\"http://www.overcomingbias.com/2007/10/no-one-knows-wh.html\">do not know of it</a>.&nbsp; But even here I have gone to some considerable pains to dispel half-rational half-mistaken ideas that could get in a beginner's way, like the idea that <a href=\"http://www.overcomingbias.com/2007/04/feeling_rationa.html\">rationality opposes feeling</a>, or the idea that <a href=\"http://www.overcomingbias.com/2008/07/the-meaning-of.html\">rationality opposes value</a>, or the idea that sophisticated thinkers should be <a href=\"http://www.overcomingbias.com/2008/07/existential-ang.html\">angsty</a> and <a href=\"http://www.overcomingbias.com/2009/02/cynical-about-cynicism.html\">cynical</a>.</p>\n<p>And if, as I hope, someone goes on to develop the art of fighting akrasia or achieving mental well-being as thoroughly as I have developed the art of answering impossible questions, I do fully expect that those who wrap themselves in their illusions will not <em>begin</em> to compete.&nbsp; Meanwhile&mdash;others may do better than I, if happiness is their dearest desire, for I myself have invested little effort here.</p>\n<p>I find it hard to believe that the <em>optimally</em> motivated individual, the <em>strongest</em> entrepreneur a human being can become, is still wrapped up in a blanket of comforting overconfidence.&nbsp; I think they've probably thrown that blanket out the window and organized their mind a little <em>differently.</em>&nbsp; I find it hard to believe that the happiest we can possibly live, even in the realms of human possibility, involves a tiny awareness lurking in the corner of your mind that it's all a lie.&nbsp; I'd rather stake my hopes on neurofeedback or Zen meditation, though I've tried neither.</p>\n<p>But it cannot be denied that this is a very real issue in very real life.&nbsp; Consider this <a href=\"/lw/2s/3_levels_of_rationality_verification/#1xv\">pair of comments</a> from Less Wrong:</p>\n<blockquote>\n<p>I'll be honest &mdash;my life has taken a sharp downturn since I deconverted. My theist girlfriend, with whom I was very much in love, couldn't deal with this change in me, and after six months of painful vacillation, she left me for a co-worker. That was another six months ago, and I have been heartbroken, miserable, unfocused, and <em>extremely</em> ineffective since.</p>\n<p>Perhaps this is an example of the <a href=\"/lw/2o/soulless_morality/1q1#comments\">valley of bad rationality</a> of which PhilGoetz spoke, but I still hold my current situation higher in my preference ranking than happiness with false beliefs.</p>\n</blockquote>\n<p>And:</p>\n<blockquote>\n<p>My empathies: that happened to me about 6 years ago (though thankfully without as much visible vacillation).</p>\n<p>My sister, who had some Cognitive Behaviour Therapy training, reminded me that relationships are forming and breaking all the time, and given I wasn't unattractive and hadn't retreated into monastic seclusion, it wasn't rational to think I'd be alone for the rest of my life (she turned out to be right). That was helpful at the times when my feelings hadn't completely got the better of me.</p>\n</blockquote>\n<p>So&mdash;in practice, in real life, in sober fact&mdash;those first steps can, in fact, be painful.&nbsp; And then things can, in fact, get better.&nbsp; And there is, in fact, no <em>guarantee </em>that you'll end up higher than before.&nbsp; Even if in principle the path must go further, there is no guarantee that any given person will get that far.</p>\n<p>If you don't <em>prefer</em> truth to happiness with false beliefs...</p>\n<p>Well... <em>and</em> if you are not doing anything especially precarious or confusing... and if you are not buying lottery tickets... and if you're already <a href=\"http://www.overcomingbias.com/2008/12/you-only-live-twice.html\">signed up for cryonics</a>, a sudden ultra-high-stakes confusing acid test of rationality that illustrates the Black Swan quality of trying to bet on ignorance <em>in</em> ignorance...</p>\n<p>Then it's not <em>guaranteed</em> that taking all the incremental steps toward rationality that you can find, will leave you better off.&nbsp; But the vaguely plausible-sounding arguments against losing your illusions, generally <em>do</em> consider just one single step, without postulating any further steps, without suggesting any attempt to regain everything that was lost and go it one better.&nbsp; Even the surveys are comparing the average religious person to the average atheist, not the most advanced theologians to the most advanced rationalists.</p>\n<p>But if you don't care about the truth&mdash;<em>and</em> you have nothing to protect&mdash;<em>and</em> you're not attracted to the thought of pushing your art as far as it can go&mdash;<em>and</em> your current life seems to be going fine&mdash;<em>and</em> you have a sense that your mental well-being depends on illusions you'd rather not think about&mdash;</p>\n<p>Then you're probably not reading this.&nbsp; But if you are, then, I guess... well... (a) sign up for cryonics, and then (b) <em>stop reading Less Wrong before your illusions collapse!&nbsp; RUN AWAY!</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "9YFoDPFwMoWthzgkY": 2, "5f5c37ee1b5cdee568cfb1f2": 7}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oZNXmHcdhb4m7vwsv", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 73, "baseScore": 83, "extendedScore": null, "score": 0.000126, "legacy": true, "legacyId": "272", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "bayesians-vs-barbarians", "canonicalPrevPostSlug": "collective-apathy-and-the-internet", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 83, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rZX4WuufAPbN6wQTv", "wP2ymm44kZZwaFPYh", "W7LcN9gmdnaAk9K52"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-04T16:42:38.405Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-04T17:49:19.283Z", "modifiedAt": null, "url": null, "title": "The First London Rationalist Meetup", "slug": "the-first-london-rationalist-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:30.671Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DMmzrGnxaPs4mtFsH/the-first-london-rationalist-meetup", "pageUrlRelative": "/posts/DMmzrGnxaPs4mtFsH/the-first-london-rationalist-meetup", "linkUrl": "https://www.lesswrong.com/posts/DMmzrGnxaPs4mtFsH/the-first-london-rationalist-meetup", "postedAtFormatted": "Saturday, April 4th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20First%20London%20Rationalist%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20First%20London%20Rationalist%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDMmzrGnxaPs4mtFsH%2Fthe-first-london-rationalist-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20First%20London%20Rationalist%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDMmzrGnxaPs4mtFsH%2Fthe-first-london-rationalist-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDMmzrGnxaPs4mtFsH%2Fthe-first-london-rationalist-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 753, "htmlBody": "<p>Here's a brief summarly of the first meetup. It took place on cafe on top of Waterstone bookstore on Saturday 2009-04-04, starting at 14:00 and lasting until about 17:15. Six people showed up: Tomasz (me), Michael, Will, Julian, Shane, and Marc.</p>\n<p>We started with a game of estimation warewolf - there was 1 decider, and 3 participants, one of the dishonest. 2 people showed up later, so they joined the game as openly honest. I don't think the decider position was really necessary, we could simply randomly assign people to honest and dishonest set. Or if the dishonest guy was necessary, we were confused enough without any active help. The subject was \"maize production of Mexico\". We did our estimate twice. First based on what Mexicans are likely to eat. Our estimates were:</p>\n<ul>\n<li>100 million Mexicans</li>\n<li>3000 kcal / day / Mexican</li>\n<li>30% of their calories from maize</li>\n<li>extra 50% on top of the result for animal feed, biofuels and other uses</li>\n<li>giving 44.3 mln tons of maize per year</li>\n</ul>\n<p>Most of the time we discussed it first, and then took the median of our guesses as the estimate. The discussion was really the fun bit, I'll give a few examples later. There was a lot of joking about anchoring effect, but I don't think there was that much of it.<a id=\"more\"></a></p>\n<p>Then we hid the first estimate, and tried the same question again, in a different way, estimating:</p>\n<ul>\n<li>Land area of Mexico was 3,125,000 square km. This estimate took surprisingly long time, with paths like \"USA has 4 time zones, there are 15 degrees per time zone, north Mexican border is about half of south USA border, Mexico is shaped more or less like a triangle\" etc., drawing pictures from memory and taking medians of them, guessing how many times different countries are bigger than each other, and guessing from territorial changes after Mexican-American wars. I guess everybody enjoyed it so much, because we all had so many bits of information vaguely related to what we were trying to guess, but no direct estimate.</li>\n<li>Land used for growing plants is 1/2 of all land.</li>\n<li>Land for growith maize is 1/3 of that.</li>\n<li>10 plants per square meter.</li>\n<li>500g per plant.</li>\n<li>giving 2600 mln tons of maize per year</li>\n</ul>\n<p>That was almost two orders of magnitude off. I was so sure that the second estimate failed any sanity check that I took a 10000:1 bet against it (conditional on our arithmetics being correct), taking 1p against 100 pound donation to the Singularity Institute. At this point we gave our point estimates, and checked it against reality. If my notes are correct, they were:</p>\n<ul>\n<li>Tomasz - 100 mln tons</li>\n<li>Shane - 150 mln tons</li>\n<li>Michael - 250 mln tons</li>\n<li>Will - 75 mln tons</li>\n<li>Julian - 100 mln tons</li>\n<li>Marc - 650 mln tons</li>\n<li>Reality (as spoken through Wikipedia) - 22.5 mln tons</li>\n</ul>\n<p>So the Singularity Institute isn't getting their money, our first estimate was very accurate considering our lack of clue about the subject matter, the second was widely off, and everybody except Marc gave more credence to the first. They might have been convinced by me taking that absurd bet via Aumann's Theorem.</p>\n<p>Errors on individual estimates were:</p>\n<ul>\n<li>population - 109 mln Mexicans (estimate 9% low)</li>\n<li>area - 1972550 km (estimate 58% high)</li>\n<li>maize consumption - 400 kg / year (estimate 22% low)</li>\n<li> 13% of Mexican land is arable (estimate 280% high)</li>\n<li>area used for maize in Mexico - 75500 square km (estimate 588% high)</li>\n<li>yield per square km - 286 ton/square km (estimate 1650% high) - this number had more doubts than any other, and it seems we were correct in our doubt</li>\n</ul>\n<p>After that, we just had chat about the Cabal on Wikipedia (which doesn't exist), tvtropes, early Internet sentimentalism, option pricing, financial crisis, quantum computers, prospects of AGI, and other random subjects. We also invented a new way of paying the bill \"by the bailout\" - everybody puts as much money on the plate, or takes as much from it as they want, as long as the final result sum was right.</p>\n<p>We're most likely going to do the next meeting in about a month, in the same place. Here's the picture. Please correct me if I misremembered anything important.</p>\n<p><img src=\"http://i42.tinypic.com/153w3vb.jpg\" alt=\"\" width=\"653\" height=\"490\" /></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DMmzrGnxaPs4mtFsH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 15, "extendedScore": null, "score": 4.856575959470265e-07, "legacy": true, "legacyId": "279", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-05T00:01:29.756Z", "modifiedAt": null, "url": null, "title": "Why Support the Underdog?", "slug": "why-support-the-underdog", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:03.885Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A4MK9RQqSAJZjanQD/why-support-the-underdog", "pageUrlRelative": "/posts/A4MK9RQqSAJZjanQD/why-support-the-underdog", "linkUrl": "https://www.lesswrong.com/posts/A4MK9RQqSAJZjanQD/why-support-the-underdog", "postedAtFormatted": "Sunday, April 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20Support%20the%20Underdog%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20Support%20the%20Underdog%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4MK9RQqSAJZjanQD%2Fwhy-support-the-underdog%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20Support%20the%20Underdog%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4MK9RQqSAJZjanQD%2Fwhy-support-the-underdog", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4MK9RQqSAJZjanQD%2Fwhy-support-the-underdog", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 763, "htmlBody": "<p>One of the strangest human biases is the almost universal tendency to support the underdog.<br /><br />I say \"human\" because even though Americans like to identify themselves as particular friends of the underdog, you can find a little of it everywhere. Anyone who's watched anime knows the Japanese have it. Anyone who's read the Bible knows the Israelites had it (no one was rooting for Goliath!) From mythology to literature to politics to sports, it keeps coming up.<br /><br />I say \"universal\" because it doesn't just affect silly things like sports teams. <a href=\"http://psp.sagepub.com/cgi/reprint/33/12/1603\">Some psychologists did a study</a> where they showed participants two maps of Israel: one showing it as a large country surrounding the small Palestinian enclaves, and the other showing it as a tiny island in the middle of the hostile Arab world. In the \"Palestinians as underdogs\" condition, 55% said they supported Palestine. In the \"Israelis as underdogs\" condition, 75% said they supported Israel. Yes, you can change opinion thirty points by altering perceived underdog status. By comparison, my informal experiments trying to teach people relevant facts about the region's history changed opinion approximately zero percent.</p>\n<p><a id=\"more\"></a></p>\n<p>(Oh, and the Israelis and Palestinians know this. That's why the propaganda handbooks they give to their respective supporters - of <em>course</em> they give their supporters propaganda handbooks! - specifically suggest the supporters portray their chosen cause as an underdog. It's also why every time BBC or someone shows a clip about the region, they get complaints from people who thought it didn't make their chosen side seem <em>weak </em>enough!)</p>\n<p>And there aren't many mitigating factors. Even when the underdog is obviously completely doomed, we still identify with them: witness Leonidas at Thermopylae. Even when the underdog is evil and the powerful faction is good, we can still feel a <em>little </em>sympathy for them; I remember some of my friends and I talking about bin Laden, and admitting that although he was clearly an evil terrorist scumbag, there was still something sort of <em>awesome </em>about a guy who could take on the entire western world from a cave somewhere.<br /><br />I say \"strangest\" because I can't make heads or tails of why evolutionary psychology would allow it. Let's say Zug and Urk are battling it out for supremacy of your hunter-gatherer tribe. Urk comes to you and says \"Hey, my faction is really weak. We don't have a chance against Zug, who is much stronger than us. I think we will probably be defeated and humiliated, and our property divided up among Zug's supporters.\"<br /><br />The purely rational response seems to be \"Wow, thanks for warning me, I'll go join Zug's side right now. Riches and high status as part of the winning faction, here I come!\"<br /><br />Now, many of us probably would join Zug's side. But introspection would tell us we were opposing rational calculation on Zug's side to a native, preconscious support for Urk. Why? The native preconscious part of our brain is usually the one that's really good at ending up on top in tribal power struggles. This sort of thing goes against everything it usually stands for.<br /><br />I can think of a few explanations, none of them satisfying. First, it could be a mechanism to prevent any one person from getting too powerful. Problem is, this sounds kind of like group selection. Maybe the group does best if there's no one dictator, but from an individual point of view, the best thing to do in a group with a powerful dictator is get on that dictator's good side. Any single individual who initiates the strategy of supporting the underdog gets crushed by all the other people who are still on the dictator's team.<br /><br />Second, it could be a mechanism to go where the rewards are highest. If a hundred people support Zug, and only ten people support Urk, then you have a chance to become one of Urk's top lieutenants, with all the high status and reproductive opportunities that implies if Urk wins. But I don't like this explanation either. When there's a big disparity in faction sizes, you have no chance of winning, and when there's a small disparity in faction sizes, you don't gain much by siding with the smaller faction. And as size differential between groups increases, the smaller faction's chance of success should drop much more quickly than the opportunities for status with the smaller faction should rise.<br /><br />So I admit it. I'm stumped. What does Less Wrong think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"pszEEb3ctztv3rozd": 1, "exZi6Bing5AiM4ZQB": 1, "4R8JYu4QF2FqzJxE5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A4MK9RQqSAJZjanQD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 48, "baseScore": 40, "extendedScore": null, "score": 8.9e-05, "legacy": true, "legacyId": "280", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 37, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 102, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-05T03:23:33.076Z", "modifiedAt": null, "url": null, "title": "Off-Topic Discussion Thread: April 2009", "slug": "off-topic-discussion-thread-april-2009", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:45.729Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6BHcfSqNRjaYRoc2S/off-topic-discussion-thread-april-2009", "pageUrlRelative": "/posts/6BHcfSqNRjaYRoc2S/off-topic-discussion-thread-april-2009", "linkUrl": "https://www.lesswrong.com/posts/6BHcfSqNRjaYRoc2S/off-topic-discussion-thread-april-2009", "postedAtFormatted": "Sunday, April 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Off-Topic%20Discussion%20Thread%3A%20April%202009&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOff-Topic%20Discussion%20Thread%3A%20April%202009%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6BHcfSqNRjaYRoc2S%2Foff-topic-discussion-thread-april-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Off-Topic%20Discussion%20Thread%3A%20April%202009%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6BHcfSqNRjaYRoc2S%2Foff-topic-discussion-thread-april-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6BHcfSqNRjaYRoc2S%2Foff-topic-discussion-thread-april-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 169, "htmlBody": "<p>Dale McGowan <a href=\"http://parentingbeyondbelief.com/blog/?p=1957\">writes</a>:</p>\n<blockquote>\n<p>And it needs to go well beyond one greeter. EVERY MEMBER of EVERY GROUP should make it a point to chat up new folks&mdash;and each other, for that matter. And not just about the latest debunky book. Ask where he&rsquo;s from, what she does for a living, whether he follows the Mets or the Yankees. You know, mammal talk.<em></em></p>\n</blockquote>\n<p>In this spirit, I propose the creation of a fully off-topic discussion thread.</p>\n<p>Here is our monthly place to discuss topics entirely unrelated to Less Wrong that (of course) have not appeared in recent posts.</p>\n<p><a id=\"more\"></a>ETA: There are two behaviors I would love to see associated with this thread. First of all, discussions often drift off-topic in the middle of a thread. In these cases \"let's take this to the off-topic thread\" would be an excellent response.&nbsp; Secondly, given who's doing the discussing, I could easily see, say, a discussion about recent developments in some webcomic blossoming into a LW-worthy insight, in which case someone could spawn a new thread.</p>\n<p><em></em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6BHcfSqNRjaYRoc2S", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 12, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "282", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-05T14:28:31.031Z", "modifiedAt": null, "url": null, "title": "Voting etiquette", "slug": "voting-etiquette", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:57.503Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gjm", "createdAt": "2009-03-09T01:11:32.668Z", "isAdmin": false, "displayName": "gjm"}, "userId": "977L8MR7JmNrQx6df", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MBs78fg6JMTMatQZQ/voting-etiquette", "pageUrlRelative": "/posts/MBs78fg6JMTMatQZQ/voting-etiquette", "linkUrl": "https://www.lesswrong.com/posts/MBs78fg6JMTMatQZQ/voting-etiquette", "postedAtFormatted": "Sunday, April 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Voting%20etiquette&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVoting%20etiquette%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBs78fg6JMTMatQZQ%2Fvoting-etiquette%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Voting%20etiquette%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBs78fg6JMTMatQZQ%2Fvoting-etiquette", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBs78fg6JMTMatQZQ%2Fvoting-etiquette", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 465, "htmlBody": "<p>Not all that surprisingly, there's quite a lot of discussion on LW about questions like</p>\n<ul>\n<li>just what should get voted up or down?</li>\n<li>what conclusions can one reasonably draw from getting downvoted?</li>\n<li>should downvotes (or even upvotes) be accompanied by explanations?</li>\n<li>should the way karma and voting work be changed?</li>\n</ul>\n<p>This generally happens in dribs and drabs, typically in response to more specific questions of the form</p>\n<ul>\n<li>Waaaa, how come my supremely insightful comment above is currently sitting at -69?</li>\n</ul>\n<p>and therefore tends to clutter up discussions that are meant to be about something else. So maybe it's worth seeing if we can arrive at some sort of consensus about the general issues, at which point maybe we can write that up and refer newcomers to it.</p>\n<p>(The outcome may be that we find that there's no consensus to be had. That would be useful information too.)</p>\n<p>I'll kick things off with a few unfocused thoughts.<a id=\"more\"></a></p>\n<p><strong>What voting is for</strong>: establishing the nearest thing we have to the consensus view of the LW community, so as to (1) help readers guess what might be most worth reading and (2) help writers adjust their writing (if they wish) to please the audience more. Note that these purposes are somewhat separate from ...</p>\n<p><strong>What karma is for</strong>: motivating people to participate, motivating people to participate <em>well</em>, giving readers an indication of which writers are most worth reading.</p>\n<p>It seems to me that voting is working reasonably well -- I find a reasonable correlation between comment ratings and comment quality. I'm not convinced that karma is working so well; what's rewarded by the system is prolific posting at least as much as high-quality posting. Doing away with the auto-self-upvote (and making it impossible to upvote one's own comments) seems likely to be an improvement. Or maybe making each comment count for (say) 1/4 as much as an upvote.</p>\n<p><strong>Explanations for votes</strong>: Lots of comments get voted up; quite a lot get voted down. The practice of explaining votes (even just downvotes) would make for cluttered threads. Also: upvotes and downvotes are anonymous, which is largely a good thing. So, here's one possibility. (It might just be unnecessary complication). When you vote something up or down, you get the chance (or the obligation?) to write a brief explanation of why; it doesn't go into the thread as a comment, but gets associated with the comment you voted on (without your name attached). Then hovering over a comment's score (or something) could pop up a list of votes each way and their explanations, if any. Still anonymous; out of the way when not specifically asked for; but gives some hope of finding why something was downvoted, and also a way of distinguishing between +1 -0 and +14 -13.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MBs78fg6JMTMatQZQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 12, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "285", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-05T15:39:03.228Z", "modifiedAt": null, "url": null, "title": "Formalizing Newcomb's", "slug": "formalizing-newcomb-s", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:49.213Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GZ8t3uJRPSQb2sAH3/formalizing-newcomb-s", "pageUrlRelative": "/posts/GZ8t3uJRPSQb2sAH3/formalizing-newcomb-s", "linkUrl": "https://www.lesswrong.com/posts/GZ8t3uJRPSQb2sAH3/formalizing-newcomb-s", "postedAtFormatted": "Sunday, April 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Formalizing%20Newcomb's&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFormalizing%20Newcomb's%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZ8t3uJRPSQb2sAH3%2Fformalizing-newcomb-s%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Formalizing%20Newcomb's%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZ8t3uJRPSQb2sAH3%2Fformalizing-newcomb-s", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZ8t3uJRPSQb2sAH3%2Fformalizing-newcomb-s", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 266, "htmlBody": "<p>This post was inspired by taw <a href=\"/lw/7i/rationality_is_systematized_winning/52q?context=1#52q\">urging us</a>&nbsp;to mathematize Newcomb's problem and Eliezer <a href=\"/lw/7k/incremental_progress_and_the_valley/5f9?context=2#5f9\">telling me</a>&nbsp;to post stuff I like instead of complaining.</p>\n<p>To make <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">Newcomb's problem</a> more concrete we need a workable model of Omega. Let me count the ways:</p>\n<p>1) Omega reads your decision from the future using a time loop. In this case the contents of the boxes are directly causally determined by your actions via the loop, and it's logical to one-box.</p>\n<p>2) Omega simulates your decision algorithm. In this case the decision algorithm has indexical uncertainty on whether it's being run inside Omega or in the real world, and it's logical to one-box thus making Omega give the \"real you\" the million.</p>\n<p>3) Omega \"scans your brain and predicts your decision\" without simulating you: calculates the FFT of your brainwaves or whatever. In this case you can intend to build an identical scanner, use it on yourself to determine what Omega predicted, and then do what you please. Hilarity ensues.</p>\n<p>(NB: if Omega prohibits agents from using mechanical aids for self-introspection, this is in effect a restriction on how rational you're allowed to be. If so, all bets are off - this wasn't the deal.)</p>\n<p>(Another NB: this case is distinct from 2 because it requires Omega, and thus your own scanner too, to terminate without simulating everything. A simulator Omega would go into infinite recursion if treated like this.)</p>\n<p>4) Same as 3, but the universe only has room for one Omega, e.g. the God Almighty. Then ipso facto it cannot ever be modelled mathematically, and let's talk no more.</p>\n<p>I guess this one is settled, folks. Any questions?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GZ8t3uJRPSQb2sAH3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 21, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "283", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 117, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-05T20:22:02.593Z", "modifiedAt": null, "url": null, "title": "Supporting the underdog is explained by Hanson\u2019s Near/Far distinction", "slug": "supporting-the-underdog-is-explained-by-hanson-s-near-far", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:33.052Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Roko", "createdAt": "2009-02-27T14:12:55.113Z", "isAdmin": false, "displayName": "Roko"}, "userId": "73WJbnX59kE4afuuY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v9ouxk76FMDQ4Fir9/supporting-the-underdog-is-explained-by-hanson-s-near-far", "pageUrlRelative": "/posts/v9ouxk76FMDQ4Fir9/supporting-the-underdog-is-explained-by-hanson-s-near-far", "linkUrl": "https://www.lesswrong.com/posts/v9ouxk76FMDQ4Fir9/supporting-the-underdog-is-explained-by-hanson-s-near-far", "postedAtFormatted": "Sunday, April 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Supporting%20the%20underdog%20is%20explained%20by%20Hanson%E2%80%99s%20Near%2FFar%20distinction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASupporting%20the%20underdog%20is%20explained%20by%20Hanson%E2%80%99s%20Near%2FFar%20distinction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv9ouxk76FMDQ4Fir9%2Fsupporting-the-underdog-is-explained-by-hanson-s-near-far%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Supporting%20the%20underdog%20is%20explained%20by%20Hanson%E2%80%99s%20Near%2FFar%20distinction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv9ouxk76FMDQ4Fir9%2Fsupporting-the-underdog-is-explained-by-hanson-s-near-far", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv9ouxk76FMDQ4Fir9%2Fsupporting-the-underdog-is-explained-by-hanson-s-near-far", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1100, "htmlBody": "<p class=\"MsoNormal\">Yvain can&rsquo;t make head nor tails of the apparently near universal human tendency to root for the underdog. [Read <a href=\"/lw/7s/why_support_the_underdog/\">Yvain&rsquo;s post</a> before going any further]..</p>\n<p class=\"MsoNormal\">He uses the following plausible-sounding story from a small hunter-gatherer tribe in our Era of Evolutionary Adaptedness to illustrate why support for the underdog seems to be an antiprediction of the standard theory of human evolutionary psychology:</p>\n<blockquote>\n<p class=\"MsoNormal\">Suppose Zug and Urk are battling it out for supremacy in the tribe. Urk comes up to you and says &ldquo;my faction are hopelessly outnumbered and will probably be killed, and our property divided up amongst Zug&rsquo;s supporters.&rdquo; Those cave-men with genes that made them support the underdog would join Urk&rsquo;s faction and be wiped out. Their genes would not make it very far in evolution&rsquo;s ruthless race, unless we can think of some even stronger effect that might compensate for this.</p>\n</blockquote>\n<p class=\"MsoNormal\">Yvain cites an experiment where people supported either Israel or Palestine depending on who they saw as the underdog. This seems to contradict the claim that the human mind is well adapted to its EEA.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\">A lot of people tried to use the &ldquo;truel&rdquo; situation as an explanation: in a game of three players, it is rational for the weaker two to team up against the stronger one. But the choice of which faction to join is not a truel between three approximately equal players: as an individual you will have almost no impact upon which faction wins, and if you join the winning side you won&rsquo;t necessarily be next on the menu: you will have about as much chance as anyone else in Zug&rsquo;s faction of doing well if there is another mini-war. People who proffered this explanation are guilty of not being more surprised by fiction than reality. To start with, if this theory were correct, we would expect to see soldiers defecting away from the winning side in the closing stages of a war... which, to my knowledge, is the opposite of what happens.&nbsp;</p>\n<p class=\"MsoNormal\">SoulessAutomaton comes closest to the truth when he makes the following statement:</p>\n<blockquote>\n<p class=\"MsoNormal\">there may be a critical difference between voicing sympathy for the losing faction and actually joining it and sharing its misfortune.</p>\n</blockquote>\n<p class=\"MsoNormal\">Yes! Draw Distinctions!</p>\n<p class=\"MsoNormal\">I thought about what the answer to Yvain&rsquo;s puzzle was before reading the comments &ndash; and decided that <a href=\"http://www.overcomingbias.com/2008/11/abstractdistant.html\">Robin&rsquo;s Near/Far distinction</a> is the answer.</p>\n<blockquote>\n<p><em>All of these bring each other more to mind: </em> <strong>here, now, me</strong>, us; trend-deviating likely real local events; concrete, context-dependent, unstructured, detailed, goal-irrelevant incidental features; <strong>feasible safe acts</strong>; secondary local concerns; socially close folks with unstable traits.&nbsp;</p>\n<p><em>Conversely, all these bring each other more to mind: </em> <strong>there, then, them</strong>; trend-following unlikely hypothetical global events; abstract, schematic, context-freer, core, coarse, goal-related features; <strong>desirable risk-taking acts</strong>, central global symbolic concerns, confident predictions, polarized evaluations, socially distant people with stable traits.&nbsp;</p>\n</blockquote>\n<p class=\"MsoNormal\">When you put people in a social-science experiment room and tell them, in the abstract, about the Isreal/Palestine conflict, they are in &ldquo;far&rdquo; mode. This situation is totally unlike having to choose which side to join in an actual fight &ndash; where your brain goes into &ldquo;near&rdquo; mode, and you quickly (I predict) join the likely victors. This explains the apparent contradiction between the Israel experiment and the situation in a real fight between Zug&rsquo;s faction and Urk&rsquo;s faction.</p>\n<p class=\"MsoNormal\">In a situation where there is an extremely unbalanced conflict that you are &ldquo;distant&rdquo; from, there are various reasons I can think of for supporting the underdog: but <strong>the common theme is that when the mind is in &ldquo;far&rdquo; mode, its primary purpose is to signal how nice it is, rather than to actually acquire resources</strong>. Why do we want to signal to others that we are nice people? We do this because they are more likely to cooperate with us and trust us! If evolution built a cave-man who went around telling other cave-men what a selfish bastard he was... well, that cave-man wouldn't last long.&nbsp;</p>\n<p class=\"MsoNormal\">When people support, for example, Palestine, they don't say \"I support Palestine because it is the underdog\", they say \"I support Palestine because they are the party with the ethical high ground, they are in the right, Israel is in the wrong\". In doing so, they have signalled that they support people for ethical reasons rather than self-interested reasons. Someone who is guided by ethical principles rather than self-interest makes a better ally. Conversely, someone who supports the stronger side signalls that they are more self-interested and less concerned with ethical considerations. Admittedly, this is a signal that you can fake to some extent: there is probably a tradeoff between the probability that the winning side will punish you, and the value that supporting someone for ethical reasons carries. When the conflict is very close, the probability of you becoming involved makes the signal too expensive. When the conflict is far, the signal is almost (but not quite) free.</p>\n<p class=\"MsoNormal\">You also put yourself in a better bargaining position for when you meet the victorious side: you can complain that they don't really deserve all their conquest-acquired wealth because they stole it anyway. In a world where people genuinely think that they are nicer than they really are (which is, by the way, the world of humans), being able to frame someone as being the \"bad guy\" puts you in a position of strength when negotiating. They might make concessions to preserve their self-image. In a world where you can't lie perfectly, preserving your self-image as a nice person or a nice tribe is worth making some concessions for.</p>\n<p class=\"MsoNormal\">All that remains to explain is what situation in our evolutionary past corresponds to hearing about a faraway conflict (Like Israel/Palestine for westerners who don&rsquo;t live there or have any true interest). This I am not sure about: perhaps it would be like hearing of a distant battle between two tribes? Or a conflict between two factions of your tribe, which occurs in such a way that you cannot take sides?</p>\n<p class=\"MsoNormal\">My explanation makes the prediction that if you performed a social-science experiment where people felt sufficiently close to the conflict to be personally involved, they would support the likely winner. This might involve making people very frightened and thus not pass ethics committee approval, though.</p>\n<p class=\"MsoNormal\">The only good experience I have with &ldquo;near&rdquo; tribal conflicts is my experiences at school; whenever some poor underdog was being bullied, I felt compelled to join in with the bullying, in exactly the same &ldquo;automatic&rdquo; way that I feel compelled to support the underdog in Far situations. I just couldn&rsquo;t help myself.<span>&nbsp; </span></p>\n<p class=\"MsoNormal\">Hat-tip to Yvain for admitting he couldn&rsquo;t explain this. The path to knowledge is paved with grudging admissions of your ignorance.<span>&nbsp; </span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 2, "FkzScn5byCs9PxGsA": 2, "DdgSyQoZXjj3KnF4N": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v9ouxk76FMDQ4Fir9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 28, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "318", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["A4MK9RQqSAJZjanQD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-05T22:26:38.377Z", "modifiedAt": null, "url": null, "title": "Real-Life Anthropic Weirdness", "slug": "real-life-anthropic-weirdness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:39.759Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kKAmxmQq9umJiMFSp/real-life-anthropic-weirdness", "pageUrlRelative": "/posts/kKAmxmQq9umJiMFSp/real-life-anthropic-weirdness", "linkUrl": "https://www.lesswrong.com/posts/kKAmxmQq9umJiMFSp/real-life-anthropic-weirdness", "postedAtFormatted": "Sunday, April 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Real-Life%20Anthropic%20Weirdness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReal-Life%20Anthropic%20Weirdness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkKAmxmQq9umJiMFSp%2Freal-life-anthropic-weirdness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Real-Life%20Anthropic%20Weirdness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkKAmxmQq9umJiMFSp%2Freal-life-anthropic-weirdness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkKAmxmQq9umJiMFSp%2Freal-life-anthropic-weirdness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 359, "htmlBody": "<p>In passing, I <a href=\"/lw/7k/incremental_progress_and_the_valley\">said</a>:</p>\n<blockquote>\n<p>From a statistical standpoint, lottery winners don't exist - you would never encounter one in your lifetime, if it weren't for the selective reporting.</p>\n</blockquote>\n<p>And lo, CronoDAS <a href=\"/lw/7k/incremental_progress_and_the_valley/#5dr\">said</a>:</p>\n<blockquote>\n<p>Well... one of my grandmothers' neighbors, whose son I played with as a child, did indeed win the lottery. (AFAIK, it was a relatively modest jackpot, but he did win!)</p>\n</blockquote>\n<p>To which I replied:</p>\n<blockquote>\n<p>Well, yes, some of the <em>modest</em> jackpots are statistically <em>almost</em> possible, in the sense that on a large enough web forum, someone <em>else's</em> grandmother's neighbor will have won it. Just not your <em>own</em> grandmother's neighbor.</p>\n<p>Sorry about your statistical anomalatude, CronoDAS - it had to happen to someone, just not me.</p>\n</blockquote>\n<p>There's a certain resemblance here - though not an actual analogy - to the strange position your <em>friend</em> ends up in, after <em>you</em> test the Quantum Theory of Immortality.<a id=\"more\"></a></p>\n<p>For those unfamiliar with QTI, it's a simple simultaneous test of many-worlds plus a particular interpretation of anthropic observer-selection effects:&nbsp; You put a gun to your head and wire up the trigger to a quantum coinflipper.&nbsp; After flipping a million coins, if the gun still hasn't gone off, you can be pretty sure of the simultaneous truth of MWI+QTI.</p>\n<p>But what is your watching <em>friend</em> supposed to think?&nbsp; Though his predicament is perfectly predictable to <em>you</em> - that is, you expected before starting the experiment to see his confusion - from <em>his</em> perspective it is just a pure 100% unexplained miracle.&nbsp; What you have reason to believe and what he has reason to believe would now seem separated by an uncrossable gap, which no amount of explanation can bridge.&nbsp; This is the main plausible exception I know to Aumann's Agreement Theorem.</p>\n<p>Pity those poor folk who <em>actually win the lottery!</em>&nbsp; If the hypothesis \"this world is a holodeck\" is normatively assigned a calibrated confidence well above 10<sup>-8</sup>, the lottery winner now has <em>incommunicable</em> good reason to believe they are in a holodeck.&nbsp; (I.e. to believe that the universe is such that <em>most</em> conscious observers observe ridiculously improbable positive events.)</p>\n<p>It's a sad situation to be in - but don't worry: it will always happen to someone <em>else</em>, not <em>you.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kKAmxmQq9umJiMFSp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 32, "extendedScore": null, "score": 5e-05, "legacy": true, "legacyId": "284", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 90, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oZNXmHcdhb4m7vwsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T00:19:25.192Z", "modifiedAt": null, "url": null, "title": "Rationalist Wiki", "slug": "rationalist-wiki", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:20.898Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KPp6DZXAR9SumbzJz/rationalist-wiki", "pageUrlRelative": "/posts/KPp6DZXAR9SumbzJz/rationalist-wiki", "linkUrl": "https://www.lesswrong.com/posts/KPp6DZXAR9SumbzJz/rationalist-wiki", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20Wiki&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20Wiki%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKPp6DZXAR9SumbzJz%2Frationalist-wiki%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20Wiki%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKPp6DZXAR9SumbzJz%2Frationalist-wiki", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKPp6DZXAR9SumbzJz%2Frationalist-wiki", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<p>Some (including myself) have suggested that a rationality wiki would be a useful supplement to this site. In the spirit of getting things done, I set one up here: <a href=\"http://rationality.tiddlyspot.com/\">http://rationality.tiddlyspot.com/</a> The password to save edits is omega.</p>\n<p>The <a href=\"http://www.tiddlywiki.com\">TiddlyWiki</a> framework it uses is very lightweight and won't be satisfactory as a long-term solution. I do think it has potential as a minimalist beginner's guide though, and could serve us well for the time being. I am not very knowledgable about wiki software in general, but TiddlyWiki has served me well for multiple personal wikis. I planned on developing it a little further before revealing it to the community, but other commitments demand my attention. Please feel free to contribute.</p>\n<p>Comments, suggestions? Is it better to start with something that can handle a significant user base and future growth, or should it stay small and self-contained to remain accessible to beginners?</p>\n<p><strong>Update: </strong>I think it's becoming clear this can't serve as more than a short-term hack, even for a minimalist beginner's guide. At least it is provoking discussion. I'm still hoping for contributions so we have a leg up once an official solution emerges. If you do contribute, please try to keep markup to a minimum to facilitate a future conversion.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KPp6DZXAR9SumbzJz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 11, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "319", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T01:12:31.928Z", "modifiedAt": null, "url": null, "title": "Rationality Toughness Tests", "slug": "rationality-toughness-tests", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:04.717Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinHanson", "createdAt": "2009-02-26T13:46:26.443Z", "isAdmin": false, "displayName": "RobinHanson"}, "userId": "P4HT9AG3PuXjZv5Mw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oNwbEPrat8pyBrimk/rationality-toughness-tests", "pageUrlRelative": "/posts/oNwbEPrat8pyBrimk/rationality-toughness-tests", "linkUrl": "https://www.lesswrong.com/posts/oNwbEPrat8pyBrimk/rationality-toughness-tests", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Toughness%20Tests&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Toughness%20Tests%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoNwbEPrat8pyBrimk%2Frationality-toughness-tests%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Toughness%20Tests%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoNwbEPrat8pyBrimk%2Frationality-toughness-tests", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoNwbEPrat8pyBrimk%2Frationality-toughness-tests", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 300, "htmlBody": "<p>(Epistemic) rationality has two major components:</p>\n<ul>\n<li><strong>Smarts:</strong> An ability to, by attending, infer truth from info under ideal circumstances.</li>\n<li><strong>Toughness:</strong> An ability to limit performance degradation as circumstances worsen.</li>\n</ul>\n<p>Attending takes time, energy, quiet, etc.&nbsp; Circumstances where human rationality degrades include when:</p>\n<ul>\n<li>We expect the truth to long remain hidden.</li>\n<li>The stakes are <a href=\"http://www.overcomingbias.com/2009/04/incentives-allies-cut-bias.html\">very low</a>, or <a href=\"http://www.overcomingbias.com/2009/04/choke-to-submit.html\">very high</a>, to us.</li>\n<li>Others see our opinions, and prefer certain ones.</li>\n<li>The topics are where humans <a href=\"http://www.overcomingbias.com/2009/03/how-spend-rationality-test.html\">oft self-deceive</a>.</li>\n</ul>\n<p>It seems relatively easy to test rationality smarts; repeatedly give folks info and time to work new problems and measure their accuracy, calibration, etc.&nbsp; And I have an idea for <a href=\"/lw/h/test_your_rationality/\">testing for rationality</a> toughness: compare performance on info-similar pairs of good/bad-circumstance problems.&nbsp; <br /><br />For example, assume people are better at evaluating if a spouse is cheating when considering an acquaintance in their social circle, relative to a stranger or their own spouse. If so, we could pose them a pair of problems with very similar info structure, one with an easy spouse and one with a hard spouse.&nbsp; The closeness of their response in these two cases would then be a measure of their rationality toughness.<br /><br />Of course this test may fail if the similarity is too obvious, or the pair are asked too closely in time.&nbsp; But maybe we don't even need to ask the same person the two questions; perhaps we could usefully compare someone's answer on a hard question to answers from a pool of similar people on matched easy questions.<br /><br />While I haven't thought this through, it already suggests a training technique: consider matched hard/easy circumstance problems and compare your answers, separated by enough time that you forget most of your previous analysis.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"tRPnS4FoZeWjRfBxN": 2, "Ng8Gice9KNkncxqcj": 2, "fR7QfYx4JA3BnptT9": 2, "5f5c37ee1b5cdee568cfb163": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oNwbEPrat8pyBrimk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 28, "extendedScore": null, "score": 5.5e-05, "legacy": true, "legacyId": "320", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Kn6H8Tk6EPT4Atq4k"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T06:55:10.539Z", "modifiedAt": null, "url": null, "title": "Heuristic is not a bad word", "slug": "heuristic-is-not-a-bad-word", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:25.563Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "HughRistik", "createdAt": "2009-03-10T19:45:18.256Z", "isAdmin": false, "displayName": "HughRistik"}, "userId": "edjn5sXHGjFCn9Qr7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kjua3pfeGiskAAac2/heuristic-is-not-a-bad-word", "pageUrlRelative": "/posts/kjua3pfeGiskAAac2/heuristic-is-not-a-bad-word", "linkUrl": "https://www.lesswrong.com/posts/kjua3pfeGiskAAac2/heuristic-is-not-a-bad-word", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Heuristic%20is%20not%20a%20bad%20word&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHeuristic%20is%20not%20a%20bad%20word%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkjua3pfeGiskAAac2%2Fheuristic-is-not-a-bad-word%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Heuristic%20is%20not%20a%20bad%20word%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkjua3pfeGiskAAac2%2Fheuristic-is-not-a-bad-word", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkjua3pfeGiskAAac2%2Fheuristic-is-not-a-bad-word", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 828, "htmlBody": "<p><em>An insect tries to escape through the windowpane, tries the same again and again, and does not try the next window which is open and through which it came into the room. A man is able, or at least should be able, to act more intelligently. &mdash;<a href=\"http://en.wikipedia.org/wiki/George_P%C3%B3lya\">George Polya</a>, <a href=\"http://en.wikipedia.org/wiki/How_to_solve_it\">How To Solve It</a></em><br /><br />Intelligence makes humans capable of many impressive feats. Unlike flies and birds, we don't bang up against windows multiple times trying to get out of our houses. We can travel to the moon. We have taken over the planet. Why? Because intelligence enables us to solve problems. <br /><br />All problems start the same way. They start unsolved. Each fact humans have figured out was initially unfigured out by us. Then we did <em>something</em>, which converted the unknown fact into a known fact, changed the state of a problem from unsolved to solved.<br /><br />I emphasize the unknown starting state of problems to make a point: problem solving, the basis of human achievement, depends on a process of discovery, discovery of new facts, new possibilities, new methods, and new ways of thought.<br /><br />Heuristic&mdash;the art and science of discovery&mdash;has been integral for human progress. The word \"heuristic\" is related to \"Eureka!\"<a id=\"more\"></a></p>\n<h2>Heuristics and biases<br /></h2>\n<p>Unfortunately, heuristic is a bad word. At least, that's the impression you might get, seeing it hand-in-hand with \"bias\" in the psychological literature. In <em>Judgment under Uncertainty: Heuristics and Biases</em>, <a href=\"http://en.wikipedia.org/wiki/Amos_Tversky\">Tversky</a> and <a href=\"http://en.wikipedia.org/wiki/Daniel_Kahneman\">Kahneman</a> acknowledge that \"in general, these heuristics are quite useful, but sometimes they lead to severe and systematic errors.\" On Overcoming Bias, heuristics seem primarily <a href=\"http://www.google.com/cse?cx=015839050583929870010%3Any5p7j-pnbw&amp;q=heuristic&amp;sa=%C2%BB\">discussed</a> as resulting in biases.</p>\n<p>Bias-reduction is a form of skepticism that is a critical part of rationality. Due to the <a href=\"http://en.wikipedia.org/wiki/Fallibilism\">uncertain</a> nature of the <a href=\"/lw/31/what_do_we_mean_by_rationality/\">territory</a> of reality, many notions of the territory are <a href=\"http://www.overcomingbias.com/2008/05/no-defenses.html\">wrong</a>. Rational skepticism helps us identify false assumptions, areas where our map will depart from the territory.<br /><br />While bias-reduction is necessary in the search for rationality, it is not <em>sufficient</em>. It's a mistake in cartography to have areas of your map that are filled in wrong, but it's also a mistake to have areas on your map blank that you could have filled in, at least with something approximate. A map with wrong patches will not take you to your destination, but neither will a map with blank patches. Believing things that are false is one error which will prevent us from finding the truth or winning in our endeavors, yet another error in rationality is failing to recognize or believe things that <em>are</em> true, probable, or useful.</p>\n<p>How can we draw our maps more accurately in the first place, so that they need less corrections? This is a job for heuristic.</p>\n<h2>Heuristic as rational creativity</h2>\n<p>Rationality depends on both bias-reduction and heuristic. Heuristic is the creative faculty, while overcoming bias and other skeptical techniques are the critical faculty. As Ben Kovitz proposes on the <a href=\"http://greenlightwiki.com/heuristic/Heuristic\">Heuristic Wiki</a>, \"Heuristic is about how to steer your attention so that you find things that meet the criteria of logic.\" From the start, heuristic depends on avoiding bias, or else it will be based on false assumptions and spiral off in the wrong direction. The results of even well-calibrated heuristics require critical scrutiny. Yet no matter how good your ability to critique ideas may be&mdash;to separate the wheat from the chaff&mdash;you will never learn anything if your attention is wasted on ideas that are overwhelmingly chaff; heuristic is about growing better wheat in the first place, making your winnowing efforts more productive.<br /><br />While granting and emphasizing the fallibility of heuristic and its danger of taking us away from truth, and that <a href=\"http://en.wikipedia.org/wiki/Sturgeon%27s_law\">most applications of heuristic will be crap</a>, I also want to explore the potential of heuristic to take us towards truth. I want to understand how heuristic works in practice, not just acknowledge the benefits of heuristic in principle. Heuristic enabled Tversky and Kahneman to make new discoveries about bias; it enabled Einstein to formulate General Relativity and <a href=\"http://www.overcomingbias.com/2007/09/einsteins-arrog.html\">arrogantly</a> state his confidence in it regardless of future experiments.</p>\n<p>While many of the heuristics currently scrutinized for bias seem like quaint quirks of human psychology to which we condescendingly admit usefulness in some situations, we must recognize that all of human knowledge came from heuristic and started off as a guess. To the extent that we think that humans have solved any problems&mdash;albeit approximately or provisionally&mdash;we should value heuristic. Perhaps the best heuristics are so far unarticulated or undiscovered.<br /><br />The varied results of heuristic lead me not to pessimism about heuristic, but rather to optimism about how we might identify the strong heuristics currently in use and develop even stronger ones. In future posts, I intend to delve deeper into what heuristic is, why we need it, and how to practice specific heuristics. I don't yet know a great deal about heuristic on a conscious level, but I want to figure it out.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kjua3pfeGiskAAac2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 11, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "322", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>An insect tries to escape through the windowpane, tries the same again and again, and does not try the next window which is open and through which it came into the room. A man is able, or at least should be able, to act more intelligently. \u2014<a href=\"http://en.wikipedia.org/wiki/George_P%C3%B3lya\">George Polya</a>, <a href=\"http://en.wikipedia.org/wiki/How_to_solve_it\">How To Solve It</a></em><br><br>Intelligence makes humans capable of many impressive feats. Unlike flies and birds, we don't bang up against windows multiple times trying to get out of our houses. We can travel to the moon. We have taken over the planet. Why? Because intelligence enables us to solve problems. <br><br>All problems start the same way. They start unsolved. Each fact humans have figured out was initially unfigured out by us. Then we did <em>something</em>, which converted the unknown fact into a known fact, changed the state of a problem from unsolved to solved.<br><br>I emphasize the unknown starting state of problems to make a point: problem solving, the basis of human achievement, depends on a process of discovery, discovery of new facts, new possibilities, new methods, and new ways of thought.<br><br>Heuristic\u2014the art and science of discovery\u2014has been integral for human progress. The word \"heuristic\" is related to \"Eureka!\"<a id=\"more\"></a></p>\n<h2 id=\"Heuristics_and_biases\">Heuristics and biases<br></h2>\n<p>Unfortunately, heuristic is a bad word. At least, that's the impression you might get, seeing it hand-in-hand with \"bias\" in the psychological literature. In <em>Judgment under Uncertainty: Heuristics and Biases</em>, <a href=\"http://en.wikipedia.org/wiki/Amos_Tversky\">Tversky</a> and <a href=\"http://en.wikipedia.org/wiki/Daniel_Kahneman\">Kahneman</a> acknowledge that \"in general, these heuristics are quite useful, but sometimes they lead to severe and systematic errors.\" On Overcoming Bias, heuristics seem primarily <a href=\"http://www.google.com/cse?cx=015839050583929870010%3Any5p7j-pnbw&amp;q=heuristic&amp;sa=%C2%BB\">discussed</a> as resulting in biases.</p>\n<p>Bias-reduction is a form of skepticism that is a critical part of rationality. Due to the <a href=\"http://en.wikipedia.org/wiki/Fallibilism\">uncertain</a> nature of the <a href=\"/lw/31/what_do_we_mean_by_rationality/\">territory</a> of reality, many notions of the territory are <a href=\"http://www.overcomingbias.com/2008/05/no-defenses.html\">wrong</a>. Rational skepticism helps us identify false assumptions, areas where our map will depart from the territory.<br><br>While bias-reduction is necessary in the search for rationality, it is not <em>sufficient</em>. It's a mistake in cartography to have areas of your map that are filled in wrong, but it's also a mistake to have areas on your map blank that you could have filled in, at least with something approximate. A map with wrong patches will not take you to your destination, but neither will a map with blank patches. Believing things that are false is one error which will prevent us from finding the truth or winning in our endeavors, yet another error in rationality is failing to recognize or believe things that <em>are</em> true, probable, or useful.</p>\n<p>How can we draw our maps more accurately in the first place, so that they need less corrections? This is a job for heuristic.</p>\n<h2 id=\"Heuristic_as_rational_creativity\">Heuristic as rational creativity</h2>\n<p>Rationality depends on both bias-reduction and heuristic. Heuristic is the creative faculty, while overcoming bias and other skeptical techniques are the critical faculty. As Ben Kovitz proposes on the <a href=\"http://greenlightwiki.com/heuristic/Heuristic\">Heuristic Wiki</a>, \"Heuristic is about how to steer your attention so that you find things that meet the criteria of logic.\" From the start, heuristic depends on avoiding bias, or else it will be based on false assumptions and spiral off in the wrong direction. The results of even well-calibrated heuristics require critical scrutiny. Yet no matter how good your ability to critique ideas may be\u2014to separate the wheat from the chaff\u2014you will never learn anything if your attention is wasted on ideas that are overwhelmingly chaff; heuristic is about growing better wheat in the first place, making your winnowing efforts more productive.<br><br>While granting and emphasizing the fallibility of heuristic and its danger of taking us away from truth, and that <a href=\"http://en.wikipedia.org/wiki/Sturgeon%27s_law\">most applications of heuristic will be crap</a>, I also want to explore the potential of heuristic to take us towards truth. I want to understand how heuristic works in practice, not just acknowledge the benefits of heuristic in principle. Heuristic enabled Tversky and Kahneman to make new discoveries about bias; it enabled Einstein to formulate General Relativity and <a href=\"http://www.overcomingbias.com/2007/09/einsteins-arrog.html\">arrogantly</a> state his confidence in it regardless of future experiments.</p>\n<p>While many of the heuristics currently scrutinized for bias seem like quaint quirks of human psychology to which we condescendingly admit usefulness in some situations, we must recognize that all of human knowledge came from heuristic and started off as a guess. To the extent that we think that humans have solved any problems\u2014albeit approximately or provisionally\u2014we should value heuristic. Perhaps the best heuristics are so far unarticulated or undiscovered.<br><br>The varied results of heuristic lead me not to pessimism about heuristic, but rather to optimism about how we might identify the strong heuristics currently in use and develop even stronger ones. In future posts, I intend to delve deeper into what heuristic is, why we need it, and how to practice specific heuristics. I don't yet know a great deal about heuristic on a conscious level, but I want to figure it out.</p>", "sections": [{"title": "Heuristics and biases", "anchor": "Heuristics_and_biases", "level": 1}, {"title": "Heuristic as rational creativity", "anchor": "Heuristic_as_rational_creativity", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "13 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T14:16:30.733Z", "modifiedAt": null, "url": null, "title": "Rationalists should beware rationalism", "slug": "rationalists-should-beware-rationalism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:21.573Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b88EtWvjyRQc89XzT/rationalists-should-beware-rationalism", "pageUrlRelative": "/posts/b88EtWvjyRQc89XzT/rationalists-should-beware-rationalism", "linkUrl": "https://www.lesswrong.com/posts/b88EtWvjyRQc89XzT/rationalists-should-beware-rationalism", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalists%20should%20beware%20rationalism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalists%20should%20beware%20rationalism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb88EtWvjyRQc89XzT%2Frationalists-should-beware-rationalism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalists%20should%20beware%20rationalism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb88EtWvjyRQc89XzT%2Frationalists-should-beware-rationalism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb88EtWvjyRQc89XzT%2Frationalists-should-beware-rationalism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 973, "htmlBody": "<p><em>Rationalism is most often characterized as an epistemological position. On this view, to be a rationalist requires at least one of the following: (1) a privileging of reason and intuition over sensation and experience, (2) regarding all or most ideas as innate rather than adventitious, (3) an emphasis on certain rather than merely probable knowledge as the goal of enquiry.</em> -- The Stanford Encyclopedia of Philosophy <a href=\"http://plato.stanford.edu/entries/continental-rationalism/\">on Continental Rationalism.<br /><br /></a>By now, there are some things which most <em>Less Wrong</em> readers will agree on. One of them is that beliefs must be fueled by <a href=\"http://www.overcomingbias.com/2007/09/what-is-evidenc.html\">evidence gathered from the environment</a>. A belief must correlate with reality, and an important part of that is whether or not it can be tested - if a belief produces no <a href=\"http://www.overcomingbias.com/2007/07/making-beliefs-.html\">anticipation of experience</a>, it is nearly worthless. We can <a href=\"http://www.overcomingbias.com/2007/08/conservation-of.html\">never try to confirm a theory</a>, only test it.</p>\n<p>But yet, we seem to have no problem coming up with theories that are either untestable or that we have no intention of testing, such as evolutionary psychological explanations for the <a href=\"/lw/7s/why_support_the_underdog/\">underdog</a> <a href=\"/lw/8u/supporting_the_underdog_is_explained_by_hansons/\">effect</a>.</p>\n<p>I'm being a bit unfair here. Those posts were well thought out and reasonably argued, and Roko's post actually made testable predictions. Yvain even made a good try at solving the puzzle, and when he couldn't, he reasonably concluded that he was stumped and asked for help. That sounds like a <a href=\"http://www.overcomingbias.com/2006/12/the_proper_use_.html\">proper use of humility</a> to me.</p>\n<p>But the way that ev-psych explanations get rapidly manufactured and carelessly flung around on OB and LW has always been a bit of a pet peeve for me, as that's exactly how <em>bad</em> evpsych gets done. The best evolutionary psychology takes biological and evolutionary facts, applies those to humans and then makes testable predictions, which it goes on to verify. It doesn't take existing behaviors and then try to come up with some nice-sounding rationalization for them, blind to whether or not the rationalization can be tested. <strong>Not every behavior needs to have an evolutionary explanation</strong> - it could have evolved via genetic drift, or be a pure side-effect from some actual adaptation. If we set out by trying to find an evolutionary reason for some behavior, we are assuming from the start that there must be one, when it isn't a given that there is. And even a good theory <a href=\"http://www.overcomingbias.com/2007/08/update-yourself.html\">need not explain every observation</a>.<a id=\"more\"></a></p>\n<p>Obviously I'm not saying that we should never come up with such theories. <a href=\"http://yudkowsky.net/rational/virtues\">Be wary of those who speak of being open-minded and modestly confess their ignorance</a><em>. </em>But we <em>should</em> avoid giving them excess weight, and instead assign them very broad confidence intervals. <em>This seems to contradict the claim that the human mind is well adapted to its EEA. Is evolutionary psychology wrong? Maybe the creationists are correct after all </em><a href=\"/lw/8u/supporting_the_underdog_is_explained_by_hansons/\">writes Roko</a>, implying that it is crucial for us to come up with an explanation (yes, I do know that this is probably just a dramatic exaggaration on Roko's part, but it made such a good example that I couldn't help but to use it). But regardless of whether or not we do come up with an explanation, that explanation doesn't carry much weight if it doesn't provide testable predictions. And even if it did provide such predictions, we'd need to find confirming evidence first, before lending it much credence.</p>\n<p>I suspect that we rationalists may have a tendency towards rationalism, as in the meaning above. In order to learn how to think, we study math and probability theory. We consider different fallacies, and find out how to dismantle broken reasoning, both that of others and our own. We learn to downplay the role of our personal experiences, recognizing that those may be just the result of a random effect and a small sample size. But learning to think more like a mathematician, whose empiricism resides in the realm of pure thought, does not predispose us to more readily go collect evidence from the real world. Neither does the downplaying of our personal experiences. Many are computer science majors, used to being in the comfortable position of being capable of testing their hypotheses without needing to leave their office. It is, then, an easy temptation to come up with a nice-sounding theory which happens to explain the facts, and then consider the question solved. Reason must reign supreme, must it not?</p>\n<p>But if we really do so, we are endangering our ability to find the truth in the future. Our <a href=\"/lw/6i/deliberate_and_spontaneous_creativity/\">existing preconceptions constrain part of our creativity</a>, and if we believe untested hypotheses too uncritically, the true ones may never even occur to us. If we believe in one falsehood, then everything that we build on top of it will also be flawed.</p>\n<p>This isn't to say that all tests would necessarily <em>have</em> to involve going out of your room to dig for fossils. A hypothesis does get some validation from simply being compatible with existing knowledge - that's how they pass the initial \"does this make sense\" test in the first place. Certainly, a scholarly article citing several studies and theories in its support is already drawing on considerable supporting evidence. It often happens that a conclusion, built on top of previous knowledge, is so obvious that you don't even need to test it. Roko's post, while not yet in this category, drew on already established arguments relating to the Near-Far distinction and other things, and I do in fact find it rather plausible. Unless contradictory evidence comes in, I'll consider it the best explanation of the underdog phenomenon, one which I can build further hypotheses on. But I do keep in mind that none of its <em>predictions</em> have been tested yet, and that it might still be wrong.</p>\n<p>It is therefore that I say: certainly do come up with all kinds of hypotheses, but if they haven't been tested, be careful not to believe in them too much.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"9YFoDPFwMoWthzgkY": 2, "izp6eeJJEg9v5zcur": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b88EtWvjyRQc89XzT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 32, "extendedScore": null, "score": 5.3e-05, "legacy": true, "legacyId": "323", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["A4MK9RQqSAJZjanQD", "v9ouxk76FMDQ4Fir9", "5aaPPRAM6JdLqceqX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T17:05:23.522Z", "modifiedAt": null, "url": null, "title": "Newcomb's Problem standard positions", "slug": "newcomb-s-problem-standard-positions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.571Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WhzCbrxG4KzFz7W4d/newcomb-s-problem-standard-positions", "pageUrlRelative": "/posts/WhzCbrxG4KzFz7W4d/newcomb-s-problem-standard-positions", "linkUrl": "https://www.lesswrong.com/posts/WhzCbrxG4KzFz7W4d/newcomb-s-problem-standard-positions", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Newcomb's%20Problem%20standard%20positions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANewcomb's%20Problem%20standard%20positions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhzCbrxG4KzFz7W4d%2Fnewcomb-s-problem-standard-positions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Newcomb's%20Problem%20standard%20positions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhzCbrxG4KzFz7W4d%2Fnewcomb-s-problem-standard-positions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhzCbrxG4KzFz7W4d%2Fnewcomb-s-problem-standard-positions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<p><a href=\"http://kops.ub.uni-konstanz.de/volltexte/2000/524/pdf/ledwig.pdf \">Marion Ledwig's dissertation</a> summarizes much of the existing thinking that's gone into Newcomb's Problem.</p>\n<p>(For the record, <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">I myself</a> am neither an evidential decision theorist, nor a causal decision theorist in the current sense.&nbsp; My view is not easily summarized, but it is <em>reflectively consistent </em>without need of precommitment or similar dodges; my agents see no need to modify their own source code or invoke abnormal decision procedures on Newcomblike problems.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fihKHQuS5WZBJgkRm": 1, "5f5c37ee1b5cdee568cfb28e": 1, "5f5c37ee1b5cdee568cfb28f": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WhzCbrxG4KzFz7W4d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 7, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "324", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T17:10:02.598Z", "modifiedAt": null, "url": null, "title": "Average utilitarianism must be correct?", "slug": "average-utilitarianism-must-be-correct", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:32.456Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/px4nYEy3rDqeegJw3/average-utilitarianism-must-be-correct", "pageUrlRelative": "/posts/px4nYEy3rDqeegJw3/average-utilitarianism-must-be-correct", "linkUrl": "https://www.lesswrong.com/posts/px4nYEy3rDqeegJw3/average-utilitarianism-must-be-correct", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Average%20utilitarianism%20must%20be%20correct%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAverage%20utilitarianism%20must%20be%20correct%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpx4nYEy3rDqeegJw3%2Faverage-utilitarianism-must-be-correct%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Average%20utilitarianism%20must%20be%20correct%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpx4nYEy3rDqeegJw3%2Faverage-utilitarianism-must-be-correct", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpx4nYEy3rDqeegJw3%2Faverage-utilitarianism-must-be-correct", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 753, "htmlBody": "<p>I said this in a comment on <a href=\"/lw/7w/reallife_anthropic_weirdness/\">Real-life entropic weirdness</a>, but it's getting off-topic there, so I'm posting it here.</p>\n<p>My original writeup was confusing, because I used some non-standard terminology, and because I wasn't familiar with the crucial theorem.&nbsp; We cleared up the terminological confusion (thanks esp. to conchis and Vladimir Nesov), but the question remains.&nbsp; I rewrote the title yet again, and have here a restatement that I hope is clearer.</p>\n<ul>\n<li>We have a utility function u(outcome) that gives a utility for one possible outcome.&nbsp; (Note the word <em>utility</em>.&nbsp; That means your diminishing marginal utility, and all your preferences, and your aggregation function for a single outcome, are already incorporated into this function.&nbsp; There is no need to analyze u further, as long as we agree on using a utility function.)</li>\n<li>We have a utility function U(lottery) that gives a utility for a probability distribution over all possible outcomes.</li>\n<li>The von Neumann-Morgenstern theorem indicates that, given 4 reasonable axioms about U, the only reasonable form for U is to calculate the expected value of u(outcome) over all possible outcomes.&nbsp; This is why we constantly talk on LW about rationality as maximizing expected utility.</li>\n<li>This means that your utility function U is indifferent with regard to whether the distribution of utility is equitable among your future selves.&nbsp; Giving one future self u=10 and another u=0 is equally as good as giving one u=5 and another u=5.</li>\n<li>This is the same ethical judgement that an average utilitarian makes when they say that, to calculate social good, we should calculate the average utility of the population; modulo the problems that population can change and that not all people are equal.&nbsp; This is clearer if you use a many-worlds interpretation, and think of maximizing expected value over possible futures as applying average utilitarianism to the population of all possible future yous.</li>\n<li>Therefore, I think that, if the 4 axioms are valid when calculating U(lottery), they are probably also valid when calculating not our private utility, but a <em>social</em> utility function s(outcome), which sums over people in a similar way to how U(lottery) sums over possible worlds.&nbsp; The theorem then shows that we should set s(outcome) = the average value of all of the utilities for the different people involved. (In other words, average utilitarianism is <em>correct</em>).&nbsp; Either that, or the axioms are inappropriate for both U and s, and we should not define rationality as maximizing expected utility.</li>\n<li>(I am not saying that the theorem reaches down through U to say anything directly about the form of u(outcome).&nbsp; I am saying that choosing a shape for U(lottery) is the same type of ethical decision as choosing a shape for s(outcome); and the theorem tells us what U(lottery) should look like; and if that ethical decision is right for U(lottery), it should also be right for s(outcome). ) </li>\n<li>And yet, average utilitarianism asserts that equity of utility, even among equals, has no utility.&nbsp; This is shocking, especially to Americans.</li>\n<li>It is even more shocking that it is thus possible to prove, given reasonable assumptions, which type of utilitarianism is correct.&nbsp; One then wonders what other seemingly arbitrary ethical valuations actually have provable answers given reasonable assumptions.</li>\n</ul>\n<p>Some problems with average utilitarianism from the <a href=\"http://plato.stanford.edu/entries/repugnant-conclusion/\">Stanford Encyclopedia of Philosophy</a>:</p>\n<blockquote>\n<p>Despite these advantages, average utilitarianism has not obtained much acceptance in the philosophical literature. This is due to the fact that the principle has implications generally regarded as highly counterintuitive. For instance, the principle implies that for any population consisting of very good lives there is a better population consisting of just one person leading a life at a slightly higher level of well-being (Parfit 1984 chapter 19). More dramatically, the principle also implies that for a population consisting of just one person leading a life at a very negative level of well-being, e.g., a life of constant torture, there is another population which is better even though it contains millions of lives at just a slightly less negative level of well-being (Parfit 1984). That total well-being should not matter when we are considering lives worth ending is hard to accept. Moreover, average utilitarianism has implications very similar to the Repugnant Conclusion (see Sikora 1975; Anglin 1977).</p>\n</blockquote>\n<p>(If you assign different weights to the utilities of different people, we could probably get the same result by considering a person with weight W to be equivalent to W copies of a person with weight 1.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zs4nYLkNr7Rbo4mAP": 1, "ouT6wKhACJRouGokM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "px4nYEy3rDqeegJw3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 7, "extendedScore": null, "score": 1.1e-05, "legacy": true, "legacyId": "325", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 169, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kKAmxmQq9umJiMFSp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T19:24:43.022Z", "modifiedAt": null, "url": null, "title": "Rationalist wiki, redux", "slug": "rationalist-wiki-redux", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:21.485Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZXLnFxLgpm3KtLo6q/rationalist-wiki-redux", "pageUrlRelative": "/posts/ZXLnFxLgpm3KtLo6q/rationalist-wiki-redux", "linkUrl": "https://www.lesswrong.com/posts/ZXLnFxLgpm3KtLo6q/rationalist-wiki-redux", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20wiki%2C%20redux&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20wiki%2C%20redux%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZXLnFxLgpm3KtLo6q%2Frationalist-wiki-redux%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20wiki%2C%20redux%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZXLnFxLgpm3KtLo6q%2Frationalist-wiki-redux", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZXLnFxLgpm3KtLo6q%2Frationalist-wiki-redux", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 179, "htmlBody": "<p>This site is very likely impenetrable to the newcomer. You <em>one-box</em> and <em>defect</em> on the <em>True Prisoner's Dilemma</em>, but is that just because of a <em>cached thought</em>, or is it your <em>Tsuyoku Naratai</em>?&nbsp; So I've created the <a href=\"http://lesswrong.wikia.com/wiki/LessWrong_Wiki\">LessWrong Wiki on Wikia</a>. I'd like this to become a respository of useful definitions and links: it can support our discussions here, and create something lasting from the ephemerality of a blog.</p>\n<p>badger <a href=\"/lw/8v/rationalist_wiki/\">already created a Wiki</a>, but as you can see in the updates to that article badger and others pretty quickly concluded that TiddlyWiki wouldn't be up to the job. MediaWiki, the software Wikipedia and Wikia use, is the monster of them all, and will give us good support for practically anything we want to do, including mathematical notation. I've ported across a couple of articles from the old wiki onto the new, but many more are needed. The \"download\" link in TiddlyWiki and a text editor may help.</p>\n<p>EDIT: Usernames are global across all of Wikia, so you may not be able to use the same name there as here. Sorry.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZXLnFxLgpm3KtLo6q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 12, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "327", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KPp6DZXAR9SumbzJz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T22:08:13.104Z", "modifiedAt": null, "url": null, "title": "What do fellow rationalists think about Mensa?", "slug": "what-do-fellow-rationalists-think-about-mensa", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.428Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vgxMj9X3KwXdNtTTS/what-do-fellow-rationalists-think-about-mensa", "pageUrlRelative": "/posts/vgxMj9X3KwXdNtTTS/what-do-fellow-rationalists-think-about-mensa", "linkUrl": "https://www.lesswrong.com/posts/vgxMj9X3KwXdNtTTS/what-do-fellow-rationalists-think-about-mensa", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20do%20fellow%20rationalists%20think%20about%20Mensa%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20do%20fellow%20rationalists%20think%20about%20Mensa%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgxMj9X3KwXdNtTTS%2Fwhat-do-fellow-rationalists-think-about-mensa%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20do%20fellow%20rationalists%20think%20about%20Mensa%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgxMj9X3KwXdNtTTS%2Fwhat-do-fellow-rationalists-think-about-mensa", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgxMj9X3KwXdNtTTS%2Fwhat-do-fellow-rationalists-think-about-mensa", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 269, "htmlBody": "<p>It's not a typical OB/LW subject, but Robin correctly pointed out that most rationalists are outside OB/LW, and so I'm asking about one of the organizations that might hold many of them.</p>\n<p>A couple of weeks ago I took a supervised IQ test by Mensa due to curiosity and for some CV padding (cheap signaling is a perfectly rational thing to do). Now I got a letter back from them that I'm in top whatever %, and they'd like me to join. I wasn't really planning joining Mensa, or anything else, so I'm wondering - does any of fellow rationalists have any experience with them? Is it worth bothering?</p>\n<p>As a bonus here's a quick description of their supervised IQ testing process:</p>\n<ul>\n<li>First you get Catell scale B test, which is a mix of English word puzzles, picture puzzles, and logic puzzles. It obviously discriminates against non-native speakers. It has somewhat tight per-page timing. It seems to have stddev 24.</li>\n<li>Then after a break you get Catell Culture Fair test, which is pure pictures, on extremely tight and stressful per-page timing. It seems to have stddev 16.</li>\n</ul>\n<p>They compute percentile based on both tests separately, and higher of two counts as the result. So you can has 0 points on one (if at all possible), and respectively 148 / 132 on the other, and you're in (2 stddev above mean, or top 2%). The tests obviously check knowledge of obscure English words and meanings and ability to deal with pressure in addition to intelligence as such. Well, I guess no test is perfect.</p>\n<p>So Mensa - good or bad?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4cKQgA4S7xfNeeWXg": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vgxMj9X3KwXdNtTTS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 3, "extendedScore": null, "score": 4.861175714650459e-07, "legacy": true, "legacyId": "329", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-06T22:57:31.701Z", "modifiedAt": null, "url": null, "title": "Extenuating Circumstances", "slug": "extenuating-circumstances", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:39.674Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XYrcTJFJoYKX2DxNL/extenuating-circumstances", "pageUrlRelative": "/posts/XYrcTJFJoYKX2DxNL/extenuating-circumstances", "linkUrl": "https://www.lesswrong.com/posts/XYrcTJFJoYKX2DxNL/extenuating-circumstances", "postedAtFormatted": "Monday, April 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Extenuating%20Circumstances&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExtenuating%20Circumstances%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYrcTJFJoYKX2DxNL%2Fextenuating-circumstances%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Extenuating%20Circumstances%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYrcTJFJoYKX2DxNL%2Fextenuating-circumstances", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYrcTJFJoYKX2DxNL%2Fextenuating-circumstances", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1293, "htmlBody": "<p><strong>Followup to</strong>:&nbsp; <a href=\"http://www.overcomingbias.com/2007/03/tsuyoku_naritai.html\">Tsuyoku Naritai</a></p>\n<blockquote>\n<p>\"Just remember, there but for a massive genetic difference, environmental factors, and conscious choices, go you or I.\" -- Justin Corwin</p>\n</blockquote>\n<p>Failures don't have single causes.&nbsp; We <em>choose</em> single causes to <em>focus</em> on, but nothing in the universe emerges from a single parent event.&nbsp; Every assassination ever committed is the fault of every asteroid that wasn't in the right place to hit the assassin.</p>\n<p>What good, then, does it do to blame <em>circumstances</em> for your failure?&nbsp; What good does it do? - to look over a huge causal lattice in which your own decisions played a part, and point to something you can't control, and say:&nbsp; \"<em>There</em> is where it failed.\"&nbsp; It might be that a surgical intervention on the past, altering some node outside yourself, would have let you succeed instead of fail.&nbsp; But what good does this counterfactual do you?&nbsp; Will you <em>choose</em> that outside reality be different on your next try?</p>\n<p>And yet... when I look at <em>other</em> people, not myself, I find myself taking \"extenuating circumstances\" into account a great deal.&nbsp; I go to great lengths to \"save the world\" (as I believe from my epistemic vantage point).&nbsp; When I consider doing less, I consider that this would make me a horrible awful unforgivable person.&nbsp; And then I cheerfully shake hands with others who aren't trying <em>at all </em>to save the world.&nbsp; I seem to want to have my cake and eat it too - to instantiate <a href=\"/lw/2o/soulless_morality/\">Goetz's Paradox</a>:&nbsp; \"Society tells you to work to make yourself more valuable.&nbsp; Then it tells you that when you reason morally, you must assume that all lives are equally valuable.&nbsp; You can't have it both ways.\"</p>\n<p>Is this an inherent subjective asymmetry - does morality just look different from the outside than inside?&nbsp; If so, is that okay, or is it a sign of self-contradiction?&nbsp; Or is it condescension on my part - that I think less of others and so hold them to lower standards?<a id=\"more\"></a></p>\n<p>I've pondered this question for a while, and this is the main defense I can offer against the charge of condescension:</p>\n<p>I wouldn't tell others to take into account \"extenuating circumstances\" in judging <em>themselves</em>.</p>\n<p>Indeed, that would feel like an act of sabotage - like slashing their tires.&nbsp; Too much of life consists of holding ourselves to a high enough standard.</p>\n<p>There <em>are</em> people who blame themselves too easily - people depressed, falling into despair and not moving forward, because they blame themselves for things they couldn't help.</p>\n<p>But you really want to be very careful with applying this kind of reasoning to <em>yourself</em>, because a whole whack of a lot of people who were successful in life got there by driving straight through problems that <em>couldn't be helped</em>.&nbsp; I'm minded of a recent comment on Hacker News (not sure where) about someone who wanted to work at a certain game company, only there were no jobs available and no H.R. contact listed... so they looked at the numbers listed and deduced the corporate phone prefix, then systematically dialed telephone numbers until they got the CEO's office, and then pled their case to be hired.&nbsp; They did not, in fact, get that job; but, not surprisingly, <em>did </em>eventually end up employed in their chosen industry.&nbsp; Contrast to someone who reasons, \"I won't be able to get a job <em>now</em> - there's a recession!\"</p>\n<p>For yea, I have watched some people be stopped in their tracks <a href=\"http://www.overcomingbias.com/2008/10/use-the-try-har.html\">without trying</a> by \"obstacles\" that <em>other </em>people I know, Silicon Valley entrepreneur types, would roll over like a steamroller flattening out a speedbump.&nbsp; That difference probably accounts for a <em>lot</em> of real life performance, and it probably has a great deal to do with what, exactly, you regard as a valid excuse - a condition that makes a failure <em>not</em> reflect badly on you.</p>\n<p>A lot of people would regard being 14 years old as a valid excuse for not starting your own company.&nbsp; Not <a href=\"http://ben.casnocha.com/\">Ben Casnocha</a>, though.</p>\n<p>If someone has advanced to the point of <em>explicitly</em> pleading some excuse, then that's probably the point at which I <em>do </em>begin to hold them accountable.&nbsp; When someone says to me, \"I haven't signed up my teenage son for cryonics because I'm religious so I must not believe in that sort of thing,\" I think, <em>Well, I can't blame them, they don't know anything about rationality.</em>&nbsp; But if they say, \"I haven't signed up my teenage son for cryonics, because I don't know anything about rationality, so you can't expect me to give the correct answer to this dilemma,\" then at <em>that</em> point I really might start blaming them.</p>\n<p>The way a real extenuating circumstance looks <a href=\"http://www.overcomingbias.com/2008/02/algorithm-feels.html\">from the inside</a> is not that you think \"I have an extenuating circumstance, so I can be excused for failing to do X\", but rather, that X just doesn't seem like an available option at all, or X seems like it would have so many penalties attached that it's <em>not </em>in fact the best option which you could and should perform but aren't performing.</p>\n<p>Similarly, if ignorance is your extenuating circumstance, you just don't <em>realize</em> that X is a good idea, rather than thinking to yourself, \"I am ignorant of the fact that X is a good idea, therefore I can be excused for failing to choose it.\"</p>\n<p>Like \"to believe falsely\", if there were a verb meaning \"to forgive due to extenuating circumstances\", it would have no first-person, present-tense indicative.</p>\n<p>So I would advise others, like myself, not to think in terms of \"extenuating circumstances\" at all; I would advise people to hold themselves accountable for every dilemma they have advanced to the point of explicitly perceiving as a dilemma - the same rule I use internally.&nbsp; This is my defense against the charge of condescension / Goetz's Paradox - that at this sufficiently meta level, I would tell others to use the same rule as I.</p>\n<p>If I hold myself responsible for doing certain things, it is because I perceive them as morally-good, prosocially-obligatory options... which I may nonetheless have some difficulty in doing... but which I nonetheless <em>could </em>realistically do without overspending my mental energy budget.</p>\n<p>That's my own main limit, incidentally, my mental energy budget.&nbsp; I am constantly wrestling with the fact of its reality, because it sounds like such a hideously wonderful excuse that my reflexes keep on doubting it.&nbsp; On any given occasion I'm never sure if it's a valid justification.&nbsp; And so when I do run up against my limits hard enough that there's no mistaking them, there's a certain guilty pleasure of validation, that I can feel <em>less </em>guilty about having done less on other occasions...</p>\n<p>Well, that's my own demon to wrestle with.&nbsp; My intended point here is that <a href=\"http://www.overcomingbias.com/2006/12/the_proper_use_.html\">I could be wrong</a> about my mental energy budget.&nbsp; I could be doing too little, relative to what I can do without overspending myself.&nbsp; But I couldn't possibly say-in-the-moment, \"I'm failing to choose the right option, but as an extenuating circumstance, I underestimated my own mental energy.\"&nbsp; If I <em>am </em>wrong, some forgiving other might look upon it as an \"extenuating circumstance\".&nbsp; But I cannot <em>myself </em>say, \"And if I'm wrong, then that's an extenuating circumstance.\"&nbsp; From my own perspective, rather, I am obliged to not be wrong.</p>\n<p>\"<em>There are no outs.</em>&nbsp; Even if someone else would call it an extenuating circumstance and forgive me for giving up, I'll just get it done anyway.\"&nbsp; I'm not a venture capitalist, but if I were, that's the attitude I'd want to see in a startup founder before I invested money.</p>\n<p>If after all that the project failed <em>anyway,</em> then I might really believe that everything that could be done, had been done...</p>\n<p>...so long as it wasn't <em>my</em> project, which is supposed by golly to <em>succeed</em> and not fail due to \"extenuating circumstances\".</p>\n<p>A true rationalist should <em>win,</em> after all.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hrezrpGqXXdSe76ks": 2, "GDGYkF29pxEQNWjYc": 2, "nSHiKwWyMZFdZg5qt": 2, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XYrcTJFJoYKX2DxNL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 45, "extendedScore": null, "score": 6.9e-05, "legacy": true, "legacyId": "326", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["E5QXf3tCeE7fZGq4t"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-07T02:44:26.333Z", "modifiedAt": null, "url": null, "title": "On Comments, Voting, and Karma - Part I", "slug": "on-comments-voting-and-karma-part-i", "viewCount": null, "lastCommentedAt": "2009-04-09T17:17:58.535Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "thomblake", "createdAt": "2009-02-27T15:35:08.282Z", "isAdmin": false, "displayName": "thomblake"}, "userId": "zCHE6bXWKB6kfJsJS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aoLncXJMFfTH9vL5a/on-comments-voting-and-karma-part-i", "pageUrlRelative": "/posts/aoLncXJMFfTH9vL5a/on-comments-voting-and-karma-part-i", "linkUrl": "https://www.lesswrong.com/posts/aoLncXJMFfTH9vL5a/on-comments-voting-and-karma-part-i", "postedAtFormatted": "Tuesday, April 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Comments%2C%20Voting%2C%20and%20Karma%20-%20Part%20I&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Comments%2C%20Voting%2C%20and%20Karma%20-%20Part%20I%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaoLncXJMFfTH9vL5a%2Fon-comments-voting-and-karma-part-i%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Comments%2C%20Voting%2C%20and%20Karma%20-%20Part%20I%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaoLncXJMFfTH9vL5a%2Fon-comments-voting-and-karma-part-i", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaoLncXJMFfTH9vL5a%2Fon-comments-voting-and-karma-part-i", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1279, "htmlBody": "<p>There has been a great deal of discussion here about the proper methods of voting on comments and on how karma should be assigned. &nbsp;I believe it's finally reached the point where a post is warranted that covers some of the issues involved. &nbsp;(This may be just because I find myself frequently in disagreement with others about it.)</p>\n<h3>The Automatic Upvote<br /></h3>\n<p>First, there is the question of whether one should be able to upvote one's own comment. &nbsp;This actually breaks apart into two related concerns:</p>\n<p>(1) One is able to upvote one's own comments, and</p>\n<p>(2) One gains a point of karma just for posting a comment.</p>\n<p>These need not be tied. &nbsp;We could have (2) without (1) by awarding a point of karma for commenting, without changing the comment's score. &nbsp;We could also have (1) without (2) by simply not counting self-upvotes for karma.</p>\n<p>I am in favor of (2). &nbsp;The main argument against (2) is that it rewards quantity over quality. &nbsp;The main argument for (2) is that it offers an automatic incentive to post comments; that is, it rewards commenting over silence. &nbsp;As we're community-building, I think the latter incentive is more important than the former. &nbsp;But I'm not sure this is worth arguing further - it serves as a distraction from the benefits of (1).</p>\n<p>I am also in favor of (1). &nbsp;As a default, all comments have a base rating of 0. &nbsp;Since one is allowed to vote on one's own comments, and upvoting is the default for one's own comments, this makes comments effectively start at a rating of 1. &nbsp;The argument against this is that it makes more sense for comments to start with a rating of 0, so that someone else liking a comment gives it a positive rating, while someone disliking it gives it a negative rating. &nbsp;I disagree with this assessment.</p>\n<p>If I post a comment, it's because it's the best comment I could think of to add to the discussion. &nbsp;I will usually not bother saying something if I don't think it's the sort of thing that I would upvote. &nbsp;When I see someone else's comment that I don't think is very good, I downvote it. &nbsp;Since they already upvoted it, I'm in effect disagreeing that this was something worth saying. &nbsp;The score now reflects this - a score of 0 shows that one person thought it was a worthwhile comment, and one person did not.</p>\n<p>Furthermore, if I was not able to vote on my own comments, I would be much more reluctant to upvote. &nbsp;Since I would not be able to upvote my comment, upvoting someone else's comment would suggest that I think their comment is better than my own. But by hypothesis, I thought my comment was nearly the best thing that could be said on the subject; thus, upvotes will be rare.</p>\n<p>And so I say that we implement a compromise - (1) and not (2).</p>\n<h3>What should upvote/downvote mean?<br /></h3>\n<p>I think it is established pretty well that upvote means \"High quality comment\" or \"I would like to see more comments like this one\", while downvote means \"Low quality comment\" or \"I would like to see fewer comments like this one\". &nbsp;However, this definition still retains a good bit of ambiguity.</p>\n<p>It is too easy to think of upvote and downvote as 'agree' and 'disagree'. &nbsp;Even guarding myself against this behavior I find the cursor drifting to downvote as soon as I think, \"Well that's obviously wrong\". &nbsp;But that's clearly not what the concept is there for. &nbsp;Comments voted up appear higher on the page (on certain views), which allows casual readers to see the best comments and discussions on any particular post. &nbsp;If we use upvote and downvote to mean 'agree' and 'disagree', then this is effectively an echo chamber, where the only comments to float to the top are the ones that jive with the groupthink.</p>\n<p>Instead, upvote and downvote should reflect overall quality of a comment. &nbsp;There are several criteria I tend to use to judge a good comment (this list is not all-inclusive):</p>\n<ol>\n<li>Did the comment add any information, or did it just add to the noise? (+)</li>\n<li>Does the comment include references or links to relevant information? (+)</li>\n<li>Does the comment reflect a genuinely held point-of-view that adds to the discussion? (+)</li>\n<li>Is the comment part of a discussion that might lead somewhere interesting? (+)</li>\n<li>Is the comment obvious spam / trolling? (-)</li>\n<li>Is the comment off-topic? (-)</li>\n</ol>\n<p>Since we feel the need to voice whether we agree or disagree with comments, but 'I agree' and 'I disagree' comments are noisy, it's been suggested that there should be separate buttons to indicate agreement and disagreement. &nbsp;Thus, someone posting a well-argued on-topic defense of theism can get the upvote and 'disagree', while someone posting an off-topic 'physicalism is true' can get the downvote and 'agree'. &nbsp;Presumably, we'd only count upvotes and downvotes for karma, but we could use 'agree' and 'disagree' for \"most controversial\" or other views/metrics.</p>\n<h3>Whether votes should require an explanation<br /></h3>\n<p>It has been suggested that votes, or downvotes specifically, should require an explanation. &nbsp;I disagree with both sentiments. &nbsp;First, requiring explanations for downvotes but not upvotes would bias the voting positively, which would have the effect of rewarding quantity over quality and decrease the impact of downvotes.</p>\n<p>But requiring explanations for votes is in general a bad idea. &nbsp;This site is already a burden to keep up with; for those of us that do a lot of voting, writing an explanation for each one would be too much time and effort. &nbsp;Requiring an explanation for every vote would doubtless result in a lot less voting. &nbsp;Also, explaining votes is almost always off-topic, so adds to the noise here without really contributing to the discussion.</p>\n<p>Note Yvain's more personal rationale:</p>\n<blockquote>I'm not prepared to write an essay explaining exactly was wrong with each of them, especially if the original commenter wasn't prepared to take three seconds to write a halfway decent response.</blockquote>\n<p>Adding to the burden of those already performing the service of voting unduly penalizes those who are doing good, to the end of appeasing those who are contributing to the noise here.</p>\n<h3>Relevant Comments<br /></h3>\n<p>For reference, some links to relevant posts and sections of comments. &nbsp;I tried to be inclusive, since there have been a lot of discussions about these issues - more relevant ones hopefully near the top. (Please comment if you know of any other relevant discussions)</p>\n<p><a title=\"Your price for joining\" href=\"/lw/5j/your_price_for_joining/3pk?context=1#3pk\">1</a> <a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/u\">2</a> <a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/2u#comments\">3</a> what upvote and downvote should mean and whether there should be agree/disagree buttons</p>\n<p><a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/ba#comments\">4</a> whether karma should be the sum of individual post scores, or (perhaps) an average</p>\n<p><a title=\"Simultaneously Right and Wrong\" href=\"/lw/1d/simultaneously_right_and_wrong/sb#comments\">5</a> super-votes</p>\n<p><a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/a5\">6</a> The utility of comment karma</p>\n<p><a title=\"Where are we\" href=\"/lw/7c/where_are_we/4v8#comments\">7</a> whether one should unselect the self-upvote</p>\n<p><a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/21t?context=1#21t\">8</a> <a title=\"Proverbs and Cached Judgments The Rolling Stone\" href=\"/lw/70/proverbs_and_cached_judgments_the_rolling_stone/4za#comments\">9</a> whether downvotes should require explanation</p>\n<p><a title=\"Open Thread March 2009\" href=\"/lw/5h/open_thread_march_2009/3q7?context=1#3q7\">10</a> whether Eliezer Yudkowsky gets fewer upvotes than others</p>\n<p><a title=\"Test Your Rationality\" href=\"/lw/h/test_your_rationality/7g#comments\">11</a> whether karma can be used to gauge rationality</p>\n<p><a title=\"Helpless Individuals\" href=\"/lw/64/helpless_individuals/4bk#comments\">12</a> whether people downvote for disagreeing with groupthink</p>\n<p><a title=\"Most Rationalists are Elsewhere\" href=\"/lw/6g/most_rationalists_are_elsewhere/\">13</a> whether karma promotes a closed-garden effect</p>\n<p><a title=\"How to Not Lose an Argument\" href=\"/lw/3k/how_to_not_lose_an_argument/2nc#comments\">14</a> whether administrators should delete comments entirely</p>\n<p><a title=\"Lesswrong Antikibitzer\" href=\"/lw/1s/lesswrong_antikibitzer_hides_comment_authors_and/\">15</a> Lesswrong Antikibitzer: tool for hiding comment authors and vote counts</p>\n<p>ETA: I might concede that this post is possibly off-topic for Less Wrong - but the blog/community site about \"Less Wrong\" does not exist yet, so this seems like the best place to post it.</p>\n<p>ETA2: Public records of upvotes/downvotes might solve some of these problems; discuss.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "hGzywXvWhSdJi5F2a": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aoLncXJMFfTH9vL5a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 9, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "331", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>There has been a great deal of discussion here about the proper methods of voting on comments and on how karma should be assigned. &nbsp;I believe it's finally reached the point where a post is warranted that covers some of the issues involved. &nbsp;(This may be just because I find myself frequently in disagreement with others about it.)</p>\n<h3 id=\"The_Automatic_Upvote\">The Automatic Upvote<br></h3>\n<p>First, there is the question of whether one should be able to upvote one's own comment. &nbsp;This actually breaks apart into two related concerns:</p>\n<p>(1) One is able to upvote one's own comments, and</p>\n<p>(2) One gains a point of karma just for posting a comment.</p>\n<p>These need not be tied. &nbsp;We could have (2) without (1) by awarding a point of karma for commenting, without changing the comment's score. &nbsp;We could also have (1) without (2) by simply not counting self-upvotes for karma.</p>\n<p>I am in favor of (2). &nbsp;The main argument against (2) is that it rewards quantity over quality. &nbsp;The main argument for (2) is that it offers an automatic incentive to post comments; that is, it rewards commenting over silence. &nbsp;As we're community-building, I think the latter incentive is more important than the former. &nbsp;But I'm not sure this is worth arguing further - it serves as a distraction from the benefits of (1).</p>\n<p>I am also in favor of (1). &nbsp;As a default, all comments have a base rating of 0. &nbsp;Since one is allowed to vote on one's own comments, and upvoting is the default for one's own comments, this makes comments effectively start at a rating of 1. &nbsp;The argument against this is that it makes more sense for comments to start with a rating of 0, so that someone else liking a comment gives it a positive rating, while someone disliking it gives it a negative rating. &nbsp;I disagree with this assessment.</p>\n<p>If I post a comment, it's because it's the best comment I could think of to add to the discussion. &nbsp;I will usually not bother saying something if I don't think it's the sort of thing that I would upvote. &nbsp;When I see someone else's comment that I don't think is very good, I downvote it. &nbsp;Since they already upvoted it, I'm in effect disagreeing that this was something worth saying. &nbsp;The score now reflects this - a score of 0 shows that one person thought it was a worthwhile comment, and one person did not.</p>\n<p>Furthermore, if I was not able to vote on my own comments, I would be much more reluctant to upvote. &nbsp;Since I would not be able to upvote my comment, upvoting someone else's comment would suggest that I think their comment is better than my own. But by hypothesis, I thought my comment was nearly the best thing that could be said on the subject; thus, upvotes will be rare.</p>\n<p>And so I say that we implement a compromise - (1) and not (2).</p>\n<h3 id=\"What_should_upvote_downvote_mean_\">What should upvote/downvote mean?<br></h3>\n<p>I think it is established pretty well that upvote means \"High quality comment\" or \"I would like to see more comments like this one\", while downvote means \"Low quality comment\" or \"I would like to see fewer comments like this one\". &nbsp;However, this definition still retains a good bit of ambiguity.</p>\n<p>It is too easy to think of upvote and downvote as 'agree' and 'disagree'. &nbsp;Even guarding myself against this behavior I find the cursor drifting to downvote as soon as I think, \"Well that's obviously wrong\". &nbsp;But that's clearly not what the concept is there for. &nbsp;Comments voted up appear higher on the page (on certain views), which allows casual readers to see the best comments and discussions on any particular post. &nbsp;If we use upvote and downvote to mean 'agree' and 'disagree', then this is effectively an echo chamber, where the only comments to float to the top are the ones that jive with the groupthink.</p>\n<p>Instead, upvote and downvote should reflect overall quality of a comment. &nbsp;There are several criteria I tend to use to judge a good comment (this list is not all-inclusive):</p>\n<ol>\n<li>Did the comment add any information, or did it just add to the noise? (+)</li>\n<li>Does the comment include references or links to relevant information? (+)</li>\n<li>Does the comment reflect a genuinely held point-of-view that adds to the discussion? (+)</li>\n<li>Is the comment part of a discussion that might lead somewhere interesting? (+)</li>\n<li>Is the comment obvious spam / trolling? (-)</li>\n<li>Is the comment off-topic? (-)</li>\n</ol>\n<p>Since we feel the need to voice whether we agree or disagree with comments, but 'I agree' and 'I disagree' comments are noisy, it's been suggested that there should be separate buttons to indicate agreement and disagreement. &nbsp;Thus, someone posting a well-argued on-topic defense of theism can get the upvote and 'disagree', while someone posting an off-topic 'physicalism is true' can get the downvote and 'agree'. &nbsp;Presumably, we'd only count upvotes and downvotes for karma, but we could use 'agree' and 'disagree' for \"most controversial\" or other views/metrics.</p>\n<h3 id=\"Whether_votes_should_require_an_explanation\">Whether votes should require an explanation<br></h3>\n<p>It has been suggested that votes, or downvotes specifically, should require an explanation. &nbsp;I disagree with both sentiments. &nbsp;First, requiring explanations for downvotes but not upvotes would bias the voting positively, which would have the effect of rewarding quantity over quality and decrease the impact of downvotes.</p>\n<p>But requiring explanations for votes is in general a bad idea. &nbsp;This site is already a burden to keep up with; for those of us that do a lot of voting, writing an explanation for each one would be too much time and effort. &nbsp;Requiring an explanation for every vote would doubtless result in a lot less voting. &nbsp;Also, explaining votes is almost always off-topic, so adds to the noise here without really contributing to the discussion.</p>\n<p>Note Yvain's more personal rationale:</p>\n<blockquote>I'm not prepared to write an essay explaining exactly was wrong with each of them, especially if the original commenter wasn't prepared to take three seconds to write a halfway decent response.</blockquote>\n<p>Adding to the burden of those already performing the service of voting unduly penalizes those who are doing good, to the end of appeasing those who are contributing to the noise here.</p>\n<h3 id=\"Relevant_Comments\">Relevant Comments<br></h3>\n<p>For reference, some links to relevant posts and sections of comments. &nbsp;I tried to be inclusive, since there have been a lot of discussions about these issues - more relevant ones hopefully near the top. (Please comment if you know of any other relevant discussions)</p>\n<p><a title=\"Your price for joining\" href=\"/lw/5j/your_price_for_joining/3pk?context=1#3pk\">1</a> <a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/u\">2</a> <a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/2u#comments\">3</a> what upvote and downvote should mean and whether there should be agree/disagree buttons</p>\n<p><a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/ba#comments\">4</a> whether karma should be the sum of individual post scores, or (perhaps) an average</p>\n<p><a title=\"Simultaneously Right and Wrong\" href=\"/lw/1d/simultaneously_right_and_wrong/sb#comments\">5</a> super-votes</p>\n<p><a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/a5\">6</a> The utility of comment karma</p>\n<p><a title=\"Where are we\" href=\"/lw/7c/where_are_we/4v8#comments\">7</a> whether one should unselect the self-upvote</p>\n<p><a title=\"Issues Bugs and Requested Features\" href=\"/lw/5/issues_bugs_and_requested_features/21t?context=1#21t\">8</a> <a title=\"Proverbs and Cached Judgments The Rolling Stone\" href=\"/lw/70/proverbs_and_cached_judgments_the_rolling_stone/4za#comments\">9</a> whether downvotes should require explanation</p>\n<p><a title=\"Open Thread March 2009\" href=\"/lw/5h/open_thread_march_2009/3q7?context=1#3q7\">10</a> whether Eliezer Yudkowsky gets fewer upvotes than others</p>\n<p><a title=\"Test Your Rationality\" href=\"/lw/h/test_your_rationality/7g#comments\">11</a> whether karma can be used to gauge rationality</p>\n<p><a title=\"Helpless Individuals\" href=\"/lw/64/helpless_individuals/4bk#comments\">12</a> whether people downvote for disagreeing with groupthink</p>\n<p><a title=\"Most Rationalists are Elsewhere\" href=\"/lw/6g/most_rationalists_are_elsewhere/\">13</a> whether karma promotes a closed-garden effect</p>\n<p><a title=\"How to Not Lose an Argument\" href=\"/lw/3k/how_to_not_lose_an_argument/2nc#comments\">14</a> whether administrators should delete comments entirely</p>\n<p><a title=\"Lesswrong Antikibitzer\" href=\"/lw/1s/lesswrong_antikibitzer_hides_comment_authors_and/\">15</a> Lesswrong Antikibitzer: tool for hiding comment authors and vote counts</p>\n<p>ETA: I might concede that this post is possibly off-topic for Less Wrong - but the blog/community site about \"Less Wrong\" does not exist yet, so this seems like the best place to post it.</p>\n<p>ETA2: Public records of upvotes/downvotes might solve some of these problems; discuss.</p>", "sections": [{"title": "The Automatic Upvote", "anchor": "The_Automatic_Upvote", "level": 1}, {"title": "What should upvote/downvote mean?", "anchor": "What_should_upvote_downvote_mean_", "level": 1}, {"title": "Whether votes should require an explanation", "anchor": "Whether_votes_should_require_an_explanation", "level": 1}, {"title": "Relevant Comments", "anchor": "Relevant_Comments", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "47 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zKiLtGJjw2erQ7eE3", "XbfdLQrAWTRfpggRM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-07T05:32:37.012Z", "modifiedAt": null, "url": null, "title": "Newcomb's Problem vs. One-Shot Prisoner's Dilemma", "slug": "newcomb-s-problem-vs-one-shot-prisoner-s-dilemma", "viewCount": null, "lastCommentedAt": "2017-06-17T03:52:05.103Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ceXpD4vjzfiNkNYTp/newcomb-s-problem-vs-one-shot-prisoner-s-dilemma", "pageUrlRelative": "/posts/ceXpD4vjzfiNkNYTp/newcomb-s-problem-vs-one-shot-prisoner-s-dilemma", "linkUrl": "https://www.lesswrong.com/posts/ceXpD4vjzfiNkNYTp/newcomb-s-problem-vs-one-shot-prisoner-s-dilemma", "postedAtFormatted": "Tuesday, April 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Newcomb's%20Problem%20vs.%20One-Shot%20Prisoner's%20Dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANewcomb's%20Problem%20vs.%20One-Shot%20Prisoner's%20Dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FceXpD4vjzfiNkNYTp%2Fnewcomb-s-problem-vs-one-shot-prisoner-s-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Newcomb's%20Problem%20vs.%20One-Shot%20Prisoner's%20Dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FceXpD4vjzfiNkNYTp%2Fnewcomb-s-problem-vs-one-shot-prisoner-s-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FceXpD4vjzfiNkNYTp%2Fnewcomb-s-problem-vs-one-shot-prisoner-s-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 391, "htmlBody": "<p><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>ZH-CN</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:DontVertAlignCellWithSp /> <w:DontBreakConstrainedForcedTables /> <w:DontVertAlignInTxbx /> <w:Word11KerningPairs /> <w:CachedColBalance /> <w:UseFELayout /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!-- /* Font Definitions */ @font-face {font-family:\u5b8b\u4f53; panose-1:2 1 6 0 3 1 1 1 1 1; mso-font-alt:SimSun; mso-font-charset:134; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:3 680460288 22 0 262145 0;} @font-face {font-family:\"Cambria Math\"; panose-1:2 4 5 3 5 4 6 3 2 4; mso-font-charset:0; mso-generic-font-family:roman; mso-font-pitch:variable; mso-font-signature:-1610611985 1107304683 0 0 159 0;} @font-face {font-family:Calibri; panose-1:2 15 5 2 2 2 4 3 2 4; mso-font-charset:0; mso-generic-font-family:swiss; mso-font-pitch:variable; mso-font-signature:-1610611985 1073750139 0 0 159 0;} @font-face {font-family:\"\\@\u5b8b\u4f53\"; panose-1:2 1 6 0 3 1 1 1 1 1; mso-font-charset:134; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:3 680460288 22 0 262145 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-unhide:no; mso-style-qformat:yes; mso-style-parent:\"\"; margin-top:0in; margin-right:0in; margin-bottom:10.0pt; margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\u5b8b\u4f53; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} a:link, span.MsoHyperlink {mso-style-priority:99; color:blue; mso-themecolor:hyperlink; text-decoration:underline; text-underline:single;} a:visited, span.MsoHyperlinkFollowed {mso-style-noshow:yes; mso-style-priority:99; color:purple; mso-themecolor:followedhyperlink; text-decoration:underline; text-underline:single;} .MsoChpDefault {mso-style-type:export-only; mso-default-props:yes; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\u5b8b\u4f53; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} .MsoPapDefault {mso-style-type:export-only; margin-bottom:10.0pt; line-height:115%;} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.0in 1.0in 1.0in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} --><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-qformat:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin;} --> <!--[endif]--></p>\n<p class=\"MsoNormal\"><strong>Continuation of</strong>: <a href=\"/lw/7/kinnairds_truels/i7#comments\">http://lesswrong.com/lw/7/kinnairds_truels/i7#comments</a></p>\n<p class=\"MsoNormal\">Eliezer has convinced me to one-box Newcomb's problem, but I'm not ready to Cooperate in one-shot PD yet. In <a href=\"http://www.overcomingbias.com/2008/09/iterated-tpd.html?cid=129270958#comment-129270958\">http://www.overcomingbias.com/2008/09/iterated-tpd.html?cid=129270958#comment-129270958</a>, Eliezer wrote:</p>\n<blockquote>\n<p class=\"MsoNormal\"><span id=\"comment-129270958-content\">PDF, </span>on the 100th [i.e. final] move of the iterated dilemma, I cooperate if and only if I expect the paperclipper to cooperate if and only if I cooperate, that is:</p>\n<p class=\"MsoNormal\">Eliezer.C &lt;=&gt; (Paperclipper.C &lt;=&gt; Eliezer.C)</p>\n</blockquote>\n<p class=\"MsoNormal\">The problem is, the paperclipper would like to deceive Eliezer into believing that Paperclipper.C &lt;=&gt; Eliezer.C, while actually playing D. This means Eliezer has to expend resources to verify that Paperclipper.C &lt;=&gt; Eliezer.C really is true with high probability. If the potential gain from cooperation in a one-shot PD is less than this cost, then cooperation isn't possible. In Newbomb&rsquo;s Problem, the analogous issue can be assumed away, by stipulating that Omega will see through any deception. But in the standard game theory analysis of one-shot PD, the opposite assumption is made, namely that it's impossible or prohibitively costly for players to convince each other that Player1.C &lt;=&gt; Player2.C.</p>\n<p class=\"MsoNormal\">It seems likely that this assumption is false, at least for some types of agents and sufficiently high gains from cooperation. In <a href=\"http://www.nabble.com/-sl4--prove-your-source-code-td18454831.html\">http://www.nabble.com/-sl4--prove-your-source-code-td18454831.html</a>, I asked how superintelligences can prove their source code to each other, and Tim Freeman responded with this suggestion:</p>\n<blockquote>\n<p class=\"MsoNormal\">Entity A could prove to entity B that it has source code S by consenting to be replaced by a new entity A' that was constructed by a manufacturing process jointly monitored by A and B.<span>&nbsp; </span>During this process, both A and B observe that A' is constructed to run source code S.<span>&nbsp; </span>After A' is constructed, A shuts down and gives all of its resources to A'.</p>\n</blockquote>\n<p class=\"MsoNormal\">But this process seems quite expensive, so even SIs may not be able to play Cooperate in one-shot PD, unless the stakes are pretty high. Are there cheaper solutions, perhaps ones that can be applied to humans as well, for players in one-shot PD to convince each other what decision systems they are using?</p>\n<p class=\"MsoNormal\">On a related note, Eliezer has claimed that truly one-shot PD is very rare in real life. I would agree with this, except that the same issue also arises from indefinitely repeated games where the probability of the game ending after the current round is too high, or the time discount factor is too low, for a tit-for-tat strategy to work.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 1, "fihKHQuS5WZBJgkRm": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ceXpD4vjzfiNkNYTp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 14, "extendedScore": null, "score": 4.861825857493295e-07, "legacy": true, "legacyId": "243", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-07T10:36:49.348Z", "modifiedAt": null, "url": null, "title": "What isn't the wiki for?", "slug": "what-isn-t-the-wiki-for", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:21.740Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p3TfgGvbAd3tfxYe3/what-isn-t-the-wiki-for", "pageUrlRelative": "/posts/p3TfgGvbAd3tfxYe3/what-isn-t-the-wiki-for", "linkUrl": "https://www.lesswrong.com/posts/p3TfgGvbAd3tfxYe3/what-isn-t-the-wiki-for", "postedAtFormatted": "Tuesday, April 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20isn't%20the%20wiki%20for%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20isn't%20the%20wiki%20for%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp3TfgGvbAd3tfxYe3%2Fwhat-isn-t-the-wiki-for%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20isn't%20the%20wiki%20for%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp3TfgGvbAd3tfxYe3%2Fwhat-isn-t-the-wiki-for", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp3TfgGvbAd3tfxYe3%2Fwhat-isn-t-the-wiki-for", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 551, "htmlBody": "<p><a href=\"http://lesswrong.wikia.com/wiki/LessWrong_Wiki\">The new wiki</a> is off to a flying start - it's less than 15 hours old, and already it has over 20 articles and five authors. It's probably about time we worked out what it was for.</p>\n<p>I created it because as things stand, I can't point my friends to Less Wrong and say \"come and learn about rationality and take part in these fascinating and potentially important discussions!\" The discussions we have here assume years of reading Overcoming Bias and close attention to what's been said there and here; it must be practically impenetrable to newcomers. So for me the primary goal is simply to provide a glossary, to give newcomers a fighting chance of understanding what on Earth we are talking about and why. I think it can do more than that, but before I come to that, let me say a little about what I think it's not for.</p>\n<p>The way I would currently like to see it, <strong>the wiki is not there to duplicate what is already done elsewhere</strong>. So it's not a place for discussion - that's what this site is for, and the features to support discussion here are far stronger than they are there, what with voting, threading and so forth. By the same token, it's not a place to advance your ideas - it's better to do that here, where people can comment on them and where it's clearly tagged as the work of one author rather than some sort of collective conclusion.</p>\n<p>I'd like to avoid duplication in other areas, too. Anything that can go in Wikipedia instead of our wiki should do: we will get better results if we and they are editing the same biography of Eliezer Yudkowsky, rather than creating a fork. To that end, I've created a {{wikilink}} template that can go at the top of an article, linking to the article with the same name in Wikipedia. Have a look at <a href=\"http://lesswrong.wikia.com/wiki/Newcomb%27s_paradox\">our current article on Newcomb's paradox</a> - there is far more detail in the linked Wikipedia article, but there are some things we carry because they (rightly) won't: the sometimes non-standard vocabulary we tend to use around it (eg \"Omega\") and links to related articles in Overcoming Bias/Less Wrong on the subject, which they might not choose to keep (since Wikipedia is not a link farm).</p>\n<p>Similarly, we don't want to provide our own index of heuristics and biases, since there's <a href=\"http://en.wikipedia.org/wiki/Category:Cognitive_biases\">one on Wikipedia</a> and <a href=\"http://psychology.wikia.com/wiki/Category:Cognitive_biases\">another on the Psychology wiki</a>, and most of what they lack on the subject we can fix there rather than trying to address by duplication.</p>\n<p>It's often easier to say what a thing is not for than what it is for. What have I missed out here that we should be using the wiki for; am I right to discourage what I set out above; what else do we need to say about how best to use it? Because we could be discussing anything in a given week, but a wiki evolves more slowly, I'd like to hope that if in a year's time I meet someone who seems open to the ideas we discuss here and wants to learn more, it's the wiki I'd point them at rather than this website; it might eventually be the best starting point on how to become less wrong.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p3TfgGvbAd3tfxYe3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 4.86227201248588e-07, "legacy": true, "legacyId": "332", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-07T15:10:27.725Z", "modifiedAt": null, "url": null, "title": "Eternal Sunshine of the Rational Mind", "slug": "eternal-sunshine-of-the-rational-mind", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:01.626Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KsZNM2aiSKNTXfhZm/eternal-sunshine-of-the-rational-mind", "pageUrlRelative": "/posts/KsZNM2aiSKNTXfhZm/eternal-sunshine-of-the-rational-mind", "linkUrl": "https://www.lesswrong.com/posts/KsZNM2aiSKNTXfhZm/eternal-sunshine-of-the-rational-mind", "postedAtFormatted": "Tuesday, April 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Eternal%20Sunshine%20of%20the%20Rational%20Mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEternal%20Sunshine%20of%20the%20Rational%20Mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKsZNM2aiSKNTXfhZm%2Feternal-sunshine-of-the-rational-mind%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Eternal%20Sunshine%20of%20the%20Rational%20Mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKsZNM2aiSKNTXfhZm%2Feternal-sunshine-of-the-rational-mind", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKsZNM2aiSKNTXfhZm%2Feternal-sunshine-of-the-rational-mind", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 190, "htmlBody": "<p>What if you could choose which memories and associations to retain and which to discard?&nbsp;Using that capability rationally (whatever that word means to you) would be a significant challenge -- and that challenge has just come <a title=\"Brain Researchers Open Door to Editing Memory \" href=\"http://www.nytimes.com/2009/04/06/health/research/06brain.html?pagewanted=1&amp;_r=2&amp;ref=science\" target=\"_self\">one step closer to being a reality</a>.</p>\r\n<blockquote>\r\n<p>Dr. Fenton had already devised a clever way to teach animals strong memories for where things are located. He teaches them to move around a small chamber to avoid a mild electric shock to their feet. Once the animals learn, they do not forget. Placed back in the chamber a day later, even a month later, they quickly remember how to avoid the shock and do so.</p>\r\n<p>But when injected &mdash; directly into their brain &mdash; with a drug called ZIP that interferes with PKMzeta, they are back to square one, almost immediately. &ldquo;When we first saw this happen, I had grad students throwing their hands up in the air, yelling,&rdquo; Dr. Fenton said. &ldquo;Well, we needed a lot more than that&rdquo; one study.</p>\r\n<p>They now have it. Dr. Fenton&rsquo;s lab repeated the experiment, in various ways...</p>\r\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"feSdiScf9o6zgrwgG": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KsZNM2aiSKNTXfhZm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 10, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "333", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-07T18:26:41.675Z", "modifiedAt": "2021-04-07T04:59:17.180Z", "url": null, "title": "Of Lies and Black Swan Blowups", "slug": "of-lies-and-black-swan-blowups", "viewCount": null, "lastCommentedAt": "2021-05-30T07:29:51.542Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/E7CKXxtGKPmdM9ZRc/of-lies-and-black-swan-blowups", "pageUrlRelative": "/posts/E7CKXxtGKPmdM9ZRc/of-lies-and-black-swan-blowups", "linkUrl": "https://www.lesswrong.com/posts/E7CKXxtGKPmdM9ZRc/of-lies-and-black-swan-blowups", "postedAtFormatted": "Tuesday, April 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Of%20Lies%20and%20Black%20Swan%20Blowups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOf%20Lies%20and%20Black%20Swan%20Blowups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE7CKXxtGKPmdM9ZRc%2Fof-lies-and-black-swan-blowups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Of%20Lies%20and%20Black%20Swan%20Blowups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE7CKXxtGKPmdM9ZRc%2Fof-lies-and-black-swan-blowups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE7CKXxtGKPmdM9ZRc%2Fof-lies-and-black-swan-blowups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 121, "htmlBody": "\n\n\n\n  \n\n  \n\n  <p>Judge Marcus Einfeld, age 70, Queen&#x2019;s Counsel since 1977, Australian Living Treasure 1997, United Nations Peace Award 2002, founding president of Australia&#x2019;s Human Rights and Equal Opportunities Commission, retired a few years back but routinely brought back to judge important cases . . . </p>\n\n  <p>. . . went to jail for two years over a series of perjuries and lies <a href=\"https://en.wikipedia.org/wiki/Marcus_Einfeld\">that started with a $77, 6-mph-over speeding ticket</a>.</p>\n\n  <p>That whole <em>suspiciously virtuous-sounding</em> theory about honest people not being good at lying, and entangled traces being left somewhere, and the entire thing blowing up in a Black Swan epic fail, actually <em>does</em> have a certain number of exemplars in real life, though obvious selective reporting is at work in our hearing about this one.</p>\n\n", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"SrW9iP2j6Hi8R5PmT": 1, "cHoCqtfE9cF7aSs9d": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "E7CKXxtGKPmdM9ZRc", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 25, "extendedScore": null, "score": 3.8e-05, "legacy": true, "legacyId": "334", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2021-04-07T04:59:17.077Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": "GSqFqc646rsRd2oyz", "canonicalCollectionSlug": "rationality", "canonicalBookId": "coGq3LC5Yn4vZiu6k", "canonicalNextPostSlug": "dark-side-epistemology", "canonicalPrevPostSlug": "entangled-truths-contagious-lies", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "rPsASnzcvaBdBEaSJ", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "2.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-07T20:31:50.409Z", "modifiedAt": null, "url": null, "title": "Whining-Based Communities", "slug": "whining-based-communities", "viewCount": null, "lastCommentedAt": "2020-06-15T02:44:50.267Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rg7vPTtyLMfT6Qqud/whining-based-communities", "pageUrlRelative": "/posts/rg7vPTtyLMfT6Qqud/whining-based-communities", "linkUrl": "https://www.lesswrong.com/posts/rg7vPTtyLMfT6Qqud/whining-based-communities", "postedAtFormatted": "Tuesday, April 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Whining-Based%20Communities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhining-Based%20Communities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Frg7vPTtyLMfT6Qqud%2Fwhining-based-communities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Whining-Based%20Communities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Frg7vPTtyLMfT6Qqud%2Fwhining-based-communities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Frg7vPTtyLMfT6Qqud%2Fwhining-based-communities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1065, "htmlBody": "<p><strong>Previously in series</strong>:&nbsp; <a href=\"/lw/77/selecting_rationalist_groups/\">Selecting Rationalist Groups</a><br /><strong>Followup to</strong>:&nbsp; <a href=\"/lw/7i/rationality_is_systematized_winning/\">Rationality is Systematized Winning</a>, <a href=\"/lw/92/extenuating_circumstances/\">Extenuating Circumstances</a></p>\n<p>Why emphasize the connection between rationality and winning?&nbsp; Well... that <em>is</em> what decision theory is <em>for</em><em>.</em>&nbsp; But also to <a href=\"http://www.overcomingbias.com/2007/12/cultish-counter.html\">place a Go stone to block</a> becoming a whining-based community.</p>\n<p>Let's be fair to <a href=\"http://www.overcomingbias.com/2007/12/ayn-rand.html\">Ayn Rand</a>:&nbsp; There were legitimate messages in <em>Atlas Shrugged</em> that many readers had never heard before, and this lent the book a part of its compelling power over them.&nbsp; The message that <em>it's all right to excel</em>&mdash;that it's okay to be, <a href=\"http://www.overcomingbias.com/2007/03/tsuyoku_vs_the_.html\">not just good, but better than others</a>&mdash;of this the Competitive Conspiracy would approve.</p>\n<p>But this is only part of Rand's message, and the other part is the poison pill, a deadlier appeal:&nbsp; It's those looters who <em>don't </em>approve of excellence who are <em>keeping you down.</em>&nbsp; Surely you would be rich and famous and high-status <em>like you deserve</em> if not for <em>them,</em> those unappreciative bastards and their conspiracy of mediocrity.</p>\n<p>If you consider the <em>reasonableness-based </em>conception of rationality rather than the <em>winning-based </em>conception of rationality&mdash;well, you can easily imagine some community of people congratulating themselves on how <em>reasonable</em> they were, while blaming the surrounding <em>unreasonable</em> society for keeping them down.&nbsp; Wrapping themselves up in their own bitterness for reality refusing to comply with the greatness they thought they should have.</p>\n<p>But this is <em>not </em>how decision theory works&mdash;the \"rational\" strategy adapts to the other players' strategies, it does <em>not</em> depend on the other players being rational.&nbsp; If a rational agent believes the other players are irrational then it takes that <em>expectation </em>into account in maximizing <em>expected</em> utility.&nbsp; <a href=\"/lw/3m/rationalist_fiction/\">Van Vogt</a> got this one right: his rationalist protagonists are formidable from accepting reality swiftly and adapting to it swiftly, without reluctance or attachment.<a id=\"more\"></a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Self-handicapping\">Self-handicapping</a> (hat-tip <a href=\"/lw/1d/simultaneously_right_and_wrong/\">Yvain</a>) is when people who have been made aware of their own incompetence or probable future failure, deliberately impose handicaps on themselves&mdash;on the standard model, in order to give themselves an <em>excuse</em> for failure.&nbsp; To make sure they had an excuse, subjects reduced preparation times for athletic events, studied less, exerted less effort, gave opponents an advantage, lowered their own expectations, even took a drug they had been told was performance-inhibiting...</p>\n<p>So you can see how much people<em> value</em> having an excuse&mdash;how much they'll <em>pay</em> to make sure they have something outside themselves to blame, in case of failure.&nbsp; And this is a need which many belief systems fill&mdash;they provide an <em>excuse.</em></p>\n<p>It's the government's fault, that taxes you and suppresses the economy&mdash;if it weren't for <em>that</em>, you would be a great entrepreneur.&nbsp; It's the fault of those less competent who envy your excellence and slander you&mdash;if not for <em>that,</em> the whole world would pilgrimage to admire you.&nbsp; It's racism, or sexism, that keeps you down&mdash;if it weren't for <em>that,</em> you would have gotten so much further in life with the same effort.&nbsp; Your rival Bob got the promotion by bootlicking.&nbsp; Those you call sinners may be much wealthier than you, but that's because God set up the system to reward the good deeds of the wicked in this world and punish them for their sins in the next, vice versa for the virtuous:&nbsp; \"A boor cannot know, nor can a fool understand this: when the wicked bloom like grass and all the doers of iniquity blossom&mdash;it is to destroy them till eternity.\"</p>\n<p>And maybe it's all true.&nbsp; The government <em>does</em> impose taxes and barriers to new businesses.&nbsp; There <em>is</em> racism and sexism.&nbsp; Scientists <em>don't</em> run out and embrace new ideas without huge amounts of work to evangelize them.&nbsp; Loyalty <em>is</em> a huge factor in promotions and flattery does signify loyalty.&nbsp; I can't back religions on that divine plan thing, but still, those wealthier than you may have gotten there by means more vile than you care to use...</p>\n<p>And so what?&nbsp; In other countries there are those with far greater obstacles and less opportunity than you.&nbsp; There are those born with Down's Syndrome.&nbsp; There's not a one of us in this world, even the <a href=\"http://davidbrin.blogspot.com/2005/10/holodeck-scenario-part-i_23.html\">luckiest</a>, whose path is <em>entirely</em> straight and without obstacles.&nbsp; In this unfair world, the test of your existence is how well you do in this unfair world.</p>\n<p>I <a href=\"http://www.overcomingbias.com/2008/06/the-ultimate-so.html\">earlier</a> suggested that we view our parents and environment and genes as having determined <em>which</em> person makes a decision&mdash;plucking <em>you</em> out of Platonic person-space to agonize in front of the burning orphanage, rather than someone else&mdash;but<em> you</em> determine what that <em>particular</em> person decides.&nbsp; If, counterfactually, your genes or environment had been different, then it would not so much <em>change your decision</em> as determine that <em>someone else would make</em> that decision.</p>\n<p>In the same sense, I would suggest that a baby with your genes, born into a universe entirely fair, would by now be such a different person that as to be nowhere close to \"you\", your point in Platonic person-space.&nbsp; <em>You</em> are defined by the particular unfair challenges that you face; and the test of <em>your</em> existence is how well you do with them.</p>\n<p>And in that unfair challenge, the art of rationality (if you can find it) is there to help you deal with the horrible unfair challenge and by golly <em>win anyway,</em> not to provide fellow bitter losers to hang out with.&nbsp; Even if the government <em>does</em> tax you and people <em>do </em>slander you and racists <em>do</em> discriminate against you and others smarm their way to success while you keep your ethics... still, this whole business of rationality is there to help you <em>win anyway, </em>if you can find the art you need.&nbsp; Find the art together, win together, if we can.&nbsp; And if we can't win, it means we weren't such good rationalists as we thought, and ought to try something different the next time around.&nbsp; (If it's one of those challenges where you get more than one try.)</p>\n<p>From within that project&mdash;what good does a sense of <em>violated entitlement</em> do?&nbsp; At all?&nbsp; Ever?&nbsp; What good does it do to tell ourselves that we did everything right and deserved better, and that someone or something else is to blame?&nbsp; Is <em>that </em>the key thing we need to change, to do better next time?</p>\n<p>Immediate adaptation to the realities of the situation!&nbsp; Followed by winning!</p>\n<p>That is how I would cast down the gauntlet, just to make really, really sure we don't go down the utterly, completely, pointlessly unhelpful, surprisingly common path of mutual bitterness and consolation.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/9c/mandatory_secret_identities/\">Mandatory Secret Identities</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/7k/incremental_progress_and_the_valley/\">Incremental Progress and the Valley</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZzxvopS4BwLuQy42n": 1, "x6evH6MyPK3nxsoff": 1, "zv7v2ziqexSn5iS9v": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rg7vPTtyLMfT6Qqud", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 78, "baseScore": 73, "extendedScore": null, "score": 0.000113, "legacy": true, "legacyId": "317", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 73, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 99, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZEj9ATpv3P22LSmnC", "4ARtkT3EYox3THYjF", "XYrcTJFJoYKX2DxNL", "q79vYjHAE9KHcAjSs", "P3uavjFmZD5RopJKk", "YdcF6WbBmJhaaDqoD", "gBewgmzcEiks2XdoQ", "oZNXmHcdhb4m7vwsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-07T23:22:21.112Z", "modifiedAt": null, "url": null, "title": "Help, help, I'm being oppressed!", "slug": "help-help-i-m-being-oppressed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:34.281Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PCpzG9NJeviXM5YSq/help-help-i-m-being-oppressed", "pageUrlRelative": "/posts/PCpzG9NJeviXM5YSq/help-help-i-m-being-oppressed", "linkUrl": "https://www.lesswrong.com/posts/PCpzG9NJeviXM5YSq/help-help-i-m-being-oppressed", "postedAtFormatted": "Tuesday, April 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Help%2C%20help%2C%20I'm%20being%20oppressed!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelp%2C%20help%2C%20I'm%20being%20oppressed!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPCpzG9NJeviXM5YSq%2Fhelp-help-i-m-being-oppressed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Help%2C%20help%2C%20I'm%20being%20oppressed!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPCpzG9NJeviXM5YSq%2Fhelp-help-i-m-being-oppressed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPCpzG9NJeviXM5YSq%2Fhelp-help-i-m-being-oppressed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1524, "htmlBody": "<p><strong>Followup to</strong>:&nbsp; <a href=\"/lw/7s/why_support_the_underdog/\">Why Support the Underdog?</a><br /><strong>Serendipitously related to</strong>: <a href=\"/lw/8t/whiningbased_communities/\">Whining-Based Communities</a><a href=\"/lw/92/extenuating_circumstances\"></a></p>\n<p>Pity whatever U.N. official has to keep track of all the persecution going on. With two hundred plus countries in the world, there's just so much of it. <br /><br />Some places persecute Christians. Here's a Christian writer from a nation we'll call Country A:</p>\n<blockquote>\n<p>Global reports indicate that over 150,000 Christians were martyred last year, chiefly in foreign countries. However, statistics are changing: persecution of Christians is on the increase at home. What's happening to bring about this change? According to some experts a pattern is emerging reminiscent of Jewish persecution in post war Germany. \"Isolation of, and discrimination against Christians is growing almost geometrically\" says Don McAlvany in The Midnight Herald. \"This is the way it started in Germany against the Jews. As they became more isolated and marginalized by the Nazi propaganda machine, as popular hatred and prejudice against the Jews increased among the German people, wholesale persecution followed.&nbsp; Could this be where the growing anti-Christian consensus in this country is taking us?\"</p>\n</blockquote>\n<p>And some countries persecute atheists. Here's an atheist activist describing what we'll call Country B.</p>\n<blockquote>\n<p>Godless atheists are the most despised and distrusted minority in our country. The growing attention to atheism and atheists has given rise to increased anti-atheist bigotry in the media. Circumstances for them can be difficult enough that they have to stay in the closet and hide their atheism from friends and family. Atheists have to fear discrimination on the job, in the community, and even in their own families if their atheism is made known. Some even have to contend with harassment and vandalism. Distrust and hatred of atheists is widespread enough through our society that they have plenty of reasons to be concerned.</p>\n</blockquote>\n<p>Some countries persecute Muslims. A Muslim youth in Country C:</p>\n<blockquote>\n<p>The government has continuously persecuted Arabs and Muslims with extremist and unpopular views, charging them with terrorism and criminal acts related to terrorism. I am proud of [Muslims] who stand up to this system of injustice and to our country's gulag. They may beat them, but they will continues to suffer because in this country, Arabs are never innocent, they are merely guilty of lesser crimes. Even if they are proven innocent, after years of suffering and being defamed, the gulag and the political persecution will continue.</p>\n</blockquote>\n<p>And some countries persecute everyone <em>except</em> Muslims. A politician in Country D writes:</p>\n<blockquote>\n<p>The gathering storm I have been warning of for years has now formed over us. Yet instead of fighting the gradual incursion of Sharia and the demands of an intolerant, even militant Islam, we are cowering and fatalistic.</p>\n</blockquote>\n<p>Since countries A, B, C, and D are all America<sup>1</sup>, what's up with all these people claiming persecution?</p>\n<p><a id=\"more\"></a></p>\n<p>I don't doubt that there are examples of Christians, atheists, Muslims, and non-Muslims all getting persecuted in the US. There's no rule that says only one group can be persecuted at a time, especially in a society as pluralistic as our own. But compare the claim \"There are a few incidents of people persecuting Christians\" with the claim \"Christians are a persecuted group in our society.\" The first <a href=\"/lw/48/the_power_of_positivist_thinking/\">reduces to an objectively true statement</a>. The second is a <a href=\"/lw/4h/when_truth_isnt_enough/\">sorta-meaningless \"dangling variable\"</a> that can be declared either true or false depending on what connotation you want to send.<br /><br />And people tend to take the liberty to call the is_persecuted variable \"true\" for their own group and \"false\" for groups they don't like. Why does everyone want to be persecuted so badly? Here are some reasons I can think of:<br /><br />1. The <a href=\"/lw/7s/why_support_the_underdog/\">tendency to support the underdog</a>. Being persecuted is about as underdog as you can get, and underdog supporters everywhere are quick to leap to the support of persecuted groups.<br /><br />2. To create an incentive for fair-minded people to \"level the playing field\" by raising their status. I read about a tribe in India involved in a media campaign to inform everyone just how persecuted they really were. Why? They wanted to be added to India's affirmative action program, which would give them a better chance at government jobs. Likewise, when Christians talk about persecution, they usually point out that one great way to stop this persecution would be to put up the Ten Commandments in all public places. <br /><br />3. To <a href=\"/lw/1d/simultaneously_right_and_wrong/\">self-handicap</a>. If I'm unsuccessful, it's not because I'm lazy or unqualified, it's beacuse they were persecuting me! Likewise, if I'm successful, then I managed to triumph in the face of adversity. I'm practically Martin Luther King or someone.<br /><br />4. To build in-group cohesiveness. People come together in the face of a common enemy.<br /><br />5. To explain away a lack of success. Let's say you're a fundamentalist Christian and you notice most of the rest of America dislikes you and thinks you're crazy. You might say \"Well, by Aumann's Agreement Theorem, they probably know something I don't, and I should moderate my religious views.\" But if your Revolutionary is AWOL, <a href=\"/lw/20/the_apologist_and_the_revolutionary/\">your Apologist</a> could conclude that there is a sinister campaign going on to discredit Christianity, and everyone has fallen for this campaign but you and your friends.<br /><br />I think these all play a role, with 1 and 2 the most important.<br /><br />But one common thread in psychology is that the mind very frequently wants to have its cake and eat it too. Last week, we agreed that people like supporting the underdog, but we also agreed that there's a benefit to being on top; that when push comes to shove a lot of people are going to <a href=\"/lw/7s/why_support_the_underdog/\">side with Zug instead of Urk</a>. What would be really useful in winning converts would be to be a persecuted underdog who was also very powerful and certain to win out. But how would you do that?<br /><br />Some Republicans have found a way. Whether they're in control of the government or not, the right-wing blogosphere invariably presents them as under siege, a rapidly dwindling holdout of Real American Values in a country utterly in the grip of liberalism.<br /><br />But they don't say anything like \"Everyone's liberal, things are hopeless, might as well stay home.\" They believe in a silent majority. Liberals control all sorts of nefarious institutions that are currently exercising a stranglehold on power and hiding the truth, but most Americans, once you pull the wool off their eyes, are conservatives at heart and just as angry about this whole thing as they are. Any day now, they're going to throw off the yoke of liberal tyranny and take back their own country.<br /><br />This is a great system. Think about it. Not only should you support the Republicans for support-the-underdog and level-the-playing-field reasons, you should also support them for majoritarian reasons and because their side has the best chance of winning. It's the best possible world short of coming out and saying \"Insofar as it makes you want to vote for us, we are in total control of the country, but insofar as that makes you not want to vote for us, we are a tiny persecuted minority who need your help\".<br /><br />We're coming dangerously close to talking politics here, but this isn't just a Republican phenomenon. It underlies a lot of the uses of the word \"elite\" - this sense that there's a small minority of wrong-headed people who disagree with you in control of everything, even though the vast majority of people are secretly on your side. Whether it's the \"neoliberal capitalist elite\", the \"east coast intellectual elite\" or whatever, it's a one word Pavlovian trigger that activates this concept of your favorite group simultaneously being dominant <em>and</em> being persecuted by those darned elites.<br /><br />There are branches of social science that consciously devote themselves solely to officially identifying the Powerful and the Powerless in every issue and conflict. They have their uses. But as rationalists, we need to devote ourselves to the separate task of disentangling the question at hand from the question of who is more powerful. Otherwise, we are at the mercy of the underdog bias, the support-the-winning-team bias, and any mutant combinations of them that may arise<sup>2</sup>.</p>\n<p>As is often the case, <a href=\"/lw/48/the_power_of_positivist_thinking/\">reduction of statements with objective truth-values</a> can save your hide here. If every time Chris the Christian says \"Christians are persecuted,\" you hear \"Christians aren't allowed to stick the Ten Commandments up in schools,\" then you're no longer vulnerable to his appeal to pity.</p>\n<p>What other defenses are there against the human tendency to obsess over which side is more powerful, instead of which side is right?</p>\n<p><strong>Footnotes:</strong></p>\n<p><strong>1:</strong> The first comment <a href=\"http://www.worthynews.com/1710-persecution-of-christians-growing-in-the-united-states\">comes from Worthy News</a>, the second from <a href=\"http://atheism.about.com/od/atheistbigotryprejudice/Bigotry_Discrimination_Against_Atheists_Godless_Nonreligious.htm\">About Atheism</a>, the third from <a href=\" http://mideastyouth.com/2007/12/29/boim-case-overturned-american-persecution-of-muslims-arabs-hits-another-road-block/\">Mideast Youth</a>, and the fourth is <a href=\"http://creepingsharia.wordpress.com/2009/02/12/intimidating-critics-of-islam-rick-santorum-on-wilders/\">Senator Rick Santorum</a></p>\n<p><strong>2: </strong>Has anyone else ever watched two people in an argument completely abandon discussion over who is right, and instead turn to which person's side is persecuted worse, as if they were more or less the same question anyway? It's not a pretty sight.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2EFq8dJbxKNzforjM": 1, "FkzScn5byCs9PxGsA": 1, "Q6P8jLn8hH7kbuXRr": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PCpzG9NJeviXM5YSq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": 39, "extendedScore": null, "score": 6.5e-05, "legacy": true, "legacyId": "335", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 145, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["A4MK9RQqSAJZjanQD", "rg7vPTtyLMfT6Qqud", "XYrcTJFJoYKX2DxNL", "azoP7WeKYYfgCozoh", "9hR2RmpJmxT8dyPo4", "P3uavjFmZD5RopJKk", "ZiQqsgGX6a42Sfpii"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-08T01:19:18.700Z", "modifiedAt": null, "url": null, "title": "Zero-based karma coming through", "slug": "zero-based-karma-coming-through", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:36.542Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iNhRdRqwFqQHPRqE4/zero-based-karma-coming-through", "pageUrlRelative": "/posts/iNhRdRqwFqQHPRqE4/zero-based-karma-coming-through", "linkUrl": "https://www.lesswrong.com/posts/iNhRdRqwFqQHPRqE4/zero-based-karma-coming-through", "postedAtFormatted": "Wednesday, April 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Zero-based%20karma%20coming%20through&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AZero-based%20karma%20coming%20through%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNhRdRqwFqQHPRqE4%2Fzero-based-karma-coming-through%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Zero-based%20karma%20coming%20through%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNhRdRqwFqQHPRqE4%2Fzero-based-karma-coming-through", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNhRdRqwFqQHPRqE4%2Fzero-based-karma-coming-through", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 55, "htmlBody": "<p>Our friends at Tricycle will push through a zero-based karma system (no self-voting possible) sometime this evening.&nbsp; At present this will only cover future posts/comments - they may go back and revise history some time in the indefinite future (or not), but apparently that would be overly complicated for now.&nbsp; We'll see how this works.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iNhRdRqwFqQHPRqE4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 9, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "337", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-08T13:01:01.604Z", "modifiedAt": null, "url": null, "title": "E-Prime", "slug": "e-prime", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:23.210Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CannibalSmith", "createdAt": "2009-02-27T07:32:08.507Z", "isAdmin": false, "displayName": "CannibalSmith"}, "userId": "4DedYkNap2GW8X79T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K9mSWuKpZSk7t8FaH/e-prime", "pageUrlRelative": "/posts/K9mSWuKpZSk7t8FaH/e-prime", "linkUrl": "https://www.lesswrong.com/posts/K9mSWuKpZSk7t8FaH/e-prime", "postedAtFormatted": "Wednesday, April 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20E-Prime&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AE-Prime%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK9mSWuKpZSk7t8FaH%2Fe-prime%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=E-Prime%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK9mSWuKpZSk7t8FaH%2Fe-prime", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK9mSWuKpZSk7t8FaH%2Fe-prime", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p>I found this and thought we could find a use for it.</p>\n<blockquote>\n<p>Wikipedia describes <a href=\"http://en.wikipedia.org/wiki/E-Prime\">E-Prime</a>, short for English-Prime, as a modified form of English. E-Prime uses very slightly simplified syntax and vocabulary, eliminating all forms of the verb to be.</p>\n<p>Some people use E-Prime as a mental discipline to filter speech and translate the speech of others. For example, the sentence \"the movie was good\", translated into E-Prime, could become \"I liked the movie\". The translation communicates the speaker's subjective experience of the movie rather than the speaker's judgment of the movie. In this example, using E-Prime makes it harder for the writer or reader to confuse a statement of opinion with a statement of fact.</p>\n</blockquote>\n<p>Discuss! In E-Prime!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FtT2T9bRbECCGYxrL": 1, "5f5c37ee1b5cdee568cfb12a": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K9mSWuKpZSk7t8FaH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 16, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "340", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-08T18:10:20.193Z", "modifiedAt": "2019-12-09T20:12:57.547Z", "url": null, "title": "Mandatory Secret Identities", "slug": "mandatory-secret-identities", "viewCount": null, "lastCommentedAt": "2019-06-22T16:19:43.055Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gBewgmzcEiks2XdoQ/mandatory-secret-identities", "pageUrlRelative": "/posts/gBewgmzcEiks2XdoQ/mandatory-secret-identities", "linkUrl": "https://www.lesswrong.com/posts/gBewgmzcEiks2XdoQ/mandatory-secret-identities", "postedAtFormatted": "Wednesday, April 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mandatory%20Secret%20Identities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMandatory%20Secret%20Identities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgBewgmzcEiks2XdoQ%2Fmandatory-secret-identities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mandatory%20Secret%20Identities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgBewgmzcEiks2XdoQ%2Fmandatory-secret-identities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgBewgmzcEiks2XdoQ%2Fmandatory-secret-identities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 976, "htmlBody": "<p><strong>Previously in series</strong>:&nbsp; <a href=\"/lw/8t/whiningbased_communities/\">Whining-Based Communities</a></p>\n<blockquote>\n<p>\"But there is a reason why many of my students have achieved great things; and by that I do not mean high rank in the Bayesian Conspiracy.&nbsp; I expected much of them, and they came to expect much of themselves.\" &mdash;<a href=\"http://www.overcomingbias.com/2008/05/class-project.html\">Jeffreyssai</a></p>\n</blockquote>\n<p>Among the <a href=\"/lw/2i/epistemic_viciousness/\">failure modes of martial arts dojos</a>, I suspect, is that a sufficiently <em>dedicated </em>martial arts student, will dream of...</p>\n<p>...becoming a teacher and having their own martial arts dojo someday.</p>\n<p>To see what's wrong with this, imagine going to a class on literary criticism, falling in love with it, and dreaming of someday becoming a famous literary critic <em>just like your professor,</em> but <em>never actually writing anything.</em>&nbsp; Writers tend to look down on literary critics' understanding of the art form itself, for just this reason.&nbsp; (Orson Scott Card uses the analogy of a wine critic who listens to a wine-taster saying \"This wine has a great bouquet\", and goes off to tell their students \"You've got to make sure your wine has a great bouquet\".&nbsp; When the student asks, \"How?&nbsp; Does it have anything to do with grapes?\" the critic replies disdainfully, \"That's for <em>grape-growers!</em>&nbsp; I teach <em>wine.</em>\")</p>\n<p>Similarly, I propose, no student of rationality should study with the purpose of becoming a rationality instructor in turn.&nbsp; You do that on Sundays, or full-time after you retire.</p>\n<p>And to place a go stone blocking this failure mode, I propose a requirement that all rationality instructors must have secret identities.&nbsp; They must have a life <em>outside</em> the Bayesian Conspiracy, which would be worthy of respect even if they were not rationality instructors.&nbsp; And to enforce this, I suggest the rule:</p>\n<p style=\"padding-left: 30px;\">&nbsp; Rationality_Respect<sub>1</sub>(Instructor) = <em>min</em>(Rationality_Respect<sub>0</sub>(Instructor), Non_Rationality_Respect<sub>0</sub>(Instructor))</p>\n<p>That is, you can't respect someone <em>as </em>a rationality instructor, <em>more</em> than you would respect them if they were <em>not </em>rationality instructors.<a id=\"more\"></a></p>\n<p>Some notes:</p>\n<p>&bull; This doesn't set Rationality_Respect<sub>1</sub> <em>equal</em> to Non_Rationality_Respect<sub>0</sub>.&nbsp; It establishes an <em>upper bound.</em>&nbsp; This doesn't mean you can find random awesome people and expect them to be <a href=\"/lw/m/unteachable_excellence/\">able to teach you</a>.&nbsp; Explicit, abstract, cross-domain understanding of rationality and the ability to teach it to others <em>is</em>, unfortunately, an additional discipline on top of domain-specific life success.&nbsp; Newton was a Christian etcetera.&nbsp; I'd rather hear what Laplace had to say about rationality&mdash;Laplace wasn't as famous <em>as Newton</em>, but Laplace was a great mathematician, physicist, and astronomer in his own right, <em>and</em> he was the one who said \"I have no need of that hypothesis\" (when Napoleon asked why Laplace's works on celestial mechanics did not mention God).&nbsp; So I would respect Laplace as a rationality instructor well above Newton, by the <em>min</em>() function given above.</p>\n<p>&bull; We should be generous about what counts as a secret identity <em>outside </em>the Bayesian Conspiracy.&nbsp; If it's something that outsiders do in fact see as impressive, then it's \"outside\" regardless of how much Bayesian content is in the job.&nbsp; An experimental psychologist who writes good papers on heuristics and biases, a successful trader who uses Bayesian algorithms, a well-selling author of a general-audiences popular book on atheism&mdash;all of these have worthy secret identities.&nbsp; None of this contradicts the spirit of being <em>good at something besides rationality</em>&mdash;no, not even the last, because <em>writing books that sell </em>is a further difficult skill!&nbsp; At the same time, you don't want to be too lax and start respecting the instructor's ability to put up probability-theory equations on the blackboard&mdash;it has to be visibly <em>outside</em> the walls of the dojo and nothing that could be systematized <em>within</em> the Conspiracy as a token requirement.</p>\n<p>&bull; Apart from this, I shall not try to specify what exactly is worthy of respect.&nbsp; A creative mind may have good reason to depart from any criterion I care to describe.&nbsp; I'll just stick with the idea that \"Nice rationality instructor\" should be bounded above by \"Nice secret identity\".</p>\n<p>&bull; <em>But </em>if the Bayesian Conspiracy is ever to populate itself with instructors, this criterion should not be too strict.&nbsp; A simple test to see whether you live inside an elite bubble is to ask yourself whether the percentage of PhD-bearers in your apparent world exceeds the 0.25% rate at which they are found in the general population.&nbsp; Being a math professor at a small university who has published a few original proofs, or a successful day trader who retired after five years to become an organic farmer, or a serial entrepreneur who lived through three failed startups before going back to a more ordinary job as a senior programmer&mdash;that's nothing to sneeze at.&nbsp; The vast majority of people go through their whole lives without being that interesting.&nbsp; Any of these three would have some tales to tell of real-world use, on Sundays at the small rationality dojo where they were instructors.&nbsp; What I'm trying to say here is: don't demand that everyone be Robin Hanson in their secret identity, that is setting the bar too high.&nbsp; Selective reporting makes it seem that fantastically high-achieving people have a far higher relative frequency than their real occurrence.&nbsp; So if you ask for your rationality instructor to be <em>as interesting as the sort of people you read about in the newspapers</em>&mdash;and a master rationalist on top of that&mdash;and a good teacher on top of <em>that</em>&mdash;then you're going to have to join one of three famous dojos in New York, or something.&nbsp; <em>But </em>you don't want to be too lax and start respecting things that others wouldn't respect if they weren't specially looking for reasons to praise the instructor.&nbsp; \"Having a good secret identity\" should require <em>way</em> more effort than anything that could become a token requirement.</p>\n<p>Now I put to you:&nbsp; If the instructors all have real-world anecdotes to tell of using their knowledge, and all of the students know that the desirable career path can't <em>just</em> be to become a rationality instructor, doesn't that sound healthier?</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/9v/beware_of_otheroptimizing/\">Beware of Other-Optimizing</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/8t/whiningbased_communities/\">Whining-Based Communities</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zv7v2ziqexSn5iS9v": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gBewgmzcEiks2XdoQ", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 77, "baseScore": 61, "extendedScore": null, "score": 9.3e-05, "legacy": true, "legacyId": "336", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 61, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 186, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["rg7vPTtyLMfT6Qqud", "T8ddXNtmNSHexhQh8", "34Tu4SCK5r5Asdrn3", "YdcF6WbBmJhaaDqoD", "6NvbSwuSAooQxxf7f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-08T20:28:48.644Z", "modifiedAt": null, "url": null, "title": "Rationality, Cryonics and Pascal's Wager", "slug": "rationality-cryonics-and-pascal-s-wager", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:00.517Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Roko", "createdAt": "2009-02-27T14:12:55.113Z", "isAdmin": false, "displayName": "Roko"}, "userId": "73WJbnX59kE4afuuY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dz3Mmr2Cykz6RRfhK/rationality-cryonics-and-pascal-s-wager", "pageUrlRelative": "/posts/dz3Mmr2Cykz6RRfhK/rationality-cryonics-and-pascal-s-wager", "linkUrl": "https://www.lesswrong.com/posts/dz3Mmr2Cykz6RRfhK/rationality-cryonics-and-pascal-s-wager", "postedAtFormatted": "Wednesday, April 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%2C%20Cryonics%20and%20Pascal's%20Wager&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%2C%20Cryonics%20and%20Pascal's%20Wager%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdz3Mmr2Cykz6RRfhK%2Frationality-cryonics-and-pascal-s-wager%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%2C%20Cryonics%20and%20Pascal's%20Wager%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdz3Mmr2Cykz6RRfhK%2Frationality-cryonics-and-pascal-s-wager", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdz3Mmr2Cykz6RRfhK%2Frationality-cryonics-and-pascal-s-wager", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1401, "htmlBody": "<!--[if !mso]> <mce:style><! v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} --> <!--[endif]--> <!--[endif]-->\n<p>This has been <a href=\"http://www.overcomingbias.com/2009/03/pascals-wager-metafallacy.html\">covered by Eliezer on OB</a>, but I the debate will work better with the LW voted commenting system, and I hope I can add something to the OB debate, which I feel left the spectre of Pascalian religious apology clinically dead but not quite <a href=\"http://en.wikipedia.org/wiki/Information-theoretic_death\">information theoretically dead</a>. Anna Salamon <a href=\"http://www.overcomingbias.com/2009/03/pascals-wager-metafallacy.html?cid=6a00d8341c6a2c53ef01127973ce5e28a4#comment-6a00d8341c6a2c53ef01127973ce5e28a4\">writes</a>:</p>\n<blockquote>\n<p><span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\">The &ldquo;isn&rsquo;t that like Pascal&rsquo;s wager?&rdquo; response is plausibly an instance of <a rel=\"nofollow\" href=\"http://www.overcomingbias.com/2008/10/the-dark-side.html\">dark side epistemology</a>, and one that affects many aspiring rationalists.</span></p>\n<p>Many of us came up against the Pascal&rsquo;s wager argument at some point before we gained much rationality skill, disliked the conclusion, and hunted around for some means of disagreeing with its reasoning. The overcoming bias <a rel=\"nofollow\" href=\"http://www.overcomingbias.com/2008/08/where-does-pasc.html#comments\">thread</a> discussing Pascal&rsquo;s wager strikes me as including a fair number of fallacious comments aimed at finding some rationale, any rationale, for dismissing Pascal&rsquo;s wager.</p>\n</blockquote>\n<p><span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\">This really got me worried: do I really rationally believe in the efficacy of cryonics and not of religion? Or did I write <a href=\"http://www.overcomingbias.com/2007/09/the-bottom-line.html\">the bottom line</a> first and then start thinking of justifications? </span></p>\n<p><span>Of course, it is easy to write a post justifying cryonics in a way that shuns religion. That's what everyone wants to hear on this forum! What is hard is doing it in a way that ensures you're not just writing even more justification with no chance of retracting the bottom line. I hope that with this post I have succeeded in burying the Pascalian attack on cryonics for good; and in removing a little more ignorance about my true values. <br /></span></p>\n<p><span><a id=\"more\"></a><br /></span></p>\n<p><!--[if gte vml 1]><v:shapetype id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\" path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\"> <v:stroke joinstyle=\"miter\" /> <v:formulas> <v:f eqn=\"if lineDrawn pixelLineWidth 0\" /> <v:f eqn=\"sum @0 1 0\" /> <v:f eqn=\"sum 0 0 @1\" /> <v:f eqn=\"prod @2 1 2\" /> <v:f eqn=\"prod @3 21600 pixelWidth\" /> <v:f eqn=\"prod @3 21600 pixelHeight\" /> <v:f eqn=\"sum @0 0 1\" /> <v:f eqn=\"prod @6 1 2\" /> <v:f eqn=\"prod @7 21600 pixelWidth\" /> <v:f eqn=\"sum @8 21600 0\" /> <v:f eqn=\"prod @7 21600 pixelHeight\" /> <v:f eqn=\"sum @10 21600 0\" /> </v:formulas> <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\" /> <o:lock v:ext=\"edit\" aspectratio=\"t\" /> </v:shapetype><v:shape id=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"\" style='width:.75pt; height:.75pt'> <v:imagedata src=\"file:///C:\\DOCUME~1\\me\\LOCALS~1\\Temp\\msohtml1\\01\\clip_image001.gif\" mce_src=\"file:///C:\\DOCUME~1\\me\\LOCALS~1\\Temp\\msohtml1\\01\\clip_image001.gif\" o:href=\"http://lesswrong.com/static/tiny_mce/plugins/summarybreak/img/trans.gif\" /> </v:shape><![endif]--><!--[if !vml]--><!--[endif]--></p>\n<p>To me, the justification for wanting to be cryopreserved is that there is, in fact, a good chance (more than the chance of rolling a 5 or a 6 on a six sided die)<sup>1</sup> that I will be revived into a very nice world indeed, and that the chance of being revived into a hell I cannot escape from is less than or equal to this (I am a risk taker). How sensitive is this to the expected goodness and length-in-time of the utopia I wake up in? If the utopia is as good as <a href=\"http://en.wikipedia.org/wiki/The_Culture\">Iain M Banks' culture</a>, I'd still be interested in spending 5% of my income a year and 5% of my time getting frozen if the probability was around about the level of rolling two consecutive sixes.</p>\n<p>Does making the outcome better change things? Suppose we take the culture and \"upgrade it\" by fulfilling all of my fantasies:&nbsp;<span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\"> T</span>he Banksian utopia I have described is analogous to the utopia of the tired peasant compared to what is possible. An even better utopia which appeals to me on an intellectual and subtly sentimental level would involve continued personal growth towards experiences beyond raw peak experience as I know it today. This perhaps pushes me to tolerating probabilities around the four sixes level, (1/(6*6*6*6) ~ 1/1000) but no further. For me this probability feels like \"just a little bit less unlikely than impossible\".&nbsp;</p>\n<p>Now, how does this bear on Pascal's wager? Well, I just don't register long-term life outcomes that happen with a probability of less than one in a thousand. End of story! Heaven *could not be good enough* and hell *could not be bad enough* to make it matter to me, and I can be fairly sure about this because I have just visualized a plausible heaven that I actually \"believe in\".</p>\n<p>Now what is my actual probability estimate of Cryonics working? <a href=\"http://www.overcomingbias.com/2009/03/break-cryonics-down.html\">Robin</a> talks about breaking it down into a series of events and estimating their conditional probabilities. My breakdown of the probability of a successful outcome if you die right now is:</p>\n<ol type=\"1\">\n<li class=\"MsoNormal\">The probability that human civilization will survive into the sufficiently far future (my estimate: 50%)</li>\n<li class=\"MsoNormal\">The probability that you get cryopreserved rather than autopsied or shot in the head, and you get cooled down sufficiently quickly (my estimate: 80%, though this will improve)</li>\n<li class=\"MsoNormal\">The probability that cryonics preserves appropriate brain structure (my estimate: 75%)</li>\n<li class=\"MsoNormal\">The probability that you don't get destroyed whilst frozen, for example by incompetent financial management of cryonics companies (my estimate: 80%)</li>\n<li class=\"MsoNormal\">The probability that someone will revive you into a pleasant society conditional upon the above (my estimate: 95%)</li>\n</ol>\n<p><span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\">Yielding a disappointingly low probability of 0.228. [I expect this to improve to ~0.4 by the time I get old enough for it to be a personal consideration.] I don't think that one could be any more optimistic than the above. But this probability is tantalizing: Enough to get me very excited about all those peak experiences and growth that I described above, though <strong>it probably won't happen</strong>. It is roughly the probability of tossing a coin twice and getting heads both times.</span></p>\n<p>It is also worth mentioning that the analyses I have seen relating to <a href=\"http://www.nickbostrom.com/papers/future.pdf\">the future of humanity</a> indicate that a Banksian almost-utopia is unlikely, that the positive scenarios are *very positive*, and negative scenarios usually involve the destruction of human technological society. My criterion of personal identity will probably be the limiting factor in how good a future I can experience. If I am prepared to spend 5% of my time and effort pursuing a 1 in 100 chance of the this maxed-out utopia, I should be prepared to put quite a lot of effort into making sure I \"make it\" given the probability I've just estimated.</p>\n<p>If someone were to convince me that the probability of cryonics working was, in fact, less than 1 in 1000, I would (quite rationally) give up on it.<span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\"><br /> <!--[endif]--></span></p>\n<p>This relatively high probability I've estimated (two heads on a coin) has other consequences for cryonaughts alive today, if they believe it. We should be prepared to expend a non-negligible amount of effort moving somewhere where the probability of quick suspension is as high as possible.<span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\"> Making cryonics more popular will make probabilities 1, 2, and 4 increase. (2 will increase because people will have a stake in the future after their deanimation). The cryonics community should therefore spend some time and effort convincing more people to be cryopreserved, though this is a hard problem, intimately related to the purpose of Less Wrong, rationality and to secular ethics and secular \"religions\" such as <a href=\"http://www.secularhumanism.org/\">secular humanism</a>, <a href=\"http://www.transhumanism.org/index.php/WTA/index/\">h+</a> and <a href=\"http://the-brights.net/\">the brights</a>. Those who are pro-cryonics and have old relatives should be prepared to bite the social cost of attempting to persuade those relatives that cryonics is worth thinking about, at least to the extent that they care about their relatives. This is an actionable item that I intend to action with all of my 4 remaining grandparents in the next few months. <br /> <!--[endif]--></span></p>\n<p>I have seen (but cannot find the citation for, though see <a href=\"http://www.nia.nih.gov/Alzheimers/ResearchInformation/NewsReleases/Archives/PR2001/PR20011112cognitiveimpairment.htm\">this</a>) research that predicts that 50% of people will suffer from dementia for the 6 months before they die by 2020 (and that this will get <em>worse </em>over time as life expectancy increases). If we add to my list above a term for \"the probability that you won't be information theoretically dead before you're legally dead\", and set it to 50%, the overall probability takes a huge hit; in addition, a controlled deanimation improves the probability of being deanimated without damage. Any cryonaught who really shares my beliefs about the rewards and probabilities for cryonics should be prepared to deainmate theselves before they would naturally die, <span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\">perhaps by a significant amount, say 10 years. </span>(yes, I know this is illegal, but it is a useful thought experiment, and it indicates that we should be campaigning hard for this). If you really believe the probabilities I've given for cryonics, you should deanimate instead of retiring. At a sufficiently high probability of cryonics working, you should rationally attempt to deanimate immediately or within a few years, no matter how old you are, in order to maximize the amount of your personal development which occurs in a really good environment. It seems unlikely that this situation will come to pass, but it is an interesting thought experiment; if you would not be prepared, under sufficiently compelling circumstances, to prematurely deanimate, you may be in cryonics for nonrational reasons.</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p><sup>1 </sup>[The use of dice rather than numbers to represent probabilities <span id=\"comment-6a00d8341c6a2c53ef01127973ce5e28a4-content\">in this article</span> comes from my war-gaming days. I have a good emotional intuition as to how unlikely rolling a 6 is, it is more informative to me than 0.1666. I've won and lost battles based on 6+ <a href=\"http://en.wikipedia.org/wiki/Saving_throw\">saving throws</a>. I recommend that readers play some game that involves dice to get a similarly good intuition]</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZnHkaTkxukegSrZqE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dz3Mmr2Cykz6RRfhK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 18, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "127", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-08T22:16:28.907Z", "modifiedAt": null, "url": null, "title": "Less Wrong IRC Meetup", "slug": "less-wrong-irc-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:24.892Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4xEohME6vfXNmHmAz/less-wrong-irc-meetup", "pageUrlRelative": "/posts/4xEohME6vfXNmHmAz/less-wrong-irc-meetup", "linkUrl": "https://www.lesswrong.com/posts/4xEohME6vfXNmHmAz/less-wrong-irc-meetup", "postedAtFormatted": "Wednesday, April 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20IRC%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20IRC%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xEohME6vfXNmHmAz%2Fless-wrong-irc-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20IRC%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xEohME6vfXNmHmAz%2Fless-wrong-irc-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xEohME6vfXNmHmAz%2Fless-wrong-irc-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 129, "htmlBody": "<p>Less Wrong will be having a meetup on Saturday at 7pm UTC (<a href=\"http://www.timeanddate.com/worldclock/fixedtime.html?month=4&amp;day=11&amp;year=2009&amp;hour=19&amp;min=0&amp;sec=0&amp;p1=0\" target=\"_self\">convert to other time zones</a>), in the #lesswrong IRC channel on Freenode. If all goes well, this will be a recurring event. If you haven't used IRC before, <a href=\"http://mibbit.com/chat/?server=irc.freenode.net&amp;channel=%23lesswrong\" target=\"_blank\">Mibbit</a> provides a web-based client you can use.</p>\n<p>We may do some <a href=\"/lw/77/selecting_rationalist_groups/\">Paranoid Debating</a>. Discuss rules and procedures here. A few people should bring questions, but avoid looking at the answers if you can avoid it. Depending how many people show up, we'll may need to break into multiple groups. Once we've finalized the rules and done it a few times, I (or someone else) can write a bot to assign roles and keep score.</p>\n<p>(Edit: Downgraded Paranoid Debating from being the purpose of the meetup to being a likely activity.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4xEohME6vfXNmHmAz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 4, "extendedScore": null, "score": 4.865413628618489e-07, "legacy": true, "legacyId": "344", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZEj9ATpv3P22LSmnC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-09T00:24:02.553Z", "modifiedAt": "2020-04-29T18:46:38.321Z", "url": null, "title": "\"Stuck In The Middle With Bruce\"", "slug": "stuck-in-the-middle-with-bruce", "viewCount": null, "lastCommentedAt": "2022-04-08T16:19:59.140Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "CronoDAS", "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FZaDFYbnRoHmde7F6/stuck-in-the-middle-with-bruce", "pageUrlRelative": "/posts/FZaDFYbnRoHmde7F6/stuck-in-the-middle-with-bruce", "linkUrl": "https://www.lesswrong.com/posts/FZaDFYbnRoHmde7F6/stuck-in-the-middle-with-bruce", "postedAtFormatted": "Thursday, April 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Stuck%20In%20The%20Middle%20With%20Bruce%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Stuck%20In%20The%20Middle%20With%20Bruce%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFZaDFYbnRoHmde7F6%2Fstuck-in-the-middle-with-bruce%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Stuck%20In%20The%20Middle%20With%20Bruce%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFZaDFYbnRoHmde7F6%2Fstuck-in-the-middle-with-bruce", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFZaDFYbnRoHmde7F6%2Fstuck-in-the-middle-with-bruce", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 354, "htmlBody": "<p>I was somewhat disappointed to find a lack of Magic: the Gathering players on LessWrong when I asked about it in the off-topic thread. You see, competitive Magic is one of the best, most demanding rationality battlefields that I know about. Furthermore, Magic is discussed extensively on the Internet, and many articles in which people try to explain how to become a better Magic player are, essentially, describing how to become more rational: how to better learn from experience, make judgments from noisy data, and (yes) overcome biases that interfere with one's ability to make better decisions.</p>\n<p>Because people here don't play Magic, I can't simply link to those articles and say, \"Here. Go read.\" I have to put everything into context, because Magic jargon has become its own language, distinct from English. Think I'm kidding? I was able to follow match coverage written in <em>French</em> using nothing but my knowledge of Magic-ese and what I remembered from my high school <em>Spanish</em> classes. Instead of simply linking, in order to give you the full effect, I'd have to undertake a project equivalent to translating a work in a foreign language.</p>\n<p>So it is with great trepidation that I give you, untranslated, one of the \"classics\" of Magic literature.</p>\n<p><a href=\"https://articles.starcitygames.com/premium/stuck-in-the-middle-with-bruce/\">Stuck In The Middle With Bruce</a> by John F. Rizzo.</p>\n<p>Now, John \"Friggin'\" Rizzo isn't one of the great Magic players. Far from it. He is, however, one of the great Magic <em>writers</em>, to the extent that the adjective \"great\" can be applied to someone who writes about Magic. His bizarre stream-of-consciousness writing style, personal stories, and strongly held opinions have made him a legend in the Magic community. \"Stuck in the Middle with Bruce\" is his most famous work, as incomprehensible as it may be to those who don't speak our language (and even to those that do).</p>\n<p>So, why am I choosing to direct you to this particular piece of writing? Well, although Rizzo doesn't know much about winning, he knows an awful lot about what causes people to lose, and that's the topic of this particular piece - people's need to lose.</p>\n<p>Does Bruce whisper into your ear, too?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FZaDFYbnRoHmde7F6", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 93, "baseScore": 93, "extendedScore": null, "score": 0.000143, "legacy": true, "legacyId": "348", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 93, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 101, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-09T02:44:20.056Z", "modifiedAt": null, "url": null, "title": "Extreme Rationality: It's Not That Great", "slug": "extreme-rationality-it-s-not-that-great", "viewCount": null, "lastCommentedAt": "2022-03-07T17:29:40.408Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LgavAYtzFQZKg95WC/extreme-rationality-it-s-not-that-great", "pageUrlRelative": "/posts/LgavAYtzFQZKg95WC/extreme-rationality-it-s-not-that-great", "linkUrl": "https://www.lesswrong.com/posts/LgavAYtzFQZKg95WC/extreme-rationality-it-s-not-that-great", "postedAtFormatted": "Thursday, April 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Extreme%20Rationality%3A%20It's%20Not%20That%20Great&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExtreme%20Rationality%3A%20It's%20Not%20That%20Great%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLgavAYtzFQZKg95WC%2Fextreme-rationality-it-s-not-that-great%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Extreme%20Rationality%3A%20It's%20Not%20That%20Great%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLgavAYtzFQZKg95WC%2Fextreme-rationality-it-s-not-that-great", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLgavAYtzFQZKg95WC%2Fextreme-rationality-it-s-not-that-great", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2372, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/41/individual_rationality_is_a_matter_of_life_and/\">Individual Rationality is a Matter of Life and Death</a>, <a href=\"/lw/6t/the_benefits_of_rationality/\">The Benefits of Rationality</a>, <a href=\"/lw/7i/rationality_is_systematized_winning/\">Rationality is Systematized Winning</a><br /><strong>But I finally snapped after reading: </strong><a href=\"/lw/9c/mandatory_secret_identities/\">Mandatory Secret Identities</a><br /><br />Okay, the title was for shock value. Rationality is pretty great. Just not <em>quite </em>as great as everyone here seems to think it is.<br /><br />For this post, I will be using \"extreme rationality\" or \"x-rationality\" in the sense of \"techniques and theories from Overcoming Bias, Less Wrong, or similar deliberate formal rationality study programs, above and beyond the standard level of rationality possessed by an intelligent science-literate person without formal rationalist training.\" It seems pretty uncontroversial that there are massive benefits from going from a completely irrational moron to the average intelligent person's level. I'm coining this new term so there's no temptation to confuse x-rationality with normal, lower-level rationality.<br /><br />And for this post, I use \"benefits\" or \"practical benefits\" to mean anything not relating to philosophy, truth, winning debates, or a sense of personal satisfaction from understanding things better. Money, status, popularity, and scientific discovery all count.<br /><br />So, what are these \"benefits\" of \"x-rationality\"?<br /><br />A while back, Vladimir Nesov asked exactly that, and <a href=\"/lw/2x/in_what_ways_have_you_become_stronger/\">made a thread for people to list all of the positive effects</a> x-rationality had on their lives. Only a handful responded, and most responses weren't very practical. Anna Salamon, one of the few people to give a really impressive list of benefits, wrote:</p>\n<blockquote>\n<p>I'm surprised there are so few apparent gains listed. Are most people who benefited just being silent? We should expect a certain number of headache-cures, etc., just by placebo effects or coincidences of timing.</p>\n</blockquote>\n<p>There have since been a few more people claiming practical benefits from x-rationality, but we should generally expect more people to claim benefits than to actually experience them. Anna mentions the placebo effect, and to that I would add cognitive dissonance - people spent all this time learning x-rationality, so it MUST have helped them! - and the same sort of confirmation bias that makes Christians swear that their prayers really work.<br /><br />I find my personal experience in accord with the evidence from Vladimir's thread. I've gotten countless clarity-of-mind benefits from Overcoming Bias' x-rationality, but practical benefits? Aside from some peripheral disciplines<sup>1</sup>, I can't think of any.<br /><br />Looking over history, I do not find any tendency for successful people to have made a formal study of x-rationality. This isn't entirely fair, because the discipline has expanded vastly over the past fifty years, but the basics - syllogisms, fallacies, and the like - have been around much longer. The few groups who made a concerted effort to study x-rationality didn't shoot off an unusual number of geniuses - the Korzybskians are a good example. In fact as far as I know the only follower of Korzybski to turn his ideas into a vast personal empire of fame and fortune was (ironically!) L. Ron Hubbard, who took the basic concept of techniques to purge confusions from the mind, replaced the substance with a bunch of attractive flim-flam, and founded Scientology. And like Hubbard's superstar followers, many of this century's most successful people have been notably <em>ir</em>rational.<br /><br />There seems to me to be approximately zero empirical evidence that x-rationality has a large effect on your practical success, and some anecdotal empirical evidence against it. The evidence in favor of the proposition right now seems to be its sheer obviousness. Rationality is the study of knowing the truth and making good decisions. How the heck could knowing more than everyone else and making better decisions than them not make you more successful?!?<br /><br />This is a difficult question, but I think it has an answer. A complex, multifactorial answer, but an answer.</p>\n<p><a id=\"more\"></a></p>\n<p>One factor <a href=\"/lw/2c/a_sense_that_more_is_possible/1ch#comments\">we have to once again come back to</a> is akrasia<sup>2</sup>. I find akrasia in myself and others to be the most important limiting factor to our success. Think of that phrase \"limiting factor\" formally, the way you'd think of the limiting reagent in chemistry. When there's a limiting reagent, it doesn't matter how much more of the other reagents you add, the reaction's not going to make any more product. Rational decisions are practically useless without the willpower to carry them out. If our limiting reagent is willpower and not rationality, throwing truckloads of rationality into our brains isn't going to increase success very much.<br /><br />This is a very large part of the story, but not the whole story. If I was rational enough to pick only stocks that would go up, I'd become successful regardless of how little willpower I had, as long as it was enough to pick up the phone and call my broker.<br /><br />So the second factor is that most people are rational enough for their own purposes. Oh, they go on wild flights of fancy when discussing politics or religion or philosophy, but when it comes to business they suddenly become cold and calculating. This relates to Robin Hanson on Near and Far modes of thinking. Near Mode thinking is actually pretty good at a lot of things, and Near Mode thinking is the thinking whose accuracy gives us practical benefits. <br /><br />And - when I was young, I used to watch The Journey of Allen Strange on Nickleodeon. It was a children's show about this alien who came to Earth and lived with these kids. I remember one scene where Allen the Alien was watching the kids play pool. \"That's amazing,\" Allen told them. \"I could never calculate differential equations in my head that quickly.\" The kids had to convince him that \"it's in the arm, not the head\" - that even though the movement of the balls is governed by differential equations, humans don't actually calculate the equations each time they play. They just move their arm in a way that feels right. If Allen had been smarter, he could have explained that the kids were doing some very impressive mathematics on a subconscious level that produced their arm's perception of \"feeling right\". But the kids' point still stands; even though in theory explicit mathematics will produce better results than eyeballing it, in practice you can't become a good pool player just by studying calculus.<br /><br />A lot of human rationality follows the same pattern. Isaac Newton is frequently named as a guy who knew no formal theories of science or rationality, who was hopelessly irrational in his philosophical beliefs and his personal life, but who is still widely and justifiably considered the greatest scientist who ever lived. Would Newton have gone even further if he'd known Bayes theory? Probably it would've been like telling the world pool champion to try using more calculus in his shots: not a pretty sight.</p>\n<p>Yes, yes, beisutsukai should be able <a href=\"http://www.overcomingbias.com/2008/05/class-project.html\">to develop quantum gravity in a month</a> and so on. But until someone on Less Wrong actually goes and does it, that story sounds a lot like when Alfred Korzybski claimed that World War Two could have been prevented if everyone had just used more <a href=\"/lw/9g/eprime/\">General Semantics</a>.</p>\n<p>And then there's just plain <em>noise</em>. Your success in the world depends on things ranging from your hairstyle to your height to your social skills to your IQ score to cognitive constructs psychologists don't even have names for yet. X-Rationality can help you succeed. But so can excellent fashion sense. It's not clear in real-world terms that x-rationality has <em>more</em> of an effect than fashion. And don't dismiss that with \"A good x-rationalist will know if fashion is important, and study fashion.\" A good normal rationalist could do that too; it's not a specific advantage of x-rationalism, just of having a general rational outlook. And having a general rational outlook, as I mentioned before, is limited in its effectiveness by poor application and akrasia.</p>\n<p>I no longer believe mastering all these Overcoming Bias and Less Wrong techniques will turn me into Anas&ucirc;rimbor Kellhus or John Galt. I no longer even believe mastering all these Overcoming Bias techniques will turn me into Eliezer Yudkowsky (who, as his writings from 2001 indicate, had developed his characteristic level of awesomeness before he became interested in x-rationality at all)<sup>3</sup>. I think it may help me succeed in life a little, but <strong>I think the correlation between x-rationality and success is probably closer to 0.1 than to 1.</strong> Maybe 0.2 in some businesses like finance, but people in finance tend to know this and use specially developed x-rationalist techniques on the job already without making it a lifestyle commitment. I think it was primarily a Happy Death Spiral around how wonderfully super-awesome x-rationality was that made me once think otherwise.<br /><br />And this is why I am not so impressed by Eliezer's claim that an x-rationality instructor should be successful in their non-rationality life. Yes, there probably are some x-rationalists who will also be successful people. But again, correlation 0.1. Stop saying <a href=\"/lw/9c/mandatory_secret_identities/672#comments\">only practically successful people could be good x-rationality teachers</a>! Stop saying we need to start having huge real-life victories or our art is useless! Stop calling x-rationality the Art of Winning! Stop saying <a href=\"/lw/6t/the_benefits_of_rationality/4hh#comments\">I must be engaged in some sort of weird signalling effort</a> for saying I'm here because I like mental clarity instead of because I want to be the next Bill Gates! It trivializes the very virtues that brought most of us to Overcoming Bias, and replaces them with what sounds a lot like a pitch for some weird self-help cult...</p>\n<p>...</p>\n<p>...</p>\n<p>...but you will disagree with me. And we are both aspiring rationalists, and therefore we resolve disagreements by experiments. I propose one.<br /><br />For the next time period - a week, a month, whatever - take special note of every decision you make. By \"decision\", I don't mean the decision to get up in the morning, I mean the sort that's made on a conscious level and requires at least a few seconds' serious thought. Make a tick mark, literal or mental, so you can count how many of these there are.<br /><br />Then note whether you make that decision rationally. If yes, also record whether you made that decision x-rationally. I don't just mean you spent a brief second thinking about whether any biases might have affected your choice. I mean one where you think there's a serious (let's arbitrarily say 33%) chance that using x-rationality instead of normal rationality actually changed the result of your decision.<br /><br />Finally, note whether, once you came to the rational conclusion, you actually followed it. This is not a trivial matter. For example, before writing this blog post I wondered briefly whether I should use the time studying instead, used normal (but not x-) rationality to determine that yes, I should, and then proceeded to write this anyway. And if you get that far, note whether your x-rational decisions tend to turn out particularly well.<br /><br />This experiment seems easy to rig<sup>4</sup>; merely doing it should increase your level of conscious rational decisions quite a bit. And yet I have been trying it for the past few days, and the results have not been pretty. Not pretty at all. Not only do I make fewer conscious decisions than I thought, but the ones I do make I rarely apply even the slightest modicum of rationality to, and the ones I apply rationality to it's practically never x-rationality, and when I do apply everything I've got I don't seem to follow those decisions too consistently.<br /><br />I'm not so great a rationalist anyway, and I may be especially bad at this. So I'm interested in hearing how different your results are. Just don't rig it. If you find yourself using x-rationality twenty times more often than you were when you weren't performing the experiment, you're rigging it, consciously or otherwise<sup>5</sup>.<br /><br />Eliezer writes:</p>\n<blockquote>\n<p>The novice goes astray and says, \"The Art failed me.\"<br />The master goes astray and says, \"I failed my Art.\"</p>\n</blockquote>\n<p>Yet one way to fail your Art is to expect more of it than it can deliver. No matter how good a swimmer you are, you will not be able to cross the Pacific. This is not to say crossing the Pacific is impossible. It just means it will require a different sort of thinking than the one you've been using thus far. Perhaps there are developments of the Art of Rationality or its associated Arts that <em>can</em> turn us into a Kellhus or a Galt, but they will not be reached by trying to overcome biases <em>really really hard.</em></p>\n<p><strong>Footnotes:</strong></p>\n<p><strong>1: </strong>Specifically, reading Overcoming Bias convinced me to study evolutionary psychology in some depth, which has been useful in social situations. As far as I know. I'd probably be biased into thinking it had been even if it hadn't, because I like evo psych and it's very hard to measure.</p>\n<p><strong>2: </strong>Eliezer considers fighting akrasia to be part of the art of rationality; he compares it to \"kicking\" to our \"punching\". I'm not sure why he considers them to be the same Art rather than two related Arts.</p>\n<p><strong>3: </strong>This is actually an important point. I think there are probably quite a few smart, successful people who develop an interest in x-rationality, but I can't think of any people who started out merely above-average, developed an interest in x-rationality, and then became smart and successful because of that x-rationality.</p>\n<p><strong>4: </strong>This is a terribly controlled experiment, and the only way its data can be meaningfully interpreted at all is through what one of my professors called the \"ocular trauma test\" - when the data hits you between the eyes. If people claim they always follow their rational decisions, I think I will be more likely to interpret it as lack of enough cognitive self-consciousness to notice when they're doing something irrational than an honest lack of irrationality.</p>\n<p><strong>5: </strong>In which case it will have ceased to be an experiment and become a technique instead. I've noticed this happening a lot over the past few days, and I may continue doing it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"9YFoDPFwMoWthzgkY": 6, "Ng8Gice9KNkncxqcj": 1, "3QnDqGSdRMA5mdMM6": 7, "5f5c37ee1b5cdee568cfb345": 2, "bXSkC7FFgApRnSajw": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LgavAYtzFQZKg95WC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 212, "baseScore": 221, "extendedScore": null, "score": 0.000334, "legacy": true, "legacyId": "349", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 222, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 281, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WzMJRQBN3ryxiAbhi", "DXBbQBHACYwAdKKyx", "4ARtkT3EYox3THYjF", "gBewgmzcEiks2XdoQ", "EsGuKGNC9gerguLv9", "K9mSWuKpZSk7t8FaH"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 13, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-09T15:45:07.922Z", "modifiedAt": null, "url": null, "title": "\"Playing to Win\"", "slug": "playing-to-win", "viewCount": null, "lastCommentedAt": "2017-06-17T03:52:15.363Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zrg8zohTAJKGAo5if/playing-to-win", "pageUrlRelative": "/posts/Zrg8zohTAJKGAo5if/playing-to-win", "linkUrl": "https://www.lesswrong.com/posts/Zrg8zohTAJKGAo5if/playing-to-win", "postedAtFormatted": "Thursday, April 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Playing%20to%20Win%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Playing%20to%20Win%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZrg8zohTAJKGAo5if%2Fplaying-to-win%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Playing%20to%20Win%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZrg8zohTAJKGAo5if%2Fplaying-to-win", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZrg8zohTAJKGAo5if%2Fplaying-to-win", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<p>John F. Rizzo is an expert on losing. However, if you want to win, you would do better to seek advice from an expert on winning.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/David_Sirlin\">David Sirlin</a> is such an expert, a renowned Street Fighter player and game designer. He wrote a series of articles with the title \"Playing to Win\", about playing competitive games at a high level, which were so popular that he expanded them into a book. You can either read it for free online (donations are appreciated) or purchase a dead tree edition.</p>\n<p>Any further summary would simply be redundant when you could simply read Sirlin's own words, so here is the link:</p>\n<p>http://www.sirlin.net/ptw</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 1, "hrezrpGqXXdSe76ks": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zrg8zohTAJKGAo5if", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 29, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "351", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-09T20:26:21.052Z", "modifiedAt": null, "url": null, "title": "Secret Identities vs. Groupthink", "slug": "secret-identities-vs-groupthink", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:25.394Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmy", "createdAt": "2009-02-28T00:36:34.416Z", "isAdmin": false, "displayName": "Swimmy"}, "userId": "pNdunthLRqh3unTry", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5epdtcyuDiuRFFJk5/secret-identities-vs-groupthink", "pageUrlRelative": "/posts/5epdtcyuDiuRFFJk5/secret-identities-vs-groupthink", "linkUrl": "https://www.lesswrong.com/posts/5epdtcyuDiuRFFJk5/secret-identities-vs-groupthink", "postedAtFormatted": "Thursday, April 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Secret%20Identities%20vs.%20Groupthink&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASecret%20Identities%20vs.%20Groupthink%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5epdtcyuDiuRFFJk5%2Fsecret-identities-vs-groupthink%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Secret%20Identities%20vs.%20Groupthink%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5epdtcyuDiuRFFJk5%2Fsecret-identities-vs-groupthink", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5epdtcyuDiuRFFJk5%2Fsecret-identities-vs-groupthink", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 283, "htmlBody": "<p>From <a href=\"http://www.marginalrevolution.com/marginalrevolution/2009/04/what-groups-talk-about.html\">Marginal Revolution</a>:</p>\n<blockquote>\n<p>A new <a href=\"http://www.apa.org/journals/releases/apl942535.pdf\">meta-analysis</a>&nbsp;(pdf) of 72 studies, involving 4,795 groups and over 17,000 individuals has shown that groups tend to <a href=\"http://www.citeulike.org/group/2546/article/1398512\">spend most of their time discussing the information shared by members</a>, which is therefore redundant, rather than discussing information known only to one or a minority of members. This is important because those groups that do share unique information tend to make better decisions.<br /><br />Another important factor is how much group members talk to each other. Ironically, <a href=\"http://www.csb.uncw.edu/people/magnusj/\">Jessica Mesmer-Magnus</a> and <a href=\"http://www.psych.ucf.edu/faculty_dechurch.php\">Leslie DeChurch</a> found that groups that talked more tended to share less unique information.</p>\n</blockquote>\n<p>A result that shouldn't surprise this group. I've noticed obvious attempts to avoid this tendency in Less Wrong (for instance, Yvain's <a href=\"/lw/9b/help_help_im_being_oppressed/64z#comments\">avoiding further Christian-bashing</a>). We've had at least <a href=\"/lw/2l/closet_survey_1/\">one post</a> asking specifically for information that was unique. And I don't know about the rest of you, but I've already had plenty of new food for thought on Less Wrong.</p>\n<p>But are we tapping the full potential? Each of us has, or should have, a <a href=\"/lw/9c/mandatory_secret_identities/\">secret identity</a>. The nice thing about those identities is that they give us access to unique knowledge. We've been asked (though I can't find the link) to avoid large posts applying learned rationality techniques to controversial topics, for fear of <a href=\"http://www.overcomingbias.com/2007/02/politics_is_the.html\">killing minds</a>, which seems reasonable to me. Is there a better way to allow discipline-specific knowledge to be shared among Less Wrong readers without setting off our politicosensors? It seems beneficial not only for improved rationality training, but also to enhance our secret identities. For instance, I, as an economist-in-training, would like to know not just what an anthropologist can tell me, but what a Bayesian-trained anthropologist can tell me.</p>\n<p><img id=\"smallDivTip\" style=\"border: 1px solid blue; z-index: 90; opacity: 1; position: absolute; left: 720px; top: 348px;\" src=\"chrome://dictionarytip/skin/book.png\" alt=\"\" /></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ALwRRZqvhaop8gxkT": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5epdtcyuDiuRFFJk5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 22, "extendedScore": null, "score": 4.867366385981731e-07, "legacy": true, "legacyId": "354", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gPdM553fhdZuNmDxn", "gBewgmzcEiks2XdoQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-09T21:24:19.367Z", "modifiedAt": null, "url": null, "title": "Silver Chairs, Paternalism, and Akrasia", "slug": "silver-chairs-paternalism-and-akrasia", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:38.043Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dclayh", "createdAt": "2009-03-07T01:16:38.966Z", "isAdmin": false, "displayName": "dclayh"}, "userId": "E7xnxwP5EPuGiP99X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WMYHEcs5tyFESkjsr/silver-chairs-paternalism-and-akrasia", "pageUrlRelative": "/posts/WMYHEcs5tyFESkjsr/silver-chairs-paternalism-and-akrasia", "linkUrl": "https://www.lesswrong.com/posts/WMYHEcs5tyFESkjsr/silver-chairs-paternalism-and-akrasia", "postedAtFormatted": "Thursday, April 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Silver%20Chairs%2C%20Paternalism%2C%20and%20Akrasia&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASilver%20Chairs%2C%20Paternalism%2C%20and%20Akrasia%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWMYHEcs5tyFESkjsr%2Fsilver-chairs-paternalism-and-akrasia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Silver%20Chairs%2C%20Paternalism%2C%20and%20Akrasia%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWMYHEcs5tyFESkjsr%2Fsilver-chairs-paternalism-and-akrasia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWMYHEcs5tyFESkjsr%2Fsilver-chairs-paternalism-and-akrasia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1036, "htmlBody": "<p><em>Inspired in part by Robin Hanson's <a href=\"http://www.overcomingbias.com/2008/04/paternalism-par.html\">excellent article</a> on paternalism a while back, and in response to <a href=\"/tag/akrasia/\">the various akrasia posts</a>.<br /></em></p>\n<p>In C.S. Lewis's fourth Narnia book, <em>The Silver Chair</em>, the protagonists (two children and a Marsh-wiggle) are faced with a dilemma regarding the title object.&nbsp; To wit, they met an eloquent and quite sane-seeming young man, who after a while reveals that he has a mental disorder: for an hour every night, he loses his mind and must be restrained in the Silver Chair; and if he were to be released during that time he would become a giant, evil snake (it is a fantasy novel, after all).&nbsp; The heroes determine to witness this, and the young man calmly straps himself into the chair.&nbsp; After a few moments, a change comes over him and he begins struggling and begging for release, claiming the <em>other</em> personality is the false one.&nbsp; The children are nonplussed: which person(ality) should they believe?&nbsp; And (a separate question) which should they help?</p>\n<p>In the book this dilemma is resolved by means of a cheat<sup>*</sup>, but we in real life have no such thing.&nbsp; We do, however, have an abundance of Silver Chairs, in the form of psychotropic drugs from alcohol to hallucinogens to fancy antidepressants and antipsychotics. Of course not every person who takes such drugs is in a Silver Chair situation, but consider for instance the alcoholic who insists he doesn't have a problem, or the paranoid schizophrenic who fears that any drug is an attempt to poison him.&nbsp; Now we as observers or authorities may know from statistics or even from their personal histories that the detoxxed/drugged-up versions of these people would be happy for the change and not want to return to the previous state, but does that mean it's right (in a paternalistic sense, meaning for their <em>own</em> good) to force them towards what we call mental health?</p>\n<p>I would say it is not, that our preference for one side of the Silver Chair over the other is simple bias in favor of mental states similar to our own.&nbsp; From our places near normality we can't imagine wanting to be in these bizarre mental states, so we assume that the people who are in them don't <em>really</em> want to be either.&nbsp; They might claim to, sure, but why believe them?&nbsp; After all, they're crazy.&nbsp; For two amusing thought experiments in this line which have been considered in detail by others, let the bizarre mental state in question take the values \"religious belief\", and \"sense of humor\".&nbsp; For a sobering real-world application, consider the fate of homosexuals until a few decades ago. And then think about how, <a href=\"http://www.overcomingbias.com/2009/01/scary-eutopia.html\">as Eliezer has said</a>, the future like the past will be filled with people whose values we would find abhorrent.</p>\n<p><a id=\"more\"></a></p>\n<p>This idea has internal relevance as well.&nbsp; You could easily consider, for instance, the self introspecting at home who wants to lose weight and the self in a restaurant who wants to order cheesecake as two sides of a Silver Chair<sup>**</sup>.&nbsp; And I think that view is more helpful than just calling it \"akrasia\", because it presents the situation as two aspects of your personality which happen to want different things, instead of some \"weakness\" which is interfering with your \"true will\". Then instead of castigating yourself for weakness of will, you merely think \"I suppose my desire for cheesecake was stronger than I anticipated.&nbsp; When I return to a state where my desire to lose weight is dominant, I shall have to make stricter plans.\"</p>\n<p>Again, I see a bias: we think that the desires (and in fact the entire mental state) which we have while, e.g., sitting alone calmly in a quiet room are the \"true\" ones, or even the \"right\" ones in some moral sense, and that feelings or thoughts we have at other times are \"lesser\" or akrasic, simply because at the time when we're introspecting we can't feel the power of those other situations,<sup>&dagger;</sup> and of course we rightly privilege our calm-quiet thinking for its prowess in answering objective questions.&nbsp; We spend (presumably) the bulk of our lives <em>not</em> engaged in quiet introspection, so why should we defer to what our desires are then?</p>\n<p>Of course, one can always say \"When I calmly introspect and plan things in advance, I end up happier/more successful than if I were to give in to my impulses\".&nbsp; To which I would respond \"That's fine.&nbsp; If happiness or success is what you want, and that method is effective, then go for it.\"<sup>&Dagger;</sup>&nbsp; My point is that, just as you shouldn't condemn someone else for not conforming to the desires or thought patterns you think they ought to have, much less <em>force</em> them to conform, neither should you condemn yourself.&nbsp; Your utils come from doing what you want, not being happy or successful, or finding the most efficient way to satisfy as many of your desires as possible, or anything else.</p>\n<p>This idea also seems to have relevance to the topic-which-shall-not-be-named, but I guess this isn't the time for that.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>* Specifically, the chairbound personality invokes the Holy Name of God, which breaks the symmetry. Not a solution many readers of this site would go for, I think.</p>\n<p>** That phrasing is admittedly quite awkward; I guess the two sides would be \"(sitting) in\" and \"out\" of the chair.</p>\n<p>&dagger; I once read that brain scans show that one cannot remember the <em>sensation</em> of sex/orgasms in the same way one can remember other more ordinary sensations.&nbsp; That doesn't jive with my personal experience, but if true I think it gives interesting evidence.&nbsp; A related phenomenon sometimes mentioned by poets (and which I <em>have</em> experienced) is that as you fall in love with someone, you actually find it harder to remember what they look like.</p>\n<p>&Dagger; One can also object that impulsive desires are incoherent: e.g. <a href=\"/lw/6c/akrasia_hyperbolic_discounting_and_picoeconomics/\">hyperbolic discounting</a>.&nbsp; But I would say that incoherence is a property of epistemic systems, i.e. things that must be explained by other things.&nbsp; A desire doesn't need to be explained by anything or agree with anything; it merely is.&nbsp; And paradoxes of wanting both X and !X don't seem to arise (or if they do, you can always kick in some rationality at that point).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GBpwq8cWvaeRoE9X5": 1, "r7qAjcbfhj2256EHH": 1, "gsv9XWbZDcnZmKuqM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WMYHEcs5tyFESkjsr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 34, "extendedScore": null, "score": 5.8e-05, "legacy": true, "legacyId": "356", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["geNZ6ZpfFce5intER"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-09T22:00:13.538Z", "modifiedAt": null, "url": null, "title": "Extreme Rationality: It Could Be Great", "slug": "extreme-rationality-it-could-be-great", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:08.205Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B3b29FJboqnANJRDz/extreme-rationality-it-could-be-great", "pageUrlRelative": "/posts/B3b29FJboqnANJRDz/extreme-rationality-it-could-be-great", "linkUrl": "https://www.lesswrong.com/posts/B3b29FJboqnANJRDz/extreme-rationality-it-could-be-great", "postedAtFormatted": "Thursday, April 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Extreme%20Rationality%3A%20It%20Could%20Be%20Great&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExtreme%20Rationality%3A%20It%20Could%20Be%20Great%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB3b29FJboqnANJRDz%2Fextreme-rationality-it-could-be-great%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Extreme%20Rationality%3A%20It%20Could%20Be%20Great%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB3b29FJboqnANJRDz%2Fextreme-rationality-it-could-be-great", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB3b29FJboqnANJRDz%2Fextreme-rationality-it-could-be-great", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 660, "htmlBody": "<p><strong>Reply to: </strong><a href=\"/lw/9p/extreme_rationality_its_not_that_great/\">Extreme Rationality: It's Not That Great</a></p>\n<p>I considered making this into a comment on Yvain's last post, but I'd like to redirect the discussion slightly. Yvain's warning is important, but we're left with the question of how to turn the current state of the art in rationality into something great. I think we are all on the same page that more is possible. Now we just need to know how to get there.</p>\n<p>Even though Yvain disapproved of Eliezer's recent post on <a href=\"/lw/9c/mandatory_secret_identities/\">day jobs</a>, I thought the two shared a common thread: rationalists should be careful about staying in Far-mode too long. I took Eliezer's point to be more about well-developed rationalist communities, and Yvain's to be about our rag-tag band of aspirants, but I think they are both speaking to the same issue. All of this has to be for a purpose,&nbsp; and we can't become ungrounded.</p>\n<p>Near- and Far-mode have to be balanced. This shouldn't be surprising, because in this context, Near and Far roughly equate to applied and theoretical work. The two intermingle and build off one another. The history of math and physics is filled with paired problems: calculus and dynamics, Fourier series and heat distribution, least-squares and astronomy, etc. Real world problems need theory to be solved, but theory needs problems to motivate and test it.</p>\n<p>My guess is that any large subject develops through the following iterative alteration between Near and Far:</p>\n<p>&nbsp;&nbsp;&nbsp; F1. Develop general theory.<br /> &nbsp;&nbsp;&nbsp; F2. Refine and check for consistency and correctness.<br /> &nbsp;&nbsp;&nbsp; F3. Consolidate theory.<br /> &nbsp;&nbsp;&nbsp; N1. Apply existing theory to problems.<br /> &nbsp;&nbsp;&nbsp; N2. Evaluate successes and failures.<br /> &nbsp;&nbsp;&nbsp; GOTO F1.<a id=\"more\"></a></p>\n<p>This looks like a close relative of our trusty friend, the scientific method, and is similarly idealized. In terms of this process, I think the Less Wrong community is between F2 and F3. We have lots of phrases, techniques, and standard examples laying around, and work has been done on testing them for conceptual soundness. The <a href=\"http://lesswrong.wikia.com\">wiki</a> represents an attempt to begin consolidating this information so we can move onto more applied domains.</p>\n<p>Assuming this process is productive, how long will it take to produce something useful? If Newton invented undergraduate material in math and physics, as is often quipped, I think existing x-rationality theory and techniques are on a JR High level, at best. I'm not surprised x-rationality hasn't produced clear benefits yet. The commonly agreed upon rule of thumb is that it takes about <a href=\"http://en.wikipedia.org/wiki/Expert#Expertise\">10 years or 10,000 hours of practice</a> to become an expert in a subject. X-rationality as a subject is around 30 years old, and OB was only founded in 2006. Most of the current experts should be coming from fields like psychology, game theory, logic, physics, economics, or AI, where the 10,000 hours were acquired indirectly over a career. I think rationality theory will count as a success once someone can acquire PhD level expertise in rationality by age 25 or 30 like in other subjects and can spend a career only on these topics.</p>\n<p>I'd also like to reemphasize the comments of <a href=\"/lw/9p/extreme_rationality_its_not_that_great/6av#comments\">pjeby</a> and <a href=\"/lw/9p/extreme_rationality_its_not_that_great/6ec#comments\">hegemonicon</a>, in conjuction with Yvain, on consciously using x-rationality. I know I need to do more work on integrating OB concepts into my everyday life. I don't think the material referenced in OB isn't going to produce many visible benefits, but I'd bet those concepts will have to come naturally before anything really useful could be learned, much less created. For example, if someone has to consciously think about what the Cartesian plane represents or what a function is, they are going to have a difficult time learning calculus.</p>\n<p>I don't think the current lack of success is of too much worry. This is a long-term project, and I'd be suspicious if breakthroughs came too easily. As long as this community stays grounded, and can move between theory and application, I remain hopeful.</p>\n<p>Is my assessment of x-rationality's long term prospects correct? How does my vision accord with everyone else's?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3QnDqGSdRMA5mdMM6": 1, "Ng8Gice9KNkncxqcj": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B3b29FJboqnANJRDz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 15, "extendedScore": null, "score": 4.867505076701991e-07, "legacy": true, "legacyId": "353", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LgavAYtzFQZKg95WC", "gBewgmzcEiks2XdoQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T00:30:08.149Z", "modifiedAt": null, "url": null, "title": "The uniquely awful example of theism", "slug": "the-uniquely-awful-example-of-theism", "viewCount": null, "lastCommentedAt": "2021-09-13T16:31:56.799Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gjm", "createdAt": "2009-03-09T01:11:32.668Z", "isAdmin": false, "displayName": "gjm"}, "userId": "977L8MR7JmNrQx6df", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dLL6yzZ3WKn8KaSC3/the-uniquely-awful-example-of-theism", "pageUrlRelative": "/posts/dLL6yzZ3WKn8KaSC3/the-uniquely-awful-example-of-theism", "linkUrl": "https://www.lesswrong.com/posts/dLL6yzZ3WKn8KaSC3/the-uniquely-awful-example-of-theism", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20uniquely%20awful%20example%20of%20theism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20uniquely%20awful%20example%20of%20theism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdLL6yzZ3WKn8KaSC3%2Fthe-uniquely-awful-example-of-theism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20uniquely%20awful%20example%20of%20theism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdLL6yzZ3WKn8KaSC3%2Fthe-uniquely-awful-example-of-theism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdLL6yzZ3WKn8KaSC3%2Fthe-uniquely-awful-example-of-theism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 712, "htmlBody": "<p>When an LW contributor is in need of an example of something that (1) is plainly, uncontroversially (here on LW, at least) very wrong but (2) an otherwise reasonable person might get lured into believing by dint of inadequate epistemic hygiene, there seems to be only one example that everyone reaches for: belief in God. (Of course there are different sorts of god-belief, but I don't think that makes it count as more than one example.) Eliezer is particularly fond of this trope, but he's not alone.</p>\n<p>How <em>odd</em> that there should be exactly one example. How convenient that there is one at all! How strange that there isn't more than one!</p>\n<p>In the population at large (even the smarter parts of it) god-belief is sufficiently widespread that using it as a canonical example of irrationality would run the risk of annoying enough of your audience to be counterproductive. Not here, apparently. Perhaps we-here-on-LW are just <em>better reasoners</em> than everyone else ... but then, again, isn't it strange that there aren't a bunch of other popular beliefs that we've all seen through? In the realm of politics or economics, for instance, surely there ought to be some.</p>\n<p>Also: it doesn't seem to me that I'm that a much better thinker than I was a few years ago when (alas) I was a theist; nor does it seem to me that everyone on LW is substantially better at thinking than I am; which makes it hard for me to believe that there's a certain level of rationality that almost everyone here has attained, and that makes theism vanishingly rare.</p>\n<p>I offer the following uncomfortable conjecture: We all <em>want</em> to find (and advertise) things that our superior rationality has freed us from, or kept us free from. (Because the idea that Rationality Just Isn't That Great is disagreeable when one has invested time and/or effort and/or identity in rationality, and because we want to look impressive.) We observe our own atheism, and that everyone else here seems to be an atheist too, and not unnaturally we conclude that we've found such a thing. But in fact (I conjecture) LW is <em>so</em> full of atheists not only because atheism is more rational than theism (note for the avoidance of doubt: yes, I agree that atheism is more rational than theism, at least for people in our epistemic situation) but also because<a id=\"more\"></a></p>\n<ul>\n<li>the readership of LW (and, earlier, of OB) is drawn disproportionately from communities that have long been atheistic (and not just because their members are supremely rational);</li>\n<li>theism has been used so often (here, and earlier on OB) as a canonical example of Wrongness that any theists who might have participated have either deconverted or gone away;</li>\n<li>any theists who remain are keeping quiet about it because they don't want to get jumped on.</li>\n</ul>\n<p>Does any of this matter? I think it might, because</p>\n<ul>\n<li>it would be a shame to fool ourselves into thinking that rationality (or x-rationality) is more powerful than it really is;</li>\n</ul>\n<ul>\n<li>we may be scaring away people who (despite their obstinate clinging to irrational superstitions, etc., etc., etc) would be valuable here. As Eliezer has pointed out a few times, <a title=\"Wikipedia article on Robert Aumann\" href=\"http://en.wikipedia.org/wiki/Robert_Aumann\">Robert Aumann</a> is an Orthodox Jew; whatever mental contortions he may have to go through to maintain that, it seems fairly clear that if he turned up at LW wanting to contribute we would be ill-advised to drive him away. I bet he isn't the only person who manages to remain religious despite knowing a thing or two about rationality;</li>\n</ul>\n<ul>\n<li>we may be annoying and upsetting some readers, which is a (minor) pity in itself;</li>\n</ul>\n<ul>\n<li>perhaps there are other equally good (or better) Awful Examples that we aren't availing ourselves of because the habit of using god-belief for that purpose has become so ingrained.</li>\n</ul>\n<p>So. Is theism <em>really</em> a uniquely awful example? If so, then surely there must be insights aplenty to be had from seeing what makes it so unique. If not, though ... Anyone got any <em>other</em> examples of things just about everyone here has seen the folly of, even though they're widespread among otherwise-smart people? And, if not, what shall we do about it?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dLL6yzZ3WKn8KaSC3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 50, "baseScore": 43, "extendedScore": null, "score": 6.9e-05, "legacy": true, "legacyId": "347", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 176, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T01:58:49.232Z", "modifiedAt": null, "url": null, "title": "Beware of Other-Optimizing", "slug": "beware-of-other-optimizing", "viewCount": null, "lastCommentedAt": "2019-09-15T21:03:33.707Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6NvbSwuSAooQxxf7f/beware-of-other-optimizing", "pageUrlRelative": "/posts/6NvbSwuSAooQxxf7f/beware-of-other-optimizing", "linkUrl": "https://www.lesswrong.com/posts/6NvbSwuSAooQxxf7f/beware-of-other-optimizing", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beware%20of%20Other-Optimizing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeware%20of%20Other-Optimizing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6NvbSwuSAooQxxf7f%2Fbeware-of-other-optimizing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beware%20of%20Other-Optimizing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6NvbSwuSAooQxxf7f%2Fbeware-of-other-optimizing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6NvbSwuSAooQxxf7f%2Fbeware-of-other-optimizing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1515, "htmlBody": "<p>I've noticed a serious problem in which aspiring rationalists vastly overestimate their ability to optimize other people's lives.&nbsp; And I think I have some idea of how the problem arises.</p>\n<p>You read nineteen different webpages advising you about personal improvement&mdash;productivity, dieting, saving money.&nbsp; And the writers all sound bright and enthusiastic about Their Method, they tell tales of how it worked for them and promise <em>amazing</em> results...</p>\n<p>But most of the advice rings so false as to not even seem worth considering.&nbsp; So you sigh, mournfully pondering the wild, childish enthusiasm that people can seem to work up for just about anything, no matter how silly.&nbsp; Pieces of advice #4 and #15 sound interesting, and you try them, but... they don't... quite... well, it fails miserably.&nbsp; The advice was wrong, or you couldn't do it, and either way you're not any better off.</p>\n<p>And then you read the twentieth piece of advice&mdash;or even more, you discover a twentieth method that wasn't in any of the pages&mdash;and STARS ABOVE IT ACTUALLY WORKS THIS TIME.</p>\n<p>At long, long last you have discovered the <em>real</em> way, the <em>right</em> way, the way that actually <em>works.</em>&nbsp; And when someone else gets into the sort of trouble you used to have&mdash;well, this time you <em>know</em> how to help them.&nbsp; You can save them all the trouble of reading through nineteen useless pieces of advice and skip directly to the correct answer.&nbsp; As an aspiring rationalist you've already learned that most people don't listen, and you usually don't bother&mdash;but this person is a friend, someone you know, someone you trust and respect to listen.</p>\n<p>And so you put a comradely hand on their shoulder, look them straight in the eyes, and tell them how to do it.<a id=\"more\"></a></p>\n<p>I, personally, get quite a lot of this.&nbsp; Because you see... when you've discovered the way that <em>really works</em>... well, you know better by now than to run out and tell your friends and family.&nbsp; But you've got to try telling Eliezer Yudkowsky.&nbsp; He <em>needs </em>it, and there's a pretty good chance that <em>he'll</em> understand.</p>\n<p>It actually did take me a while to understand.&nbsp; One of the critical events was when someone on the Board of the Institute Which May Not Be Named, told me that I didn't need a salary increase to keep up with inflation&mdash;because I could be spending substantially less money on food if I used an online coupon service.&nbsp; And I believed this, because it was a friend I trusted, and it was delivered in a tone of such confidence.&nbsp; So my girlfriend started trying to use the service, and a couple of weeks later she gave up.</p>\n<p>Now here's the the thing: if I'd run across exactly the same advice about using coupons on some blog somewhere, I probably wouldn't even have paid much attention, just read it and moved on.&nbsp; Even if it were written by Scott Aaronson or some similar person known to be intelligent, I still would have read it and moved on.&nbsp; But because it was delivered to me personally, by a friend who I knew, my brain processed it differently&mdash;as though I were being told <em>the</em> secret; and that indeed is the tone in which it was told to me.&nbsp; And it was something of a delayed reaction to realize that I'd simply been told, as personal advice, what otherwise would have been just a blog post somewhere; no more and no less likely to work for me, than a productivity blog post written by any other intelligent person.</p>\n<p>And because I have encountered a great many people trying to optimize me, I can attest that the advice I get is as wide-ranging as the productivity blogosphere.&nbsp; But others don't see this plethora of productivity advice as indicating that people are <em>diverse</em> in which advice works for them.&nbsp; Instead they see a lot of obviously wrong poor advice.&nbsp; And then they finally discover the right way&mdash;the way that works, unlike all those other blog posts that don't work&mdash;and then, quite often, they decide to use it to optimize Eliezer Yudkowsky.</p>\n<p>Don't get me wrong.&nbsp; Sometimes the advice is helpful.&nbsp; Sometimes it works.&nbsp; <a href=\"/lw/9o/stuck_in_the_middle_with_bruce/\">\"Stuck In The Middle With Bruce\"</a>&mdash;that resonated, for me.&nbsp; It may prove to be the most helpful thing I've read on the new&nbsp;<em>Less Wrong</em> so far, though that has yet to be determined.</p>\n<p>It's just that your earnest personal advice, that amazing thing you've found to actually work by golly, is no more and no less likely to work for me than a random personal improvement blog post written by an intelligent author is likely to work for you.</p>\n<p>\"Different things work for different people.\"&nbsp; That sentence may give you a squicky feeling; I know it gives me one.&nbsp; Because this sentence is a tool wielded by <a href=\"http://www.overcomingbias.com/2008/10/the-dark-side.html\">Dark Side Epistemology</a> to shield from criticism, used in a way closely akin to \"Different things are true for different people\" (which is simply false).</p>\n<p>But until you grasp the laws that are near-universal generalizations, sometimes you end up messing around with surface tricks that work for one person and not another, without your understanding why, because you don't know the general laws that would dictate what works for who.&nbsp; And the best you can do is remember that, and be willing to take \"No\" for an answer.</p>\n<p>You <em>especially</em> had better be willing to take \"No\" for an answer, if you have <em>power</em> over the Other.&nbsp; Power is, in general, a very dangerous thing, which is tremendously easy to abuse, without your being aware that you're abusing it.&nbsp; There are things you can do to prevent yourself from abusing power, but you have to actually do them or they don't work.&nbsp; There was a post on OB on how being in a position of power has been shown to decrease our ability to empathize with and understand the other, though I can't seem to locate it now.&nbsp; I have seen a rationalist who did not think he had power, and so did not think he needed to be cautious, who was amazed to learn that he might be feared...</p>\n<p>It's even worse when their discovery that works for them, requires a little <em>willpower.</em>&nbsp; Then if you say it doesn't work for you, the answer is clear and obvious: you're just being <em>lazy</em>, and they need to exert some <em>pressure</em> on you to get you to do the <em>correct </em>thing, the advice they've found that actually works.</p>\n<p>Sometimes&mdash;I suppose&mdash;people are being lazy.&nbsp; But be very, very, <em>very</em> careful before you assume that's the case and wield power over others to \"get them moving\".&nbsp; Bosses who can tell when something actually <em>is</em> in your capacity if you're a little more motivated, without it burning you out or making your life incredibly painful&mdash;these are the bosses who are a pleasure to work under.&nbsp; <em>That ability is extremely rare,</em> and the bosses who have it are worth their weight in silver.&nbsp; It's a high-level interpersonal technique that most people do not have.&nbsp; I surely don't have it.&nbsp; Do not assume you have it, because your intentions are good.&nbsp; Do not assume you have it, because you'd never do anything to <em>others </em>that you didn't want done to <em>yourself.</em>&nbsp; Do not assume you have it, because no one has ever complained to you.&nbsp; Maybe they're just scared.&nbsp; That rationalist of whom I spoke&mdash;who did not think he held power and threat, though it was certainly obvious enough to me&mdash;he did not realize that anyone could be scared of him.</p>\n<p>Be careful even when you hold <em>leverage,</em> when you hold an important decision in your hand, or a threat, or something that the other person needs, and all of a sudden the temptation to optimize them seems overwhelming.</p>\n<p>Consider, if you would, that <a href=\"http://www.overcomingbias.com/2007/12/ayn-rand.html\">Ayn Rand</a>'s whole reign of terror over Objectivists can be seen in just this light&mdash;that she found herself with power and leverage, and could not resist the temptation to optimize.</p>\n<p>We underestimate the distance between ourselves and others.&nbsp; Not just <a href=\"http://www.overcomingbias.com/2007/10/inferential-dis.html\">inferential distance</a>, but distances of temperament and ability, distances of situation and resource, distances of unspoken knowledge and unnoticed skills and luck, distances of interior landscape.</p>\n<p>Even I am often surprised to find that X, which worked so well for me, doesn't work for someone else.&nbsp; But with so many others having tried to optimize me, I can at least recognize distance when I'm hit over the head with it.</p>\n<p>Maybe being pushed on does work... for you.&nbsp; Maybe <em>you</em> don't get sick to the stomach when someone with power over you starts helpfully trying to reorganize your life the correct way. &nbsp;I don't know what makes you tick.&nbsp; In the realm of willpower and akrasia and productivity, as in other realms, I don't know the generalizations deep enough to hold almost always.&nbsp; I don't possess the deep keys that would tell me <em>when</em> and <em>why</em> and for <em>who</em> a technique works or doesn't work.&nbsp; All I can do is be willing to accept it, when someone tells me it doesn't work... and go on looking for the deeper generalizations that will hold everywhere, the deeper laws governing both the rule and the exception, waiting to be found, someday.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 4, "vcvfjGJwRmFbMMS3d": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6NvbSwuSAooQxxf7f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 128, "baseScore": 148, "extendedScore": null, "score": 0.000224, "legacy": true, "legacyId": "355", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "practical-advice-backed-by-deep-theories", "canonicalPrevPostSlug": "bayesians-vs-barbarians", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 148, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 119, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FZaDFYbnRoHmde7F6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 12, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T16:16:20.261Z", "modifiedAt": null, "url": null, "title": "How theism works", "slug": "how-theism-works", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:25.738Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/riaLsnntuxkPnWF6H/how-theism-works", "pageUrlRelative": "/posts/riaLsnntuxkPnWF6H/how-theism-works", "linkUrl": "https://www.lesswrong.com/posts/riaLsnntuxkPnWF6H/how-theism-works", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20theism%20works&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20theism%20works%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FriaLsnntuxkPnWF6H%2Fhow-theism-works%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20theism%20works%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FriaLsnntuxkPnWF6H%2Fhow-theism-works", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FriaLsnntuxkPnWF6H%2Fhow-theism-works", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 431, "htmlBody": "<p>There's a reason we can all agree on theism as a good source of examples of irrationality.</p>\n<p>Let's divide the factors that lead to memetic success into two classes: those based on corresponding to evidence, and those detached from evidence. If we imagine a two-dimensional scattergram of memes rated against these two criteria, we can define a frontier of maximum success, along which any idea can only gain in one criterion by losing on the other. This doesn't imply that evidential and non-evidential success are opposed in general; just that whatever shape memespace has, it will have a convex hull that can be drawn across this border.</p>\n<p>Religion is what you get when you push totally for non-evidential memetic success. All ties to reality are essentially cut. As a result, all the other dials can be pushed up to 11. God is not just wise, nice, and powerful - he is all knowing, omnibenificent, and omnipotent. Heaven and Hell are not just pleasant and unpleasant places you can spend a long time in - they are the very best possible and the very worst possible experiences, and for all eternity. Religion doesn't just make people better; it is the sole source of morality. And so on; because all of these things happen \"offstage\", there's no contradictory evidence when you turn the dials up, so of course they'll end up on the highest settings.</p>\n<p>This freedom is theism's defining characteristic. Even the most stupid pseudoscience is to some extent about \"evidence\": people wouldn't believe in it if they didn't think they had evidence for it, though we now understand the cognitive biases and other effects that lead them to think so. That's why there are no homeopathic cures for amputation.</p>\n<p>I agree with other commentators that the drug war is the other real world idea that I would attack here without fear of contradiction, but I would still say that drug prohibition is a model of sanity compared to theism. Theism really is the maddest thing you can believe without being considered mad.</p>\n<p><strong>Footnote:</strong> This was originally a <a href=\"/lw/9n/the_uniquely_awful_example_of_theism/6iz#comments\">comment</a> on <em><a href=\"/lw/9n/the_awful_example_of_theism/\">The uniquely awful example of theism</a></em>, but I was encouraged to make a top-level post from it. I should point out that there are issues with my dividing line between \"evidence-based\" and \"not evidence-based\", since you could argue that mathematics is not evidence-based and nor is the belief that evidence is a good way to learn about the world; however, it should be clear that neither of these has the freedom that religion has to make up whatever will make people most likely to spread the word.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1, "cHoCqtfE9cF7aSs9d": 1, "XYHzLjwYiqpeqaf4c": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "riaLsnntuxkPnWF6H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 64, "baseScore": 56, "extendedScore": null, "score": 8.9e-05, "legacy": true, "legacyId": "363", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 59, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dLL6yzZ3WKn8KaSC3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T17:10:32.945Z", "modifiedAt": null, "url": null, "title": "That Crisis thing seems pretty useful", "slug": "that-crisis-thing-seems-pretty-useful", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:26.683Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TyNtW86j5CSbjQnAT/that-crisis-thing-seems-pretty-useful", "pageUrlRelative": "/posts/TyNtW86j5CSbjQnAT/that-crisis-thing-seems-pretty-useful", "linkUrl": "https://www.lesswrong.com/posts/TyNtW86j5CSbjQnAT/that-crisis-thing-seems-pretty-useful", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20That%20Crisis%20thing%20seems%20pretty%20useful&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThat%20Crisis%20thing%20seems%20pretty%20useful%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyNtW86j5CSbjQnAT%2Fthat-crisis-thing-seems-pretty-useful%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=That%20Crisis%20thing%20seems%20pretty%20useful%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyNtW86j5CSbjQnAT%2Fthat-crisis-thing-seems-pretty-useful", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyNtW86j5CSbjQnAT%2Fthat-crisis-thing-seems-pretty-useful", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 997, "htmlBody": "<p>Since there's been much questioning of late over \"What good is advanced rationality in the real world?\", I'd like to remind everyone that it isn't all about post-doctoral-level reductionism.</p>\n<p>In particular, as a technique that seems like it <em>ought</em> to be useful in the real world, I exhibit the highly advanced, difficult, multi-component <strong><a href=\"http://www.overcomingbias.com/2008/10/got-crisis.html\">Crisis of Faith</a></strong> aka Reacting To The Damn Evidence aka Actually Changing Your Mind.</p>\n<p>Scanning through <a href=\"http://www.overcomingbias.com/2008/10/got-crisis.html\">this post</a> and the list of sub-posts at the bottom (EDIT: copied to below the fold) should certainly qualify it as \"extreme rationality\" or \"advanced rationality\" or \"x-rationality\" or \"Bayescraft\" or whatever you want to distinguish from \"traditional rationality as passed down from Richard Feynman\".</p>\n<p>An actual sit-down-for-an-hour Crisis of Faith might be something you'd only use once or twice in every year or two, but on <em>important</em> occasions.&nbsp; And the <em>components </em>are often things that you could practice day in and day out, also to positive effect.</p>\n<p>I <em>think</em> this is the strongest foot that I could put forward for \"real-world\" uses of my essays.&nbsp; (Anyone care to nominate an alternative?)</p>\n<p>Below the fold, I copy and paste the list of components from the original post, so that we have them at hand:<a id=\"more\"></a></p>\n<ul>\n<li><a href=\"http://www.overcomingbias.com/2007/10/avoiding-your-b.html\">Avoiding Your Belief's Real Weak Points</a> - One of the first temptations in a crisis of faith is to doubt the strongest points of your belief, so that you can <a href=\"http://www.overcomingbias.com/2007/08/one-argument--1.html\">rehearse</a> your good answers.&nbsp; You need to seek out the most painful spots, not the arguments that are most reassuring to consider.</li>\n<li><a href=\"http://www.overcomingbias.com/2007/10/curiosity.html\">The Meditation on Curiosity</a> - Roger Zelazny once distinguished between \"wanting to be an author\" versus \"wanting to write\", and there is likewise a distinction between wanting to have investigated and wanting to investigate.&nbsp; It is not enough to say \"It is my duty to criticize my own beliefs\"; you must be curious, and only uncertainty can create curiosity.&nbsp; Keeping in mind <a href=\"http://www.overcomingbias.com/2007/08/conservation-of.html\">Conservation of Expected Evidence</a> may help you <a href=\"http://www.overcomingbias.com/2007/08/update-yourself.html\">Update Yourself Incrementally</a>:&nbsp; For every <em>single</em> point that you consider, and each element of new argument and new evidence, you should not expect your beliefs to shift more (on average) in one direction than another - thus you can be truly curious each time about how it will go.</li>\n<li><a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">Cached Thoughts</a> and Pirsig's <a href=\"http://www.overcomingbias.com/2007/10/original-seeing.html\">Original Seeing</a>, to prevent standard thoughts from rushing in and completing the pattern.</li>\n<li>The <a href=\"http://www.overcomingbias.com/2007/08/you-can-face-re.html\">Litany of Gendlin</a> and the <a href=\"http://www.overcomingbias.com/2007/10/curiosity.html\">Litany of Tarski</a>:&nbsp; People can stand what is true, for they are already enduring it.&nbsp; If a belief is true you will be better off believing it, and if it is false you will be better off rejecting it.&nbsp; You would advise a religious person to try to visualize fully and deeply the world in which there is no God, and to, without excuses, come to the full understanding that <em>if</em> there is no God <em>then</em> they will be better off believing there is no God.&nbsp; If one cannot come to accept this on a deep emotional level, they will not be able to have a crisis of faith.&nbsp; So you should put in a sincere effort to visualize the <em>alternative</em> to your belief, the way that the best and highest skeptic would want you to visualize it.&nbsp; Think of the effort a religionist would have to put forth to imagine, without corrupting it for their own comfort, an atheist's view of the universe.</li>\n<li><a href=\"http://www.overcomingbias.com/2008/10/isshokenmei.html\">Make an Extraordinary Effort</a>, for the concept of <em>isshokenmei</em>, the desperate convulsive effort to be rational that it would take to surpass the level of Robert Aumann and all the great scientists throughout history who never let go of their religions.</li>\n<li><a href=\"http://www.overcomingbias.com/2008/07/genetic-fallacy.html\">The Genetic Heuristic</a>:&nbsp; You should be extremely suspicious if you have many ideas suggested by a source that you now know to be untrustworthy, but by golly, it seems that all the ideas still ended up being right.&nbsp; (E.g., the one concedes that the Bible was written by human hands, but still clings to the idea that it contains <a href=\"http://www.overcomingbias.com/2007/08/religions-claim.html\">indispensable ethical wisdom</a>.)</li>\n<li><a href=\"http://www.overcomingbias.com/2007/08/the-importance-.html\">The Importance of Saying \"Oops\"</a> - it really is less painful to swallow the entire bitter pill in one terrible gulp.</li>\n<li><a href=\"http://www.overcomingbias.com/2007/10/singlethink.html\">Singlethink</a>, the opposite of doublethink.&nbsp; See the thoughts you flinch away from, that <a href=\"http://www.overcomingbias.com/2007/10/singlethink.html\">appear in the corner of your mind for just a moment </a>before you refuse to think them.&nbsp; If you become aware of what you are not thinking, you can think it.</li>\n<li><a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">Affective Death Spirals</a> and <a href=\"http://www.overcomingbias.com/2007/12/resist-the-happ.html\">Resist the Happy Death Spiral</a>.&nbsp; Affective death spirals are prime generators of false beliefs that it will take a Crisis of Faith to shake loose.&nbsp; But since affective death spirals can also get started around real things that are genuinely nice, you don't have to admit that your belief is a lie, to try and resist the halo effect at every point - refuse false praise even of genuinely nice things.&nbsp; <a href=\"http://www.overcomingbias.com/2007/03/policy_debates_.html\">Policy debates should not appear one-sided</a>.</li>\n<li><a href=\"http://www.overcomingbias.com/2007/10/hold-off-solvin.html\">Hold Off On Proposing Solutions</a> until the problem has been discussed as thoroughly as possible without proposing any; make your mind <a href=\"http://www.overcomingbias.com/2007/10/we-change-our-m.html\">hold off from knowing what its answer will be</a>; and <a href=\"http://www.overcomingbias.com/2008/10/use-the-try-har.html\">try for five minutes before giving up</a>, both generally, and especially when pursuing the devil's point of view.</li>\n<li>The sequence on <a href=\"http://www.overcomingbias.com/2007/09/the-bottom-line.html\">The Bottom Line</a> and <a href=\"http://www.overcomingbias.com/2007/09/rationalization.html\">Rationalization</a>, which explains why it is always wrong to selectively argue one side of a debate.</li>\n<li><a href=\"http://www.overcomingbias.com/2007/08/positive-bias-l.html\">Positive Bias</a> and <a href=\"http://www.overcomingbias.com/2007/04/knowing_about_b.html\">motivated skepticism</a> and <a href=\"http://www.overcomingbias.com/2007/10/motivated-stopp.html\">motivated stopping</a>, lest you selectively look for support, selectively look for counter-counterarguments, and selectively stop the argument before it gets dangerous.&nbsp; <a href=\"http://www.overcomingbias.com/2007/05/the_third_alter.html\">Missing alternatives</a> are a special case of stopping.&nbsp; A special case of motivated skepticism is <a href=\"http://www.overcomingbias.com/2006/12/the_proper_use_.html\">fake humility</a> where you bashfully confess that <a href=\"http://www.overcomingbias.com/2007/10/no-one-knows-wh.html\">no one can know</a> something you would rather not know.&nbsp; Don't selectively demand <a href=\"http://www.overcomingbias.com/2008/01/absolute-author.html\">too much authority</a> of counterarguments.</li>\n<li>Beware of <a href=\"http://www.overcomingbias.com/2007/08/semantic-stopsi.html\">Semantic Stopsigns</a>, <a href=\"http://www.overcomingbias.com/2007/09/applause-lights.html\">Applause Lights</a>, and the choice to&nbsp; <a href=\"http://www.overcomingbias.com/2007/09/explainworshipi.html\"><span style=\"text-decoration: underline;\">E</span>xplain/<span style=\"text-decoration: underline;\">W</span>orship/<span style=\"text-decoration: underline;\">I</span>gnore</a>.</li>\n<li>Feel the weight of <a href=\"http://www.overcomingbias.com/2007/09/burdensome-deta.html\">Burdensome Details</a>; each detail a separate burden, a point of crisis.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mQbxDKHxPcKKRG4mb": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TyNtW86j5CSbjQnAT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 16, "extendedScore": null, "score": 4.869194541997691e-07, "legacy": true, "legacyId": "364", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T20:08:45.734Z", "modifiedAt": null, "url": null, "title": "Spay or Neuter Your Irrationalities", "slug": "spay-or-neuter-your-irrationalities", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:25.216Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gt4D8WXp96Aq8knCW/spay-or-neuter-your-irrationalities", "pageUrlRelative": "/posts/gt4D8WXp96Aq8knCW/spay-or-neuter-your-irrationalities", "linkUrl": "https://www.lesswrong.com/posts/gt4D8WXp96Aq8knCW/spay-or-neuter-your-irrationalities", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Spay%20or%20Neuter%20Your%20Irrationalities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpay%20or%20Neuter%20Your%20Irrationalities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgt4D8WXp96Aq8knCW%2Fspay-or-neuter-your-irrationalities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Spay%20or%20Neuter%20Your%20Irrationalities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgt4D8WXp96Aq8knCW%2Fspay-or-neuter-your-irrationalities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgt4D8WXp96Aq8knCW%2Fspay-or-neuter-your-irrationalities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 510, "htmlBody": "<p>No human person has, so far as I am aware, managed to eradicate all irrationalities from their thinking.&nbsp; They are unavoidable, and this is particularly distressing when the irrationalities are lurking in your brain like rats in the walls and you don't know what they are.&nbsp; Of course you don't know what they are - they are irrationalities, and you are a rationalist, so if you had identified them, they would be dying (quickly or slowly, but dying).&nbsp; It's only natural for someone committed to rationality to want to indiscriminately exterminate the threats to the unattainable goal.<br /><br />But are they all worth getting rid of?<br /><br />It is my opinion that they are not: some irrationalities are small and cute and neutered, and can be confined and kept where you can see them, like pet gerbils instead of rats in the walls.<br /><br />I'll give you an example: I use iTunes for my music organization and listening.&nbsp; iTunes automatically records the number of times I have listened to each song and displays it.&nbsp; Within a given playlist, I irrationally believe that all of these numbers have to match: if I have listened to the theme from The Phantom of the Opera exactly fifty-two times, I have to also have listened to \"The Music of the Night\" exactly fifty-two times, no matter how much I want to listen to the theme on repeat all afternoon.<br /><br />Does this make any sense?&nbsp; No, of course not, but it isn't worth my time to get rid of it.&nbsp; It is small - it affects only a tiny corner of my life, and if it starts to get in the way of my musical preferences, I can cheat it by resetting play counts or fast-forwarding through songs (like I could get around the chore of feeding a gerbil with an automatic food dispenser).&nbsp; It is \"cute\" - I can use it as a conversation starter and people generally find it a mildly entertaining quirk, not evidence that I need psychiatric help.&nbsp; I have it metaphorically neutered - since I make no effort to suppress it, I'm able to recognize the various emotional reactions that satsifying or frustrating this irrational preference creates, and I would notice them if they cropped up anywhere else, where I would deal with them appropriately.&nbsp; I also don't encourage it to memetically spread to others.&nbsp; I keep it where I can see it - I make note of when I take actions to satisfy my irrational preference, and acknowledge in so doing that it's my reason and my reason doesn't make much sense.<br /><br />In short, I treat it like a pet.&nbsp; If it started being more trouble than it would be to root it out of my brain, I'd go through the necessary desensitization, just as I would get rid of a pet gerbil that bit me or kept me up at night even if this meant two hours each way on the bus to the Humane Society.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "5Whwix4cZ3p5otshm": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gt4D8WXp96Aq8knCW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 3, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "370", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T20:30:15.899Z", "modifiedAt": "2021-08-12T19:34:32.624Z", "url": null, "title": "The Unfinished Mystery of the Shangri-La Diet", "slug": "the-unfinished-mystery-of-the-shangri-la-diet", "viewCount": null, "lastCommentedAt": "2019-08-28T06:01:57.427Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BD4oExxQguTgpESdm/the-unfinished-mystery-of-the-shangri-la-diet", "pageUrlRelative": "/posts/BD4oExxQguTgpESdm/the-unfinished-mystery-of-the-shangri-la-diet", "linkUrl": "https://www.lesswrong.com/posts/BD4oExxQguTgpESdm/the-unfinished-mystery-of-the-shangri-la-diet", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Unfinished%20Mystery%20of%20the%20Shangri-La%20Diet&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Unfinished%20Mystery%20of%20the%20Shangri-La%20Diet%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBD4oExxQguTgpESdm%2Fthe-unfinished-mystery-of-the-shangri-la-diet%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Unfinished%20Mystery%20of%20the%20Shangri-La%20Diet%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBD4oExxQguTgpESdm%2Fthe-unfinished-mystery-of-the-shangri-la-diet", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBD4oExxQguTgpESdm%2Fthe-unfinished-mystery-of-the-shangri-la-diet", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1467, "htmlBody": "<p><strong>Followup to</strong>:&nbsp; <a href=\"/lw/9v/beware_of_otheroptimizing/\">Beware of Other-Optimizing</a></p>\n<p>Once upon a time, <a href=\"http://sethroberts.net/\">Seth Roberts</a> (a professor of psychology at Berkeley, on the editorial board of <em>Nutrition</em>) noticed that he'd started losing weight while on vacation in Europe.&nbsp; For no apparent reason, he'd stopped <em>wanting </em>to eat.</p>\n<p>Some time later, <em>The Shangri-La Diet</em> swept... the econoblogosphere, anyway.&nbsp; People including some respectable economists tried it, found that it actually seemed to <em>work,</em> and told their friends.</p>\n<p>The Shangri-La Diet is unfortunately named - I would have called it \"the set-point diet\".&nbsp; And even worse, the actual <em>procedure</em> sounds like the wackiest fad diet imaginable:</p>\n<p>Just drink two tablespoons of extra-light olive oil early in the morning... don't eat anything else for at least an hour afterward... and in a few days <em>it will no longer take willpower to eat less;</em> you'll feel so full all the time, you'll have to <em>remind</em> yourself to eat.</p>\n<p>Why?&nbsp; I'm tempted to say \"No one knows\" just to see what kind of comments would show up, but that would be cheating.&nbsp; Roberts does have <a href=\"http://sethroberts.net/science/index.html\">a theory motivating the diet</a>, an elegant combination of pieces individually backed by previous experiments:</p>\n<ul>\n<li>Your metabolism has a <em>set point,</em> like the setting on a thermostat: when your weight is below the set point, you feel hungry; when your weight is above the set point, you feel full.</li>\n<li>But the set point is not a constant; it is raised and lowered by what you eat.</li>\n<li>This mechanism in turn seems to be regulated by a <em>flavor-calorie</em> association.&nbsp; (Possibly as a famine-storage mechanism that tries to store more resources when dense food sources are available.)&nbsp; If you eat something with flavor X, which is followed by your metabolism detecting a large source of calories, flavor X will (a) seem more appealing and taste better, and (b) will <em>raise your set point </em>whenever you eat items with flavor X.</li>\n<li>Your set point is always naturally dropping, but is raised by eating; usually these forces are in dynamic balance and your weight stays constant.</li>\n</ul>\n<p>I'm not going to go into all the <a href=\"http://sethroberts.net/about/whatmakesfoodfattening.pdf\">existing evidence</a> that backs up each step of this theory, but the theory is very beautiful and elegant.&nbsp; The actual Shangri-La Diet is painfully simple by comparison: consume nearly tasteless extra-light olive oil, being careful <em>not</em> to associate it with any flavors before or after, to raise your body weight a little <em>without</em> raising your set point.&nbsp; Your body weight goes above your set point, and you stop feeling hungry.&nbsp; Then you eat less... and your weight drops... and your set point drops a little <em>less </em>than that... but then next morning it's time for your next dose of extra-light olive oil, which once again puts your (decreased) weight a bit above the set point.&nbsp; The regular dose of almost flavorless calories tilts the dynamic balance downward.&nbsp; That's the <em>theory</em>.</p>\n<p><a href=\"http://boards.sethroberts.net/\">Many people</a>, including some trustworthy <a href=\"http://sethroberts.net/blogosphere/index.html\">econblogger types</a>, have reported losing 1-2 pounds/week by implementing the actual actions of the Shangri-La Diet, up to 30 pounds or even more in some cases.&nbsp; <em>Without expending willpower.</em></p>\n<p>I tried it.&nbsp; It didn't work for me.<a id=\"more\"></a></p>\n<p>Now here's the frustrating thing:&nbsp; The Shangri-La Diet does not contain an obvious exception for Eliezer Yudkowsky.&nbsp; On the theory as stated, it should just work.&nbsp; But I am not the only person who reports trying this diet (and a couple of variations that Roberts recommended) without anything happening, except possibly some weight gain due to the added calories.</p>\n<p>And here's the more frustrating thing:&nbsp; Roberts's explanation <em>felt </em>right.&nbsp; It's one of those insights that you grasp and then so much else snaps into place.</p>\n<p>It explained that frustrating experience I'd often had, wherein I would try a new food and it would fill me up for a whole day - and then, as I kept on eating this amazing food in an effort to keep my total intake down, the satiation effect would go away.</p>\n<p>It explained why I'd lost on the order of 50-60 pounds - with what, in retrospect, was very little effort - when I first moved out of my parents' house and to a new city and <em>started eating non-Jewish food.</em>&nbsp; In retrospect, I was eating an <em>amazingly</em> little amount each day, like 1200 calories, but without any feeling of hunger.&nbsp; And then my weight slowly started creeping up again, and no amount of exercise - to which (ha!) I'd originally attributed the weight loss - seemed able to stop it.</p>\n<p>It's always hard to pick reality out of the gigantic morass of competing dietary theories.&nbsp; One of the elegant charms of Robert's hypothesis is that it helps <em>explain</em> why this is so - the mess of incoherent results.&nbsp; <em>Any</em> new diet will seem to work for a few months or weeks, you're losing weight and everything seems wonderful, you tell all your friends and they buy the same diet book, and then <em>bam</em> the flavor-calorie association kicks back in and you're back to hell.&nbsp; The number-one result of weight-loss science is that 95% of people who lose weight regain it.</p>\n<p>(I haven't heard any complaints from people regaining weight they lost on the Shangri-La Diet, however - if it works for you at all, it seems to go on working.&nbsp; Most of the complaints on the forums are from people who suddenly plateau after losing 30 pounds, but who want to lose more.&nbsp; Or people like me, who try it, and find that it doesn't seem to do anything, or that we're gaining weight with no apparent loss of appetite.)</p>\n<p>I have a pretty strong feeling - I don't know if I should trust it, since I'm not a dietary scientist - that Roberts's hypothesis is at least <em>partially</em> right.&nbsp; It makes a <em>lot </em>of data snap into focus.&nbsp; The pieces are well-supported individually.</p>\n<p>But I don't think that Roberts has the whole story.&nbsp; There's something missing - something that would explain why the Shangri-La Diet lets some people control their weight as easily as a thermostat setting, and why others lose 30 pounds and then plateau well short of their goal, and why others simply find the Shangri-La diet ineffective.&nbsp; The Mystery of Shangri-La is not how the diet works when it <em>does</em> work; Roberts has made an excellent case for <em>that</em>.&nbsp; The question is why it sometimes <em>doesn't</em> work.&nbsp; There is a deeper law, I strongly suspect, that governs <em>both the rule and the exception</em>.</p>\n<p>The problem is, though - and here's the <em>really</em> frustrating part - Roberts seems to think he <em>does</em> have the whole answer.&nbsp; If the diet doesn't work at first, his answer is to try more oil... which is a pretty scary answer if you're already gaining weight from the extra calorie intake!&nbsp; I decided not to go down this route because it didn't seem to work for the people on the forums who were reporting that the Shangri-La Diet didn't work for them.&nbsp; They just gained even more weight.</p>\n<p>And what really makes this a catastrophe is that <em>this theory has never been analyzed by controlled experiment, which drives me up the frickin' WALL.</em>&nbsp; Roberts himself is a big advocate of \"self-experimentation\", which I suppose explains why he's not pushing harder for testing.&nbsp; (Though it's not like Roberts is a standard pseudoscientist, he's an academic in good standing.)&nbsp; But with reports of such drastic success from so many observers, some of them reliable, outside dietary scientists ought to be studying this.&nbsp; <em>What the fsck, dietary scientists?&nbsp; Get off your butts and study this thing!&nbsp; NOW!&nbsp; </em>Report these huge results in a peer-reviewed journal so that everyone gets excited and starts studying the <em>exceptions</em> to the rule!</p>\n<p>It's awful; it seems like Roberts has gotten <em>so close</em> to burying the scourge Obesity, but the theory is still missing some final element, some completing piece that would explain the rule <em>and</em> the exception, and with that last piece it might be possible to make the diet work for <em>everyone...</em></p>\n<p>If we had a large-sized rationalist community going that had solved <a href=\"/lw/5j/your_price_for_joining/\">the group effort coordination problem</a>, those of us who are metabolically disprivileged would be pooling resources and launching our own controlled study of this thing, and entering every conceivable variable we could report into the matrix, and hiring a professional biochemist to analyze our metabolisms before and afterward, and we would <em>cryopreserve </em>anyone who got in our way.&nbsp; You have <em>no idea.</em></p>\n<p>(Warning:&nbsp; Do not try the Shangri-La diet at home based on only the info here, there's a couple of caveats and I can't think offhand of a good complete description on the 'Net.&nbsp; Also you might want to reconsider the recommendation to use fructose in the sugar water route, because IIRC fructose has been shown to contribute to insulin resistance or something like that - sucrose may actually make more sense, despite the higher glycemic index.)</p>\n<p><strong>Continued in</strong>:&nbsp; <a href=\"/lw/ab/akrasia_and_shangrila/\">Akrasia and Shangri-La</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XqykXFKL9t38pbSEm": 1, "fkABsGCJZ6y9qConW": 1, "92SxJsDZ78ApAGq72": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BD4oExxQguTgpESdm", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 43, "extendedScore": null, "score": 7.2e-05, "legacy": true, "legacyId": "366", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 231, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6NvbSwuSAooQxxf7f", "Q8evewZW5SeidLdbA", "geqg9mk73NQh6uieE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-10T20:30:15.899Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T20:53:14.746Z", "modifiedAt": null, "url": null, "title": "Akrasia and Shangri-La", "slug": "akrasia-and-shangri-la", "viewCount": null, "lastCommentedAt": "2019-04-15T06:19:58.256Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/geqg9mk73NQh6uieE/akrasia-and-shangri-la", "pageUrlRelative": "/posts/geqg9mk73NQh6uieE/akrasia-and-shangri-la", "linkUrl": "https://www.lesswrong.com/posts/geqg9mk73NQh6uieE/akrasia-and-shangri-la", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Akrasia%20and%20Shangri-La&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAkrasia%20and%20Shangri-La%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgeqg9mk73NQh6uieE%2Fakrasia-and-shangri-la%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Akrasia%20and%20Shangri-La%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgeqg9mk73NQh6uieE%2Fakrasia-and-shangri-la", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgeqg9mk73NQh6uieE%2Fakrasia-and-shangri-la", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 666, "htmlBody": "<p><strong>Continuation of</strong>:&nbsp; <a href=\"/lw/a6/the_unfinished_mystery_of_the_shangrila_diet/\">The Unfinished Mystery of the Shangri-La Diet</a></p>\n<p><a href=\"/lw/a6/the_unfinished_mystery_of_the_shangrila_diet/\">My post about the Shangri-La Diet</a> is there to make a point about akrasia.&nbsp; <a href=\"/lw/9v/beware_of_otheroptimizing/\">It's not just an excuse: people really <em>are</em> different</a> and what works for one person sometimes <em>doesn't</em> work for another.</p>\n<p>You can never be sure in the realm of the mind... but out in material foodland, I know that I was, in fact, drinking extra-light olive oil in the fashion prescribed.&nbsp; There is no reason <em>within </em>Roberts's theory why it shouldn't have worked.</p>\n<p>Which just means Roberts's theory is incomplete.&nbsp; In the complicated mess that is the human metabolism there is something <em>else</em> that needs to be considered.&nbsp; (My guess would be \"something to do with insulin\".)</p>\n<p>But if the <em>actions</em> needed to implement the Shangri-La Diet weren't so simple and verifiable... if some of them took place within the mind... if it took, not a metabolic trick, but <em>willpower</em> to get to that amazing state where dieting comes effortlessly and you can lose 30 pounds...</p>\n<p>Then when the Shangri-La Diet didn't work, we unfortunate exceptions would get yelled at for doing it wrong and not having enough <em>willpower.</em>&nbsp; Roberts already seems to think that his diet ought to work for everyone; when someone says it's not working, Roberts tells them to drink more extra-light olive oil or try a slightly different variant of the diet, rather than saying, \"This doesn't work for some people and I don't know why.\"</p>\n<p>If the failure had occurred somewhere inside the dark recesses of my mind where it could be blamed on <em>me,</em> rather than within my metabolism...<a id=\"more\"></a></p>\n<p>If Roberts's hypothesis is correct, then I'm sure that plenty of people have made some dietary change, started losing weight due to the disrupted flavor-calorie association, and congratulated themselves on their wonderful <em>willpower</em> for eating less<em>.</em>&nbsp; When I moved out of my parents' home and started eating less and exercising and losing more than a pound a week, you can bet I was congratulating myself on my amazing <em>willpower</em>.</p>\n<p>Hah.&nbsp; No, I just stumbled onto a metabolic pot of gold that let me lose a lot of weight using a sustainable expenditure of willpower.&nbsp; When that pot of gold was exhausted, willpower ceased to avail.</p>\n<p>(The metabolically privileged don't believe in metabolic privilege, since <em>they </em>are able to lose weight by trying! harder! to diet and exercise, and the diet and exercise actually work the way they're supposed to... I remember the nine-month period in my life where <em>that </em>was true.)</p>\n<p>When I look at the current state of the art in fighting akrasia, I see the same sort of mess.</p>\n<p>People try all sorts of crazy things&mdash;and as in dieting, there's secretly a general reason why <em>any</em> crazy thing might seem to work: if you expect to win an internal conflict, you've already programmed yourself to do the right thing because you expect that to be your action; it takes less willpower to win an internal conflict you expect to win.</p>\n<p>And people make up all sorts of fantastic stories to <em>explain why </em>their tricks worked for them.</p>\n<p>But their tricks don't work for everyone&mdash;some others report success, some don't.&nbsp; The inventors do not know the deep generalizations that would tell them <em>why and who</em>, explain the rule <em>and </em>the exception.&nbsp; But the stories the inventors have created to explain their own successes, naturally praise their own willpower and other virtues, and contain no element of luck... and so they exhort others:&nbsp; <em>Try harder!&nbsp; You're doing it wrong!</em></p>\n<p>There <em>is </em>a place in the mind for willpower.&nbsp; Don't get me wrong, it's useful stuff.&nbsp; But people who assign their successes to willpower&mdash;who congratulate themselves on their stern characters&mdash;may be a tad reluctant to appreciate just how much you can be privileged or disprivileged by having a mental metabolism where expending willpower is <em>effective</em>, where you can achieve encouraging results, at an acceptable cost to yourself, and sustain the effort in the long run.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/9m/collective_apathy_and_the_internet/\">Collective Apathy and the Internet</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/9v/beware_of_otheroptimizing/\">Beware of Other-Optimizing</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"r7qAjcbfhj2256EHH": 1, "YrLoz567b553YouZ2": 1, "XqykXFKL9t38pbSEm": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "geqg9mk73NQh6uieE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 46, "baseScore": 48, "extendedScore": null, "score": 7.5e-05, "legacy": true, "legacyId": "371", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 97, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BD4oExxQguTgpESdm", "6NvbSwuSAooQxxf7f", "YdcF6WbBmJhaaDqoD", "NnQbfLo868wgnHF4n"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T21:09:21.105Z", "modifiedAt": null, "url": null, "title": "Maybe Theism Is OK ", "slug": "maybe-theism-is-ok", "viewCount": null, "lastCommentedAt": "2017-06-17T03:56:27.876Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "byrnema", "createdAt": "2009-03-20T18:02:38.305Z", "isAdmin": false, "displayName": "byrnema"}, "userId": "SCnD6W8NiztYBN39M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JRt4qrbbpgEW5LBWG/maybe-theism-is-ok", "pageUrlRelative": "/posts/JRt4qrbbpgEW5LBWG/maybe-theism-is-ok", "linkUrl": "https://www.lesswrong.com/posts/JRt4qrbbpgEW5LBWG/maybe-theism-is-ok", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Maybe%20Theism%20Is%20OK%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaybe%20Theism%20Is%20OK%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJRt4qrbbpgEW5LBWG%2Fmaybe-theism-is-ok%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Maybe%20Theism%20Is%20OK%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJRt4qrbbpgEW5LBWG%2Fmaybe-theism-is-ok", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJRt4qrbbpgEW5LBWG%2Fmaybe-theism-is-ok", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 201, "htmlBody": "<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> </w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" LatentStyleCount=\"156\"> </w:LatentStyles> </xml><![endif]--> I would like to argue that there could be a more tolerant view of religion/theism here on Less Wrong. The extent to which theism is vilified here seems disproportionate to me.</p>\n<p class=\"MsoNormal\">It depends on the specific scenario how terrible religion is. It is easy to look at the very worst examples of religion and conclude that religion <em>can be</em> irrational in a terribly wrong way. However, religion can also be nearly rational. Considering that any way we view the world is an illusion to some extent. Indeed the whole point of this site is to learn ways to shed <em>more</em> of our illusions, not that we have <em>no</em> illusions.</p>\n<p class=\"MsoNormal\">There are the religious beliefs that contradict empirical observation and those that are independent of it...</p>\n<p class=\"MsoNormal\">A) Could it be rational for a person to hold beliefs that are independent of empirical observation if (a) the person concedes that they are <del>irrational</del> <span style=\"color: #ff0000;\">not empirically based</span> and (b) is willing to drop them if they prove to not be useful?</p>\n<p class=\"MsoNormal\">B) Could it be rational for a person to hold unusual beliefs as a result of contradicting empirical observations?</p>\n<p class=\"MsoNormal\">As a least convenient world exercise, what is the most rational belief in God that you can think of?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JRt4qrbbpgEW5LBWG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -2, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "373", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T23:41:52.946Z", "modifiedAt": null, "url": null, "title": "Metauncertainty", "slug": "metauncertainty", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:25.444Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimmy", "createdAt": "2009-02-27T18:23:27.410Z", "isAdmin": false, "displayName": "jimmy"}, "userId": "JKdbpXHkv9AsuazJ3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LKHJ2Askf92RBbhBp/metauncertainty", "pageUrlRelative": "/posts/LKHJ2Askf92RBbhBp/metauncertainty", "linkUrl": "https://www.lesswrong.com/posts/LKHJ2Askf92RBbhBp/metauncertainty", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Metauncertainty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMetauncertainty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKHJ2Askf92RBbhBp%2Fmetauncertainty%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Metauncertainty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKHJ2Askf92RBbhBp%2Fmetauncertainty", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKHJ2Askf92RBbhBp%2Fmetauncertainty", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 580, "htmlBody": "<p><strong>Response to:</strong> <a href=\"http://www.overcomingbias.com/2008/07/when-not-to-use.html\">When (Not) To Use Probabilities </a><br /><br />&ldquo;It appears to be a quite general principle that, whenever there is a randomized way of doing something, then there is a nonrandomized way that delivers better performance but requires more thought.&rdquo; &mdash;E. T. Jaynes<br /><br />The uncertainty due to vague (non math) language is no different than uncertainty by way of \"randomizing\" something (after all, <a href=\"http://www.overcomingbias.com/2008/03/mind-probabilit.html\">probability is in the mind</a>). The principle still holds; you should be able to come up with a better way of doing things if you can put in the extra thought.<br /><br />In some cases, you can't afford to waste time or it's not worth the thought, but when dealing with things such as the deciding whether to run the LHC or signing up for cryonics, there's time, and it's sorta a big deal, so it pays to do it right.<br /><br /><br />If you're asked \"how likely is X?\", you can answer \"very unlikely\" or \"0.127%\". The latter may give the impression that the probability is known more precisely than it is, but the first is too vague; both strategies do poorly on the <a href=\"http://yudkowsky.net/rational/technical\">log score</a>.<br /><br />If you are unsure what probability to state, state this with... another probability distribution.</p>\n<p><a id=\"more\"></a>\"My probability distribution over probabilities is an exponential with a mean of 0.127%\" isn't vague, it isn't overconfident (at the meta^1 level), and gives you numbers to actually bet on.<br /><br />The expectation value of the metaprobability distribution (integral from 0 to 1 of Pmeta*p*dp) is equal to the probability you give when trying to maximize your expected log score . <br /><br />To see this, we write out the expected log score (Integral from 0 to 1 of Pmeta*(p*log(q)+(1-p)log(1-q))dp). If you split this into two integrals and pull out the terms that are independent of p, the integrals just turn into the expectation value of p, and the formula is now that of the log score with p replaced with mean(p). We already know that the log score is maximized when q = p, so in this case we set q = mean(p)<br /><br />This is a very useful result when dealing with extremes where we are not well calibrated. Instead of punting and saying \"err... prolly aint gonna happen\", put a probability distribution on your probability distribution and take the mean. For example, if you think X is true, but you don't know if you're 99% sure or 99.999% sure, you've got to bet at ~99.5%. <br /><br />It is still no guarantee that you'll be right 99.5% of times (by assumption we're not calibrated!), but you can't do any better given your metaprobability distribution.<br />&nbsp;<br />You're not saying \"99.5% of the time I'm this confident, I'm right\". You're just saying \"I expect my log score to be maximized if I bet on 99.5%\". The former implies the latter, but the latter does not (necessarily) imply the former.<br /><br />This method is much more informative than \"almost sure\", and gives you numbers to act on when it comes time to \"shut up and multiply\". Your first set of numbers may not have \"come from numbers\", but the ones you quote now do, which is an improvement. Theoretically this could be taken up a few steps of meta, but once is probably enough.</p>\n<p>Note: <a href=\"/lw/3j/rationality_cryonics_and_pascals_wager/69t#comments\">Anna Salamon's comment</a> makes this same point. &nbsp;&nbsp;&nbsp; <a href=\"/lw/3j/rationality_cryonics_and_pascals_wager/69t#comments\"><br /></a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JHYaBGQuuKHdwnrAK": 1, "6nS8oYmSMuFMaiowF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LKHJ2Askf92RBbhBp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 26, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "357", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-10T23:48:35.000Z", "modifiedAt": null, "url": null, "title": "Is masochism necessary?", "slug": "is-masochism-necessary", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:25.935Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mCQf5FCXjwTBeLC6u/is-masochism-necessary", "pageUrlRelative": "/posts/mCQf5FCXjwTBeLC6u/is-masochism-necessary", "linkUrl": "https://www.lesswrong.com/posts/mCQf5FCXjwTBeLC6u/is-masochism-necessary", "postedAtFormatted": "Friday, April 10th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20masochism%20necessary%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20masochism%20necessary%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmCQf5FCXjwTBeLC6u%2Fis-masochism-necessary%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20masochism%20necessary%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmCQf5FCXjwTBeLC6u%2Fis-masochism-necessary", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmCQf5FCXjwTBeLC6u%2Fis-masochism-necessary", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 549, "htmlBody": "<p>Followup to <a href=\"/lw/9o/stuck_in_the_middle_with_bruce/\">Stuck in the middle with Bruce</a>:</p>\n<p>Bruce is a description of <a href=\"http://en.wikipedia.org/wiki/Self-defeating_personality_disorder\">masochistic personality disorder</a>.&nbsp; Bruce's dysfunctional behavior may or may not be related to <a href=\"http://en.wikipedia.org/wiki/Sadism_and_masochism_as_medical_terms\">sexual masochism</a> [safe for work], which is demonized by most people in America.&nbsp; Yet there are ordinary, socially-accepted behaviors that seem partly masochistic to me:</p>\n<ul>\n<li>Eating spicy food</li>\n<li>Listening to the music of Anton Webern or Alban Berg (not trying to be funny; this is very serious)</li>\n<li>Listening to music turned up so loud that it hurts</li>\n<li>Fiction</li>\n<li>Movies, especially horror movies</li>\n<li>Roller coasters</li>\n<li>Saunas</li>\n<li>Enjoying exercise</li>\n<li>Being Bruce</li>\n</ul>\n<p>Question 1: Can you list more?</p>\n<p>Question 2: Doubtless some of the behaviors I listed have completely different explanations, some of which might not involve masochism at all.&nbsp; Which do you think involve enjoying pain?&nbsp; Can you cluster them by causal mechanism?</p>\n<p>Question 3: When we find ourselves acting masochistically, should we try to \"correct\" it?&nbsp; Or is it part of a healthy human's nature?&nbsp; If so, what's the evolutionary-psych explanation?&nbsp; (I was surprised not to find any evo-psych explanations for masochism on the web; or even any general theory of masochism that tried to unite two different behaviors.&nbsp; All I found were the ideas that sexual masochism is caused by bad childhood models of love, and that masochistic personality is caused by other, unspecified bad experiences.&nbsp; No suggestion that masochism is part of our normal pleasure mechanism.)</p>\n<p>Some hypotheses:</p>\n<ol>\n<li>Evolution implemented \"need to explore\" (in the \"exploration/exploitation\" sense) as pleasure in new experiences, and adaptation to any particular often-repeated stimulus.&nbsp; This could result in seeking ever-higher levels of stimulation, even above the pain threshold.&nbsp; (This could affect a culture as well as an organism, giving the progression Vivaldi -&gt; Bach -&gt; Mozart -&gt; Beethoven -&gt; Wagner -&gt; Stravinsky -&gt; Berg -&gt; screw it, let's invent rock and roll and start over.&nbsp; My original belief was that this progression was caused by people trying to signal sophistication, rather than by honest enjoyment of music.&nbsp; But maybe some people &lt;DELETION of \"jaded\"&gt; honestly enjoy Berg.)</li>\n<li>We have a \"pain thermostat\" to get us to explore / prevent us from being too cowardly, and modern life leaves us below our set point.&nbsp; (Is masochism more prevalent now than in the bad old days?)<ol>\n<li>An objection to this is that sometimes, when people are in emotional pain, they work through it by throwing themselves into further emotional pain (e.g., by listening to Pink Floyd).<ol>\n<li>An objection to this objection is that primal scream therapy seems not actually to work except in the short term.</li>\n</ol></li>\n</ol></li>\n<li>Pain triggers endorphins in order to help us fight or flee, and it feels good.</li>\n<li>We enjoy fighting and athletic competition, and pain is associated with these things we enjoy.</li>\n</ol>\n<p>My guess is that, if it's a side-effect (e.g., 3) or a non-causal association (4), it's okay to eliminate masochism.&nbsp; Otherwise, that could be risky.</p>\n<p>These all lead up to Question 4, which is a <a href=\"http://www.overcomingbias.com/2009/01/fun-theory-sequence.html\">fun-theory</a> question:&nbsp; Would purging ourselves of masochism make life less fun?</p>\n<p>ADDED: Question 5: Can we train ourselves not to be Bruce without damaging our enjoyment of these other things?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"LaDu5bKDpe8LxaR7C": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mCQf5FCXjwTBeLC6u", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 9, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "372", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 147, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FZaDFYbnRoHmde7F6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-11T03:15:40.595Z", "modifiedAt": null, "url": null, "title": "Missed Distinctions", "slug": "missed-distinctions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.394Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Afvk6GGfoo8mea5cb/missed-distinctions", "pageUrlRelative": "/posts/Afvk6GGfoo8mea5cb/missed-distinctions", "linkUrl": "https://www.lesswrong.com/posts/Afvk6GGfoo8mea5cb/missed-distinctions", "postedAtFormatted": "Saturday, April 11th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Missed%20Distinctions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMissed%20Distinctions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAfvk6GGfoo8mea5cb%2Fmissed-distinctions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Missed%20Distinctions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAfvk6GGfoo8mea5cb%2Fmissed-distinctions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAfvk6GGfoo8mea5cb%2Fmissed-distinctions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 741, "htmlBody": "<p>When we lump unlike things together, it confuses us and opens holes in our theories. I'm not normally one to read about diets, dieting advice, or anything of that sort, but in today's article about the <a href=\"/lw/a6/the_mysteries_of_shangrila_dieting/\" target=\"_self\">Shangri-La Diet</a>, I saw an important distinction that no one's talked about. Something Eliezer said in the comments struck me as odd:</p>\n<blockquote>\n<p>a skipped meal you wouldn't notice would have me dizzy when I stand up</p>\n</blockquote>\n<p>And a few posts later,</p>\n<blockquote>\n<p>I can starve or think, not both at the same time.</p>\n</blockquote>\n<p>Reading these, I thought, that's not what being hungry like feels like for <em>me</em>. But while being hungry doesn't feel like that, those descriptions were nonetheless familiar. And then it hit me.</p>\n<p>He wasn't describing the symptoms of hunger. He was describing the symptoms of hypoglycemia, more commonly known as low blood sugar. Blood sugar is one of the main systems responsible for regulating appetite, so for most people, having low blood sugar and being hungry are one and the same. The main focus of the Atkins diet, for example, is reducing swings in blood sugar, thereby reducing appetite. The Shangri-La diet seems like it would have a similar effect.</p>\n<p><a id=\"more\"></a>Being diabetic (the kind caused by immunology, not the kind caused by diet), I monitor and control my blood sugar, so I have ample opportunities to observe how it affects my eating habits and how I feel. Like most insulin-dependent diabetics, I have been trained with a fairly detailed model of blood sugar, how it's affected by food and insulin, and procedures to follow if it's too high or low. The standard procedure for low blood sugar, taught to all diabetics, is to test blood sugar, eat exactly 15g (60 calories) of sugar, wait 15 minutes, then test again. In practice, I have sometimes responded to hypoglycemia, not with 15g of sugar as the procedure specifies, but with 15g of sugar, immediately followed by a thousand plus calories of binge eating - basically, as much food as I could shove down in the time between when I first started eating, and when my blood sugar returned to normal (about ten minutes). This behavior is common among people on diets stricter than they can handle. For me, someone not on a diet, with a mostly full stomach, it's downright odd. Or is it?</p>\n<p>Being hungry is <em>not the same</em> as having low blood sugar. Hypoglycaemia feels like extreme hunger (plus a few other symptoms), but while extreme hunger takes a lot of food to get rid of, it only takes 60 calories and 15 minutes to completely eliminate hypoglycaemia. If you're hungry, you ought to suppress it. If you're hypoglycaemic, on the other hand, you need to deal with it swiftly, and in a controlled manner. What happens if you don't? As a diabetic, this, too, is in my training. The pancreas will release glucagon, a hormone that causes the liver to release stored sugar into the bloodstream. Getting rid of stored energy is good for a dieter, right? Well, in this case, no it isn't; the sugar stored in the liver would have been released the next time you exercised. Rather than burning fat, you're burning short-term energy reserves, so that when you <em>do</em> make it to the gym, you'll hit a wall more quickly. And of course, while your blood sugar is low and you aren't eating, you can't focus and you quickly burn through willpower.</p>\n<p>Today's best diets prevent low blood sugar entirely, rendering the hunger vs. hypoglycaemia distinction moot. However, if you can't tell the difference between hunger and hypoglycaemia, then you can't tell whether it's your diet failing or your willpower. Blood sugar test kits are affordable and don't require a prescription, and once you know what low blood sugar feels like, you won't need the kit anymore. There is much more to dieting than just controlling blood sugar, of course, but we <em>do</em> know that blood sugar is important. So why has no one proposed the Prick Your Finger diet? Why do none of the popular diets involve measuring blood sugar at all, ever?</p>\n<p>Mild hypoglycaemia feels like a caffeine overdose without the energy: irritability, palpitations, and tingling in the extremities. It is a distinctly alien feeling, and includes an urgent desire for food. Only sugar can eliminate it; fat, protein and complex carbohydrates will not help at all, and should be avoided. Severe hypoglycaemia produces other symptoms, but can only be produced using medication.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"92SxJsDZ78ApAGq72": 2, "AHK82ypfxF45rqh9D": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Afvk6GGfoo8mea5cb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 38, "extendedScore": null, "score": 6.4e-05, "legacy": true, "legacyId": "375", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 37, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BD4oExxQguTgpESdm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-11T06:32:50.408Z", "modifiedAt": null, "url": null, "title": "Maybe Theism Is OK -- Part 2", "slug": "maybe-theism-is-ok-part-2", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:25.351Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "byrnema", "createdAt": "2009-03-20T18:02:38.305Z", "isAdmin": false, "displayName": "byrnema"}, "userId": "SCnD6W8NiztYBN39M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S4a66fZs64kxjBskY/maybe-theism-is-ok-part-2", "pageUrlRelative": "/posts/S4a66fZs64kxjBskY/maybe-theism-is-ok-part-2", "linkUrl": "https://www.lesswrong.com/posts/S4a66fZs64kxjBskY/maybe-theism-is-ok-part-2", "postedAtFormatted": "Saturday, April 11th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Maybe%20Theism%20Is%20OK%20--%20Part%202&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaybe%20Theism%20Is%20OK%20--%20Part%202%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS4a66fZs64kxjBskY%2Fmaybe-theism-is-ok-part-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Maybe%20Theism%20Is%20OK%20--%20Part%202%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS4a66fZs64kxjBskY%2Fmaybe-theism-is-ok-part-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS4a66fZs64kxjBskY%2Fmaybe-theism-is-ok-part-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 658, "htmlBody": "<p>In response to:<a href=\"/lw/9n/the_uniquely_awful_example_of_theism\"> The uniquely awful example of theism</a></p>\n<p>And <a class=\"title\" href=\"/lw/ad/maybe_theism_is_ok\">Maybe Theism Is OK</a></p>\n<p>Finally, I think I understand where gim and others are coming from when they made statements that I thought represented overly intolerant views of religious belief. I think that a good summary of the source of the initial difference in opinion is that while many people in this group have the purpose to eliminate all sources of irrationality,&nbsp; I would like to pick and choose which sources of irrationality I have in the optimization of a different problem: general life-hacking.</p>\n<p>Probably many people in this group believe that the best life-hack would be to eliminate irrationality. But I'm pretty sure this depends on the person (not everyone is suited for X-rationality), and I'm pretty sure -- though not certain -- that my best life-hack would include some irrationality.</p>\n<p>Since my goals are different than that of this forum, many of my views are not relevant here, and there is no need to debate them.</p>\n<p>Instead, I would like to present two arguments (1,2) for why it could be rational to hold an irrational belief, and two arguments (3,4) as to why someone could be more accepting of the existence of irrational beliefs (i.e., why not to hate it).</p>\n<p>(1) It could be rational to hold an irrational belief if you are <em>aware </em>of your irrational belief and <em>choose</em> to hold it because it is grafted to components of your personality/ psyche that are valuable to you. For example, you may find that</p>\n<ul>\n<li>eschewing your religious beliefs makes you feel depressed and you are unable to work productively </li>\n<li>your ability to control unwanted impulses is tied with a moral conscience that is inextricably tied with beliefs about God. </li>\n<li>ability to perform a certain artistic activity that you enjoy is compartmentalized with spiritual beliefs</li>\n</ul>\n<p>I imagine these situations would be the result of an organically developing mind that has made several errors and is possibly unstable. But until we have a full understanding of mental processes/psychology/the physiology of emotions, we cannot expect a rational person to just \"tough it out\" to optimize rationality while his life falls apart.</p>\n<p>Later added: This argument has since been described better, with a better emphasis, with [this comment.](http://lesswrong.com/lw/aq/how_much_thought/6zp)</p>\n<p>(2) It could be rational to hold an irrational belief if you <em>choose</em> to hold it because you would like to exercise true control of your mind. Put another way, you may find it to be an aesthetic art of some form to choose a set of beliefs and truly believe them. Why would anyone want to do this? Eliminating all beliefs and becoming rational is a good exercise in controlling your mind.&nbsp;I hazard that a second exercise would be to believe what you consciously choose to.</p>\n<p>(3) I think there is another reason to consciously choose to try to believe something that you don't believe rationally-- true understanding of the enemy; the source and the grip of an irrational thought. What irked me most about the negative comments about religious views was the lack of any empathy for those views. It may seem like a contradiction but while I believe some religious views are irrational I do not dismiss people who hold them as hopelessly irrational. With empathy, I believe that it is possible to hold religious views and not greatly compromise rationality.</p>\n<p>(4) Maybe you are indeed right that any kind of religious view is irrational and that we would be better off without it. However, it is not at as clear that religious views can ever be completely exorcised... Suppose we wanted to create a world in which important parts of people's personalities are never tied to religious views. Are children allowed to daydream? Is a child allowed to daydream they are omnipotent? Are they allowed to pretend there is a God for a day? How will it affect creativity and motivation and development if there is no empathy for an understanding of God?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S4a66fZs64kxjBskY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -6, "extendedScore": null, "score": -1e-05, "legacy": true, "legacyId": "376", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dLL6yzZ3WKn8KaSC3", "JRt4qrbbpgEW5LBWG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-11T11:25:16.530Z", "modifiedAt": null, "url": null, "title": "Toxic Truth", "slug": "toxic-truth", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:27.279Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MichaelHoward", "createdAt": "2009-03-01T12:12:44.105Z", "isAdmin": false, "displayName": "MichaelHoward"}, "userId": "TCDxnyqmz6ZTCYuQQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g3W2mLoGN5osuH4f4/toxic-truth", "pageUrlRelative": "/posts/g3W2mLoGN5osuH4f4/toxic-truth", "linkUrl": "https://www.lesswrong.com/posts/g3W2mLoGN5osuH4f4/toxic-truth", "postedAtFormatted": "Saturday, April 11th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Toxic%20Truth&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToxic%20Truth%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg3W2mLoGN5osuH4f4%2Ftoxic-truth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Toxic%20Truth%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg3W2mLoGN5osuH4f4%2Ftoxic-truth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg3W2mLoGN5osuH4f4%2Ftoxic-truth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 361, "htmlBody": "<p>For those who haven't heard about this yet, I thought this would be a good way to show the potentially insidious effect of biased, one-sided analysis and presentation of evidence under ulterior motives, and the importance of seeking out counter-arguments before accepting a point, <em>even when the evidence being presented to support that point is true</em>.</p>\n<blockquote>\n<p style=\"padding-left: 30px;\">\"[DHMO] has been a part of nature longer than we have; what gives us the right to eliminate it?\" - Pro-DHMO web site.</p>\n</blockquote>\n<p>DHMO (hydroxilic acid), commonly found in excised tumors and lesions of terminal lung and throat cancer patients, is a compound <em>known </em>to occur in second hand tobacco smoke. Prolonged exposure in solid form causes severe tissue damage, and a proven link has been established between inhalation of DHMO (even in small quantities) and several deaths, including many young children whose parents were heavy smokers.<br /><br />It's also used as a solvent during the synthesis of cocaine, in certain forms of particularly cruel and unnecessary animal research, and has been traced to the distribution process of several cases of pesticides causing genetic damage and birth defects. But there are <em>huge</em> political and financial incentives to continue using the compound.<br /><br />There have been efforts across the world to ban DHMO - an Australian MP has announced a campaign to ban it internationally - but little progress. Several online petitions to the British prime minister on this subject have been rejected. The executive director of the public body that operates Louisville Waterfront Park was actually <em>criticised </em>for posting warning signs on a public fountain that was found to contain DHMO. Jacqui Dean, New Zealand National Party MP was simily told \"I seriously doubt that the Expert Advisory Committee on Drugs would want to spend any time evaluating that substance\".</p>\n<p>If you haven't guessed why, re-read my first sentence then click <a href=\"http://en.wikipedia.org/wiki/Dihydrogen_monoxide_hoax\">here</a>.<br /><br />HT the Coalition to Ban Dihydrogen Monoxide.</p>\n<p>[Edit to clarify point:] I'm not saying truth is in any way bad. Truth rocks. I'm reminding you truth is *not sufficient*. <em>When they're given treacherously or used recklessly, truth is as toxic as hydroxilic acid.</em></p>\n<p><strong>Follow-up to:</strong> <a href=\"/lw/6q/seeing_patterns_where_they_dont_exist/4fa#comments\">Comment</a> in <em>The Forbidden Post</em>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nANxo5C4sPG9HQHzr": 1, "ZzxvopS4BwLuQy42n": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g3W2mLoGN5osuH4f4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 16, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "377", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-11T14:05:18.306Z", "modifiedAt": null, "url": null, "title": "Too much feedback can be a bad thing", "slug": "too-much-feedback-can-be-a-bad-thing", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:27.209Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GsiTXp2v3SRfG8ugK/too-much-feedback-can-be-a-bad-thing", "pageUrlRelative": "/posts/GsiTXp2v3SRfG8ugK/too-much-feedback-can-be-a-bad-thing", "linkUrl": "https://www.lesswrong.com/posts/GsiTXp2v3SRfG8ugK/too-much-feedback-can-be-a-bad-thing", "postedAtFormatted": "Saturday, April 11th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Too%20much%20feedback%20can%20be%20a%20bad%20thing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToo%20much%20feedback%20can%20be%20a%20bad%20thing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGsiTXp2v3SRfG8ugK%2Ftoo-much-feedback-can-be-a-bad-thing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Too%20much%20feedback%20can%20be%20a%20bad%20thing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGsiTXp2v3SRfG8ugK%2Ftoo-much-feedback-can-be-a-bad-thing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGsiTXp2v3SRfG8ugK%2Ftoo-much-feedback-can-be-a-bad-thing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 216, "htmlBody": "<p>Didn't have the time to read the article itself, but based on the abstract, <a href=\"http://dx.doi.org/10.1016/j.obhdp.2008.05.005\">this</a> certainly sounds relevant for LW:</p>\r\n<blockquote>\r\n<p>Recent advances in information technology make it possible for decision makers to track information in real-time and obtain frequent feedback on their decisions. From a normative sense, an increase in the frequency of feedback and the ability to make changes should lead to enhanced performance as decision makers are able to respond more quickly to changes in the environment and see the consequences of their actions. At the same time, there is reason to believe that more frequent feedback can sometimes lead to declines in performance. Across four inventory management experiments, we find that in environments characterized by random noise more frequent feedback on previous decisions leads to declines in performance. Receiving more frequent feedback leads to excessive focus on and more systematic processing of more recent data as well as a failure to adequately compare information across multiple time periods.</p>\r\n</blockquote>\r\n<p>Hat tip to the <a href=\"http://bps-research-digest.blogspot.com/2009/04/extras.html\">BPS Resarch Digest</a>.</p>\r\n<p>ETA: Some other relevant studies from the same site, don't remember which ones have been covered here already:</p>\r\n<p><a href=\"http://bps-research-digest.blogspot.com/2009/04/threat-of-terrorism-boosts-peoples-self.html\">Threat of terrorism boosts people's self-esteem</a></p>\r\n<p><a href=\"http://bps-research-digest.blogspot.com/2009/04/is-less-always-more-testing-limits-of.html\">The \"too much choice\" problem isn't as straightforward as you'd think</a></p>\r\n<p><a href=\"http://bps-research-digest.blogspot.com/2008/08/forget-everything-you-thought-you-knew.html\">Forget everything you thought you knew about Phineas Gage, Kitty Genovese, Little Albert, and other classic psychological tales</a></p>\r\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"wygybwY9SMdaPepZr": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GsiTXp2v3SRfG8ugK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 11, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "379", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-11T14:40:10.521Z", "modifiedAt": null, "url": null, "title": "Twelve Virtues booklet printing?", "slug": "twelve-virtues-booklet-printing", "viewCount": null, "lastCommentedAt": "2013-11-16T08:35:18.581Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a3MhmPM7eZbP6pFPZ/twelve-virtues-booklet-printing", "pageUrlRelative": "/posts/a3MhmPM7eZbP6pFPZ/twelve-virtues-booklet-printing", "linkUrl": "https://www.lesswrong.com/posts/a3MhmPM7eZbP6pFPZ/twelve-virtues-booklet-printing", "postedAtFormatted": "Saturday, April 11th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Twelve%20Virtues%20booklet%20printing%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATwelve%20Virtues%20booklet%20printing%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa3MhmPM7eZbP6pFPZ%2Ftwelve-virtues-booklet-printing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Twelve%20Virtues%20booklet%20printing%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa3MhmPM7eZbP6pFPZ%2Ftwelve-virtues-booklet-printing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa3MhmPM7eZbP6pFPZ%2Ftwelve-virtues-booklet-printing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 282, "htmlBody": "<p>For a while now, I've been using a laser printer to print out a couple of hundred copies of the <a href=\"http://yudkowsky.net/rational/virtues\">Twelve Virtues of Rationality</a> (in its <a href=\"http://yudkowsky.net/assets/pdf/twelve_virtues.pdf\">printable pamphlet</a> version) and taking them with me to conferences, talks, and <a href=\"http://pc7.penguicon.org/\">science fiction conventions</a>.&nbsp; Cut, staple in the middle (using a large-sized, measuring stapler), and fold.&nbsp; This method is <em>very</em> cheap, probably something like ten cents a copy for ink and paper.&nbsp; But it produces crappy-looking pamphlets.</p>\n<p>Does anyone know of a way of cheaply printing small 16-page pamphlets?&nbsp; Take a look at the <a href=\"http://yudkowsky.net/assets/pdf/twelve_virtues.pdf\">pamphlet</a> to see the current size.&nbsp; I would really like to see the pamphlets stack well so I can plump down 50 of them without the tower falling over, which is the main problem with the staple-and-fold method.&nbsp; But even more important is that they be <em>cheap,</em> considering the quantities in which I hand these out for free.&nbsp; Something conducive to a professional-looking cover (i.e. allowing for the top sheet to be glossy or a higher quality of paper) would also be nice, again cost permitting.</p>\n<p>If I can find a good solution I'll also go ahead and get the pamphlet graphically redesigned before printing, of course, and include some more direct proselytizing material for <em>Less Wrong</em> on the back cover.</p>\n<p>I've looked around online, but all the print shops I've seen have been way too expensive for giving away 200 copies per convention - even by myself, much less getting other people to do it on a routine basis.&nbsp; Does anyone know how to get this done cheaply?&nbsp; A minimum order of 10,000 for $1000 would be quite acceptable - I expect at that price I could ship some boxes to other LWers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8uNFGxejo5hykCEez": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a3MhmPM7eZbP6pFPZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 7, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "380", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2009-04-11T14:40:10.521Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-11T16:53:29.690Z", "modifiedAt": null, "url": null, "title": "Maybe theism is wrong", "slug": "maybe-theism-is-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T03:53:04.496Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "infotropism", "createdAt": "2009-02-27T21:33:06.774Z", "isAdmin": false, "displayName": "infotropism"}, "userId": "X2yCuTTPzYdobZhii", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nGovfP5okymjcghw8/maybe-theism-is-wrong", "pageUrlRelative": "/posts/nGovfP5okymjcghw8/maybe-theism-is-wrong", "linkUrl": "https://www.lesswrong.com/posts/nGovfP5okymjcghw8/maybe-theism-is-wrong", "postedAtFormatted": "Saturday, April 11th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Maybe%20theism%20is%20wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaybe%20theism%20is%20wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnGovfP5okymjcghw8%2Fmaybe-theism-is-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Maybe%20theism%20is%20wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnGovfP5okymjcghw8%2Fmaybe-theism-is-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnGovfP5okymjcghw8%2Fmaybe-theism-is-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1024, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin-bottom: 0cm;\">(This is meant as an entirely rewritten version of the original post. It is still long, but hopefully clearer.)</p>\n<p style=\"margin-bottom: 0cm;\">&nbsp;</p>\n<p style=\"margin-bottom: 0cm;\">Theism is often bashed. Part of that bashing is gratuitous and undeserved. Some people therefore feel compelled to defend theism. Their defence of theism goes further than just putting the record straight though. It attempts to show how theism can be a good thing, or right. That is probably going too far.</p>\n<p style=\"margin-bottom: 0cm;\">I would argue several points. And for that I will be using the most idealistic vision of religion I can conjure, keeping in mind that real world examples may not be as utopian. My intended conclusion is that fairness and tolerance are a necessary and humane means to the end of helping people, which cannot, however, be used to justify as right something that is ultimately wrong.</p>\n<p style=\"margin-bottom: 0cm;\">Theism is indeed a good thing, on short and mid term, both for individuals and society, as it holds certain benefits.Such as helping people stick together in close knit communities, helping people life a more virtuous life by giving themselves incentives to do so, helping them feel better when life feels unbearable or meaningless.</p>\n<p style=\"margin-bottom: 0cm;\">Another point is that theism also possesses deep similarities with science, and uses optimally rational arguments and induction. Optimally, that is, insofar as the premises of theism allow; those premises, what we could call their priors are, for instance, in Christianity, to be found in the Bible.</p>\n<p style=\"margin-bottom: 0cm;\">Finally, I also wanted to draw on further similarities between religion and secular groups of people. Atheism, humanism, transhumanism, even rationalism as we know it on LW. These similarities lie in the objectives which any of those groups honestly strives to attain. Those goals are, for instance, truth, the welfare of human beings, and their betterment.</p>\n<p style=\"margin-bottom: 0cm;\">Within the world view of each of those groups, each is indeed doing its best to achieve those ends. One of catholicism's final beacon, used to guide people's life path, can be roughly said to be \"what action should I take that will make me more able to love others, and myself\" for instance. This, involves understanding, and following the word of God, as love and morality is understood to emanate from that source.</p>\n<p style=\"margin-bottom: 0cm;\">And so the Bible, is supposed to hold those absolute truths, not so much in a straightforward, explained way, but rather in the same way that the observable universe is supposed to hold absolute truth for secular science. And just as it is possible to misconstrue observations and build flawed theories in the scientific model, given that observational, experimental data, so is it for a christian person, to misunderstand the data presented in the Bible. Rational edifices of thought have therefore been built to derive humanly understandable, cross checked (inside that edifice), usable-on-a-daily-basis truth, from the Bible.</p>\n<p style=\"margin-bottom: 0cm;\">That is about as far as we can go for similarities, purity of purpose, intellectual honesty and adequacy with the real world.</p>\n<p style=\"margin-bottom: 0cm;\">The premise of theism itself, is flawed. Theism presupposes the supernatural. Therefore, the priors of theism, do not correspond to the real state of the universe as we observe it, and this implies two main consequences.</p>\n<p style=\"margin-bottom: 0cm;\">The first is that an intellectual edifice based upon flawed premises, no matter how carefully crafted, will still be flawed itself.</p>\n<p style=\"margin-bottom: 0cm;\">The second runs deeper and is that the premises of theism themselves are in part incompatible with rationality itself, and hence limit the potential use of rational methods. In other words, some methods of rationality, as well as some particular arguments are forbidden, or unknown to what we could tentatively call religious science.</p>\n<p style=\"margin-bottom: 0cm;\">From that, my first conclusion is that theism is wrong. Epistemically wrong, but also, doing itself a disservice, as the goals it has set itself up to, cannot be completed through its program. This program will not be able to hit its targets in optmization space, because of that epistemical flaw. Even though theism possesses short and mid term advantages, its whole edifice makes it a dead end, which will at the very least slow down humanity's progress towards nobler objectives like truth or betterment, if not even rendering that progress outright impossible past a certain point.</p>\n<p style=\"margin-bottom: 0cm;\">Yet, it seems to me that this mistaken edifice isn't totally insane, far from it, at least at its roots. Hence it should be possible to heal it. Or at least, helping the people that are part of it, healing them.</p>\n<p style=\"margin-bottom: 0cm;\">But, religion cannot be honestly called right, no matter how deep that idea is rooted in our culture and collective consciousness. On the long term, theism deprives us of our potential, it builds a virtual, unnecessary cage around us.</p>\n<p style=\"margin-bottom: 0cm;\">To conclude on that, I wanted to point out that religious belief appears to be a human universal, and probably a hard coded part of human nature. It seems fair to recognize it in us, if we have that tendency. I know I do, for instance, and fairly strongly so. Idem for belief in the supernatural.</p>\n<p style=\"margin-bottom: 0cm;\">This should be part of a more general mental discipline, of admitting to our faults and biases, rather than trying to hide and make up for them. The only way to dissect and correct them, is to first thoroughly observe those faults in our reasoning. Publicly so even. In a community of rationalists, there should be no question that even the most flawed, irrational of us, should only be treated as a friend in need of help, if he so desires, and if we have enough ressources to provide to his needs. The important thing there, is to have someone possessing a willingness to learn, and grow past his mistakes. This, can indeed be made easier, if we are supportive of each other, and tolerant, unconditionally.</p>\n<p style=\"margin-bottom: 0cm;\">Yet, at the same time, even for that purpose, we can't yield to falseness. We can and must admit for instance that religion has good points, that we may not have a licence to change people against their will, and that if people want to be helped, that they should feel relaxed in explaining all the relevant information about what they perceive to be their problem. We can't go as far as saying that such a flaw, or problem, is, in itself, alright, though.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nGovfP5okymjcghw8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": -6, "extendedScore": null, "score": -9e-06, "legacy": true, "legacyId": "381", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-11T18:53:48.155Z", "modifiedAt": null, "url": null, "title": "Less Wrong IRC meetup, going soon", "slug": "less-wrong-irc-meetup-going-soon", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:25.191Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8q8hqtfBHALBEmyYi/less-wrong-irc-meetup-going-soon", "pageUrlRelative": "/posts/8q8hqtfBHALBEmyYi/less-wrong-irc-meetup-going-soon", "linkUrl": "https://www.lesswrong.com/posts/8q8hqtfBHALBEmyYi/less-wrong-irc-meetup-going-soon", "postedAtFormatted": "Saturday, April 11th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20IRC%20meetup%2C%20going%20soon&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20IRC%20meetup%2C%20going%20soon%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8q8hqtfBHALBEmyYi%2Fless-wrong-irc-meetup-going-soon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20IRC%20meetup%2C%20going%20soon%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8q8hqtfBHALBEmyYi%2Fless-wrong-irc-meetup-going-soon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8q8hqtfBHALBEmyYi%2Fless-wrong-irc-meetup-going-soon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p><strong>Reminder:&nbsp; <a href=\"/lw/9k/less_wrong_irc_meetup/\">Less Wrong will be having a meetup</a></strong> on Saturday at 7pm UTC (<a href=\"http://www.timeanddate.com/worldclock/fixedtime.html?month=4&amp;day=11&amp;year=2009&amp;hour=19&amp;min=0&amp;sec=0&amp;p1=0\" target=\"_self\">convert to other time zones</a>), in the <a href=\"irc://irc.freenode.net/lesswrong\">#lesswrong IRC channel on Freenode</a>. If all goes well, this will be a recurring event. If you haven't used IRC before, <a href=\"http://mibbit.com/chat/?server=irc.freenode.net&amp;channel=%23lesswrong\" target=\"_blank\">Mibbit</a> provides a web-based client you can use.</p>\n<p>(It's my understanding that this works out to 12pm Pacific or 3pm Eastern, i.e. in about 7 minutes from the time of this posting.&nbsp; I'll delete this post after the meeting is over - comments to <a href=\"/lw/9k/less_wrong_irc_meetup/\">main post</a> only, please.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8q8hqtfBHALBEmyYi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "383", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4xEohME6vfXNmHmAz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-12T04:56:40.773Z", "modifiedAt": null, "url": null, "title": "How Much Thought", "slug": "how-much-thought", "viewCount": null, "lastCommentedAt": "2017-12-05T13:19:33.719Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YKSwmhGJ3pY9qobnw/how-much-thought", "pageUrlRelative": "/posts/YKSwmhGJ3pY9qobnw/how-much-thought", "linkUrl": "https://www.lesswrong.com/posts/YKSwmhGJ3pY9qobnw/how-much-thought", "postedAtFormatted": "Sunday, April 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Much%20Thought&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Much%20Thought%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYKSwmhGJ3pY9qobnw%2Fhow-much-thought%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Much%20Thought%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYKSwmhGJ3pY9qobnw%2Fhow-much-thought", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYKSwmhGJ3pY9qobnw%2Fhow-much-thought", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1304, "htmlBody": "<p>We have many built in heuristics, and most of them are trouble. The <a href=\"http://www.overcomingbias.com/2007/09/absurdity-heuri.html\" target=\"_self\">absurdity heuristic</a> makes us reject reasonable things out of hand, so we should take the time to fully understand things that seem absurd at first. Some of our beliefs are not reasoned, but <a href=\"http://www.overcomingbias.com/2006/11/beware_heritabl.html\" target=\"_self\">inherited</a>; we should sniff those out and discard them. We repeat <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\" target=\"_self\">cached thoughts</a>, so we should clear and rethink them. The <a href=\"http://www.overcomingbias.com/2007/11/affect-heuristi.html\" target=\"_self\">affect heuristic</a> is a tricky one; to work around it, we have to <a href=\"http://www.overcomingbias.com/2007/07/beware-the-insi.html\" target=\"_self\">take the outside view</a>. Everything we see and do <a href=\"http://www.overcomingbias.com/2007/10/priming-and-con.html\" target=\"_self\">primes</a> us, so for really important decisions, we should <a href=\"/lw/3b/never_leave_your_room/\" target=\"_self\">never leave our rooms</a>. We fail to attribute agency to things which should have it, like opinions, so if less drastic means don't work, we should <a href=\"/lw/9g/eprime/\" target=\"_self\">modify English</a> to make ourseves do so.</p>\n<p>All of these articles bear the same message, the same message that can be easily found in the subtext of every book, treatise and example of rationality. <em>Think more</em>. Look for the <a href=\"http://www.overcomingbias.com/2007/05/the_third_alter.html\" target=\"_self\">third alternative</a>. <a href=\"http://www.overcomingbias.com/2009/02/write-your-hypothetical-apostasy.html\" target=\"_self\">Challenge your deeply held beliefs</a>. Drive through <a href=\"http://www.overcomingbias.com/2007/08/semantic-stopsi.html\" target=\"_self\">semantic stop signs</a>. <a href=\"http://www.overcomingbias.com/2008/02/leave-retreat.html\" target=\"_self\">Prepare a line of retreat</a>. If you don't understand, you should <a href=\"http://www.overcomingbias.com/2008/10/isshokenmei.html\" target=\"_self\">make an extraordinary effort</a>. When you do find cause to change your beliefs, <a href=\"/lw/19/checklists/\" target=\"_self\">complete a checklist</a>, <a href=\"/lw/1g/the_mistake_script/\" target=\"_self\">run a script</a> and <a href=\"http://www.overcomingbias.com/2008/10/the-question.html\" target=\"_self\">follow a ritual</a>. Recheck your answers, because <a href=\"http://www.overcomingbias.com/2008/11/thinking-helps.html\" target=\"_self\">thinking helps</a>; more thought is always better.</p>\n<p>The problem is, there's only a limited amount of time in each day. To spend more time thinking about something, we must spend less time on something else. The more we think about each topic, the fewer topics we have time to think about at all. Rationalism gives us a long list of extra things to think about, and angles to think about them from, without guidance on <em>where</em> or <em>how much</em> to apply them. This can make us overthink some things and disastrously underthink others. Our worst mistakes are not those where our thoughts went astray, but those we failed to think about at all. The time between when we learn rationality techniques and when we learn where to apply them is <a href=\"/lw/7k/incremental_progress_and_the_valley/\" target=\"_self\">the valley</a>.</p>\n<p><a id=\"more\"></a></p>\n<p>Reason, like time and money, is a resource. There are many complex definitions of reason, but I will use a simple one: reason is time spent thinking. We mainly use our reason to make decisions and answer questions; if we do it right, the more reason we spend, the more likely our answer will be correct.. We might question this analogy on the basis that we can't directly control our thoughts, but then, many people can't directly control their monetary spending, either; they impulse buy. In both cases, we can control our spending directly, using willpower (which is also a limited resource), or indirectly by finding ways to adjust our routine.</p>\n<p>This model is convenient enough to be suspicious, so we should apply some sanity checks to make sure it all adds up to normality. The utility we get from thinking about a decision is the cost of deciding incorrectly times the probability that we'll change our mind from incorrect to correct, minus the probability that we'll change our mind from correct to incorrect. From this, we get the highly normal statements <em>thinking has higher expected utility when you're likely to change your mind</em> and <em>thinking has higher expected utility when the subject is important</em>. With a resource model of reason, we should also expect simple representations for surpluses and shortages. A surplus of reason manifests as boredom; we are bored when we have nothing to do but think, and nothing interesting to think about. A shortage or reason manifests as stress; we're stressed when we have too much to think about.</p>\n<p>&nbsp;</p>\n<p>When we consider costs as well as benefits, it becomes possible to reason about which techniques are worthwhile. It is not enough to show that a technique will sometimes illuminate truth; to justify its cost, it must be marginally more likely to illuminate truth than the next best technique. On easy questions of little consequence, a single cached thought or a simple heuristic will suffice. On hard problems, most techniques will fail to produce any insight, so we need to try more of them.</p>\n<p>Our mind is built on heuristics because they're efficient. A <a href=\"/lw/8y/heuristic_is_not_a_bad_word/\" target=\"_self\">heuristic is not a bad word</a>, but a way of answering questions cheaply. You shouldn't base core beliefs or important choices on heuristics alone, but for minor decisions a few simple heuristics may be all you can afford. Core beliefs and important choices, on the other hand, spawn a tree of sub-questions, the leaves of which are answered by heuristics or cached thoughts.</p>\n<p>The Overcoming Bias articles on heuristics treat them like villains that sabotage our thoughts. The standard way to prove that a heuristic exists is to present an example where it leads us astray. That means teaching readers, not to avoid using heuristics where they're inappropriate, but to avoid using them entirely. Fortunately, the architecture of our minds won't let us do that, since eliminating a heuristic entirely would make us much stupider. Instead, we should focus on learning and teaching what they <a href=\"http://www.overcomingbias.com/2008/02/algorithm-feels.html\" target=\"_self\">feel like from the inside</a>, with examples where they lead us astray <em>and examples where they work properly</em>.</p>\n<p>&nbsp;</p>\n<p>In general, the expected return on investment for thinking about a topic starts high, as initial thoughts cut through confusion and affect our decision greatly, then drops as the most productive lines of reasoning are depleted. Once the expected return drops below some threshold, we should stop thinking about it.</p>\n<p>Normally, the process for allocating reason works automatically and works well. However, sometimes it breaks. Sometimes we run into questions that we simply can't resolve with the information we have available. If it's important, we run through our entire repertoire of techniques before giving up, perhaps guessing, and moving on. If it's less important, we try only the techniques that we think are likely to work before we give up. If you teach someone more techniques, then you increase the amount of time they can spend on a topic before running out of angles and being forced to move on. If those techniques fail to produce insight, then they make him stupider; he will spend more time on questions for little benefit, and ignore more. Some people are completely unable to budget their reason, like the man who spends ten minutes deciding what to order in a restaurant, knowing fully that he would be happier spending those ten minutes focused on conversation instead. If you teach him enough statistics, he might be foolish enough to try to calculate the probability of various dishes making him happy. He'll fail, of course, because statistics can't answer that question with the data he has, but he'll waste even more time trying.</p>\n<p>It would be nice to have more reason, but evidence points to cognitive capacity being a fixed quantity. We can, however, allocate the reason we do have more efficiently. We can set cutoff points to limit the time spent on silly things like restaurant orders. Some things are known to be wastes of reason; <a href=\"http://www.overcomingbias.com/2007/02/politics_is_the.html\" target=\"_self\">politics is the mind killer</a> because it can use an unlimited amount of mental energy without producing the slightest bit of utility.&nbsp;We can identify the thoughts that are least valuable to us by observing what our mind goes to when we're bored: mostly, we daydream and retread old lines of thought. That means that when there are worthwhile topics to think about, daydreaming and retreading should be the first things to go. This conclusion shouldn't surprise anyone, but it's good to have theoretical justification.</p>\n<p>&nbsp;</p>\n<p>Take a moment to think about what you spend time thinking about, and where your cutoff point is. Do you keep thinking about the same topic well past the point where insights stop coming? Do you get distracted and stop too early? If you decide unconsciously, would your conscious choice be the same or different?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "wfW6iL96u26mbatep": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YKSwmhGJ3pY9qobnw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 48, "baseScore": 46, "extendedScore": null, "score": 7.7e-05, "legacy": true, "legacyId": "386", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZmQv4DFx6y4jFbhLy", "K9mSWuKpZSk7t8FaH", "HnzB46zsL8ehdpLcd", "GDKX7S9mqL46qWct2", "oZNXmHcdhb4m7vwsv", "kjua3pfeGiskAAac2"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-12T06:06:39.990Z", "modifiedAt": null, "url": null, "title": "Awful Austrians", "slug": "awful-austrians", "viewCount": null, "lastCommentedAt": "2021-07-20T16:00:35.491Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmy", "createdAt": "2009-02-28T00:36:34.416Z", "isAdmin": false, "displayName": "Swimmy"}, "userId": "pNdunthLRqh3unTry", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GShnZZRJHsELHviC4/awful-austrians", "pageUrlRelative": "/posts/GShnZZRJHsELHviC4/awful-austrians", "linkUrl": "https://www.lesswrong.com/posts/GShnZZRJHsELHviC4/awful-austrians", "postedAtFormatted": "Sunday, April 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Awful%20Austrians&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAwful%20Austrians%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGShnZZRJHsELHviC4%2Fawful-austrians%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Awful%20Austrians%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGShnZZRJHsELHviC4%2Fawful-austrians", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGShnZZRJHsELHviC4%2Fawful-austrians", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1536, "htmlBody": "<p><strong>Response to</strong>: <a href=\"/lw/9n/the_uniquely_awful_example_of_theism/\">The uniquely awful example of theism</a></p>\n<p>Why is theism such an ever-present example of irrationality in this community? I think ciphergoth <a href=\"/lw/a3/how_theism_works/\">overstates the case</a>. Even theism is not completely immune to evidence, as the acceptance of, say, evolution by so many denominations over time will testify. Theism is a useful whipping boy because it needs no introduction.</p>\n<p>But I think the case is overstated for another reason. There are terrible epistemologies out there that are just as bad as theism's. Allow me to tell you a tale, of how I gave up my religion and my association with a school of economics at the same time.</p>\n<p>I grew up in a southern Presbyterian church in the U.S. While I was taught standard pseudo-evidential defenses for belief, such as \"creation science\" and standard critiques of evolution, my church was stringently anti-evidentialist. Their preferred apologetic was something called <a href=\"http://en.wikipedia.org/wiki/Presuppositional_apologetics\">presuppositionalism</a>. It's certainly a minority apologetic among major defenders of Christianity today, especially compared to the cosmological or morality arguments. But it's a particularly rigorous attempt to defend beliefs against evidence nonetheless.</p>\n<p>Presuppositionalism (in some forms) hangs on the <a href=\"http://www.overcomingbias.com/2008/07/recursive-justi.html\">problem of induction</a>. We cannot ultimately justify any of our beliefs without first making some assumptions, otherwise we end in solipsism. Christianity, then, justifies itself not on evidence, but on internal consistency. It is ok for an argument to be ultimately circular, because all arguments are ultimately circular. Christianity alone maintains perfect worldview consistency when examined through this lens, and is therefore correct.</p>\n<p>Since I've spent a lot of time thinking about this--it can take a considerable effort to <a href=\"http://www.overcomingbias.com/2008/10/the-question.html\">change one's mind</a>, after all--I can imagine innumerable things wrong with it, but they're not the focus of this entry. First, I just want to note how <em>close</em> it is to a kind of intro-level Bayesian understanding. Bayesians admit that we must have priors, that it's indeed nonsense to think we can even <a href=\"http://www.overcomingbias.com/2008/06/no-universally.html\">have an argument</a> with one who doesn't. We must ultimately admit that certain justifications are going to be either recursive or based on priors. We believe that we should update our priors based on evidence, but there's nothing in the math that tells us we can't start with a prior for some position of 0% or 100%. (There is something in the math that tells us such probability assignments are very <a href=\"http://www.overcomingbias.com/2008/01/0-and-1-are-not.html\">bad ideas</a>, and we have more than enough cognitive bias literature that tells us we shouldn't be so damn overconfident. But then, what if you have a prior that keeps you from accepting such evidence?) It doesn't have any of the mathematical rigor, but it comes very close on a few major points.<a id=\"more\"></a></p>\n<p>This is why Bayesianism appealed to me. It seemed similar to the supposedly deep argument I understood for God's existence, like something I could actually work with. (This is why, I think, anti-religion Overcoming Bias posts didn't throw me into defense mode.) This is also why I used to find Austrian economics so compelling.</p>\n<p>For those who aren't familiar, Austrian economics is a radical free-market school, the intellectual product of Ludwig von Mises, Friedrich von Hayek, and Murray Rothbard. Before I continue, in hopes of taking any Austrian economists reading this out of defense mode: I still find many Austrian insights useful, I admire Hayek for his work on knowledge and institutions, and Mises for the economic calculation argument. But the first section on epistemology in Mises' magnum opus, <em>Human Action</em>, is probably the best example of Dark Side Epistemology I have yet seen outside of religious apologetics or standard woo-woo. What does economics (or in Mises' case, praxeology, an expanded science of all human action that seeks to understand more than resource allocation) investigate? After excluding psychology, Mises tells us,</p>\n<blockquote>\n<p>No laboratory experiments can be performed with regard to human action. We are never in a position to observe the change in one element only, all other conditions of the event remaining unchanged. . . The information conveyed by historical experience cannot be used as building material for the construction of theories and the prediction of future events. . . Neither experimental verification nor experimental falsification of a general proposition is possible in its field. (p. 31)</p>\n</blockquote>\n<p>Well, ok. So how does economics tell us anything at all?</p>\n<blockquote>\n<p>Praxeology is a theoretical and systematic, not a historical, science. . . It aims at knowledge valid for all instances in which the conditions exactly correspond to those implied in its assumptions and inferences. Its statements and propositions are not derived from experience. They are, like those of logic and mathematics, a priori. They are not subject to verification or falsification on the ground of experience and facts. They are both logically and temporally antecedent to any comprehension of historical facts. (p. 31)</p>\n</blockquote>\n<p>In other words, the assumptions built into economics (which is a subset of praxeology)--people have preferences, are selfish (in the tautological sense--even altruist acts are self-serving to Mises), and they take rational action to satisfy those preferences--are unquestionable, ultimate givens. No evidence could ever confirm or disconfirm the predictions of economics, because it is an a priori science, just like math or logic. It is deductive--it starts from some assumptions, and its case rests on those assumptions alone, not on any evidence. (And he has a word for those of us seeking instances of <a href=\"http://www.overcomingbias.com/2008/01/allais-paradox.html\">human irrationality</a>. On page 103, he claims out that any sign of preference reversals can never be considered irrationality, because preferences cannot be considered stable, even across spans of a few seconds. If your by-the-second preference changing leads you to be pumped for money, so be it. You're still by assumption a rational actor, satisfying his desires.)</p>\n<p>You can understand why I think this sounds so similar to presuppositionalism. And, if you've been following Overcoming Bias, you can see how a Bayesian would differ from these views.</p>\n<p>I saw the same problems with presuppositionalism as I did Mises' epistemology. So what if it's deductive? What if your deductive logic doesn't conform to the real world? This could be true of math just as well as economics. What if 2 + 2 didn't really equal 4 in our world? <a href=\"http://www.overcomingbias.com/2007/09/how-to-convince.html\">Could there be any way to convince you</a>? If the answer is no, then aren't you just <a href=\"http://www.overcomingbias.com/2007/09/the-bottom-line.html\">starting from the bottom line</a>? If your deductively valid economic argument makes a prediction that is observed to <em>never</em> be true in the real world, would this not affect your rating of your deductions' usefulness? If your deductions are non-disprovable, why do you make <a href=\"http://www.overcomingbias.com/2007/08/religions-claim.html\">so many claims</a> regarding their predictive value? What does your logic <a href=\"http://www.overcomingbias.com/2007/08/conservation-of.html\">not predict</a>?</p>\n<p>To really solidify the feeling that Mises' predictions about economics are comparable to the Bible's predictions about how the world works, consider the following. As I mentioned, Mises defines self-interest tautologically:</p>\n<blockquote>\n<p>Praxeology is indifferent to the ultimate goals of action. Its findings are valid for all kinds of action irrespective of the ends aimed at. It is a science of means, not of ends. It applies the term happiness in a purely formal sense. In the praxeological terminology the proposition: man's unique aim is to attain happiness, is tautological. It does not imply any statement about the state of affairs from which man expects happiness. (p. 15)</p>\n</blockquote>\n<p>However, Mises specifically predicts economic outcomes based on self-interest as, well, actual self-interest. For instance, on page 763, he proclaims that price controls will lead to rationing by non-price means. But this is only true if the provider of the good in question is attempting to maximize profit; if the producer is willing to take a hit in the wallet out of the goodness of his heart for his customers' well-being, as Mises' tautological definition of self-interest allows, a small price ceiling could conceivably have no effect.</p>\n<p>So when are we to believe Mises? When he says economics is a deductive logic that can never be tested in the real world, or when he makes predictions that can be tested in the real world? When should we believe presuppositional apologists? When they claim that \"the Bible is the word of God\" is an ultimate given, or when they tell us all about miracles (evidence for God) that we can test in the real world (by finding evidence for a global flood)?</p>\n<p>The insistence on placing assumptions further and further away from our real ultimate givens, our real recursions, our real mystical priors, is a dark side epistemology. If we can devise a test for one of our assumptions, by golly, as rationalists we're called to test it. If that assumption fails, we have to perform a proper Bayesian update. We have to use all of our evidence available to us.</p>\n<p>So to answer what other forms of irrationality we can regularly cite, I'd like to nominate Austrian economics, or at least those of its followers who still eschew the introduction of statistics, behavorial economics, or experimental economics into the discipline. It certainly isn't as pervasive as religion. It's a very minor branch of a specific discipline. Not all of its conclusions are wrong, but I think there's at least a little <a href=\"http://econlog.econlib.org//archives/2006/03/the_socialist_c.html\">evidence</a> of <a href=\"/lw/a3/how_theism_works/\">dial-cranking</a> in Austrianism. And I think its epistemology is quite awful, as awful as the most evidence-defying justification for theism.</p>\n<p>Reference: Ludwig von Mises. <a href=\"http://mises.org/resources/3250\"><em>Human Action</em></a>. San Francisco: Fox &amp; Wilkes, 1996.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PDJ6KqJBRzvKPfuS3": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GShnZZRJHsELHviC4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 50, "baseScore": 37, "extendedScore": null, "score": 6e-05, "legacy": true, "legacyId": "387", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 37, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 91, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dLL6yzZ3WKn8KaSC3", "riaLsnntuxkPnWF6H"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-12T17:30:52.592Z", "modifiedAt": null, "url": null, "title": "Sunk Cost Fallacy", "slug": "sunk-cost-fallacy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:37.147Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Z_M_Davis", "createdAt": "2009-02-27T04:57:37.811Z", "isAdmin": false, "displayName": "Z_M_Davis"}, "userId": "YEWv9mcjBb7Z7Cgw3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tyMdPwd8x2RygcheE/sunk-cost-fallacy", "pageUrlRelative": "/posts/tyMdPwd8x2RygcheE/sunk-cost-fallacy", "linkUrl": "https://www.lesswrong.com/posts/tyMdPwd8x2RygcheE/sunk-cost-fallacy", "postedAtFormatted": "Sunday, April 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sunk%20Cost%20Fallacy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASunk%20Cost%20Fallacy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtyMdPwd8x2RygcheE%2Fsunk-cost-fallacy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sunk%20Cost%20Fallacy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtyMdPwd8x2RygcheE%2Fsunk-cost-fallacy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtyMdPwd8x2RygcheE%2Fsunk-cost-fallacy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 622, "htmlBody": "<p><strong>Related to</strong>: <a href=\"http://www.overcomingbias.com/2007/02/a_time_to_lose_.html\">Just Lose Hope Already</a>, <a href=\"http://www.overcomingbias.com/2008/01/allais-paradox.html\">The Allais Paradox</a>, <a href=\"/lw/4e/cached_selves/\">Cached Selves</a></p>\n<p>In economics we have this concept of <em>sunk costs</em>, referring to costs that have already been incurred, but which cannot be recouped. <em>Sunk cost fallacy</em> refers to the fallacy of honoring sunk costs, which decision-theoretically should just be ignored. The canonical example goes something like this: you have purchased a nonrefundable movie ticket in advance. (For the nitpickers in the audience, I will also specify that the ticket is nontransferable and that you weren't planning on meeting anyone.) When the night of the show comes, you notice that you don't actually feel like going out, and would actually enjoy yourself more at home. Do you go to the movie anyway?</p>\n<p>A lot of people say yes, to avoid wasting the ticket. But on further consideration, it would seem that these people are simply getting it wrong. The ticket is a sunk cost: it's already paid for, and you can't do anything with it but go to the movie. But we've stipulated that you don't want to go to the movie. The theater owners don't care whether you go; they already have their money. The other theater-goers, insofar as they can be said to have a preference, would actually rather you stayed home, making the theater marginally less crowded. If you go to the movie to satisfy your intuition about not wasting the ticket, you're not actually <em>helping</em> anyone. Of course, you're entitled to your values, <a href=\"http://www.overcomingbias.com/2006/12/you_are_never_e.html\">if not your belief</a>. If you really do place <a href=\"http://www.overcomingbias.com/2007/11/terminal-values.html\">terminal value</a> on using something because you've paid for it, well, fine, I guess. But we should all try to <em>notice</em> exactly what it is we're doing, in case it turns out to not be what we want. Please, think it through.</p>\n<p>Dearest reader, if you're now about to scrap your intuition against wasting things, I implore you: don't! The moral of the parable of the movie ticket is <em>not</em> that waste is okay; it's that you should implement your waste-reduction interventions at a time when they can actually <em>help</em>. If you can anticipate your enthusiasm waning on the night of the show, don't purchase the nonrefundable ticket in the first place!<a id=\"more\"></a></p>\n<p>You can view ignoring sunk costs as a sort of backwards perspective on <a href=\"http://www.overcomingbias.com/2007/09/the-bottom-line.html\">the principle of the bottom line</a>. The bottom line tells us that a decision can only be justified by its true causes; any arguments that come strictly afterwards don't count; if it just happens to all turn out for the best anyway, that only means you got lucky. The sunk cost fallacy tells us that a decision can only be justified by its <em>immediate</em> true causes; any arguments considered in the past but subsequently dismissed don't count; if you could have seen it coming, why didn't you?</p>\n<p>Another possible takeaway: perhaps don't be so afraid to behave inconsistently. Rational behavior may be consistent, but that doesn't mean you can be more rational simply by being more consistent. (Compare with the argument against <a href=\"http://www.overcomingbias.com/2007/03/on_majoritarian.html\">majoritarianism</a>: the <a href=\"http://www.overcomingbias.com/2006/12/agreeing_to_agr.html\">Aumann results</a> guarantee that Bayesians would agree, but that doesn't mean we can be more Bayesian simply by agreeing.) <em>Overcoming Bias</em> commenter John <a href=\"http://www.overcomingbias.com/2007/08/the-importance-.html?cid=83687583#comment-83687583\">suggests</a> that you go so far as to pretend that you've just been dropped into your current life with no warning. It may be disturbing to even consider such a radical discontinuity from your past&mdash;but <a href=\"http://www.overcomingbias.com/2008/02/leave-retreat.html\">you can consider something hypothetically</a>, without necessarily having to believe or act on it in any way. And <em>if</em>, on reflection, it turned out that your entire life up to now was a complete waste, well, wouldn't you want to <em>know</em> about it?&mdash;and <em>do</em> something about it?</p>\n<p>Decision theory is <a href=\"http://www.overcomingbias.com/2008/04/which-basis-is.html\"><em>local</em></a>. Don't be afraid to ask of your methodology: \"What have you done for me lately?\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"stnsBEmuGpnSfQ5vj": 2, "Ng8Gice9KNkncxqcj": 2, "LDTSbmXtokYAsEq8e": 2, "4R8JYu4QF2FqzJxE5": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tyMdPwd8x2RygcheE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 39, "extendedScore": null, "score": 6.6e-05, "legacy": true, "legacyId": "389", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BHYBdijDcAKQ6e45Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-12T21:06:20.881Z", "modifiedAt": null, "url": null, "title": "It's okay to be (at least a little) irrational", "slug": "it-s-okay-to-be-at-least-a-little-irrational", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:02.154Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Yiv9BeroBhJC6zqSs/it-s-okay-to-be-at-least-a-little-irrational", "pageUrlRelative": "/posts/Yiv9BeroBhJC6zqSs/it-s-okay-to-be-at-least-a-little-irrational", "linkUrl": "https://www.lesswrong.com/posts/Yiv9BeroBhJC6zqSs/it-s-okay-to-be-at-least-a-little-irrational", "postedAtFormatted": "Sunday, April 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20It's%20okay%20to%20be%20(at%20least%20a%20little)%20irrational&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIt's%20okay%20to%20be%20(at%20least%20a%20little)%20irrational%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYiv9BeroBhJC6zqSs%2Fit-s-okay-to-be-at-least-a-little-irrational%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=It's%20okay%20to%20be%20(at%20least%20a%20little)%20irrational%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYiv9BeroBhJC6zqSs%2Fit-s-okay-to-be-at-least-a-little-irrational", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYiv9BeroBhJC6zqSs%2Fit-s-okay-to-be-at-least-a-little-irrational", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 736, "htmlBody": "<p>Caused by: <a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately/\">Purchase Fuzzies and Utilons Separately</a><br /><br />As most readers will know by now, if you're donating to a charity, <a href=\"http://www.overcomingbias.com/2007/07/bad-balance-bia.html\">it doesn't make sense</a> to spread your donations across several charities (assuming you're primarily trying to maximize the amount of good done). You'll want to pick the charity where your money does the most good, and then donate as much as possible to that one. Most readers will also be aware that this isn't intuitive to most people - many will instinctively try to spread their money across several different causes.<br /><br />I'm spending part of my income on charity, too. Admittedly, this isn't much - 30 USD each month - but then neither is my income as a student. Previously I had been spreading that sum to three different charities, each of them getting an equal amount. On at least two different venues, people had (not always knowingly) tried to <a href=\"http://www.overcomingbias.com/2007/07/bad-balance-bia.html?cid=77119746#comment-77119746\">talk me out of it</a>, and I did feel that their arguments were pretty strong. Still, I didn't change my ways, even though there was mental pressure building up, trying to push me in that direction. There were actually even some other charities I was considering also donating to, even though I knew I probably shouldn't.<br /><br />Then I read Eliezer's <a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately/\">Purchase Fuzzies and Utilons Separately</a>. Here was a post saying, in essence, that it's <em>okay</em> to spend some of your money in what amounted to an irrational way. Yes, go ahead and spread your money, and go ahead and use some of it just to purchase warm fuzzies. You're just human, after all. Just try to make sure you still donate more to a utilon maximizer than to purchasing the fuzzies.<br /><br />Here I was, with a post that allowed me to stop rationalizing reasons for why spreading money was good, and instead spread them because I was honestly selfish and just buying a good feeling. Now, I didn't need to worry about being irrational in having diversified donations. So since it was okay, I logged in to PayPal, cancelled the two monthly donations I had going to the other organizations, and tripled the amount of money that I was giving to the Institute Which Shall Not Be Named.<br /><br />Not exactly the outcome one might have suspected.<br /><a id=\"more\"></a></p>\r\n<p>A theme that has come up several times is that it's easier to lie to others if you believe in the lies yourself. Being in a community where rationality is highly valued, many people will probably want to avoid appearing irrational, lest they lose the respect of others. They want to signal rationality. One way to avoid admitting irrationality to others is by not admitting it to yourself. But then, if you never even admit your irrationality to yourself, you'll have a hard time of getting over it.<br /><br />If, on the other hand, the community makes it clear that <em>it's okay</em> to be irrational, for as long as you're trying to get rid of that, then you can actually <em>become</em> more rational. You don't need to rationalize reasons why you're not being irrational, you can accept that you are irrational and then change it. Eliezer's post did that for me, for one particular irrationality [1]. So let me say that out loud: <strong>It's okay to be irrational, and to admit that. You are only a human.</strong><br /><br />Failing to realize this is probably a failure mode for many communities which try to extinguish a specific way of thinking. If you make a behavior seem like it's just outright bad, something which nobody should ever admit to, then you'll get a large amount of people who'll never admit to it - even when they should, in order to get over it.<br /><br />And it's not just a community thing, it's also an individual thing. Don't simply make it clear to others that some irrationality is okay: make it also clear for yourself. <em>It's okay to be irrational</em>.</p>\r\n<p>&nbsp;</p>\r\n<p>Footnote [1]: Note that Eliezer's post didn't extinguish the irrationality <em>entirely</em>. I'm still intending on using some of my money on purchasing warm fuzzies, once my total income is higher. But then I'll actually admit that that's what I'm doing, and treat my purchases of fuzzies and utilions as separate cases. And the utilon purchasing <em>will</em> be the one getting more money.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "3ee9k6NJfcGzL6kMS": 1, "JsJPrdgRGRqnci8cZ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Yiv9BeroBhJC6zqSs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 64, "baseScore": 61, "extendedScore": null, "score": 9.3e-05, "legacy": true, "legacyId": "392", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 61, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 59, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3p3CYauiX8oLjmwRF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-12T21:41:26.537Z", "modifiedAt": null, "url": null, "title": "Marketing rationalism", "slug": "marketing-rationalism", "viewCount": null, "lastCommentedAt": "2016-02-11T15:38:29.250Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/G5bDjtSbJwbXuji4r/marketing-rationalism", "pageUrlRelative": "/posts/G5bDjtSbJwbXuji4r/marketing-rationalism", "linkUrl": "https://www.lesswrong.com/posts/G5bDjtSbJwbXuji4r/marketing-rationalism", "postedAtFormatted": "Sunday, April 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Marketing%20rationalism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMarketing%20rationalism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5bDjtSbJwbXuji4r%2Fmarketing-rationalism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Marketing%20rationalism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5bDjtSbJwbXuji4r%2Fmarketing-rationalism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5bDjtSbJwbXuji4r%2Fmarketing-rationalism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 348, "htmlBody": "<p>Suppose you're a protestant, and you want to convince other people to do what the Bible says to do.&nbsp; Would you persuade them by showing them that the Bible says that they should?</p>\n<p>Now suppose you're a rationalist, and you want to convince other people to be rational.&nbsp; Would you persuade them with a rational argument?</p>\n<p>If not, how?</p>\n<p>ADDED:&nbsp; I'm not talking about persuading others who already accept reason as final arbiter to adopt Bayesian principles, or anything like that.&nbsp; I mean persuading Joe on the street who does whatever feels good, and feels pretty good about that.&nbsp; Or a doctor of philosophy who believes that truth is relative and reason is a social construct.&nbsp; Or a Christian who believes that the Bible is God's Word, and things that contradict the Bible must be false.</p>\n<p>Christians don't place a whole set of the population off-limits and say, \"These people are unreachable; their paradigms are too different.\"&nbsp; They go after everyone.&nbsp; There is no class of people whom they are unsuccessful with.</p>\n<p>Saying that we have to play by a set of self-imposed rules in the competition for the minds of humanity, while our competitors don't, means we will lose.&nbsp; And isn't rationality about <em>winning?</em></p>\n<p>ADDED:&nbsp; People are missing the point that the situation is symmetrical for religious evangelists.&nbsp; For them to step outside of their worldview, and use reason to gain converts, is as epistemically dangerous for them, as it is for us to gain converts using something other than reason.&nbsp; Contemporary Christians consider themselves on good terms with reason; but if you look back in history, you'll find that <a href=\"/lw/b0/antirationality_quotes/\">many of the famous and influential Christian theologians (starting with Paul) made explicit warnings against the temptation of reason</a>.&nbsp; The proceedings from Galileo's trial contain some choice bits on the relation between reason and faith.</p>\n<p>Using all sorts of persuasive techniques that are not grounded in religious truth, and hence are epistemically repulsive to them and corrosive to their belief system, has proven a winning strategy for all religions.&nbsp; It's a compromise; but these compromises did not weaken those religions.&nbsp; They made them stronger.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "zv7v2ziqexSn5iS9v": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "G5bDjtSbJwbXuji4r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 16, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "394", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kWRFfWfhrS6m4Fibm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-13T01:26:15.635Z", "modifiedAt": null, "url": null, "title": "Bystander Apathy", "slug": "bystander-apathy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:28.287Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K5nq3KcDXaGm7QQWR/bystander-apathy", "pageUrlRelative": "/posts/K5nq3KcDXaGm7QQWR/bystander-apathy", "linkUrl": "https://www.lesswrong.com/posts/K5nq3KcDXaGm7QQWR/bystander-apathy", "postedAtFormatted": "Monday, April 13th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bystander%20Apathy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABystander%20Apathy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK5nq3KcDXaGm7QQWR%2Fbystander-apathy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bystander%20Apathy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK5nq3KcDXaGm7QQWR%2Fbystander-apathy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK5nq3KcDXaGm7QQWR%2Fbystander-apathy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 964, "htmlBody": "<p>The bystander effect, also known as bystander apathy, is that larger groups are less likely to act in emergencies - not just individually, but collectively.&nbsp; Put an experimental subject alone in a room and let smoke start coming up from under the door.&nbsp; 75% of the subjects will leave to report it.&nbsp; Now put <em>three</em> subjects in the room - real subjects, none of whom know what's going on.&nbsp; On only 38% of the occasions will <em>anyone</em> report the smoke.&nbsp; Put the subject with two confederates who ignore the smoke, and they'll only report it 10% on the time - even staying in the room until it becomes hazy.&nbsp; (Latane and Darley 1969.)</p>\n<p>On the standard model, the two primary drivers of bystander apathy are:</p>\n<ul>\n<li><em>Diffusion of responsibility</em> - everyone hopes that someone else will be first to step up and incur any costs of acting.&nbsp; When no one does act, being part of a crowd provides an excuse and reduces the chance of being held personally responsible for the results.</li>\n<li><a href=\"/lw/3h/why_our_kind_cant_cooperate\"><em>Pluralistic ignorance</em></a> - people try to <em>appear </em>calm while looking for cues, and see... that the others appear calm.</li>\n</ul>\n<p>Cialdini (2001):</p>\n<blockquote>\n<p>Very often an emergency is not obviously an emergency.&nbsp; Is the man lying in the alley a heart-attack victim or a drunk sleeping one off?&nbsp; ...&nbsp; In times of such uncertainty, the natural tendency is to look around at the actions of others for clues.&nbsp; We can learn from the way the other witnesses are reacting whether the event is or is not an emergency.&nbsp; What is easy to forget, though, is that everybody else observing the event is likely to be looking for social evidence, too.&nbsp; Because we all prefer to appear poised and unflustered among others, we are likely to search for that evidence placidly, with brief, camouflaged glances at those around us.&nbsp; Therefore everyone is likely to see everyone else looking unruffled and failing to act.</p>\n</blockquote>\n<p>Cialdini suggests that if you're ever in emergency need of help, you point to <em>one single </em>bystander and ask them for help - making it very clear to whom you're referring.&nbsp; Remember that the <em>total</em> group, combined, may have less chance of helping than one individual.<a id=\"more\"></a></p>\n<p>I've mused a bit on the evolutionary psychology of the bystander effect.&nbsp; Suppose that in the ancestral environment, most people in your band were likely to be at least a little related to you - enough to be worth saving, if you were the only one who could do it.&nbsp; But if there are two others present, then the <em>first</em> person to act incurs a cost, while the other two both reap the <em>genetic</em> benefit of a partial relative being saved.&nbsp; Could there have been an arms race for who waited the longest?</p>\n<p>As far as I've followed this line of speculation, it doesn't seem to be a good explanation - at the point where the whole group is failing to act, a gene that helps immediately ought to be able to invade, I would think.&nbsp; The experimental result is not a long wait before helping, but simply failure to help: if it's a genetic benefit to help when you're the only person who can do it (as <em>does</em> happen in the experiments) then the group equilibrium should not be <em>no</em> one helping (as happens in the experiments).</p>\n<p>So I don't think an arms race of delay is a plausible evolutionary explanation.&nbsp; More likely, I think, is that we're looking at a nonancestral problem.&nbsp; If the experimental subjects actually <em>know</em> the apparent victim, the chances of helping go way up (i.e., we're not looking at the correlate of helping an actual fellow band member).&nbsp; If I recall correctly, if the experimental subjects know each <em>other</em>, the chances of action also go up.</p>\n<p>Nervousness about public action may also play a role.&nbsp; If Robin Hanson is right about <a href=\"http://www.overcomingbias.com/2009/04/choke-to-submit.html\">the evolutionary role of \"choking\"</a>, then being <em>first</em> to act in an emergency might also be taken as a dangerous bid for high status.&nbsp; (Come to think, I can't actually recall seeing <em>shyness </em>discussed in analyses of the bystander effect, but that's probably <a href=\"http://www.overcomingbias.com/2007/10/no-one-knows-wh.html\">just my poor memory</a>.)</p>\n<p>Can the bystander effect be explained primarily by diffusion of moral responsibility?&nbsp; We could be cynical and suggest that people are mostly interested in <em>not being blamed</em> for not helping, rather than having any positive desire to help - that they mainly wish to escape antiheroism and possible retribution.&nbsp; Something like this may well be a contributor, but two observations that mitigate against it are (a) the experimental subjects did not report smoke coming in from under the door, even though it could well have represented a strictly selfish threat and (b) telling people about the bystander effect reduces the bystander effect, even though they're no more likely to be held publicly responsible thereby.</p>\n<p>In fact, the bystander effect is one of the main cases I recall offhand where telling people about a bias actually seems able to strongly reduce it - maybe because the appropriate way to compensate is so obvious, and it's not easy to <em>over</em>compensate (as when you're trying to e.g. adjust your calibration).&nbsp; So we should be careful not to be too cynical about the implications of the bystander effect and diffusion of responsibility, if we interpret individual action in terms of a cold, calculated attempt to avoid public censure.&nbsp; People seem at least to sometimes hold <em>themselves</em> responsible, once they realize they're the only ones who know enough about the bystander effect to be likely to act.</p>\n<p>Though I wonder what happens if you know that you're part of a crowd where <em>everyone</em> has been told about the bystander effect...</p>\n<hr />\n<p>Cialdini, R. (2001.)&nbsp; <em>Influence: Science and Practice.</em>&nbsp; Boston, MA: Allyn and Bacon.</p>\n<p>Latane, B. and Darley, J. (1969.)&nbsp; Bystander \"Apathy\", <em>American Scientist</em>, <strong>57</strong>: 244-268.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "5f5c37ee1b5cdee568cfb150": 10}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K5nq3KcDXaGm7QQWR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 40, "extendedScore": null, "score": 6.1e-05, "legacy": true, "legacyId": "343", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "collective-apathy-and-the-internet", "canonicalPrevPostSlug": "purchase-fuzzies-and-utilons-separately", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 40, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7FzD7pNm9X68Gp5ZC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-13T08:43:12.255Z", "modifiedAt": null, "url": null, "title": "Persuasiveness vs Soundness", "slug": "persuasiveness-vs-soundness", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:26.983Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Patrick", "createdAt": "2009-02-27T08:09:44.663Z", "isAdmin": false, "displayName": "Patrick"}, "userId": "KC7mjSorWj2XsdL3v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bDK63YCNoFT5wRSyb/persuasiveness-vs-soundness", "pageUrlRelative": "/posts/bDK63YCNoFT5wRSyb/persuasiveness-vs-soundness", "linkUrl": "https://www.lesswrong.com/posts/bDK63YCNoFT5wRSyb/persuasiveness-vs-soundness", "postedAtFormatted": "Monday, April 13th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Persuasiveness%20vs%20Soundness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APersuasiveness%20vs%20Soundness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbDK63YCNoFT5wRSyb%2Fpersuasiveness-vs-soundness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Persuasiveness%20vs%20Soundness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbDK63YCNoFT5wRSyb%2Fpersuasiveness-vs-soundness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbDK63YCNoFT5wRSyb%2Fpersuasiveness-vs-soundness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 452, "htmlBody": "<p>Compare the following two arguments.</p>\n<ol>\n<li>E. is described by the following <a href=\"http://en.wikipedia.org/wiki/Euclidean_geometry#Axioms\">axioms</a></li>\n<li>Therefore under E. The square of the longest side of a&nbsp; right angle triangle is equal to the sum of the squares of the remaining two sides.</li>\n</ol> <ol>\n<li>All men are mortal.</li>\n<li>Socrates is a man.</li>\n<li>Therefore Socrates is mortal.</li>\n</ol>\n<p>Naively, the second argument seems tautological, whereas with the first it's much harder to tell. Of course in reality the first argument is the tautology and the second argument is the more dubious one. The phrase \"immortal man\" doesn't seem contradictory, and how do we know Socrates is a man? He could be an android doppleganger. And the first argument's conclusion completely follows from euclid's axioms. Euclid and 100s of other mathematicians have proved that it does.</p>\n<p>So, why does the average human think the opposite?<a id=\"more\"></a></p>\n<p>The arguments that change what we think, and the arguments that would change what a logically omniscient bayesian superman wielding <a href=\"http://www.overcomingbias.com/2007/09/occams-razor.html\">Solomonoff's Lightsaber</a> thinks are not very tightly correlated. In fact, there's a whole catalogue dedicated to finding out types of arguments we're persuaded by that a bayesian superman wouldn't be, the logical fallacies. But it's not just argument structure that causes us to lose our way, another factor is how well the argument is written.</p>\n<p>People are more persuaded by essays from Eliezer Yudkowsky, Bertrand Russell, Paul Graham or George Orwell than they would be from a forum post by an average 13 year old atheist, even if they both make the exact same point. This threw me for a bit of a loop, until I realized that Eliezer was pitching to bayesian supermen as well as us mortals. How well stylish writing correlates to the truth compared to unstylish writing is nowhere near how much we are persuaded by stylish writing compared to unstylish writing.&nbsp;</p>\n<p>There's also the dreaded intuition pump, I think the reason it's so maligned is because it makes things much more persuasive without making them any more sound. A well chosen metaphor can do more to the human mind than a thousand pages of logic. Of course, we *want* intuition pumps for things that are actually true, because we want people to persuaded of things that are true and more importantly, we want them to be able to reason about things that are true. A good metaphor can enable this reasoning far more effectively than a list of axioms.</p>\n<p>The problem lies in both directions, we aren't always persuaded by cogent arguments, and we are sometime persuaded by crappy arguments that are delivered well. I put it to Less Wrong readers, how can we reduce the gap between what we are persuaded by, and what a bayesian superman is persuaded by?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "ZzxvopS4BwLuQy42n": 1, "FtT2T9bRbECCGYxrL": 1, "JHYaBGQuuKHdwnrAK": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bDK63YCNoFT5wRSyb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 0, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "397", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-13T12:01:06.657Z", "modifiedAt": null, "url": null, "title": "Declare your signaling and hidden agendas  ", "slug": "declare-your-signaling-and-hidden-agendas", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:34.000Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yCjofyFSoAq73LT2A/declare-your-signaling-and-hidden-agendas", "pageUrlRelative": "/posts/yCjofyFSoAq73LT2A/declare-your-signaling-and-hidden-agendas", "linkUrl": "https://www.lesswrong.com/posts/yCjofyFSoAq73LT2A/declare-your-signaling-and-hidden-agendas", "postedAtFormatted": "Monday, April 13th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Declare%20your%20signaling%20and%20hidden%20agendas%20%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeclare%20your%20signaling%20and%20hidden%20agendas%20%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCjofyFSoAq73LT2A%2Fdeclare-your-signaling-and-hidden-agendas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Declare%20your%20signaling%20and%20hidden%20agendas%20%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCjofyFSoAq73LT2A%2Fdeclare-your-signaling-and-hidden-agendas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCjofyFSoAq73LT2A%2Fdeclare-your-signaling-and-hidden-agendas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 853, "htmlBody": "<p><strong>Follow-up to:</strong> <a href=\"/lw/aw/its_okay_to_be_at_least_a_little_irrational/\">It's okay to be (at least a little) irrational</a><br /><br />Many science journals require their authors to <a href=\"http://www.bmj.com/cgi/content/full/317/7154/291/DC1\">declare</a> any competing interests they happen to have. For instance, if you're submitting a study about the health effects of tobacco, and you happen to sit on the board of directors of a major tobacco company, you're supposed to say that out loud.&nbsp;<br /><br />The process obviously isn't perfect, as most journals don't have the resources to ensure their authors do actually declare all competing interests. On the whole, though, it helps protect both the readers and the authors. The readers, because they'll know to be more careful in evaluating the reports of researchers who might be biased. The authors, because by declaring any competing interests upfront, they're protected from later accusations of dishonesty. (That's the theory, at least. In practice, authors <a href=\"http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1121658\">often don't declare</a> their interests, even if they should.)<br /><br /><a href=\"http://www.overcomingbias.com/signaling/\">Signaling</a> has been discussed a lot on Overcoming Bias, though a bit less on Less Wrong. A large fraction of people's behavior is actually intended to signal some qualities to others, though this <a href=\"http://www.overcomingbias.com/2009/02/beware-ideal-screen-theories.html\">isn't</a> <a href=\"http://www.overcomingbias.com/2009/02/the-evolutionarycognitive-boundary.html\">necessarily</a> a conscious process. On the other hand, it often is. As seasoned OB/LW readers, it seems to me like many would instinctively try to avoid giving the impression of <a href=\"http://www.overcomingbias.com/2007/01/excess_signalin.html\">excess signaling</a>. We're rationalists, after all! We're trying to find the truth, not show off or impress others of our worth!<br /><br />As if we even <em>could</em> avoid trying to make a good impression on others, or avoid having other kinds of hidden agendas. <a href=\"http://www.overcomingbias.com/2007/12/every-cause-wan.html\">We're not any less human simply because we have rallied our rationality's banner</a>. (Not to mention that signaling isn't a bad thing, by itself - humanity would be in a very poor state if we didn't have <em>any</em> signals about what others were like.) So, in the interest of <a href=\"/lw/aw/its_okay_to_be_at_least_a_little_irrational/\">self-honesty</a>, I suggest we all begin <em>explicitly declaring our (conscious) hidden agendas and signaling intentions</em> when writing posts. As with the policy of scholarly journals, this will help both readers and writers, and in this case also serve a third and fourth function - making us more honest to ourselves, and make people realize that it's okay to have hidden agendas, and that they don't have to pretend they don't have any. I'll start out with mine.</p>\r\n<p><a id=\"more\"></a></p>\r\n<p>I have roughly classified my hidden agendas at three different levels of severity. A \"<strong>mild</strong>\" agenda had a small impact on the behavior in question (for instance, writing a particular post), but I would have done it either way. A \"<strong>strong</strong>\" agenda means the behavior probably wouldn't have happened without the hidden agenda. A \"<strong>moderate</strong>\" agenda means that I'm not able to say either way - the behavior could have happened anyway, or then it might have not. I recognize that these are merely my <em>conscious </em>estimates of the different strengths and agendas, which are likely to be mistaken. They are, however, better than nothing.<br /><br /><span style=\"text-decoration: underline;\">Posting here in general</span> - A desire to seek fame and respect in a community of rationalists, and to prove my worth as one (<strong>moderate</strong>). A desire to indicate that I have read and internalized the previous postings on OB, by linking to any relevant previous articles mentioning related concepts (<strong>moderate </strong>when it comes to linking, but <strong>mild</strong> when it comes to writing the articles - without the desire I might not have thrown in so many links, but I'd probably have written the posts anyway). <br /><a href=\"/lw/14/does_blind_review_slow_down_science/\">Does blind review slow down science?</a> - Uncertain, as I don't remember my exact motivations for writing this post anymore.<br /><a href=\"/lw/1b/the_golem/\">The Golem</a> - A <strong>mild</strong> desire to indirectly promote polyamory (by linking to a book about it as the source of the quote).<br /><a href=\"/lw/2v/the_tragedy_of_the_anticommons/\">The Tragedy of the Anticommons</a> - A <strong>mild to moderate</strong> desire to signal scholarship. My previous posts cited two books and some research articles and now I cited a third book, to give the (mostly accurate) impression that I read a lot and survey the research literature when I want to form an opinion of something. <strong>Mild</strong> desire to nudge people in the direction of a resource pointing out the harms of patents and copyright in their current form (declaration of possibly competing interest: I'm a board member of the <a href=\"http://www.piraattipuolue.fi\">Finnish</a> <a href=\"http://en.wikipedia.org/wiki/Pirate_party\">Pirate Party</a>).<br /><a href=\"/lw/6i/deliberate_and_spontaneous_creativity/\">Deliberate and spontaneous creativity</a> - <strong>Mild to moderate</strong> desire to signal scholarship, again.<br /><a href=\"/lw/8z/rationalists_should_beware_rationalism/\">Rationalists should beware rationalism</a> - Looking over the post, I'm not certain of any of my motives anymore, be they overt or covert. Perhaps a <strong>mild to moderate</strong> desire to signal resistance to groupthink.<br /><a href=\"/lw/aj/too_much_feedback_can_be_a_bad_thing/\">Too much feedback can be a bad thing</a> - None that I can remember.<br /><a href=\"/lw/aw/its_okay_to_be_at_least_a_little_irrational/\">It's okay to be (at least a little) irrational</a> - <strong>Mild</strong> desire to signal support for the Institute Which Shall Not Be Named. <strong>Mild</strong> desire to signal altruism by bringing up my regular donations.<br /><span style=\"text-decoration: underline;\">This post</span> - <strong>Strong</strong> desire to signal honesty.&nbsp;<strong>Mild</strong> desire to more effectively promote my previous hidden agendas, by stating them out loud.<br /><br />What are yours?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Q6P8jLn8hH7kbuXRr": 1, "nANxo5C4sPG9HQHzr": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yCjofyFSoAq73LT2A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 25, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "398", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Yiv9BeroBhJC6zqSs", "fsSoAMsntpsmrEC6a", "d4pyYJ8Xdi5o6GJYT", "RAftfkp3NqDDR2o79", "5aaPPRAM6JdLqceqX", "b88EtWvjyRQc89XzT", "GsiTXp2v3SRfG8ugK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-13T17:28:58.896Z", "modifiedAt": null, "url": null, "title": "GroupThink, Theism ... and the Wiki", "slug": "groupthink-theism-and-the-wiki", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.484Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "byrnema", "createdAt": "2009-03-20T18:02:38.305Z", "isAdmin": false, "displayName": "byrnema"}, "userId": "SCnD6W8NiztYBN39M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AErxyDpiBy7CyM2Mk/groupthink-theism-and-the-wiki", "pageUrlRelative": "/posts/AErxyDpiBy7CyM2Mk/groupthink-theism-and-the-wiki", "linkUrl": "https://www.lesswrong.com/posts/AErxyDpiBy7CyM2Mk/groupthink-theism-and-the-wiki", "postedAtFormatted": "Monday, April 13th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20GroupThink%2C%20Theism%20...%20and%20the%20Wiki&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroupThink%2C%20Theism%20...%20and%20the%20Wiki%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAErxyDpiBy7CyM2Mk%2Fgroupthink-theism-and-the-wiki%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=GroupThink%2C%20Theism%20...%20and%20the%20Wiki%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAErxyDpiBy7CyM2Mk%2Fgroupthink-theism-and-the-wiki", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAErxyDpiBy7CyM2Mk%2Fgroupthink-theism-and-the-wiki", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 536, "htmlBody": "<p>In response to the&nbsp;<a href=\"/lw/9n/the_uniquely_awful_example_of_theism\"> The uniquely awful example of theism,</a> I presented myself as a datapoint of someone in the group who disagrees that theism is uncontroversially irrational.</p>\n<p>With a loss of considerable time, several karma points and two bad posts, I now retract my position.<a id=\"more\"></a></p>\n<p>Because I have deconverted? (Sorry, but no.)</p>\n<p>I had a working assumption (inferred from<a href=\"/lw/31/what_do_we_mean_by_rationality\"> here</a>) that rationality meant believing that all beliefs must be rigorously consistent with empirical observation. I now think of this as a weak form of rationalism (see full definition below). A stronger form of rationalism held by (many, most?) rationalists is that there is no other valid source of knowledge. If we define a belief system as religious if and only if it claims knowledge that is independent of empirical experience (i.e., metaphysical) then it is trivially true that all religions are irrational -- using the stronger definition of rational.</p>\n<p>A disagreement of definitions is not really a disagreement. Someone suggested on the April open thread that we define \"rationality\". My idea of a definition would look something like this:</p>\n<p>&nbsp;</p>\n<p>Rationality assumes that:</p>\n<p>(1) The only source of knowledge is empirical experience.</p>\n<p>(2) The only things that are known are deduced from empirical experience by valid logical reasoning and mathematics.</p>\n<p>&nbsp;</p>\n<p>Weak Rationality assumes that:</p>\n<p>(1) The first source of knowledge is empirical experience.</p>\n<p>(2) The only things that are known with certainty are deduced from empirical experience by valid logical reasoning and mathematics.</p>\n<p>(3) Define a belief system as all knowledge deduced from empirical observation with all metaphysical beliefs, if any. Then the belief system is rational (<em>nearly</em> rational or <em>weakly </em>rational) if the belief system is internally consistent.</p>\n<p>&nbsp;</p>\n<p>Probably these definitions have been outlined somewhere better than they are here. Perhaps I have misplaced emphasis and certainly there are important nuances and variations. Whether this definition works or not, I think it's important to have a working set of definitions that we all agree upon. The wiki has just started out, but I think it's a terrific idea and worth putting time into. Every time you struggle with finding the right definition for something I suggest you add your effort to the group knowledge by adding that definition to the Wiki.</p>\n<p>I made the accusation that the consensus about religion was due to \"group think\". In its pejorative sense, group think means everyone thinks the same thing because dissent is eliminated in some way. However, group think can also be the common set of definitions that we are working with. I think that having a well-defined group think will make posting much more efficient for everyone (with fewer semantic confusions) and will also aid newcomers.</p>\n<p>The \"group think\" defined in the Wiki would certainly need to be dynamic, nuanced and inclusive. A Wiki is already dynamic. To foster nuance and inclusion, the wiki might prompt for alternatives. For example, if I posted the two definitions of rationality above I might also write, \"Do you have another working definition of rationalism? Please add it here.\" so that a newcomer to LW would know they were not excluded from the \"group of rationalists\" if they have a different definition.</p>\n<p>What are some definitions that we could/should add to the Wiki? (I've noticed that \"tolerance\", as a verb or a noun, is problematic.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ALwRRZqvhaop8gxkT": 1, "gHCNhqxuJq2bZ2akb": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AErxyDpiBy7CyM2Mk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -2, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "399", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 62, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dLL6yzZ3WKn8KaSC3", "RcZCwxFiZzE6X7nsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-14T00:02:19.161Z", "modifiedAt": null, "url": null, "title": "Collective Apathy and the Internet", "slug": "collective-apathy-and-the-internet", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.792Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NnQbfLo868wgnHF4n/collective-apathy-and-the-internet", "pageUrlRelative": "/posts/NnQbfLo868wgnHF4n/collective-apathy-and-the-internet", "linkUrl": "https://www.lesswrong.com/posts/NnQbfLo868wgnHF4n/collective-apathy-and-the-internet", "postedAtFormatted": "Tuesday, April 14th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Collective%20Apathy%20and%20the%20Internet&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACollective%20Apathy%20and%20the%20Internet%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnQbfLo868wgnHF4n%2Fcollective-apathy-and-the-internet%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Collective%20Apathy%20and%20the%20Internet%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnQbfLo868wgnHF4n%2Fcollective-apathy-and-the-internet", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnQbfLo868wgnHF4n%2Fcollective-apathy-and-the-internet", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 725, "htmlBody": "<p>Yesterday I convered <a href=\"/lw/9j/bystander_apathy/\">the bystander effect</a>, aka bystander apathy: given a fixed problem situation, a <em>group </em>of bystanders is actually <em>less</em> likely to act than a <em>single</em> bystander.&nbsp; The standard explanation for this result is in terms of pluralistic ignorance (if it's not clear whether the situation is an emergency, each person tries to <em>look </em>calm while darting their eyes at the other bystanders, and sees other people <em>looking </em>calm) and diffusion of responsibility (everyone hopes that someone else will be first to act; being part of a crowd diminishes the individual pressure to the point where no one acts).</p>\n<p>Which may be a symptom of our <a href=\"http://www.overcomingbias.com/2007/11/evolutionary-ps.html\">hunter-gatherer</a> coordination mechanisms being defeated by modern conditions.&nbsp; You didn't usually <a href=\"/lw/64/helpless_individuals/\">form task-forces with strangers</a> back in the ancestral environment; it was mostly people you knew.&nbsp; And in fact, when all the subjects know each other, the bystander effect diminishes.</p>\n<p>So I know this is an amazing and revolutionary observation, and I hope that I don't kill any readers outright from shock by saying this: but people seem to have a hard time reacting constructively to problems encountered over the Internet.</p>\n<p>Perhaps because our innate coordination instincts are not tuned for:</p>\n<ul>\n<li>Being part of a group of strangers.&nbsp; (When all subjects know each other, the bystander effect diminishes.)</li>\n<li>Being part of a group of unknown size, of strangers of unknown identity.</li>\n<li>Not being in physical contact (or visual contact); not being able to exchange meaningful glances.</li>\n<li>Not communicating in real time.</li>\n<li>Not being much beholden to each other for other forms of help; not being codependent on the group you're in.</li>\n<li>Being shielded from reputational damage, or the fear of reputational damage, by your own apparent anonymity; no one is visibly looking at you, before whom your reputation might suffer from inaction.</li>\n<li>Being part of a large collective of other inactives; no one will single out you to blame.</li>\n<li>Not hearing a voiced plea for help.<a id=\"more\"></a></li>\n</ul>\n<p>Etcetera.&nbsp; I don't have a brilliant solution to this problem.&nbsp; But it's the sort of thing that I would wish for potential dot-com cofounders to ponder explicitly, rather than wondering how to throw sheep on Facebook.&nbsp; (Yes, I'm looking at <em>you</em>, Hacker News.)&nbsp; There are online activism web apps, but they tend to be along the lines of <em>sign this petition! yay, you signed something!</em> rather than <em>How can we counteract the bystander effect, restore motivation, and work with native group-coordination instincts, over the Internet?</em></p>\n<p>Some of the things that come to mind:</p>\n<ul>\n<li>Put a video of someone asking for help online.</li>\n<li>Put up names and photos or even brief videos if available of the <em>first</em> people who helped (or have some redditish priority algorithm that depends on a combination of amount-helped and recency).</li>\n<li>Give helpers a video thank-you from the founder of the cause that they can put up on their \"people I've helped\" page, which with enough standardization could be partially or wholly assembled automatically and easily embedded in their home webpage or Facebook account.</li>\n<li>Find a <em>non-annoying </em>idiom for \"Tell a friend about cause X\"; allow referrer link codes; then show people how many others they've evangelized (how many people who initially got here using referrer code X actually contributed or took some other action).</li>\n<li>(All of the above applies not just to donations, but to open-source projects to which people have contributed code.&nbsp; Or if people really do want nothing but signatures on a petition, then for signatures.&nbsp; There are ways to help besides money&mdash;even though <a href=\"/lw/65/money_the_unit_of_caring/\">money is usually the most effective</a>.&nbsp; The main thing is that the form of help has to be verifiable online.)</li>\n<li>Make it easier for people to offer monetary bounties on subtasks whose performance is verifiable.</li>\n</ul>\n<p>But mostly I just hand you an open, unsolved problem: make it possible / easier for groups of strangers to coalesce into an effective task force over the Internet, in defiance of the usual failure modes and the default reasons why this is a non-ancestral problem.&nbsp; Think of that old statistic about Wikipedia representing <a href=\"http://www.shirky.com/herecomeseverybody/2008/04/looking-for-the-mouse.html\">1/2,000</a> of the time spent in the US alone on watching television.&nbsp; There's quite a lot of fuel out there, if there were only such a thing as an effective engine...</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MXcpQvaPGtXpB6vkM": 1, "JsJPrdgRGRqnci8cZ": 1, "chuP2QqQycjD8qakL": 1, "5f5c37ee1b5cdee568cfb150": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NnQbfLo868wgnHF4n", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 41, "extendedScore": null, "score": 6.2e-05, "legacy": true, "legacyId": "346", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "incremental-progress-and-the-valley", "canonicalPrevPostSlug": "bystander-apathy", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 42, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K5nq3KcDXaGm7QQWR", "f42BHX7rMw2dyFJfT", "ZpDnRCeef2CLEFeKM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-14T18:15:18.104Z", "modifiedAt": null, "url": null, "title": "Tell it to someone who doesn't care", "slug": "tell-it-to-someone-who-doesn-t-care", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:33.304Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DjM7cjeRLNBosz65Q/tell-it-to-someone-who-doesn-t-care", "pageUrlRelative": "/posts/DjM7cjeRLNBosz65Q/tell-it-to-someone-who-doesn-t-care", "linkUrl": "https://www.lesswrong.com/posts/DjM7cjeRLNBosz65Q/tell-it-to-someone-who-doesn-t-care", "postedAtFormatted": "Tuesday, April 14th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tell%20it%20to%20someone%20who%20doesn't%20care&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATell%20it%20to%20someone%20who%20doesn't%20care%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDjM7cjeRLNBosz65Q%2Ftell-it-to-someone-who-doesn-t-care%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tell%20it%20to%20someone%20who%20doesn't%20care%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDjM7cjeRLNBosz65Q%2Ftell-it-to-someone-who-doesn-t-care", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDjM7cjeRLNBosz65Q%2Ftell-it-to-someone-who-doesn-t-care", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 929, "htmlBody": "<p>Followup to <a href=\"/lw/ay/marketing_rationalism/\">Marketing rationalism</a></p>\n<h4>Target fence-sitters<br /></h4>\n<p>American culture frames issues as debates between two sides.&nbsp; The inefficacy of debates is amazing.&nbsp; You can attend debates on a subject for years without ever seeing anyone change their mind.&nbsp; I think this is because of who attends debates.&nbsp; People listen to debates because they <em>care</em> about the issue.&nbsp; And they only care about the issue because they've already taken a side.&nbsp; Caring then innoculates them to reason.</p>\n<p><em>If</em> the debate really can be approximated by a binary decision, then the people you want to talk to are the fence-sitters.&nbsp; And they aren't there.</p>\n<p>This reminded me of my <a href=\"/lw/2b/so_you_say_youre_an_altruist/1dq?context=1\">\"wound-healing\" theory of international aid</a>.&nbsp; I'll float a similar idea for social debate:&nbsp; In order to win society over to a view in the long run, you should target the people who don't care much one way or the other.&nbsp; Politicians already do this.</p>\n<p>So how do you get them to listen?&nbsp; They won't come to your debate, or your conference, or your website.&nbsp; Here are some ways:</p>\n<ul>\n<li>Fiction.&nbsp; Think <a href=\"http://en.wikipedia.org/wiki/Atlas_Shrugged\"><em>Atlas Shrugged</em></a>.&nbsp; People will read a novel or watch a movie even if they're not interested in the issues that it's about.</li>\n<li>The Christian church teaches that evangelism happens through friends.&nbsp; Big church-tent revival meetings have been effective now and then; but most conversions happen one person at a time.</li>\n<li>Marketing.&nbsp; There's a much-larger-than-multibillion-dollar industry that does nothing except try to solve the problem of selling things to people who aren't interested in them.&nbsp; Too bad I don't know anything about it.</li>\n<li>Teaching kids.&nbsp; (We like to say that a child should grow up to the age where they can make their own decisions.&nbsp; But the unbiased child is a myth.)&nbsp; The public consensus is already to teach science rather than religion in school.&nbsp; I'm happy with that consensus and don't think it needs to be pushed further by teaching rationalist ideology.<a id=\"more\"></a></li>\n</ul>\n<p>(When I combine this theory with the observation that most people don't change their worldview or their preferences much after the age of maybe 15, I come up with the idea that most cultural change is driven by the random drift of the opinions of children.)</p>\n<h4>Gravitational debate<br /></h4>\n<p>But there are many instances of inspirational books targeted at people already well on one side of an issue, that inspired people to action, or had a strong influence on people without flipping them from a 0 to a 1.&nbsp; <em>The God Delusion</em>, for example; or <a title=\"Erwin Schr&ouml;dinger\" href=\"http://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger\">Schr&ouml;dinger</a>'s <a href=\"http://en.wikipedia.org/wiki/What_is_Life%3F_(Schr%C3%B6dinger)\"><em>What is Life?</em></a>.</p>\n<p>So here's theory number 2: The gravitational model of debate.&nbsp; People adjust their opinions in response to the opinions of the people around them.&nbsp; If a lot of the people around Jack shift their opinions to the right, Jack is likely to shift his opinion to the right.&nbsp; I suspect that Jack is more sensitive to opinions similar to his, than to opinions far away.&nbsp; So, like gravity, the strength of the attraction falls off with distance.&nbsp; An opinion sufficiently different from your own is repelling; it invokes an outgroup response rather than an attractive ingroup response.&nbsp; Rush Limbaugh causes some people to shift further left.&nbsp; We could posit a gravitational attraction between opinions that varies from positive at close range, to negative at long range.</p>\n<p>The consequences of this model are that, by shifting anyone's opinion in one direction, you may trigger a cascade of opinion-shifts that will move the median<sup>1</sup> opinion.&nbsp; This says you can write a book targeted anywhere on a spectrum of opinion, and have it effect the entire spectrum indirectly, moving some people from one side of the fence to the other even though they never heard of your book.</p>\n<p>One consequence is that, as in <a title=\"http://lesswrong.com/lw/79/aumann_voting_or_how_to_vote_when_youre_ignorant/\" href=\"/\">tug-of-war voting</a>, it's rational to try to persuade extremists to be even more extreme than you think is rational, in order to shift the median opinion in your chosen direction.&nbsp; (It might not be the most effective use of your time).</p>\n<p>Another consequence is that your book might not influence the masses if the distribution of opinions in opinion-space has large gaps.&nbsp; If, for instance, you write a rah-rah transhumanist book, this might have no effect on the population at large if few people have a partly-positive view of transhumanism - even if the gap in opinion-space isn't where your targeted audience would be.&nbsp; If the gap is large, your book might move median opinion farther away from your position.&nbsp; The Nazis had a tremendous effect on later 20th century philosophy, and perhaps art - but not in the way they would have liked.</p>\n<p>This model works best for emotional issues, or regulatory issues, in which one's position can be expressed by a real number or vector.&nbsp; In an academic debate, if you have <em>n</em> competing hypothesis, the range of possible positions is discrete; and opinion space probably isn't a metric space.</p>\n<h4>Compare and contrast?<br /></h4>\n<p>These two models make nearly opposite recommendations on how to influence public opinion.&nbsp; The first says to use marketing to target people who don't care.&nbsp; The second says (approximately) to examine the distribution of opinions, and express an opinion near a large mass of opinions, in the same direction as the vector from the median opinion to your desired opinion.</p>\n<p>I think both models have some truth to them.&nbsp; But which accounts for more of our behavior; and when should you use which model?</p>\n<p>&nbsp;</p>\n<p><sup>1</sup> (The median opinion is more relevant than the mean with one-person one-vote.&nbsp; The mean is more relevant with voting systems that let people express the strength of their opinions.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"rnvHPB3X2TiD5NMwY": 1, "FkzScn5byCs9PxGsA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DjM7cjeRLNBosz65Q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 25, "extendedScore": null, "score": 4.877773588144056e-07, "legacy": true, "legacyId": "384", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Followup to <a href=\"/lw/ay/marketing_rationalism/\">Marketing rationalism</a></p>\n<h4 id=\"Target_fence_sitters\">Target fence-sitters<br></h4>\n<p>American culture frames issues as debates between two sides.&nbsp; The inefficacy of debates is amazing.&nbsp; You can attend debates on a subject for years without ever seeing anyone change their mind.&nbsp; I think this is because of who attends debates.&nbsp; People listen to debates because they <em>care</em> about the issue.&nbsp; And they only care about the issue because they've already taken a side.&nbsp; Caring then innoculates them to reason.</p>\n<p><em>If</em> the debate really can be approximated by a binary decision, then the people you want to talk to are the fence-sitters.&nbsp; And they aren't there.</p>\n<p>This reminded me of my <a href=\"/lw/2b/so_you_say_youre_an_altruist/1dq?context=1\">\"wound-healing\" theory of international aid</a>.&nbsp; I'll float a similar idea for social debate:&nbsp; In order to win society over to a view in the long run, you should target the people who don't care much one way or the other.&nbsp; Politicians already do this.</p>\n<p>So how do you get them to listen?&nbsp; They won't come to your debate, or your conference, or your website.&nbsp; Here are some ways:</p>\n<ul>\n<li>Fiction.&nbsp; Think <a href=\"http://en.wikipedia.org/wiki/Atlas_Shrugged\"><em>Atlas Shrugged</em></a>.&nbsp; People will read a novel or watch a movie even if they're not interested in the issues that it's about.</li>\n<li>The Christian church teaches that evangelism happens through friends.&nbsp; Big church-tent revival meetings have been effective now and then; but most conversions happen one person at a time.</li>\n<li>Marketing.&nbsp; There's a much-larger-than-multibillion-dollar industry that does nothing except try to solve the problem of selling things to people who aren't interested in them.&nbsp; Too bad I don't know anything about it.</li>\n<li>Teaching kids.&nbsp; (We like to say that a child should grow up to the age where they can make their own decisions.&nbsp; But the unbiased child is a myth.)&nbsp; The public consensus is already to teach science rather than religion in school.&nbsp; I'm happy with that consensus and don't think it needs to be pushed further by teaching rationalist ideology.<a id=\"more\"></a></li>\n</ul>\n<p>(When I combine this theory with the observation that most people don't change their worldview or their preferences much after the age of maybe 15, I come up with the idea that most cultural change is driven by the random drift of the opinions of children.)</p>\n<h4 id=\"Gravitational_debate\">Gravitational debate<br></h4>\n<p>But there are many instances of inspirational books targeted at people already well on one side of an issue, that inspired people to action, or had a strong influence on people without flipping them from a 0 to a 1.&nbsp; <em>The God Delusion</em>, for example; or <a title=\"Erwin Schr\u00f6dinger\" href=\"http://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger\">Schr\u00f6dinger</a>'s <a href=\"http://en.wikipedia.org/wiki/What_is_Life%3F_(Schr%C3%B6dinger)\"><em>What is Life?</em></a>.</p>\n<p>So here's theory number 2: The gravitational model of debate.&nbsp; People adjust their opinions in response to the opinions of the people around them.&nbsp; If a lot of the people around Jack shift their opinions to the right, Jack is likely to shift his opinion to the right.&nbsp; I suspect that Jack is more sensitive to opinions similar to his, than to opinions far away.&nbsp; So, like gravity, the strength of the attraction falls off with distance.&nbsp; An opinion sufficiently different from your own is repelling; it invokes an outgroup response rather than an attractive ingroup response.&nbsp; Rush Limbaugh causes some people to shift further left.&nbsp; We could posit a gravitational attraction between opinions that varies from positive at close range, to negative at long range.</p>\n<p>The consequences of this model are that, by shifting anyone's opinion in one direction, you may trigger a cascade of opinion-shifts that will move the median<sup>1</sup> opinion.&nbsp; This says you can write a book targeted anywhere on a spectrum of opinion, and have it effect the entire spectrum indirectly, moving some people from one side of the fence to the other even though they never heard of your book.</p>\n<p>One consequence is that, as in <a title=\"http://lesswrong.com/lw/79/aumann_voting_or_how_to_vote_when_youre_ignorant/\" href=\"/\">tug-of-war voting</a>, it's rational to try to persuade extremists to be even more extreme than you think is rational, in order to shift the median opinion in your chosen direction.&nbsp; (It might not be the most effective use of your time).</p>\n<p>Another consequence is that your book might not influence the masses if the distribution of opinions in opinion-space has large gaps.&nbsp; If, for instance, you write a rah-rah transhumanist book, this might have no effect on the population at large if few people have a partly-positive view of transhumanism - even if the gap in opinion-space isn't where your targeted audience would be.&nbsp; If the gap is large, your book might move median opinion farther away from your position.&nbsp; The Nazis had a tremendous effect on later 20th century philosophy, and perhaps art - but not in the way they would have liked.</p>\n<p>This model works best for emotional issues, or regulatory issues, in which one's position can be expressed by a real number or vector.&nbsp; In an academic debate, if you have <em>n</em> competing hypothesis, the range of possible positions is discrete; and opinion space probably isn't a metric space.</p>\n<h4 id=\"Compare_and_contrast_\">Compare and contrast?<br></h4>\n<p>These two models make nearly opposite recommendations on how to influence public opinion.&nbsp; The first says to use marketing to target people who don't care.&nbsp; The second says (approximately) to examine the distribution of opinions, and express an opinion near a large mass of opinions, in the same direction as the vector from the median opinion to your desired opinion.</p>\n<p>I think both models have some truth to them.&nbsp; But which accounts for more of our behavior; and when should you use which model?</p>\n<p>&nbsp;</p>\n<p><sup>1</sup> (The median opinion is more relevant than the mean with one-person one-vote.&nbsp; The mean is more relevant with voting systems that let people express the strength of their opinions.)</p>", "sections": [{"title": "Target fence-sitters", "anchor": "Target_fence_sitters", "level": 1}, {"title": "Gravitational debate", "anchor": "Gravitational_debate", "level": 1}, {"title": "Compare and contrast?", "anchor": "Compare_and_contrast_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "34 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["G5bDjtSbJwbXuji4r"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-14T23:45:48.156Z", "modifiedAt": "2021-07-05T22:58:30.316Z", "url": null, "title": "Bayesians vs. Barbarians", "slug": "bayesians-vs-barbarians", "viewCount": null, "lastCommentedAt": "2022-04-15T06:59:50.204Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KsHmn6iJAEr9bACQW/bayesians-vs-barbarians", "pageUrlRelative": "/posts/KsHmn6iJAEr9bACQW/bayesians-vs-barbarians", "linkUrl": "https://www.lesswrong.com/posts/KsHmn6iJAEr9bACQW/bayesians-vs-barbarians", "postedAtFormatted": "Tuesday, April 14th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesians%20vs.%20Barbarians&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesians%20vs.%20Barbarians%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKsHmn6iJAEr9bACQW%2Fbayesians-vs-barbarians%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesians%20vs.%20Barbarians%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKsHmn6iJAEr9bACQW%2Fbayesians-vs-barbarians", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKsHmn6iJAEr9bACQW%2Fbayesians-vs-barbarians", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2279, "htmlBody": "<p><a href=\"/lw/3h/why_our_kind_cant_cooperate\">Previously</a>:<blockquote>\n<p>Let's say we have two groups of soldiers.&nbsp; In group 1, the privates are ignorant of tactics and strategy; only the sergeants know anything about tactics and only the officers know anything about strategy.&nbsp; In group 2, everyone at all levels knows all about tactics and strategy.</p>\n<p>Should we expect group 1 to defeat group 2, because group 1 will follow orders, while everyone in group 2 comes up with <em>better idea</em>s than whatever orders they were given?</p>\n<p>In this case I have to question how much group 2 really understands about military theory, because it is an <em>elementary</em> proposition that an uncoordinated mob gets slaughtered.</p>\n</blockquote>\n<p>Suppose that a country of rationalists is attacked by a country of <a href=\"http://www.overcomingbias.com/2007/06/are-your-enemie.html\">Evil</a> Barbarians who know nothing of probability theory or decision theory.</p>\n<p>Now there's a certain viewpoint on \"rationality\" or \"rationalism\" which would say something like this:</p>\n<p>\"Obviously, the rationalists will lose.&nbsp; The Barbarians believe in an afterlife where they'll be rewarded for courage; so they'll throw themselves into battle without hesitation or remorse.&nbsp; Thanks to their <a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">affective death spirals</a> around their Cause and Great Leader Bob, their warriors will obey orders, and their citizens at home will produce enthusiastically and at full capacity for the war; anyone caught skimming or holding back will be burned at the stake in accordance with Barbarian tradition.&nbsp; They'll believe in each other's goodness and hate the enemy more strongly than any sane person would, binding themselves into a tight group.&nbsp; Meanwhile, the rationalists will realize that there's no conceivable reward to be had from dying in battle; they'll wish that others would fight, but not want to fight themselves.&nbsp; Even if they can find soldiers, their civilians won't be as cooperative:&nbsp; So long as any <em>one</em> sausage almost certainly doesn't lead to the collapse of the war effort, they'll want to keep that sausage for themselves, and so not contribute as much as they could.&nbsp; No matter how refined, elegant, civilized, productive, and nonviolent their culture was to start with, they won't be able to resist the Barbarian invasion; sane discussion is no match for a frothing lunatic armed with a gun.&nbsp; In the end, the Barbarians will win because they <em>want</em> to fight, they <em>want</em> to hurt the rationalists, they <em>want</em> to conquer and their whole society is united around conquest; they care about that more than any sane person would.\"<em></em><em><a id=\"more\"></a></em></p>\n<p>War is not fun.&nbsp; As many many people have found since the dawn of recorded history, as many many people have found out before the dawn of recorded history, as some community somewhere is finding out right now in some sad little country whose internal agonies don't even make the front pages any more.</p>\n<p>War is not fun.&nbsp; <em>Losing </em>a war is even less fun.&nbsp; And it was said since the ancient times:&nbsp; \"If thou would have peace, prepare for war.\"&nbsp; Your opponents don't have to believe that you'll <em>win,</em> that you'll conquer; but they have to believe you'll put up enough of a fight to make it not worth their while.</p>\n<p>You perceive, then, that if it were genuinely the lot of \"rationalists\" to always lose in war, that I could not in good conscience advocate the widespread public adoption of \"rationality\".</p>\n<p>This is probably the dirtiest topic I've discussed or plan to discuss on LW.&nbsp; War is not clean.&nbsp; Current high-tech militaries&mdash;by this I mean the US military&mdash;are unique in the overwhelmingly superior force they can bring to bear on opponents, which allows for a historically extraordinary degree of concern about enemy casualties and civilian casualties.</p>\n<p>Winning in war has not always meant tossing aside <em>all</em> morality.&nbsp; Wars have been won without using torture.&nbsp; The unfunness of war does not imply, say, that questioning the President is unpatriotic.&nbsp; We're used to \"war\" being exploited as an excuse for bad behavior, because in recent US history that pretty much <em>is</em> exactly what it's been used for...</p>\n<p>But reversed stupidity is not intelligence.&nbsp; And reversed evil is not intelligence either.&nbsp; It remains true that <em>real</em> wars cannot be won by refined politeness.&nbsp; If \"rationalists\" can't prepare themselves for that mental shock, the Barbarians really will win; and the \"rationalists\"... I don't want to say, \"deserve to lose\".&nbsp; But they will have failed that test of their society's existence.</p>\n<p>Let me start by disposing of the idea that, <em>in principle</em>, ideal rational agents cannot fight a war, because each of them prefers being a civilian to being a soldier.</p>\n<p>As has already been discussed at some length, I <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">one-box on Newcomb's Problem</a>.</p>\n<p>Consistently, I do <em>not</em> believe that if an <a href=\"http://www.overcomingbias.com/2008/12/voting-kills.html\">election</a> is settled by 100,000 to 99,998 votes, that all of the voters were irrational in expending effort to go to the polling place because \"my staying home would not have affected the outcome\".&nbsp; (Nor do I believe that if the election came out 100,000 to 99,999, then 100,000 people were <em>all</em>, individually, <em>solely responsible </em>for the outcome.)</p>\n<p>Consistently, I also hold that two rational AIs (that use my kind of decision theory), even if they had completely different utility functions and were designed by different creators, will cooperate on the <a href=\"http://www.overcomingbias.com/2008/09/true-pd.html\">true Prisoner's Dilemma</a> if they have common knowledge of each other's source code.&nbsp; (Or even just common knowledge of each other's <em>rationality</em> in the appropriate sense.)</p>\n<p>Consistently, I believe that rational agents are capable of coordinating on group projects whenever the (expected probabilistic) outcome is better than it would be without such coordination.&nbsp; A society of agents that use my kind of decision theory, and have common knowledge of this fact, will end up at Pareto optima instead of Nash equilibria.&nbsp; If all rational agents agree that they are better off fighting than surrendering, they will fight the Barbarians rather than surrender.</p>\n<p>Imagine a community of self-modifying AIs who collectively prefer fighting to surrender, but individually prefer being a civilian to fighting.&nbsp; One solution is to run a lottery, unpredictable to any agent, to select warriors.&nbsp; <em>Before</em> the lottery is run, all the AIs change their code, in advance, so that if selected they will fight as a warrior in the most communally efficient possible way&mdash;even if it means calmly marching into their own death.</p>\n<p>(A reflectively consistent decision theory works the same way, only without the self-modification.)</p>\n<p>You reply:&nbsp; \"But in the real, human world, agents are not perfectly rational, nor do they have common knowledge of each other's source code.&nbsp; Cooperation in the Prisoner's Dilemma requires certain conditions according to your decision theory (which these margins are too small to contain) and these conditions are not met in real life.\"</p>\n<p>I reply:&nbsp; The <a href=\"http://www.overcomingbias.com/2008/09/true-pd.html\">pure, true Prisoner's Dilemma</a> is incredibly rare in real life.&nbsp; In real life you usually have knock-on effects&mdash;what you do affects your reputation.&nbsp; In real life most people care to some degree about what happens to other people.&nbsp; And in real life you have an opportunity to set up incentive mechanisms.</p>\n<p>And in real life, I <em>do</em> think that a community of human rationalists could manage to produce soldiers willing to die to defend the community.&nbsp; So long as children aren't told in school that ideal rationalists are supposed to defect against each other in the Prisoner's Dilemma.&nbsp; Let it be widely believed&mdash;and I do believe it, for exactly the same reason I one-box on Newcomb's Problem&mdash;that if people decided as individuals not to be soldiers or if soldiers decided to run away, then that is the same as deciding for the Barbarians to win.&nbsp; By that same theory whereby, if a lottery is won by 100,000 votes to 99,998 votes, it does not make sense for every voter to say \"my vote made no difference\".&nbsp; Let it be said (for it is true) that utility functions don't need to be solipsistic, and that a rational agent can fight to the death if they care enough about what they're protecting.&nbsp; Let them not be told that rationalists should expect to lose reasonably.</p>\n<p>If this is the culture and the mores of the rationalist society, then, I think, <em>ordinary human beings</em> in that society would volunteer to be soldiers.&nbsp; That also seems to be built into human beings, after all.&nbsp; You only need to ensure that the cultural training <em>does not get in the way.</em></p>\n<p>And if I'm wrong, and that doesn't get you enough volunteers?</p>\n<p>Then so long as people still prefer, on the whole, fighting to surrender; they have an opportunity to set up incentive mechanisms, and avert the True Prisoner's Dilemma.</p>\n<p>You can have lotteries for who gets elected as a warrior.&nbsp; Sort of like the example above with AIs changing their own code.&nbsp; Except that if \"be reflectively consistent; do that which you would precommit to do\" is not sufficient motivation for humans to obey the lottery, then...</p>\n<p>...well, in advance of the lottery actually running, we can perhaps all agree that it is a good idea to give the selectees drugs that will induce extra courage, and shoot them if they run away.&nbsp; Even considering that we ourselves might be selected in the lottery.&nbsp; Because in <em>advance</em> of the lottery, this is the general policy that gives us the highest <em>expectation </em>of survival.</p>\n<p>...like I said:&nbsp; Real wars = not fun, losing wars = less fun.</p>\n<p>Let's be clear, by the way, that I'm not endorsing the draft as practiced nowadays.&nbsp; Those drafts are not collective attempts by a populace to move from a Nash equilibrium to a Pareto optimum.&nbsp; Drafts are a tool of kings playing games in need of toy soldiers. The Vietnam draftees who fled to Canada, I hold to have been in the right.&nbsp; But a society that considers itself too smart for kings, does <em>not </em>have to be too smart to survive.&nbsp; Even if the Barbarian hordes are invading, and the Barbarians do practice the draft.</p>\n<p>Will rational soldiers obey orders?&nbsp; What if the commanding officer makes a mistake?</p>\n<p>Soldiers march.&nbsp; Everyone's feet hitting the ground in the same rhythm.&nbsp; Even, perhaps, <a href=\"/lw/5j/your_price_for_joining/\">against their own inclinations</a>, since people left to themselves would walk all at separate paces.&nbsp; Lasers made out of people.&nbsp; That's marching.</p>\n<p>If it's possible to invent some method of group decisionmaking that is <em>superior</em> to the captain handing down orders, then a company of rational soldiers might implement that procedure.&nbsp; If there is no proven method better than a captain, then a company of rational soldiers commit to obey the captain, even against their own separate inclinations.&nbsp; And if human beings aren't that rational... then in advance of the lottery, the general policy that gives you the highest personal expectation of survival is to shoot soldiers who disobey orders.&nbsp; This is not to say that those who fragged their own officers in Vietnam were in the wrong; for they could have consistently held that they preferred <em>no one</em> to participate in the draft lottery.</p>\n<p>But an uncoordinated mob gets slaughtered, and so the soldiers need <em>some</em> way of all doing the same thing at the same time in the pursuit of the same goal, even though, left to their own devices, they might march off in all directions.&nbsp; The orders may not come from a captain like a superior tribal chief, but unified orders have to come from <em>somewhere.</em>&nbsp; A society whose soldiers are too clever to obey orders, is a society which is too clever to survive.&nbsp; Just like a society whose people are too clever to <em>be</em> soldiers.&nbsp; That is why I say \"clever\", which I often use as a term of opprobrium, rather than \"rational\".</p>\n<p>(Though I do think it's an important question as to whether you can come up with a small-group coordination method that really genuinely in practice works better than having a leader.&nbsp; The more people can trust the group decision method&mdash;the more they can believe that it really is superior to people going their own way&mdash;the more coherently they can behave even in the absence of enforceable penalties for disobedience.)</p>\n<p>I say all this, even though I certainly don't expect rationalists to take over a country any time soon, because I think that what we believe about a society of \"people like us\" has some reflection on what we think of ourselves.&nbsp; If you believe that a society of people like you would be too reasonable to survive in the long run... that's one sort of self-image.&nbsp; And it's a different sort of self-image if you think that a society of people all like you could fight the vicious Evil Barbarians and <em>win</em>&mdash;not just by dint of superior technology, but because your people care about each other and about their collective society&mdash;and because they can face the realities of war without losing themselves&mdash;and because they would calculate the group-rational thing to do and make sure it got done&mdash;and because there's nothing in the rules of probability theory or decision theory that says you can't sacrifice yourself for a cause&mdash;and because if you really <em>are </em>smarter than the Enemy and not just flattering yourself about that, then you should be able to exploit the blind spots that the Enemy does not allow itself to think about&mdash;and because no matter how heavily the Enemy hypes itself up before battle, you think that just maybe a coherent mind, undivided within itself, and perhaps practicing something akin to meditation or self-hypnosis, can fight as hard in practice as someone who theoretically believes they've got seventy-two virgins waiting for them.</p>\n<p>Then you'll expect more of yourself <em>and people like you operating in groups;</em> and then you can see yourself as something more than a cultural dead end.</p>\n<p>So look at it <a href=\"http://www.overcomingbias.com/2007/10/fictional-evide.html\">this way</a>:&nbsp; <a href=\"http://www.overcomingbias.com/2008/05/eld-science.html\">Jeffreyssai</a> probably wouldn't give up against the Evil Barbarians if he were fighting <em>alone.</em>&nbsp; A whole <em>army </em>of <em>beisutsukai</em> masters ought to be a force that <em>no one</em> would mess with.&nbsp; That's the motivating vision.&nbsp; The question is how, exactly, that works.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xXX3n22DQZuKqXEdT": 1, "zv7v2ziqexSn5iS9v": 5, "9YFoDPFwMoWthzgkY": 2, "dPPATLhRmhdJtJM2t": 1, "chuP2QqQycjD8qakL": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KsHmn6iJAEr9bACQW", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 86, "baseScore": 88, "extendedScore": null, "score": 0.000134, "legacy": true, "legacyId": "195", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "beware-of-other-optimizing", "canonicalPrevPostSlug": "incremental-progress-and-the-valley", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 89, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 285, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7FzD7pNm9X68Gp5ZC", "Q8evewZW5SeidLdbA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 10, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-14T23:45:48.156Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-15T15:27:13.693Z", "modifiedAt": null, "url": null, "title": "Actions and Words: Akrasia and the Fruit of Self-Knowledge", "slug": "actions-and-words-akrasia-and-the-fruit-of-self-knowledge", "viewCount": null, "lastCommentedAt": "2017-11-19T14:02:56.215Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Annoyance", "createdAt": "2009-02-28T04:06:40.600Z", "isAdmin": false, "displayName": "Annoyance"}, "userId": "yEm6LWatswJYGwBFq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rGTfQJ8E5CxqcA6LD/actions-and-words-akrasia-and-the-fruit-of-self-knowledge", "pageUrlRelative": "/posts/rGTfQJ8E5CxqcA6LD/actions-and-words-akrasia-and-the-fruit-of-self-knowledge", "linkUrl": "https://www.lesswrong.com/posts/rGTfQJ8E5CxqcA6LD/actions-and-words-akrasia-and-the-fruit-of-self-knowledge", "postedAtFormatted": "Wednesday, April 15th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Actions%20and%20Words%3A%20Akrasia%20and%20the%20Fruit%20of%20Self-Knowledge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AActions%20and%20Words%3A%20Akrasia%20and%20the%20Fruit%20of%20Self-Knowledge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrGTfQJ8E5CxqcA6LD%2Factions-and-words-akrasia-and-the-fruit-of-self-knowledge%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Actions%20and%20Words%3A%20Akrasia%20and%20the%20Fruit%20of%20Self-Knowledge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrGTfQJ8E5CxqcA6LD%2Factions-and-words-akrasia-and-the-fruit-of-self-knowledge", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrGTfQJ8E5CxqcA6LD%2Factions-and-words-akrasia-and-the-fruit-of-self-knowledge", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 687, "htmlBody": "<blockquote>\n<p>Knowing other people requires intelligence,</p>\n<p>but knowing yourself requires wisdom.</p>\n<p>Those who overcome others have force,</p>\n<p>but those who overcome themselves have power.</p>\n<p>- <em>Tao Te Ching</em>, Chapter 33:&nbsp; Without Force, Without Perishing</p>\n</blockquote>\n<p>Much has been written here about the issue of <a href=\"http://en.wikipedia.org/wiki/Akrasia\">akrasia</a>.&nbsp; People often report that they really, sincerely want to do something, that they recognize that certain courses of action are desirable/undesirable and that they should choose them -- but when the time comes to decide, they do otherwise.&nbsp; Their choices don't match what they said their choices would be.</p>\n<p>While I'm sure many people are less than honest in reporting their intentions to others, and possibly even more who aren't even being honest with themselves, there are still plenty of people that are presumably sincere and honest.&nbsp; So how can they make their actions match their understanding of what they want?&nbsp; How can their choices reflect their own best judgment?</p>\n<p>Isn't that really the wrong question?<a id=\"more\"></a></p>\n<blockquote>\n<p>The very powerful and the very stupid have one thing in common:&nbsp; they don't alter their views to fit the facts, they alter the facts to fit their views.&nbsp; Which can be very uncomfortable, if you're one of the facts that needs correcting.</p>\n<p>Doctor Who, <em>The Face of Evil</em></p>\n</blockquote>\n<p>If a model of a phenomenon fails to accurately predict it, we conclude that the model is flawed and try to change it.&nbsp; If what we're trying to understand is ourselves, our own choices, and the motivations, desires, and preferences that direct those choices, why should we do any differently?&nbsp; Our actions reveal what we actually want, not what we believe we want or believe we should want.&nbsp; No one chooses against their own judgment.&nbsp; What we do is choose against our <em>understanding</em> of our own judgment, and that is a far subtler matter.&nbsp; By our fruits shall we know ourselves.</p>\n<blockquote>\n<p>Q:&nbsp; How many therapists does it take to change a lightbulb?</p>\n<p>A:&nbsp; The lightbulb has to <em>want</em> to change.</p>\n</blockquote>\n<p>Expecting our behavior to be constrained and controlled by our understanding is like expecting our limbs to move if we yell at them to do so.&nbsp; It doesn't matter how much we believe we want them to move, or how much we say we want them to move.&nbsp; It is irrelevant whether we have a conscious understanding of the nerves and muscles involved.&nbsp; Our conscious awareness is a bystander that reports what happens and attributes its observations to itself, when in actuality it controls very little at all.</p>\n<p>There are people whose ability to move has been damaged by nerve trauma or damage to the brain.&nbsp; The established relationships between their intents, their desires, and the signals to their muscles, have been damaged or destroyed.&nbsp; Such people do not improve by talking to others about how much they want to move, or by talking to themselves about it (which is what conscious thought really is).&nbsp; They get better by searching out connections that work and building on them.</p>\n<blockquote>\n<p>Those whom heaven helps we call the children of heaven.&nbsp; They do not learn this by learning.&nbsp; They do not work it by working.&nbsp; They do not reason it by using reason.&nbsp; To let understanding stop at what cannot be understood is a high achievement.</p>\n<p>- Zhuangzi, <em>Zhuangzi</em>, Chapter 2:&nbsp; On the Proper Order of Things</p>\n</blockquote>\n<p>Babies have little if any consciousness, and they don't possess theory.&nbsp; Their nervous systems learn to move their bodies by bombarding their muscles with random noise triggered by their interests, and strengthening the signals that happen to get them closer to what they want.&nbsp; Not what they <em>think </em>they want.&nbsp; It is quite unlikely that babies have models of their minds, much less conscious ones, although they are either born with models of their bodies or the foundations for building such a model.</p>\n<p>Those who wish to bring themselves into alignment with what is truly correct, instead of what their impulses and desires seek in themselves, must first understand the nature of their impulses and the nature of their understanding.</p>\n<blockquote>\n<p><span class=\"body\">Let him that would move the world first move himself.</span></p>\n<p>- Socrates of Athens</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"r7qAjcbfhj2256EHH": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rGTfQJ8E5CxqcA6LD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 10, "extendedScore": null, "score": 4.879651096586897e-07, "legacy": true, "legacyId": "403", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-15T20:09:12.138Z", "modifiedAt": null, "url": null, "title": "Mechanics without wrenches", "slug": "mechanics-without-wrenches", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:45.506Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GTaPLD3Wponb7hFC3/mechanics-without-wrenches", "pageUrlRelative": "/posts/GTaPLD3Wponb7hFC3/mechanics-without-wrenches", "linkUrl": "https://www.lesswrong.com/posts/GTaPLD3Wponb7hFC3/mechanics-without-wrenches", "postedAtFormatted": "Wednesday, April 15th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mechanics%20without%20wrenches&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMechanics%20without%20wrenches%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGTaPLD3Wponb7hFC3%2Fmechanics-without-wrenches%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mechanics%20without%20wrenches%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGTaPLD3Wponb7hFC3%2Fmechanics-without-wrenches", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGTaPLD3Wponb7hFC3%2Fmechanics-without-wrenches", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 979, "htmlBody": "<p>Say you're taking your car to an auto mechanic for repairs.&nbsp; You've been told he's the best mechanic in town.&nbsp; The mechanic rolls up the steel garage door before driving the car into the garage, and you look inside and notice something funny.&nbsp; There are no tools.&nbsp; The garage is bare - just an empty concrete space with four bay doors and three other cars.</p>\n<p>You point this out to the mechanic.&nbsp; He shrugs it off, saying, \"This is how I've always worked.&nbsp; I'm just that good.&nbsp; You were lucky I had an opening; I'm usually booked.\"&nbsp; And you believe him, having seen the parking lot full of cars waiting to be repaired.</p>\n<p>You take your car to another mechanic in the same town.&nbsp; He, too, has no tools in his garage.&nbsp; You visit all the mechanics in town, and find a few that have some wrenches, and others with a jack or an air compressor, but no one with a full set of tools.</p>\n<p>You notice the streets are nearly empty besides your car.&nbsp; Most of the cars in town seem to be in for repairs.&nbsp; You talk to the townsfolk, and they tell you how they take their cars from one shop to another, hoping to someday find the mechanic who is brilliant and gifted enough to fix their car.</p>\n<p>I sometimes tell people how I believe that governments should not be documents, but semi-autonomous computer programs.&nbsp; I have a story that I'm not going to tell now, about incorporating inequalities into laws, then incorporating functions into them, then feedback loops, then statistical measures, then learning mechanisms, on up to the point where voters and/or legislatures set only the values that control the system, and the system produces the low-level laws and policy decisions (in a way that balances exploration and exploitation).&nbsp; (Robin's futarchy in which you \"<a href=\"http://hanson.gmu.edu/futarchy.pdf\">vote on values, bet on beliefs</a>\" describes a similar, though less-automated system of government.)</p>\n<p>And one reaction - actually, one of the most intelligent reactions - is, \"But then... legislators would have to understand something about math.\"&nbsp; As if that were a bug, and not a feature.<a id=\"more\"></a></p>\n<p>We have 535 Congressmen in the United States.&nbsp; Over the past half a year, they've decided how to spend several trillion of our dollars on interventions to vitalize our economy.&nbsp; But after listening to them for 20 years, I have the feeling that few of them could explain the concepts of opportunity cost, diminishing returns, or the law of supply and demand.&nbsp; You could probably count on one hand the number who could solve an ordinary differential equation.</p>\n<p>This isn't the fault of the congressmen.&nbsp; This is the fault of the voters.&nbsp; Why do we regularly elect representatives who are mechanics without wrenches?</p>\n<p>We like to praise the man who achieves great things through vision, genius, and force of personality.&nbsp; If you tell people that he had great tools, people think you're trying to diminish his accomplishments.&nbsp; People love Einstein above all scientists because they have the idea that he just sat in a chair and conducted thought-experiments.&nbsp; They like to believe that he did poorly in math at school (he <a href=\"http://www.amazon.com/Einstein-Life-Universe-Walter-Isaacson/dp/0743264746/\">didn't</a>).&nbsp; Maybe this is because they feel math is a crutch that a true genius wouldn't need.&nbsp; Maybe it's because they would like to think that they could also come up with general relativity if they just had enough time alone.&nbsp; They love scientists who say they work by visualization or intuition, and who talk about seeing the solution to a problem in a dream. &nbsp;It's not evident that Einstein was smarter than John von Neumann or Alan Turing, yet most Americans have never heard their names.</p>\n<p>I think that what America needs most, in terms of rationality, is not training in rationalist techniques - although that's of value.&nbsp; What America needs most is awareness of how much of a difference intelligence and education and rationality can make.&nbsp; And what America needs second-most is for people to recognize the toolkits of rationality and appreciate their power.</p>\n<p>Most people don't realize that there are small bodies of knowledge that radically amplify your intelligence.&nbsp; Even a general understanding of evolution, or thermodynamics, or information theory, gives you a grasp on all sorts of other topics that would have otherwise remained mysterious.&nbsp; Understanding how to rephrase a real-world problem as a function maximization problem lets you think quantitatively about something that before you would have had to address with gut feelings.</p>\n<p>One reason for this may be that, in the mind of the public, the prototypical smart person is a physicist.&nbsp; And particle physics, quantum mechanics, and relativity just aren't very useful toolkits.&nbsp; People hardly ever get an insight into anything in their ordinary lives from quantum mechanics or relativity (and when they do, they're wrong).&nbsp; You don't have to know that stuff.&nbsp; And, as 20th-century physics is thought of as the pinnacle of science, it taints all the other sciences with its own narrowness of applicability.</p>\n<p>With the exception of math, I can't recall any teacher ever trying to show me that something we were studying was a toolkit applicable beyond the subject being studied.&nbsp; The way we try to teach our students to think is like the (failed) way we tried to teach AIs to think in the 1970s (and, in Austin, through the present day) - by giving them a lot of specialized knowledge about a lot of different subjects.&nbsp; This is a time-tested way to spend a lot of time and money without instilling much intelligence into either a computer or a student.&nbsp; A better approach would be to look for abstractions that can be applied to as many domains as possible, and to have one class for each of these abstractions.</p>\n<p>&nbsp;</p>\n<p>(PS - When I speak specifically about America, it's not because I think the rest of the world is unimportant.&nbsp; I just don't know as much about the rest of the world.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FkzScn5byCs9PxGsA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GTaPLD3Wponb7hFC3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 36, "extendedScore": null, "score": 4.880065827912729e-07, "legacy": true, "legacyId": "219", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-15T23:59:26.897Z", "modifiedAt": null, "url": null, "title": "I Changed My Mind Today - Canned Laughter", "slug": "i-changed-my-mind-today-canned-laughter", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:31.951Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pre", "createdAt": "2009-02-27T14:35:32.511Z", "isAdmin": false, "displayName": "pre"}, "userId": "XCwdovczssgYqBwT2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wiF4xWEoBwXR4XdSY/i-changed-my-mind-today-canned-laughter", "pageUrlRelative": "/posts/wiF4xWEoBwXR4XdSY/i-changed-my-mind-today-canned-laughter", "linkUrl": "https://www.lesswrong.com/posts/wiF4xWEoBwXR4XdSY/i-changed-my-mind-today-canned-laughter", "postedAtFormatted": "Wednesday, April 15th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%20Changed%20My%20Mind%20Today%20-%20Canned%20Laughter&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%20Changed%20My%20Mind%20Today%20-%20Canned%20Laughter%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwiF4xWEoBwXR4XdSY%2Fi-changed-my-mind-today-canned-laughter%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%20Changed%20My%20Mind%20Today%20-%20Canned%20Laughter%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwiF4xWEoBwXR4XdSY%2Fi-changed-my-mind-today-canned-laughter", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwiF4xWEoBwXR4XdSY%2Fi-changed-my-mind-today-canned-laughter", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 833, "htmlBody": "<p>If we had topic-headings here, I'd be suggesting a new one: I changed my mind today.<br /><br />Being rational is all about chainging your mind, right? It's about re-assessing in the face of some new evidence. About examining the difference between your assumptions and the world itself. Narrowing down the difference between the model and the reality, the map and the territory.<br /><br />Maybe your 'karma' should reflect how much you've told us when you changed your mind? Certainly I'd like to know when people change their minds about things more than when they just agree with me.</p>\n<p>In fact, I think that is probably the thing I most want to know about from any of the people whom I know primarily because of their professed rationality.</p>\n<p>Especially if they explain why they changed their minds, and do it well.<br /><br />With that in mind, and introducing the new acronym: ICMMT<br /><br />I Changed My Mind Today!<br /><br />Or at least I revised my opinion.<br /><a id=\"more\"></a><br />As you may know, the UK TV channel \"Dave\" recorded and then broadcast three new episodes of \"Red Dwarf\" this Easter. If you didn't know that, your time is better spent tracking down those shows and watching them than reading the remainder of this article. Come back when you're done. If you haven't even watched the BBC originals then, um. Enjoy! See you in a year or so.<br /><br />Anyway.<br /><br />I enjoyed the new episodes, laughed a lot, reminisced a lot more, but was left somehow feeling more *flat* than when watching previous shows.</p>\n<p>I didn't really even know why, until a friend pointed it out:</p>\n<p>&gt; The new shows have no 'laugh track'.</p>\n<p>As soon as she said it, I knew that I'd heard mention that this was the first time they'd shot the show without a studio audience. And that she was right. And that the \"laugh track\" had been an important part of that show to me right from the first episode.<br /><br />Now this was a revelation. <br /><br />Until now, when I've noticed a laugh-track or when a laugh-track has been talked about by others, it's been to bitch about \"canned laughter\" being really false and it ruining the whole atmosphere and making everything seem fake.<br /><br />Which I agreed with. Totally. That stuff is damned annoying. When I notice a laugh-track, it's because the people laughing are clearly moronic idiots who'd laugh at the fact of gravity and I hate them.<br /><br />However. When my friend said that the lack of that laugh track left the show 'flat', I knew exactly what she meant. It made all the difference in the world. Deathly silence, all over. The comedic timing that was essential, the knowing when the laughter comes, knowing when it dies, responding to the audience, was gone.<br /><br />They were all great actors, and they faked it well. Presumably they timed it so well with my drunken-stoned first viewing that I didn't even notice. But once you do, it's obvious.<br /><br />Which completely changes my view on the laugh-track in comedy.<br /><br />I used to think it was just an annoying gloss, a manipulation, an attempt to program my brain through skinneresque association. Now I see that it communicates *both sides* of an interaction between two groups of people. That the live audience, and being able to hear that audience in the edit, tells the performer exactly how to act. How to reflect the laughter and mood back.<br /><br />This is annoying, to some extent. I have some minor film-making ambition, and in any show I want to shoot on any kind of budget I can afford, the audience won't be there. Yet now I see the need to find a way to do so. Which makes it all even *more* expensive and difficult.<br /><br />I already knew that \"<em>canned laughter</em>\" isn't the same as \"<em>filmed in front of a live studio audience</em>\" of course. But it always just sounded like a cop-out.<br /><br />Turns out that the live audience laughter and the actor actually interact. That's what makes it so compelling. That's what makes it actually work in a way that actual canned laughter doesn't. Why actual 'canned laughter', if it really exists, got it's reputation.<br /><br />Even showing the film to an audience and then dubbing on their laughter for release won't really cut it. The way the actor responds to the audience is more important than the way the audience responds to the actor.<br /><br />So yeah.</p>\n<p>I changed my mind today. I already knew the difference between \"Live studio audience\" and \"Canned laughter\", but now I feel like I know why one irritates so much and the other stops a film looking so damed flat. I'm no longer against it in principle.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3RnEKrsNgNEDxuNnw": 1, "hNFdS3rRiYgqqD8aM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wiF4xWEoBwXR4XdSY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 15, "extendedScore": null, "score": 4.880407252557929e-07, "legacy": true, "legacyId": "404", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-16T00:56:11.827Z", "modifiedAt": null, "url": null, "title": "Of Gender and Rationality", "slug": "of-gender-and-rationality", "viewCount": null, "lastCommentedAt": "2018-05-25T18:49:48.229Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xsyG7PkMekHud2DMK/of-gender-and-rationality", "pageUrlRelative": "/posts/xsyG7PkMekHud2DMK/of-gender-and-rationality", "linkUrl": "https://www.lesswrong.com/posts/xsyG7PkMekHud2DMK/of-gender-and-rationality", "postedAtFormatted": "Thursday, April 16th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Of%20Gender%20and%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOf%20Gender%20and%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxsyG7PkMekHud2DMK%2Fof-gender-and-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Of%20Gender%20and%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxsyG7PkMekHud2DMK%2Fof-gender-and-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxsyG7PkMekHud2DMK%2Fof-gender-and-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1431, "htmlBody": "<p>Among all self-identified \"rationalist\" communities that I know of, and <em>Less Wrong</em> in particular, there is an obvious gender imbalance&mdash;a male/female ratio tilted strongly toward males.</p>\n<p>Yet surely <a href=\"/lw/31/what_do_we_mean_by_rationality/\">epistemic and instrumental rationality</a> have no gender signature.&nbsp; There is no such thing as masculine probability theory or feminine decision theory.</p>\n<p>There <em>could</em> be some entirely innocuous explanation for this imbalance.&nbsp; Perhaps, by sheer historical contingency, aspiring rationalists are recruited primarily from the <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">atheist/libertarian/technophile cluster</a>, which has a gender imbalance for its <em>own</em> reasons&mdash;having <em>nothing to do with </em>rationality or rationalists; and this is the <em>entire </em>explanation.</p>\n<p>Uh huh.&nbsp; Sure.</p>\n<p>And then there are the less innocuous explanations&mdash;those that point an accusing finger at the rationalist community, or at womankind.<a id=\"more\"></a></p>\n<p>If possible, let's try not to make things <em>worse</em> in the course of having this discussion.&nbsp; Remember that to name two parts of a community is to split that community&mdash;see the <a href=\"http://www.overcomingbias.com/2007/12/the-robbers-cav.html\">Robbers Cave experiment</a>:&nbsp; Two labels &rarr; two groups.&nbsp; Let us try <em>not</em> to make some of our fellow rationalists feel singled-out as objects of scrutiny, here.&nbsp; But in the long run especially, it is not a good thing if half the potential audience is being actively filtered out; whatever the cause, the effect is noticeable, and we can't afford to ignore the question.</p>\n<p>These are the major possibilities that I see:</p>\n<p>(1)&nbsp; While the pure math of the <em>right</em> Way has no gender signatures on it, we can imagine that men and women are annoyed to different degrees by different <em>mistakes.</em>&nbsp; Suppose that Less Wrong is <em>too disagreeable</em>&mdash;that relative to the ideal, just-right, perfectly-rational amount of disagreement, we have a little more disagreement than that.&nbsp; You can imagine that to the men, this seems normal, forgivable, takeable in-stride&mdash;wrong, perhaps, but not really all that <em>annoying.</em>&nbsp; And you can imagine that conversely, the female-dominated mirror-image of Less Wrong would involve too much agreement relative to the ideal&mdash;lots of comments agreeing with each other&mdash;and that while this would seem normal, forgivable, takeable-in-stride to the female majority, it would drive the men up the wall, and some of them would leave, and the rest would be gritting their teeth.&nbsp; (This example plays to gender stereotypes, but that's because I'm speculating blindly; my brain only knows half the story and has to guess at the other half.&nbsp; Less obvious hypotheses are also welcome.)&nbsp; In a case like this, you begin by checking with trusted female rationalists to see if they think you're doing anything characteristically male, irrational, and annoying.</p>\n<p>(2)&nbsp; The above points a finger at the rationalist community, and in particular its men, as making a mistake that drives away rational women.&nbsp; The complementary explanation would say:&nbsp; \"No, we have exactly the rational amount of argument as it stands, or even too little.&nbsp; Male newcomers are fine with this, but female newcomers feel that there's too much conflict and disagreement and they leave.\"&nbsp; The true Way has no gender signature, but you can have a <em>mistake </em>that is characteristic of one sex but not the other, or a mistake that has been culturally inculcated in one gender but not the other.&nbsp; In this case we try to survey female newcomers to see what aspects seem like turn-offs (whether normatively rational or not), and then fix it (if not normatively rational) or try to soften the impact somehow (if normatively rational).&nbsp; (Ultimately, though, rationality is tough for everyone&mdash;there are parts that are hard for <em>anyone</em> to swallow, and you just have to make it as easy as you can.)</p>\n<p>(3)&nbsp; It could be some <a href=\"http://www.overcomingbias.com/2008/11/chaotic-inversi.html\">indefinable</a> difference of style&mdash;\"indefinable\" meaning that we can't pin it down tightly enough to duplicate&mdash;whereby male writers tend to attract male recruits and female writers attract female recruits.&nbsp; On this hypothesis, male writers end up with mostly male readers for much the same reason that Japanese writers end up with mostly Japanese readers.&nbsp; In this case I would suggest to potential female authors that they should write more, including new introductions and similar recruiting material.&nbsp; We could try for a mix of authorial genders in the material first encountered on-site.&nbsp; (By the same logic that if we wanted more Japanese rationalists we might encourage potential writers who happened to be Japanese.)</p>\n<p>(4)&nbsp; We could be looking at a direct gender difference&mdash;where I parenthetically note that (by convention in such discussions) \"gender\" refers to a culture's concept of what it means to be a man or woman, while \"sex\" refers to actual distinctions of XX versus XY chromosomes.&nbsp; For example, consider <a href=\"http://pics.blameitonthevoices.com/042009/small_from%201970s%20childrens%20book.jpg\">this inspirational poster from a 1970s childrens' book</a>.&nbsp; \"Boys are pilots... girls are stewardesses... boys are doctors... girls are nurses.\"&nbsp; \"Modern\" cultures may still have a strong dose of \"boys are rational, girls are un-self-controlled creatures of pure feeling who find logic and indeed all verbal argument to be vaguely unfeminine\".&nbsp; I suppose the main remedy would be (a) to try and correct this the same way you would correct any other sort of childhood damage to sanity and (b) present strong female rationalist role models.</p>\n<p>(5)&nbsp; The complementary hypothesis is a direct <em>sex </em>difference&mdash;i.e., the average female human actually <em>is</em> less interested in and compelled by deliberative reasoning compared to the average male human.&nbsp; If you were motivated to correct the sex balance regardless, you would consider e.g. where to find a prefiltered audience of people compellable by deliberative reasoning, a group that already happened to have good gender balance, and go recruiting there.</p>\n<p>(6)&nbsp; We could be looking an indirect gender difference.&nbsp; Say, boys are raised to find a concept like \"<a href=\"http://www.overcomingbias.com/2007/03/tsuyoku_naritai.html\">tsuyoku naritai</a>\" (\"I want to become stronger\") appealing, while girls are told to shut up and keep their heads down.&nbsp; If the masculine gender concept has a stronger endorsement of aspiring to self-improvement, it will, as a side effect, make a stronger endorsement of improving one's rationality.&nbsp; Again, the solutions would be female authors to tailor introductions to feminine audiences, and strong female role models.&nbsp; (If you're a woman and you're a talented writer and speaker, consider reading up on <a href=\"/tag/antitheism/\">antitheism</a> and trying to become a Fifth Horsewoman alongside Dawkins, Dennett, Harris and Hitchens...?)</p>\n<p>(7)&nbsp; We could be looking at an indirect sex difference.&nbsp; The obvious <a href=\"http://www.overcomingbias.com/2007/11/evolutionary-ps.html\">evolutionary psychology</a> hypothesis behind the imbalanced gender ratio in the iconoclastic community&mdash;the <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">atheist/libertarian/technophile cluster</a>&mdash;is the idea that males are inherently more attracted to gambles that seem high-risk and high-reward; they are more driven to try out strange ideas that come with big promises, because the genetic payoff for an unusually successful male has a much higher upper bound than the genetic payoff for an unusually successful female.&nbsp; It seems to me that male teenagers especially have something like a <em>higher cognitive temperature</em>, an ability to wander into strange places both good and bad.&nbsp; To some extent, this can be viewed as a problem of authorial style as well as innate dispositions&mdash;there's no law that says you have to <em>emphasize </em>the strangeness.&nbsp; You could start right out with pictures of a happy gender-balanced <a href=\"/lw/5v/church_vs_taskforce/\">rationalist unchurch</a> somewhere, and banner the page \"A Return To Sanity\".&nbsp; But a difference as basic as \"more male teenagers have a high cognitive temperature\" could prove very hard to address completely.</p>\n<p>(8)&nbsp; Then there's the hypothesis made infamous by Larry Summers:&nbsp; Male <em>variance</em> in IQ (not the mean) is higher, so the right tail is dominated by males as you get further out.&nbsp; I know that just mentioning this sort of thing can cause a webpage to burst into flames, and so I would like to once again point out that <em>individual</em> IQ differences, whether derived from genes or eating lead-based paint as a kid, <a href=\"http://www.overcomingbias.com/2007/10/why-is-individu.html\">are already as awful as it gets</a>&mdash;nothing is made any <em>worse</em> by talking about groups, since groups are just made out of individuals.&nbsp; The universe is already dreadful along this dimension, so we shouldn't care <em>more </em>whether groups are involved&mdash;though of course, thanks to our political instincts, we do care.&nbsp; The remedies in this not-actually-any-<em>more-</em>awful case are (a) continue the quest to systematize rationality training so that it is less exclusively the preserve of high-<em>g</em> individuals, and (b) recruit among prefiltered audiences that have good gender balance.</p>\n<p>(9)&nbsp; Perhaps women are less underrepresented on <em>Less Wrong</em> than may at first appear, and men are more likely to <em>comment</em> for some reason.&nbsp; Or perhaps women are less likely to choose visibly feminine usernames.&nbsp; The gender ratio at physical meetups, while still unbalanced, seems noticeably <em>better </em>than the visible gender ratio among active commenters on the Internet.&nbsp; Not very plausible as a <em>complete</em> explanation; but we should consider hypotheses that involve unbalanced participation/visibility rather than unbalanced attraction/retention.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/bd/my_way/\">My Way</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/5f/bayesians_vs_barbarians/\">Bayesians vs. Barbarians</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xsyG7PkMekHud2DMK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 55, "baseScore": 55, "extendedScore": null, "score": 8.5e-05, "legacy": true, "legacyId": "385", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 55, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 360, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv", "7FzD7pNm9X68Gp5ZC", "p5DmraxDmhvMoZx8J", "YdcF6WbBmJhaaDqoD", "FBgozHEv7J72NCEPB", "KsHmn6iJAEr9bACQW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-16T09:06:25.124Z", "modifiedAt": null, "url": null, "title": "Welcome to Less Wrong!", "slug": "welcome-to-less-wrong", "viewCount": null, "lastCommentedAt": "2020-03-11T19:22:55.335Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CG9AEXwSjdrXPBEZ9/welcome-to-less-wrong", "pageUrlRelative": "/posts/CG9AEXwSjdrXPBEZ9/welcome-to-less-wrong", "linkUrl": "https://www.lesswrong.com/posts/CG9AEXwSjdrXPBEZ9/welcome-to-less-wrong", "postedAtFormatted": "Thursday, April 16th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Welcome%20to%20Less%20Wrong!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWelcome%20to%20Less%20Wrong!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCG9AEXwSjdrXPBEZ9%2Fwelcome-to-less-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Welcome%20to%20Less%20Wrong!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCG9AEXwSjdrXPBEZ9%2Fwelcome-to-less-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCG9AEXwSjdrXPBEZ9%2Fwelcome-to-less-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 519, "htmlBody": "<p>If you've recently joined the <a href=\"/lw/1/about_less_wrong/\">Less Wrong community</a>, please leave a comment here and introduce yourself. We'd love to know who you are, what you're doing, or how you found us. Tell us <a href=\"/lw/2/tell_your_rationalist_origin_story/\">how you came to identify as a rationalist</a>, or describe what it is you <a href=\"http://www.overcomingbias.com/2008/01/something-to-pr.html\">value and work to achieve</a>.</p>\n<p>If you'd like to meet other LWers in real life, there's a <a href=\"/lw/7c/where_are_we/\">meetup thread</a> and a <a href=\"http://www.facebook.com/home.php#/group.php?gid=144017955332&amp;ref=ts\">Facebook group</a>. If you've your own blog or other online presence, please feel free to link it. If you're confused about any of the terms used on this site, you might want to pay a visit to the <a href=\"http://lesswrong.wikia.com/wiki/LessWrong_Wiki\">LW Wiki</a>, or simply ask a question in this thread.&nbsp; Some of us have been having this conversation for a few years now, and we've developed a fairly specialized way of talking about some things. Don't worry -- you'll pick it up pretty quickly.</p>\n<p>You may have noticed that all the posts and all the comments on this site have buttons to vote them up or down, and all the users have \"karma\" scores which come from the sum of all their comments and posts. Try not to take this too personally. Voting is used mainly to get the most useful comments up to the top of the page where people can see them. It may be difficult to contribute substantially to ongoing conversations when you've just gotten here, and you may even see some of your comments get voted down. Don't be discouraged by this; it happened to many of us. If you've any questions about karma or voting, please feel free to ask here.</p>\n<p>If you've come to Less Wrong to teach us about a particular topic, this thread would be a great place to start the conversation, especially until you've worked up enough karma for a top level post. By posting here, and checking the responses, you'll probably get a good read on what, if anything, has already been said here on that topic, what's widely understood and what you might still need to take some time explaining.</p>\n<p>A note for theists: you will find LW overtly atheist. We are happy to have you participating but please be aware that other commenters are likely to treat religion as an open-and-shut case. This isn't groupthink; we really, truly have given full consideration to theistic claims and found them to be false. If you'd like to know how we came to this conclusion you may find <a href=\"http://wiki.lesswrong.com/wiki/Religion\">these related posts</a> a good starting point.</p>\n<p>A couple technical notes: when leaving comments, you may notice a 'help' link below and to the right of the text box. &nbsp;This will explain how to <em>italicize</em>, <a href=\"http://www.lesswrong.com\">linkify</a>, or quote bits of text. You'll also want to check your <a href=\"/message/inbox\">inbox</a>, where you can always see whether people have left responses to your comments.</p>\n<p>Welcome to Less Wrong, and we look forward to hearing from you throughout the site.</p>\n<p>(Note from MBlume: though my name is at the top of this page, the wording in various parts of the welcome message owes a debt to other LWers who've helped me considerably in working the kinks out)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CG9AEXwSjdrXPBEZ9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 50, "baseScore": 55, "extendedScore": null, "score": 0.00011109961369496296, "legacy": true, "legacyId": "405", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 50, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2003, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2om7AHEHtbogJmT5s", "BHMBBFupzb4s8utts", "gRkFrDmuE82difQRH"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-16T23:15:43.765Z", "modifiedAt": null, "url": null, "title": "Instrumental Rationality is a Chimera", "slug": "instrumental-rationality-is-a-chimera", "viewCount": null, "lastCommentedAt": "2017-06-17T04:36:43.012Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tom_Talbot", "createdAt": "2009-03-01T16:19:24.634Z", "isAdmin": false, "displayName": "Tom_Talbot"}, "userId": "3kMLvQM3hA4tnMBNr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qTSRpyuuu6i9gGmWY/instrumental-rationality-is-a-chimera", "pageUrlRelative": "/posts/qTSRpyuuu6i9gGmWY/instrumental-rationality-is-a-chimera", "linkUrl": "https://www.lesswrong.com/posts/qTSRpyuuu6i9gGmWY/instrumental-rationality-is-a-chimera", "postedAtFormatted": "Thursday, April 16th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Instrumental%20Rationality%20is%20a%20Chimera&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInstrumental%20Rationality%20is%20a%20Chimera%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqTSRpyuuu6i9gGmWY%2Finstrumental-rationality-is-a-chimera%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Instrumental%20Rationality%20is%20a%20Chimera%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqTSRpyuuu6i9gGmWY%2Finstrumental-rationality-is-a-chimera", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqTSRpyuuu6i9gGmWY%2Finstrumental-rationality-is-a-chimera", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 714, "htmlBody": "<p style=\"margin-bottom: 0cm;\">Eliezer observes, &ldquo;Among all self-identified \"rationalist\" communities that I know of, and <em>Less Wrong</em> in particular, there is an obvious gender imbalance - a male/female ratio tilted strongly toward males.&rdquo; and provides us with a selection of hypotheses that attempt to explain this notable fact, ranging over the normal cultural and biological explanations for male/female imbalances in any community. One important point was missing however, a point raised by Yvain last week under the title, <a href=\"/lw/9p/rationality_its_not_that_great/\">Extreme Rationality: It's Not That Great</a>. That fact is that <em>we have not</em> <em>done anything yet</em>. Eliezer writes under the assumption that women ought to want to study our writings, but since we have so far failed to produce a single practical application of our rationalist techniques, I really cannot blame women for staying away. They may be being more rational than we are.</p>\n<p style=\"margin-bottom: 0cm;\"><a id=\"more\"></a></p>\n<p style=\"margin-bottom: 0cm;\"><a name=\"query\"></a>Long have we pondered Eliezer's enigmatic homily, &ldquo;Rationalists should <strong>win</strong>.&rdquo; and like the aristoteleans of old we agreed that it must be so, since a proclivity to <strong>win</strong> is inherent in the definition of the word &ldquo;rationalist&rdquo;.</p>\n<p style=\"margin-bottom: 0cm;\">Well, have you won anything lately? Are the horizons of your power expanding, you rationalist <em>&Uuml;bermenschen</em><span style=\"font-style: normal;\">? Perhaps you will say, &ldquo;We have only just gotten started! We are pregnant with potential, if not abounding with achievements.&rdquo;</span></p>\n<p style=\"margin-bottom: 0cm;\"><span style=\"font-style: normal;\">I do not mean to be impatient but it </span><em>has</em><span style=\"font-style: normal;\"> been a few weeks now and we appear to be spinning our wheels a little tiny bit. As interesting as many of the posts here have been, I cannot recall any of them having been instrumentally useful to me, or anyone else here mentioning posts that have been instrumentally useful to them. In fact it almost seems as if most of the posts contributed by the Less Wrong community have been about the Less Wrong community. These self-referential meta-posts accumulate, and as they become increasingly impenetrable they discourage potential contributors of either sex.</span></p>\n<p style=\"margin-bottom: 0cm;\"><span style=\"font-style: normal;\">Since the confusion caused by this notion of instrumental rationality shows no signs of abating, I will attempt to cut the knot. There is no such thing as instrumental rationality. What is the rational way to butter toast? Brew coffee? Drive a car? Raise a child? Conduct a particle physics experiment? You will notice that the unifying feature among these examples is that there is no unifying feature among these examples. Rationality &ndash; real world, day to day, nine to five rationality &ndash; is entirely context dependent. The attempt to develop a grand unified theory of instrumental rationality is an attempt to abstract away from the details of inidividual circumstances, in order to come up with a Best Way To Do Everything Forever. This is untenable. Rationality can be used to choose the best course of action for achieving a particular goal, but this is simply an example of knowing the truth &ndash; epistemic rationality.</span></p>\n<p style=\"margin-bottom: 0cm;\"><span style=\"font-style: normal;\">I think that we have been on the wrong track, up until now. I believe we can do better, but first we must abandon the silly martial arts metaphors. You do not need academic-grade rationality every second of the day and you do not need to pretend that you are the only rational person in the world. Co-operate. In order to live rationally and live well, we must have easy access to organised expert domain knowledge in useful areas such as self-motivation, health and fitness, development of social skills, use of technology and of course, the abstract rules of epistemic rationality. I am sure there is much more that could be added to this list. To achieve this I suggest that, like an economy, we subdivide and specialise. Rather than racking their brains in an attempt to come up with something novel to say on the topic of abstract rationalism, we should encourage contributors to tell us about something they specialise in, to give us advice backed by evidence and reasoned argument about something they know a lot about, and to direct us to useful references wherein we may learn more. I imagine people contributing a guide to getting accurate medical information, tips on child psychology and raising children</span><em>, </em><span style=\"font-style: normal;\">or an essay on how to exercise to increase longevity. </span></p>\n<p style=\"margin-bottom: 0cm;\"><span style=\"font-style: normal;\">Clearly, we have a group of interested, motivated, highly intelligent people here at Less Wrong, each of whom has their own particular talent, so why not make the most of them?</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3QnDqGSdRMA5mdMM6": 1, "Ng8Gice9KNkncxqcj": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qTSRpyuuu6i9gGmWY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 10, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "412", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LgavAYtzFQZKg95WC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-16T23:21:05.787Z", "modifiedAt": null, "url": null, "title": "Practical rationality questionnaire", "slug": "practical-rationality-questionnaire", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:35.504Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hbdYWmu2ozwNvvWcW/practical-rationality-questionnaire", "pageUrlRelative": "/posts/hbdYWmu2ozwNvvWcW/practical-rationality-questionnaire", "linkUrl": "https://www.lesswrong.com/posts/hbdYWmu2ozwNvvWcW/practical-rationality-questionnaire", "postedAtFormatted": "Thursday, April 16th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Practical%20rationality%20questionnaire&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APractical%20rationality%20questionnaire%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhbdYWmu2ozwNvvWcW%2Fpractical-rationality-questionnaire%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Practical%20rationality%20questionnaire%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhbdYWmu2ozwNvvWcW%2Fpractical-rationality-questionnaire", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhbdYWmu2ozwNvvWcW%2Fpractical-rationality-questionnaire", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 303, "htmlBody": "<p>EDIT, 4/18:&nbsp; I'm closing the survey.&nbsp; I'll post analysis and a better anonymized version of the raw data in a day or so.&nbsp; 236 people responded; thanks very much to all who did.</p>\n<p>For survey participants curious about the calibration questions, the answers are:</p>\n<p>Number of republics the USSR broke up into, following the output of the cold war: 15.</p>\n<p>The year in which the global population reached 1 billion: 1804.</p>\n<p>The average percentage of a watermelon's weight that comes from water: 92.</p>\n<p>&nbsp;</p>\n<p><a id=\"more\"></a>The old post:</p>\n<p>There <a href=\"/lw/j/the_costs_of_rationality/\">has</a> <a href=\"/lw/41/individual_rationality_is_a_matter_of_life_and/\">been</a> <a href=\"/lw/9p/extreme_rationality_its_not_that_great/\">much</a> <a href=\"/lw/2c/a_sense_that_more_is_possible/\">discussion</a> of the extent to which rationality is or isn&rsquo;t practically useful.&nbsp; There have also been many calls for better empirical evidence.<br /><br />In an attempt to produce empirical evidence for or against rationality&rsquo;s usefulness for LW-ers, I have here a rationality questionnaire.&nbsp; It takes about 15 minutes to complete, according to myself and to Katja Grace, who kindly helped me with it.&nbsp; I tried to hug the query of &ldquo;Are there OB/LW-like techniques, or similar techniques, that actually help LW-ers achieve their goals?&rdquo;&nbsp;&nbsp; <strong>This isn&rsquo;t a test -- we&rsquo;re not measuring individuals&rsquo; rationality -- we&rsquo;re just looking for correlations and noisy indicators that may nevertheless tell us give us useful info in aggeragate, when used on groups.</strong><br /><br />Fill in the survey -- by following</p>\n<p><a href=\"http://spreadsheets.google.com/viewform?formkey=cDRQN25STjJFemEzVFljVzk5M0tIR0E6MA..\"><strong>this survey link</strong> [Survey is now closed.&nbsp; Though the link will still let you see the questions.]<br /></a></p>\n<p>-- and know your next 15 minutes will contribute to science, truth, rationality, and the future practical successes of LW-ers.&nbsp; =)&nbsp; (... at least as far as expected value is concerned, if you assign some probablity to this data being useful.)</p>\n<p>ADDED:&nbsp; Please hold off on discussing the implications of different responses for a day or two, until the rate of survey-completions dies down.&nbsp; Unless you're <strong>sure</strong> your discussion won't prejudice others' answers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"kJrjorSx3hXa7q7CJ": 1, "MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hbdYWmu2ozwNvvWcW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 22, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "411", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9Z3pezjiWLfNANg9P", "WzMJRQBN3ryxiAbhi", "LgavAYtzFQZKg95WC", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T00:49:54.828Z", "modifiedAt": null, "url": null, "title": "Test Post", "slug": "test-post-3", "viewCount": null, "lastCommentedAt": "2017-06-17T03:52:33.370Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wmoore", "createdAt": "2009-02-17T05:49:50.396Z", "isAdmin": false, "displayName": "wmoore"}, "userId": "EgQZcMBqxf6sGmKfi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/agJzTQ6AqZKtKnyvW/test-post-3", "pageUrlRelative": "/posts/agJzTQ6AqZKtKnyvW/test-post-3", "linkUrl": "https://www.lesswrong.com/posts/agJzTQ6AqZKtKnyvW/test-post-3", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Test%20Post&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATest%20Post%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FagJzTQ6AqZKtKnyvW%2Ftest-post-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Test%20Post%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FagJzTQ6AqZKtKnyvW%2Ftest-post-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FagJzTQ6AqZKtKnyvW%2Ftest-post-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": null, "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "agJzTQ6AqZKtKnyvW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 2e-06, "legacy": true, "legacyId": "414", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": null, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T01:25:26.171Z", "modifiedAt": null, "url": null, "title": "My Way", "slug": "my-way", "viewCount": null, "lastCommentedAt": "2019-08-19T23:19:12.235Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FBgozHEv7J72NCEPB/my-way", "pageUrlRelative": "/posts/FBgozHEv7J72NCEPB/my-way", "linkUrl": "https://www.lesswrong.com/posts/FBgozHEv7J72NCEPB/my-way", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20Way&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20Way%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFBgozHEv7J72NCEPB%2Fmy-way%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20Way%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFBgozHEv7J72NCEPB%2Fmy-way", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFBgozHEv7J72NCEPB%2Fmy-way", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2016, "htmlBody": "<p><strong>Previously in series</strong>:&nbsp; <a href=\"/lw/5f/bayesians_vs_barbarians/\">Bayesians vs. Barbarians</a><br /><strong>Followup to</strong>:&nbsp; <a href=\"/lw/ap/of_gender_and_rationality/\">Of Gender and Rationality</a>, <a href=\"/lw/9v/beware_of_otheroptimizing/\">Beware of Other-Optimizing</a></p>\n<p>There is <a href=\"/lw/5f/bayesians_vs_barbarians/\">no such thing</a> as masculine probability theory or feminine decision theory.&nbsp; In their pure form, the maths probably <a href=\"http://www.overcomingbias.com/2009/02/super-happy-people.html\">aren't even human</a>.&nbsp; But the <em>human practice</em> of rationality&mdash;the arts associated with, for example, motivating yourself, or compensating factors applied to overcome your own biases&mdash;these things can in principle differ from gender to gender, or from person to person.</p>\n<p>My attention was first drawn to this possibility of <a href=\"/lw/9v/beware_of_otheroptimizing/\">individual differences in optimization</a> (in general) by thinking about <a href=\"/lw/ap/of_gender_and_rationality/\">rationality and gender</a> (in particular).&nbsp; I've written rather more fiction than I've ever <em>finished</em> and <em>published,</em> including a story in which the main character, who happens to be the most rational person around, happens to be female.&nbsp; I experienced no particular difficulty in writing a female character who happened to be a rationalist.&nbsp; But she was not an <em>obtrusive, explicit</em> rationalist.&nbsp; She was not <a href=\"http://www.overcomingbias.com/2008/05/eld-science.html\">Jeffreyssai</a>.</p>\n<p>And it occurred to me that I could not imagine how to write Jeffreyssai as a woman; his way of teaching is paternal, not maternal.&nbsp; Even more, it occurred to me that in my writing there are women who are highly <em>rational</em> (on their way to other goals) but not women who are <em>rationalists</em> (as their primary, explicit role in the story).</p>\n<p>It was at this point that I realized how much of my own take on rationality was specifically male, which hinted in turn that even more of it might be specifically Eliezer Yudkowsky.<a id=\"more\"></a></p>\n<p>A parenthetical, at this point, upon my own gender politics (lest anyone misinterpret me here).&nbsp; Of much of what passes for gender politics in present times, I have very little patience, as you might guess.&nbsp; But <a href=\"http://pics.blameitonthevoices.com/042009/small_from%201970s%20childrens%20book.jpg\">as recently as the 1970s this still passed for educational material</a>, which makes me a bit more sympathetic.</p>\n<p>So this about my gender politics:&nbsp; Unlike the case with, say, race, I don't think that an optimal outcome consists of gender distinctions being obliterated.&nbsp; If the day comes when no one notices or cares whether someone is black or white, any more than they notice eye color, I would only applaud.&nbsp; But obliterating the difference between male and female does <em>not </em>seem to me desirable, and I am glad that it is impossible using present-day technology; the fact that humanity has (at least) two sexes is <a href=\"http://www.overcomingbias.com/2009/01/failed-utopia-42.html\">part of what keeps life interesting</a>.</p>\n<p><em>But</em> it seems to me that, as an inheritance from the dark ages, the concept of \"normal\" is tilted more toward male than female.&nbsp; Men are not constantly made aware that they are men in the same way that women are made constantly aware that they are women.&nbsp; (Though there are contexts where explicit masculinity is suddenly a focus.)&nbsp; It's not fun for women if <em>female</em> is defined as <em>abnormal,</em> as <em>special.</em>&nbsp; And so some feminists direct their efforts into trying to collapse gender distinctions, the way you would try to collapse racial distinctions.&nbsp; Just have everyone be normal, part of the same group.&nbsp; But I don't think that's realistic for our species&mdash;sex is real, it's not just gender&mdash;and in any case I <em>prefer</em> to live in a culture with (at least) two genders.</p>\n<p>So&mdash;rather than obliterate the difference between genders into a common normality&mdash;I think that men should become more aware of themselves as men, so that being female isn't any <em>more</em> special or unusual or abnormal or worthy-of-remark than being male.&nbsp; Until a man sees his own argumentativeness as a distinctively male trait, he'll see women as <em>abnormally passive</em> (departures from the norm) rather than thinking \"I am a male and therefore argumentative\" (in the same way that women now identify various parts of themselves as feminine).</p>\n<p>And yes, this does involve all sorts of dangers.&nbsp; Other cultures already have stronger male gender identities, and that's not always a good thing for the women in those cultures, if that culture already has an imbalance of power.&nbsp; But I'm not sure that the safe-seeming path of trying to obliterate as many distinctions as possible, is really <em>available;</em> men and women <em>are</em> different.&nbsp; Moreover, I <em>like</em> being a man free to express those forms of masculinity that I think are worthwhile, and I want to live in a world in which women are free to express whatever forms of feminity they think are worthwhile.</p>\n<p>I'm saying all this, because I look over my accumulated essays and see that I am a distinctively <em>male</em> rationalist.&nbsp; Meanwhile, in another thread, a number of my fellow rationalists did go to some length to disidentify themselves as \"female rationalists\".&nbsp; I am sympathetic; from having been a child prodigy, I know how annoying it is to be celebrated as \"having done so much while so young\" rather than just \"having done neat stuff in its own right regardless of age\".&nbsp; I doubt that being singled out as an \"amazing <em>female</em> rationalist\" is any less annoying.&nbsp; But still:&nbsp; I built my art out of <em>myself</em>, and it became tied into every part of myself, and it happens to be a fact that I'm male.&nbsp; And if a woman were to pursue her art far enough, and tie it into every part of herself, she would, I think, find that her art came to resemble herself more and more, tied into her own motives and preferences; so that her art was, among other things, female.</p>\n<p>It's hard to pin down this sort of thing exactly, because my own brain knows only half the story.&nbsp; My understanding of what it means to be female is too much <em>shallower </em>than my understanding of what it means to be male, it doesn't ring as true.&nbsp; I will try, though, to give an example of what I mean, if you will excuse me another excursion...</p>\n<p>The single author I know who strikes me as <em>most </em><em>feminine</em> is Jacqueline Carey.&nbsp; When I read her book <em>Kushiel's Avatar,</em> it gave me a feeling of being <em>overwhelmingly</em> outmatched as an author.&nbsp; I <em>want </em>to write characters with that kind of incredible depth and I <em>can't.</em>&nbsp; She is too far above me as an author.&nbsp; I write stories with female characters, and I wish I could write female characters who were as female as Carey's female characters, and so long as I'm dreaming, I also want to sprout wings and fly.</p>\n<p>Let me give you an example, drawn from <em>Kushiel's Avatar.</em>&nbsp; This book&mdash;as have so many other books&mdash;involves, among its other plot points, saving the world.&nbsp; A shallow understanding of sex and gender, built mostly around abstract evolutionary psychology&mdash;such as I myself possess&mdash;would suggest that \"taking great risks to save your tribe\" is likely to be a more male sort of motivation&mdash;the status payoff from success would represent a greater fitness benefit to a man, and in the ancestral environment, it is the men who defend their tribe, etcetera.&nbsp; But in fact, reading SF and fantasy books by female authors, I have not noticed any particularly <em>lower </em>incidence of world-saving behavior by female protagonists.</p>\n<p>If you told me to write a strongly feminine character, then I, with my shallow understanding, might try to have her risk everything to save her husband.&nbsp; The protagonist of <em>Kushiel's Avatar,</em> Ph&egrave;dre n&oacute; Delaunay, does realize that the world is in danger and it needs to be saved.&nbsp; But she is also, in the same process, trying to rescue a kidnapped young boy.&nbsp; Her own child?&nbsp; That's how I would have written the story, but no; she is trying to rescue someone <em>else's</em> child.&nbsp; The child of her own archenemy, in fact, but no less innocent for all that.&nbsp; When I look at it after the fact, I can see how this reveals a deeper feminity, not the stereotype but a step beyond and behind the stereotype, something that rings <em>true</em>.&nbsp; Ph&egrave;dre loves her husband&mdash;and this is shown <em>not </em>by how she puts aside saving the world to save him, but by how much it hurts her to put him in harm's way to save the world.&nbsp; Her feminity is shown, not by how protective she is toward her own child, but toward someone else's child.</p>\n<p>It is this <a href=\"http://www.overcomingbias.com/2007/10/how-to-seem-and.html\">depth</a> of writing that makes me aware of how my own brain is only <a href=\"http://www.overcomingbias.com/2007/10/original-seeing.html\">regurgitating stereotypes</a> by comparison.</p>\n<p>I do dare say that I have developed my art of rationality as thoroughly as Carey has developed her thesis on love.&nbsp; And so <em>my</em> art taps into parts of me that are male.&nbsp; I cultivate the desire to become stronger; I accept and acknowledge within myself the desire to outdo others; I have learned to take pride in my identity as someone who faces down impossible challenges.&nbsp; While my own brain only knows half the story, it does seem to me that this is <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/Determinator\">noticeably</a> more a theme of <em>sh\u014dnen</em> anime than <em>sh</em><em>\u014d</em><em>jo</em> anime.&nbsp; Watch <em>Hikaru no Go</em> for an idea of what I mean.</p>\n<p>And this is the reason why I can't write Jeffreyssai as a woman&mdash;I would not be able to really understand her motivations; I don't understand what taps female drives on that deep a level.&nbsp; I can regurgitate stereotypes, but reading Jacqueline Carey has made me aware that my grasp is shallow; it would not ring true.</p>\n<p>What would the corresponding female <em>rationalist </em>be like?&nbsp; I don't know.&nbsp; I can't say.&nbsp; Some woman has to pursue her art as far as I've pursued mine, far enough that <a href=\"http://www.overcomingbias.com/2008/05/no-defenses.html\">the art she learned from others fails her</a>, so that she must remake her shattered art in her own image and in the image of her own task.&nbsp; And then tell the rest of us about it.</p>\n<p>I sometimes think of myself as being like the protagonist in a classic SF labyrinth story, wandering further and further into some alien artifact, trying to call into a radio my description of the bizarre things I'm seeing, so that I can be followed.&nbsp; But what I'm finding is not just <em>the</em> Way, the thing that lies at the center of the labyrinth; it is also <em>my</em> Way, the path that <em>I</em> would take to come closer to the center, from whatever place I started out.</p>\n<p>(Perhaps a woman would phrase the above, not as \"Bayes's Theorem is the high pure abstract thing that is not male or female\", but rather, \"Bayes's Theorem is something we can all agree on\".&nbsp; Or maybe that's only my own brain regurgitating stereotypes.)</p>\n<p>Someone's bound to suggest, \"Take the male parts out, then!&nbsp; Don't describe rationality as 'the martial art of mind'.\"&nbsp; Well... I may put in some work to gender-purify my planned book on rationality.&nbsp; It would be too much effort to make my blog posts less like myself, in that dimension.&nbsp; But I also want to point out that I <em>enjoyed</em> reading <em>Kushiel's Avatar</em>&mdash;I was not blocked from appreciating it on account of the book being visibly female.</p>\n<p>I say all this because I want to convey this important idea, that there is <em>the</em> Way and <em>my</em> Way, the pure (or perhaps <em>shared</em>) thing at the center, and the many paths we take there from wherever we started out.&nbsp; To say that the path is <em>individualized</em>, is <em>not </em>to say that we are <a href=\"/lw/57/the_sacred_mundane/\">shielded from criticism by a screen of privacy</a> (a common idiom of modern <a href=\"http://www.overcomingbias.com/2008/10/the-dark-side.html\">Dark Side Epistemology</a>).&nbsp; There is still a common thing we are all trying to find.&nbsp; We <a href=\"/lw/9v/beware_of_otheroptimizing/\">should be aware</a> that others' shortest paths may not be the <em>same</em> as our own, but this is not the same as giving up the ability to judge <em>or</em> to share.</p>\n<p>Even so, you should be aware that I have radioed back my description of the single central shape and the path <em>I</em> took to get closer.&nbsp; If there are parts that are visibly male, then there are probably other parts&mdash;perhaps harder to identify&mdash;that are tightly bound to growing up with Orthodox Jewish parents, or (cough) certain other unusual features of my life.</p>\n<p>I think there will not be a <em>proper </em>Art until <em>many</em> people have progressed to the point of remaking the Art in their own image, and then radioed back to describe their paths.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/c3/the_sin_of_underconfidence/\">The Sin of Underconfidence</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/ap/of_gender_and_rationality/\">Of Gender and Rationality</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FBgozHEv7J72NCEPB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 55, "baseScore": 45, "extendedScore": null, "score": 6.9e-05, "legacy": true, "legacyId": "409", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 126, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KsHmn6iJAEr9bACQW", "xsyG7PkMekHud2DMK", "6NvbSwuSAooQxxf7f", "Fwt4sDDacko8Sh5iR", "YdcF6WbBmJhaaDqoD", "pkFazhcTErMw7TFtT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T01:54:32.266Z", "modifiedAt": null, "url": null, "title": "The Art of Critical Decision Making", "slug": "the-art-of-critical-decision-making", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:37.823Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/D8vWc2SdBsTbmcrNw/the-art-of-critical-decision-making", "pageUrlRelative": "/posts/D8vWc2SdBsTbmcrNw/the-art-of-critical-decision-making", "linkUrl": "https://www.lesswrong.com/posts/D8vWc2SdBsTbmcrNw/the-art-of-critical-decision-making", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Art%20of%20Critical%20Decision%20Making&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Art%20of%20Critical%20Decision%20Making%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD8vWc2SdBsTbmcrNw%2Fthe-art-of-critical-decision-making%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Art%20of%20Critical%20Decision%20Making%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD8vWc2SdBsTbmcrNw%2Fthe-art-of-critical-decision-making", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD8vWc2SdBsTbmcrNw%2Fthe-art-of-critical-decision-making", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 35, "htmlBody": "<p><a href=\"http://www.teach12.com/ttcx/coursedesclong2.aspx?cid=5932\">The Art of Critical Decision Making</a> is a new 12-hour lecture series (audio and video) available from The Teaching Company, available as an audio MP3 download for $35.&nbsp; After May 14 it will cost $130.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"KoXbd2HmbdRfqLngk": 1, "izp6eeJJEg9v5zcur": 1, "zv7v2ziqexSn5iS9v": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "D8vWc2SdBsTbmcrNw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": -2, "extendedScore": null, "score": 4.882704196845415e-07, "legacy": true, "legacyId": "415", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T02:07:32.881Z", "modifiedAt": "2020-04-30T19:59:59.889Z", "url": null, "title": "The Trouble With \"Good\"", "slug": "the-trouble-with-good", "viewCount": null, "lastCommentedAt": "2017-06-17T04:35:33.553Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Scott Alexander", "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M2LWXsJxKS626QNEA/the-trouble-with-good", "pageUrlRelative": "/posts/M2LWXsJxKS626QNEA/the-trouble-with-good", "linkUrl": "https://www.lesswrong.com/posts/M2LWXsJxKS626QNEA/the-trouble-with-good", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Trouble%20With%20%22Good%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Trouble%20With%20%22Good%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM2LWXsJxKS626QNEA%2Fthe-trouble-with-good%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Trouble%20With%20%22Good%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM2LWXsJxKS626QNEA%2Fthe-trouble-with-good", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM2LWXsJxKS626QNEA%2Fthe-trouble-with-good", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1921, "htmlBody": "<p><strong>Related to: </strong><a href=\"https://www.lesswrong.com/posts/yA4gF5KrboK2m2Xu7/how-an-algorithm-feels-from-inside\">How An Algorithm Feels From Inside</a>, <a href=\"https://www.lesswrong.com/posts/Kow8xRzpfkoY7pa69/the-affect-heuristic\">The Affect Heuristic</a>, <a href=\"/lw/48/the_power_of_positivist_thinking/\">The Power of Positivist Thinking</a></p>\n<p>I am a normative utilitarian and a descriptive emotivist: I believe utilitarianism is the correct way to resolve moral problems, but that the normal mental algorithms for resolving moral problems use emotivism.<br /><br />Emotivism, aka the yay/boo theory, is the belief that moral statements, however official they may sound, are merely personal opinions of preference or dislike. Thus, \"feeding the hungry is a moral duty\" corresponds to \"yay for feeding the hungry!\" and \"murdering kittens is wrong\" corresponds to \"boo for kitten murderers!\"<br /><br />Emotivism is a very nice theory of what people actually mean when they make moral statements. Billions of people around the world, even the non-religious, happily make moral statements every day without having any idea what they reduce to or feeling like they ought to reduce to anything.<br /><br />Emotivism also does a remarkably good job capturing the common meanings of the words \"good\" and \"bad\". An average person may have beliefs like \"pizza is good, but seafood is bad\", \"Israel is good, but Palestine is bad\", \"the book was good, but the movie was bad\", \"atheism is good, theism is bad\", \"evolution is good, creationism is bad\", and \"dogs are good, but cats are bad\". Some of these seem to be moral beliefs, others seem to be factual beliefs, and others seem to be personal preferences. But we are happy using the word \"good\" for all of them, and it doesn't feel like we're using the same word in several different ways, the way it does when we use \"right\" to mean both \"correct\" and \"opposite of left\". It feels like they're all just the same thing. The moral theory that captures that feeling is emotivism. Yay pizza, books, Israelis, atheists, dogs, and evolution! Boo seafood, Palestinians, movies, theists, creationism, and cats!</p>\n<p><a id=\"more\"></a></p>\n<p>Remember, evolution is a crazy tinker who recycles everything. So it would not be surprising to find that our morality is a quick hack on the same machinery that runs our decisions about which food to eat or which pet to adopt. To make an outrageous metaphor: our brains run a system rather like Less Wrong's karma. You're allergic to cats, so you down-vote \"cats\" a couple of points. You hear about a Palestinian committing a terrorist attack, so you down-vote \"Palestinians\" a few points. Richard Dawkins just said something especially witty, so you up-vote \"atheism\". High karma score means seek it, use it, acquire it, or endorse it. Low karma score means avoid it, ignore it, discard it, or condemn it.<sup>1</sup><br /><br />Remember back during the presidential election, when a McCain supporter claimed that an Obama supporter attacked her and carved a \"B\" on her face with a knife? This was HUGE news. All of my Republican friends started emailing me&nbsp; and saying \"Hey, did you hear about this, this proves we've been right all along!\" And all my Democratic friends were grumbling and saying how it was probably made up and how we should all just forget the whole thing.<br /><br />And then it turned out it WAS all made up, and the McCain supporter had faked the whole affair. And now all of my Democrat friends started emailing me and saying \"Hey, did you hear about this, it shows what those Republicans and McCain supporters are REALLY like!\" and so on, and the Republicans were trying to bury it as quickly as possible.<br /><br />The overwhelmingly interesting thing I noticed here was that everyone seemed to accept - not explicitly, but implicitly very much - that an Obama supporter acting violently was in some sense evidence against Obama or justification for opposition to Obama; or, that a McCain supporter acting dishonestly was in some sense evidence against McCain or confirmation that Obama supporters were better people. To a Bayesian, this would be balderdash. But to an emotivist, where any bad feelings associated with Obama count against him, it sort of makes sense. All those people emailing me about this were saying: Look, here is something negative associated with Obama; downvote him!<sup>2</sup><br /><br />So this is one problem: the inputs to our mental karma system aren't always closely related to the real merit of a person/thing/idea.<br /><br />Another problem: our interpretation of whether to upvote or downvote something depends on how many upvotes or downvotes it already has. Here on Less Wrong we call this an <a href=\"/lw/z/information_cascades/\">information cascade</a>. In the mind, we call it an <a href=\"https://www.lesswrong.com/posts/XrzQW69HpidzvBxGr/affective-death-spirals\">Affective Death Spiral</a>.<br /><br />Another problem: we are tempted to assign everything about a concept the same score. Eliezer Yudkowsky currently has 2486 karma. How good is Eliezer at philosophy? Apparently somewhere around the level it would take to get 2486 karma. How much does he know about economics? Somewhere around level 2486 would be my guess. How well does he write? Probably well enough to get 2486 karma. Translated into mental terms, this looks like <a href=\"https://www.lesswrong.com/posts/ACGeaAk6KButv2xwQ/the-halo-effect\">the Halo Effect</a>. Yes, we can pick apart our analyses in greater detail; having read Eliezer's posts, I know he's better at some things than others. But that 2486 number is going to cause anchoring-and-adjustment issues even so.<br /><br />But the big problem, the world-breaking problem, is that sticking everything good and bad about something <a href=\"https://www.lesswrong.com/posts/Kow8xRzpfkoY7pa69/the-affect-heuristic\">into one big bin and making decisions</a> based on whether it's a net positive or a net negative is an unsubtle, leaky heuristic completely unsuitable for complicated problems.<br /><br />Take gun control. Are guns good or bad? My gut-level emotivist response is: bad. They're loud and scary and dangerous and they shoot people and often kill them. It is very tempting to say: guns are bad, therefore we should have fewer of them, therefore gun control. I'm not saying gun control is therefore wrong: reversed stupidity is not intelligence. I'm just saying that before you can rationally consider whether or not gun control is wrong, you need to get past this mode of thinking about the problem.<br /><br />In the hopes of using theism less often, a bunch of Less Wrongers have agreed that the War on Drugs would make a good stock example of irrationality. So, why is the War on Drugs so popular? I think it's because drugs are obviously BAD. They addict people, break up their families, destroy their health, drive them into poverty, and eventually kill them. If we've got to have a category \"drugs\"<sup>3</sup>, and we've got to call it either \"good\" or \"bad\", then \"bad\" is clearly the way to go. And if drugs are bad, getting rid of them would be good! Right?<br /><br />So how do we avoid all of these problems?<br /><br />I said at the very beginning that I think we should switch to solving moral problems through utilitarianism. But we can't do that directly. If we ask utilitarianism \"Are drugs good or bad?\" it returns: CATEGORY ERROR. Good for it.<br /><br />Utilitarianism can only be applied to states, actions, or decisions, and it can only return a comparative result. Want to know whether stopping or diverting the trolley in the Trolley Problem would be better? Utilitarianism can tell you. That's because it's a decision between two alternatives (alternate way of looking at it: two possible actions; or two possible states) and all you need to do is figure out which of the two is higher utility.<br /><br />When people say \"Utilitarianism says slavery is bad\" or \"Utilitarianism says murder is wrong\" - well, a utilitarian would endorse those statements over their opposites, but it takes a lot of interpretation first. What utilitarianism properly says is \"In this particular situation, the action of freeing the slaves leads to a higher utility state than not doing so\" and possibly \"and the same would be true of any broadly similar situation\".<br /><br />But why in blue blazes can't we just go ahead and say \"slavery is bad\"? What could possibly go wrong?<br /><br />Ask an anarchist. Taxation of X% means you're forced to work for X% of the year without getting paid. Therefore, since slavery is \"being forced to work without pay\" taxation is slavery. Since slavery is bad, taxation is bad. Therefore government is bad and statists are no better than slavemasters.<sup>4</sup><br /><br />(again, reversed stupidity is not intelligence. There are good arguments against taxation. But this is not one of them.)<br /><br />Emotivism is the native architecture of the human mind. No one can think like a utilitarian all the time. But when you are in an Irresolvable Debate, utilitarian thinking may become necessary to avoid dangling variable problems around the word \"good\" (<a href=\"/lw/48/the_power_of_positivist_thinking/\">cf. Islam is a religion of peace</a>). Problems that are insoluble at the emotivist level can be reduced, simplified, and resolved on the utilitarian level with enough effort.<br /><br />I've used the example before, and I'll use it again. Israel versus Palestine. One person can go on and on for months about all the reasons the Israelis are totally right and the Palestinians are completely in the wrong, and another person can go on just as long about how the Israelis are evil oppressors and the Palestinians just want freedom. And then if you ask them about an action, or a decision, or a state - they've never thought about it. They'll both answer something like \"I dunno, the two-state solution or something?\". And if they still disagree at this level, you can suddenly apply the full power of utilitarianism to the problem in a way that tugs sideways to all of their personal prejudices.<br /><br />In general, any debate about whether something is \"good\" or \"bad\" is sketchy, and can be changed to a more useful form by converting the thing to an action and applying utilitarianism.</p>\n<p><strong>Footnotes:</strong><br /><br /><strong>1:</strong> It should be noted that this karma analogy can't explain our original perception of good and bad, only the system we use for combining, processing and utilizing it. My guess is that the original judgment of good or bad takes place through association with other previously determined good or bad things, down to the bottom level which are programmed into the organism (ie pain, hunger, death) with some input from the rational centers.<br /><br /><strong>2:</strong> More evidence: we tend to like the idea of \"good\" or \"bad\" being innate qualities of objects. Thus the alternative medicine practioner who tells you that real medicine is bad, because it uses scary pungent chemicals, which are unhealthy, and alternative medicine is good, because it uses roots and plants and flowers, which everyone likes. Or fantasy books, where the Golden Sword of Holy Light can only be wielded for good, and the Dark Sword of Demonic Shadow can only be wielded for evil.<br /><br /><strong>3: </strong>Of course, the battle has already been half-lost once you have a category \"drugs\". Eliezer once mentioned something about how considering {Adolf Hitler, Joe Stalin, John Smith} a natural category isn't going to do John Smith any good, no matter how nice a man he may be. In the category \"drugs\", which looks like {cocaine, heroin, LSD, marijuana}, LSD and marijuana get to play the role of John Smith.</p>\n<p><strong>4:</strong> And, uh, <a href=\"/lw/9b/help_help_im_being_oppressed/62n\">I'm sure Louis XVI would feel the same way</a>. Sorry. I couldn't think of a better example.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "Kj9q8FXoauL7mQDWt": 2, "4R8JYu4QF2FqzJxE5": 2, "5f5c37ee1b5cdee568cfb0e9": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M2LWXsJxKS626QNEA", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 99, "baseScore": 96, "extendedScore": null, "score": 0.000158, "legacy": true, "legacyId": "416", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 96, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 137, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["yA4gF5KrboK2m2Xu7", "Kow8xRzpfkoY7pa69", "azoP7WeKYYfgCozoh", "DNQw596nPCX4x7xT9", "XrzQW69HpidzvBxGr", "ACGeaAk6KButv2xwQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T08:01:10.478Z", "modifiedAt": null, "url": null, "title": "While we're on the subject of meta-ethics...", "slug": "while-we-re-on-the-subject-of-meta-ethics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:30.287Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J2zFSMNxkz2CaPYqq/while-we-re-on-the-subject-of-meta-ethics", "pageUrlRelative": "/posts/J2zFSMNxkz2CaPYqq/while-we-re-on-the-subject-of-meta-ethics", "linkUrl": "https://www.lesswrong.com/posts/J2zFSMNxkz2CaPYqq/while-we-re-on-the-subject-of-meta-ethics", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20While%20we're%20on%20the%20subject%20of%20meta-ethics...&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhile%20we're%20on%20the%20subject%20of%20meta-ethics...%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ2zFSMNxkz2CaPYqq%2Fwhile-we-re-on-the-subject-of-meta-ethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=While%20we're%20on%20the%20subject%20of%20meta-ethics...%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ2zFSMNxkz2CaPYqq%2Fwhile-we-re-on-the-subject-of-meta-ethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ2zFSMNxkz2CaPYqq%2Fwhile-we-re-on-the-subject-of-meta-ethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 84, "htmlBody": "<p>The best theory of morality I've ever found is the one invented by <a href=\"http://www.alonzofyfe.com/\">Alonzo Fyfe</a>, which he chose to call \"desire utilitarianism.\"</p>\n<p><a href=\"http://ia331413.us.archive.org/2/items/WhatIsMoralityMeta-ethicsInPlainTalkpdf/WhatIsMorality-Meta-ethicsInPlainTalkV1.0.pdf\">This short e-book</a> (warning: pdf), written by a commenter on <a href=\"http://atheistethicist.blogspot.com/\">Alonzo's blog</a>, describes the theory very well. He also wrote <a href=\"http://commonsenseatheism.com/?p=776\">a FAQ</a>.</p>\n<p>One great advantage of this theory is that what it describes <em>actually exists</em> even if you <a href=\"http://www.overcomingbias.com/2008/03/wrong-words.html\">prefer to use the word \"morality\" to mean something else.</a>&nbsp; Even a community of <a href=\"http://lesswrong.wikia.com/wiki/Paperclip_maximizer\">paperclip maximizer</a>s may find something in it to be relevant, amazingly enough.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ouT6wKhACJRouGokM": 1, "Z8wZZLeLMJ3NSK7kR": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J2zFSMNxkz2CaPYqq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 7e-06, "legacy": true, "legacyId": "417", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T17:52:35.547Z", "modifiedAt": null, "url": null, "title": "Chomsky on reason and science", "slug": "chomsky-on-reason-and-science", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:31.898Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bXqtCQYXgrFd9DYaZ/chomsky-on-reason-and-science", "pageUrlRelative": "/posts/bXqtCQYXgrFd9DYaZ/chomsky-on-reason-and-science", "linkUrl": "https://www.lesswrong.com/posts/bXqtCQYXgrFd9DYaZ/chomsky-on-reason-and-science", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Chomsky%20on%20reason%20and%20science&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AChomsky%20on%20reason%20and%20science%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbXqtCQYXgrFd9DYaZ%2Fchomsky-on-reason-and-science%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Chomsky%20on%20reason%20and%20science%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbXqtCQYXgrFd9DYaZ%2Fchomsky-on-reason-and-science", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbXqtCQYXgrFd9DYaZ%2Fchomsky-on-reason-and-science", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 616, "htmlBody": "<p>I came across this delightful <a href=\"http://www.chomsky.info/articles/1995----02.htm\">1995 article by Noam Chomsky</a> while testing whether googling 'rationality' would lead people to LW (it doesn't).&nbsp; It defends rational inquiry against postmodern, Kuhnian attacks<sup>1</sup>.&nbsp; I was pleasantly surprised, because Chomsky is ideologically aligned with the people making the attacks.&nbsp; (Also because I have reservations about Chomsky's rationality, which I will not state because I don't want this to turn into a discussion of Chomsky, socialism, American foreign policy, or universal grammar.)</p>\n<p>Here are some choice sentences:</p>\n<blockquote>\n<p>With regard to the second problem, since what is called \"science,\" etc., is largely unfamiliar to me, let me replace it by \"X,\" and see if I understand the argument against X. Let's consider several kinds of properties attributed to X, then turning to the proposals for a new direction; quotes below are from the papers criticizing X.</p>\n<p>&lt;long paragraph of <a href=\"/lw/ah/toxic_truth/\">DHMO</a>-like attributions about X&gt;</p>\n<p>Conclusion: there is \"something inherently wrong\" with X. We must reject or transcend it, replacing it by something else; and we must instruct poor and suffering people to do so likewise. It follows that we must abandon literacy and the arts, which surely satisfy the conditions on X as well as science. More generally, we must take a vow of silence and induce the world's victims to do so likewise since language and its use typically have all these properties.</p>\n</blockquote>\n<p>...</p>\n<blockquote>\n<p>There is also at least an element of truth in the statement that the natural sciences are \"disembedded from the body, from metaphorical thought, from ethical thought and from the world\"--to their credit. ... Though scientists are human, and cannot get out of their skins, they certainly, if honest, try to overcome the distortions imposed by \"body\" (in particular, human cognitive structures, with their specific properties) as much as possible. ... It is also true that \"Reason separates the `real' or knowable...and the `not real',\" or at least tries to (without identifying \"real\" with \"knowable\")--again, to its credit.</p>\n</blockquote>\n<p>...</p>\n<blockquote>\n<p>It strikes me as remarkable that their left counterparts today should seek to deprive oppressed people not only of the joys of understanding and insight, but also of tools of emancipation, informing us that the \"project of the Enlightenment\" is dead, that we must abandon the \"illusions\" of science and rationality--a message that will gladden the hearts of the powerful, delighted to monopolize these instruments for their own use.</p>\n</blockquote>\n<p>...</p>\n<blockquote>\n<p>The critique of \"science\" and \"rationality\" has many merits, which I haven't discussed. But as far as I can see, where valid and useful the critique is largely devoted to the perversion of the values of rational inquiry as they are \"wrongly used\" in a particular institutional setting. What is presented here as a deeper critique of their nature seems to me based on beliefs about the enterprise and its guiding values that have little basis. No coherent alternative is suggested, as far as I can discern; the reason, perhaps, is that there is none. What is suggested is a path that leads directly to disaster for people who need help--which means everyone, before too long.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p><sup>1</sup>&nbsp; Kuhn later claimed not to have made these kinds of attacks on science.&nbsp; I don't accept citations of Kuhn's interpretation of Kuhn as valid; I've concluded that my interpretation of Kuhn-1962 is more accurate than Kuhn-1977's interpretation of Kuhn-1962.&nbsp; What I think happened was that Kuhn made a lot of radical claims and rode them to fame; once he was famous and part of the establishment, it was advantageous to abandon those claims and pretend not to have made them.&nbsp; Anyway, Kuhn has said \"I am not a Kuhnian\", so I take that as license to keep using the term the way I used it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bXqtCQYXgrFd9DYaZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 8, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "406", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["g3W2mLoGN5osuH4f4"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T17:55:30.517Z", "modifiedAt": null, "url": null, "title": "Anti-rationality quotes", "slug": "anti-rationality-quotes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:38.208Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kWRFfWfhrS6m4Fibm/anti-rationality-quotes", "pageUrlRelative": "/posts/kWRFfWfhrS6m4Fibm/anti-rationality-quotes", "linkUrl": "https://www.lesswrong.com/posts/kWRFfWfhrS6m4Fibm/anti-rationality-quotes", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anti-rationality%20quotes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnti-rationality%20quotes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkWRFfWfhrS6m4Fibm%2Fanti-rationality-quotes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anti-rationality%20quotes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkWRFfWfhrS6m4Fibm%2Fanti-rationality-quotes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkWRFfWfhrS6m4Fibm%2Fanti-rationality-quotes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1354, "htmlBody": "&nbsp;\n<p>There's a semi-regular feature on OB called \"Rationality quotes\".&nbsp; In <a href=\"/lw/ay/marketing_rationalism/\">Marketing rationality</a>, I'm claiming that for conservative religious people, using rationality instrumentally is as epistemically dangerous as for us to use faith instrumentally.&nbsp; People object.&nbsp; So to supplement that, I'm giving you a list of anti-rationality quotes.&nbsp; I originally compiled them to respond to a theologian who claimed that Christianity encouraged inquisitiveness; but I think they apply to reason as well.&nbsp; Please note that these quotes are not from obscure authors; all of these quotes, with the <em>possible</em> exception of Sturgeon, are from authors who are considered by Christians (either Catholics or Protestants) to be more authoritative than anyone alive today.<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> </w:WordDocument> </xml><![endif]--><!--[endif]--></p>\n<p>Some of these examples come from &ldquo;<span style=\"font-weight: normal;\">Curiosity, Forbidden Knowledge, and the Reformation of Natural Philosophy in Early Modern England</span>&rdquo;, Peter Harrison, <em>Isis</em>, Vol. 92, No. 2 (June 2001), pp. 265-290; and from <em>The Uses of Curiosity in Early Modern France and Germany</em>, Neil Kenny (2004).&nbsp; 2 quotes come from chpt. 5 of Hitchens, <em>God is Not Great</em>.&nbsp; (His Aquinas quote, however, says exactly the opposite of what Aquinas actually said.)&nbsp; Some of them I found myself.</p>\n<p>Also see the <a href=\"http://en.wikipedia.org/wiki/Syllabus_of_Errors\">Wikipedia page on the Syllabus of Errors</a> that <a href=\"/lw/b0/antirationality_quotes/839\">byrnema provided</a>.</p>\n<p>ADDED:&nbsp; ICMMT.&nbsp; I concede that the relation between rationalists using unreason, and Christians using reason, is not symmetric.&nbsp; But it is analogical.</p>\n<ul>\n<li>And when the woman saw that the tree was good for food, and that it was pleasant to the eyes, and a tree to be desired to make one wise, she took of the fruit thereof, and did eat, and gave also unto her husband with her; and he did eat.<span>&nbsp; </span>&ndash; <em>Genesis 3:6 (KJV)</em><em><br /></em></li>\n</ul>\n<ul>\n<li>There is a way which seems right to a man, but its end is the way of death.<span>&nbsp; </span>&ndash; <em>Proverbs </em><em>14:12</em><em>; Proverbs </em><em>16:25</em><em> (NASB)</em><em><br /></em></li>\n</ul>\n<ul>\n<li>&ldquo;Where were you when I laid the foundation of the earth?<span>&nbsp; </span>Tell <em>Me,</em> if you have understanding, Who set its measurements?<span>&nbsp; </span>Since you know.<span>&nbsp; </span>Or who stretched the line on it?&rdquo;<span>&nbsp; </span><em>Job 38:4-5 (NASB)</em></li>\n</ul>\n<ul>\n<li>I will destroy the wisdom of the wise; the intelligence of the intelligent I will frustrate.<span>&nbsp; </span>&ndash; <em>God, quoted in Isaiah 29:14, NIV</em><em><br /></em></li>\n</ul>\n<ul>\n<li>Seek not out things that are too hard for thee, neither search the things that are above they strength&hellip; Be not curious in unnecessary matters.<span>&nbsp; </span>&ndash; <em>Ben Sira (a book of the Septuagint Bible, still in the Eastern Orthodox Bible), circa 200BC</em><em><br /></em></li>\n</ul>\n<ul>\n<li>Where is the wise man?<span>&nbsp; </span>Where is the scholar?<span>&nbsp; </span>Where is the philosopher of this age?<span>&nbsp; </span>Has not God made foolish the wisdom of the world?<span>&nbsp; </span>For since in the wisdom of God the world through its wisdom did not know him, God was pleased through the foolishness of what was preached to save those who believe.<span>&nbsp; </span>&ndash; <em>St. Paul</em><em>, 1 Corinthians 1:20-21 (NIV)</em><em><br /></em></li>\n</ul>\n<ul>\n<li>See to it that no one takes you captive through hollow and deceptive philosophy, which depends on human tradition and the basic principles of this world rather than on Christ.<span>&nbsp; </span>&ndash; <em>St. Paul</em><em>, Colossians 2:8 (NIV)</em><em><br /></em></li>\n</ul>\n<ul>\n<li>Turn away from godless chatter and the opposing ideas of what is falsely called knowledge, which some have professed and in so doing have wandered from the faith.<span>&nbsp; </span>&ndash; <em>St. Paul</em><em>, 1 Timothy 6:20-21 (NIV)</em></li>\n</ul>\n<ul>\n<li>For philosophy is the material of the world&rsquo;s wisdom, the rash interpreter of the nature and dispensation of God.&nbsp; Indeed heresies are themselves instigated by philosophy&hellip; What indeed has Athens to do with Jerusalem? What has the Academy to do with the Church? <span>&nbsp;</span>What have heretics to do with Christians? <span>&nbsp;</span>Our instruction comes from the porch of Solomon, who had himself taught that the Lord should be sought in simplicity of heart.<span>&nbsp; </span>Away with all attempts to produce a Stoic, Platonic, and dialectic Christianity! <span>&nbsp;</span>We want no curious disputation after possessing Christ Jesus, no inquisition after receiving the gospel! <span>&nbsp;</span>When we believe, we desire no further belief. <span>&nbsp;</span>For this is our first article of faith, that there is nothing which we ought to believe besides. &ndash; <em>Tertullian, circa 200AD</em></li>\n</ul>\n<ul>\n<li>The most penetrating mind cannot attain to the knowledge of the least of the phenomena of the world&hellip;<span>&nbsp; </span>Put then a limit to your thought, so that your curiousity in investigating the incomprehensible may not incur the reproaches of Job, and you be not asked by him, &ldquo;Whereupon are the foundations thereof fastened?&rdquo;<span>&nbsp; </span>&ndash;<em> St. Basil the Great, circa 370AD</em><em><br /></em></li>\n</ul>\n<ul>\n<li><span>Besides this there is yet another form of temptation still more complex in its peril. For in addition to the fleshly appetite which strives for the gratification of all senses and pleasures--in which its slaves perish because they separate themselves from thee--there is also a certain vain and curious longing in the soul, rooted in the same bodily senses, which is cloaked under the name of knowledge and learning; not having pleasure in the flesh, but striving for new experiences through the flesh. This longing--since its origin is our appetite for learning, and since the sight is the chief of our senses in the acquisition of knowledge--is called in the divine language &ldquo;the lust of the eyes.&rdquo;</span><span style=\"font-size: 9pt;\"> &hellip;</span><span> This malady of curiosity is the reason for all those strange sights exhibited in the theater. It is also the reason why we proceed to search out the secret powers of nature--those which have nothing to do with our destiny&mdash;which do not profit us to know about, and concerning which men desire to know only for the sake of knowing.<span>&nbsp; </span>&ndash; </span><em><span>St. Augustine</span></em><em><span>, Confessions, 397AD</span></em><em><span><br /></span></em></li>\n</ul>\n<ul>\n<li>Is it not evident that a man who day and night wrestles with the dialectic art, the student of natural science whose gaze pierces the heavens, walks in vanity of understanding and darkness of mind? &ndash; <em>St. Jerome</em><em>, circa 400AD</em><em><br /></em></li>\n</ul>\n<ul>\n<li>Rightly is curiosity considered the first step of pride; it was the beginning of all sin. &ndash; <em>St. Bernard of Clairvaux, 12<sup>th</sup> century</em><em><br /></em></li>\n</ul>\n<ul>\n<li>[Curiousity may be a sin in 4 ways:]<span>&nbsp; </span>Thirdly, when a man desires to know the truth about creatures, without referring his knowledge to its due end, namely, the knowledge of God. Hence Augustine says (De Vera Relig. 29) that \"in studying creatures, we must not be moved by empty and perishable curiosity; but we should ever mount towards immortal and abiding things.&rdquo; &ndash; <em>St. Thomas Aquinas, Summa Theologica 2.2.167, 1265-1274AD</em></li>\n</ul>\n<ul>\n<li>Dei sacrificium intellectus.&nbsp;(We sacrifice the intellect to God.) &ndash; <em>St. Ignatius Loyola, \"To the members of the society in Portugal\", 1553</em></li>\n</ul>\n<ul>\n<li>Eve erred in not regulating the measure of her knowledge by the will of God. And we all daily suffer under the same disease, because we desire to know more than is right, and more than God allows; whereas the principal point of wisdom is a well-regulated sobriety in obedience to God. &ndash; <em>John Calvin, Commentary on Genesis 3:5, 1554</em><em><br /></em></li>\n</ul>\n<ul>\n</ul>\n<ul>\n<li>We say, pronounce, sentence, and declare that you, the said Galileo, by reason of the matters adduced in trial, and by you confessed as above, have rendered yourself in the judgment of this Holy Office vehemently suspected of heresy, namely, of having believed and held the doctrine&mdash;which is false and contrary to the sacred and divine Scriptures&mdash;that the Sun is the center of the world and does not move from east to west and that the Earth moves and is not the center of the world; and that an opinion may be held and defended as probable after it has been declared and defined to be contrary to the Holy Scripture; and that consequently you have incurred all the censures and penalties imposed and promulgated in the sacred canons and other constitutions, general and particular, against such delinquents.&nbsp; &ndash;<em><a href=\"http://www.law.umkc.edu/faculty/projects/ftrials/galileo/condemnation.html\">Papal condemnation of Galileo</a>, 1633<br /></em></li>\n</ul>\n<ul>\n<li>If God has concealed anything, it is God&rsquo;s glory to conceal it, and it is right that it should be hidden. If God has not told us any truth, it is for his glory not to tell it to us.&nbsp; &ndash; <em>Charles Spurgeon, 1877AD<br /> </em></li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1, "Ng8Gice9KNkncxqcj": 1, "NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kWRFfWfhrS6m4Fibm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 14, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "396", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["G5bDjtSbJwbXuji4r"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T19:44:16.522Z", "modifiedAt": null, "url": null, "title": "Two-Tier Rationalism", "slug": "two-tier-rationalism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:33.984Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PL7KpiDdJnh6j5LZS/two-tier-rationalism", "pageUrlRelative": "/posts/PL7KpiDdJnh6j5LZS/two-tier-rationalism", "linkUrl": "https://www.lesswrong.com/posts/PL7KpiDdJnh6j5LZS/two-tier-rationalism", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Two-Tier%20Rationalism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATwo-Tier%20Rationalism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPL7KpiDdJnh6j5LZS%2Ftwo-tier-rationalism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Two-Tier%20Rationalism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPL7KpiDdJnh6j5LZS%2Ftwo-tier-rationalism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPL7KpiDdJnh6j5LZS%2Ftwo-tier-rationalism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1203, "htmlBody": "<p><strong>Related to:</strong> <a href=\"/lw/5f/bayesians_vs_barbarians/\">Bayesians vs. Barbarians</a><br /><br /><a href=\"http://plato.stanford.edu/entries/consequentialism/\">Consequentialism</a><sup>1</sup> is a catchall term for a vast number of specific ethical theories, the common thread of which is that they take goodness (<em>usually</em> of a state of affairs) to be the determining factor of rightness (<em>usually</em> of an action).&nbsp; One family of consequentialisms that came to mind when it was <a href=\"/lw/bk/the_trouble_with_good/7xp?context=1#7xp\">suggested</a> that I post about my Weird Forms of Utilitarianism class is called \"Two-Tier Consequentialism\", which I think can be made to connect interestingly to our rationalism goals on Less Wrong.&nbsp; Here's a summary of two-tier consequentialism<sup>2</sup>.<br /><br />(Some form of) consequentialism is correct and yields the right answer about what people ought to do.&nbsp; But (this form of) consequentialism has many bad features:</p>\n<ul>\n<li>It is <em>unimplementable</em> (because to use it correctly requires more calculation than anyone has time to do based on more information than anyone has time to gather and use).</li>\n</ul>\n<ul>\n<li>It is \"alienating\" (because people trying to obey consequentialistic dictates find them very unlike the sorts of moral motivations they usually have, like \"I want to be a nice person\" or \"so-and-so is my friend\")<sup>3</sup>.</li>\n<li>It is \"integrity-busting\" (because it can force you to consider alternatives that are unthinkably horrifying, if there is the possibility that they might lead to the \"best\" consequences).</li>\n<li>It is \"virtue-busting\" (because it too often requires a deviation from a <em>pattern of behavior</em> that we consider to be an expression of good personal qualities that we would naturally hope and expect from good people).</li>\n<li>It is prone to self-serving abuse (because it's easy, when calculating utilities, to \"cook the books\" and wind up with the outcome you already wanted being the \"best\" outcome).</li>\n</ul>\n<ul>\n<li>It is \"cooperation-busting\" (because individuals don't tend to have an incentive to avoid free-riding when their own participation in a cooperative activity will neither make nor break the collective good).</li>\n</ul>\n<p><br />To solve these problems, some consequentialist ethicists (my class focused on Railton and Hare) invented \"two-tier consequentialism\".&nbsp; The basic idea is that because all of these bad features of (pick your favorite kind of) consequentialism, <em>being a consequentialist has bad consequences, and therefore you shouldn't do it</em>.&nbsp; Instead, you should layer on top of your consequentialist thinking a second tier of moral principles called your \"Practically Ideal Moral Code\", which ought to have the following more convenient properties:<a id=\"more\"></a></p>\n<ul>\n<li>Must be <em>moral</em> principles that identify a situation or class of situations and call for an action in that/those situation(s).</li>\n<li>Must be <em>believable</em>.&nbsp; You should not put in your second tier any principles that you can't buy on a deep level.</li>\n<li>Must be potentially <em>sturdy</em>.&nbsp; Your second tier of principles should be ones that you could stick to, in the face of both your own fallibility <em>and</em> the possibility that they will sometimes lead you to perform acts that are not, strictly speaking by your favorite consequentialism, <em>right</em>.</li>\n<li>Must be <em>useful</em>.&nbsp; They cannot be principles that are as unimplementable as the original favorite consequentialism - you have to be able to bring them to bear quickly and easily.</li>\n<li>Must guide you in actions that are consistent with the expressions of <em>virtue and integrity</em>.</li>\n<li>Must satisfy a <em>publicity condition</em>.&nbsp; That is, widespread acceptance of this set of principles should be conducive to cooperation and not lead to the same self-serving abuse problem that consequentialism has.</li>\n<li>And most importantly, the principles must, collectively, lead you to <em>usually perform actions that your favorite consequentialism would endorse</em>.&nbsp; In fact, part of the point of the second tier is that, in the long run, it should do a better job of making you do things that are right-according-to-consquentialism than actually trying to implement your favorite consequentialism would.</li>\n</ul>\n<p><br />That last part is key, because the two-tier consequentialist is not abandoning consequentialism.&nbsp; Unlike a rule consequentialist, he still thinks that any given action (if his favorite consequentialism is act-based) is right according to the goodness of something (probably a resulting state of affairs), not according to whether they are permitted by his Practically Ideal Moral Code.&nbsp; He simply brainwashes himself into using his Practically Ideal Moral Code because over the long run, this will be for the best <em>according to his initial, consequentialist values</em>.<br /><br />And here is the reason I linked to \"Bayesians vs. Barbarians\", above: what Eliezer is proposing as the best course of action for a rationalist society that is attacked from without sounds like a second-tier rationalism.&nbsp; If it is rational - for the society as a whole and in the long run - that there be soldiers chosen by a particular mechanism who go on to promptly obey the orders of their commanding officers?&nbsp; Well, then, the rational society will just have to arrange for that - even if this causes <em>some individual actions</em> to be non-rational - because the general <em>strategy</em> is the one that generates the results they are interested in (winning the war), and the most rational general strategy isn't one that consists of all the most individually rational parts.<br /><br />In ethics, the three main families are consequentialism (rightness via goodness), deontic ethics (rightness as adherence to duty), and virtue ethics (rightness as the implementation of virtues and/or faithfulness to an archetype of a good person).&nbsp; Inasmuch as rationality and morality are isomorphic, it seems like you could just as easily have a duty-based rationalism or a virtue-based rationalism.&nbsp; I have strong sympathy for two-tier consequentialism <em>as consequentialist ethics go</em>.&nbsp; But it seems like Eliezer is presupposing a kind of consequentialism of rationality, both in that article and in general with the maxim \"rationalists should win!\"&nbsp; It sounds rather like we are supposed to be rationalists <em>because rationalists win</em>, and <em>winning is good</em>.<br /><br />I don't know how widely that maps onto other people's motivations, but for my part, I think my intuitions around why I wish to be rational have more to do with considering it a virtue.&nbsp; I like winning just fine, but even if it turns out that devoting myself to ever finer-grained rationalism confers no significant winnings, I will still consider it a valuable thing in and of itself to be rational.&nbsp; It's not difficult to imagine someone who thinks that it is the duty of intelligent beings in general to hone their intellects in the form of rationalist training; such a person would be more of a deontic rationalist.</p>\n<p><br /><br /><sup>1</sup>I'm not a consequentialist of any stripe myself.&nbsp; However, my views are almost extensionally equivalent with an extremely overcomplicated interpretation of <a href=\"http://www.amazon.com/Anarchy-State-Utopia-Robert-Nozick/dp/0465097200/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1239995486&amp;sr=8-1\">Nozickian</a> side-constraint rights-based utilitarianism.<br /><br /><sup>2</sup>Paraphrased liberally from classroom handouts by <a href=\"http://www.umass.edu/philosophy/faculty/feldman.htm\">Fred Feldman</a>.<br /><br /><sup>3</sup>The example we were given in class was of a man who buys flowers for his wife and, when asked why, says, \"As her husband, I'm in a special position to efficiently generate utility in her, and considered buying her flowers to be for the best overall.\"&nbsp; This in contrast to, \"Well, because she's my wife and I love her and she deserves a bouquet of carnations every now and then.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 1, "ouT6wKhACJRouGokM": 1, "ZTRNmvQGgoYiymYnq": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PL7KpiDdJnh6j5LZS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 46, "baseScore": 48, "extendedScore": null, "score": 9.5e-05, "legacy": true, "legacyId": "419", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KsHmn6iJAEr9bACQW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T20:26:26.304Z", "modifiedAt": null, "url": null, "title": "My main problem with utilitarianism", "slug": "my-main-problem-with-utilitarianism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:34.108Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cPNr6JCnZATZMc6AZ/my-main-problem-with-utilitarianism", "pageUrlRelative": "/posts/cPNr6JCnZATZMc6AZ/my-main-problem-with-utilitarianism", "linkUrl": "https://www.lesswrong.com/posts/cPNr6JCnZATZMc6AZ/my-main-problem-with-utilitarianism", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20main%20problem%20with%20utilitarianism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20main%20problem%20with%20utilitarianism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcPNr6JCnZATZMc6AZ%2Fmy-main-problem-with-utilitarianism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20main%20problem%20with%20utilitarianism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcPNr6JCnZATZMc6AZ%2Fmy-main-problem-with-utilitarianism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcPNr6JCnZATZMc6AZ%2Fmy-main-problem-with-utilitarianism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 453, "htmlBody": "<p>It seems that in the rationalist community there's almost universal acceptance of utilitarianism as basics of ethics. The version that seems most popular goes something like this:</p>\n<ul>\n<li>Everybody has preference function assigning real values (utilons) to states of reality</li>\n<li>Preference function is a given and shouldn't be manipulated</li>\n<li>People try to act to maximize number of utilons, that's how we find about their preference function</li>\n<li>People are happier when they get more utilons</li>\n<li>We should give everybody as much utilons as we can</li>\n</ul>\n<p>There are a few obivous problems here, that I won't be bothering with today:</p>\n<ul>\n<li>Any affine transformation of preference function leaves what is essentially the same preference function, but it matters when we try to aggregate them. If we multiply one person's preference function values by 3^^^3, they get to decide everything in every utilitarian scenario</li>\n<li>Problem of total vs average number of utilons</li>\n<li>People don't really act consistently with \"maximizing expected number of utilons\" model</li>\n<li>Time discounting is a horrible mess, especially since we're hyperbolic so inconsistent by definition</li>\n</ul>\n<p>But my main problem is that there's very little evidence getting utilons is actually increasing anybody's happiness significantly. Correlation might very well be positive, but it's just very weak. Giving people what they want is just not going to make them happy, and not giving them what they want is not going to make them unhappy. This makes perfect evolutionary sense - an organism that's content with what it has will fail in competition with one that always wants more, no matter how much it has. And organism that's so depressed it just gives up will fail in competition with one that just tries to function the best it can in its shabby circumstances. We all had extremely successful and extremely unsuccessful cases among our ancestors, and the only reason they are on our family tree was because they went for just a bit more or respectively for whatever little they could get.</p>\n<p>Modern economy is just wonderful at mass producing utilons - we have orders of magnitude more utilons per person than our ancestors - and it doesn't really leave people that much happier. It seems to me that the only realistic way to significantly increase global happiness is directly hacking happiness function in brain - by making people happy with what they have. If there's a limit in our brains, some number of utilons on which we stay happy, it's there only because it almost never happened in our evolutionary history.</p>\n<p>There might be some drugs, or activities, or memes that increase happiness without dealing with utilons. Shouldn't we be focusing on those instead?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zs4nYLkNr7Rbo4mAP": 1, "ouT6wKhACJRouGokM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cPNr6JCnZATZMc6AZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -1, "extendedScore": null, "score": -5e-06, "legacy": true, "legacyId": "420", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 84, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-17T23:13:08.720Z", "modifiedAt": null, "url": null, "title": "Just for fun - let's play a game.", "slug": "just-for-fun-let-s-play-a-game", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:38.365Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YSb3YzXf7p8fBYvP4/just-for-fun-let-s-play-a-game", "pageUrlRelative": "/posts/YSb3YzXf7p8fBYvP4/just-for-fun-let-s-play-a-game", "linkUrl": "https://www.lesswrong.com/posts/YSb3YzXf7p8fBYvP4/just-for-fun-let-s-play-a-game", "postedAtFormatted": "Friday, April 17th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Just%20for%20fun%20-%20let's%20play%20a%20game.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJust%20for%20fun%20-%20let's%20play%20a%20game.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYSb3YzXf7p8fBYvP4%2Fjust-for-fun-let-s-play-a-game%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Just%20for%20fun%20-%20let's%20play%20a%20game.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYSb3YzXf7p8fBYvP4%2Fjust-for-fun-let-s-play-a-game", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYSb3YzXf7p8fBYvP4%2Fjust-for-fun-let-s-play-a-game", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 203, "htmlBody": "<p>How well can we, at Less Wrong, tell the difference between truth and fiction? Let's play a little game, which I once saw <a href=\"http://www.imdb.com/title/tt0401997/\">in a movie</a>.&nbsp;</p>\n<p>In this game, we each say five things about ourselves, four of which are true. We then try to guess which ones are true and which ones are lies. (Go ahead and use Google, if you like.) I'll start.</p>\n<p>My five facts:</p>\n<p>1) I have another LessWrong commenter's autograph.</p>\n<p>2) I once received the first place prize in an (unsanctioned, online) Magic tournament that lasted a total of ten rounds (seven rounds of Swiss pairings, plus three single elimination rounds) but only beat an opponent at Magic during four of them.</p>\n<p>3) I've beaten Battletoads, on an actual NES, without using a Game Genie or other cheat device.</p>\n<p>4) Not too long ago, I made a $500 donation to <a href=\"http://www.givewell.net/PSI\">Population Services International</a>, using my debit card. Unfortunately, this overdrew my checking account. My parents were not pleased, not only because I overdrew my checking account, but also because they disapproved of my donating such a large amount of money.</p>\n<p>5) My favorite Star Wars movie is \"Attack of the Clones.\"</p>\n<p>(Note: I used a random number generator to determine which position would contain the lie.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 1, "hNFdS3rRiYgqqD8aM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YSb3YzXf7p8fBYvP4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 12, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "423", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 71, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-18T01:26:13.041Z", "modifiedAt": "2021-04-28T14:50:46.450Z", "url": null, "title": "Rationality Quotes - April 2009", "slug": "rationality-quotes-april-2009", "viewCount": null, "lastCommentedAt": "2015-05-12T09:01:44.250Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jBd3Zdb8j9LHwFMwL/rationality-quotes-april-2009", "pageUrlRelative": "/posts/jBd3Zdb8j9LHwFMwL/rationality-quotes-april-2009", "linkUrl": "https://www.lesswrong.com/posts/jBd3Zdb8j9LHwFMwL/rationality-quotes-april-2009", "postedAtFormatted": "Saturday, April 18th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20-%20April%202009&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20-%20April%202009%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjBd3Zdb8j9LHwFMwL%2Frationality-quotes-april-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20-%20April%202009%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjBd3Zdb8j9LHwFMwL%2Frationality-quotes-april-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjBd3Zdb8j9LHwFMwL%2Frationality-quotes-april-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p>A monthly thread for posting any interesting rationality-related quotes you've seen recently on the Internet, or had stored in your quotesfile for ages.</p>\n<ul>\n<li>Please post all quotes <em>separately</em> (so that they can be voted up (or down) separately) unless they are strongly related/ordered.</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB - if we do this, there should be a separate thread for it.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jBd3Zdb8j9LHwFMwL", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 15, "extendedScore": null, "score": 2.8e-05, "legacy": true, "legacyId": "424", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 144, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-18T01:26:13.041Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-18T05:36:17.561Z", "modifiedAt": null, "url": null, "title": "The Epistemic Prisoner's Dilemma", "slug": "the-epistemic-prisoner-s-dilemma", "viewCount": null, "lastCommentedAt": "2019-12-21T14:51:57.266Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vtMSQtxH7ei2a5T4r/the-epistemic-prisoner-s-dilemma", "pageUrlRelative": "/posts/vtMSQtxH7ei2a5T4r/the-epistemic-prisoner-s-dilemma", "linkUrl": "https://www.lesswrong.com/posts/vtMSQtxH7ei2a5T4r/the-epistemic-prisoner-s-dilemma", "postedAtFormatted": "Saturday, April 18th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Epistemic%20Prisoner's%20Dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Epistemic%20Prisoner's%20Dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvtMSQtxH7ei2a5T4r%2Fthe-epistemic-prisoner-s-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Epistemic%20Prisoner's%20Dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvtMSQtxH7ei2a5T4r%2Fthe-epistemic-prisoner-s-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvtMSQtxH7ei2a5T4r%2Fthe-epistemic-prisoner-s-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 576, "htmlBody": "<p>Let us say you are a doctor, and you are dealing with a malaria epidemic in your village. You are faced with two problems. First, you have no access to the drugs needed for treatment. Second, you are one of two doctors in the village, and the two of you cannot agree on the nature of the disease itself. You, having carefully tested many patients, being a highly skilled, well-educated diagnostician, have proven to yourself that the disease in question is malaria. Of this you are &gt;99% certain. Yet your colleague, the blinkered fool, insists that you are dealing with an outbreak of bird flu, and to this he assigns &gt;99% certainty.</p>\n<p>Well, it need hardly be said that someone here is failing at rationality. Rational agents do not have common knowledge of disagreements etc. But... what can we say? We're human, and it happens.</p>\n<p>So, let's say that one day, <span class=\"msoDel\"><del>Omega</del></span>Dr. House calls you both into his office and tells you that he knows, with certainty, which disease is afflicting the villagers. As confident as you both are in your own diagnoses, you are <em>even more</em> confident in House's abilities. House, however, will not <em>tell</em> you his diagnosis until you've played a game with him. He's going to put you in one room and your colleague in another. He's going to offer you a choice between 5,000 units of malaria medication, and 10,000 units of bird-flu medication. At the same time, he's going to offer your colleague a choice between 5,000 units of bird-flu meds, and 10,000 units of malaria meds.<a id=\"more\"></a></p>\n<p>(Let us assume that keeping a malaria patient alive and healthy takes the same number of units of malaria meds as keeping a bird flu patient alive and healthy takes bird flu meds).</p>\n<p>You <em>know</em> the disease in question is malaria. The bird-flu drugs are literally <em>worthless </em>to you, and the malaria drugs <em>will save lives</em>. You might worry that your colleague would be upset with you for making this decision, but you also know House is going to tell him that it was actually malaria before he sees you. Far from being angry, he'll embrace you, and thank you for doing the right thing, despite his blindness.</p>\n<p>So you take the 5,000 units of malaria medication, your colleague takes the 5,000 units of bird-flu meds (reasoning in precisely the same way), and you have 5,000 units of useful drugs with which to fight the outbreak.</p>\n<p>Had you each taken that which you supposed to be worthless, you'd be guaranteed 10,000 units. I don't think you can claim to have acted rationally.</p>\n<p>Now <em>obviously</em> you should be able to do even better than that. You should be able to take one another's estimates into account, share evidence, revise your estimates, reach a probability you both agree on, and, if the odds exceed 2:1 in one direction or the other, jointly take 15,000 units of whatever you expect to be effective, and otherwise get 10,000 units of each. I'm not giving out any excuses for failing to take this path.</p>\n<p>But still, both choosing the 5,000 units&nbsp;<em>strictly loses</em>. If you can agree on nothing else, you should <em>at least </em>agree that cooperating is better than defecting.</p>\n<p>Thus I propose that the epistemic prisoner's dilemma, though it has unique features (the agents differ epistemically, not preferentially) should be treated by rational agents (or agents so boundedly rational that they can still <em>have </em>persistent disagreements)&nbsp;in the same way as the <a href=\"http://www.overcomingbias.com/2008/09/true-pd.html\">vanilla prisoner's dilemma</a>. What say you?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 3, "wzgcQCrwKfETcBpR9": 1, "b8FHrKqyXuYGWc6vn": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vtMSQtxH7ei2a5T4r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 43, "baseScore": 67, "extendedScore": null, "score": 0.000103, "legacy": true, "legacyId": "359", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-18T20:05:49.049Z", "modifiedAt": "2020-05-07T21:45:08.306Z", "url": null, "title": "How a pathological procrastinor can lose weight [Anti-akrasia]", "slug": "how-a-pathological-procrastinor-can-lose-weight-anti-akrasia", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:31.727Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dreeves", "createdAt": "2009-02-28T00:36:12.431Z", "isAdmin": false, "displayName": "dreeves"}, "userId": "SXhuTNpwfY65bMunC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z6ESPufeiC4P8c8en/how-a-pathological-procrastinor-can-lose-weight-anti-akrasia", "pageUrlRelative": "/posts/Z6ESPufeiC4P8c8en/how-a-pathological-procrastinor-can-lose-weight-anti-akrasia", "linkUrl": "https://www.lesswrong.com/posts/Z6ESPufeiC4P8c8en/how-a-pathological-procrastinor-can-lose-weight-anti-akrasia", "postedAtFormatted": "Saturday, April 18th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20a%20pathological%20procrastinor%20can%20lose%20weight%20%5BAnti-akrasia%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20a%20pathological%20procrastinor%20can%20lose%20weight%20%5BAnti-akrasia%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6ESPufeiC4P8c8en%2Fhow-a-pathological-procrastinor-can-lose-weight-anti-akrasia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20a%20pathological%20procrastinor%20can%20lose%20weight%20%5BAnti-akrasia%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6ESPufeiC4P8c8en%2Fhow-a-pathological-procrastinor-can-lose-weight-anti-akrasia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6ESPufeiC4P8c8en%2Fhow-a-pathological-procrastinor-can-lose-weight-anti-akrasia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1355, "htmlBody": "<p><em>[This post has now been subsumed by the following: <a href=\"http://blog.beeminder.com/akrasia\">blog.beeminder.com/akrasia</a>. Also, the service described below, then known as Kibotzer, is now a real startup called Beeminder, announced here: <a href=\"http://lesswrong.com/lw/7z1/antiakrasia_tool_like_stickkcom_for_data_nerds/\">http://lesswrong.com/lw/7z1/antiakrasia_tool_like_stickkcom_for_data_nerds/</a>]</em></p>\n<p>If you are a pathological procrastinator you're pretty screwed when it comes to weight loss.\u00a0 You have this monumental goal like \"lose 20 pounds\" but there's no \"last minute\" that you can put it off until.</p>\n<p>I and my partner have thought a lot about akrasia (ie, failure to do what we think we should be doing) and have a tool that tries to apply some anti-akrasia principles.\u00a0 It's called Kibotzer (for \"kibitzing robot\") and is currently in private beta.</p>\n<p>This is not necessarily the best way to use Kibotzer but if you're a pathological procrastinator and want to just embrace that flaw, Kibotzer can help:\u00a0 (It's more general than weight-loss but that makes for a nice example.)</p>\n<p>1. Pick your goal weight and goal date.</p>\n<p>2. Kibotzer creates your \"Yellow Brick Road.\"</p>\n<p><img src=\"http://kibotzer.com/data/example.png\" /></p>\n<p>3. Place a bet with us that you'll stay on your Road.</p>\n<p>\u00a0\u00a0 (if you go off your Road for even a single day, you lose.)</p>\n<p>4. Procrastinate like hell until you're about to lose the bet.</p>\n<p>The change in focus from \"weigh 20 pounds less next year\" to \"be on the yellow brick road tomorrow morning\" makes all the difference.\u00a0 If you're in the wrong \"lane\" of your Road today then it's crunch time.\u00a0 You have to be on your road tomorrow morning.\u00a0 Pull an all-nighter on the treadmill if that's what it takes.<a></a></p>\n<p>In one sense that mentality's crazy.\u00a0 Whatever you do in any single 24 hour period makes essentially no difference to your weight next year. But that's the kind of thinking that let you drift away from your ideal weight in the first place.\u00a0 The whole secret of Kibotzer is to automatically break down your long-term goal into day-to-day guidance.\u00a0 And then, critically, add a wager to force you to stick to it.</p>\n<p>Kibotzer's tagline is \"Bring Long-Term Consequences Near!\"\u00a0 (Note that this differs from <a href=\"http://stickk.com/\">Stickk.com</a> which adds consequences but can't bring them quite so near!)</p>\n<p>We're interested to get the opinions of folks on LessWrong and perhaps some of you would like to be guinea pigs...</p>\n<p>I'll put the rest of the details in the form of an FAQ.\u00a0 Basically, we want to make sure we never cheat anyone out of money so we have safeguards we've worked out based on previous bets.</p>\n<p>FREQUENTLY ASKED QUESTIONS:</p>\n<p>1. \"What if I have a random up-day because I'm retaining water or something?\"</p>\n<p>The Yellow Brick Road adjusts its width so you shouldn't ever lose because of a random up-day.\u00a0 We want to set unbending rules where each day matters, because that's what's motivating (no \"I'll catch up later\" where you dig yourself in a hole) but you should never lose on a technicality.</p>\n<p>\u00a0</p>\n<p>2. \"What if I forget to reply to the bot or get too busy?\"</p>\n<p>If you stop replying to the bot you automatically get your money back. We only want your money if we're providing something so valuable that you want to interact with it continually.</p>\n<p>\u00a0</p>\n<p>3. \"My goal is a year away; will you just hold my money that whole time?\"</p>\n<p>Whenever we're holding on to your money we pay a fair interest rate on it.</p>\n<p>\u00a0</p>\n<p>4. \"It seems a little unforgiving; everyone makes mistakes...\"</p>\n<p>The Yellow Brick Road itself allows for a nice margin of error but to further ensure that you don't lose because of one or two mistakes, there's a \"three-strikes\" policy:\u00a0 You can drive off your Road twice and the road will then be reset from where you currently are, targeting the same goal weight and goal date.\u00a0 Only on the third time do you actually lose the bet.</p>\n<p>\u00a0</p>\n<p>5. \"Do I still win if I go off the road once but end up reaching my goal in time?\"</p>\n<p>The short answer is that you lose if you go off at *any* time (modulo the three-strikes policy).\u00a0 *But* the brilliance of Kibotzer is that it *knows* about random fluctuation, water retention, and hormonal cycles: the road is wide enough that you will never lose on a technicality.\u00a0 What that roughly means is that you have to mostly stay in the right lane of your yellow brick road and reserve the left lane as your safety buffer for random (or monthly) up-days.</p>\n<p>Recall Kibotzer's goal: \"bring long-term consequences near\".\u00a0 In other words, the fact that you lose the game if you go off *tomorrow* is by design.\u00a0 It's very hard to, for example, forgo that piece of pie merely because it will make it harder to weigh 20 pounds less 10 months from now.\u00a0 Please!\u00a0 One piece of pie won't make the difference and there's plenty of time to catch up!\u00a0 Each individual piece of pie is *totally worth it*.\u00a0 Same with each workout you really don't feel like doing right now.\u00a0 Which of course is how you and everyone else in the country end up 20 pounds away from their ideal.\u00a0 With Kibotzer that whole dynamic changes: when you're in the wrong lane of your road that one piece of pie could very well make the difference *tomorrow morning* and you're acutely aware of it.\u00a0 The consequences are immediate.\u00a0 And of course even better is the flipside of that coin: if you are well into your right lane then it's very very nice to be able to enjoy your hard-earned safety buffer and eat that piece of pie guilt-free!</p>\n<p>\u00a0</p>\n<p>6. \"The graphs and numbers and betting seem a little gimmicky; is there another way to do this?\"</p>\n<p>Fundamentally it has to involve making a genuine commitment. Like, yes, I'm perfectly capable of staying below X pounds and I can commit to doing that. And then \"commit\" has to actually be made meaningful. Risking a painful chunk of money is the simplest way to do that.</p>\n<p>It's sad but it often doesn't mean much when we verbally commit to something. (Some people are worse about this than others.) So the bet is like an acknowledgment that there's two \"me\"s: the me right now who definitely wants this to happen and then future-me who is going to thumb their nose and thwart it. You just have to force future-me's hand. Forget the charade that it's the same me -- it isn't. Verbalize the commitment all you want, history proves that future-me has a damn good chance of thumbing their nose at you (after all, how did you end up well over your ideal weight in the first place?). So if current-me is really serious then prove it by making it impossible for future-me to renege. Or, not impossible, just make future-me not *want* to renege. That's the best you can do and all that's needed.</p>\n<p>\u00a0</p>\n<p>7. \"How do I actually place a bet?\"</p>\n<p>Email me with how much money you might be willing to risk (or indicate this on kibotzer.com/register).\u00a0 I'll reply with the odds (how much you can win).\u00a0 If that's acceptable, there's a \"donate\" button at kibotzer.com/money where you can put up the money.\u00a0 The rest is honor system for now.</p>\n<p>\u00a0</p>\n<p>8. \"I don't understand betting lingo.\u00a0 What are 'odds'?\"\u00a0 (Probably don't need this one for LessWrong folks but interested to hear your ideas on how to explain this sort of thing to layfolk!)</p>\n<p>First, \"even odds\" means that if you win you double your money.\u00a0 If I'm betting on something where I'll probably lose then I'll want better odds to compensate, meaning that I'll more than double my money on the off chance that I win.\u00a0 Higher risk, higher reward.\u00a0 From your perspective, it's lower risk so you'll have a lower reward if you win.</p>\n<p>For example, if you choose to risk $1000 then we'll figure you're highly likely to win so we might offer you odds where you risk the $1000 but only win $50 if you stay on your road (we'll also factor in how steep your Road is).\u00a0 If you're sufficiently sure you can stay on your Road then that's a free $50 for you. (Of course the real advantage is the motivation it provides and the fact that you end up at the end of your Yellow Brick Road!)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"TkZ7MFwCi4D63LJ5n": 1, "r7qAjcbfhj2256EHH": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z6ESPufeiC4P8c8en", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 28, "extendedScore": null, "score": 4.886446368240304e-07, "legacy": true, "legacyId": "382", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.2.0", "pingbacks": {"Posts": ["6oYETaG248zGF45aD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-18T21:25:14.492Z", "modifiedAt": null, "url": null, "title": "Atheist or Agnostic?", "slug": "atheist-or-agnostic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:00.257Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "byrnema", "createdAt": "2009-03-20T18:02:38.305Z", "isAdmin": false, "displayName": "byrnema"}, "userId": "SCnD6W8NiztYBN39M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8fbFuQEEH5ZhD2trL/atheist-or-agnostic", "pageUrlRelative": "/posts/8fbFuQEEH5ZhD2trL/atheist-or-agnostic", "linkUrl": "https://www.lesswrong.com/posts/8fbFuQEEH5ZhD2trL/atheist-or-agnostic", "postedAtFormatted": "Saturday, April 18th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Atheist%20or%20Agnostic%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAtheist%20or%20Agnostic%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fbFuQEEH5ZhD2trL%2Fatheist-or-agnostic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Atheist%20or%20Agnostic%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fbFuQEEH5ZhD2trL%2Fatheist-or-agnostic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fbFuQEEH5ZhD2trL%2Fatheist-or-agnostic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 411, "htmlBody": "<p class=\"MsoNormal\"><strong>If you&rsquo;re not sure:</strong></p>\n<p class=\"MsoNormal\">Where I come from, if you don&rsquo;t believe in God and you don&rsquo;t have a proof that God doesn&rsquo;t exist, you say you&rsquo;re agnostic. A typical conversation in polite company would go like this:</p>\n<p class=\"MsoNormal\"><strong>Woman</strong>: What are your religious views?</p>\n<p class=\"MsoNormal\"><strong>Me</strong>: Oh, I&rsquo;m an atheist. You?</p>\n<p class=\"MsoNormal\"><strong>Woman</strong>: Well, do you know for certain that God doesn&rsquo;t exist?</p>\n<p class=\"MsoNormal\"><strong>Me</strong>: I&rsquo;m pretty sure, that&rsquo;s what I believe.</p>\n<p class=\"MsoNormal\"><strong>Woman</strong>: How do you know that God isn&rsquo;t withholding all evidence that he exists to test your faith? How do you know that&rsquo;s not the case?</p>\n<p class=\"MsoNormal\"><strong>Me</strong>: Well, it&rsquo;s possible that everything is an illusion.</p>\n<p class=\"MsoNormal\"><strong>Woman</strong> (<em>with finality</em>): You&rsquo;re agnostic.</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">Every community has its own set of definitions. Here on LW, you are an atheist, simply, if you don&rsquo;t believe in God. You don&rsquo;t have to be 100% certain &ndash; we understand that nothing is 100% certain and you believe in God&rsquo;s non-existence if you believe it with the same conviction that you believe other things, such as the Earth is orbiting around the sun. For a fuller explanation, see <a href=\"/lw/bs/rationality_quotes_april_2009/8b4\">this comment</a>.<a href=\"/lw/bv/lw/bs/rationality_quotes_april_2009/8b4\"><br /></a></p>\n<p class=\"MsoNormal\">&nbsp;<strong>For the rest of us:</strong></p>\n<p class=\"MsoNormal\">My favorite passage in the Bible is Exodus 4 because this is the part of the bible that made me suspect that it was written by men; men that were pretty unsophisticated in their sense of justice and reasonable deity behavior. God asks Moses to come be on His side, and Moses agrees. The next thing that happens is that God is trying to kill Moses because his son isn&rsquo;t circumcised. I guess God already asked Moses to do that? They left that part out of the story. Nevertheless, God seems more peevish than rational here. Presumably, he chose Moses for a reason. So trying to kill him in the very next scene doesn&rsquo;t make a lot of sense.</p>\n<p class=\"MsoNormal\">As someone who has had some trouble figuring out how things are thought about in atheist circles, I would like to suggest not being like God in Exodus 4 when people ask why we&rsquo;re atheist even though we can&rsquo;t prove there&rsquo;s no God. It&rsquo;s understandably annoying to repeat yourself, but they need to understand the context of atheism here. You can refer them to&nbsp;&nbsp;<a href=\"/lw/bs/rationality_quotes_april_2009/8b4\">this comment</a> again or \"<a href=\"http://www.overcomingbias.com/2008/01/gray-fallacy.html\">The Fallacy of Gray</a>\" or here.</p>\n<p class=\"MsoNormal\">And steel yourself for the inevitable argument that belief in God is a special case and deserves extra certainty. These are final steps&hellip;</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">----</p>\n<p class=\"MsoNormal\">I would like this to be a reference for people coming onto the site that consider themselves agnostic. Any editing suggestions welcome.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8fbFuQEEH5ZhD2trL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 7, "extendedScore": null, "score": 4.886564639359104e-07, "legacy": true, "legacyId": "428", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-19T00:59:14.063Z", "modifiedAt": null, "url": null, "title": "Great Books of Failure", "slug": "great-books-of-failure", "viewCount": null, "lastCommentedAt": "2022-03-29T21:36:25.382Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RWosa2YbcK4qeoYMD/great-books-of-failure", "pageUrlRelative": "/posts/RWosa2YbcK4qeoYMD/great-books-of-failure", "linkUrl": "https://www.lesswrong.com/posts/RWosa2YbcK4qeoYMD/great-books-of-failure", "postedAtFormatted": "Sunday, April 19th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Great%20Books%20of%20Failure&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGreat%20Books%20of%20Failure%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRWosa2YbcK4qeoYMD%2Fgreat-books-of-failure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Great%20Books%20of%20Failure%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRWosa2YbcK4qeoYMD%2Fgreat-books-of-failure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRWosa2YbcK4qeoYMD%2Fgreat-books-of-failure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<p><strong>Followup to</strong>:&nbsp; <a href=\"/lw/m/unteachable_excellence/\">Unteachable Excellence</a></p>\n<p>As previously observed, extraordinary successes tend to be considered <em>extraordinary</em> <a href=\"/lw/m/unteachable_excellence/\">precisely because it is hard to teach</a> (relative to the then-current level of understanding and systematization).&nbsp; On the other hand, famous <em>failures</em> are much more likely to contain lessons on what to avoid next time.</p>\n<p>Books about epic screwups have constituted some of my more enlightening reading.&nbsp; Do you have any such books to recommend?</p>\n<p>Please break up multiple recommendations into multiple comments, one book per comment, so they can be voted on and discussed separately.&nbsp; And please say at least a little about the book's subject and what sort of lesson you learned from it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zcvsZQWJBFK6SxK4K": 1, "4Kcm4etxAJjmeDkHP": 1, "8SfkJYYMe75MwjHzN": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RWosa2YbcK4qeoYMD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 30, "extendedScore": null, "score": 4.8868813095827e-07, "legacy": true, "legacyId": "429", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["34Tu4SCK5r5Asdrn3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-19T01:13:23.164Z", "modifiedAt": null, "url": null, "title": "Weekly Wiki Workshop and suggested articles", "slug": "weekly-wiki-workshop-and-suggested-articles", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:32.050Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4LjFH7GxyeryaKzv4/weekly-wiki-workshop-and-suggested-articles", "pageUrlRelative": "/posts/4LjFH7GxyeryaKzv4/weekly-wiki-workshop-and-suggested-articles", "linkUrl": "https://www.lesswrong.com/posts/4LjFH7GxyeryaKzv4/weekly-wiki-workshop-and-suggested-articles", "postedAtFormatted": "Sunday, April 19th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20Wiki%20Workshop%20and%20suggested%20articles&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20Wiki%20Workshop%20and%20suggested%20articles%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4LjFH7GxyeryaKzv4%2Fweekly-wiki-workshop-and-suggested-articles%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20Wiki%20Workshop%20and%20suggested%20articles%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4LjFH7GxyeryaKzv4%2Fweekly-wiki-workshop-and-suggested-articles", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4LjFH7GxyeryaKzv4%2Fweekly-wiki-workshop-and-suggested-articles", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 259, "htmlBody": "<p>Now 12 days old, <a href=\"http://lesswrong.wikia.com\">LWiki</a>&nbsp;is still growing. Most of the articles are <a href=\"http://lesswrong.wikia.com/wiki/Category:Article_stubs\">stubs</a>, but progress is being made. Eliezer confirmed that an official wiki hosted on LW is eventually coming, so be careful about linking to the wiki, but don't let that deter you from adding content.&nbsp;</p>\n<p>Standards and conventions are still being hashed out, so jump in now if you want to contribute. There is broad consensus that articles should primarily defer to existing work, either on OB/LW or Wikipedia. However, even quick summaries and links to blog posts can look very different depending on the subject. For example, contrast <a href=\"http://lesswrong.wikia.com/wiki/Rationality_as_martial_art\">Rationality as Martial Art</a>&nbsp;and&nbsp;<a href=\"http://lesswrong.wikia.com/wiki/Bias\">Bias</a>. The former is short and to the point, whereas the latter annotates each link. The latter also makes for much more interesting reading, in my opinion.</p>\n<p>Ok, then where do we go from here? The two main avenues of development are creating stubs and then fleshing them out with content.&nbsp;For the first, please suggest any topics, concepts, established phrases, acronyms, techniques, or jargon in this thread that you can think of, and I will be happy to add them as new articles. Or, better yet, feel free to add them yourself.&nbsp;</p>\n<p>For the second, I suggest we have a weekly thread that designates one topic for our community to throw its collective intelligence at. That way, we can get all the relevant discussion about the content of an article out at once. For this inaugural Weekly Wiki Workshop, I'm going to suggest the <a href=\"http://lesswrong.wikia.com/wiki/Rationality\">Rationality</a>&nbsp;article.</p>\n<p>So, what articles could the wiki use? What should the <a href=\"http://lesswrong.wikia.com/wiki/Rationality\">Rationality</a> article look like?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4LjFH7GxyeryaKzv4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 3, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "430", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-19T08:57:02.580Z", "modifiedAt": null, "url": null, "title": "The True Epistemic Prisoner's Dilemma", "slug": "the-true-epistemic-prisoner-s-dilemma", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:05.403Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3DQTfZCxSKZBEGyoN/the-true-epistemic-prisoner-s-dilemma", "pageUrlRelative": "/posts/3DQTfZCxSKZBEGyoN/the-true-epistemic-prisoner-s-dilemma", "linkUrl": "https://www.lesswrong.com/posts/3DQTfZCxSKZBEGyoN/the-true-epistemic-prisoner-s-dilemma", "postedAtFormatted": "Sunday, April 19th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20True%20Epistemic%20Prisoner's%20Dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20True%20Epistemic%20Prisoner's%20Dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DQTfZCxSKZBEGyoN%2Fthe-true-epistemic-prisoner-s-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20True%20Epistemic%20Prisoner's%20Dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DQTfZCxSKZBEGyoN%2Fthe-true-epistemic-prisoner-s-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DQTfZCxSKZBEGyoN%2Fthe-true-epistemic-prisoner-s-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 564, "htmlBody": "<p>I spoke yesterday of the&nbsp;<a href=\"/lw/9z/the_epistemic_prisoners_dilemma/\">epistemic prisoner's dilemma</a>, and JGWeissman wrote:</p>\n<blockquote>\n<p><span style=\"font-family: Arial;\">I am having some difficulty imagining that I am 99% sure of something, but I cannot either convince a person to outright agree with me or accept that he is uncertain and therefore should make the choice that would help more if it is right, but I could convince that same person to cooperate in the prisoner's dilemma. However, if I did find myself in that situation, I would cooperate.</span></p>\n</blockquote>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial; background-color: #f7f7f8;\">To which I said:</p>\n<blockquote>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial; background-color: #f7f7f8;\">Do you think you could convince a young-earth creationist to cooperate in the prisoner's dilemma?</p>\n</blockquote>\n<p><span style=\"font-family: Arial;\">And lo, JGWeissman saved me a lot of writing when he replied thus:</span></p>\n<blockquote>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial;\">Good point. I probably could. I expect that the young-earth creationist has a huge bias that does not have to interfere with reasoning about the prisoner's dilemma.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial; background-color: #f7f7f8;\">So, suppose Omega finds a young-earth creationist and an atheist, and plays the following game with them. They will each be taken to a separate room, where the atheist will choose between each of them receiving $10000 if the earth is less than 1 million years old or each receiving $5000 if the earth is more than 1 million years old, and the young earth creationist will have a similar choice with the payoffs reversed. Now, with prisoner's dilemma tied to the young earth creationist's bias, would I, in the role of the atheist still be able to convince him to cooperate? I don't know. I am not sure how much the need to believe that the earth is around 5000 years would interfere with recognizing that it is in his interest to choose the payoff for earth being over a million years old. But still, if he seemed able to accept it, I would cooperate.</p>\n</blockquote>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial; background-color: #f7f7f8;\">I make one small modification. You and your creationist friend are actually not that concerned about money, being distracted by the massive meteor about to strike the earth from an unknown direction. Fortunately, Omega is promising to protect limited portions of the globe, based on your decisions (I think you've all seen enough PDs that I can leave the numbers as an excercise).</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial; background-color: #f7f7f8;\">It is this then which I call the true epistemic prisoner's dilemma. If I tell you a story about two doctors, even if I tell you to put yourself in the shoes of one, and not the other, it is <em>easy</em>&nbsp;for you to take yourself outside them, see the symmetry and say \"the doctors should cooperate\". &nbsp;I hope I have now broken some of that emotional symmetry.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial; background-color: #f7f7f8;\">As Omega lead the creationist to the other room, you would (I know I certainly would) <a href=\"http://www.overcomingbias.com/2008/10/shut-up-and-do.html\">make a convulsive effort</a> to convince him of the truth of evolution. Despite every pointless, futile argument you've ever had in an IRC room or a YouTube thread, you would struggle desperately, calling out every half-remembered fragment of Dawkins or Sagan you could muster, in hope that just before the door shut, the creationist would hold it open and say \"You're right, I was wrong. You defect, I'll cooperate -- let's save the world together.\"</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; line-height: 19.0px; font: 13.0px Arial; background-color: #f7f7f8;\">But of course, you would fail. And the door would shut, and you would grit your teeth, and curse 2000 years of screamingly bad epistemic hygiene, and weep bitterly for the people who might die in a few hours because of your counterpart's ignorance. And then -- I hope -- you would cooperate.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3DQTfZCxSKZBEGyoN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 18, "extendedScore": null, "score": 2.9e-05, "legacy": true, "legacyId": "425", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 72, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vtMSQtxH7ei2a5T4r"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-19T19:25:32.850Z", "modifiedAt": null, "url": null, "title": "Spreading the word?", "slug": "spreading-the-word", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:04.165Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2pR3aStEjxJp4fphr/spreading-the-word", "pageUrlRelative": "/posts/2pR3aStEjxJp4fphr/spreading-the-word", "linkUrl": "https://www.lesswrong.com/posts/2pR3aStEjxJp4fphr/spreading-the-word", "postedAtFormatted": "Sunday, April 19th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Spreading%20the%20word%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpreading%20the%20word%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2pR3aStEjxJp4fphr%2Fspreading-the-word%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Spreading%20the%20word%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2pR3aStEjxJp4fphr%2Fspreading-the-word", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2pR3aStEjxJp4fphr%2Fspreading-the-word", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 78, "htmlBody": "<p>This has been discussed some, but I don't think it's been the sole subject of a top-level post. I want to find out other people's ideas rather than driving the discussion into my ideas, so I'm asking the question in a very general form, and holding off on my own answers:</p>\n<ul>\n<li>Should we be trying to spread the word?</li>\n<li>If so, what is the word, and how should we be trying to spread it?</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2pR3aStEjxJp4fphr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 7, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "431", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-19T21:23:42.999Z", "modifiedAt": null, "url": null, "title": "The ideas you're not ready to post", "slug": "the-ideas-you-re-not-ready-to-post", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:17.902Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JulianMorrison", "createdAt": "2009-02-27T12:57:27.471Z", "isAdmin": false, "displayName": "JulianMorrison"}, "userId": "CeZ67D5YxAKemKhYL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZJSGLPbnKxjRiTHHz/the-ideas-you-re-not-ready-to-post", "pageUrlRelative": "/posts/ZJSGLPbnKxjRiTHHz/the-ideas-you-re-not-ready-to-post", "linkUrl": "https://www.lesswrong.com/posts/ZJSGLPbnKxjRiTHHz/the-ideas-you-re-not-ready-to-post", "postedAtFormatted": "Sunday, April 19th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20ideas%20you're%20not%20ready%20to%20post&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20ideas%20you're%20not%20ready%20to%20post%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZJSGLPbnKxjRiTHHz%2Fthe-ideas-you-re-not-ready-to-post%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20ideas%20you're%20not%20ready%20to%20post%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZJSGLPbnKxjRiTHHz%2Fthe-ideas-you-re-not-ready-to-post", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZJSGLPbnKxjRiTHHz%2Fthe-ideas-you-re-not-ready-to-post", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 152, "htmlBody": "<p>I've often had half-finished LW post ideas and crossed them off for a number of reasons, mostly they were too rough or undeveloped and I didn't feel expert enough. Other people might worry their post would be judged harshly, or feel overwhelmed, or worried about topicality, or they just want some community input before adding it.</p>\n<p>So: this is a special sort of open thread. Please post your unfinished ideas and sketches for LW posts here as comments, if you would like constructive critique, assistance and checking from people with more expertise, etc. Just pile them in without worrying too much. Ideas can be as short as a single sentence or as long as a finished post. Both subject and presentation are on topic in replies. Bad ideas should be mined for whatever good can be found in them. Good ideas should be poked with challenges to make them stronger. No being nasty!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 2, "7mTviCYysGmLqiHai": 2, "fkABsGCJZ6y9qConW": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZJSGLPbnKxjRiTHHz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 29, "extendedScore": null, "score": 5.9e-05, "legacy": true, "legacyId": "432", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 264, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-20T04:51:42.006Z", "modifiedAt": null, "url": null, "title": "Evangelical Rationality", "slug": "evangelical-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:32.341Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CannibalSmith", "createdAt": "2009-02-27T07:32:08.507Z", "isAdmin": false, "displayName": "CannibalSmith"}, "userId": "4DedYkNap2GW8X79T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cH85oDuQasBdtakWv/evangelical-rationality", "pageUrlRelative": "/posts/cH85oDuQasBdtakWv/evangelical-rationality", "linkUrl": "https://www.lesswrong.com/posts/cH85oDuQasBdtakWv/evangelical-rationality", "postedAtFormatted": "Monday, April 20th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Evangelical%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEvangelical%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcH85oDuQasBdtakWv%2Fevangelical-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Evangelical%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcH85oDuQasBdtakWv%2Fevangelical-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcH85oDuQasBdtakWv%2Fevangelical-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 381, "htmlBody": "<p><a href=\"/lw/bz/spreading_the_word/\">Spreading the Word</a> prompted me to report back <a href=\"/lw/6g/most_rationalists_are_elsewhere/4ap#comments\">as promised</a>.</p>\n<p>I have two sisters aged 17 and 14, and mom and dad aged 40-something. I'm 22, male. We're all white and <a href=\"http://en.wikipedia.org/wiki/Latvia\">Latvian</a>. I translated the articles as I read them.</p>\n<p>I read <a href=\"/lw/3b/never_leave_your_room/\">Never Leave Your Room</a> to the oldest sister and she expressed great interest in it.</p>\n<p>I read <a href=\"/lw/4e/cached_selves/\">Cached Selves</a> to them all. When I got to the part about Greenskyers the older sister asserted \"the sky is green\" for fun. Later in the conversation I asked her, \"Is the sky blue?\", and her answer was \"No. I mean, yes! Gah!\" They all found real life examples of this quickly - it turns out this is how the older sister schmoozes money and stuff out of dad (\"Can I have this discount cereal?\" followed by \"Can I have this expensive yogurt to go with my cereal?\").</p>\n<p>I started reading <a href=\"/lw/20/the_apologist_and_the_revolutionary/\">The Apologist and the Revolutionary</a> to them but halfway through the article they asked \"what's the practical application for us?\", and I realized that I couldn't answer that question - it's just a piece of trivia. So I moved on.</p>\n<p>I tried reading about near-far thing to them, but couldn't find a single good article that describes it concisely. Thus I stumbled around, and failed to convey the idea properly.</p>\n<p>In the end I asked whether they'd like to hear similar stuff in the future, and the reply was an unanimous yes. I asked them why, in their opinion, haven't they found this stuff by themselves and the reason seems to be that they have have no paths that lead to rationality stuff in their lives. Indeed, I found OB through Dresden Codak, which I found through Minus, which I found through some other webcomic forum. Nobody in my family reads webcomics not to mention frequenting their forums.</p>\n<p><strong>The takeaway</strong>, I think, is this: We must establish non-geeky paths to rationality. Go and tell people how to not be suckers. Start with people who would listen to you. You don't have to advertise LW - just be +5 informative. Rationality stuff must enter the mass media: radio, TV, newspapers. If you are in a position to make that happen, act!</p>\n<p>I would also like to see more articles like this one on LW - go, do something, report back.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7ow6EFpypbH4hzFuz": 2, "izp6eeJJEg9v5zcur": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cH85oDuQasBdtakWv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 42, "extendedScore": null, "score": 6.5e-05, "legacy": true, "legacyId": "390", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 42, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2pR3aStEjxJp4fphr", "ZmQv4DFx6y4jFbhLy", "BHYBdijDcAKQ6e45Z", "ZiQqsgGX6a42Sfpii"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-20T06:30:03.826Z", "modifiedAt": null, "url": null, "title": "The Sin of Underconfidence", "slug": "the-sin-of-underconfidence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:38.358Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pkFazhcTErMw7TFtT/the-sin-of-underconfidence", "pageUrlRelative": "/posts/pkFazhcTErMw7TFtT/the-sin-of-underconfidence", "linkUrl": "https://www.lesswrong.com/posts/pkFazhcTErMw7TFtT/the-sin-of-underconfidence", "postedAtFormatted": "Monday, April 20th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Sin%20of%20Underconfidence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Sin%20of%20Underconfidence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpkFazhcTErMw7TFtT%2Fthe-sin-of-underconfidence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Sin%20of%20Underconfidence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpkFazhcTErMw7TFtT%2Fthe-sin-of-underconfidence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpkFazhcTErMw7TFtT%2Fthe-sin-of-underconfidence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1866, "htmlBody": "<p>There are three great besetting sins of rationalists in particular, and the third of these is underconfidence.&nbsp; Michael Vassar regularly accuses me of this sin, which makes him unique among the entire population of the Earth.</p>\n<p>But he's actually quite right to worry, and I worry too, and any adept rationalist will probably spend a fair amount of time worying about it.&nbsp; When subjects know about a bias or are warned about a bias, <em>overcorrection</em> is not unheard of as an experimental result.&nbsp; That's what makes a lot of cognitive subtasks so troublesome&mdash;you know you're biased but you're not sure <em>how much,</em> and you don't know if you're correcting <em>enough</em>&mdash;and so perhaps you ought to correct a little more, and then a little more, but is <em>that</em> enough?&nbsp; Or have you, perhaps, far overshot?&nbsp; Are you now perhaps worse off than if you hadn't tried any correction?</p>\n<p>You contemplate the matter, feeling more and more lost, and the very task of estimation begins to feel increasingly futile...</p>\n<p>And when it comes to the particular questions of <em>confidence, overconfidence,</em> and <em>underconfidence</em>&mdash;being interpreted now in the broader sense, not just calibrated confidence intervals&mdash;then there is a natural tendency to cast overconfidence as the <em>sin</em> of pride, out of that <em>other </em>list which never warned against <a href=\"http://www.overcomingbias.com/2006/12/the_proper_use_.html\">the improper use of humility</a> or <a href=\"http://www.overcomingbias.com/2007/08/the-proper-use-.html\">the abuse of doubt</a>.&nbsp; To place yourself too high&mdash;to overreach your proper place&mdash;to think too much of yourself&mdash;to put yourself forward&mdash;to put down your fellows by implicit comparison&mdash;and the consequences of humiliation and being cast down, perhaps publicly&mdash;are these not loathesome and fearsome things?</p>\n<p>To be too <em>modest</em>&mdash;seems lighter by comparison; it wouldn't be so humiliating to be called on it publicly, indeed, finding out that you're better than you imagined might come as a warm surprise; and to put yourself down, and others implicitly above, has a positive tinge of <em>niceness</em> about it, it's the sort of thing that Gandalf would do.</p>\n<p>So if you have learned a thousand ways that humans fall into error and read a hundred experimental results in which anonymous subjects are humiliated of their overconfidence&mdash;heck, even if you've just read a couple of dozen&mdash;and you don't <em>know</em> exactly how overconfident you are&mdash;then yes, you might genuinely be in danger of nudging yourself a step too far down.<a id=\"more\"></a></p>\n<p>I have no perfect formula to give you that will counteract this.&nbsp; But I have an item or two of advice.</p>\n<p>What is the <em>danger</em> of underconfidence?</p>\n<p>Passing up opportunities.&nbsp; Not doing things you could have done, but didn't try (<a href=\"http://www.overcomingbias.com/2008/10/use-the-try-har.html\">hard enough</a>).</p>\n<p>So here's a first item of advice:&nbsp; If there's a way to <em>find out</em> how good you are, the thing to do is <em>test</em> it.&nbsp; <em>A hypothesis affords testing;</em> hypotheses about your own abilities likewise.&nbsp; Once upon a time it seemed to me that I ought to be able to win at the <a href=\"http://yudkowsky.net/singularity/aibox\">AI-Box Experiment</a>; and it seemed like a very doubtful and hubristic thought; so I tested it.&nbsp; Then later it seemed to me that I might be able to win even with large sums of money at stake, and I tested that, but I only won 1 time out of 3.&nbsp; So that was the limit of my ability at that time, and it was not necessary to argue myself upward or downward, because I could just <em>test</em> it.</p>\n<p>One of the chief ways that <a href=\"http://www.amazon.com/Why-Smart-People-Can-Stupid/dp/0300090331\">smart people end up stupid</a>, is by getting <em>so used to winning</em> that they stick to places where they <em>know they can win</em>&mdash;meaning that they never stretch their abilities, they never try anything difficult.</p>\n<p>It is said that this is linked to defining yourself in terms of your \"intelligence\" rather than \"effort\", because then winning <em>easily </em>is a sign of your \"intelligence\", where failing on a hard problem could have been interpreted in terms of a good effort.</p>\n<p>Now, I am not quite sure this is how an adept rationalist should think about these things: <a href=\"/lw/7i/rationality_is_systematized_winning/\">rationality <em>is </em>systematized winning</a> and <a href=\"http://www.overcomingbias.com/2008/10/trying-to-try.html\">trying to try</a><strong> </strong>seems like a path to failure.&nbsp; I would put it this way:&nbsp; A hypothesis affords testing!&nbsp; If you <em>don't know </em>whether you'll win on a hard problem&mdash;then <em>challenge your rationality</em> to <em>discover</em> your current level.&nbsp; I don't usually hold with congratulating yourself on having tried&mdash;it seems like a bad mental habit to me&mdash;but surely <em>not</em> trying is even <em>worse.</em>&nbsp; If you have cultivated a general habit of confronting challenges, and won on at least <em>some</em> of them, then you may, perhaps, think to yourself \"I did keep up my habit of confronting challenges, and will do so next time as well\".&nbsp; You may also think to yourself \"I have gained valuable information about my current level and where I need improvement\", so long as you properly complete the thought, \"I shall try not to gain this same valuable information again <a href=\"http://www.overcomingbias.com/2007/03/tsuyoku_naritai.html\">next time</a>\".</p>\n<p>If you win <em>every</em> time, it means you aren't stretching yourself enough.&nbsp; But you <em>should</em> seriously try to win every time.&nbsp; And if you console yourself too much for failure, you lose your winning spirit and <a href=\"http://www.sirlin.net/articles/playing-to-win-part-1.html\">become a scrub</a>.</p>\n<p>When I try to imagine what a fictional master of the Competitive Conspiracy would say about this, it comes out something like:&nbsp; \"It's <em>not </em>okay to lose.&nbsp; But the <em>hurt</em> of losing is not something so scary that you should flee the challenge for fear of it.&nbsp; It's not so scary that you have to carefully avoid feeling it, or refuse to admit that you lost and lost hard.&nbsp; Losing is <em>supposed</em> to hurt.&nbsp; If it didn't hurt you wouldn't be a Competitor.&nbsp; And there's <em>no </em>Competitor who <em>never </em>knows the pain of losing.&nbsp; Now get out there and <em>win</em>.\"</p>\n<p>Cultivate a habit of confronting challenges&mdash;not the ones that can kill you outright, perhaps, but perhaps ones that can potentially <em>humiliate</em> you.&nbsp; I recently read of a certain theist that he had defeated Christopher Hitchens in a debate (severely so; this was said by atheists).&nbsp; And so I wrote at once to the Bloggingheads folks and asked if they could arrange a debate.&nbsp; This seemed like someone I wanted to test myself against.&nbsp; Also, it was said by them that Christopher Hitchens should have watched the theist's earlier debates and been prepared, so I decided <em>not </em>to do that, because I think I should be able to handle damn near anything on the fly, and I desire to learn whether this thought is correct; and I am willing to risk public humiliation to find out.&nbsp; Note that this is <em>not </em>self-handicapping in the classic sense&mdash;if the debate is indeed arranged (I haven't yet heard back), and I do not prepare, and I fail, then I do lose those stakes of myself that I have put up; I gain information about my limits; I have <em>not</em> given myself anything I consider an excuse for losing.</p>\n<p>Of course this is only a way to think when you really <em>are</em> confronting a challenge just to test yourself, and not because you have to win at any cost.&nbsp; In <em>that</em> case you make everything as easy for yourself as possible.&nbsp; To do otherwise would be <em>spectacular</em> overconfidence, even if you're playing tic-tac-toe against a three-year-old.</p>\n<p>A subtler form of underconfidence is <em>losing your forward momentum</em>&mdash;amid all the things you realize that humans are doing wrong, that you used to be doing wrong, of which you are probably still doing some wrong.&nbsp; You become timid; you question yourself <em>but don't answer the self-questions and move on;</em> when you hypothesize your own inability <em>you do not put that hypothesis to the test.</em></p>\n<p>Perhaps without there ever being a watershed moment when you deliberately, self-visibly <em>decide not to try</em> at some particular test... you just.... slow..... down......</p>\n<p>It doesn't seem worthwhile any more, to go on trying to fix one thing when there are a dozen other things that will still be wrong...</p>\n<p>There's not enough hope of triumph to <em>inspire </em>you to try <em>hard</em>...</p>\n<p>When you consider doing any new thing, a dozen questions about your ability at once leap into your mind, and it does not occur to you that you could <em>answer</em> the questions by <em>testing</em> yourself...</p>\n<p>And having read so much wisdom of human flaws, it seems that the course of wisdom is ever doubting (never resolving doubts), ever the humility of refusal (never the humility of preparation), and just generally, that it is wise to say worse and worse things about human abilities, to pass into <a href=\"http://www.overcomingbias.com/2009/02/cynical-about-cynicism.html\">feel-good feel-bad cynicism</a>.</p>\n<p>And so my last piece of advice is another perspective from which to view the problem&mdash;by which to judge any potential habit of thought you might adopt&mdash;and that is to ask:</p>\n<p><em>Does this way of thinking make me stronger, or weaker?&nbsp; Really truly?</em></p>\n<p>I have previously spoken of the danger of <em>reasonableness</em>&mdash;the reasonable-sounding argument that we should <a href=\"http://www.overcomingbias.com/2008/01/newcombs-proble.html\">two-box on Newcomb's problem</a>, the reasonable-sounding argument that we can't know anything due to <a href=\"http://www.overcomingbias.com/2008/07/recursive-justi.html\">the problem of induction</a>, the reasonable-sounding argument that we will be better off on average if we always <a href=\"http://www.overcomingbias.com/2007/03/on_majoritarian.html\">adopt the majority belief</a>, and other such impediments to the Way.&nbsp; \"Does it win?\" is one question you could ask to get an alternate perspective.&nbsp; Another, slightly different perspective is to ask, \"Does this way of thinking make me stronger, or weaker?\"&nbsp; Does constantly reminding yourself to doubt everything make you stronger, or weaker?&nbsp; Does <a href=\"http://www.overcomingbias.com/2007/08/the-proper-use-.html\">never resolving</a> or decreasing those doubts make you stronger, or weaker?&nbsp; Does undergoing a deliberate <a href=\"http://www.overcomingbias.com/2008/10/got-crisis.html\">crisis of faith</a><strong> </strong>in the face of uncertainty make you stronger, or weaker?&nbsp; Does answering every objection with a humble confession of you fallibility make you stronger, or weaker?</p>\n<p>Are your current attempts to compensate for possible overconfidence making you stronger, or weaker?&nbsp; Hint:&nbsp; If you are taking more precautions, more scrupulously trying to test yourself, asking friends for advice, working your way up to big things incrementally, or still failing sometimes but less often then you used to, you are probably getting stronger.&nbsp; If you are <em>never </em>failing, avoiding challenges, and feeling generally hopeless and dispirited, you are probably getting weaker.</p>\n<p>I learned the first form of this rule at a very early age, when I was practicing for a certain math test, and found that my score was going down with each practice test I took, and noticed going over the answer sheet that I had been pencilling in the correct answers and erasing them.&nbsp; So I said to myself, \"All right, <em>this</em> time I'm going to use the Force and act on instinct\", and my score shot up to above what it had been in the beginning, and on the real test it was higher still.&nbsp; So that was how I learned that doubting yourself does not always make you stronger&mdash;especially if it interferes with your ability to be moved by good information, such as your math intuitions.&nbsp; (But I <em>did</em> need the test to tell me this!)</p>\n<p>Underconfidence is not a unique sin of rationalists alone.&nbsp; But it is a particular danger into which <em>the attempt to be rational</em> can lead you.&nbsp; And it is a <em>stopping</em> mistake&mdash;an error which prevents you from gaining that further experience which would correct the error.</p>\n<p>Because underconfidence actually <em>does</em> seem quite common among aspiring rationalists who I meet&mdash;though rather less common among rationalists who have become famous role models)&mdash;I would indeed name it third among the three besetting sins of rationalists.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hrezrpGqXXdSe76ks": 1, "9YFoDPFwMoWthzgkY": 1, "YPZCAs9Axp9PtrF22": 1, "8hPTCJbwJnLBmfpCX": 4, "5f5c37ee1b5cdee568cfb118": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pkFazhcTErMw7TFtT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 89, "baseScore": 86, "extendedScore": null, "score": 0.00013, "legacy": true, "legacyId": "435", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "go-forth-and-create-the-art", "canonicalPrevPostSlug": "practical-advice-backed-by-deep-theories", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 86, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 185, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4ARtkT3EYox3THYjF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-20T21:20:50.815Z", "modifiedAt": null, "url": null, "title": "Masochism vs. Self-defeat", "slug": "masochism-vs-self-defeat", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:37.564Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psychohistorian", "createdAt": "2009-04-05T18:10:22.976Z", "isAdmin": false, "displayName": "Psychohistorian"}, "userId": "mAQgf4N8jv2jTMK5B", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yuhYmSmHTqC7QPShf/masochism-vs-self-defeat", "pageUrlRelative": "/posts/yuhYmSmHTqC7QPShf/masochism-vs-self-defeat", "linkUrl": "https://www.lesswrong.com/posts/yuhYmSmHTqC7QPShf/masochism-vs-self-defeat", "postedAtFormatted": "Monday, April 20th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Masochism%20vs.%20Self-defeat&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMasochism%20vs.%20Self-defeat%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyuhYmSmHTqC7QPShf%2Fmasochism-vs-self-defeat%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Masochism%20vs.%20Self-defeat%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyuhYmSmHTqC7QPShf%2Fmasochism-vs-self-defeat", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyuhYmSmHTqC7QPShf%2Fmasochism-vs-self-defeat", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 525, "htmlBody": "<p>Follow up to: <a href=\"/lw/ac/is_masochism_necessary/\">Is masochism necessary?</a>,&nbsp; <a href=\"/lw/9o/stuck_in_the_middle_with_bruce/\"><span style=\"color: #8a8a8b;\">Stuck in the middle with Bruce</span></a></p>\r\n<p>Masochism has two very different meanings: enjoyment of pain, and pursuit (<em>not</em> enjoyment) of suffering.</p>\r\n<p>As a rather blunt example of this distinction, consider a sexual masochist. If his girlfriend ties him up and beats him, he'll experience pain, but he certainly won't suffer; he'll probably enjoy himself immensely. Put someone with vanilla sexual tastes in his place, and he would experience both pain and suffering.</p>\r\n<p><a href=\"/lw/9o/stuck_in_the_middle_with_bruce/\">Bruce-like</a> behaviour is best understood as pursuit of suffering. People undermine themselves or set themselves up to lose. They may do it so that they have a comfortable excuse, or because they are used to failing and afraid of being happy, or for many other reasons. Most of us do this to some degree, however slight, and it's something we want to avoid.<sup>1</sup> Pursuit of suffering, quite simply, gets in the way of <a href=\"/lw/7i/rationality_is_systematized_winning/\">winning</a>, and, much like akratic behaviour, it is something that we should try desperately to find and destroy, because we should be happier without it.</p>\r\n<p>This is very, very different from enjoyment of pain. If you like getting beaten up, or spicy foods, or running marathons, this has no effect on whether you win; these become&nbsp;a <em>kind</em> of winning.&nbsp;The fact that these activities cause suffering in some people is wholly irrelevant.&nbsp;For those who enjoy them, they create happiness, and obtaining them is, in a sense, a form of winning. Because of this, there's no reason to try to catch ourselves engaging in them or to worry about engaging in them less. It does not seem like people would be happier if they lost these prefereces.<sup>2</sup></p>\r\n<p>Indeed, given that they require some level of initial exposure, and (in the sexual case) have strong social taboos against them, it seems quite likely that masochistic behaviour isn't engaged in <em>enough</em>, though I admit I may be going too far.</p>\r\n<p>Edit: As a point of clarification, \"Bruce-like\" behaviour may be overbroad. Some people set themselves up to lose because, for whatever reason, they genuinely like losing. That isn't pursuit of suffering, because there's no suffering. However, we do sometimes undermine ourselves&nbsp;when we want to win. The precise cause of this is, for my purposes, immaterial. This is what I'm referring to by \"pursuit of suffering,\" and my entire point is that it&nbsp;is quite distinct from&nbsp;enjoyment or&nbsp;pursuit of pain, and that this difference is worth noticing.</p>\r\n<p>A proof of the utilitarian benefit of sadism is left to the reader, or as the topic for a follow-up post if people like this one.</p>\r\n<p><strong>1 - </strong>If we actually enjoy failure, such that presented with the simple choice of win/lose, we repeatedly chose lose, that's a separate subject and would fall under&nbsp;another description, like \"enjoyment of&nbsp;failure.\" This is something that one might be happier without, but that's really another issue for another post.</p>\r\n<p><strong>2- </strong>This is not to say that some people shouldn't engage in them less. There are people who engage in self-destructive behaviour. Some use sex as a means of escape. Some anorexics exercise compulsively. But the fact that these can be unhealthy in specific circumstances is of no relevance to the greater population that enjoys them responsibly.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Jzm2mYuuDBCNWq8hi": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yuhYmSmHTqC7QPShf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "438", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mCQf5FCXjwTBeLC6u", "FZaDFYbnRoHmde7F6", "4ARtkT3EYox3THYjF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-21T02:44:52.788Z", "modifiedAt": "2020-08-01T06:43:23.081Z", "url": null, "title": "Well-Kept Gardens Die By Pacifism", "slug": "well-kept-gardens-die-by-pacifism", "viewCount": null, "lastCommentedAt": "2019-07-01T19:02:49.749Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism", "pageUrlRelative": "/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism", "linkUrl": "https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism", "postedAtFormatted": "Tuesday, April 21st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Well-Kept%20Gardens%20Die%20By%20Pacifism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWell-Kept%20Gardens%20Die%20By%20Pacifism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftscc3e5eujrsEeFN4%2Fwell-kept-gardens-die-by-pacifism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Well-Kept%20Gardens%20Die%20By%20Pacifism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftscc3e5eujrsEeFN4%2Fwell-kept-gardens-die-by-pacifism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftscc3e5eujrsEeFN4%2Fwell-kept-gardens-die-by-pacifism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1368, "htmlBody": "<p><strong>Previously in series</strong>:&nbsp; <a href=\"/lw/bd/my_way/\">My Way</a><br /><strong>Followup to</strong>:&nbsp; <a href=\"/lw/c3/the_sin_of_underconfidence/\">The Sin of Underconfidence</a></p>\n<p>Good online communities die primarily by refusing to defend themselves.</p>\n<p>Somewhere in the vastness of the Internet, it is happening even now.&nbsp; It was once a well-kept garden of intelligent discussion, where knowledgeable and interested folk came, attracted by the high quality of speech they saw ongoing.&nbsp; But into this garden comes a fool, and the level of discussion drops a little&mdash;or more than a little, if the fool is very prolific in their posting.&nbsp; (It is worse if the fool is just articulate enough that the former inhabitants of the garden feel obliged to respond, and correct misapprehensions&mdash;for then the fool dominates conversations.)</p>\n<p>So the garden is tainted now, and it is <em>less fun to play in;</em> the old inhabitants, already invested there, will stay, but they are that much less likely to attract new blood.&nbsp; Or if there are new members, their quality also has gone down.</p>\n<p>Then <em>another</em> fool joins, and the two fools begin talking to <em>each other,</em> and at that point some of the old members, those with the highest standards and the best opportunities elsewhere, leave...</p>\n<p>I am old enough to remember the USENET that is forgotten, though I was very young.&nbsp; Unlike the first Internet that died so long ago in the Eternal September, in these days there is always <em>some</em> way to delete unwanted content.&nbsp; We can thank spam for that&mdash;so egregious that no one defends it, so prolific that no one can just ignore it, there <em>must</em> be a banhammer somewhere.</p>\n<p>But when the fools begin their invasion, <em>some</em> communities think themselves too <em>good </em>to use their banhammer for&mdash;gasp!&mdash;<em>censorship.</em></p>\n<p>After all&mdash;anyone acculturated by academia knows that <em>censorship</em> is a very grave sin... in their walled gardens where it costs thousands and thousands of dollars to enter, and students fear their professors' grading, and heaven forbid the janitors should speak up in the middle of a colloquium.<a id=\"more\"></a></p>\n<p>It is easy to be naive about the evils of <em>censorship </em>when you already live in a carefully kept garden.&nbsp; Just like it is easy to be naive about the universal virtue of unconditional nonviolent pacifism, when your country already has armed soldiers on the borders, and your city already has police.&nbsp; It costs you nothing to be righteous, so long as the police stay on their jobs.</p>\n<p>The thing about online communities, though, is that you can't rely on the police ignoring you and staying on the job; the community actually pays the price of its virtuousness.</p>\n<p>In the beginning, while the community is still thriving, <em>censorship </em>seems like a terrible and unnecessary imposition.&nbsp; Things are still going fine.&nbsp; It's just one fool, and if we can't tolerate just one fool, well, we must not be very tolerant.&nbsp; Perhaps the fool will give up and go away, without any need of <em>censorship.</em>&nbsp; And if the whole community has become just that much less <em>fun</em> to be a part of... mere <em>fun</em> doesn't seem like a good justification for (gasp!) <em>censorship,</em> any more than disliking someone's looks seems like a good reason to punch them in the nose.</p>\n<p>(But <em>joining</em> a community is a strictly voluntary process, and if prospective new members don't like your looks, they won't join in the first place.)</p>\n<p>And after all&mdash;<em>who</em> will be the censor?&nbsp; Who can <em>possibly </em>be trusted with such power?</p>\n<p>Quite a lot of people, probably, in any well-kept garden.&nbsp; But if the garden is even a little divided within <em>itself </em>&mdash;if there are <em>factions</em>&mdash;if there are people who hang out in the community despite <em>not</em> much trusting the moderator or whoever could potentially wield the banhammer&mdash;</p>\n<p>(for such internal politics often seem like a matter of far greater import than mere invading barbarians)</p>\n<p>&mdash;then trying to defend the community is typically depicted as a <em>coup attempt</em>.&nbsp; Who is this one who <em>dares </em>appoint themselves as judge and executioner?&nbsp; Do they think their ownership of the server means they own the <em>people?</em>&nbsp; Own <em>our</em> community?&nbsp; Do they think that control over the source code makes them a <em>god?</em></p>\n<p>I confess, for a while I didn't even understand why communities had such trouble defending themselves&mdash;I thought it was pure <em>naivete</em>.&nbsp; It didn't occur to me that it was an <a href=\"http://www.overcomingbias.com/2007/03/tsuyoku_vs_the_.html\">egalitarian instinct</a> to prevent chieftains from getting too much power.&nbsp; \"None of us are bigger than one another, all of us are men and can fight; I am going to get my arrows\", was the saying in one hunter-gatherer tribe whose name I forget.&nbsp; (Because among humans, unlike chimpanzees, weapons are an equalizer&mdash;the tribal chieftain seems to be an invention of agriculture, when people can't just walk away any more.)</p>\n<p>Maybe it's because I grew up on the Internet in places where there was always a sysop, and so I take for granted that whoever runs the server has certain responsibilities.&nbsp; Maybe I understand on a gut level that the opposite of censorship is not academia but 4chan (which probably <em>still</em> has mechanisms to prevent spam).&nbsp; Maybe because I grew up in that wide open space where the freedom that mattered was the freedom to <em>choose </em>a well-kept garden that you liked and that liked you, as if you actually could find a country with good laws.&nbsp; Maybe because I take it for granted that if you don't like the archwizard, the thing to do is walk away (this did happen to me once, and I did indeed just walk away).</p>\n<p>And maybe because I, myself, have often been the one running the server.&nbsp; But I am consistent, usually being first in line to support moderators&mdash;even when they're on the other side from me of the internal politics.&nbsp; I <em>know</em> what happens when an online community starts questioning its moderators.&nbsp; Any political enemy I have on a mailing list who's popular enough to be dangerous is probably not someone who would abuse that <em>particular</em> power of censorship, and when they put on their moderator's hat, I vocally support them&mdash;they need urging on, not restraining.&nbsp; People who've grown up in academia simply don't realize how strong are the walls of exclusion that keep the trolls out of their lovely garden of \"free speech\".</p>\n<p>Any community that <em>really</em> needs to question its moderators, that <em>really seriously</em> has abusive moderators, is probably not worth saving.&nbsp; But this is more accused than realized, so far as I can see.</p>\n<p>In any case the light didn't go on in my head about egalitarian instincts (instincts to prevent leaders from exercising power) killing online communities until just recently.&nbsp; While reading a comment at Less Wrong, in fact, though I don't recall which one.</p>\n<p>But I <em>have</em> seen it happen&mdash;over and over, with myself urging the moderators on and supporting them whether they were people I liked or not, and the moderators <em>still</em> not doing enough to prevent the slow decay.&nbsp; Being too <em>humble,</em> doubting themselves an order of magnitude more than <em>I</em> would have doubted them.&nbsp; It was a rationalist hangout, and the third besetting sin of rationalists is <a href=\"/lw/c3/the_sin_of_underconfidence/\">underconfidence</a>.</p>\n<p>This about the Internet:&nbsp; Anyone can walk in.&nbsp; And anyone can walk out.&nbsp; And so an online community must stay <em>fun</em> to stay alive.&nbsp; Waiting until the last resort of absolute, blatent, undeniable egregiousness&mdash;waiting as long as a police officer would wait to open fire&mdash;indulging your conscience and the virtues you learned in walled fortresses, waiting until you can be <em>certain you are in the right, and fear no questioning looks</em>&mdash;is waiting <em>far</em> too late.</p>\n<p>I have seen rationalist communities die because they trusted their moderators too little.</p>\n<p>But <em>that</em> was not a karma system, actually.</p>\n<p>Here&mdash;you must trust <em>yourselves.</em></p>\n<p>A certain quote seems appropriate here:&nbsp; \"Don't believe in yourself!&nbsp; Believe that I believe in you!\"</p>\n<p>Because I really do honestly think that if you want to downvote a comment that seems low-quality... and yet you hesitate, wondering if maybe you're downvoting just because you disagree with the conclusion or dislike the author... feeling nervous that someone watching you might accuse you of groupthink or echo-chamber-ism or (gasp!) <em>censorship...</em> then nine times of ten, I bet, nine times out of ten at <em>least,</em> it is a comment that really is low-quality.</p>\n<p>You have the downvote.&nbsp; Use it or USENET.</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/c3/the_sin_of_underconfidence/\">The Sin of Underconfidencee</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 2, "MXcpQvaPGtXpB6vkM": 3, "oraLTPkETL5xKmhx3": 5}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tscc3e5eujrsEeFN4", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 184, "baseScore": 189, "extendedScore": null, "score": 0.000292, "legacy": true, "legacyId": "433", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 189, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 316, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FBgozHEv7J72NCEPB", "pkFazhcTErMw7TFtT", "YdcF6WbBmJhaaDqoD", "LqjKP255fPRY7aMzw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 18, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-21T02:44:52.788Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-22T00:23:12.630Z", "modifiedAt": null, "url": null, "title": "UC Santa Barbara Rationalists Unite - Saturday, 6PM", "slug": "uc-santa-barbara-rationalists-unite-saturday-6pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:36.689Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dTnfX3HWizKeovFn3/uc-santa-barbara-rationalists-unite-saturday-6pm", "pageUrlRelative": "/posts/dTnfX3HWizKeovFn3/uc-santa-barbara-rationalists-unite-saturday-6pm", "linkUrl": "https://www.lesswrong.com/posts/dTnfX3HWizKeovFn3/uc-santa-barbara-rationalists-unite-saturday-6pm", "postedAtFormatted": "Wednesday, April 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20UC%20Santa%20Barbara%20Rationalists%20Unite%20-%20Saturday%2C%206PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUC%20Santa%20Barbara%20Rationalists%20Unite%20-%20Saturday%2C%206PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdTnfX3HWizKeovFn3%2Fuc-santa-barbara-rationalists-unite-saturday-6pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=UC%20Santa%20Barbara%20Rationalists%20Unite%20-%20Saturday%2C%206PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdTnfX3HWizKeovFn3%2Fuc-santa-barbara-rationalists-unite-saturday-6pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdTnfX3HWizKeovFn3%2Fuc-santa-barbara-rationalists-unite-saturday-6pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 110, "htmlBody": "<p>Anna Salamon and I are calling for a Less Wrong meetup here in sunny Santa Barbara. Anna and Steve Rayhawk, Less Wrong's most successful (and so far, only) writing duo are on their way through SB, and I know there's a few LWers hiding in Isla Vista and in Santa Barbara. We'll be meeting at the college of creative studies building on the UCSB campus,&nbsp;right between Santa Rosa dorms and the Multicultural Center. I'll also be inviting some folks from the campus secular group, SURE (Scientific Understanding and Reason Enrichment).</p>\n<p>You'll also find the event <a href=\"http://www.facebook.com/event.php?eid=70359748485&amp;ref=nf\">listed on Facebook</a> -- feel free to RSVP there.&nbsp;</p>\n<p>Definitely looking forward to seeing you all =).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dTnfX3HWizKeovFn3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 3, "extendedScore": null, "score": 4.893226949185925e-07, "legacy": true, "legacyId": "446", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-22T01:18:01.692Z", "modifiedAt": null, "url": null, "title": "LessWrong Boo Vote (Stochastic Downvoting)", "slug": "lesswrong-boo-vote-stochastic-downvoting", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:45.477Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_Nesov", "createdAt": "2009-02-27T09:55:13.458Z", "isAdmin": false, "displayName": "Vladimir_Nesov"}, "userId": "qf77EiaoMw7tH3GSr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/d96W52qJhKkp7syYY/lesswrong-boo-vote-stochastic-downvoting", "pageUrlRelative": "/posts/d96W52qJhKkp7syYY/lesswrong-boo-vote-stochastic-downvoting", "linkUrl": "https://www.lesswrong.com/posts/d96W52qJhKkp7syYY/lesswrong-boo-vote-stochastic-downvoting", "postedAtFormatted": "Wednesday, April 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LessWrong%20Boo%20Vote%20(Stochastic%20Downvoting)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALessWrong%20Boo%20Vote%20(Stochastic%20Downvoting)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd96W52qJhKkp7syYY%2Flesswrong-boo-vote-stochastic-downvoting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LessWrong%20Boo%20Vote%20(Stochastic%20Downvoting)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd96W52qJhKkp7syYY%2Flesswrong-boo-vote-stochastic-downvoting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd96W52qJhKkp7syYY%2Flesswrong-boo-vote-stochastic-downvoting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p><strong>Related to</strong>: <a href=\"/lw/c1/wellkept_gardens_die_by_pacifism/\">Well-Kept Gardens Die By Pacifism</a>.</p>\n<p>I wrote a <a href=\"http://userscripts.org/scripts/show/47209\">script</a> for the <a href=\"https://addons.mozilla.org/firefox/addon/748\">greasemonkey extension</a> for Firefox, implementing less painful downvoting. It inserts a button \"Vote <a href=\"/lw/bk/the_trouble_with_good/\">boo</a>\" in addition to \"Vote up\" and \"Vote down\" for each comment. Pressing this button has 30% chance of resulting in downvoting the comment, which is on average equivalent to taking 0.3 points of rating. If pressing the button once has no effect, don't press it twice: the action is already performed, resulting in one of the two possible outcomes.</p>\n<p><a href=\"/lw/c1/wellkept_gardens_die_by_pacifism/8ux#comments\">The idea</a> is to lower the level of punishment from downvoting, thus making it easier to downvote <em>average</em> mediocre comments, not just remarkably bad ones. Systematically downvoting mediocre comments should make their expected rating negative, creating an incentive to focus more on making high-quality comments, and punishing <a href=\"/lw/c1/wellkept_gardens_die_by_pacifism/\">systematic mediocrity</a>. At the same time, low penalty for average comments (implemented through stochastic downvoting) allows to still make them freely, which is essential for supporting a discussion. Contributors may see positive rating of good comments as currency for which they can buy a limited number of discussion-supporting average comments.</p>\n<p>The \"Vote boo\" option is not to be taken lightly, one <a href=\"/lw/c1/wellkept_gardens_die_by_pacifism/8xn#comments\">should understand</a> a comment before declaring it mediocre. If you are not sure, don't vote. If comment is visibly a simple passing remark, or of mediocre quality, press the button.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "d96W52qJhKkp7syYY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 4, "extendedScore": null, "score": 5e-06, "legacy": true, "legacyId": "447", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tscc3e5eujrsEeFN4", "M2LWXsJxKS626QNEA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-22T05:21:49.377Z", "modifiedAt": null, "url": null, "title": "Proposal: Use the Wiki for Concepts", "slug": "proposal-use-the-wiki-for-concepts", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:49.600Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cDQFK7tPDo9H4nPSE/proposal-use-the-wiki-for-concepts", "pageUrlRelative": "/posts/cDQFK7tPDo9H4nPSE/proposal-use-the-wiki-for-concepts", "linkUrl": "https://www.lesswrong.com/posts/cDQFK7tPDo9H4nPSE/proposal-use-the-wiki-for-concepts", "postedAtFormatted": "Wednesday, April 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Proposal%3A%20Use%20the%20Wiki%20for%20Concepts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProposal%3A%20Use%20the%20Wiki%20for%20Concepts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcDQFK7tPDo9H4nPSE%2Fproposal-use-the-wiki-for-concepts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Proposal%3A%20Use%20the%20Wiki%20for%20Concepts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcDQFK7tPDo9H4nPSE%2Fproposal-use-the-wiki-for-concepts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcDQFK7tPDo9H4nPSE%2Fproposal-use-the-wiki-for-concepts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 806, "htmlBody": "<p>So... the longer I think about this Wiki thing, the more it seems like a really good idea - a missing piece falling into place.</p>\n<p>Here's my proposal, which I turn over to this, the larger community that suggested the Wiki in the first place:</p>\n<p>The Wiki should consist mainly of <em>short concept introductions</em> plus <em>links to longer posts,</em> rather than <em>original writing.</em>&nbsp; Original writing goes in a post on Less Wrong, which may get voted up and down, or commented on; and this post should reference previous work by <em>linking to the Wiki rather than other posts,</em> to the extent that the concepts referred to can be given short summaries.&nbsp; The intent is to set up a resonance that bounces back and forth between the Wiki (short concept summaries that can be read standalone, and links to more info for in-depth exploration) and the posts (which make the actual arguments and do the actual analyses).</p>\n<p>My role model here is TV Tropes, which manages to be, shall we say, <em>really explorable,</em> because of the resonance between the tropes, and the shows/events in which those tropes occur, and the <em>other</em> tropes that occur in those shows/events.&nbsp; And furthermore, you know that the trope explanation itself will be a short bite of joy, and that reading the further references is optional.<a id=\"more\"></a></p>\n<p>There would be exceptions to the \"no original research\" rule for projects that were multi-editor and not easily prosecuted through comments - for example, a project to make a list of all posts with one-sentence summaries in chronological order.</p>\n<p>There are also obvious exceptions to the \"link to the wiki\" rule, such as for any case where it really was futile to reference anything except the complete argument; or where you wanted to talk about part of the argument, rather than the general concept argued; or when you wanted to talk about a conversational event that happened in a particular post.</p>\n<p>I would suggest that the general format of a Wiki entry be a short summary / definition (that can maybe <em>gloss</em> or <em>list</em> some of the arguments if there's room, or even give the argument if it can be put really briefly), with the body of this being no more than a screenful as a general rule.&nbsp; Then links to posts, with descriptions (for each post) of why that post is relevant or what it has to say - probably one or two sentences, as a rule.&nbsp; Then references to outside posts on the same topic - although if the <em>best</em> reference is an outside discussion, that could come first.</p>\n<p>Summaries of whole sequences could also go on the Wiki - since it seems more like <em>static descriptive content,</em> rather than <em>debatable analysis and argument,</em> which is how the wiki/blog dichotomy is starting to shape up in my mind.</p>\n<p>Given unlimited development resources we'd want to integrate the two userbases, have a karma requirement to edit the Wiki, and such things, but we don't have much development resources (whines for Python volunteers again).&nbsp; But I would still like to see a list of recent edits and/or active pages in the Less Wrong blog sidebar, and a list of recent blog posts and recent comments in the Wiki sidebar.&nbsp; Of course the first priority is getting the Wiki set up on Less Wrong at all, rather than the current foreign host - I'm told this is in In Progress.</p>\n<p>Once my old posts are imported from Overcoming Bias, it would be nice if someone went through them and changed the links to posts (that reference concepts <em>per se</em>, rather than conversational events or parts of arguments) to links to the Wiki, creating appropriate pages and concept summaries as necessary.&nbsp; That is, it would be nice if I didn't have to do this myself.&nbsp; Anyone interested in volunteering, leave a comment - it'd be nice if you had some comments to your name, by which to judge your writing skills, and perhaps some karma.&nbsp; This is a large job - though 10 posts a day would get it done in two months - so don't step up if you don't have the time.&nbsp; It does seem like the sort of thing that should definitely get done by someone who is not me.</p>\n<p>I've already seen <a href=\"http://ricketyclick.com/blog/index.php/2008/06/12/quote-of-the-day-wearing-the-clown-suit/\">at least one person</a> call <em>Overcoming Bias</em> \"a bigger, and far more productive, time sink than Wikipedia or even TV Tropes\".&nbsp; Done right, it really <em>could</em> be more addictive than TV Tropes, for the intellectually curious, because it would seem (and be!) more productive; when you browse TV Tropes it <em>feels</em> like you're wasting time.</p>\n<p>I suppose I should feel slightly nervous about this, but it still seems like something that ought to be done if feasible, even though it sounds a bit scary - and I <em>hope</em> I'm not just saying that because I'm tempted to break out into mad scientist laughter.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "ZWmB62xB6uLyRuAtX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cDQFK7tPDo9H4nPSE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 39, "extendedScore": null, "score": 0.000550405687542528, "legacy": true, "legacyId": "448", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-22T21:15:14.171Z", "modifiedAt": null, "url": null, "title": "Escaping Your Past", "slug": "escaping-your-past", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:37.667Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Z_M_Davis", "createdAt": "2009-02-27T04:57:37.811Z", "isAdmin": false, "displayName": "Z_M_Davis"}, "userId": "YEWv9mcjBb7Z7Cgw3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ASiCdt4qFaNADzdzw/escaping-your-past", "pageUrlRelative": "/posts/ASiCdt4qFaNADzdzw/escaping-your-past", "linkUrl": "https://www.lesswrong.com/posts/ASiCdt4qFaNADzdzw/escaping-your-past", "postedAtFormatted": "Wednesday, April 22nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Escaping%20Your%20Past&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEscaping%20Your%20Past%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FASiCdt4qFaNADzdzw%2Fescaping-your-past%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Escaping%20Your%20Past%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FASiCdt4qFaNADzdzw%2Fescaping-your-past", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FASiCdt4qFaNADzdzw%2Fescaping-your-past", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 850, "htmlBody": "<p><strong>Followup to:</strong> <a href=\"/lw/at/sunk_cost_fallacy/\">Sunk Cost Fallacy</a></p>\n<p><strong>Related to:</strong>&nbsp;<a href=\"http://www.overcomingbias.com/2008/07/rebelling-withi.html\">Rebelling Against Nature</a>,&nbsp;<a href=\"http://www.overcomingbias.com/2008/10/shut-up-and-do.html\">Shut Up and Do the Impossible!</a></p>\n<p><em>(expanded from <a href=\"http://www.overcomingbias.com/2008/10/open-thread.html?cid=133178107#comment-133178107\">my comment</a>)</em></p>\n<p>\"The world is weary of the past&mdash;<br />O might it die or rest at last!\"<br />&mdash; Percy Bysshe Shelley, from \"Hellas\"</p>\n<p>Probability theory and decision theory push us in opposite directions. Induction demands that you cannot forget your past; the sunk cost fallacy demands that you <em>must</em>. Let me explain.</p>\n<p>An important part of epistemic rationality is learning to be at home in a material universe. You are not a magical fount of originality and free will; you are a physical system: the same <a href=\"http://en.wikipedia.org/wiki/Physics\">laws</a> that bind the planets in their orbits, also bind <em>you</em>; the same <a href=\"http://en.wikipedia.org/wiki/Economics\">sorts</a> <a href=\"http://en.wikipedia.org/wiki/Evolutionary_psychology\">of</a> <a href=\"http://en.wikipedia.org/wiki/Ecology\">regularities</a> in these laws that govern the lives of rabbits or aphids, also govern human societies. Indeed, in the last analysis, <em>free will</em> as traditionally conceived is but a <a href=\"http://en.wikipedia.org/wiki/Compatibilism#Compatibilism\">confusion</a>&mdash;and <em>bind</em> and <em>govern</em> are <a href=\"http://www.overcomingbias.com/2008/02/words-as-hidden.html\">misleading metaphors</a> at best: what is bound as by ropes can be unbound with, say, a good knife; what is \"bound\" by \"nature\"&mdash;well, I can hardly finish the sentence, the phrasing being so absurd!</p>\n<p><a href=\"/lw/31/what_do_we_mean_by_rationality\">Epistemic rationality</a> alone might be well enough for those of us who simply&nbsp;love truth (who love&nbsp;truth<em>seeking</em>, I mean; the truth itself is usually an <a href=\"/lw/3s/rationalist_poetry_fans_unite/2qt\">abomination</a>), but some of my friends tell me there should be some sort of payoff for all this work of inference. And indeed, there should be: if you <em>know</em> how something works, you might be able to make it work better. Enter intrumental rationality, the art of doing better. We all want to better, and we all believe that we <em>can</em> do better...</p>\n<p>But we should also all know that <em>beliefs</em> require evidence.</p>\n<p>Suppose you're an employer interviewing a jobseeker for a position you have open. Examining the jobseeker's application, you see that she was expelled from four schools, was fired from her last three jobs, and was convicted of two felonies. You ask, \"Given your record, I regret having let you enter the building. Why on Earth should I hire you?\"</p>\n<p>And the jobseeker replies, \"But all those transgressions&nbsp;are in the&nbsp;<em>past</em>. <a href=\"/lw/at/sunk_cost_fallacy/\">Sunk costs</a> can't play into&nbsp;my decision theory&mdash;it would hardly be <em>helping</em> for me to go sulk in a gutter somewhere. I can only seek to maximize expected utility <em>now</em>, and right now that means working ever so hard for you, O dearest future boss! <em><a href=\"http://www.overcomingbias.com/2007/03/tsuyoku_naritai.html\">Tsuyoku naritai</a>!</em>\"</p>\n<p>And you say, \"Why should I believe you?\"</p>\n<p>And then&mdash;oh, wait. Just a moment, I've gotten my notes mixed up&mdash;oh, dear. I've been telling this scenario all wrong. You're not the employer. You're the <em>jobseeker</em>.<a id=\"more\"></a></p>\n<p>Why should you believe <em>yourself</em>? You honestly swear that you're going to change, and this is great.&nbsp;But take the <a href=\"http://www.overcomingbias.com/2007/07/beware-the-insi.html\">outside view</a>. What good have these oaths done for all the other millions who have sworn them? You might very well <a href=\"http://www.overcomingbias.com/2009/03/ill-be-different.html\">be different</a>, but in order to justifiably believe that you're different, you need to have some sort of evidence that you're different. <a href=\"http://www.overcomingbias.com/2008/07/recursive-justi.html\">It's not a special question</a>; there has to be something about your brain that is different, whether or not you can easily communicate this evidence to others with present technology. What do you have <em>besides</em> the oath? Are you doing reasearch, trying new things, keeping track of results, genuinely searching at long last for something that will actually <em>work</em>?</p>\n<p>For if you do succeed,&nbsp;it&nbsp;won't&nbsp;have been a miracle:&nbsp;you should be able to pin down at least approximately the causal factors that got you to where you are. And it has to be a <em>plausible</em> story. You won't really be able to say, \"Well, I read all these blogposts about rationality, and that's why I'm such an amazing person now.\"&nbsp;Compare: \"I read the Bible, and that's why I'm such an amazing person now.\" The words are different, but translated into math, is it really a different story? It could be. But if it is, you should be able to explain further; there has to be some coherent sequence of events that could take place in an material universe, a continuous path through spacetime that took you from there to here. If the blog helped, <em>how specifically</em>&nbsp;did it help? What&nbsp;did it cause you to <em>do</em> that you would not otherwise have done?</p>\n<p>This could be more difficult than it now&nbsp;seems in your current ignorance: <a href=\"http://www.overcomingbias.com/2008/10/lies-contagious.html\">the more you know</a> about the forces that determine you, the less room there is for magical hopes. When you have a really fantastic day, you're more likely to expect tomorrow to be like that as well if you don't know about <a href=\"http://en.wikipedia.org/wiki/Regression_toward_the_mean\">regression towards the mean</a>.</p>\n<p>I'm not trying to induce despair with this post; really, I'm not. It <em>is</em> possible to do better; I myself am doing better than I was this time last year. I just think it's important to understand exactly what doing better really involves.</p>\n<p>I feel bad blogging about rationality, given that I'm so horribly, ludicrously bad at it.&nbsp;I'm also horribly, ludicrously bad at writing.&nbsp;But it would hardly be <em>helping</em> for me to just shut up in despair&mdash;to go sulk in a gutter somewhere. I can only seek to maximize expected utility <em>now</em>, and for now, that <em>apparently</em> means writing the occasional blogpost. <em>Tsuyoku</em>&mdash;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "5f5c37ee1b5cdee568cfb117": 1, "ZzxvopS4BwLuQy42n": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ASiCdt4qFaNADzdzw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 28, "extendedScore": null, "score": 4.895086216560738e-07, "legacy": true, "legacyId": "450", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 51, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tyMdPwd8x2RygcheE", "RcZCwxFiZzE6X7nsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-23T01:37:14.442Z", "modifiedAt": null, "url": null, "title": "Go Forth and Create the Art!", "slug": "go-forth-and-create-the-art", "viewCount": null, "lastCommentedAt": "2013-05-11T07:54:29.363Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aFEsqd6ofwnkNqaXo/go-forth-and-create-the-art", "pageUrlRelative": "/posts/aFEsqd6ofwnkNqaXo/go-forth-and-create-the-art", "linkUrl": "https://www.lesswrong.com/posts/aFEsqd6ofwnkNqaXo/go-forth-and-create-the-art", "postedAtFormatted": "Thursday, April 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Go%20Forth%20and%20Create%20the%20Art!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGo%20Forth%20and%20Create%20the%20Art!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaFEsqd6ofwnkNqaXo%2Fgo-forth-and-create-the-art%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Go%20Forth%20and%20Create%20the%20Art!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaFEsqd6ofwnkNqaXo%2Fgo-forth-and-create-the-art", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaFEsqd6ofwnkNqaXo%2Fgo-forth-and-create-the-art", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1501, "htmlBody": "<p>I have said <a href=\"http://www.cs.auckland.ac.nz/~andwhay/postlist.html\">a thing or two about rationality</a>, these past months.&nbsp; I have said a thing or two about how to untangle questions that have become confused, and how to tell the difference between real reasoning and fake reasoning, and the will to become stronger that leads you to try before you flee; I have said something about doing the impossible.</p>\n<p>And these are all techniques that I developed <a href=\"/lw/bd/my_way/\">in the course of my own projects</a>&mdash;which is why there is so much about cognitive reductionism, say&mdash;and it is possible that your mileage may vary in trying to apply it yourself.&nbsp; The one's <a href=\"/lw/9v/beware_of_otheroptimizing/\">mileage may vary</a>.&nbsp; Still, those wandering about asking \"But what good is it?\" might consider rereading some of the <a href=\"http://www.cs.auckland.ac.nz/~andwhay/postlist.html\">earlier posts</a>; knowing about e.g. the conjunction fallacy and how to spot it in an argument, hardly seems esoteric.&nbsp; Understanding why <a href=\"http://www.overcomingbias.com/2007/04/knowing_about_b.html\">motivated skepticism is bad for you</a> can constitute the whole difference, I suspect, between a smart person who ends up smart and a smart person who ends up stupid.&nbsp; <a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">Affective death spirals</a> consume <em>many</em> among the unwary...</p>\n<p>Yet there is, I think, more <em>absent</em> than <em>present</em> in this \"art of rationality\"&mdash;defeating akrasia and coordinating groups are two of the deficits I feel most keenly.&nbsp; I've concentrated more heavily on epistemic rationality than instrumental rationality, in general.&nbsp; And then there's training, teaching, verification, and becoming a proper experimental science based on that.&nbsp; And if you generalize a bit further, then <em>building the Art</em> could also be taken to include issues like developing better introductory literature, developing better slogans for public relations, establishing common cause with other Enlightenment subtasks, analyzing and addressing the gender imbalance problem...</p>\n<p>But those small pieces of rationality that I've set out... I <em>hope</em>... just maybe...</p>\n<p>I suspect&mdash;you could even call it a guess&mdash;that there is a <em>barrier to getting started,</em> in this matter of rationality.&nbsp; Where by default, in the beginning, you don't have enough to build on.&nbsp; Indeed so little that you don't have a clue that more exists, that there is an Art to be found.&nbsp; And if you do begin to <a href=\"/lw/2c/a_sense_that_more_is_possible/\">sense that more is possible</a>&mdash;then you may just <em>instantaneously </em>go wrong.&nbsp; As David Stove observes&mdash;I'm not going to link it, because it deserves its own post&mdash;most \"great thinkers\" in philosophy, e.g. Hegel, are properly objects of pity.&nbsp; That's what happens by default to anyone who sets out to develop the art of thinking; they develop fake answers.<a id=\"more\"></a></p>\n<p>When you try to develop part of the human art of thinking... then you are doing something <em>not too dissimilar</em> to what I was doing over in Artificial Intelligence.&nbsp; You will be tempted by fake explanations of the mind, fake accounts of causality, mysterious holy words, and the amazing idea that solves everything.</p>\n<p>It's not that the particular, epistemic, fake-detecting methods that I use, are so good for every <em>particular</em> problem; but they seem like they might be helpful for discriminating good and bad <em>systems of thinking.</em></p>\n<p>I hope that someone who learns the part of the Art that I've set down here, will not <em>instantaneously </em>and <em>automatically</em> go wrong, if they start asking themselves, \"How should people think, in order to solve new problem X that I'm working on?\"&nbsp; They will not immediately run away; they will not just make stuff up at random; they may be moved to consult the literature in experimental psychology; they will not automatically go into an <a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">affective death spiral</a> around their Brilliant Idea; they will have some idea of what distinguishes a <a href=\"http://www.overcomingbias.com/2007/08/fake-explanatio.html\">fake explanation</a> from a real one.&nbsp; They will get a saving throw.</p>\n<p>It's this sort of barrier, <em>perhaps,</em> which prevents people from <em>beginning</em> to develop an art of rationality, if they are not already rational.</p>\n<p>And so instead they... go off and invent Freudian psychoanalysis.&nbsp; Or a new religion.&nbsp; Or something.&nbsp; That's what happens by <em>default</em>, when people start thinking about thinking.</p>\n<p>I hope that the part of the Art I have set down, as incomplete as it may be, can surpass that preliminary barrier&mdash;give people a base to build on; give them an idea that an Art exists, and somewhat of how it ought to be developed; and give them at least a <em>saving throw</em> before they <em>instantaneously</em> go astray.</p>\n<p>That's my dream&mdash;that this highly specialized-seeming art of answering confused questions, may be some of what is needed, in the very beginning, <em>to go and complete the rest.</em></p>\n<p>A task which I am leaving to <em>you</em>.&nbsp; Probably, anyway.&nbsp; I make no promises as to where my attention may turn in the future.&nbsp; But y'know, there <em>are</em> certain other things I need to do.&nbsp; Even if I develop yet more Art by accident, it may be that I will not have the time to write any of it up.</p>\n<p>Beyond all that I have said of fake answers and traps, there are two things I would like you to keep in mind.</p>\n<p>The first&mdash;that I drew on multiple sources to create my Art.&nbsp; I read many different authors, many different experiments, used analogies from many different fields.&nbsp; <em>You </em>will need to draw on multiple sources to create <em>your</em> portion of the Art.&nbsp; You should not be getting all your rationality from one author&mdash;though there might be, perhaps, a certain centralized website, where you went to post the links and papers that struck you as really important.&nbsp; And a maturing Art will need to draw from multiple sources.&nbsp; To the best of my knowledge there is <em>no</em> true science that draws its strength from only one person.&nbsp; To the best of my knowledge that is <em>strictly</em> an idiom of cults.&nbsp; A true science may have its heroes, it may even have its lonely defiant heroes, but <em>it will have more than one.</em></p>\n<p>The second&mdash;that I created my Art in the course of <em>trying to do some particular thing</em> which animated all my efforts.&nbsp; Maybe I'm being too idealistic&mdash;maybe thinking too much of the way the world <em>should</em> work&mdash;but even so, I somewhat suspect that you couldn't develop the Art <em>just</em> by sitting around thinking to yourself, \"Now how can I fight that akrasia thingy?\"&nbsp; You'd develop the rest of the Art in the course of trying to <em>do something</em>.&nbsp; Maybe even&mdash;if I'm not overgeneralizing from my own history&mdash;some task difficult enough to strain and break your old understanding and force you to reinvent a few things.&nbsp; But maybe I'm wrong, and the next leg of the work will be done by direct, specific investigation of \"rationality\", without any need of a specific application considered more important.</p>\n<p>My previous attempt to describe this principle in terms of respect bounded by a secret identity, was <a href=\"/lw/9c/mandatory_secret_identities/\">roundly rejected</a> by my audience.&nbsp; Maybe \"leave the house\" would be more appropriate?&nbsp; It <em>sounds</em> to me like a really good, healthy idea.&nbsp; Still&mdash;perhaps I am deceived.&nbsp; We shall see where the next pieces of the Art do, in fact, come from.</p>\n<p>I have striven for a long time now to convey, pass on, share a piece of the strange thing I touched, which seems to me so precious.&nbsp; And I'm not sure that I ever said the central rhythm into words.&nbsp; Maybe you can find it by listening to the notes.&nbsp; I can say these words but not the rule that generates them, or the rule behind the rule; one can only hope that by <em>using</em> the ideas, perhaps, similar machinery might be born inside you.&nbsp; Remember that <em>all </em>human efforts at learning arcana, slide by default into <a href=\"http://www.overcomingbias.com/2007/08/guessing-the-te.html\">passwords</a>, <a href=\"http://www.overcomingbias.com/2007/12/affective-death.html\">hymns</a>, and <a href=\"http://www.overcomingbias.com/2007/07/making-beliefs-.html\">floating assertions</a>.</p>\n<p>I have striven for a long time now to convey my Art.&nbsp; Mostly without success, before this present effort.&nbsp; Earlier I made efforts only in passing, and got, perhaps, as much success as I deserved.&nbsp; Like throwing pebbles in a pond, that generate a few ripples, and then fade away...&nbsp; This time I put some back into it, and heaved a large rock.&nbsp; Time will tell if it was large enough&mdash;if I really <em>disturbed</em> anyone deeply enough that the waves of the impact will continue under their own motion.&nbsp; Time will tell if I have created anything that moves under its own power.</p>\n<p>(Not to mention that&mdash;I hope&mdash;the thing with the karma will stop the <a href=\"/lw/c1/wellkept_gardens_die_by_pacifism/\">slide into virtual entropy</a> that has destroyed every community I tried to build earlier as soon as I tried to pull back my attention a little.)</p>\n<p>My last essay on having a secret identity was not well-received, so let me try again:&nbsp; I want people to go forth, but also to return.&nbsp; Or maybe even to go forth and stay simultaneously, because this is the Internet and we can get away with that sort of thing; I've learned some interesting things on Less Wrong, lately, and if continuing motivation over years is any sort of problem, talking to others (or even <em>seeing</em> that others are also trying) does often help.</p>\n<p>But at any rate, if I have affected you at all, then I hope you will go forth and confront challenges, and achieve somewhere beyond your armchair, and create new Art; and then, remembering whence you came, radio back to tell others what you learned.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "izp6eeJJEg9v5zcur": 9, "zv7v2ziqexSn5iS9v": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aFEsqd6ofwnkNqaXo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 68, "baseScore": 67, "extendedScore": null, "score": 0.000102, "legacy": true, "legacyId": "436", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": "Rationality: A-Z", "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "", "canonicalPrevPostSlug": "the-sin-of-underconfidence", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FBgozHEv7J72NCEPB", "6NvbSwuSAooQxxf7f", "Nu3wa6npK4Ry66vFp", "gBewgmzcEiks2XdoQ", "tscc3e5eujrsEeFN4"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2009-04-23T01:37:14.442Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-23T14:54:10.191Z", "modifiedAt": null, "url": null, "title": "Fix it and tell us what you did", "slug": "fix-it-and-tell-us-what-you-did", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:39.362Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JulianMorrison", "createdAt": "2009-02-27T12:57:27.471Z", "isAdmin": false, "displayName": "JulianMorrison"}, "userId": "CeZ67D5YxAKemKhYL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N75n9scjdvvvMN627/fix-it-and-tell-us-what-you-did", "pageUrlRelative": "/posts/N75n9scjdvvvMN627/fix-it-and-tell-us-what-you-did", "linkUrl": "https://www.lesswrong.com/posts/N75n9scjdvvvMN627/fix-it-and-tell-us-what-you-did", "postedAtFormatted": "Thursday, April 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fix%20it%20and%20tell%20us%20what%20you%20did&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFix%20it%20and%20tell%20us%20what%20you%20did%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN75n9scjdvvvMN627%2Ffix-it-and-tell-us-what-you-did%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fix%20it%20and%20tell%20us%20what%20you%20did%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN75n9scjdvvvMN627%2Ffix-it-and-tell-us-what-you-did", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN75n9scjdvvvMN627%2Ffix-it-and-tell-us-what-you-did", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<div id=\"body_t1_999\" class=\"comment-content\">\n<div class=\"md\">\n<p>The main danger for LW is that it could become rationalist-porn for daydreamers.</p>\n<p>I suggest a pattern of counterattack:</p>\n<ol>\n<li>\n<p>Find a nonrational aspect of your nature that is hindering you right now.</p>\n</li>\n<li>\n<p>Determine privately to fix it.</p>\n</li>\n<li>\n<p>Set a short deadline. Do the necessary work.</p>\n</li>\n<li>\n<p>Write it up on LW at the deadline. <em>Whether or not it worked.</em></p>\n</li>\n</ol>(This used to be a comment, <a href=\"/lw/c4/go_forth_and_create_the_art/999\">here</a>.)</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 2, "2wjPMY34by2gXEXA2": 2, "fkABsGCJZ6y9qConW": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N75n9scjdvvvMN627", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 47, "extendedScore": null, "score": 0.00012, "legacy": true, "legacyId": "456", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-23T19:07:48.215Z", "modifiedAt": null, "url": null, "title": "This Didn't Have To Happen", "slug": "this-didn-t-have-to-happen", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.956Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oNeE7jcHnLL2Gg2vW/this-didn-t-have-to-happen", "pageUrlRelative": "/posts/oNeE7jcHnLL2Gg2vW/this-didn-t-have-to-happen", "linkUrl": "https://www.lesswrong.com/posts/oNeE7jcHnLL2Gg2vW/this-didn-t-have-to-happen", "postedAtFormatted": "Thursday, April 23rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20This%20Didn't%20Have%20To%20Happen&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThis%20Didn't%20Have%20To%20Happen%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoNeE7jcHnLL2Gg2vW%2Fthis-didn-t-have-to-happen%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=This%20Didn't%20Have%20To%20Happen%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoNeE7jcHnLL2Gg2vW%2Fthis-didn-t-have-to-happen", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoNeE7jcHnLL2Gg2vW%2Fthis-didn-t-have-to-happen", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 86, "htmlBody": "<p>My girlfriend/SO's grandfather died last night, running on a treadmill when his heart gave out.</p>\n<p>He wasn't signed up for <a href=\"http://www.overcomingbias.com/2008/12/you-only-live-twice.html\">cryonics</a>, of course.&nbsp; She tried to convince him, and I tried myself a little the one time I met her grandparents.</p>\n<p>\"This didn't have to happen.&nbsp; Fucking religion.\"</p>\n<p>That's what my girlfriend said.</p>\n<p>I asked her if I could share that with you, and she said yes.</p>\n<p>Just so that we're clear that all the wonderful emotional benefits of self-delusion come with a price, and the price isn't just to you.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E9ihK6bA9YKkmJs2f": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oNeE7jcHnLL2Gg2vW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 57, "baseScore": 27, "extendedScore": null, "score": 4.897035147492428e-07, "legacy": true, "legacyId": "457", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 189, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-24T04:21:34.312Z", "modifiedAt": null, "url": null, "title": "Just a bit of humor...", "slug": "just-a-bit-of-humor", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:37.099Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SzZKTNzexDuAGHa9a/just-a-bit-of-humor", "pageUrlRelative": "/posts/SzZKTNzexDuAGHa9a/just-a-bit-of-humor", "linkUrl": "https://www.lesswrong.com/posts/SzZKTNzexDuAGHa9a/just-a-bit-of-humor", "postedAtFormatted": "Friday, April 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Just%20a%20bit%20of%20humor...&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJust%20a%20bit%20of%20humor...%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzZKTNzexDuAGHa9a%2Fjust-a-bit-of-humor%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Just%20a%20bit%20of%20humor...%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzZKTNzexDuAGHa9a%2Fjust-a-bit-of-humor", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzZKTNzexDuAGHa9a%2Fjust-a-bit-of-humor", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 7, "htmlBody": "<p><a href=\"http://www.sexdrugsandjunecleaver.com/2008/07/14/green-bags/\"><img title=\"And people are worried about androids...\" src=\"http://www.nerdcomics.com/sdjc/wp-content/uploads/2008/07/tote-bag.gif\" alt=\"\" width=\"600\" height=\"934\" /></a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hNFdS3rRiYgqqD8aM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SzZKTNzexDuAGHa9a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": -8, "extendedScore": null, "score": -9e-06, "legacy": true, "legacyId": "459", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-24T23:49:28.000Z", "modifiedAt": null, "url": null, "title": "Less Wrong: Progress Report", "slug": "less-wrong-progress-report", "viewCount": null, "lastCommentedAt": "2017-06-17T03:51:47.455Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5mRQdFJNWC6PDkR9r/less-wrong-progress-report", "pageUrlRelative": "/posts/5mRQdFJNWC6PDkR9r/less-wrong-progress-report", "linkUrl": "https://www.lesswrong.com/posts/5mRQdFJNWC6PDkR9r/less-wrong-progress-report", "postedAtFormatted": "Friday, April 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%3A%20Progress%20Report&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%3A%20Progress%20Report%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5mRQdFJNWC6PDkR9r%2Fless-wrong-progress-report%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%3A%20Progress%20Report%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5mRQdFJNWC6PDkR9r%2Fless-wrong-progress-report", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5mRQdFJNWC6PDkR9r%2Fless-wrong-progress-report", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 614, "htmlBody": "<p><a href=\"http://lesswrong.com/\">Less Wrong</a> is emerging from beta as bugs continue to get fixed.&#0160; This is an open-source project, and if any Python-fluent programmers are willing to <a href=\"http://lesswrong.com/lw/1t/wanted_python_open_source_volunteers/\">contribute a day or two of work</a>, more would get done faster.</p><p>The character of the new site is becoming clear.&#0160; The <a href=\"http://lesswrong.com/comments/\">pace of commenting</a> is higher; the threaded comments encourage short replies and continuing conversations.&#0160; The <a href=\"http://lesswrong.com/recentposts\">pace of posting</a> exceeds my fondest hopes - apparently <em>not </em>being able to post automatically on OB was a much greater barrier to potential contributors than I realized.</p><p>We&#39;ve had 12,428 comments so far on 113 articles, 100 of them posted since contributing was enabled for all users over 20 karma on March 5th.</p><p>Browsing to the <a href=\"http://lesswrong.com/top?t=all\">Top Scoring articles</a> on <em>Less Wrong</em> will give you an idea of how things are developing.&#0160; A quick view of all posts can be found <a href=\"http://lesswrong.com/recentposts\">here</a>, with the current top scorer being &quot;<a href=\"http://lesswrong.com/lw/4e/cached_selves/\">Cached Selves</a>&quot; by Salamon and Rayhawk, followed by &quot;<a href=\"http://lesswrong.com/lw/36/rational_me_or_we/\">Rational Me or We?</a>&quot; by Hanson.&#0160; If this looks like a blog you like, <strong>go ahead and add it to your blog roll</strong> now, please!</p><ul>\n<li><a href=\"http://lesswrong.com/user/Yvain/submitted/\">Yvain</a> has emerged as a prolific and highly upvoted contributor with too many excellent posts to mention, but <a href=\"http://lesswrong.com/lw/20/the_apologist_and_the_revolutionary/\">The Apologist and the Revolutionary</a> (on brain damage and rationalization) and <a href=\"http://lesswrong.com/lw/2k/the_least_convenient_possible_world/\">The Least Convenient Possible World</a> (an exercise in <span style=\"font-style: italic;\"></span><em>not</em> avoiding painful questions) are two places to start.</li>\n<li>Our most highly commented thread was <a href=\"http://lesswrong.com/user/And/\">And</a>&#39;s <a href=\"http://lesswrong.com/lw/2l/closet_survey_1/\">Closet survey #1:&#0160; What do you believe that most people on this site don&#39;t?</a> with 314 comments.</li>\n<li><a href=\"http://lesswrong.com/user/Johnicholas/submitted/\">Johnicholas</a> brings us <a href=\"http://lesswrong.com/lw/z/information_cascades/\">Information Cascades</a> showing how taking other people&#39;s ratings into account in your own vote vastly decreases the information content...</li>\n<li>...which inspired <a href=\"http://lesswrong.com/user/Marcello/\">Marcello</a> to build the <a href=\"http://lesswrong.com/lw/1s/lesswrong_antikibitzer_hides_comment_authors_and/\">anti-kibitzer Firefox extension</a> that hides comment authors and vote counts.&#0160; (We&#39;d like to integrate these sorts of features into the site, but we need more Python programmers!)</li>\n<li><a href=\"http://lesswrong.com/lw/bn/twotier_rationalism/\">Alicorn</a> observes that systems of rationality must have two tiers: an ideal tier, and a tier that can actually be implemented (analyzing consequentialism as an example).<br />\n</li>\n<li><a href=\"http://lesswrong.com/user/Kaj_Sotala/\">Kaj_Sotala</a> asks whether <a href=\"http://lesswrong.com/lw/14/does_blind_review_slow_down_science/\">blind review slows down science</a> by preventing old scientists from championing new ideas.</li>\n<li><a href=\"http://lesswrong.com/user/MBlume/submitted/\">MBlume</a> asks what resources are available for <a href=\"http://lesswrong.com/lw/25/on_the_care_and_feeding_of_young_rationalists/\">raising young rationalists</a>.</li>\n<li><a href=\"http://lesswrong.com/user/jimrandomh/\">Jimrandomh</a> notes that <a href=\"http://lesswrong.com/lw/3y/support_that_sounds_like_dissent/\">support can sound like dissent</a>, creating a false picture of the overall reaction, and suggests prefixing &quot;I agree with your conclusion, but...&quot;</li>\n</ul>\n<a id=\"more\"></a>\n<ul>\n<li><a href=\"http://lesswrong.com/user/steven0461/\">Steven0461</a> on &quot;<a href=\"http://lesswrong.com/lw/1p/the_wrath_of_kahneman/\">The Wrath of Kahneman</a>&quot;</li>\n<li><a href=\"http://lesswrong.com/user/Z_M_Davis/\">Z_M_Davis</a> on &quot;<a href=\"http://lesswrong.com/lw/1i/its_the_same_five_dollars/\">It&#39;s the Same Five Dollars!</a>&quot;</li>\n<li><a href=\"http://lesswrong.com/user/Vladimir_Nesov/\">Vladimir_Nesov</a> on &quot;<a href=\"http://lesswrong.com/lw/3l/counterfactual_mugging/\">Counterfactual Mugging</a>&quot;</li>\n<li><a href=\"http://lesswrong.com/user/thomblake/\">Thomblake</a> on &quot;<a href=\"http://lesswrong.com/lw/2h/is_santa_real/\">Is Santa Real?</a>&quot;</li>\n<li><a href=\"http://lesswrong.com/user/PhilGoetz/\">Phil Goetz</a> on &quot;<a href=\"http://lesswrong.com/lw/2o/soulless_morality/\">Soulless Morality</a>&quot;</li>\n<li><a href=\"http://lesswrong.com/user/CarlShulman/\">Carl Shulman</a> warns us, &quot;<a href=\"http://lesswrong.com/lw/4b/dont_revere_the_bearer_of_good_info/\">Don&#39;t Revere The Bearer of Good Info</a>&quot;</li>\n<li><a href=\"http://lesswrong.com/user/patrissimo/\">Patri Friedman</a> on &quot;<a href=\"http://lesswrong.com/lw/41/individual_rationality_is_a_matter_of_life_and/\">Individual Rationality is a Matter of Life and Death</a>&quot;</li>\n<li>...and <a href=\"http://lesswrong.com/recentposts\">the list goes on</a>.&#0160; And any number of highly intelligent comments are being upvoted to the prominence they deserve.</li>\n</ul>\n<p>It might be just my imagination or my prior hopes, but it looks to me like the threaded, rated, and sorted comments create a completely different experience of reading a post - the first comment you encounter is going to be something highly intelligent, and then right away, you&#39;re going to see the most intelligent reply and a well-sorted discussion all in one place.&#0160; Much more of the action is in the comments.</p><p>The karma system is giving me valuable (if not always pleasant) feedback about which of my posts and comments my readers actually like.&#0160; I shall try not to be too influenced by this.</p><p>An on-site <a href=\"http://lesswrong.com/lw/cg/proposal_use_the_wiki_for_concepts/\">wiki</a> is on the way, and meanwhile there&#39;s a <a href=\"http://lesswrong.wikia.com/wiki/LessWrong_Wiki\">temporary Wiki hosted at Wikia</a>, currently with 163 articles.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5mRQdFJNWC6PDkR9r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 5e-06, "legacy": true, "legacyId": "1263", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": "postCommentsOld", "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["J2sr4tdC4ThrbJRR3", "BHYBdijDcAKQ6e45Z", "w9kwayt5SWqBQe8Nx", "ZiQqsgGX6a42Sfpii", "neQ7eXuaXpiYw7SBy", "gPdM553fhdZuNmDxn", "DNQw596nPCX4x7xT9", "XbfdLQrAWTRfpggRM", "PL7KpiDdJnh6j5LZS", "fsSoAMsntpsmrEC6a", "SWraogEDJ6gocpvwa", "vHCetv8tx6LbRtfyc", "YGPzzqqpYcAoyzF4d", "JZRtfjG48xNR3GKeo", "mg6jDEuQEjBGtibX7", "iQRA6mMrxrs3xPhGz", "E5QXf3tCeE7fZGq4t", "tSgcorrgBnrCH8nL3", "WzMJRQBN3ryxiAbhi", "cDQFK7tPDo9H4nPSE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-24T23:53:51.129Z", "modifiedAt": null, "url": null, "title": "What's in a name? That which we call a rationalist\u2026", "slug": "what-s-in-a-name-that-which-we-call-a-rationalist", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:02.548Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "badger", "createdAt": "2009-02-27T06:50:31.697Z", "isAdmin": false, "displayName": "badger"}, "userId": "w3rzcs3GwLDqgRpwo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tGPeyg2GXFvtXH8XN/what-s-in-a-name-that-which-we-call-a-rationalist", "pageUrlRelative": "/posts/tGPeyg2GXFvtXH8XN/what-s-in-a-name-that-which-we-call-a-rationalist", "linkUrl": "https://www.lesswrong.com/posts/tGPeyg2GXFvtXH8XN/what-s-in-a-name-that-which-we-call-a-rationalist", "postedAtFormatted": "Friday, April 24th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What's%20in%20a%20name%3F%20That%20which%20we%20call%20a%20rationalist%E2%80%A6&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat's%20in%20a%20name%3F%20That%20which%20we%20call%20a%20rationalist%E2%80%A6%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtGPeyg2GXFvtXH8XN%2Fwhat-s-in-a-name-that-which-we-call-a-rationalist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What's%20in%20a%20name%3F%20That%20which%20we%20call%20a%20rationalist%E2%80%A6%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtGPeyg2GXFvtXH8XN%2Fwhat-s-in-a-name-that-which-we-call-a-rationalist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtGPeyg2GXFvtXH8XN%2Fwhat-s-in-a-name-that-which-we-call-a-rationalist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 165, "htmlBody": "<p>Who are we? I've heard a couple of comments about what Less Wrong members should be called lately. \"Rationalist\" is the word most commonly used, although use of that term might presume we are something we are not. \"Aspiring rationalist\" avoids that problem, but is awkward to use casually. Something unique to this site might insulate us from the rest of the world, however.&nbsp;</p>\n<p>What are your suggestions? Please make one suggestion per comment to facilitate voting.</p>\n<p><strong>Update:</strong>&nbsp;I think \"Less Wrong reader\" works well for referring to members of this site as members of this site, but what are we trying to be in a broader sense? Maybe my intent in asking for suggestions was unclear. Is there a word that could replace \"rationalist\" in the following titles:</p>\n<p>\n<ul>\n<li><a href=\"/lw/2/tell_your_rationalist_origin_story/\">Tell Your Rationalist Story</a></li>\n<li><a href=\"/lw/1l/the_mystery_of_the_haunted_rationalist/\">The Mystery of the Haunted Rationalist</a></li>\n<li><a href=\"/lw/77/selecting_rationalist_groups/\">Selecting Rationalist Groups</a></li>\n<li><a href=\"/lw/3s/rationalist_poetry_fans_unite/\">Rationalist Poetry Fans, Unite!</a></li>\n<li><a href=\"/lw/39/tarski_statements_as_rationalist_exercise/\">Tarski Statements as Rationalist Exercise</a></li>\n</ul>\n<div>or is \"rationalist\" just the least bad term?</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "aa3Qg7Qrp9LM7QMaz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tGPeyg2GXFvtXH8XN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 7, "extendedScore": null, "score": 4.899600115642061e-07, "legacy": true, "legacyId": "465", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 92, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BHMBBFupzb4s8utts", "mja6jZ6k9gAwki9Nu", "ZEj9ATpv3P22LSmnC", "iNCg6mjw584r9BWZK", "qJiSvhGyvbgwQcNXn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T02:33:00.000Z", "modifiedAt": null, "url": null, "title": "A puzzle", "slug": "a-puzzle", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:08.809Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Thomas", "createdAt": "2009-03-02T17:47:09.607Z", "isAdmin": false, "displayName": "Thomas"}, "userId": "GrAKeuxT4e9AKyHdE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RyWLr5e68TGDMdP4h/a-puzzle", "pageUrlRelative": "/posts/RyWLr5e68TGDMdP4h/a-puzzle", "linkUrl": "https://www.lesswrong.com/posts/RyWLr5e68TGDMdP4h/a-puzzle", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20puzzle&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20puzzle%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRyWLr5e68TGDMdP4h%2Fa-puzzle%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20puzzle%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRyWLr5e68TGDMdP4h%2Fa-puzzle", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRyWLr5e68TGDMdP4h%2Fa-puzzle", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p>What do these things have in common?\u00a0Nerves, emotions, morality, prices.</p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/meteuphoric.wordpress.com/2021/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/meteuphoric.wordpress.com/2021/\" /></a> <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/godelicious/meteuphoric.wordpress.com/2021/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/delicious/meteuphoric.wordpress.com/2021/\" /></a> <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gofacebook/meteuphoric.wordpress.com/2021/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/facebook/meteuphoric.wordpress.com/2021/\" /></a> <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gotwitter/meteuphoric.wordpress.com/2021/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/twitter/meteuphoric.wordpress.com/2021/\" /></a> <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gostumble/meteuphoric.wordpress.com/2021/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/stumble/meteuphoric.wordpress.com/2021/\" /></a> <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/godigg/meteuphoric.wordpress.com/2021/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/digg/meteuphoric.wordpress.com/2021/\" /></a> <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/goreddit/meteuphoric.wordpress.com/2021/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/reddit/meteuphoric.wordpress.com/2021/\" /></a> <img alt=\"\" border=\"0\" src=\"https://pixel.wp.com/b.gif?host=meteuphoric.wordpress.com&#038;blog=8643840&#038;post=2021&#038;subd=meteuphoric&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"6nS8oYmSMuFMaiowF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RyWLr5e68TGDMdP4h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": -11, "extendedScore": null, "score": -1.1e-05, "legacy": true, "legacyId": "15201", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T02:37:31.992Z", "modifiedAt": null, "url": null, "title": "Rational Groups Kick Ass", "slug": "rational-groups-kick-ass", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:45.336Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "talisman", "createdAt": "2009-03-05T23:30:16.521Z", "isAdmin": false, "displayName": "talisman"}, "userId": "SXxD8wMPMJZZEdNZe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gj7Z7Zj6SMkrEaN8J/rational-groups-kick-ass", "pageUrlRelative": "/posts/gj7Z7Zj6SMkrEaN8J/rational-groups-kick-ass", "linkUrl": "https://www.lesswrong.com/posts/gj7Z7Zj6SMkrEaN8J/rational-groups-kick-ass", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rational%20Groups%20Kick%20Ass&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARational%20Groups%20Kick%20Ass%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgj7Z7Zj6SMkrEaN8J%2Frational-groups-kick-ass%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rational%20Groups%20Kick%20Ass%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgj7Z7Zj6SMkrEaN8J%2Frational-groups-kick-ass", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgj7Z7Zj6SMkrEaN8J%2Frational-groups-kick-ass", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 570, "htmlBody": "<p>Reply to: <a href=\"/lw/9p/rationality_its_not_that_great/\">Extreme Rationality: It's Not That Great<br /></a>Belaboring of: <a href=\"/lw/36/rational_me_or_we/\">Rational Me Or We?<br /></a>Related to: <a href=\"/lw/2c/a_sense_that_more_is_possible/\">A Sense That More Is Possible</a></p>\n<p>The success of Yvain's <a href=\"/lw/9p/rationality_its_not_that_great/\">post</a> threw me off completely.&nbsp; My experience has been opposite to what he describes: x-rationality, which I've been working on since the mid-to-late nineties, has been centrally important to successses I've had in business and family life.&nbsp; Yet the LessWrong community, which I greatly respect, broadly endorsed Yvain's argument that:</p>\n<blockquote>\n<p>There seems to me to be approximately zero empirical evidence that x-rationality has a large effect on your practical success, and some anecdotal empirical evidence against it.</p>\n</blockquote>\n<p>So that left me pondering what's different in my experience.&nbsp; I've been working on these things longer than most, and am more skilled than many, but that seemed unlikely to be the key.</p>\n<p>The difference, I now think, is that I've been lucky enough to spend huge amounts of time in deeply rationalist organizations and groups--the companies I've worked at, my marriage, my circle of friends.</p>\n<p>And rational groups kick ass.</p>\n<p>An individual can <a href=\"http://www.overcomingbias.com/2008/06/thou-art-physic.html\">unpack free will</a> or figure out that <a href=\"http://www.overcomingbias.com/2008/06/the-quantum-phy.html\">the Copenhagen interpretation is nonsense</a>.&nbsp; But I agree with Yvain that in a lonely rationalist's individual life, the extra oomph of x-rationality may well be drowned in the noise of all the other factors of success and failure.</p>\n<p>But groups!&nbsp; Groups magnify the importance of rational thinking tremendously:</p>\n<ul>\n<li>Whereas a rational individual is still limited by her individual intelligence, creativity, and charisma, a rational group can promote the <em>single best</em> idea, leader, or method out of hundreds or thousands or millions.&nbsp; </li>\n<li>Groups have powerful feedback loops; small dysfunctions can grow into disaster by repeated reflection, and <a href=\"http://findarticles.com/p/articles/mi_m0KJI/is_3_117/ai_n13596011/\">small positives</a> can cascade into massive success.</li>\n<li>In a particularly powerful feedback process, groups can <a href=\"http://economics.gmu.edu/\">select for and promote</a> exceptional members.</li>\n<li>Groups can establish rules/norms/patterns that 1) directly improve members and 2) <a href=\"http://www.usconstitution.net/const.html\">counteract members' weaknesses</a>.</li>\n<li>Groups often operate in spaces where small differences are crucial.&nbsp; Companies with <em>slightly</em> better risk management are currently preparing to dominate the financial space.&nbsp; Countries with <em>slightly</em> more rational systems have generated the 0.5% of extra annual growth that leads, over centuries, to dramatically improved ways of life.&nbsp; Even in family life, a bit more rationality can easily be the difference between gradual divergence and gradual convergence.</li>\n</ul>\n<p>And we're not even <em>talking</em> about the extra power of x-rationality.&nbsp; Imagine a couple that truly understood <a href=\"http://www.overcomingbias.com/2006/12/agreeing_to_agr.html\">Aumann</a>, a company that grokked the <a href=\"http://www.overcomingbias.com/2007/09/planning-fallac.html\">Planning Fallacy</a>, a polity that consistently tried <a href=\"http://www.overcomingbias.com/2007/05/policy_tugowar.html\">Pulling the Rope Sideways</a>.</p>\n<p>When it comes to groups--sized from two to a billion--Yvain couldn't be more wrong.<a id=\"more\"></a></p>\n<p><strong>Update:</strong>&nbsp; Orthonormal <a href=\"/lw/cy/rational_groups_kick_ass/9l4\">points out</a> that I don't provide many concrete examples; I only link to three above.&nbsp; I'll try to put more here as I think of them:</p>\n<ul>\n<li>In <a href=\"http://www.amazon.com/Better-Surgeons-Performance-Atul-Gawande/dp/0805082115\">Better</a>, Atul Gawande talks about ways in which some groups of doctors have dramatically improved by becoming more group-rational, including OB standbys like keeping score and having sensitive discussions privately (and thus more openly).</li>\n<li>Google seems like an extremely rational place for a public company.&nbsp; Two strong signals are that they are <a href=\"http://news.cnet.com/google-designer-leaves-blaming-data-centrism/\">extremely data-driven</a> and have <a href=\"http://googleblog.blogspot.com/2005/09/putting-crowd-wisdom-to-work.html\">used prediction markets</a>.&nbsp; To be painfully clear, <em>I'm not claiming that Google's success is due to the use of prediction markets, </em>merely that these datapoints help demonstrate Google's overall rationality.</li>\n<li>As <a href=\"/lw/cy/rational_groups_kick_ass/9nq\">AlanCrowe</a> points out in the comments, Warren Buffett and Charlie Munger have a rationalist approach.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zv7v2ziqexSn5iS9v": 1, "Ng8Gice9KNkncxqcj": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gj7Z7Zj6SMkrEaN8J", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 32, "extendedScore": null, "score": 4.899842723930349e-07, "legacy": true, "legacyId": "466", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LgavAYtzFQZKg95WC", "w9kwayt5SWqBQe8Nx", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T07:41:41.482Z", "modifiedAt": null, "url": null, "title": "Instrumental vs. Epistemic -- A Bardic Perspective", "slug": "instrumental-vs-epistemic-a-bardic-perspective", "viewCount": null, "lastCommentedAt": "2021-02-06T17:22:51.368Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AGP9PwnhQcuYMKyMm/instrumental-vs-epistemic-a-bardic-perspective", "pageUrlRelative": "/posts/AGP9PwnhQcuYMKyMm/instrumental-vs-epistemic-a-bardic-perspective", "linkUrl": "https://www.lesswrong.com/posts/AGP9PwnhQcuYMKyMm/instrumental-vs-epistemic-a-bardic-perspective", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Instrumental%20vs.%20Epistemic%20--%20A%20Bardic%20Perspective&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInstrumental%20vs.%20Epistemic%20--%20A%20Bardic%20Perspective%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGP9PwnhQcuYMKyMm%2Finstrumental-vs-epistemic-a-bardic-perspective%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Instrumental%20vs.%20Epistemic%20--%20A%20Bardic%20Perspective%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGP9PwnhQcuYMKyMm%2Finstrumental-vs-epistemic-a-bardic-perspective", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGP9PwnhQcuYMKyMm%2Finstrumental-vs-epistemic-a-bardic-perspective", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 846, "htmlBody": "<p>(This article expands upon my response to a question posed by pjeby <a href=\"/lw/b9/welcome_to_less_wrong/968?context=1#968\">here</a>)</p>\n<p>I've seen a few back-and-forths lately debating the instrumental use of epistemic irrationality -- to put the matter in very broad strokes, you'll have one commenter claiming that a particular trick for enhancing your effectiveness, your productivity, your attractiveness, <em>demands</em>&nbsp;that you embrace some belief unsupported by the evidence, while another claims that such a compromise is unacceptable, since a true art should use all available true information. As Eliezer <a href=\"/lw/7k/incremental_progress_and_the_valley/\">put it</a>:</p>\n<blockquote>\n<p>I find it hard to believe that the <em>optimally</em> motivated individual, the <em>strongest</em> entrepreneur a human being can become, is still wrapped up in a blanket of comforting overconfidence. I think they've probably thrown that blanket out the window and organized their mind a little <em>differently.</em> I find it hard to believe that the happiest we can possibly live, even in the realms of human possibility, involves a tiny awareness lurking in the corner of your mind that it's all a lie.</p>\n</blockquote>\n<p>And with this I agree -- the idea that a fully developed rational art of <em>anything</em>&nbsp;would involving pumping yourself with false data seems absurd.</p>\n<p>Still, let us say that I am entering a club, in which I would like to pick up an attractive woman. Many people&nbsp;will tell me that I must <em>believe</em> myself to be the most attractive, interesting, desirable man <a href=\"http://www.youtube.com/watch?v=lmDTSQtK20c\">in the room</a>. An outside-view examination of my life thus far, and my success with women in particular, tells me that I most certainly am <em>not</em>. What shall I do?<a id=\"more\"></a></p>\n<p>Well, the question is, <em>why</em> am I being asked to hold these odd beliefs?&nbsp; Is it because I'm going to be performing conscious calculations of expected utility, and will be more likely to select the optimal actions if I plug incorrect probabilities into the calculation? Well, no, not exactly. More likely, it's because the <a href=\"http://www.overcomingbias.com/2007/11/an-alien-god.html\">blind idiot god</a> has already <a href=\"http://www.overcomingbias.com/2009/02/the-evolutionarycognitive-boundary.html\">done the calculation for me</a>.</p>\n<p>Evolution's goals are not my own, and neither are evolution's utility calculations. Most saliently, other men are <em>no longer allowed to hit me with mastodon bones</em> if I approach women they might have liked to pursue. The trouble is, evolution has already done the calculation, using this now-faulty assumption, with the result that, if I do not see myself as dominant, my motor cortex <a href=\"http://www.mindhacks.com/blog/2009/04/taking_pride_in_your.html\">directs the movement of my body</a> and the inflection of my voice in a way which clearly signals this fact, thus avoiding a conflict. And, of course, any woman I may be pursuing can read this signal <em>just as clearly</em>. I cannot redo this calculation, any more than I can perform a fourier analysis to decide how I should form my vowels. It seems the best I can do is to fight an error with an error, and <em>imagine</em> that I am an attractive, virile, alpha male.</p>\n<p>So the question is, is this self-deception? I think it is not.</p>\n<p>In high school, I spent four happy years as a novice initiate of the <a href=\"http://en.wikipedia.org/wiki/International_Thespian_Society\">Bardic Conspiracy</a>. And of all the roles I played, my favorite by far was Iago, from Shakespeare's Othello. We were performing at a competition, and as the day went by, I would look at the people I passed, and tell myself that if I wanted, I could control any of them, that I could find the secrets to their minds, and in just a few words, utterly own any one of them. And as I thought this, completely unbidden, my whole body language changed. My gaze became cold and penetrating, my smile grew thin and predatory, the way I held my body was altered in a thousand tiny ways that I <em>would never have known </em>to order consciously.</p>\n<p>And, judging by the reactions, both of my (slightly alarmed) classmates, and of the judges, <em>it worked</em>.&nbsp;</p>\n<p>But if a researcher with a clipboard had suddenly shown up and asked my honest opinion of my ability as a manipulator of humans, I would have dropped the act, and given a reasonably well-calibrated, modest answer.</p>\n<p>Perhaps we could call this <em>soft </em>self-deception.&nbsp;I didn't so much change my explicit conscious beliefs as... <em>rehearse</em>&nbsp;beliefs I knew to be false, and allow them to seep into my unconscious.</p>\n<p>In <em>An Actor Prepares, </em>Bardic Master&nbsp;Stanislavski describes this as the use of <em>if</em>:</p>\n<blockquote>\n<p>Take into consideration also that this inner stimulus was brought about without force, and without deception. I did not tell you that there was a madman behind the door. On the contrary, by using the word <em>if </em>I frankly recognized the fact that I was offering you only a supposition. All I wanted to accomplish was to make you say what you would have done <em>if</em>&nbsp;the supposition about the madman were a real fact, leaving you to feel what anybody in the given circumstances must feel. You in turn did not force yourselves, or make yourselves accept the supposition as reality, but only as a supposition.</p>\n</blockquote>\n<p>Is this dangerous? Is this a short step down the path to the dark side?</p>\n<p>If so, there must be a parting of ways between the <a href=\"/lw/cx/whats_in_a_name_that_which_we_call_a_rationalist/9m3?context=1#9m3\">Cartographers</a> and the Bards, and I know not which way I shall go.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"SJFsFfFhE6m2ThAYJ": 2, "HXA9WxPpzZCCEwXHT": 2, "Ng8Gice9KNkncxqcj": 2, "exZi6Bing5AiM4ZQB": 2, "AHK82ypfxF45rqh9D": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AGP9PwnhQcuYMKyMm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 73, "baseScore": 85, "extendedScore": null, "score": 0.000134, "legacy": true, "legacyId": "455", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 85, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 189, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oZNXmHcdhb4m7vwsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T09:29:31.762Z", "modifiedAt": null, "url": null, "title": "Programmatic Prediction markets", "slug": "programmatic-prediction-markets", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:46.032Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "whpearson", "createdAt": "2009-02-28T00:34:00.976Z", "isAdmin": false, "displayName": "whpearson"}, "userId": "bq8qsRbPNvFihHxgi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CC5RvYaZi9MmPWuXN/programmatic-prediction-markets", "pageUrlRelative": "/posts/CC5RvYaZi9MmPWuXN/programmatic-prediction-markets", "linkUrl": "https://www.lesswrong.com/posts/CC5RvYaZi9MmPWuXN/programmatic-prediction-markets", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Programmatic%20Prediction%20markets&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProgrammatic%20Prediction%20markets%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCC5RvYaZi9MmPWuXN%2Fprogrammatic-prediction-markets%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Programmatic%20Prediction%20markets%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCC5RvYaZi9MmPWuXN%2Fprogrammatic-prediction-markets", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCC5RvYaZi9MmPWuXN%2Fprogrammatic-prediction-markets", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 526, "htmlBody": "<p>I have a problem with \"prediction markets\" as news view. They just aren't informative enough.</p>\n<p><del>If the price of oil goes down is that due to: A reduction in demand. an increase in supply, a large amount of investors finding a better investment or a large amount of investors wanting cash (due to having to pay creditors/taxes).</del></p>\n<p>I want them to tell me enough information so that I can begin trading in an informed manner. When you see the market expects rain fall on montana is 2 cm in a day, what information is this based upon? If you read about a newly created huge man made lake in the are which you expect to change the micro climate, how do you know whether the simulations people and betting using are running take this into consideration?</p>\n<p>If I don't get this information I can't trade with expectation of being able to make a profit and the market doesn't get any information that I may have that it doesn't. I could try and reverse engineer peoples climate models from the way they trade, but that is pretty hard to do. So I would like to try and lower the barrier of entry to the market by giving more information to potential players.</p>\n<p>This lack of information is due to the signals each trader sends to the market, they are binary in nature buy or sell, with the traders strategy and information she used a black box that we can't get into. <del>As potential traders we don't know if the market is taking certain information into account with the price we are shown.</del></p>\n<p>The only way I have thought of being able to get at some of the information enclosed in the black box, is to only allow programs to bid in a market. The programs would be run on the markets server&nbsp; and have acces to news sources, financial data and government reports. The programs could be stopped at any time by the trader but otherwise not communicated with or updated. So the would be trader would have to build models of the world and ways of processing the financial data.<a id=\"more\"></a></p>\n<p>How then would we get at the information? The source for each program that wanted to trade would be held in escrow and it would be released as open source code when it was withdrawn from the system. This would create a time lag, where people could profit from a better predicting system, but also allow everyone else to catch up after a certain time. There would also be some significant financial cost to starting a new bot so that people would not just start lots of one shot bots that did a single action based on their hidden knowledge.</p>\n<p>It would have the side affect of have different biases to the human market. possibly more accurate as people would have to build the bias into the program and it would be visible and open to exploitation if it became prevalent and known.</p>\n<p>I don't see this as a reality any time soon, but I would be interested if anyone else had any, more easily implementable, ideas about improving the informativeness of the markets.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"R6dqPii4cyNpuecLt": 1, "8daMDi9NEShyLqxth": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CC5RvYaZi9MmPWuXN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 7, "extendedScore": null, "score": 5e-06, "legacy": true, "legacyId": "464", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T16:22:56.720Z", "modifiedAt": null, "url": null, "title": "Cached Procrastination", "slug": "cached-procrastination", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:59.303Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5MmCYWKNnvAPWRBYL/cached-procrastination", "pageUrlRelative": "/posts/5MmCYWKNnvAPWRBYL/cached-procrastination", "linkUrl": "https://www.lesswrong.com/posts/5MmCYWKNnvAPWRBYL/cached-procrastination", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cached%20Procrastination&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACached%20Procrastination%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5MmCYWKNnvAPWRBYL%2Fcached-procrastination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cached%20Procrastination%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5MmCYWKNnvAPWRBYL%2Fcached-procrastination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5MmCYWKNnvAPWRBYL%2Fcached-procrastination", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 771, "htmlBody": "<p>I have a paper to write. Where do I start? The first time I asked this question, it was easy: just sit down and start typing. I wrote a few hundred words, then got stuck; I needed to think some more, so I took a break and did something else. Over the next few days, my thoughts on the subject settled, and I was ready to write again. So I sat down, and asked: What do I do next? Fortunately, my brain had a <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\" target=\"_self\">cached response</a> ready to answer this question: Solitaire!<br /><a id=\"more\"></a><br />So I procrastinated, and every time I asked my brain what to write, I got back an answer like \"Don't bother!\". Now a deadline's approaching, and I still don't have much written, so I sit down to write again. This time, I'm determined: using my willpower, I will not allow myself to think about anything except for the paper and its topic. So I ask again: Where do I start? (<em>Solitaire!</em>) What thoughts come to mind? <em>I should've started a week ago. Every time I think about this topic I get stuck.&nbsp; Maybe I shouldn't write this paper after all.</em> These, too, are cached thoughts, generated during previous failed attempts to get started. These thoughts are much harder to clear, both because there are more of them, because of their emotional content, but I'm determined to do so anyways; I think through all the cached thoughts, return to the original question (Where do I start?), get my text editor open, start planning a section and... Ping! I have a new e-mail to read, I get distracted, and when I return half an hour later I have to clear those same cached thoughts <em>again</em>.<br /><br />Many authors say to stop in the middle of a thought when you leave off, so that \"Where do I start?\" will always have an easy answer. This sounds like a solution, but it ignores the fact that you'll get stuck eventually, so that you <em>have</em> to stop, at a spot that won't be easy to come back to.<br /><br />In order to stop procrastinating, there are two obstacles to overcome: A question to answer, and a cached answer to clear. The question is \"What do I do first?\" and the cached answer is \"procrastinate more\". Knowing that \"procrastinate\" was a cached answer makes it easier to get past, but the original question is still a problem. Why is deciding what to do first so often difficult?<br /><br />When I'm programming, I make a long, unorded to-do list for each project, listing all of the features I plan to implement. When I finish one, I go back to the list to pick something to work on next. Sometimes, I can't decide; I just stare at the list for awhile, weighing the costs and benefits of each, until eventually something happens to distract me. Most of the items on that list are <a href=\"http://www.overcomingbias.com/2008/12/harmful-options.html\" target=\"_self\">harmful options</a>, which serve only to induce <a href=\"http://en.wikipedia.org/wiki/Analysis_paralysis\" target=\"_self\">analysis paralysis</a>. It's the same problem some people have ordering off restaurant menus, and the same solution works. Instead of considering a series of options and deciding for each whether it's good enough to settle on, choose one option as the current-best without considering it at all, and compare options against the current-best.</p>\n<p>Usually, choosing where to start, or what to do next, requires generating options, not picking one off a menu. When choosing, say, the topic of the next chapter, it's easy to convince ourselves that we'll come up with the perfect answer, if only we think about it a little more. If we take the outside view, we can see that this is probably not the case; and if we let thinking about one decision crowd out everything else, and think about it long enough without reaching an answer, then eventually we will settle on Solitaire as the best choice. When deciding <a href=\"/lw/aq/how_much_thought/\" target=\"_self\">how much thought&nbsp;</a> to apply, remember: The utility we get from thinking about a decision is the cost of deciding incorrectly times the probability that we'll change our mind from incorrect to correct, minus the probability that we'll change our mind from correct to incorrect; and the longer we have gone without changing our mind, the less likely we are to do so in the future.</p>\n<p>Procrastination is not a single problem, at least two: cached thought, and analysis paralysis, working together to stop us from getting work done. If we <a href=\"/lw/af/missed_distinctions/\" target=\"_self\">miss the distinction</a>, then any attempts to find solutions will be doomed to confusion and failure; we must recognize and address each underlying problem, separately.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dqx5k65wjFfaiJ9sQ": 2, "5f5c37ee1b5cdee568cfb0d6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5MmCYWKNnvAPWRBYL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 39, "extendedScore": null, "score": 6.6e-05, "legacy": true, "legacyId": "470", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YKSwmhGJ3pY9qobnw", "Afvk6GGfoo8mea5cb"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T18:52:21.809Z", "modifiedAt": null, "url": null, "title": "Practical Advice Backed By Deep Theories", "slug": "practical-advice-backed-by-deep-theories", "viewCount": null, "lastCommentedAt": "2017-06-17T04:36:50.489Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LqjKP255fPRY7aMzw/practical-advice-backed-by-deep-theories", "pageUrlRelative": "/posts/LqjKP255fPRY7aMzw/practical-advice-backed-by-deep-theories", "linkUrl": "https://www.lesswrong.com/posts/LqjKP255fPRY7aMzw/practical-advice-backed-by-deep-theories", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Practical%20Advice%20Backed%20By%20Deep%20Theories&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APractical%20Advice%20Backed%20By%20Deep%20Theories%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLqjKP255fPRY7aMzw%2Fpractical-advice-backed-by-deep-theories%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Practical%20Advice%20Backed%20By%20Deep%20Theories%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLqjKP255fPRY7aMzw%2Fpractical-advice-backed-by-deep-theories", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLqjKP255fPRY7aMzw%2Fpractical-advice-backed-by-deep-theories", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1097, "htmlBody": "<p>Once upon a time, Seth Roberts took a European vacation and found that <a href=\"/lw/a6/the_unfinished_mystery_of_the_shangrila_diet/\">he started losing weight while drinking unfamiliar-tasting caloric fruit juices</a>.</p>\n<p>Now suppose Roberts had not known, and never did know, anything about metabolic set points or flavor-calorie associations&mdash;all this high-falutin' scientific experimental research that had been done on rats and occasionally humans.</p>\n<p>He would have posted to his blog, \"Gosh, everyone!&nbsp; You should try these amazing fruit juices that are making me lose weight!\"&nbsp; And that would have been the end of it.&nbsp; Some people would have tried it, it would have worked <em>temporarily</em> for some of them (until the flavor-calorie association kicked in) and there never would have been a Shangri-La Diet <em>per se</em>.</p>\n<p>The existing Shangri-La Diet is visibly incomplete&mdash;for some people, like me, it doesn't seem to work, and there is no apparent reason for this or any logic permitting it.&nbsp; But the reason why as many people have benefited as they have&mdash;the reason why there was more than just one more blog post describing a trick that seemed to work for one person and didn't work for anyone else&mdash;is that Roberts <em>knew the experimental science that let him interpret what he was seeing, in terms of deep factors that actually did exist.<a id=\"more\"></a></em></p>\n<p>One of the pieces of advice on OB/LW that was frequently cited as <a href=\"/lw/9/the_most_important_thing_you_learned/\">the most important thing</a> learned, was the idea of \"<a href=\"http://www.overcomingbias.com/2007/09/the-bottom-line.html\">the bottom line</a>\"&mdash;that once a conclusion is written in your mind, it is already true or already false, already wise or already stupid, and no amount of later argument can change that except by changing the conclusion.&nbsp; And this ties directly into another oft-cited most important thing, which is the idea of \"<a href=\"http://www.overcomingbias.com/2008/02/second-law.html\">engines of cognition</a>\", minds as mapping engines that require evidence as fuel.</p>\n<p>If I had merely written one more blog post that said, \"You know, you really should be more open to changing your mind&mdash;it's pretty important&mdash;and oh yes, you should pay attention to the evidence too.\"&nbsp; And this would not have been as useful.&nbsp; Not just because it was <em>less persuasive,</em> but because the <em>actual operations</em> would have been much less clear without the explicit theory backing it up.&nbsp; What constitutes <em>evidence,</em> for example?&nbsp; Is it anything that seems like a forceful argument?&nbsp; Having an explicit probability theory and an explicit causal account of what makes reasoning effective, makes a <em>large </em>difference in the forcefulness and implementational details of the old advice to \"Keep an open mind and pay attention to the evidence.\"</p>\n<p>It is also important to realize that <em>causal theories</em> are much more likely to be true when they are picked up from a science textbook than when invented on the fly&mdash;it is very easy to invent cognitive structures that look like causal theories but are not even <a href=\"http://www.overcomingbias.com/2007/07/making-beliefs-.html\">anticipation-controlling</a>, let alone true.</p>\n<p>This is the signature style I want to convey from all those posts that entangled cognitive science experiments and probability theory and epistemology with the practical advice&mdash;that practical advice actually becomes practically more powerful if you go out and read up on cognitive science experiments, or probability theory, or even materialist epistemology, and <em>realize what you're seeing.</em>&nbsp; This is the brand that can distinguish LW from ten thousand other blogs purporting to offer advice.</p>\n<p>I could tell you, \"You know, how much you're satisfied with your food probably depends more on the quality of the food than on how much of it you eat.\"&nbsp; And you would read it and forget about it, and the impulse to finish off a whole plate would still feel just as strong.&nbsp; But if I tell you about <a href=\"http://www.overcomingbias.com/2007/05/scope_insensiti.html\">scope insensitivity</a>, and <a href=\"http://web.mit.edu/ariely/www/MIT/Papers/duration1.pdf\">duration neglect</a> and the <a href=\"http://en.wikipedia.org/wiki/Peak-end_rule\">Peak/End rule</a>, you are suddenly aware in a very concrete way, looking at your plate, that you will form almost exactly the same retrospective memory whether your portion size is large or small; you now possess a deep theory about the <em>rules</em> governing your memory, and you know that this is what the rules say.&nbsp; (You also know to save the dessert for last.)</p>\n<p>I want to hear how I can overcome akrasia&mdash;how I can have more willpower, or get more done with less mental pain.&nbsp; But there are ten thousand people purporting to give advice on this, and for the most part, it is on the level of that alternate Seth Roberts who just tells people about the amazing effects of drinking fruit juice.&nbsp; Or actually, somewhat worse than that&mdash;it's people trying to describe internal mental levers that they pulled, for which there are no standard words, and which they do not actually know how to point to.&nbsp; See also the <a href=\"http://www.overcomingbias.com/2007/10/illusion-of-tra.html\">illusion of transparency</a>, <a href=\"http://www.overcomingbias.com/2007/10/inferential-dis.html\">inferential distance</a>, and <a href=\"http://www.overcomingbias.com/2007/10/double-illusion.html\">double illusion of transparency</a>.&nbsp; (Notice how \"You overestimate how much you're explaining and your listeners overestimate how much they're hearing\" becomes <em>much more forceful</em> as advice, after I back it up with a cognitive science experiment and some evolutionary psychology?)</p>\n<p>I think that the advice I <em>need</em> is from someone who reads up on a whole lot of experimental psychology dealing with willpower, mental conflicts, ego depletion, preference reversals, hyperbolic discounting, the breakdown of the self, picoeconomics, etcetera, and who, in the process of overcoming their own akrasia, manages to understand what they did in <em>truly general terms</em>&mdash;thanks to experiments that give them a vocabulary of cognitive phenomena that <em>actually exist</em>, as opposed to phenomena they just made up.&nbsp; And moreover, someone who can <em>explain</em> what they did to someone else, thanks again to the experimental and theoretical vocabulary that lets them point to replicable experiments that ground the ideas in very concrete results, or mathematically clear ideas.</p>\n<p>Note the grade of increasing difficulty in citing:</p>\n<ul>\n<li> <em>Concrete </em><em>experimental results</em> (for which one need merely consult a paper, hopefully one that reported p &lt; 0.01 because p &lt; 0.05 may fail to replicate)</li>\n<li><em>Causal accounts that are actually true</em> (which may be most reliably obtained by looking for the theories that are used by a majority within a given science)</li>\n<li><em>Math validly interpreted</em> (on which I have trouble offering useful advice because so much of my own math talent is intuition that kicks in before I get a chance to deliberate)</li>\n</ul>\n<p>If you don't know who to trust, or you don't trust yourself, you should concentrate on experimental results to start with, move on to thinking in terms of causal theories that are widely used within a science, and dip your toes into math and epistemology with extreme caution.</p>\n<p>But practical advice really, really <em>does </em>become a lot more powerful when it's backed up by <em>concrete experimental results</em>, <em>causal accounts that are actually true,</em> and <em>math validly interpreted.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 2, "Ng8Gice9KNkncxqcj": 2, "fF9GEdWXKJ3z73TmB": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LqjKP255fPRY7aMzw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 56, "baseScore": 62, "extendedScore": null, "score": 9.5e-05, "legacy": true, "legacyId": "472", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "pvim9PZJ6qHRTMqD3", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "the-sin-of-underconfidence", "canonicalPrevPostSlug": "beware-of-other-optimizing", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 63, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BD4oExxQguTgpESdm", "bsdxuNdSGbfEKZREP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T19:19:27.876Z", "modifiedAt": null, "url": null, "title": "Meetup Reminder: UC Santa Barbara, Today @6pm", "slug": "meetup-reminder-uc-santa-barbara-today-6pm", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QESemPKE774Wwe6gP/meetup-reminder-uc-santa-barbara-today-6pm", "pageUrlRelative": "/posts/QESemPKE774Wwe6gP/meetup-reminder-uc-santa-barbara-today-6pm", "linkUrl": "https://www.lesswrong.com/posts/QESemPKE774Wwe6gP/meetup-reminder-uc-santa-barbara-today-6pm", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20Reminder%3A%20UC%20Santa%20Barbara%2C%20Today%20%406pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20Reminder%3A%20UC%20Santa%20Barbara%2C%20Today%20%406pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQESemPKE774Wwe6gP%2Fmeetup-reminder-uc-santa-barbara-today-6pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20Reminder%3A%20UC%20Santa%20Barbara%2C%20Today%20%406pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQESemPKE774Wwe6gP%2Fmeetup-reminder-uc-santa-barbara-today-6pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQESemPKE774Wwe6gP%2Fmeetup-reminder-uc-santa-barbara-today-6pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 45, "htmlBody": "<p>Michael Blume and Anna Salamon have invited you to a Less Wrong meetup at UC Santa Barbara, at 6pm in the college of creative studies building.&nbsp; See <a href=\"/lw/ce/uc_santa_barbara_rationalists_unite_saturday_6pm/\">previous post</a>.&nbsp; (This post is a temporary reminder and will be deleted after the meetup, so comment <a href=\"/lw/ce/uc_santa_barbara_rationalists_unite_saturday_6pm/\">there</a>.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QESemPKE774Wwe6gP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "473", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dTnfX3HWizKeovFn3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-25T23:01:09.067Z", "modifiedAt": null, "url": null, "title": "\"Self-pretending\" is not as useful as we think", "slug": "self-pretending-is-not-as-useful-as-we-think", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:53.632Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pwno", "createdAt": "2009-02-27T06:17:31.584Z", "isAdmin": false, "displayName": "pwno"}, "userId": "SCgoHNxqc2agmDWEg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/58qCizhA2QNpHjEhh/self-pretending-is-not-as-useful-as-we-think", "pageUrlRelative": "/posts/58qCizhA2QNpHjEhh/self-pretending-is-not-as-useful-as-we-think", "linkUrl": "https://www.lesswrong.com/posts/58qCizhA2QNpHjEhh/self-pretending-is-not-as-useful-as-we-think", "postedAtFormatted": "Saturday, April 25th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Self-pretending%22%20is%20not%20as%20useful%20as%20we%20think&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Self-pretending%22%20is%20not%20as%20useful%20as%20we%20think%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F58qCizhA2QNpHjEhh%2Fself-pretending-is-not-as-useful-as-we-think%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Self-pretending%22%20is%20not%20as%20useful%20as%20we%20think%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F58qCizhA2QNpHjEhh%2Fself-pretending-is-not-as-useful-as-we-think", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F58qCizhA2QNpHjEhh%2Fself-pretending-is-not-as-useful-as-we-think", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 444, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:RelyOnVML /> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:DontVertAlignCellWithSp /> <w:DontBreakConstrainedForcedTables /> <w:DontVertAlignInTxbx /> <w:Word11KerningPairs /> <w:CachedColBalance /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\" \" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!-- /* Font Definitions */ @font-face {font-family:\"Cambria Math\"; panose-1:2 4 5 3 5 4 6 3 2 4; mso-font-charset:0; mso-generic-font-family:roman; mso-font-pitch:variable; mso-font-signature:-1610611985 1107304683 0 0 159 0;} @font-face {font-family:Calibri; panose-1:2 15 5 2 2 2 4 3 2 4; mso-font-charset:0; mso-generic-font-family:swiss; mso-font-pitch:variable; mso-font-signature:-1610611985 1073750139 0 0 159 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-unhide:no; mso-style-qformat:yes; mso-style-parent:\"\"; margin-top:0in; margin-right:0in; margin-bottom:10.0pt; margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:Calibri; mso-fareast-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} .MsoChpDefault {mso-style-type:export-only; mso-default-props:yes; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:Calibri; mso-fareast-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} .MsoPapDefault {mso-style-type:export-only; margin-bottom:10.0pt; line-height:115%;} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.0in 1.0in 1.0in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} --><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-qformat:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\"Times New Roman\"; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin;} --> <!--[endif]--></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"><span style=\"font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\">A few weeks ago I made a draft of a post that was originally intended to be about the same issue addressed in <a href=\"/lw/cn/instrumental_vs_epistemic_a_bardic_perspective/\">MBlume&rsquo;s post</a> regarding beneficial false beliefs. Coincidentally, my draft included the same exact hypothetical about entering a club believing you&rsquo;re the most attractive person in the room in order to increase chances of attracting women. There seems to be a general agreement with MBlume&rsquo;s &ldquo;it&rsquo;s ok to pretend because it&rsquo;s not self-deception and produces similar results&rdquo; conclusion. I was surprised to see so much agreement considering that when I made my original draft I reached a completely different conclusion. <br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"><span style=\"font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\">I do agree, however, that pretending may have some benefits, but those benefits are much more limited than MBlume makes them out to be. He brings up a time where pretending helped him better fit into his character in a play. Unfortunately, his anecdote is not an appropriate example of overcoming vestigial evolutionary impulses by pretending. His mind wasn&rsquo;t evolutionarily programmed to &ldquo;be afraid&rdquo; when pretending to be someone else, it was programmed to &ldquo;be afraid&rdquo; when <em>hitting on attractive women.</em> When I am alone in my room I can act like a real alpha male all day long, but put me in front of attractive women (or people in general) and I will retreat back to my stifled self. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"><span style=\"font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\">The only way false beliefs can overcome your obsolete evolutionary impulses is to truly believe in those false beliefs. And we all know why that would be a bad idea. Furthermore, pretending can be dangerous just like reading fiction can be dangerous. So the small benefit that pretending might give may not even be worth the cost (at times). <br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"><span style=\"font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\">But there is something we can learn from these (sometimes beneficial) false beliefs. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"><span style=\"font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\">Obviously, there is no direct casual chain that goes from self-fulfilling beliefs to real-world success. Beliefs, per se, are not the key variables in causing success; instead, these beliefs give rise to whatever the key variable is. We should figure out what are the key variables that arise and find a systematic way of getting those variables. <br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"><span style=\"font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\">With the club example, we should instead figure out what behavior changes may result from believing that every girl is attracted to you. Then, figure out which of those behaviors attract women and find a way to perfect those behaviors. This is the approach the seduction community adopts for learning how to attract women&mdash;and it works. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"><span style=\"font-family: &quot;Times New Roman&quot;,&quot;serif&quot;;\">Same goes with public speaking. If you have a fear of public speaking, you can&rsquo;t expect to pretend your fear away. There are ways of reducing unnecessary emotions; the ways that work, however, don&rsquo;t depend on pretending. </span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YTCrHWYHAsAD74EHo": 1, "ZzxvopS4BwLuQy42n": 1, "3ee9k6NJfcGzL6kMS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "58qCizhA2QNpHjEhh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 4, "extendedScore": null, "score": 4.9016634134376e-07, "legacy": true, "legacyId": "477", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AGP9PwnhQcuYMKyMm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-26T00:45:25.820Z", "modifiedAt": null, "url": null, "title": "Where's Your Sense of Mystery?", "slug": "where-s-your-sense-of-mystery", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:45.553Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/snwX7hXgLFikqDBr6/where-s-your-sense-of-mystery", "pageUrlRelative": "/posts/snwX7hXgLFikqDBr6/where-s-your-sense-of-mystery", "linkUrl": "https://www.lesswrong.com/posts/snwX7hXgLFikqDBr6/where-s-your-sense-of-mystery", "postedAtFormatted": "Sunday, April 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Where's%20Your%20Sense%20of%20Mystery%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhere's%20Your%20Sense%20of%20Mystery%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsnwX7hXgLFikqDBr6%2Fwhere-s-your-sense-of-mystery%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Where's%20Your%20Sense%20of%20Mystery%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsnwX7hXgLFikqDBr6%2Fwhere-s-your-sense-of-mystery", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsnwX7hXgLFikqDBr6%2Fwhere-s-your-sense-of-mystery", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1507, "htmlBody": "<p><strong>Related to: </strong><a href=\"http://www.overcomingbias.com/2008/03/joy-in-the-real.html\">Joy in the Merely Real</a>, <a href=\"http://www.overcomingbias.com/2008/02/algorithm-feels.html\">How An Algorithm Feels From Inside</a>, <a href=\"http://www.overcomingbias.com/2007/09/science-as-curi.html\">\"Science\" As Curiosity-Stopper<br /></a></p>\n<p>Your friend tells you that a certain rock formation on Mars looks a lot like a pyramid, and that maybe it was built by aliens in the distant past. You scoff, and respond that a lot of geological processes can produce regular-looking rocks, and in all the other cases like this closer investigation has revealed the rocks to be completely natural. You think this whole conversation is silly and don't want to waste your time on such nonsense. Your friend scoffs and asks:<br /><a href=\"http://cectic.com/036.html\"><br />\"Where's your sense of mystery?\"</a><br /><br />You respond, as you have been taught to do, that your sense of mystery is exactly where it should be, among all of the real non-flimflam mysteries of science. How exactly does photosynthesis happen, what is the relationship between gravity and quantum theory, what is the source of the perturbations in Neptune's orbit? These are the real mysteries, not some bunkum about aliens. And if we cannot learn to take joy in the merely real, our life will be empty indeed.</p>\n<p>But do you really believe it?<br /><br />I loved the Joy in the Merely Real sequence. But it spoke to me <em>because </em>it's one of the things I have the most trouble with. I am the kind of person who would have much more fun reading about the Martian pyramid than about photosynthesis.<br /><br />And the one shortcoming of Joy in the Merely Real was that it was entirely normative, and not descriptive. It tells me I should reserve my sense of mystery for real science, but doesn't explain why it's so hard to do so, or why most people never even try.</p>\n<p>So what is this sense of mystery thing anyway?<br /><a id=\"more\"></a><br />I think the sense of mystery (sense of wonder, curiosity, call it what you want) is how the mind's algorithm for determining what problems to work on feels from the inside. Compare this to lust, how the mind's algorithm for determining what potential mates to pursue feels from the inside. In both cases, the mind makes a decision based on criteria of its own, which is then presented to the consciousness in the form of an emotion. And in both cases, the mind's decision is very often contrary to our best interest - as anyone who's ever fallen for a woman based entirely on her looks can tell you.<br /><br />What sort of stuff makes us curious? I don't have anything better than introspection to go on, but here are some thoughts:<br /><br />1. We feel more curious about things that could potentially alter many different beliefs.<br />2. We feel more curious about things that we feel like we can solve.<br />3. We feel more curious about things that might give us knowledge other people want but don't have.<br />4. We feel more curious about things that <a href=\"http://www.overcomingbias.com/2008/08/use-the-native.html\">use the native architecture</a>; that is, the sorts of human-level events and personal interactions our minds evolved to deal with.<br /><br />So let's go back and consider how the original example - a pyramid on Mars versus photosynthesis - fits each of these criteria:<br /><br />The pyramid on Mars could alter our worldview completely<sup>1</sup>. We'd have to rework all of our theories about ancient history, astronomy, the origin of civilization, maybe even religion. Learning exactly how photosynthesis works, on the other hand, probably won't make too big a difference. I assume it probably involves some sort of chemistry that sounds a lot like the other chemistry I know. I anticipate that learning more about photosynthesis wouldn't alter any of my beliefs except those directly involving photosynthesis and maybe some obscure biochemical reactions.<br /><br />Pseudoscience and pseudohistory feel solveable. When you're reading a good pseudoscience book, it feels like you have all the clues and you just have to put them together. If you don't believe me, Google some pseudoscience. You'll find hundreds of webpages by people who think they've discovered the 'secret'. One person who says the pyramid on Mars was made by Atlanteans, another who says it was made by the Babylonian gods, another who says it was made by God to test our faith. On the other hand, I know I can't figure out photosynthesis without already being an expert in chemistry and biology. There's not that tantalizing sense of \"I could be the one to figure this out!\"<br /><br />Knowing about a pyramid on Mars means you know more than other people. Most of humankind doesn't think there are <em>any</em> structures on Mars - the fools! And if you were to figure it out, you'd be...one of the greatest scientists ever. The one who proved the existence of intelligent life on other planets. It'd be great! In comparison, knowing about photosynthesis makes you one of a few thousand boring chemist types who also know about photosynthesis. Even if you're the first person to discover something new about it, the only people likely to care are...a few thousand boring chemist types.<br /><br />And the pyramid deals in human-level problems: civilizations, monuments, collapse. Photosynthesis is a matter of equations and chemical reactions; much harder for most people.<br /><br />Evolutionarily, all these criteria make sense. Of <em>course</em> you should spend more time on a problem if you're likely to solve it and the solution will be very important. And when you're a hunter-gatherer, all your problems are going to be on the human level, so you might as well direct your sense of mystery there. But the algorithm is unsuited to modern day science, when interesting discoveries are usually several <a href=\"http://www.overcomingbias.com/2007/10/inferential-dis.html\">inferential distances</a> away in highly specialized domains and don't directly relate to the human level at all.<br /><br />Again, compare this to lust. In the evolutionary era, mating with a woman with wide hips was quite adaptive for a male. Nowadays, with the advent of the Caesarian section, not so much. Nowadays it's probably most important for him to choose a mate whom he can tolerate for more than a few years so he doesn't end up divorced. But the mental algorithms whose result outputs as lust don't know that, so they end up making him weak-kneed for some wide-hipped woman with a terrible personality. This isn't something to feel guilty about. It's just something he needs to be wary of and devote some of his willpower resources toward fighting.<br /><br />The practical take home advice, for me at least, is to treat curiosity in the same way. For a while, I felt genuinely guilty about my attraction to pseudohistory, as if it was some kind of moral flaw. It's not, no more than feeling lust towards someone you don't like is a moral flaw. They're both just misplaced drives, and all you can do is ignore, sublimate, or redirect them<sup>2</sup>. <br /><br />The great thing about lust is that satisfying your unconscious and conscious feelings don't have to be mutually exclusive. Sometimes somebody comes around who's both beautiful and the sort of person you want to spend the rest of your life with. Problem solved. Other times, once your conscious mind commits to someone, your unconscious mind eventually starts coming around. These are the only two solutions I've found for the curiosity problem too.<br /><br />The other practical take home advice here is for anyone whose job is educating others about science. Their job is going to be a lot easier if they can take advantage of this sense of mystery. The best science teachers I know do this. They emphasize the places where science produces counterintuitive, worldview-changing results. They present their information in the form of puzzles just difficult enough for their students to solve with a bit of effort. They try to pique their students interest with tales of the unusual or impressive. And they try to use metaphors to use the native architecture of human minds: talking about search algorithms in terms of water flowing downhill, for example.<br /><br />I hope that any work that gets done on Less Wrong involving synchronizing conscious and unconscious feelings and fighting akrasia can be applied to this issue too.</p>\n<p>&nbsp;</p>\n<p><strong>Footnotes:</strong></p>\n<p><strong>1: </strong>The brain seems <a href=\"/lw/bs/rationality_quotes_april_2009/89b\">generally bad at dealing with tiny probabilities of huge payoffs</a>. It may be that the payoff measured in size of paradigm shift from any paranormal belief being true is just so high that people aren't very good at discounting for the very small percent chance of it being true.</p>\n<p><strong>2: </strong>One big question I'm still uncertain about: why do some people, despite it all, find science really interesting? How come this is sometimes true of one science and not others? I have a friend who loves physics and desperately wants to solve its open questions, but whose eyes glaze over every time she hears about biology - what's up with that?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"moeYqrcakMgXnQNyF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "snwX7hXgLFikqDBr6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 40, "extendedScore": null, "score": 0.000550405687542528, "legacy": true, "legacyId": "478", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-26T05:38:42.984Z", "modifiedAt": null, "url": null, "title": "Less Meta", "slug": "less-meta", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:45.021Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W3LDwqHxiwKqWkWJi/less-meta", "pageUrlRelative": "/posts/W3LDwqHxiwKqWkWJi/less-meta", "linkUrl": "https://www.lesswrong.com/posts/W3LDwqHxiwKqWkWJi/less-meta", "postedAtFormatted": "Sunday, April 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Meta&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Meta%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW3LDwqHxiwKqWkWJi%2Fless-meta%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Meta%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW3LDwqHxiwKqWkWJi%2Fless-meta", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW3LDwqHxiwKqWkWJi%2Fless-meta", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 414, "htmlBody": "<p>My recent sequence on the craft and the community is highly forward-looking&mdash;not an immediately whole recipe, but a list of action items and warnings for anyone setting out in the future.&nbsp; Having expended this much effort already, it seems worthwhile to try and leverage others' future efforts.</p>\n<p>That sequence seemed like an appropriate finale, but putting it last had some side effects that I didn't expect.&nbsp; Thanks to <a href=\"http://changingminds.org/explanations/theories/recency_effect.htm\">the recency effect</a>, people are now talking as if the entire &oelig;uvre had all been anticipation of future awesomeness, with no practical value in the present...</p>\n<p>Okay, seriously, if you look over <a href=\"http://www.cs.auckland.ac.nz/~andwhay/postlist.html\">my posts on Overcoming Bias</a> that are <em>not</em> just a couple of months old, you really should see <em>quite a lot</em> of practical day-to-day stuff.&nbsp; Yes, there's a long sequence on quantum mechanics, but there really <em>is</em> plenty of day-to-day stuff, right down to <a href=\"http://www.overcomingbias.com/2007/11/evaluability.html\">applying biases of evaluability to save money on holiday shopping</a>.&nbsp; (Not to mention that I finally did derive real-world advice out of the QM detour!)</p>\n<p>I suspect there may also be a problem here with present schools not teaching people the experience of creating <em>new</em> craft.&nbsp; What they present you with, is what you learn.&nbsp; So when I talk about my belief that <em>we could be doing better</em>, they look around and say:&nbsp; \"But we <em>aren't </em>doing that well!\" rather than \"Hm, how can we make progress on this?\"</p>\n<p>And then your current accomplishments start to <a href=\"http://www.overcomingbias.com/2009/02/and-say-no-more-of-it.html\">pale in the light of grander dreams</a>, etcetera.&nbsp; One of the great lessons of Artificial Intelligence is that no matter <em>how</em> much progress you make, it can <em>always</em> be made to appear slow and unexciting just by having someone else quoted in the newspapers about much grander promises on which they fail to deliver.</p>\n<p>Anyway.&nbsp; I think that discussion here is going a bit too meta, too much about the community, and that was <em>not</em> the final push I had planned to deliver.&nbsp; (I know, I know, obvious in retrospect, yes, but I still didn't see it coming.)&nbsp; Hence the quick add-on about practical advice backed by experimental results or deep theories&mdash;thankfully we are going back to those again in <a href=\"/lw/d2/cached_procrastination/\">recent</a> posts.</p>\n<p>So if it's all right with you, dear readers, after the end of April, I will not promote more than one meta post unless at least four nonmeta posts have appeared before it&mdash;does that sound fair?</p>\n<p>&nbsp;</p>\n<p style=\"text-align:right\">Part of the sequence <a href=\"/lw/cz/the_craft_and_the_community/\"><em>The Craft and the Community</em></a></p>\n<p style=\"text-align:right\">Next post: \"<a href=\"/lw/c4/go_forth_and_create_the_art/\">Go Forth and Create the Art!</a>\"</p>\n<p style=\"text-align:right\">Previous post: \"<a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W3LDwqHxiwKqWkWJi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}], "voteCount": 21, "baseScore": 17, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "471", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5MmCYWKNnvAPWRBYL", "YdcF6WbBmJhaaDqoD", "aFEsqd6ofwnkNqaXo", "LqjKP255fPRY7aMzw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-26T05:56:14.452Z", "modifiedAt": null, "url": null, "title": "SIAI call for skilled volunteers and potential interns", "slug": "siai-call-for-skilled-volunteers-and-potential-interns", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:39.565Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TdqL5k3KaNfERpWC3/siai-call-for-skilled-volunteers-and-potential-interns", "pageUrlRelative": "/posts/TdqL5k3KaNfERpWC3/siai-call-for-skilled-volunteers-and-potential-interns", "linkUrl": "https://www.lesswrong.com/posts/TdqL5k3KaNfERpWC3/siai-call-for-skilled-volunteers-and-potential-interns", "postedAtFormatted": "Sunday, April 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SIAI%20call%20for%20skilled%20volunteers%20and%20potential%20interns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASIAI%20call%20for%20skilled%20volunteers%20and%20potential%20interns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTdqL5k3KaNfERpWC3%2Fsiai-call-for-skilled-volunteers-and-potential-interns%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SIAI%20call%20for%20skilled%20volunteers%20and%20potential%20interns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTdqL5k3KaNfERpWC3%2Fsiai-call-for-skilled-volunteers-and-potential-interns", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTdqL5k3KaNfERpWC3%2Fsiai-call-for-skilled-volunteers-and-potential-interns", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 638, "htmlBody": "<p>Want to increase the odds that humanity correctly navigates whatever risks and promises artificial intelligence may bring?&nbsp; Interested in spending this summer in the SF Bay Area, working on projects and picking up background with similar others, with some possibility of staying on thereafter?&nbsp; Want to work with, and learn with, some of the best thinkers you'll ever meet? &ndash; more specifically, some of the best at synthesizing evidence across a wide range of disciplines, and using it to make incremental progress on problems that are both damn slippery and damn important?&nbsp; <br /> <br />If so, drop us an email.&nbsp; Show us your skills; give us a chance to jointly brainstorm what you might be able to do.<br /><a id=\"more\"></a><br />We are particularly interested in people who have *any* of the following traits:</p>\n<ul>\n<li>Dazzling brilliance at math or philosophy;</li>\n<li>A history of successful academic paper-writing; strategic understanding of journal submission processes, grant application processes, etc.</li>\n<li>Strong general knowledge of science or social science, and the ability to read rapidly and/or to quickly pick up new fields;</li>\n<li>Good interpersonal skills, writing skills, and/or marketing skills;</li>\n<li>Organization, strong ability to keep projects going without much supervision, and the ability to get mundane stuff done in a reliable manner;&nbsp;</li>\n<li>Skill at implementing (non-AI) software projects, such as web apps for interactive technological forecasting, rapidly and reliably;</li>\n<li>A history of successfully pulling off large projects or events;</li>\n<li>Unusual competence of some other sort, in some domain we need, but haven&rsquo;t realized we need.</li>\n</ul>\n<p>The only musts are that you be capable, rational, and interested in helping reduce existential risk.<br /><br />If you&rsquo;re interested, send an email to annasalamon at gmail dot com, who will be doing the first-pass screening.&nbsp; Include:</p>\n<ol>\n<li>Why you&rsquo;re interested;</li>\n<li>What particular skills you would bring, and what evidence makes you think you have those skills (you might include a standard resume);</li>\n<li>Optionally, any ideas you have for what sorts of projects you might like to be involved in, or how your skillset could help us improve humanity&rsquo;s long-term odds. </li>\n</ol>\n<p>Our application process is fairly informal, so send us a quick email as initial inquiry and after some correspondence we can decide whether or not to follow up with more application components.</p>\n<p><br />(Background on where we're coming from: SIAI is currently seeing who's out there and brainstorming possibilities (however, it now looks like a summer project likely <em>will</em> go forward).&nbsp; If you're part of who's out there, do let us know.&nbsp; Plausible projects include:</p>\n<ul>\n<li> Improving technological forecasting around AI (with wide probability intervals, attention to the heuristics and biases literature, etc.);</li>\n<li>Writing academic conference/journal papers to seed academic literatures on questions around AI risks (e.g., takeoff speed, economics of AI software engineering, genie problems, what kinds of goal systems can easily arise and what portion of such goal systems would be foreign to human values; theoretical compsci knowledge would be helpful for many of these questions);</li>\n<li>Helping construct and/or test useful rationality curricula;</li>\n<li>Other activities that further our or relevant other actors' understanding of what humanity is up against or how to address it -- either directly, by research and writing on the topics themselves, or indirectly, by improvements in our individual or collective rationality.)</li>\n</ul>\n<p>(This post is specially exempted from the \"no AI discussion until after April\" ban because it is time-urgent.)</p>\n<p><strong>ETA:</strong> Fluency in economics would also be a plus.&nbsp; (But don't feel like you need all the traits.&nbsp; Rationality, general competence, and unusual skill in <em>one</em> of the above is fine.&nbsp; Special consideration if you're young and have indicators of promise, though for the most part we're looking for people who are older and have actual past success.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "NrvXXL3iGjjxu5B7d": 1, "QPt5ECwTCAg63mbNu": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TdqL5k3KaNfERpWC3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 20, "extendedScore": null, "score": 2.8e-05, "legacy": true, "legacyId": "475", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-26T17:52:21.611Z", "modifiedAt": null, "url": null, "title": "The Craft and the Community", "slug": "the-craft-and-the-community", "viewCount": null, "lastCommentedAt": "2014-10-08T00:09:00.515Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YdcF6WbBmJhaaDqoD/the-craft-and-the-community", "pageUrlRelative": "/posts/YdcF6WbBmJhaaDqoD/the-craft-and-the-community", "linkUrl": "https://www.lesswrong.com/posts/YdcF6WbBmJhaaDqoD/the-craft-and-the-community", "postedAtFormatted": "Sunday, April 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Craft%20and%20the%20Community&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Craft%20and%20the%20Community%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYdcF6WbBmJhaaDqoD%2Fthe-craft-and-the-community%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Craft%20and%20the%20Community%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYdcF6WbBmJhaaDqoD%2Fthe-craft-and-the-community", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYdcF6WbBmJhaaDqoD%2Fthe-craft-and-the-community", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3521, "htmlBody": "<p>This sequence ran from <a href=\"https://www.lessestwrong.com/lw/1e/raising_the_sanity_waterline/\">March</a> to <a href=\"https://www.lessestwrong.com/lw/c4/go_forth_and_create_the_art/\">April</a> of 2009 and dealt with the topic of building rationalist communities that could systematically improve on the art, craft, and science of human rationality.  This is a highly forward-looking sequence - not so much an immediately complete recipe, as a list of action items and warnings for anyone setting out in the future to build a craft and a community.</p><ul><li><strong><a href=\"https://www.lessestwrong.com/lw/1e/raising_the_sanity_waterline/\">Raising the Sanity Waterline</a></strong>:  Behind every particular failure of social rationality is a larger and more general failure of social rationality; even if all religious content were deleted tomorrow from all human minds, the larger failures that permit religion would still be present.  Religion may serve the function of an asphyxiated canary in a coal mine - getting rid of the canary doesn&#x27;t get rid of the gas.  Even a complete social victory for atheism would only be the beginning of the real work of rationalists.  What could you teach people without ever <em>explicitly</em> mentioning religion, that would raise their <em>general epistemic waterline</em> to the point that religion went underwater?</li><li><strong><a href=\"https://www.lessestwrong.com/lw/2c/a_sense_that_more_is_possible/\">A Sense That More Is Possible</a></strong>: The art of human rationality may have not been much developed because its practitioners lack a sense that <em>vastly more is possible.</em>  The level of expertise that most rationalists strive to develop is not on a par with the skills of a professional mathematician - more like that of a strong casual amateur.  Self-proclaimed &quot;rationalists&quot; don&#x27;t seem to get huge amounts of personal mileage out of their craft, and no one sees a problem with this.  Yet rationalists get less systematic training in a less systematic context than a first-dan black belt gets in hitting people.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/2i/epistemic_viciousness/\">Epistemic Viciousness</a></strong>:  An essay by Gillian Russell on &quot;<a href=\"http://www.artsci.wustl.edu/~grussell/epistemicviciousness.pdf\">Epistemic Viciousness in the Martial Arts</a>&quot; generalizes amazingly to possible and actual problems with building a community around rationality.  Most notably the extreme dangers associated with &quot;data poverty&quot; - the difficulty of testing the skills in the real world.  But also such factors as the sacredness of the dojo, the investment in teachings long-practiced, the difficulty of book learning that leads into the need to trust a teacher, deference to historical masters, and above all, living in data poverty while continuing to act as if the luxury of trust is possible.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/2j/schools_proliferating_without_evidence/\">Schools Proliferating Without Evidence</a></strong>:  The branching schools of &quot;psychotherapy&quot;, another domain in which experimental verification was weak (nonexistent, actually), show that an aspiring craft lives or dies by the degree to which it can be tested in the real world.  In the absence of that testing, one becomes prestigious by inventing yet another school and having students, rather than excelling at any visible performance criterion.  The field of hedonic psychology (happiness studies) began, to some extent, with the realization that you could <em>measure</em> happiness - that there was a family of measures that by golly did validate well against each other.  The act of creating a new measurement creates new science; if it&#x27;s a <em>good </em>measurement, you get good science.  </li><li><strong><a href=\"https://www.lessestwrong.com/lw/2s/3_levels_of_rationality_verification/\">3 Levels of Rationality Verification</a></strong>:  How far the craft of rationality can be taken, depends largely on what methods can be invented for verifying it.  Tests seem usefully stratifiable into <em>reputational, experimental,</em> and <em>organizational</em>.  A &quot;reputational&quot; test is some real-world problem that tests the ability of a teacher or a school (like running a hedge fund, say) - &quot;keeping it real&quot;, but without being able to break down exactly what was responsible for success.  An &quot;experimental&quot; test is one that can be run on each of a hundred students (such as a well-validated survey).  An &quot;organizational&quot; test is one that can be used to preserve the integrity of organizations by validating individuals or small groups, even in the face of strong incentives to game the test.  The strength of solution invented at each level will determine how far the craft of rationality can go in the real world.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/3h/why_our_kind_cant_cooperate/\">Why Our Kind Can&#x27;t Cooperate</a></strong>:  The atheist/libertarian/technophile/sf-fan/early-adopter/programmer/etc crowd, aka &quot;the nonconformist cluster&quot;, seems to be stunningly bad at coordinating group projects.  There are a number of reasons for this, but one of them is that people are as <em>reluctant</em> to speak <em>agreement</em> out loud, as they are eager to voice disagreements - the exact opposite of the situation that obtains in more cohesive and powerful communities.  This is not rational either!  It is dangerous to be half a rationalist (in general), and this also applies to teaching only disagreement but not agreement, or only lonely defiance but not coordination.  The pseudo-rationalist taboo against expressing strong feelings probably doesn&#x27;t help either.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/42/tolerate_tolerance/\">Tolerate Tolerance</a></strong>:  One of the likely characteristics of someone who sets out to be a &quot;rationalist&quot; is a lower-than-usual tolerance for flawed thinking.  This makes it very important to <em>tolerate other people&#x27;s tolerance</em> - to avoid rejecting them <em>because they tolerate people you wouldn&#x27;t</em> - since otherwise we must all have exactly the same standards of tolerance in order to work together, which is unlikely.  Even if someone has a nice word to say about complete lunatics and crackpots - so long as they don&#x27;t literally believe the same ideas themselves - try to be nice to them?  Intolerance of tolerance corresponds to <em>punishment of non-punishers,</em> a very dangerous game-theoretic idiom that can lock completely arbitrary systems in place even when they benefit no one at all.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/4d/youre_calling_who_a_cult_leader/\">You&#x27;re Calling Who A Cult Leader?</a></strong>:  Paul Graham gets exactly the same accusations about &quot;cults&quot; and &quot;echo chambers&quot; and &quot;coteries&quot; that I do, in exactly the same tone - e.g. comparing the long hours worked by Y Combinator startup founders to the sleep-deprivation tactic used in cults, or claiming that founders were asked to move to the Bay Area startup hub as a cult tactic of separation from friends and family.  This is bizarre, considering our relative surface risk factors.  It just seems to be a failure mode of the nonconformist community in general.  By far the most cultish-looking behavior on Hacker News is people trying to <em>show off how willing they are to disagree with Paul Graham,</em> which, I can personally testify, feels really bizarre when you&#x27;re the target.  Admiring someone shouldn&#x27;t be so scary - I don&#x27;t hold back so much when praising e.g. Douglas Hofstadter; in this world there are people who have pulled off awesome feats and it is okay to admire them highly.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/4y/on_things_that_are_awesome/\">On Things That Are Awesome</a></strong>:  Seven followup thoughts:  I can list more than <em>one</em> thing that is awesome; when I think of &quot;Douglas Hofstadter&quot; I am really thinking of his all-time greatest work; the greatest work is not the person; when we imagine other people we are imagining their output, so the real Douglas Hofstadter is the source of &quot;Douglas Hofstadter&quot;; I most strongly get the sensation of awesomeness when I see someone outdoing me overwhelmingly, at some task I&#x27;ve actually tried; we tend to admire unique detailed awesome things and overlook common nondetailed awesome things; religion and its bastard child &quot;spirituality&quot; tends to make us overlook <em>human</em> awesomeness.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/5j/your_price_for_joining/\">Your Price For Joining</a></strong>:  The game-theoretical puzzle of the Ultimatum game has its reflection in a real-world dilemma:  How much do you demand that an existing group adjust toward you, before you will adjust toward it?  Our hunter-gatherer instincts will be tuned to groups of 40 with very minimal administrative demands and equal participation, meaning that we underestimate the inertia of larger and more specialized groups and demand too much before joining them.  In other groups this resistance can be overcome by affective death spirals and conformity, but rationalists think themselves too good for this - with the result that people in the nonconformist cluster often set their joining prices <em>way way way</em> too high, like an 50-way split with each player demanding 20% of the money.  Nonconformists need to move in the direction of joining groups more easily, even in the face of annoyances and apparent unresponsiveness.  If an issue isn&#x27;t worth <em>personally fixing by however much effort it takes,</em> it&#x27;s not worth a refusal to contribute.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/5t/can_humanism_match_religions_output/\">Can Humanism Match Religion&#x27;s Output?</a></strong>:  Anyone with a <em>simple </em>and <em>obvious</em> charitable project - responding with food and shelter to a tidal wave in Thailand, say - would be better off by <em>far</em> pleading with the Pope to mobilize the Catholics, rather than with Richard Dawkins to mobilize the atheists.  <em>For so long as this is true,</em> any increase in atheism at the expense of Catholicism will be something of a hollow victory, regardless of all other benefits.  Can no rationalist match the motivation that comes from the irrational fear of Hell?  Or does the real story have more to do with the motivating power of <em>physically meeting</em> others who share your cause, and group norms of participating?</li><li><strong><a href=\"https://www.lessestwrong.com/lw/5v/church_vs_taskforce/\">Church vs. Taskforce</a></strong>:  Churches serve a role of providing community - but they aren&#x27;t explicitly optimized for this, because their nominal role is different.  If we desire community without church, can we go one better in the course of deleting religion?  There&#x27;s a great deal of work to be done in the world; rationalist communities might potentially organize themselves around good causes, while explicitly optimizing for community.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/66/rationality_common_interest_of_many_causes/\">Rationality: Common Interest of Many Causes</a></strong>:  Many causes benefit particularly from the spread of rationality - because it takes a little more rationality than usual to see their case, as a supporter, or even just a supportive bystander.  Not just the obvious causes like atheism, but things like marijuana legalization.  In the case of my own work this effect was strong enough that after years of bogging down I threw up my hands and explicitly recursed on creating rationalists.  If such causes can come to terms with <em>not individually capturing all the rationalists they create,</em> then they can mutually benefit from mutual effort on creating rationalists.  This cooperation may require learning to shut up about disagreements between such causes, and not fight over priorities, <em>except</em> in specialized venues clearly marked.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/64/helpless_individuals/\">Helpless Individuals</a></strong>:  When you consider that our grouping instincts are optimized for 50-person hunter-gatherer bands where everyone knows everyone else, it begins to seem miraculous that modern-day large institutions survive at all.  And in fact, the vast majority of large modern-day institutions simply <em>fail to exist in the first place.</em>  This is why funding of Science is largely through money thrown at Science rather than donations from individuals - research isn&#x27;t a good emotional fit for the rare problems that individuals can manage to coordinate on.  In fact very few things are, which is why e.g. 200 million adult Americans have such tremendous trouble supervising the 535 members of Congress.  Modern humanity manages to put forth very little in the way of coordinated individual effort to serve our collective individual interests.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/65/money_the_unit_of_caring/\">Money: The Unit of Caring</a></strong>:  Omohundro&#x27;s resource balance principle implies that the inside of any approximately rational system has a common currency of expected utilons.  In our world, this common currency is called &quot;money&quot; and it is the unit of how much society cares about something - a brutal yet obvious point.  Many people, seeing a good cause, would prefer to help it by donating a few volunteer hours.  But this avoids the tremendous gains of comparative advantage, professional specialization, and economies of scale - the reason we&#x27;re not still in caves, the only way anything ever gets done in this world, the tools <em>grownups</em> use when anyone really <em>cares</em>.  Donating hours worked within a professional specialty and paying-customer priority, whether directly, or by donating the money earned to hire other professional specialists, is far more effective than volunteering unskilled hours.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/6z/purchase_fuzzies_and_utilons_separately/\">Purchase Fuzzies and Utilons Separately</a></strong>:  Wealthy philanthropists typically make the mistake of trying to purchase warm fuzzy feelings, status among friends, and actual utilitarian gains, simultaneously; this results in vague pushes along all three dimensions and a mediocre final result.  It should be far more effective to spend some money/effort on buying altruistic fuzzies at maximum optimized efficiency (e.g. by helping people in person and seeing the results in person), buying status at maximum efficiency (e.g. by donating to something sexy that you can brag about, regardless of effectiveness), and spending <em>most </em>of your money on expected utilons (chosen through sheer cold-blooded shut-up-and-multiply calculation, without worrying about status or fuzzies).</li><li><strong><a href=\"https://www.lessestwrong.com/lw/77/selecting_rationalist_groups/\">Selecting Rationalist Groups</a></strong>:  Trying to breed e.g. egg-laying chickens by individual selection can produce odd side effects on the farm level, since a more dominant hen can produce more egg mass at the <em>expense of other hens.</em>  Group selection is nearly impossible in Nature, but easy to impose in the laboratory, and group-selecting hens produced substantial increases in efficiency.  Though most of my essays are about individual rationality - and indeed, Traditional Rationality also praises the lone heretic more than evil Authority - the real effectiveness of &quot;rationalists&quot; may end up determined by their performance in groups.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/7k/incremental_progress_and_the_valley/\">Incremental Progress and the Valley</a></strong>:  The optimality theorems for probability theory and decision theory, are for <em>perfect</em> probability theory and decision theory.  There is no theorem that incremental changes toward the ideal, starting from a flawed initial form, must yield incremental progress at each step along the way.  Since perfection is unattainable, why dare to try for improvement?  But my <em>limited</em> experience with <em>specialized</em> applications suggests that given <em>enough</em> progress, one can achieve <em>huge </em>improvements over baseline - it just takes a lot of progress to get there.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/8t/whiningbased_communities/\">Whining-Based Communities</a></strong>:  Many communities feed emotional needs by offering their members someone or something to blame for failure - say, those looters who don&#x27;t approve of your excellence.  You can easily imagine some group of &quot;rationalists&quot; congratulating themselves on how <em>reasonable</em> they were, while blaming the surrounding <em>unreasonable</em> society for keeping them down.  But this is not how real rationality works - there&#x27;s no assumption that other agents are rational.  We all face unfair tests (and yes, they are unfair to different degrees for different people); and how well you do with <em>your</em> unfair tests, is the test of <em>your</em> existence.  Rationality is there to <a href=\"https://www.lessestwrong.com/lw/7i/rationality_is_systematized_winning/\">help you </a><em><a href=\"https://www.lessestwrong.com/lw/7i/rationality_is_systematized_winning/\">win anyway</a>,</em> not to provide a self-handicapping excuse for losing.  There are <a href=\"https://www.lessestwrong.com/lw/92/extenuating_circumstances/\">no first-person extenuating circumstances</a>.  There is <em>absolutely no point</em> in going down the road of mutual bitterness and consolation, about <em>anything, ever.</em> </li><li><strong><a href=\"https://www.lessestwrong.com/lw/9c/mandatory_secret_identities/\">Mandatory Secret Identities</a></strong>:  This post was not well-received, but the point was to suggest that a student must at some point leave the dojo and test their skills in the real world.  <em>The aspiration of an excellent student should not consist primarily of founding their own dojo and having their own students</em>.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/9v/beware_of_otheroptimizing/\">Beware of Other-Optimizing</a></strong>:  Aspiring rationalists often vastly overestimate their own ability to optimize other people&#x27;s lives.  They read nineteen webpages offering productivity advice that doesn&#x27;t work for them... and then encounter the twentieth page, or invent a new method themselves, and <em>wow, it really works</em> - they&#x27;ve discovered the <em>true method.</em>  Actually, they&#x27;ve just discovered the one method in twenty that works for <em>them,</em> and their confident advice is no better than randomly selecting one of the twenty blog posts.  Other-Optimizing is exceptionally dangerous when you have <em>power over</em> the other person - for then you&#x27;ll just believe that they <em>aren&#x27;t trying hard enough.</em></li><li><strong><a href=\"https://www.lessestwrong.com/lw/ab/akrasia_and_shangrila/\">Akrasia and Shangri-La</a></strong>:  The <a href=\"https://www.lessestwrong.com/lw/a6/the_unfinished_mystery_of_the_shangrila_diet/\">Shangri-La diet</a> works amazingly well for some people, but completely fails for others, for no known reason.  Since the diet has a metabolic rationale and is not <em>supposed</em> to require willpower, its failure in my and other cases is unambigiously mysterious.  If it required a component of willpower, then I and others might be tempted to blame myself for not having willpower.  The art of combating akrasia (willpower failure) has the same sort of mysteries and is in the same primitive state; we don&#x27;t know the deeper rule that explains why a trick works for one person but not another.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/9m/collective_apathy_and_the_internet/\">Collective Apathy and the Internet</a></strong>:  The causes of <a href=\"https://www.lessestwrong.com/lw/9j/bystander_apathy/\">bystander apathy</a> are even worse on the Internet.  There may be an opportunity here for a startup to deliberately try to avert bystander apathy in online group coordination.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/5f/bayesians_vs_barbarians/\">Bayesians vs. Barbarians</a></strong>:  Suppose that a country of rationalists is attacked by a country of <a href=\"http://www.overcomingbias.com/2007/06/are-your-enemie.html\">Evil</a> Barbarians who know nothing of probability theory or decision theory.  There&#x27;s a certain concept of &quot;rationality&quot; which says that the rationalists inevitably lose, because the Barbarians believe in a heavenly afterlife if they die in battle, while the rationalists would all individually prefer to stay out of harm&#x27;s way.  So the rationalist civilization is doomed; it is too elegant and civilized to fight the savage Barbarians...  And then there&#x27;s the idea that rationalists should be able to (a) solve group coordination problems, (b) care a lot about other people and (c) win...</li><li><strong><a href=\"https://www.lessestwrong.com/lw/ap/of_gender_and_rationality/\">Of Gender and Rationality</a></strong>:  Analysis of the gender imbalance that appears in &quot;rationalist&quot; communities, suggesting nine possible causes of the effect, and possible corresponding solutions.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/bd/my_way/\">My Way</a></strong>:  I sometimes think of myself as being like the protagonist in a classic SF labyrinth story, wandering further and further into some alien artifact, trying to radio back a description of what I&#x27;m seeing, so that I can be followed.  But what I&#x27;m finding is not just <em>the</em> Way, the thing that lies at the center of the labyrinth; it is also <em>my</em> Way, the path that <em>I</em> would take to come closer to the center, from whatever place I started out.  And yet there is still a common thing we are all trying to find.  We should be aware that others&#x27; shortest paths may not be the <em>same</em> as our own, but this is not the same as giving up the ability to judge <em>or</em> to share.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/c3/the_sin_of_underconfidence/\">The Sin of Underconfidence</a></strong>:  When subjects know about a bias or are warned about a bias, <em>overcorrection</em> is not unheard of as an experimental result.  That&#x27;s what makes a lot of cognitive subtasks so troublesome - you know you&#x27;re biased but you&#x27;re not sure how much, and if you keep tweaking you may overcorrect.  The danger of underconfidence (overcorrecting for overconfidence) is that you pass up opportunities on which you could have been successful; not challenging difficult enough problems; losing forward momentum and adopting defensive postures; refusing to put the <em>hypothesis </em>of your inability to the test; losing enough hope of triumph to try <em>hard</em> enough to win.  You should ask yourself &quot;Does this way of thinking make me stronger, or weaker?&quot;</li><li><strong><a href=\"https://www.lessestwrong.com/lw/c1/wellkept_gardens_die_by_pacifism/\">Well-Kept Gardens Die By Pacifism</a></strong>:  Good online communities die primarily by refusing to defend themselves, and so it has been since the days of Eternal September.  Anyone acculturated by academia knows that <em>censorship</em> is a very grave sin... in their walled gardens where it costs thousands and thousands of dollars to enter.  A community with internal politics will treat any attempt to impose moderation as a coup attempt (since internal politics seem of far greater import than invading barbarians).  In rationalist communities this is probably an instance of underconfidence - mildly competent moderators are probably quite trustworthy to wield the banhammer.  On Less Wrong, the community <em>is</em> the moderator (via karma) and you will need to trust <em>yourselves</em> enough to wield the power and keep the garden clear.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/d4/practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a></strong>:  Practical advice is genuinely much, much more useful when it&#x27;s backed up by concrete experimental results, causal models that are actually true, or valid math that is validly interpreted.  (Listed in increasing order of difficulty.)  Stripping out the theories and giving the mere advice alone wouldn&#x27;t have nearly the same impact or even the same message; and oddly enough, translating experiments and math into practical advice seems to be a rare niche activity relative to academia.  If there&#x27;s a distinctive LW style, this is it.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/d3/less_meta/\">Less Meta</a></strong>:  The fact that this final series was on the craft and the community seems to have delivered a push in something of the wrong direction, (a) steering toward conversation about conversation and (b) making present accomplishment pale in the light of grander dreams.  Time to go back to practical advice and deep theories, then.</li><li><strong><a href=\"https://www.lessestwrong.com/lw/c4/go_forth_and_create_the_art/\">Go Forth and Create the Art!</a></strong>:  I&#x27;ve developed primarily the art of epistemic rationality, in particular, the arts required for advanced cognitive reductionism... arts like distinguishing fake explanations from real ones and avoiding affective death spirals.  There is much else that needs developing to create a craft of rationality - fighting akrasia; coordinating groups; teaching, training, verification, and becoming a proper experimental science; developing better introductory literature...  And yet it seems to me that there is a beginning barrier to surpass before you can <em>start</em> creating high-quality craft of rationality, having to do with virtually everyone who tries to think lofty thoughts going instantly astray, or indeed even realizing that a craft of rationality exists and that you ought to be studying cognitive science literature to create it.  It&#x27;s my hope that my writings, as partial as they are, will serve to surpass this initial barrier.  The rest I leave to you.</li></ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 9, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YdcF6WbBmJhaaDqoD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 43, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "467", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": false, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XqmjdBKa4ZaXJtNmf", "aFEsqd6ofwnkNqaXo", "Nu3wa6npK4Ry66vFp", "T8ddXNtmNSHexhQh8", "JnKCaGcgZL4Rsep8m", "5K7CMa6dEL7TN7sae", "7FzD7pNm9X68Gp5ZC", "JKxxFseBWz8SHkTgt", "cyzXoCv7nagDWCMNS", "YC3ArwKM8xhNjYqQK", "Q8evewZW5SeidLdbA", "3fNL2ssfvRzpApvdN", "p5DmraxDmhvMoZx8J", "4PPE6D635iBcGPGRy", "f42BHX7rMw2dyFJfT", "ZpDnRCeef2CLEFeKM", "3p3CYauiX8oLjmwRF", "ZEj9ATpv3P22LSmnC", "oZNXmHcdhb4m7vwsv", "rg7vPTtyLMfT6Qqud", "4ARtkT3EYox3THYjF", "XYrcTJFJoYKX2DxNL", "gBewgmzcEiks2XdoQ", "6NvbSwuSAooQxxf7f", "geqg9mk73NQh6uieE", "BD4oExxQguTgpESdm", "NnQbfLo868wgnHF4n", "K5nq3KcDXaGm7QQWR", "KsHmn6iJAEr9bACQW", "xsyG7PkMekHud2DMK", "FBgozHEv7J72NCEPB", "pkFazhcTErMw7TFtT", "tscc3e5eujrsEeFN4", "LqjKP255fPRY7aMzw", "W3LDwqHxiwKqWkWJi"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2009-04-26T17:52:21.611Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-26T21:23:53.642Z", "modifiedAt": null, "url": null, "title": "Excuse me, would you like to take a survey?", "slug": "excuse-me-would-you-like-to-take-a-survey", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:49.392Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H6LnGwjKiGvDyR5yo/excuse-me-would-you-like-to-take-a-survey", "pageUrlRelative": "/posts/H6LnGwjKiGvDyR5yo/excuse-me-would-you-like-to-take-a-survey", "linkUrl": "https://www.lesswrong.com/posts/H6LnGwjKiGvDyR5yo/excuse-me-would-you-like-to-take-a-survey", "postedAtFormatted": "Sunday, April 26th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Excuse%20me%2C%20would%20you%20like%20to%20take%20a%20survey%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExcuse%20me%2C%20would%20you%20like%20to%20take%20a%20survey%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH6LnGwjKiGvDyR5yo%2Fexcuse-me-would-you-like-to-take-a-survey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Excuse%20me%2C%20would%20you%20like%20to%20take%20a%20survey%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH6LnGwjKiGvDyR5yo%2Fexcuse-me-would-you-like-to-take-a-survey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH6LnGwjKiGvDyR5yo%2Fexcuse-me-would-you-like-to-take-a-survey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 330, "htmlBody": "<p><strong>Related to:</strong> <a href=\"/lw/bf/practical_rationality_questionnaire/\">Practical Rationality Questionnaire</a></p>\n<p>Here among this community of prior-using, Aumann-believing rationalists, it is a bit strange that we don't have any good measure of what the community thinks about certain things.<br /><br />I no longer place much credence in raw majoritarianism: the majority is too uneducated, too susceptible to the Dark Arts, and too vulnerable to cognitive biases. If I had to choose the people whose mean opinion I trusted most, it would be - all of you.<br /><br />So, at the risk of people getting surveyed-out, I'd like to run a survey on the stuff Anna Salamon didn't. Part on demographics, part on opinions, and part on the interactions between the two.<br /><br />I've already put up an incomplete rough draft of the survey I'd like to use, but I'll post it here again. Remember, this is an incomplete rough draft survey. <strong>DO NOT FILL IT OUT YET. YOUR SURVEY WILL NOT BE COUNTED.</strong><br /><br /><a href=\"http://spreadsheets.google.com/viewform?formkey=cF9KNGNtbFJXQ1JKM0RqTkxQNUY3Y3c6MA..\">Incomplete rough draft of survey</a><br /><br />Right now what I want from people is more interesting questions that you want asked. Any question that you want to know the Less Wrong consensus on. Please post each question as a separate comment, and upvote any question that you're also interested in. I'll include as many of the top-scoring questions as I think people can be bothered to answer.<br /><br />No need to include questions already on the survey, although if you really hate them you can suggest their un-inclusion or re-phrasing.</p>\n<p>Also important: how concerned are you about privacy? I was thinking about releasing the raw data later in case other people wanted to perform their own analyses, but it might be possible to identify specific people if you knew enough about them. Are there any people who would be comfortable giving such data if only one person were to see the data, but uncomfortable with it if the data were publically accessible?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"kJrjorSx3hXa7q7CJ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H6LnGwjKiGvDyR5yo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 15, "extendedScore": null, "score": 4.903661908516306e-07, "legacy": true, "legacyId": "482", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 132, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hbdYWmu2ozwNvvWcW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-27T15:42:16.444Z", "modifiedAt": null, "url": null, "title": "Should we be biased?", "slug": "should-we-be-biased", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:45.131Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "James_Miller", "createdAt": "2009-03-05T17:14:38.674Z", "isAdmin": false, "displayName": "James_Miller"}, "userId": "LzF2X9eB9oS3q4BXG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kM3P4eLDzDgnYxEHT/should-we-be-biased", "pageUrlRelative": "/posts/kM3P4eLDzDgnYxEHT/should-we-be-biased", "linkUrl": "https://www.lesswrong.com/posts/kM3P4eLDzDgnYxEHT/should-we-be-biased", "postedAtFormatted": "Monday, April 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Should%20we%20be%20biased%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShould%20we%20be%20biased%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkM3P4eLDzDgnYxEHT%2Fshould-we-be-biased%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Should%20we%20be%20biased%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkM3P4eLDzDgnYxEHT%2Fshould-we-be-biased", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkM3P4eLDzDgnYxEHT%2Fshould-we-be-biased", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p><a href=\"http://www.thefire.org/index.php/article/10526.html\">According</a> to the University of Chicago:</p>\r\n<p>\"Bias is a pre-formed negative opinion or attitude toward a group of persons who possess common characteristics, such as skin color, or cultural experiences, such as religion or national origin.\"</p>\r\n<p>&nbsp;</p>\r\n<p>So, should we ever be biased?&nbsp; And if the answer is&nbsp;yes then should&nbsp;we hide our biases for signaling reasons?</p>\r\n<p>&nbsp;</p>\r\n<p>Or should we take into account that many people have irrational biases against those who possess different skin colors, religions or national origins.&nbsp; So perhaps a high percentage of any negative biases readers of this blog have are irrational and so maybe the best course for us rationalists in training&nbsp;is to work against having any negative biases.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kM3P4eLDzDgnYxEHT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": -12, "extendedScore": null, "score": -2.3e-05, "legacy": true, "legacyId": "483", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-27T16:49:32.087Z", "modifiedAt": null, "url": null, "title": "Theism, Wednesday, and Not Being Adopted", "slug": "theism-wednesday-and-not-being-adopted", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:01.504Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AYa2gc3sFWCCFSaFq/theism-wednesday-and-not-being-adopted", "pageUrlRelative": "/posts/AYa2gc3sFWCCFSaFq/theism-wednesday-and-not-being-adopted", "linkUrl": "https://www.lesswrong.com/posts/AYa2gc3sFWCCFSaFq/theism-wednesday-and-not-being-adopted", "postedAtFormatted": "Monday, April 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Theism%2C%20Wednesday%2C%20and%20Not%20Being%20Adopted&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATheism%2C%20Wednesday%2C%20and%20Not%20Being%20Adopted%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYa2gc3sFWCCFSaFq%2Ftheism-wednesday-and-not-being-adopted%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Theism%2C%20Wednesday%2C%20and%20Not%20Being%20Adopted%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYa2gc3sFWCCFSaFq%2Ftheism-wednesday-and-not-being-adopted", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYa2gc3sFWCCFSaFq%2Ftheism-wednesday-and-not-being-adopted", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 860, "htmlBody": "<p>(<em>Disclaimer:</em> This post is sympathetic to a certain subset of theists.&nbsp; I am not myself a theist, nor have I ever been one.&nbsp; I do not intend to justify all varieties of theism, nor do I intend to justify much in the way of common theistic behavior.)</p>\n<p>I'm not adopted.&nbsp; You all believe me, right?&nbsp; How do you think I came by this information, that you're confident in my statement?&nbsp; The obvious and correct answer is that my parents told me so<sup>1</sup>.&nbsp; Why do I believe them?&nbsp; Well, they would be in a position to know the answer, and they have been generally honest and sincere in their statements to me.&nbsp; A false belief on the subject could be hazardous to me, if I report inaccurate family history to physicians, and I believe that my parents have my safety in mind.&nbsp; I know of the existence of adopted people; the possibility isn't completely absent from my mind - but I believe quite confidently that I am not among those people, because my parents say otherwise.</p>\n<p><a id=\"more\"></a></p>\n<p>Now let's consider another example.&nbsp; I have a friend who plans to name her first daughter Wednesday.&nbsp; Wednesday will also not be adopted, but that isn't the part of the example that is important: Wednesday will grow up in Provo, Utah, in a Mormon family in a Mormon community with Mormon friends, classmates, and neighbors, attending an LDS church every week and reading scripture and participating in church activities.&nbsp; It is overwhelmingly likely that she will believe the doctrines of the LDS church, because not only her parents, but <em>virtually everyone she knows</em> will reinforce these beliefs in her.&nbsp; Given the particular nuances of Mormonism as opposed to other forms of Christianity, Wednesday will <em>also</em> be regularly informed that several of these people are in a position to have special knowledge on the subject via direct prayer-derived evidence<sup>2</sup> - in much the same way that her parents will have special knowledge of her non-adopted status via direct experience when she wasn't in a state suitable to notice or remember the events.&nbsp; Also, a false belief on the subject could have all kinds of bad consequences - if the Muslims are right, for instance, no doubt Hell awaits Wednesday and her family - so if she also correctly assumes that her parents have her best interests at heart, she'll assume they would do their best to give her accurate information.</p>\n<p>Atheism tends to be treated as an open-and-shut case here and in other intellectually sophisticated venues, but is that fair?&nbsp; What about Wednesday?&nbsp; What would have to happen to her to get her to give up those beliefs?&nbsp; Well, for starters, she'd have to dramatically change her opinion of her family.&nbsp; Her parents care enough about honesty that they are already planning <em>not</em> to deceive her about Santa Claus - should she believe that they're liars?&nbsp; They're both college-educated, clever people, who read a lot and think carefully about (some) things - should she believe that they're fools?&nbsp; They've traveled around the world and have friends like me who are, vocally, non-Mormons and even non-Christians - should she believe that her parents have not been <em>exposed</em> to other ideas?</p>\n<p>Would giving up her religion help Wednesday <em>win</em>?&nbsp; I don't think her family would outright reject her for it, but it would definitely strain those valued relationships, and some of the aforementioned friends, classmates, and neighbors would certainly react badly.&nbsp; It doesn't seem that it would make her any richer, happier, more successful - especially if she carries on living in Utah<sup>3</sup>.&nbsp; (I reject out of hand the idea that she should deconvert in the closet and systematically lie to everyone she knows.)&nbsp; It would make her <em>right</em>.&nbsp; And that would be all it would do - if she were lucky.</p>\n<p>Is it really essential that, as a community, we exclude or dismiss or reflexively criticize theists who are good at partitioning, who like and are good at rational reasoning in every other sphere - and who just have <em>higher priorities</em> than <em>being right</em>?&nbsp; I have priorities that I'd probably put ahead of being right, too; I'm just not in a position where I really have to choose between \"keeping my friends and being right\", \"feeling at home and being right\", \"eating this week and being right\".&nbsp; That's my luck, not my cleverness, at work.</p>\n<p>When Wednesday has been born and has learned to read, it would be nice if there were a place for her here.</p>\n<p>&nbsp;</p>\n<p><sup>1</sup>I have other evidence - I have inherited some physical characteristics from my parents and have seen my birth certificate - but the point is that this is something I would take their word for even if I didn't take after them very strongly and had never seen the documentation.</p>\n<p><sup>2</sup>Mormons believe in direct revelation, and they also believe that priesthood authorities are entitled to receive revelations for those over whom they have said authority (e.g. fathers for their children, husbands for their wives, etc.).</p>\n<p><sup>3</sup>I have lived in Salt Lake City, and during this time was, as always, openly an atheist.&nbsp; Everyone was tolerant of me, but I do not think it <em>improved</em> my situation in any way.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AYa2gc3sFWCCFSaFq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 80, "baseScore": 59, "extendedScore": null, "score": 9.5e-05, "legacy": true, "legacyId": "484", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 59, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 341, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-27T21:07:52.368Z", "modifiedAt": null, "url": null, "title": "The End (of Sequences)", "slug": "the-end-of-sequences", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:25.149Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9jF4zbZqz6DydJ5En/the-end-of-sequences", "pageUrlRelative": "/posts/9jF4zbZqz6DydJ5En/the-end-of-sequences", "linkUrl": "https://www.lesswrong.com/posts/9jF4zbZqz6DydJ5En/the-end-of-sequences", "postedAtFormatted": "Monday, April 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20End%20(of%20Sequences)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20End%20(of%20Sequences)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9jF4zbZqz6DydJ5En%2Fthe-end-of-sequences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20End%20(of%20Sequences)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9jF4zbZqz6DydJ5En%2Fthe-end-of-sequences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9jF4zbZqz6DydJ5En%2Fthe-end-of-sequences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1354, "htmlBody": "<p>This concludes the final sequence on Overcoming Bias / Less Wrong.&nbsp; I have not said everything I wanted to say, but I hope I have said (almost) everything I <em>needed </em>to say.&nbsp; (Such that I actually <em>could</em> say it in these twenty-one months of daily posting, August 2007 through April 2009.)</p>\n<p>The project to which Less Wrong is devoted - the art and science and craft of human rationality - is, indeed, important.&nbsp; But the calculus of choosing among altruistic efforts is, in some ways, a calculus of who can take your place.&nbsp; I am <em>more </em>easily replaced here, than elsewhere.&nbsp; And so it has come time for me to begin pulling my focus away from Less Wrong, and turning toward other matters, where I am less easily replaced.</p>\n<p>But I do need replacing - or rather, the work that I was doing needs replacing, whether by one person or by many people or by e.g. a karma system.</p>\n<p>And so <a href=\"/lw/cz/the_craft_and_the_community/\">my final sequence</a> was my letter that describes the work that I can already see remaining to be done, gives some advice on how to configure the effort, and warns direly against standard failure modes.</p>\n<p>Any idea that can produce great enthusiasm is a dangerous idea.&nbsp; It may be a necessary idea, but that does not make it any less dangerous.&nbsp; I do fear, to a certain extent, that I will turn my focus away, and then find out that someone has picked up the ideas and run with them and <em>gotten it all wrong...</em></p>\n<p>But you can only devote your whole life to one thing at a time.&nbsp; In those ways I have thought to anticipate, at least, I have placed a blocking Go stone or two, and you have been warned.</p>\n<p>I am not going to turn my attention away entirely and all at once.&nbsp; My initial plan is to cut back my posting to no more than one post per week.<a id=\"more\"></a></p>\n<p>At some future point, though, there must come a time when I turn my attention entirely away from building rationalism, and focus only on that other task.</p>\n<p>So, yes, just to belabor the point - if there's going to be a lasting community, and not just a body of online writing that people occasionally stumble across, it needs to set itself up to run without me.</p>\n<p>The last explicit dependency left on me is promoting posts, and I've been mostly doing that based on user voting (though not entirely; my activation threshold is lower for posts I perceive as higher-quality).&nbsp; I plan to start trying to delegate that power to co-editors shortly.</p>\n<p>For myself...&nbsp; I've been feeling rather burned out on writing, so I'm thinking of taking a short vacation and then studying math and working over the summer, before I go back to producing a book.</p>\n<p>I'm no longer certain about the time-investment wisdom of trying to convert the OB/LW sequences into minibooks.&nbsp; The <a href=\"/lw/cg/proposal_use_the_wiki_for_concepts/\">Wiki</a> might accomplish a lot of the same purpose of making the info more accessible and organizing it.&nbsp; We'll see how the Wiki develops (especially once my old posts are imported which should happen Any Time Now).</p>\n<p>Now, while I'm on semi-vacation, is a <em>good time</em> to have me <a href=\"http://yudkowsky.net/contact/speaking\">speak at your hedge fund</a>.&nbsp; If you wait until after I write a book and it comes out, then, if things go remotely well, it will cost you <em>a lot more money</em> to have me speak (because the marginal utility to me of additional money will have gone way down, and demand gone up).&nbsp; Right now, though, additional money <em>does</em> have substantial marginal utility to me.&nbsp; So those of you who work at the hedge funds who were rational enough to survive: please request me for your speaker programs.&nbsp; I'm told that I give a wonderful, amazing, etcetera talk for audiences interested in rationality, considerably more than twice as useful as talks from big-name speakers who cost considerably more than twice as much.</p>\n<p>If the rationality book is written, sold, and takes off, I may well vanish entirely off the face of the Earth, all purposes of publicity having already been served.&nbsp; That is the <em>optimal</em> and desirable outcome - it means I am allowed to <a href=\"/lw/65/money_the_unit_of_caring/\">specialize</a> narrowly.</p>\n<p>I would like to take this moment to confess, once again, that I have had ulterior motives in all this - as is <a href=\"http://www.overcomingbias.com/2008/01/something-to-pr.html\">right and proper</a> to a rationalist.&nbsp; It is not the pure service of rationality that diverted my focus here... though I have <a href=\"http://www.overcomingbias.com/2009/02/and-say-no-more-of-it.html\">served that overt cause as a thing in its own right</a>, with its own integrity.</p>\n<p>And <a href=\"/lw/66/rationality_common_interest_of_many_causes/\">I will not insist on recruiting <em>all </em>the rationalists that I create</a>...</p>\n<p>But still...</p>\n<p>In the end, these 21 months were wagered upon your active response, not your passive possession of truth.&nbsp; Even those of you who are not moved to <a href=\"/lw/65/money_the_unit_of_caring/\">care</a> about the thing that I protect, may still be moved to align their activities with <a href=\"http://seasteading.org/\">Seasteading</a>, or the <a href=\"http://www.methuselahfoundation.org/\">Methuselah Foundation</a>, or <a href=\"http://www.givewell.net/\">Givewell</a>, <a href=\"http://www.cryonics.org/\">or</a> <a href=\"http://www.alcor.org/\">cryonics</a>.&nbsp; And, perhaps, tell them that we sent you, so that they know that this \"rationality\" business is working to their favor; so that maybe <em>they</em> will say a thing or two about rationality.&nbsp; And someone who encounters the craft <em>there,</em> will read on it further, and eventually donate <a href=\"/lw/65/money_the_unit_of_caring/\">professionally specialized hours</a> (in one form or another) to the <a href=\"http://intelligence.org/\">Singularity Institute</a>.&nbsp; What goes around comes around, I hope.</p>\n<p>To the extent that you don't feel moved to <em>do</em> anything in particular - even include a link in your signature, or link to apposite posts now and then in your blog - then I have lost my gamble of these 21 months.&nbsp; Or I have lost that part of the stakes which was about you and decision processes similar to you.&nbsp; (No, that doesn't mean you should seize this opportunity to post about how I lost my gamble with you.&nbsp; <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">You should know better by now,</a> if you want <em>any</em> rationalist cause to get <em>anything</em> done <em>ever,</em> whether or not <em>you</em> are a part of it.)</p>\n<p>And this advice:&nbsp; If there is some rationalist cause you have decided to help <em>eventually</em>, I advise you very strongly to help that cause <em>now</em> - even if it's just a tiny amount.&nbsp; One of the regularities I have discovered, working in the nonprofit industry, is that people who donated last year donate the next year, and people who are planning to donate next year will, next year, still be planning to donate \"next year\".&nbsp; The gap between little helpers and big helpers is a lot more permeable than the membrane that separates helpers and procrastinators.&nbsp; This holds whether you would help my own cause, or any of the other causes that have <a href=\"/lw/66/rationality_common_interest_of_many_causes/\">rationality as their common interest</a>.</p>\n<p>As for why Earth needs <em>rational</em> activists in particular - I hope that by now this has become clear.&nbsp; In this fragile Earth there are many tasks which are underserved by irrational altruists.&nbsp; <a href=\"http://www.overcomingbias.com/2007/05/scope_insensiti.html\">Scope insensitivity and the purchase of moral satisfaction</a> leads people to donate to puppy pounds as easily as existential risk prevention; <a href=\"http://www.overcomingbias.com/2008/01/circular-altrui.html\">circular altruism</a> prevents them from going so far as to multiply utilons by probabilities; unsocialized in basic economics, they <a href=\"/lw/65/money_the_unit_of_caring/\">see money as a dirty thing inferior to volunteering unspecialized labor</a>; they try to <a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately/\">purchase warm fuzzies and status and utilons all at the same time</a>; they <a href=\"http://www.overcomingbias.com/2007/12/lonely-dissent.html\">feel nervous outside of conventional groups</a> and <a href=\"http://www.overcomingbias.com/2007/10/cached-thoughts.html\">follow the first thought that associates to \"charity\"</a>...</p>\n<p>And these are all very normal and human mistakes, to be sure - <a href=\"/lw/92/extenuating_circumstances/\">forgiveable in others, if not in yourself</a>.&nbsp; Nonetheless, I will advise you that a rationalist's efforts should not be wasted on causes that are already popular far outside of rationalist circles.&nbsp; There is nothing remotely approaching an efficient market in utilons.</p>\n<p>Is all this inclusiveness a pretense?&nbsp; Did I, in the end, gamble only upon the portion of the activism that would flow to my own cause?&nbsp; Yes, of course I did; that is how the calculation comes out when I shut up and multiply.</p>\n<p>But I have faithfully served the integrity of that pretense, because that inclusiveness matters to my own cause as well.</p>\n<p>So I say to you now, on behalf of <em>all </em>our causes:<em>&nbsp; Do,</em> whatever you may find worth doing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "izp6eeJJEg9v5zcur": 1, "Ng8Gice9KNkncxqcj": 1, "Xw6pxiicjuv6NJWjf": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9jF4zbZqz6DydJ5En", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 39, "extendedScore": null, "score": 6e-05, "legacy": true, "legacyId": "474", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 40, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YdcF6WbBmJhaaDqoD", "cDQFK7tPDo9H4nPSE", "ZpDnRCeef2CLEFeKM", "4PPE6D635iBcGPGRy", "7FzD7pNm9X68Gp5ZC", "3p3CYauiX8oLjmwRF", "XYrcTJFJoYKX2DxNL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-27T21:12:02.966Z", "modifiedAt": null, "url": null, "title": "Final Words", "slug": "final-words", "viewCount": null, "lastCommentedAt": "2022-05-03T23:35:20.644Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Eliezer_Yudkowsky", "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yffPyiu7hRLyc7r23/final-words", "pageUrlRelative": "/posts/yffPyiu7hRLyc7r23/final-words", "linkUrl": "https://www.lesswrong.com/posts/yffPyiu7hRLyc7r23/final-words", "postedAtFormatted": "Monday, April 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Final%20Words&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFinal%20Words%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyffPyiu7hRLyc7r23%2Ffinal-words%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Final%20Words%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyffPyiu7hRLyc7r23%2Ffinal-words", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyffPyiu7hRLyc7r23%2Ffinal-words", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2759, "htmlBody": "<p>Sunlight enriched air already alive with curiosity, as dawn rose on Brennan and his fellow students in the place to which Jeffreyssai had summoned them.</p>\n<p>They sat there and waited, the five, at the top of the great glassy crag that was sometimes called Mount Mirror, and more often simply left unnamed.&nbsp; The high top and peak of the mountain, from which you could see all the lands below and seas beyond.</p>\n<p>(Well, not <em>all</em> the lands below, nor seas beyond.&nbsp; So far as anyone knew, there was no place in the world from which all the world was visible; nor, equivalently, any kind of vision that would see through all obstacle-horizons.&nbsp; In the end it was the top only of one particular mountain: there were other peaks, and from their tops you would see other lands below; even though, in the end, it was all a single world.)</p>\n<p>\"What do you think comes next?\" said Hiriwa.&nbsp; Her eyes were bright, and she gazed to the far horizons like a lord.</p>\n<p>Taji shrugged, though his own eyes were alive with anticipation.&nbsp; \"Jeffreyssai's last lesson doesn't have any obvious sequel that I can think of.&nbsp; In fact, I think we've learned just about everything that I knew the <em>beisutsukai</em> masters know.&nbsp; What's left, then -\"</p>\n<p>\"Are the <em>real</em> secrets,\" Yin completed the thought.</p>\n<p>Hiriwa and Taji and Yin shared a grin, among themselves.</p>\n<p>Styrlyn wasn't smiling.&nbsp; Brennan suspected rather strongly that Styrlyn was older than he had admitted.</p>\n<p>Brennan wasn't smiling either.&nbsp; He might be young, but he kept high company, and had witnesssed some of what went on behind the curtains of the world.&nbsp; Secrets had their price, always, that was the barrier that made them secrets; and Brennan thought he had a good idea of what this price might be.</p>\n<p><a id=\"more\"></a></p>\n<p>There was a cough from behind them, at a moment when they had all happened to be looking in any other direction but that one.</p>\n<p>As one, their heads turned.</p>\n<p>Jeffreyssai stood there, in a casual robe that looked more like glass than any proper sort of mirrorweave.</p>\n<p>Jeffreyssai stood there and looked at them, a strange abiding sorrow in those inscrutable eyes.</p>\n<p>\"Sen...sei,\" Taji started, faltering as that bright anticipation stumbled over Jeffreyssai's return look.&nbsp; \"What's next?\"</p>\n<p>\"Nothing,\" Jeffreyssai said abruptly.&nbsp; \"You're finished.&nbsp; It's done.\"</p>\n<p>Hiriwa, Taji, and Yin all blinked, a perfect synchronized gesture of shock.&nbsp; Then, before their expressions could turn to outrage and objections -</p>\n<p>\"Don't,\" Jeffreyssai said.&nbsp; There was real pain in it.&nbsp; \"Believe me, it hurts me more than it hurts you.\"&nbsp; He might have been looking at them; or at something far away, or long ago.&nbsp; \"I don't know exactly what roads may lie before you - but yes, I know that you're not ready. &nbsp;That&nbsp;I'm sending you out unprepared. &nbsp;That everything I taught you is incomplete.&nbsp; I know that what I said is not what you heard.&nbsp; That I left out the one most important thing.&nbsp; That the rhythm at the center of everything is missing and astray.&nbsp; I know that you will harm yourself in the course of trying to use what I taught. &nbsp;So that I, personally, will have shaped, in some fashion unknown to me, the very knife that will cut you...\"</p>\n<p>\"...that's the hell of being a teacher, you see,\" Jeffreyssai said.&nbsp; Something grim flickered in his expression.&nbsp; \"Nonetheless, you're <em>done</em>.&nbsp; Finished, for now.&nbsp; What lies between you and mastery is not another classroom.&nbsp; We are fortunate, or perhaps not fortunate, that the road to power does not wend only through lecture halls.&nbsp; Else the quest would be boring to the bitter end.&nbsp; Still, I <em>cannot </em>teach you; and so it is a moot point whether I would if I could.&nbsp; There is no master here whose art is entirely inherited.&nbsp; Even the <em>beisutsukai</em> have never discovered how to teach certain things; it is possible that such an event has been prohibited.&nbsp; And so you can only arrive at mastery by using to the fullest the techniques you have already learned, facing challenges and apprehending them, mastering the tools you have been taught <em>until they shatter in your hands -</em>\"</p>\n<p>Jeffreyssai's eyes were hard, as though steeled in acceptance of unwelcome news.</p>\n<p>\"- and you are left in the midst of wreckage absolute.&nbsp; That is where I, your teacher, am sending you.&nbsp; You are not <em>beisutsukai</em> masters.&nbsp; I cannot create masters. &nbsp;I have never known how to create masters. &nbsp;Go forth, then, and fail.\"</p>\n<p>\"But -\" said Yin, and stopped herself.</p>\n<p>\"Speak,\" said Jeffreyssai.</p>\n<p>\"But then why,\" she said, \"why teach us anything in the first place?\"</p>\n<p>Brennan's eyelids flickered some tiny amount.</p>\n<p>It was enough for Jeffreyssai.&nbsp; \"Answer her, Brennan, if you think you know.\"</p>\n<p>\"Because,\" Brennan said, \"if we were not taught, there would be no chance at all of our becoming masters.\"</p>\n<p>\"Even so,\" said Jeffreyssai.&nbsp; \"If you were not taught - then when you failed, you might simply think you had reached the limits of Reason itself.&nbsp; You would be discouraged and bitter within your disaster.&nbsp; You might not even realize when you had failed.&nbsp; No; you have been shaped into something that may emerge from the wreckage, determined to remake your Art.&nbsp; And then you may remember much that will help you.&nbsp; I cannot create masters, but if you had not been taught, your chances would be - less.\"&nbsp; His gaze passed over the group.&nbsp; \"It should be obvious, but understand that you cannot provoke the moment of your crisis artificially.&nbsp; To teach you something, the catastrophe must come to you as a surprise. You must go as far as you can, as best you can, and fail honestly. &nbsp;The higher road begins after the Art seems to fail you; though the reality will be that it was you who failed your Art.\"</p>\n<p>Brennan made the gesture with his hand that indicated a question; and Jeffreyssai nodded in reply.</p>\n<p>\"Is this the only way in which Bayesian masters come to be, sensei?\"</p>\n<p>\"I do not know,\" said Jeffreyssai, from which the overall state of the evidence was obvious enough.&nbsp; \"But I doubt there would ever be a road to mastery that goes only through the monastery.&nbsp; We are the heirs in this world of mystics as well as scientists, just as the Competitive Conspiracy inherits from chessplayers alongside cagefighters.&nbsp; We have turned our impulses to more constructive uses - but we must still stay on our guard against old failure modes.\"</p>\n<p>Jeffreyssai took a breath.&nbsp; \"Three flaws above all are common among the <em>beisutsukai.</em>&nbsp; The first flaw is to look just the slightest bit harder for flaws in arguments whose conclusions you would rather not accept.&nbsp; If you cannot contain this aspect of yourself then every flaw you know how to detect will make you that much stupider.&nbsp; This is the challenge which determines whether you possess the art or its opposite:&nbsp; Intelligence, to be useful, must be used for something other than defeating itself.\"</p>\n<p>\"The second flaw is cleverness.&nbsp; To invent great complicated plans and great complicated theories and great complicated arguments - or even, perhaps, plans and theories and arguments which are commended too much by their elegance and too little by their realism.&nbsp; There is a widespread saying which runs:&nbsp; 'The vulnerability of the <em>beisutsukai</em> is well-known; they are prone to be too clever.'&nbsp; Your enemies will know this saying, if they know you for a <em>beisutsukai,</em> so <em>you </em>had best remember it also.&nbsp; And you may think to yourself:&nbsp; 'But if I could never try anything clever or elegant, would my life even be worth living?'&nbsp; This is why cleverness is still our chief vulnerability even after its being well-known, like offering a Competitor a challenge that seems fair, or tempting a Bard with drama.\"</p>\n<p>\"The third flaw is underconfidence, though it will seem to you like modesty or humility.&nbsp; You have learned so many flaws in your own nature, some of them impossible to fix, that you may think that the rule of wisdom is to confess your own inability.&nbsp; You may question yourself, without resolution or testing to determine the self-answers. &nbsp;You may refuse to decide, pending further evidence, when a quick decision is necessary. &nbsp;You may take advice you should not take.&nbsp; Jaded cynicism and sage despair are less fashionable than once they were, but you may still be tempted by them.&nbsp; Or you may simply - lose momentum.\"</p>\n<p>Jeffreyssai fell silent then.</p>\n<p>He looked from each of them, one to the other, with quiet intensity.</p>\n<p>And said at last, \"Those are my final words to you.&nbsp; If and when we meet next, you and I - if and when you return to this place, Brennan, or Hiriwa, or Taji, or Yin, or Styrlyn - I will no longer be your teacher.\"</p>\n<p>And Jeffreyssai turned and walked swiftly away, heading back toward the glassy tunnel that had emitted him.</p>\n<p>Even Brennan was shocked.&nbsp; For a moment they were all speechless.</p>\n<p>Then -</p>\n<p>\"Wait!\" cried Hiriwa.&nbsp; \"What about our final words to you?&nbsp; I never said -\"</p>\n<p>\"I will tell you what my <em>sensei</em> told me,\" Jeffreyssai's voice came back as he disappeared.&nbsp; \"You can thank me after you return, if you return.&nbsp; One of you at least seems likely to come back.\"</p>\n<p>\"No, wait, I -\"&nbsp; Hiriwa fell silent.&nbsp; In the mirrored tunnel, the fractured reflections of Jeffreyssai were already fading.&nbsp; She shook her head.&nbsp; \"Never... mind, then.\"</p>\n<p>There was a brief, uncomfortable silence, as the five of them looked at each other.</p>\n<p>\"Good heavens,\" Taji said finally.&nbsp; \"Even the Bardic Conspiracy wouldn't try for that much drama.\"</p>\n<p>Yin suddenly laughed.&nbsp; \"Oh, this was nothing.&nbsp; You should have seen my send-off when I left Diamond Sea University.\"&nbsp; She smiled.&nbsp; \"I'll tell you about it sometime - if you're interested.\"</p>\n<p>Taji coughed.&nbsp; \"I suppose I should go back and... pack my things...\"</p>\n<p>\"I'm already packed,\" Brennan said.&nbsp; He smiled, ever so slightly, when the other three turned to look at him.</p>\n<p>\"Really?\" Taji asked.&nbsp; \"What was the clue?\"</p>\n<p>Brennan shrugged with artful carelessness.&nbsp; \"Beyond a certain point, it is futile to inquire how a <em>beisutsukai</em> master knows a thing -\"</p>\n<p>\"Come off it!<em></em>\" Yin said.&nbsp; \"You're not a <em>beisutsukai </em>master <em>yet.</em>\"</p>\n<p>\"Neither is Styrlyn,\" Brennan said.&nbsp; \"But he has already packed as well.\"&nbsp; He made it a statement rather than a question, betting double or nothing on his image of inscrutable foreknowledge.</p>\n<p>Styrlyn cleared his throat.&nbsp; \"As you say.&nbsp; Other commitments call me, and I have already tarried longer than I planned.&nbsp; Though, Brennan, I do feel that you and I have certain mutual interests, which I would be happy to discuss with you -\"</p>\n<p>\"Styrlyn, my most excellent friend, I shall be happy to speak with you on any topic you desire,\" Brennan said politely and noncommitally, \"if we should meet again.\"&nbsp; As in, not now.&nbsp; He certainly wasn't selling out his Mistress this early in their relationship.</p>\n<p>There was an exchange of goodbyes, and of hints and offers.</p>\n<p>And then Brennan was walking down the road that led toward or away from Mount Mirror (for every road is a two-edged sword), the glassy pebbles clicking under his feet.</p>\n<p>He strode out along the path with purpose, vigor, and determination, just in case someone was watching.</p>\n<p>Some time later he stopped, stepped off the path, and moved just far enough away to prevent anyone from finding him unless they were deliberately following.</p>\n<p>Then Brennan sagged back against a tree-trunk.&nbsp; It was a sparse clearing, with only a few trees poking out of the ground; not much present in the way of distracting scenery, unless you counted the red-tinted stream flowing out of a dark cave-mouth.&nbsp; And Brennan deliberately faced away from that, leaving only the far grey of the horizons, and the blue sky and bright sun.</p>\n<p><em>Now what?</em></p>\n<p>He had thought that the Bayesian Conspiracy, of all the possible trainings that existed in this world, would have cleared up his uncertainty about what to do with the rest of his life.</p>\n<p>Power, he'd sought at first.&nbsp; Strength to prevent a repetition of the past.&nbsp; \"If you don't know what you need, take power\" - so went the proverb.&nbsp; He had gone first to the Competitive Conspiracy, then to the <em>beisutsukai.</em></p>\n<p>And now...</p>\n<p>Now he felt more lost than ever.</p>\n<p>He could think of things that made him happy, but nothing that he really <em>wanted.</em></p>\n<p>The passionate intensity that he'd come to associate with his Mistress, or with Jeffreyssai, or the other figures of power that he'd met... a life of pursuing small pleasures seemed to pale in comparison, next to that.</p>\n<p>In a city not far from the center of the world, his Mistress waited for him (in all probability, assuming she hadn't gotten bored with her life and run away).&nbsp; But to merely return, and then drift aimlessly, waiting to fall into someone else's web of intrigue... no.&nbsp; That didn't seem like&nbsp;enough.</p>\n<p>Brennan plucked a blade of grass from the ground and stared at it, half-unconsciously looking for anything interesting about it; an old, old game that his very first teacher had taught him, what now seemed like ages ago.</p>\n<p><em>Why did I believe that going to Mount Mirror would tell me what I wanted?</em></p>\n<p>Well, decision theory did require that your utility function be consistent, but...</p>\n<p><em>If the beisutsukai knew what I wanted, would they even tell me?</em></p>\n<p>At Mount Mirror they taught doubt.&nbsp; So now he was falling prey to the third besetting sin of which Jeffreyssai had spoken, lost momentum, for he had learned to question the image that he held of himself in his mind.</p>\n<p><em>Are you seeking power because that is your true desire, Brennan?</em></p>\n<p><em>Or because you have a picture in your mind, of the role </em><em>that you play as an ambitious young man, and you think it is what someone playing your role would do?</em></p>\n<p>Almost everything he'd done up until now, even going to Mount Mirror, had probably been the latter.</p>\n<p>And when he blanked out the old thoughts and tried to see the problem as though for the first time...</p>\n<p>...nothing much came to mind.</p>\n<p><em>What do I want?</em></p>\n<p>Maybe it wasn't reasonable to expect the <em>beisutsukai</em> to tell him outright.&nbsp; But was there anything they had taught him by which he might answer?</p>\n<p>Brennan closed his eyes and thought.</p>\n<p><em>First, suppose there is something I would passionately desire.&nbsp; Why would I not know what it is?</em></p>\n<p><em>Because I have not yet encountered it, or ever imagined it?</em></p>\n<p><em>Or because there is some reason I would not admit it to myself?</em></p>\n<p>Brennan laughed out loud, then, and opened his eyes.</p>\n<p>So simple, once you thought of it that way.&nbsp; So obvious in retrospect.&nbsp; <em>That </em>was what they called a silver-shoes moment, and yet, if he hadn't gone to Mount Mirror, it wouldn't ever have occurred to him.</p>\n<p>Of <em>course</em> there was something he wanted.&nbsp; He knew <em>exactly</em> what he wanted.&nbsp; Wanted so desperately he could taste it like an sharp tinge on his tongue.</p>\n<p>It just hadn't come to mind earlier, because... if he acknowledged his desire explicitly... then he also had to see that it was <em>difficult</em>.&nbsp; High, high, above him.&nbsp; Far out of his reach.&nbsp; \"Impossible\" was the word that came to mind, though it was not, of course, physically impossible.</p>\n<p>But once he asked himself if he preferred to wander aimlessly through his life - once it was put that way, the answer became obvious.&nbsp; Pursuing the unattainable would make for a hard life, but not a sad one.&nbsp; He could think of things that made him happy, either way.&nbsp; And in the end - it was what he wanted.</p>\n<p>Brennan stood up, and took his first steps, in the exact direction of Shir L'or, the city that lies in the center of the world.&nbsp; He had a plot to hatch, and he did not know who would be part of it.</p>\n<p>And then Brennan almost stumbled, when he realized that Jeffreyssai had already known.</p>\n<p><em>One of you at least seems likely to come back...</em></p>\n<p>Brennan had thought he was talking about Taji.&nbsp; Taji had probably thought he was talking about Taji.&nbsp; It was what Taji said he wanted.&nbsp; But how reliable of an indicator was that, really?</p>\n<p>There was a proverb about that very road he had just left:&nbsp; <em>Whoever sets out from Mount Mirror seeking the impossible, will surely return.<br /></em></p>\n<p>When you considered Jeffreyssai's last warning - and that the proverb said nothing of <em>succeeding </em>at the impossible task itself - it was a less optimistic saying than it sounded.</p>\n<p>Brennan shook his head wonderingly.&nbsp; How could Jeffreyssai possibly have known before Brennan knew himself?</p>\n<p>Well, beyond a certain point, it is futile to inquire how a <em>beisutsukai </em>master knows a thing -</p>\n<p>Brennan halted in mid-thought.</p>\n<p>No.</p>\n<p>No, if he was going to become a <em>beisutsukai</em> master himself someday, then he ought to figure it out.</p>\n<p>It was, Brennan realized, a <em>stupid</em> proverb.</p>\n<p>So he walked, and this time, he thought about it carefully.</p>\n<p>As the sun was setting, red-golden, shading his footsteps in light.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yffPyiu7hRLyc7r23", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 117, "baseScore": 159, "extendedScore": null, "score": 0.000241, "legacy": true, "legacyId": "453", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": "Rationality: A-Z", "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "3szfzHZr7EYGSWt92", "canonicalCollectionSlug": "rationality", "canonicalBookId": "e6WsPsivzBifrWHeA", "canonicalNextPostSlug": "raising-the-sanity-waterline", "canonicalPrevPostSlug": "shut-up-and-do-the-impossible", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 159, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 16, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-27T22:29:36.931Z", "modifiedAt": null, "url": null, "title": "Bayesian Cabaret", "slug": "bayesian-cabaret", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:05.943Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yPQGYn9rSme9RRpiQ/bayesian-cabaret", "pageUrlRelative": "/posts/yPQGYn9rSme9RRpiQ/bayesian-cabaret", "linkUrl": "https://www.lesswrong.com/posts/yPQGYn9rSme9RRpiQ/bayesian-cabaret", "postedAtFormatted": "Monday, April 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20Cabaret&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20Cabaret%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyPQGYn9rSme9RRpiQ%2Fbayesian-cabaret%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20Cabaret%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyPQGYn9rSme9RRpiQ%2Fbayesian-cabaret", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyPQGYn9rSme9RRpiQ%2Fbayesian-cabaret", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 112, "htmlBody": "<p>I'd heard rumors that <a href=\"/lw/cn/instrumental_vs_epistemic_a_bardic_perspective/9nu\">some leading Bayesians had achieved rank in the Bardic Conspiracy</a>. But I wasn't aware that every two years, some of the world's top statisticians hold a Bayesian Cabaret, full of songs, dances, and skits about Bayesian probability theory.<br /><br />...no, really. Really. I think <a href=\"http://www.youtube.com/watch?v=t6jFFlz9o-E\">my favorite has got to be this one</a>.<br /><br />YouTube seems to be full of <a href=\"http://www.youtube.com/user/LindsayRenfro\">this</a> <a href=\"http://www.youtube.com/profile?user=BradleyPCarlin&amp;view=videos\">stuff</a>, including <a href=\"http://www.youtube.com/watch?v=v7BIsXQpPaU\">What A Bayesian World</a> and <a href=\"http://www.youtube.com/watch?v=ebiVF1OYXeo&amp;feature=related\">We Didn't Start The Prior</a>. Be sure to also check out some of <a href=\"http://math.bu.edu/people/mg/music.html\">the recordings</a> and the <a href=\"http://www.biostat.umn.edu/~brad/cabaret.html\">Bayesian Songbook</a>.<br /><br />Eliezer's finished his sequences, and it's a new era for Less Wrong. Let's celebrate...Bayesian style!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"KDpqtN3MxHSmD4vcB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yPQGYn9rSme9RRpiQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 25, "extendedScore": null, "score": 4.90590469094822e-07, "legacy": true, "legacyId": "486", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-27T23:39:34.940Z", "modifiedAt": null, "url": null, "title": "Verbal Overshadowing and The Art of Rationality", "slug": "verbal-overshadowing-and-the-art-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:25.588Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pangloss", "createdAt": "2009-04-20T05:08:16.073Z", "isAdmin": false, "displayName": "pangloss"}, "userId": "X7FKa3G58CKsYMjkL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sfyCj4fSWzNvYmdTR/verbal-overshadowing-and-the-art-of-rationality", "pageUrlRelative": "/posts/sfyCj4fSWzNvYmdTR/verbal-overshadowing-and-the-art-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/sfyCj4fSWzNvYmdTR/verbal-overshadowing-and-the-art-of-rationality", "postedAtFormatted": "Monday, April 27th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Verbal%20Overshadowing%20and%20The%20Art%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVerbal%20Overshadowing%20and%20The%20Art%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsfyCj4fSWzNvYmdTR%2Fverbal-overshadowing-and-the-art-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Verbal%20Overshadowing%20and%20The%20Art%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsfyCj4fSWzNvYmdTR%2Fverbal-overshadowing-and-the-art-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsfyCj4fSWzNvYmdTR%2Fverbal-overshadowing-and-the-art-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 964, "htmlBody": "<p>To begin, here are some Fun Psychology Facts: &nbsp;</p>\n<p>People who were asked to describe a face after seeing it are <a href=\"http://memlab1.eng.yale.edu/PDFs/1997_Dodson_Johnson_Schooler_MemCog.pdf\" target=\"_blank\">worse at recognizing the same face later</a>.</p>\n<p>People who are asked to describe a wine after drinking it are <a href=\"http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6WK4-45MG3M1-1D&amp;_user=10&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_sort=d&amp;view=c&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=c59a36f1073db86eef563a21afb5d717\" target=\"_blank\">worse at recognizing the same wine later</a>.</p>\n<p>People who are asked to give reasons for their preferences among a collection of jellies <span style=\"font-weight: bold;\">are worse at </span><span style=\"font-weight: bold;\">identifying their own preferences </span>among those jellies.</p>\n<p>&nbsp;</p>\n<p>This effect, known as Verbal Overshadowing, occurs primarily when a principally non-verbal process is disrupted by a task which involves verbalization. &nbsp;The above generalizations (and Verbal Overshadowing effects more generally), do not occur among what we can term \"Verbal Experts\": individuals who are as good at verbalizing the relevant process as they are at doing it implicitly or automatically. &nbsp;This seems like it will be very important to keep in mind when cultivating our own Rationality.</p>\n<p><a id=\"more\"></a></p>\n<p>Here's an oversimplified picture of what this means: &nbsp;We've got an implicit facial recognition process, IFRP, which is pretty good. &nbsp;We've also got a generalized explicit verbal thinking process, GEVTP, which is good for lots of things, but isn't especially good at recognizing faces. &nbsp;Normally, IFRP is in charge of facial recognition, but there are some things we can do, like, trying to put a face into words, that wakes up GEVTP, which then muscles IFRP out of the way, and all of a sudden, we are a lot worse at recognizing faces.</p>\n<p>The good news is that GEVTP can be trained. &nbsp;To take the wine case, people who put in the time and effort can become verbal experts about wine. &nbsp;This isn't to say they automatically have better judgments about wine. &nbsp;Rather, it means that their GEVTP is on par with their implicit wine recognition, because it has been trained to do the same quality job as the the implicit process.</p>\n<p>As a crude metaphor, imagine the difference between the natural process by which you go about walking, versus having to keep track of each and every instruction that needs to be sent to different joints and muscles if you had to consciously issue each one.</p>\n<p>Now, obviously the specific studies mentioned are important for wine tasting, eye-witness identification, or determining one's own jelly preferences, but the phenomenon of Verbal Overshadowing has a much larger, more systematic importance for th Art of Rationality.</p>\n<p>Let's bridge to the broader point with a quote from David Hume, a man whose insights were often far ahead of their time: \"I shall add [...] that, as this operation of the mind, by which we infer like effects from like causes, and vice versa, is so essential to the subsistence of all human creatures, it is not probable, that it could be trusted to the fallacious deductions of our reason, which is slow in its operations; appears not, in any degree, during the first years of infancy; and at best is, in every age and period of human life, extremely liable to error and mistake. It is more conformable to the ordinary wisdom of nature to secure so necessary an act of the mind, by some instinct or mechanical tendency, which may be infallible in its operations, may discover itself at the first appearance of life and thought, and may be independent of all the laboured deductions of the understanding. As nature has taught us the use of our limbs, without giving us the knowledge of the muscles and nerves, by which they are actuated; so has she implanted in us an instinct, which carries forward the thought in a correspondent course to that which she has established among external objects; though we are ignorant of those powers and forces, on which this regular course and succession of objects totally depends.\"</p>\n<p>In short, Hume is saying, in the field of inference and reasoning, our Implicit Reasoning Process often outpaces our GEVTP. &nbsp;I'm not suggesting that our implicit reasoning is perfect (it is, after all, fraught with its own biases), but, supposing that Verbal Overshadowing is a general phenomenon, it would appear that, with respect to our reasoning and inferences more generally, our situation is one in which trying to talk about what we are doing is liable to mess us up.</p>\n<p>The obvious suggestion, then, is that we become verbal experts on the subject, so that our thinking about rationality doesn't mess up our thinking rationally.</p>\n<p>\"Aha,\" I hear you all say, \"then your advice is unnecessary, for what is it that we Rationalists are already doing, if not training ourselves to think explicitly about rationality?\" &nbsp;And that would be a good reply, but for one crucial fact: we are not training ourselves correctly to become verbal experts.</p>\n<p>One does not become a verbal expert about wine by tasting only strange vintages or the wine of abnormal grapes. &nbsp;One does not become a verbal expert about facial recognition by practicing only on the stunningly gorgeous or the hideously deformed. &nbsp;And likewise, one does not become a verbal expert on Rational thinking by focusing on the edge cases (i.e. The Epistemic Prisoner's dilemmas, The Gettier Cases, The High Stakes scenarios, etc.). &nbsp;Verbal Experts get trained, primarily, on the paradigms.</p>\n<p>In fact, the studies on <a href=\"http://iilab.utep.edu/reprints/Science_News_4.19.03.pdf\" target=\"_blank\">Insight Puzzles</a> in particular (i.e. verbal overshadowing with respect to explaining the actual process by which one achieved the solution to a problem), suggest that those of us who engage in verbalization tasks relating to our reasoning and inferences (say, those of us dedicating a lot of time and energy to writing posts or comments about it), had better figure out how to train our Generalized Explicit Verbal Thinking Process not to drop the ball when it comes to thinking about reasoning.</p>\n<p>I am not a psychologist, but I do know that our current plan (of, for example, thinking about the brainteaser cases), is definitely not the way to develop actual expertise.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zQw5d37qwzdpgQs5P": 1, "dBPou4ihoQNY4cquv": 1, "4R8JYu4QF2FqzJxE5": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sfyCj4fSWzNvYmdTR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 70, "baseScore": 69, "extendedScore": null, "score": 0.000118, "legacy": true, "legacyId": "489", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 69, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-28T00:23:24.171Z", "modifiedAt": null, "url": null, "title": "How Not to be Stupid: Starting Up", "slug": "how-not-to-be-stupid-starting-up", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:46.682Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yn2mF9Y7fDywvR8tz/how-not-to-be-stupid-starting-up", "pageUrlRelative": "/posts/yn2mF9Y7fDywvR8tz/how-not-to-be-stupid-starting-up", "linkUrl": "https://www.lesswrong.com/posts/yn2mF9Y7fDywvR8tz/how-not-to-be-stupid-starting-up", "postedAtFormatted": "Tuesday, April 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Not%20to%20be%20Stupid%3A%20Starting%20Up&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Not%20to%20be%20Stupid%3A%20Starting%20Up%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyn2mF9Y7fDywvR8tz%2Fhow-not-to-be-stupid-starting-up%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Not%20to%20be%20Stupid%3A%20Starting%20Up%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyn2mF9Y7fDywvR8tz%2Fhow-not-to-be-stupid-starting-up", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyn2mF9Y7fDywvR8tz%2Fhow-not-to-be-stupid-starting-up", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 296, "htmlBody": "<p>First, don't <a href=\"http://www.youtube.com/watch?v=zekiZYSVdeQ\">stand up</a>. ;)</p>\n<p>Okay. So what I'm hoping to do in this mini sequence is to introduce a basic argument for Bayesian Decision Theory and epistemic probabilities. I'm going to be basing it on dutch book arguments and Dr. Omohundro's vulnerability based argument, however with various details filled in because, well... I myself had to sit and think about those things, so maybe it would be useful to others too. For that matter, actually writing this up will hopefully sort out my thoughts on this.</p>\n<p>Also, I want to try to generalize it a bit to remove the explicit dependancy of the arguments on resources. (Though I may include arguments from that to illustrate some of the ideas.)</p>\n<p>Anyways, the spirit of the idea is \"don't be stupid.\" \"Don't <span style=\"font-weight: bold;\">AUTOMATICALLY</span> lose when there's a better alternative that doesn't risk you losing even worse.\"</p>\n<p>More to the point, repeated application of that idea is going to let us build up the mathematics of decision theory. My plan right now is for each of the posts in this sequence to be relatively short, discussing and deriving one principle or (a couple of related principles) of decision theory and bayesian probability at a time from the above. The math should be pretty simple, with the very worst being potentially a tiny bit of linear algebra. I expect the nastiest bit of math will be one instance of matrix reduction down the line. Everything else ought to be rather straightforward, showing the mathematics of decision theory to be a matter of, as Mr. Smith would say, \"inevitability.\"</p>\n<p>Consider this whole sequence a work in progress. If anyone thinks any partcular bits of it could be rewritted more clearly, please speak up! Or at least type up. (But of course, don't stand up. ;))</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dJ6eJxJrCEget7Wb6": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yn2mF9Y7fDywvR8tz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "488", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-28T01:11:46.326Z", "modifiedAt": null, "url": null, "title": "How Not to be Stupid: Know What You Want, What You Really Really Want", "slug": "how-not-to-be-stupid-know-what-you-want-what-you-really", "viewCount": null, "lastCommentedAt": "2017-06-17T03:52:23.474Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H6d6Be4MzRxvz9eZT/how-not-to-be-stupid-know-what-you-want-what-you-really", "pageUrlRelative": "/posts/H6d6Be4MzRxvz9eZT/how-not-to-be-stupid-know-what-you-want-what-you-really", "linkUrl": "https://www.lesswrong.com/posts/H6d6Be4MzRxvz9eZT/how-not-to-be-stupid-know-what-you-want-what-you-really", "postedAtFormatted": "Tuesday, April 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Not%20to%20be%20Stupid%3A%20Know%20What%20You%20Want%2C%20What%20You%20Really%20Really%20Want&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Not%20to%20be%20Stupid%3A%20Know%20What%20You%20Want%2C%20What%20You%20Really%20Really%20Want%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH6d6Be4MzRxvz9eZT%2Fhow-not-to-be-stupid-know-what-you-want-what-you-really%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Not%20to%20be%20Stupid%3A%20Know%20What%20You%20Want%2C%20What%20You%20Really%20Really%20Want%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH6d6Be4MzRxvz9eZT%2Fhow-not-to-be-stupid-know-what-you-want-what-you-really", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH6d6Be4MzRxvz9eZT%2Fhow-not-to-be-stupid-know-what-you-want-what-you-really", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1322, "htmlBody": "<p>Previously: <a href=\"/lw/dk/how_not_to_be_stupid_starting_up/\">Starting Up</a></p>\n<p>So, you want to be rational, huh? You want to be Less Wrong than you were before, hrmmm? First you must pass through the posting titles of a thousand groans. Muhahahahaha!</p>\n<p>Let's start with the idea of preference rankings. &nbsp;If you prefer A to B, well, given the choice between A and B, you'd choose A.</p>\n<p>For example, if you face a choice between a random child being tortured to death vs them leading a happy and healthy life, all else being equal and the choice costing you nothing, which do you choose?</p>\n<p>This isn't a trick question. If you're a perfectly ordinary human, you presumably prefer the latter to the former.</p>\n<p>Therefore you choose it. That's what it means to prefer something. That if you prefer A over B, you'd give up situation B to gain situation A. You want situation A more than you want situation B.</p>\n<p>Now, if there're many possibilities, you may ask... \"But, what if I prefer B to A, C to B, and A to C?\"</p>\n<p>The answer, of course, is that you're a bit confused about what you actually prefer. I mean, all that ranking would do is just keep you switching between those, looping around.<a id=\"more\"></a></p>\n<p>And if thinking in terms of resources, the universe or an opponent or whatever could, for a small price, sell each of those to you in sequence, draining you of the resource (time, money, whatever) as you go around the vortex of confused desires.</p>\n<p>This, of course, translates more precisely into a sequence of states, Ai, Bi, Ci, and preferences of the form A0 &lt; B1 &lt; C2 &lt; A3 &lt; B4 ... where each one of those is the same as the original name except you also have a drop less of the relevant resource as you did before. ie, indicating a willingness to pay the price. If the sequence keeps going all the way, then you'll be drained, and that's a rather inefficient way of going about it if you just want to give the relevant resource up, no? ;)</p>\n<p>Still, a strict loop, A &gt; B, B &gt; C, C &gt; A really is an indication that you just don't know what you want. I'll just dismiss that at this point as \"not really what I'd call preferences\" as such.</p>\n<p>Note, however, that it's perfectly okay to have some states of reality, histories of the entire universe, whatever, such that A, B, and C are all ranked equally in your preferences.</p>\n<p>If you, however, say something like \"I don't prefer A less than B, nor more than B, nor equally to B\", I'm just going to give you a very stern look until you realize you're rather confused. (note, ranking two things equally doesn't mean you are incapable of distinguishing them. Also, what you want may be a function of multiple variables that may end up translate to something like \"in this instance I want X, though in that other instance I would have wanted Y.\" This is perfectly acceptable as long as the overal ranking properties (and other rules) are being followed. That is, as long as you're Not Being Stupid.)</p>\n<p>Let's suppose there're two states A and B that for you fall under this relative preference nonpreference zone.&nbsp;Let's further suppose that somehow the universe ends up presenting you with a situation in which you have to choose between them.</p>\n<p>What do you do? When it actually comes down to it, so that your options are \"choose A, choose B, or something else does the deciding.\" (either coin flip, or someone else who's willing to choose between them, or basically some something other than you.)</p>\n<p>If you can say \"if pressed, I'd have to choose... A\", then in the end, you have ranked one above the other. If you choose option 3, then basically you're saying \"I know it's going to be one or the other, but I don't want to be the one making that choice.\" Which could be interpreted as either indifferent or at least _sufficiently_ indifferent that the (emotional or whatever) cost to you of you yourself directly making that choice is much greater.</p>\n<p>At that point, if you say to me \"nope, I still neither prefer A to B, prefer B to A, nor am indifferent to the choice. It's simply not meaningful for my preferences to state any relative ranking, even equal\", well, I would be at that point rather confused as to what it is that you even meant by that statement. If in the above situation you would actually choose one of A or B, then clearly you have a relative ranking for them. If you went by the third option, and state that you're not indifferent to them, but prefer neither to the other, well, I honestly don't know what you would mean then.&nbsp;It at least <span style=\"font-style: italic;\">seems</span>&nbsp;to me at this point that such thought would be more a confusion than anything else. Or, at least, that at that point it isn't even what I think I or most other people mean by \"preferences.\" So I'm just going to declare this as the \"Hey everyone, look, here's the weakest point I think I can find so far, even though it doesn't seem like all that weak a weak point to me.\"</p>\n<p>So, for now, I'm going to move on and assume that preferences will be of the form A &lt; B &lt; C &lt; D, E, F, G &lt; H, I &lt; J &lt; K (assuming all states are comparable, \"Don't Be Stupid\" does actually seem to imply rejection of cycles.)</p>\n<p>For convinience, let's introduce a notion of numerically representing these rankings. The rule simply is this: If you rank two things the same, assign them the same real number. If you rank something B higher than A, then assign B a higher number than A. (Why real numbers? Well, we've got an ordering here. Complex numbers aren't going to be helping at all, so real numbers are perhaps the most general useful way of doing this.)</p>\n<p>For any particular preference ranking, there's obviously many valid ways of numerically representing it given the above rules. Further, one can always use a strictly increasing function to translate between any of those. And there will be an inverse, so you can translate back to your prefered encoding.</p>\n<p>(A strictly increasing function is, well, exactly what it sounds like. If x &gt; y, f(x) &gt; f(y). Try to visualize this. It never changes direction, never doubles back on itself. So there's always an inverse, for every output, there's always a unique input. So later on. when I start focusing on indexings of the preferences that has specific mathematical properties, no generality is lost. One can always translate into another numerical coding for the preferences, and then back again.)</p>\n<p>A few words of warning though: While this preference ranking thing is the ideal, any simple rule for generating the ranking is not going to reproduce your preferences, your morality, your desires. Your preferences are <a href=\"http://www.overcomingbias.com/2007/11/not-for-the-sak.html\">complex</a>. Best to instead figure out what you want in specific cases. In conflicting decisions, query yourself, see which deeper principles \"seem right\", and extrapolate from there. But any simple rule for generating your own One True Preference Ranking is simply <a href=\"http://www.overcomingbias.com/2007/12/fake-utility-fu.html\">going to be wrong</a>. (Don't worry about what a \"utility function\" is exactly yet. I'll get to that later. For now, all you need to know is that it's one of those numerical encodings of preferences that has certain useful mathematical properties.)</p>\n<p>&nbsp;</p>\n<p>(EDIT: added in the example of how lack of having a single ranking for all preferences can lead to Being Stupid)</p>\n<p>(EDIT2: (4/29/2009) okay, so I was wrong thinking that I've shown \"don't be stupid\" (in the sense used in this sequence) prohibits uncomparable states. (That is, preference functions that can, when input two states, output \"invalid pair\" rather than \"&gt;\" \"&lt;\" or \"=\". I've removed that argument and replaced it with a discussion that I think gets more to the heart of that matter.))</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H6d6Be4MzRxvz9eZT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 2, "extendedScore": null, "score": 2e-06, "legacy": true, "legacyId": "490", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yn2mF9Y7fDywvR8tz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-28T03:12:55.675Z", "modifiedAt": null, "url": null, "title": "Epistemic vs. Instrumental Rationality: Approximations", "slug": "epistemic-vs-instrumental-rationality-approximations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:05.953Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Peter_de_Blanc", "createdAt": "2009-02-27T14:15:28.882Z", "isAdmin": false, "displayName": "Peter_de_Blanc"}, "userId": "vRvaAqR5tcjGEWaoC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dMzALgLJk4JiPjSBg/epistemic-vs-instrumental-rationality-approximations", "pageUrlRelative": "/posts/dMzALgLJk4JiPjSBg/epistemic-vs-instrumental-rationality-approximations", "linkUrl": "https://www.lesswrong.com/posts/dMzALgLJk4JiPjSBg/epistemic-vs-instrumental-rationality-approximations", "postedAtFormatted": "Tuesday, April 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Epistemic%20vs.%20Instrumental%20Rationality%3A%20Approximations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEpistemic%20vs.%20Instrumental%20Rationality%3A%20Approximations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMzALgLJk4JiPjSBg%2Fepistemic-vs-instrumental-rationality-approximations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Epistemic%20vs.%20Instrumental%20Rationality%3A%20Approximations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMzALgLJk4JiPjSBg%2Fepistemic-vs-instrumental-rationality-approximations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMzALgLJk4JiPjSBg%2Fepistemic-vs-instrumental-rationality-approximations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 333, "htmlBody": "<p>What is the probability that my apartment will be struck by a meteorite tomorrow? Based on the information I have, I might say something like 10<sup>-18</sup>. Now suppose I wanted to approximate that probability with a different number. Which is a better approximation: 0 or 1/2?</p>\n<p>The answer depends on what we mean by \"better,\" and this is a situation where epistemic (truthseeking) and instrumental&nbsp;(useful) rationality will disagree.</p>\n<p>As an epistemic rationalist, I would say that 1/2 is a better approximation than 0, because the <a title=\"Kullback-Leibler Divergence\" href=\"http://en.wikipedia.org/wiki/Kullback-leibler_divergence\">Kullback-Leibler Divergence</a>&nbsp;is (about) 1 bit for the former, and infinity for the latter. This means that my expected Bayes Score drops by one bit if I use 1/2 instead of&nbsp;10<sup>-18</sup>, but it drops to minus infinity if I use 0, and any probability conditional on a meteorite striking my apartment would be undefined; if a meteorite did indeed strike, I would instantly fall to the lowest layer of <a title=\"A Technical Explanation of Technical Explanation\" href=\"http://yudkowsky.net/rational/technical\">Bayesian hell</a>. This is too horrible a fate to imagine, so I would have to go with a probability of 1/2.</p>\n<p>As an instrumental rationalist, I would say that 0 is a better approximation than 1/2. Even if a meteorite does strike my apartment, I will suffer only a finite amount of harm. If I'm still alive, I won't lose all of my powers as a predictor, even if I assigned a probability of 0; I will simply rationalize some other explanation for the destruction of my apartment. Assigning a probability of 1/2 would force me to actually plan for the meteorite strike, perhaps by moving all of my stuff out of the apartment. This is a totally unreasonable price to pay, so I would have to go with a probability of 0.</p>\n<p>I hope this can be a simple and uncontroversial example of the difference between epistemic and instrumental rationality. While the normative theory of probabilities is the same for any rationalist, the sorts of approximations a bounded rationalist would prefer can differ very much.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xgpBASEThXPuKRhbS": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dMzALgLJk4JiPjSBg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 29, "extendedScore": null, "score": 4.8e-05, "legacy": true, "legacyId": "491", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-28T09:25:48.139Z", "modifiedAt": null, "url": null, "title": "What is control theory, and why do you need to know about it?", "slug": "what-is-control-theory-and-why-do-you-need-to-know-about-it", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:26.917Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RichardKennaway", "createdAt": "2009-03-09T13:46:28.196Z", "isAdmin": false, "displayName": "RichardKennaway"}, "userId": "unnmqpwtrwhyDt6q5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fJKbCXrCPwAR5wjL8/what-is-control-theory-and-why-do-you-need-to-know-about-it", "pageUrlRelative": "/posts/fJKbCXrCPwAR5wjL8/what-is-control-theory-and-why-do-you-need-to-know-about-it", "linkUrl": "https://www.lesswrong.com/posts/fJKbCXrCPwAR5wjL8/what-is-control-theory-and-why-do-you-need-to-know-about-it", "postedAtFormatted": "Tuesday, April 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20is%20control%20theory%2C%20and%20why%20do%20you%20need%20to%20know%20about%20it%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20is%20control%20theory%2C%20and%20why%20do%20you%20need%20to%20know%20about%20it%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJKbCXrCPwAR5wjL8%2Fwhat-is-control-theory-and-why-do-you-need-to-know-about-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20is%20control%20theory%2C%20and%20why%20do%20you%20need%20to%20know%20about%20it%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJKbCXrCPwAR5wjL8%2Fwhat-is-control-theory-and-why-do-you-need-to-know-about-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJKbCXrCPwAR5wjL8%2Fwhat-is-control-theory-and-why-do-you-need-to-know-about-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2696, "htmlBody": "<p>This is long, but it's the shortest length I could cut from the material and have a complete thought.</p>\n<p><span style=\"font-weight: bold;\"><strong>1. Alien Space Bats have abducted you.</strong></span></p>\n<p>In the spirit of <a href=\"http://www.overcomingbias.com/2008/10/mundane-magic.html\">this posting</a>, I shall describe a magical power that some devices have. They have an intention, and certain means available to achieve that intention. They succeed in doing so, despite knowing almost nothing about the world outside. If you push on them, they push back. Their magic is not invincible: if you push hard enough, you may overwhelm them. But within their limits, they will push back against anything that would deflect them from their goal. And yet, they are not even aware that anything is opposing them. Nor do they act passively, like a nail holding something down, but instead they draw upon energy sources to actively apply whatever force is required. They do not know you are there, but they will struggle against you with all of their strength, precisely countering whatever you do. It seems that they have a sliver of that Ultimate Power of shaping reality, despite their almost complete ignorance of that reality. Just a sliver, not a whole beam, for their goals are generally simple and limited ones. But they pursue them relentlessly, and they absolutely will not stop until they are dead.</p>\n<p>You look inside one of these devices to see how it works, and imagine yourself doing the same task...</p>\n<blockquote>\n<p><span style=\"font-style: italic;\"><em>Alien Space Bats have abducted you. You find yourself in a sealed cell, featureless but for two devices on the wall. One seems to be some sort of meter with an unbreakable cover, the needle of which wanders over a scale marked off in units, but without any indication of what, if anything, it is measuring. There is a red blob at one point on the scale. The other device is a knob next to the meter, that you can turn. If you twiddle the knob at random, it seems to have some effect on the needle, but there is no fixed relationship. As you play with it, you realise that you very much want the needle to point to the red dot. Nothing else matters to you. Probably the ASBs' doing. But you do not know what moves the needle, and you do not know what turning the knob actually does. You know nothing of what lies outside the cell. There is only the needle, the red dot, and the knob. To make matters worse, the red dot also jumps along the scale from time to time, in no particular pattern, and nothing you do seems to have any effect on it. You don't know why, only that wherever it moves, you must keep the needle aligned with it.</em></span></p>\n<p><span style=\"font-style: italic;\"><em>Solve this problem.</em></span></p>\n</blockquote>\n<p>That is what it is like, to be one of these magical devices. They are actually commonplace: you can find them everywhere.</p>\n<p><a id=\"more\"></a>They are the thermostat that keeps your home at a constant temperature, the cruise control that keeps your car at a constant speed, the power supply that provides a constant voltage to your computer's circuit boards. The magical thing is how little they need to know to perform their tasks. They have just the needle, the mark on the scale, the knob, and hardwired into them, a rule for how to turn the knob based only on what they see the needle and the red dot do. They do not need to sense the disturbing forces, or predict the effects of their actions, or learn. The thermostat does not know when the sun comes out. The cruise control does not know the gradient of the road. The power supply does not know why or when the mains voltage or the current demand will change. They model nothing, they predict nothing, they learn nothing. They do not know what they are doing. But they work.</p>\n<p>These things are called control systems. A control system is a device for keeping a variable at a specified value, regardless of disturbing forces in its environment that would otherwise change it. It has two inputs, called the <span style=\"font-style: italic;\"><em>perception</em></span> and the <span style=\"font-style: italic;\"><em>reference</em></span>, and one output, called the <span style=\"font-style: italic;\"><em>output</em></span>&nbsp;or the <span style=\"font-style: italic;\"><em>action</em></span>. The output depends only on the perception and the reference (and possibly their past histories, integrals, or derivatives) and is such as to always tend to bring the perception closer to the reference.</p>\n<p>Why is this important for LW readers?</p>\n<p><span style=\"font-weight: bold;\"><strong>2. Two descriptions of the same thing that both make sense but don't fit together.</strong></span></p>\n<p>I shall come to that via an autobiographical detour. In the mid-90's, I came across William Powers' book, <a href=\"http://www.amazon.com/Behavior-Perception-William-T-Powers/dp/0964712172/\"><em>Behavior: the Control of Perception</em></a>, in which he set out an analysis of human behaviour in terms of control theory. (Powers' profession was -- he is retired now -- control engineering.) It made sense to me, and it made nonsense of every other approach to psychology. He gave it the name of Perceptual Control Theory, or PCT, and the title of his book expresses the fundamental viewpoint: all of the behaviour of an organism is the output of control systems, and is performed with the purpose of controlling perceptions at desired reference values. Behaviour is the control of perception.</p>\n<p>This is 180 degrees around from the behavioural stimulus-response view, in which you apply a stimulus (a perception) to the organism, and that causes it to emit a response (a behaviour). I shall come back to why this is wrong below. But there is no doubt that it is wrong. Completely, totally wrong. To this audience I can say, as wrong as theism. That wrong. Cognitive psychology just adds layers of processing between stimulus and response, and fares little better.</p>\n<p>I made a simulation of a walking robot whose control systems were designed according to the principles of PCT, and it works. It stands up, walks over uneven terrain, and navigates to food particles. (My earliest simulation is still on the web in the form of <a href=\"http://www2.cmp.uea.ac.uk/~jrk/Robotics/Archy/Archy.html\">this Java applet</a>.) It resists a simulated wind, despite having no way to perceive it. It cannot see, sensing the direction of food only by the differential scent signals from its antennae. It walks on uneven terrain, despite having no perception of the ground other than the positions of its feet relative to its body.</p>\n<p>And then, a year or two ago, I came upon Overcoming Bias, and before that, Eliezer's <a href=\"http://yudkowsky.net/rational/bayes\">article on Bayes' theorem</a>. (Anyone who has not read that article should do so: besides being essential background to OB and LW, it's a good read, and when you have studied it, you will intuitively know why a positive result on a screening test for a rare condition may not be telling you very much.) Bayes' theorem itself is a perfectly sound piece of mathematics, and has practical applications in those cases where you actually have the necessary numbers, such as in that example of screening tests.</p>\n<p>But it was being put forward as something more than that, as a fundamental principle of reasoning, even when you don't have the numbers. Bayes' Theorem as the foundation of rationality, entangling one's brain with the real world, allowing the probability mass of one's beliefs to be pushed by the evidence, acting to funnel the world through a desired tunnel in configuration space. And it was presented as even more than a technique to be learned and applied well or badly, but as the essence of all successful action. Rationality not only wins, it wins by Bayescraft. Bayescraft is the single essence of any method of pushing probability mass into sharp peaks. This all made sense too.</p>\n<p>But the two world-views did not seem to fit together. Consider the humble room thermostat, which keeps the temperature within a narrow range by turning the heating on and off (or in warmer climes, the air conditioning), and consider everything that it does <span style=\"font-style: italic;\"><em>not</em></span> do while doing the single thing that it does:</p>\n<ul>\n<li>The thermostat knows only one thing about its environment: the temperature.</li>\n<li>It has no model of its surroundings.</li>\n<li>It has no model of itself.</li>\n<li>It makes no predictions.</li>\n<li>It performs no Bayesian calculations.</li>\n<li>It has no priors.</li>\n<li>It has no utility function.</li>\n<li>It computes nothing but the difference between perception and reference, and its rule for what to do when they differ could hardly be simpler. Low temperature: turn on. High temperature: turn off.</li>\n<li>It does not think. It does nothing any more suggestive of thought than a single transistor is suggestive of a Cray.</li>\n</ul>\n<p>And yet despite that, it has a sliver of the <a href=\"http://www.overcomingbias.com/2008/10/mundane-magic.html\">Ultimate Power</a>, the ability to funnel the world through its desired tunnel in configuration space. In short, control systems <em>win</em> while being entirely arational. How is this possible?</p>\n<p><small>If you look up subjects such as \"optimal control\", \"adaptive control\", or \"modern control theory\", you will certainly find a lot of work on using Bayesian methods to design control systems. However, the fact remains that the majority of all installed control systems are nothing but manually tuned <a href=\"http://en.wikipedia.org/wiki/PID_controller\">PID controllers</a>. And I have never seen, although I have looked for it, any analysis of general control systems in Bayesian terms. (Except for one author, but despite having a mathematical background, I couldn't make head nor tail of what he was saying. I don't think it's me, because despite his being an eminent person in the field of \"intelligent control\", almost no-one cites his work.) So much for modern control theory. You can design things that way, but you usually don't have to, and it takes a lot more mathematics and computing power. I only mention it because anyone googling \"Bayes\" and \"control theory\" will find all that and may mistake it for the whole subject.</small></p>\n<p><span style=\"font-weight: bold;\"><strong>3. Why it matters.</strong></span></p>\n<p>If this was only about cruise controls and room thermostats, it would just be a minor conundrum. But it is also about people, and all living organisms. The Alien Space Bat Prison Cell describes us just as much as it describes a thermostat. We have a large array of meter needles, red dots, and knobs on the walls of our cell, but it remains the case that we are held inside an unbreakable prison exactly the same shape as ourselves. We are brains in vats, the vat of our own body. No matter how we imagine we are reaching out into the world to perceive it directly, our perceptions are all just neural signals. We have reasons to think there is a world out there that causes these perceptions (and I am not seeking to cast doubt on that), but there is no direct access. All our perceptions enter us as neural signals. Our actions, too, are more neural signals, directed outwards -- we think -- to move our muscles. We can never <a href=\"http://en.wikipedia.org/wiki/File:Flammarion.jpg\">dig our way out of the cell</a>. All that does is make a bigger cell, perhaps with more meters and knobs.</p>\n<p>We do pretty well at controlling some of those needles, without having received the grace of Bayes. When you steer your car, how do you keep it directed along the intended path? By seeing through the windscreen how it is positioned, and doing whatever is necessary with the steering wheel in order to see what you want to see. You cannot do it if the windows are blacked out (no perception), if the steering linkage is broken (no action), or if you do not care where the car goes (no reference). But you can do it even if you do not know about the cross-wind, or the misadjusted brake dragging on one of the wheels, or the changing balance of the car according to where passengers are sitting. It would not help if you did. All you need is to see the actual state of affairs, and know what you want to see, and know how to use the steering wheel to get the view closer to the view you want. You don't need to know much about that last. Most people pick it up at once in their first driving lesson, and practice merely refines their control.</p>\n<p>Consider stimulus/response again. You can't sense the crosswind from inside a car, yet the angle of the steering wheel will always be just enough to counteract the cross-wind. The correlation between the two will be very high. A simple, measurable analogue of the task is <a href=\"http://www.mindreadings.com/ControlDemo/BasicTrack.html\">easily carried out on a computer</a>. There is a mark on the screen that moves left and right, which the subject must keep close to a static mark. The position of the moving mark is simply the sum of the mouse position and a randomly drifting disturbance calculated by the program. So long as the disturbance is not too large and does not vary too rapidly, it is easy to keep the two marks fairly well aligned. The correlation between the mouse position (the subject's action) and the disturbance (which the subject cannot see) is typically around -0.99. (I just tried it and scored -0.987.) On the other hand, the correlation between mouse position and mark position (the subject's perception) will be close to zero.</p>\n<p>So in a control task, the \"stimulus\" -- the perception -- is uncorrelated with the \"response\" -- the behaviour. To put that in different terminology, the mutual information between them is close to zero. But the behaviour is highly correlated with something that the subject cannot perceive.</p>\n<p>When driving a car, suppose you decide to change lanes? (Or in the tracking task, suppose you decide to keep the moving mark one inch to the left of the static mark?) Suddenly you do something different with the steering wheel. Nothing about your perception changed, yet your actions changed, because a reference signal inside your head changed.</p>\n<p>If you do not know that you are dealing with a control system, it will seem mysterious. You will apply stimuli and measure responses, and end up with statistical mush. Since everyone else does the same, you can excuse the situation by saying that people are terribly complicated and you can't expect more. 0.6 is considered a high correlation in a psychology experiment, and 0.2 is considered publishable (<a href=\"http://www.jstor.org/pss/2093765\">link</a>). Real answers go <span style=\"font-style: italic;\"><em>ping!!</em></span> when you hit them, instead of slopping around like lumpy porridge. What is needed is to discover that a control system is present, what it is controlling, and how.</p>\n<p>There are ways of doing that, but this is enough for one posting.</p>\n<p><span style=\"font-weight: bold;\"><strong>4. Conclusion.</strong></span></p>\n<p>Conclusion of this posting, not my entire thoughts on the subject, not by a long way.</p>\n<p>My questions to you are these.</p>\n<p>Control systems win while being arational. Either explain this in terms of Bayescraft, or explain why there is no such explanation.</p>\n<p>If, as is speculated, a living organism's brain is a collection of control systems, is Bayescraft no more related to its physical working than arithmetic is? Our brains can learn to do arithmetic, but arithmetic is not how our brains work. Likewise, we can learn Bayescraft, or some <a href=\"/lw/bn/twotier_rationalism/\">practical approximation</a> to it, but do Bayesian processes have anything to do with the mechanism of brains?</p>\n<p>Does Bayescraft necessarily have anything to do with the task of building a machine that ... can do something not to be discussed here yet?</p>\n<p><span style=\"font-weight: bold;\"><strong>5. Things I have not yet spoken of.</strong></span></p>\n<p>The control system's designer who put the rule in, that tells it what output to emit given the perception and the reference: whether he supplied the rationality that is the real source of its miraculous power?</p>\n<p>How to discover the presence of a control system and discern its reference, even if its physical embodiment remains obscure.</p>\n<p>How to control a perception even when you don't know how.</p>\n<p>Hierarchical arrangements of control systems as a method of building more complex control systems.</p>\n<p>Simple control systems win at their limited tasks while being arational. How much more is possible for arational systems built of control systems?</p>\n<p><span style=\"font-weight: bold;\"><strong>6. WARNING: Autonomous device</strong></span></p>\n<p>After those few thousand words of seriousness, a small dessert.</p>\n<p>Exhibit A: <a href=\"http://www.flickr.com/photos/arenamontanus/264112997/in/set-72157594323393196/\">A supposedly futuristic warning sign.</a></p>\n<p>Exhibit B: A contemporary warning sign in an undergraduate control engineering lab: \"WARNING: These devices may start moving without warning, even if they appear powered off, and can exert sudden and considerable forces. Exercise caution in their vicinity.\"</p>\n<p>They say the same thing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"9mShmhRFzBat3523A": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fJKbCXrCPwAR5wjL8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": 53, "extendedScore": null, "score": 9.1e-05, "legacy": true, "legacyId": "487", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 53, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PL7KpiDdJnh6j5LZS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-28T12:10:30.070Z", "modifiedAt": "2019-12-28T06:35:47.001Z", "url": null, "title": "Re-formalizing PD", "slug": "re-formalizing-pd", "viewCount": null, "lastCommentedAt": "2009-08-26T23:00:11.491Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5iK6rsa3MSrMhHQyf/re-formalizing-pd", "pageUrlRelative": "/posts/5iK6rsa3MSrMhHQyf/re-formalizing-pd", "linkUrl": "https://www.lesswrong.com/posts/5iK6rsa3MSrMhHQyf/re-formalizing-pd", "postedAtFormatted": "Tuesday, April 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Re-formalizing%20PD&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARe-formalizing%20PD%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5iK6rsa3MSrMhHQyf%2Fre-formalizing-pd%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Re-formalizing%20PD%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5iK6rsa3MSrMhHQyf%2Fre-formalizing-pd", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5iK6rsa3MSrMhHQyf%2Fre-formalizing-pd", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 595, "htmlBody": "<p>The Prisoner's Dilemma has been discussed to death here on OB/LW, right? Well, here's a couple new twists to somewhat... uh... expand the discussion.</p>\n<p>Warning: programming and math ahead.</p>\n<p>&nbsp;</p>\n<p><strong>Scenario 1</strong></p>\n<p>Imagine a PD tournament between programs that can read each other's source code. In every match, player A receives the source code of player B as an argument, and vice versa. Matches are <em>one-shot</em>, not iterated.</p>\n<p>In this situation it's possible to write a program that's&nbsp;<em>much better</em> than \"always defect\". Yes, in an ordinary programming language like C or Python, no futuristic superintelligent oracles required. No, Rice's theorem doesn't cause any problems.</p>\n<p>Here's an outline of the program:<a id=\"more\"></a></p>\n<blockquote>\n<pre> // begin PREFIX<br /> Strategy main(SourceCode other)<br /> {<br /> &nbsp;&nbsp;&nbsp;&nbsp;// get source code of this program from \"begin PREFIX\" to \"end PREFIX\",<br /> &nbsp;&nbsp;&nbsp;&nbsp;// using ordinary <a href=\"http://www.nyx.net/~gthompso/quine.htm\">quine</a> (self-printing program) techniques<br /> &nbsp;&nbsp;&nbsp;&nbsp;String PREFIX = \"...\"<br /> <br /> &nbsp;&nbsp;&nbsp;&nbsp;if (other.beginsWith(PREFIX))<br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return Strategy.COOPERATE;<br /> &nbsp;&nbsp;&nbsp;&nbsp;else<br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return anythingElse(other);<br /> }<br /> // end PREFIX<br /> <br /> // from this point you can write anything you wish<br /> Strategy anythingElse(SourceCode other)<br /> {<br /> &nbsp;&nbsp;&nbsp;&nbsp;return Strategy.DEFECT;<br /> }</pre>\n</blockquote>\n<p>Some features of this program:</p>\n<ul>\n<li>It cooperates with itself.</li>\n<li>It cooperates with any other program that begins with PREFIX.</li>\n<li>It's impossible to cheat, because opponents that begin with PREFIX can't <em>not</em> cooperate with this program.</li>\n<li><del>Other authors now have an incentive to include PREFIX in their programs, moving their original logic into the \"anythingElse\" subroutine. This modification has no downside.</del></li>\n</ul>\n<p><del>So, introducing such a program into the tournament should lead to a chain reaction until everyone cooperates. Unless I've missed something</del>. What say ye?</p>\n<p><span style=\"font-style: italic;\">Edit: </span>the last point and the conclusion were wrong. Thanks to Warrigal for pointing this out.</p>\n<ul>\n</ul>\n<p>&nbsp;</p>\n<p><strong>Scenario 2</strong></p>\n<p>Now imagine another tournament where programs can't read each other's source code, but are instead given access to a perfect simulator. So programs now look like this:</p>\n<blockquote>\n<pre>Strategy main(ObjectCode self, ObjectCode other, Simulator simulator) {...}</pre>\n</blockquote>\n<p>and can call&nbsp;<em>simulator.simulate(ObjectCode a, ObjectCode b)</em> arbitrarily many times with any arguments.&nbsp;To give players a chance to avoid bottomless recursion, we also make available a random number generator.</p>\n<p>Problem: in this setting, is it possible to write a program that's better than \"always defect\"?</p>\n<p>The most general form of a reasonable program I can imagine at the moment is a centipede:</p>\n<ol>\n<li>Programmer invents a number N and a sequence of real numbers 0 &lt; p<sub>1</sub> &lt; p<sub>2</sub> &lt; ... &lt; p<sub>N</sub> &lt; 1.</li>\n<li>Program generates a random number 0 &lt; r &lt; 1.</li>\n<li>If r &lt; p<sub>1</sub>, cooperate.</li>\n<li>Simulate the opponent's reaction to you.</li>\n<li>If opponent defects, defect.</li>\n<li>Otherwise if r &lt; p<sub>2</sub>, cooperate.</li>\n<li>And so on until N.</li>\n</ol>\n<p><em>Exercise 1:</em>&nbsp;when (for what N and p<sub>i</sub>) does this program cooperate against itself? (To cooperate, the recursive tree of simulations must terminate with probability one.)</p>\n<p><em>Exercise 2:</em> when does this program win against a simple randomizing opponent?</p>\n<p><em>Exercise 3:</em>&nbsp;what's the connection between the first two exercises, and does it imply any general theorem?</p>\n<p>&nbsp;</p>\n<p><strong>Epilogue</strong></p>\n<p>Ordinary humans playing the PD othen rely on assumptions about their opponent. They may consider certain invariant properties of their opponent, like altruism, or run mental simulations. Such wetware processes are inherently hard to model, but even a half-hearted attempt brings out startling and rigorous formalizations instead of our usual vague intuitions about game theory.</p>\n<p>Is this direction of inquiry fruitful?</p>\n<p>What do you think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5iK6rsa3MSrMhHQyf", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 32, "extendedScore": null, "score": 6.4e-05, "legacy": true, "legacyId": "492", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>The Prisoner's Dilemma has been discussed to death here on OB/LW, right? Well, here's a couple new twists to somewhat... uh... expand the discussion.</p>\n<p>Warning: programming and math ahead.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Scenario_1\">Scenario 1</strong></p>\n<p>Imagine a PD tournament between programs that can read each other's source code. In every match, player A receives the source code of player B as an argument, and vice versa. Matches are <em>one-shot</em>, not iterated.</p>\n<p>In this situation it's possible to write a program that's&nbsp;<em>much better</em> than \"always defect\". Yes, in an ordinary programming language like C or Python, no futuristic superintelligent oracles required. No, Rice's theorem doesn't cause any problems.</p>\n<p>Here's an outline of the program:<a id=\"more\"></a></p>\n<blockquote>\n<pre> // begin PREFIX<br> Strategy main(SourceCode other)<br> {<br> &nbsp;&nbsp;&nbsp;&nbsp;// get source code of this program from \"begin PREFIX\" to \"end PREFIX\",<br> &nbsp;&nbsp;&nbsp;&nbsp;// using ordinary <a href=\"http://www.nyx.net/~gthompso/quine.htm\">quine</a> (self-printing program) techniques<br> &nbsp;&nbsp;&nbsp;&nbsp;String PREFIX = \"...\"<br> <br> &nbsp;&nbsp;&nbsp;&nbsp;if (other.beginsWith(PREFIX))<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return Strategy.COOPERATE;<br> &nbsp;&nbsp;&nbsp;&nbsp;else<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return anythingElse(other);<br> }<br> // end PREFIX<br> <br> // from this point you can write anything you wish<br> Strategy anythingElse(SourceCode other)<br> {<br> &nbsp;&nbsp;&nbsp;&nbsp;return Strategy.DEFECT;<br> }</pre>\n</blockquote>\n<p>Some features of this program:</p>\n<ul>\n<li>It cooperates with itself.</li>\n<li>It cooperates with any other program that begins with PREFIX.</li>\n<li>It's impossible to cheat, because opponents that begin with PREFIX can't <em>not</em> cooperate with this program.</li>\n<li><del>Other authors now have an incentive to include PREFIX in their programs, moving their original logic into the \"anythingElse\" subroutine. This modification has no downside.</del></li>\n</ul>\n<p><del>So, introducing such a program into the tournament should lead to a chain reaction until everyone cooperates. Unless I've missed something</del>. What say ye?</p>\n<p><span style=\"font-style: italic;\">Edit: </span>the last point and the conclusion were wrong. Thanks to Warrigal for pointing this out.</p>\n<ul>\n</ul>\n<p>&nbsp;</p>\n<p><strong id=\"Scenario_2\">Scenario 2</strong></p>\n<p>Now imagine another tournament where programs can't read each other's source code, but are instead given access to a perfect simulator. So programs now look like this:</p>\n<blockquote>\n<pre>Strategy main(ObjectCode self, ObjectCode other, Simulator simulator) {...}</pre>\n</blockquote>\n<p>and can call&nbsp;<em>simulator.simulate(ObjectCode a, ObjectCode b)</em> arbitrarily many times with any arguments.&nbsp;To give players a chance to avoid bottomless recursion, we also make available a random number generator.</p>\n<p>Problem: in this setting, is it possible to write a program that's better than \"always defect\"?</p>\n<p>The most general form of a reasonable program I can imagine at the moment is a centipede:</p>\n<ol>\n<li>Programmer invents a number N and a sequence of real numbers 0 &lt; p<sub>1</sub> &lt; p<sub>2</sub> &lt; ... &lt; p<sub>N</sub> &lt; 1.</li>\n<li>Program generates a random number 0 &lt; r &lt; 1.</li>\n<li>If r &lt; p<sub>1</sub>, cooperate.</li>\n<li>Simulate the opponent's reaction to you.</li>\n<li>If opponent defects, defect.</li>\n<li>Otherwise if r &lt; p<sub>2</sub>, cooperate.</li>\n<li>And so on until N.</li>\n</ol>\n<p><em>Exercise 1:</em>&nbsp;when (for what N and p<sub>i</sub>) does this program cooperate against itself? (To cooperate, the recursive tree of simulations must terminate with probability one.)</p>\n<p><em>Exercise 2:</em> when does this program win against a simple randomizing opponent?</p>\n<p><em>Exercise 3:</em>&nbsp;what's the connection between the first two exercises, and does it imply any general theorem?</p>\n<p>&nbsp;</p>\n<p><strong id=\"Epilogue\">Epilogue</strong></p>\n<p>Ordinary humans playing the PD othen rely on assumptions about their opponent. They may consider certain invariant properties of their opponent, like altruism, or run mental simulations. Such wetware processes are inherently hard to model, but even a half-hearted attempt brings out startling and rigorous formalizations instead of our usual vague intuitions about game theory.</p>\n<p>Is this direction of inquiry fruitful?</p>\n<p>What do you think?</p>", "sections": [{"title": "Scenario 1", "anchor": "Scenario_1", "level": 1}, {"title": "Scenario 2", "anchor": "Scenario_2", "level": 1}, {"title": "Epilogue", "anchor": "Epilogue", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "63 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 63, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-28T12:10:30.070Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-28T22:00:50.764Z", "modifiedAt": "2021-11-24T14:10:49.760Z", "url": null, "title": "Generalizing From One Example", "slug": "generalizing-from-one-example", "viewCount": null, "lastCommentedAt": "2022-04-15T10:51:20.283Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example", "pageUrlRelative": "/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example", "linkUrl": "https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example", "postedAtFormatted": "Tuesday, April 28th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Generalizing%20From%20One%20Example&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGeneralizing%20From%20One%20Example%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbaTWMegR42PAsH9qJ%2Fgeneralizing-from-one-example%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Generalizing%20From%20One%20Example%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbaTWMegR42PAsH9qJ%2Fgeneralizing-from-one-example", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbaTWMegR42PAsH9qJ%2Fgeneralizing-from-one-example", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1929, "htmlBody": "<p><strong>Related to:</strong> <a href=\"http://www.overcomingbias.com/2008/06/psychological-u.html\">The Psychological Unity of Humankind</a>, <a href=\"/lw/cn/instrumental_vs_epistemic_a_bardic_perspective/\">Instrumental vs. Epistemic: A Bardic Perspective</a><br /><br />\"<em>Everyone generalizes from one example. At least, I do.\"</em></p>\n<p>&nbsp;&nbsp; -- Vlad Taltos (<em>Issola, </em>Steven Brust)<br /><br />My old professor, David Berman, liked to talk about what he called the \"typical mind fallacy\", which he illustrated through the following example:<br /><br />There was a debate, in the late 1800s, about whether \"imagination\" was simply a turn of phrase or a real phenomenon. That is, can people actually create images in their minds which they see vividly, or do they simply say \"I saw it in my mind\" as a metaphor for considering what it looked like?<br /><br />Upon hearing this, my response was \"How the stars was this actually a real debate? Of course we have mental imagery. Anyone who doesn't think we have mental imagery is either such a fanatical Behaviorist that she doubts the evidence of her own senses, or simply insane.\" Unfortunately, the professor was able to parade a long list of famous people who denied mental imagery, including some leading scientists of the era. And this was all before Behaviorism even existed.<br /><br />The debate was resolved by Francis Galton, a fascinating man who among other achievements invented eugenics, the \"wisdom of crowds\", and standard deviation. Galton gave people some very detailed surveys, and found that some people did have mental imagery and others didn't. The ones who did had simply assumed everyone did, and the ones who didn't had simply assumed everyone didn't, to the point of coming up with absurd justifications for why they were lying or misunderstanding the question. There was a wide spectrum of imaging ability, from about five percent of people with perfect eidetic imagery<sup>1</sup> to three percent of people completely unable to form mental images<sup>2</sup>.</p>\n<p>Dr. Berman dubbed this the Typical Mind Fallacy: the human tendency to believe that one's own mental structure can be generalized to apply to everyone else's.</p>\n<p><a id=\"more\"></a></p>\n<p>He kind of took this idea and ran with it. He interpreted certain passages in George Berkeley's biography to mean that Berkeley was an eidetic imager, and that this was why the idea of the universe as sense-perception held such interest to him. He also suggested that experience of consciousness and qualia were as variable as imaging, and that philosophers who deny their existence (Ryle? Dennett? Behaviorists?) were simply people whose mind lacked the ability to easily experience qualia. In general, he believed philosophy of mind was littered with examples of philosophers taking their own mental experiences and building theories on them, and other philosophers with different mental experiences critiquing them and wondering why they disagreed.<br /><br />The formal typical mind fallacy is about serious matters of mental structure. But I've also run into something similar with something more like the psyche than the mind: a tendency to generalize from our personalities and behaviors. <br /><br />For example, I'm about as introverted a person as you're ever likely to meet - anyone more introverted than I am doesn't communicate with anyone. All through elementary and middle school, I suspected that the other children were out to get me. They kept on grabbing me when I was busy with something and trying to drag me off to do some rough activity with them and their friends. When I protested, they counter-protested and told me I really needed to stop whatever I was doing and come join them. I figured they were bullies who were trying to annoy me, and found ways to hide from them and scare them off.<br /><br />Eventually I realized that it was a double misunderstanding. They figured I must be like them, and the only thing keeping me from playing their fun games was that I was too shy. I figured they must be like me, and that the only reason they would interrupt a person who was obviously busy reading was that they wanted to annoy him.<br /><br />Likewise: I can't deal with noise. If someone's being loud, I can't sleep, I can't study, I can't concentrate, I can't do anything except bang my head against the wall and hope they stop. I once had a noisy housemate. Whenever I asked her to keep it down, she told me I was being oversensitive and should just mellow out. I can't claim total victory here, because she was very neat and kept yelling at me for leaving things out of place, and I told her she needed to just mellow out and you couldn't even tell that there was dust on that dresser anyway. It didn't occur to me then that neatness to her might be as necessary and uncompromisable as quiet was to me, and that this was an actual feature of how our minds processed information rather than just some weird quirk on her part.</p>\n<p>\"Just some weird quirk on her part\" and \"just being oversensitive\" are representative of the problem with the typical psyche fallacy, which is that it's invisible. We tend to neglect the role of differently-built minds in disagreements, and attribute the problems to the other side being deliberately perverse or confused. I happen to know that loud noise seriously pains and debilitates me, but when I say this to other people they think I'm just expressing some weird personal preference for quiet. Think about all those poor non-imagers who thought everyone else was just taking a metaphor about seeing mental images <em>way</em> too far and refusing to give it up.</p>\n<p>And the reason I'm posting this here is because it's rationality that helps us deal with these problems.<br /><br />There's some evidence that the usual method of interacting with people involves something sorta like emulating them within our own brain. We think about how we would react, adjust for the other person's differences, and then assume the other person would react that way. This method of interaction is very tempting, and it always feels like it ought to work.<br /><br />But when statistics tell you that the method that would work on you doesn't work on anyone else, then continuing to follow that gut feeling is a Typical Psyche Fallacy. You've got to be a good rationalist, reject your gut feeling, and follow the data.<br /><br />I only really discovered this in my last job as a school teacher. There's a lot of data on teaching methods that students enjoy and learn from. I had some of these methods...inflicted...on me during my school days, and I had no intention of abusing my own students in the same way. And when I tried the sorts of really creative stuff I would have loved as a student...it fell completely flat. What ended up working? Something pretty close to the teaching methods I'd hated as a kid. Oh. Well. Now I know why people use them so much. And here I'd gone through life thinking my teachers were just inexplicably bad at what they did, never figuring out that I was just the odd outlier who couldn't be reached by this sort of stuff.<br /><br />The other reason I'm posting this here is because I think it relates to some of the discussions of seduction that are going on in MBlume's Bardic thread. There are a lot of not-particularly-complimentary things about women that many men tend to believe. Some guys say that women will never have romantic relationships with their actually-decent-people male friends because they prefer alpha-male jerks who treat them poorly. Other guys say women want to be lied to and tricked. I could go on, but I think most of them are covered in that thread anyway.<br /><br />The response I hear from most of the women I know is that this is complete balderdash and women aren't like that at all. So what's going on?<br /><br />Well, I'm afraid I kind of trust the seduction people. They've put a lot of work into their \"art\" and at least according to their self-report are pretty successful. And unhappy romantically frustrated nice guys everywhere can't be completely wrong.<br /><br />My theory is that the women in this case are committing a Typical Psyche Fallacy. The women I ask about this are not even remotely close to being a representative sample of all women. They're the kind of women whom a shy and somewhat geeky guy knows and talks about psychology with. Likewise, the type of women who publish strong opinions about this on the Internet aren't close to a representative sample. They're well-educated women who have strong opinions about gender issues and post about them on blogs.<br /><br />And lest I sound chauvinistic, the same is certainly true of men. I hear a lot of bad things said about men (especially with reference to what they want romantically) that I wouldn't dream of applying to myself, my close friends, or to any man I know. But they're so common and so well-supported that I have excellent reason to believe they're true.<br /><br />This post has gradually been getting less rigorous and less connected to the formal Typical Mind Fallacy. First I changed it to a Typical Psyche Fallacy so I could talk about things that were more psychological and social than mental. And now it's expanding to cover the related fallacy of believing your own social circle is at least a little representative of society at large, which it very rarely is<sup>3</sup>.<br /><br />It was originally titled \"The Typical Mind Fallacy\", but I'm taking a hint fromt the quote and changing it to \"Generalizing From One Example\", because that seems to be the link between all of these errors. We only have direct first-person knowledge one one mind, one psyche, and one social circle, and we find it tempting to treat it as typical even in the face of contrary evidence.<br /><br />This, I think, is especially important for the sort of people who enjoy Less Wrong, who as far as I can tell are with few exceptions the sort of people who are extreme outliers on every psychometric test ever invented.</p>\n<p><br /><strong>Footnotes</strong><br /><br /><strong>1.</strong> Eidetic imagery, vaguely related to the idea of a \"photographic memory\", is the ability to visualize something and have it be exactly as clear, vivid and obvious as actually seeing it. My professor's example (which Michael Howard somehow remembers even though I only mentioned it once a few years ago) is that although many people can imagine a picture of a tiger, only an eidetic imager would be able to count the number of stripes.<br /><br /><strong>2.</strong> According to Galton, people incapable of forming images were overrepresented in math and science. I've since heard that this idea has been challenged, but I can't access the study.<br /><br /><strong>3.</strong> The example that really drove this home to me: what percent of high school students do you think cheat on tests? What percent have shoplifted? Someone did a survey on this recently and found that the answer was nobhg gjb guveqf unir purngrq naq nobhg bar guveq unir fubcyvsgrq (<a href=\"http://www.rot13.com/\">rot13ed</a> so you have to actually take a guess first). This shocked me and everyone I knew, because we didn't cheat or steal during high school and we didn't know anyone who did. I spent an afternoon trying to find some proof that the study was wrong or unrepresentative and coming up with nothing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 4, "fmA6cA9psxibmH8MS": 1, "YQW2DxpZFTrqrxHBJ": 2, "dJ6eJxJrCEget7Wb6": 3, "GPhMyXoaHBLyzibxB": 1, "gsv9XWbZDcnZmKuqM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "baTWMegR42PAsH9qJ", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 348, "baseScore": 380, "extendedScore": null, "score": 0.00058, "legacy": true, "legacyId": "495", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 380, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 415, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AGP9PwnhQcuYMKyMm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 24, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-04-28T22:00:50.764Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-29T03:47:50.833Z", "modifiedAt": null, "url": null, "title": "Wednesday depends on us.", "slug": "wednesday-depends-on-us", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:46.726Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "byrnema", "createdAt": "2009-03-20T18:02:38.305Z", "isAdmin": false, "displayName": "byrnema"}, "userId": "SCnD6W8NiztYBN39M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H9CyQWsEjPvczPvnA/wednesday-depends-on-us", "pageUrlRelative": "/posts/H9CyQWsEjPvczPvnA/wednesday-depends-on-us", "linkUrl": "https://www.lesswrong.com/posts/H9CyQWsEjPvczPvnA/wednesday-depends-on-us", "postedAtFormatted": "Wednesday, April 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wednesday%20depends%20on%20us.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWednesday%20depends%20on%20us.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH9CyQWsEjPvczPvnA%2Fwednesday-depends-on-us%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wednesday%20depends%20on%20us.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH9CyQWsEjPvczPvnA%2Fwednesday-depends-on-us", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH9CyQWsEjPvczPvnA%2Fwednesday-depends-on-us", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 924, "htmlBody": "<p><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> </w:WordDocument> </xml><![endif]--><!-- /* Font Definitions */ @font-face {font-family:Verdana; panose-1:2 11 6 4 3 5 4 4 2 4; mso-font-charset:0; mso-generic-font-family:swiss; mso-font-pitch:variable; mso-font-signature:536871559 0 0 0 415 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\"; mso-fareast-font-family:\"Times New Roman\";} a:link, span.MsoHyperlink {color:blue; text-decoration:underline; text-underline:single;} a:visited, span.MsoHyperlinkFollowed {color:purple; text-decoration:underline; text-underline:single;} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} /* List Definitions */ @list l0 {mso-list-id:812910932; mso-list-type:hybrid; mso-list-template-ids:-1484749044 2035711604 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;} @list l0:level1 {mso-level-text:\"\\(%1\\)\"; mso-level-tab-stop:.75in; mso-level-number-position:left; margin-left:.75in; text-indent:-.5in;} ol {margin-bottom:0in;} ul {margin-bottom:0in;} --><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\";} --> <!--[endif]--></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> </w:WordDocument> </xml><![endif]--><!-- /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\"; mso-fareast-font-family:\"Times New Roman\";} h1 {mso-style-next:Normal; margin-top:12.0pt; margin-right:0in; margin-bottom:3.0pt; margin-left:0in; mso-pagination:widow-orphan; page-break-after:avoid; mso-outline-level:1; font-size:16.0pt; font-family:Arial; mso-font-kerning:16.0pt;} a:link, span.MsoHyperlink {color:blue; text-decoration:underline; text-underline:single;} a:visited, span.MsoHyperlinkFollowed {color:purple; text-decoration:underline; text-underline:single;} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} --><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\";} --> <!--[endif]--></p>\n<p><span style=\"color: black;\">In response to </span><a href=\"/lw/dg/theism_wednesday_and_not_being_adopted\">Theism, Wednesday, and Not Being Adopted</a></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">It is a theist clich&eacute;: you need religion to define morality. The argument doesn't have to be as simplistic as &ldquo;you need God to impose it&rdquo;, but at the least it is the belief that your community needs to agree on what is ethical. When a community starts talking about what is ethical, they quickly depart from anything strictly fact-based. As a community, they need to figure out what the morality is (e.g., love your neighbor), construct a narrative using symbols that make sense to <em>everyone</em> (there&rsquo;s this external entity God, someone like your father, who wants it this way) and enforce it (if you don&rsquo;t go along, you go to Hell.) This is probably 40% of what religion is. <br /> <!--[endif]--></span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">While the development of a religion is a community effort to some extent (communities choose among competing religions and religions evolve), the main work is done by the priests. The priest is usually an exceptionally good thinker/reasoner/philosopher &ndash; maybe <del>4-7</del> <strong>3-5</strong> standard deviations from the mean.<strong> [Correction]</strong><br /></span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">There are a few things that are very confusing to Wednesday when you try to convert her. First of all, she understands on at least a subconscious level that religion is her community&rsquo;s ethical system. When you say you don&rsquo;t believe in God, she thinks you&rsquo;re saying, &lsquo;it&rsquo;s OK to torture babies&rsquo;. What&rsquo;s scary is that she&rsquo;s somewhat justified here: without an externally applied ethical belief system, individual ethics can vary widely from what <em>she</em> accepts as ethical (and what <em>you</em> accept as ethical).</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">&nbsp;If morality is something that humanity protects</span><span style=\"font-family: Verdana;\">, can we blame Wednesday for that? </span></p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">Fortunately, Eliezer <a href=\"http://www.overcomingbias.com/2008/07/the-meaning-of.html%29:\" target=\"l\">assures us:</a> Anyone worried that reductionism drains the meaning from existence can stop worrying. </span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">This brings us to the second problem for Wednesday. While I<em> believe</em> Eliezer about rationality not denying morality and meaning, I believe him in the same way Wednesday believes her priest: because he&rsquo;s been right before and I figure I probably have something to learn. </span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">&nbsp;Rational arguments sound <em>just as good</em> to Wednesday as her Bishop&rsquo;s theological arguments. What is she to do? Wednesday&rsquo;s priest has warned her of this with some well-chosen examples appropriate for her level of sophistication and he explains: when you get confused, just trust your intuition: Is it <em>really</em> OK to torture babies?</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">I think the average person needs some help to defend from wanton intellectual argument. Here's the handy heuristic: Choose to preserve a meta-truth (i.e., the truth you are committed to protect) over a fact-based truth that has proven, again and again, to not be reliable when you factor in that you're <em>not a great thinker</em> and thus can be easily mislead by &ldquo;facts&rdquo;.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\"><span>&nbsp;</span>On some level Wednesday is aware her religion contradicts facts (God is a mystery, etc) but she is comfortable with the idea that there may be a hierarchy of truths: truths about whether it is OK to torture babies <em>is</em> more important to her than knowing how many years old the Earth is. </span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">Don&rsquo;t you agree with Wednesday? If Eliezer had not already ascertained that there&rsquo;s still morality after rationality, would you be willing to go there? I wouldn&rsquo;t, personally. (If that makes me irrational, that is also what makes me human. Typical sci fi theme &ndash; but science fiction, like religion, has many symbols that ring true tones.)&nbsp; </span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\"><!--[if !supportLineBreakNewLine]--></span><span style=\"font-family: Verdana;\"> <!--[endif]-->But among two presented belief systems, an intellectually unsophisticated Wednesday is just choosing the belief system that has falseness AND &ldquo;meaningful&rdquo; truth over a belief system that (certainly, historically) has no falseness (in theory) BUT no meaningful truth. So you <em>should </em>accept Wednesday as rational: she values the value of truth, which is better than valuing valueless truth at whatever cost. </span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">&nbsp;Maybe you&rsquo;re surprised (or skeptical) that Wednesday values truth. But I&rsquo;m not. I have evidence that valuing truth is a pretty universal human quality. Alas, often second to valuing security and power &hellip; But still: another reason to accept Wednesday. She is typical humanity. Some of you have a lot of anger towards religion, with good reason, but it would be a mistake to define ourselves antagonistically against 99.99% of humanity. Even if we are <em>right</em> and they&rsquo;re <em>wrong</em>, whose side are we on?</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">&nbsp;I think we&rsquo;re on their side. Religion &ndash; defined now as the set of ways the community defines our relationship with each other and with the world &ndash; is supposed to evolve with our understanding of those relationships. Wednesday is stuck in a religion and a moral code that hasn&rsquo;t really changed in 2000 years! (35% true, but point left for dramatic effect) She <em>depends</em> upon us to figure out how to draft a new belief system based on science that is also human: an ethical science. Don&rsquo;t leave her with the choice of having to choose between either rejecting science or rejecting the meaning and value of being human.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">&nbsp;Instead of complaining about how idiotic humanity is, we have some work to do:</span></p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.5in;\"><span style=\"font-family: Verdana;\">&nbsp;<span>(1)<span style=\"font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; -x-system-font: none;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span style=\"font-family: Verdana;\">decide whether meaning exists, if it important, and if it can be brought into a scientific view of the world <em>without making stuff up</em></span></p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.5in;\"><!--[if !supportLists]--><span style=\"font-family: Verdana;\"><span>(2)<span style=\"font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; -x-system-font: none;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span style=\"font-family: Verdana;\">develop a scientific view of the world that accommodates the meta-truth, if it exists</span></p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.75in; text-indent: -0.5in;\"><!--[if !supportLists]--><span style=\"font-family: Verdana;\"><span>(3)<span style=\"font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; -x-system-font: none;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span style=\"font-family: Verdana;\">explain it to Wednesday in a way that makes sense to her (symbols and analogies are OK, but they must be honest ones) <span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span></span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana;\">I think we should debate about whether meaning exists, whether a scientific view of the world accommodates meaning, and whether it is our responsibility to help Wednesday. But if yes to all three, we should define ourselves in service to her, and bring her along.</span></p>\n<p class=\"MsoNormal\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1, "izp6eeJJEg9v5zcur": 1, "ouT6wKhACJRouGokM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H9CyQWsEjPvczPvnA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 2, "extendedScore": null, "score": 4.908525886876362e-07, "legacy": true, "legacyId": "499", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AYa2gc3sFWCCFSaFq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-29T08:35:01.709Z", "modifiedAt": null, "url": null, "title": "How to come up with verbal probabilities", "slug": "how-to-come-up-with-verbal-probabilities", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:48.791Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimmy", "createdAt": "2009-02-27T18:23:27.410Z", "isAdmin": false, "displayName": "jimmy"}, "userId": "JKdbpXHkv9AsuazJ3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6Bz4TK37T8t5S3AbM/how-to-come-up-with-verbal-probabilities", "pageUrlRelative": "/posts/6Bz4TK37T8t5S3AbM/how-to-come-up-with-verbal-probabilities", "linkUrl": "https://www.lesswrong.com/posts/6Bz4TK37T8t5S3AbM/how-to-come-up-with-verbal-probabilities", "postedAtFormatted": "Wednesday, April 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20come%20up%20with%20verbal%20probabilities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20come%20up%20with%20verbal%20probabilities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Bz4TK37T8t5S3AbM%2Fhow-to-come-up-with-verbal-probabilities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20come%20up%20with%20verbal%20probabilities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Bz4TK37T8t5S3AbM%2Fhow-to-come-up-with-verbal-probabilities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Bz4TK37T8t5S3AbM%2Fhow-to-come-up-with-verbal-probabilities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 777, "htmlBody": "<p>Unfortunately, we are kludged together, and we can't just look up our probability estimates in a register somewhere when someone asks us \"How sure are you?\".<br /><br />The usual heuristic for putting a number on the strength of beliefs is to ask \"When you're this sure about something, what fraction of the time do you expect to be right in the long run?\".&nbsp; This is surely better than just \"making up\" numbers with no feel for what they mean, but still has it's faults.&nbsp; The big one is that unless you've done your calibrating, you may not have a good idea of how often you'd expect to be right. <br /><br />I can think of a few different heuristics to use when coming up with probabilities to assign.<br /><br />1) Pretend you have to bet on it. Pretend that someone says \"I'll give you ____ odds, which side do you want?\", and figure out what the odds would have to be to make you indifferent to which side you bet on. Consider the question as if though you were <a href=\"http://www.overcomingbias.com/2007/06/uncovering_rati.html\"><em>actually going to put money on it</em> </a>. If this question is covered on a prediction market, your answer is given to you.</p>\n<p>2) Ask yourself how much evidence someone would have to give you before you're back to 50%. Since we're trying to update according to bayes law, knowing how much evidence it takes to bring you to 50% tells you the probability you're implicitely assigning.</p>\n<p>For example, pretend someone said something like \"I can guess peoples names by their looks\".&nbsp; If he guesses the first name right, and it's a common name, you'll probably write it off as fluke.&nbsp; The second time you'll probably think he knew the people or is somehow fooling you, but <a href=\"/lw/2k/the_least_convenient_possible_world/\">conditional on that</a>, you'd probably say he's just lucky.&nbsp; By bayes law, this suggests that you put the prior probability of him pulling this stunt at 0.1%&lt;p&lt;3%, and less than 0.1% prior probability of him having his claimed skill.&nbsp; If it takes 4 correct calls to bring you to equally unsure either way, then thats about 0.03^4 if they're common names, or one in a million<sup>1</sup>...<a id=\"more\"></a><br /><br />There's a couple neat things about this trick.&nbsp; One is that it allows you to get an idea of what your subconscious level of certainty is before you ever think of it.&nbsp; You can imagine your immediate reaction to \"Why yes, my name is Alex, how did you know\" as well as your carefully deliberated response to the same data (if they're much different, be wary of <a href=\"http://www.overcomingbias.com/2007/07/belief-in-belie.html\">belief in belief</a>).&nbsp; The other neat thing is that it pulls up alternate hypotheses that you find more likely, and how likely you find those to be (eg. \"you know these people\").<br /><br />3) Map out the typical shape of your probability distributions (ie through calibration tests) and then go by how many standard deviations off the mean you are. If you're asked to give the probability that x&lt;C, you can find your one sigma confidence intervals and then pull up your curve to see what it predicts based on how far out C is<sup>2</sup>.<br /><br />4) Draw out your <a href=\"/lw/9x/metauncertainty/\">metaprobability distribution</a>, and take the mean.<br /><br />You may initially have different answers for each question, and in the end you have to decide which to trust when actually placing bets.<br /><br />I personally tend to lean towards 1 for intermediate probabilities, and 2 then 4 for very unlikely things.&nbsp; The betting model breaks down as risk gets high (either by high stakes or extreme odds), since we bet to maximize a utility function that is not linear in money.<br /><br />What other techniques do you use, and to how do you weight them?<br /><br /><br />&nbsp;<br /><strong>Footnotes:</strong><br /><br /><strong>1:</strong> A common name covers about 3% of the population, so p(b|!a) = 0.03^4 for 4 consecutive correct guesses, and p(b|a) ~=1 for sake of simplicity.&nbsp; Since p(a) is small, (1-p(a)) is approximated as 1.</p>\n<p>p(a|b) = p(b|a)*p(a)/p(b) = p(b|a)*p(a)/(p(b|a)*p(a)+p(b|!a)*(1-p(a)) =&gt; approximately 0.5 = p(a)/(p(a)+0.03^4) =&gt; p(a) = 0.03^4 ~= 1/1,000,000<br /><br /><strong>2:</strong> The idea came from <a href=\"/lw/77/selecting_rationalist_groups/\">paranoid debating</a> where Steve Rayhawk assumed a cauchy distribution. I tried to fit some data I had taken myself, but had insufficient statistics to figure out what the real shape is (if you guys have a bunch more data I could try again). It's also worth noting that the shape of one's probability distribution can change significantly from question to question so this would only apply in some cases.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"z95PGFXtPpwakqkTA": 1, "bh7uxTTqmsQ8jZJdB": 1, "5f5c37ee1b5cdee568cfb294": 1, "3uE2pXvbcnS9nnZRE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6Bz4TK37T8t5S3AbM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 27, "extendedScore": null, "score": 4.908954256035474e-07, "legacy": true, "legacyId": "501", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["neQ7eXuaXpiYw7SBy", "LKHJ2Askf92RBbhBp", "ZEj9ATpv3P22LSmnC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-29T13:48:56.070Z", "modifiedAt": null, "url": null, "title": "Fighting Akrasia: Incentivising Action", "slug": "fighting-akrasia-incentivising-action", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.674Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gworley", "createdAt": "2009-03-26T17:18:20.404Z", "isAdmin": false, "displayName": "G Gordon Worley III"}, "userId": "gjoi5eBQob27Lww62", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KW5m4eREWGitPb8Ev/fighting-akrasia-incentivising-action", "pageUrlRelative": "/posts/KW5m4eREWGitPb8Ev/fighting-akrasia-incentivising-action", "linkUrl": "https://www.lesswrong.com/posts/KW5m4eREWGitPb8Ev/fighting-akrasia-incentivising-action", "postedAtFormatted": "Wednesday, April 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fighting%20Akrasia%3A%20Incentivising%20Action&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFighting%20Akrasia%3A%20Incentivising%20Action%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKW5m4eREWGitPb8Ev%2Ffighting-akrasia-incentivising-action%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fighting%20Akrasia%3A%20Incentivising%20Action%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKW5m4eREWGitPb8Ev%2Ffighting-akrasia-incentivising-action", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKW5m4eREWGitPb8Ev%2Ffighting-akrasia-incentivising-action", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 554, "htmlBody": "<p><strong>Related To:</strong>&nbsp; <a href=\"/lw/7k/incremental_progress_and_the_valley/\">Incremental Progress and the Valley</a>, <a href=\"/lw/9w/silver_chairs_paternalism_and_akrasia/\">Silver Chairs, Paternalism, and Akrasia</a>, <a href=\"/lw/am/how_a_pathological_procrastinor_can_lose_weight/\">How a pathological procrastinator can lose weight</a></p>\n<p>Akrasia can strike anywhere, but one place it doesn't seem to strike too often or too severely, assuming you are employed, is in the work place.&nbsp; You may not want to do something, and it might take considerable willpower to perform a task, but unless you want to get fired <a href=\"/lw/d2/cached_procrastination/\">you can't always play Solitaire</a>.&nbsp; The reason is clear to most working folks:&nbsp; you have to do your job to keep it, and not keeping your job is often worse than performing an undesirable task, so you suck it up and find the willpower to make it through the day.&nbsp; So one question we might ask is, how can we take this motivational method and put it to our own use?</p>\n<p>First, let's look at the mechanics of the method.&nbsp; You have to perform a task and some exterior entity will pay you unless you fail utterly to perform the task.&nbsp; Notice that this is quite different from working for prizes, where you receive pay in exchange for performing a particular task.&nbsp; Financially they may appear the same, but from <a href=\"http://www.overcomingbias.com/2008/02/algorithm-feels.html\">the inside of the human mind</a> they are quite different.&nbsp; In the former case you are motivated by a potential loss, whereas in the later you are motivated by a potential gain.&nbsp; Since <a href=\"http://en.wikipedia.org/wiki/Loss_aversion\">losses carry more weight than gains</a>, in general the former model will provide more motivation than the latter, keeping in mind that loss aversion is a statistical property of human thought and there may be exceptions.</p>\n<p><a id=\"more\"></a></p>\n<p>This suggests that certain techniques will work better more often than others.&nbsp; For example, if you run a website about rationality and need programming work done for it, you have a couple of options.&nbsp; You can wait for someone to volunteer their time, you can offer a prize for implementing certain features for the site, or you can offer to pay someone to do it on the condition that if they don't meet certain deadlines they won't get paid or will be paid a lesser amount.&nbsp; If you aren't so lucky as to have someone come along who will volunteer their time and do a fantastic job for free, you are faced with accepting mediocre free work, offering prizes, or paying someone.&nbsp; Since prizes are usually inefficient, it appears that offering to pay someone is the best option, so long as you are able to stipulate that there will be no or reduced pay if the work is not done on time and to specification.</p>\n<p>It's also important that the entity with the authority to implement the loss reside outside the self.&nbsp; This is why, for example, a swear box works best if others are around to keep you honest (or if you're religious, believe that god is watching you):&nbsp; the temptation to let yourself slide just-this-one-time is too great.&nbsp; And this really comes back to an issue of akrasia:&nbsp; you don't have to expend any willpower for someone else to implement a loss on your part, whereas you do to make yourself take a loss.</p>\n<p>In what other ways can this method work?&nbsp; Post in the comments further examples of applying loss aversion to overcome akrasia, with particular attention to details of the methods that can make or break them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dqx5k65wjFfaiJ9sQ": 1, "r7qAjcbfhj2256EHH": 1, "3Y4y9Kr8e24YWAEmD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KW5m4eREWGitPb8Ev", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 11, "extendedScore": null, "score": 4.909422564420485e-07, "legacy": true, "legacyId": "493", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oZNXmHcdhb4m7vwsv", "WMYHEcs5tyFESkjsr", "Z6ESPufeiC4P8c8en", "5MmCYWKNnvAPWRBYL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-29T16:06:11.967Z", "modifiedAt": null, "url": null, "title": "Fire and Motion", "slug": "fire-and-motion", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:47.006Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rwallace", "createdAt": "2009-03-01T16:13:25.493Z", "isAdmin": false, "displayName": "rwallace"}, "userId": "cPhXNeZvnK7LgPMnv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SnGmTK4bSmtPTuZee/fire-and-motion", "pageUrlRelative": "/posts/SnGmTK4bSmtPTuZee/fire-and-motion", "linkUrl": "https://www.lesswrong.com/posts/SnGmTK4bSmtPTuZee/fire-and-motion", "postedAtFormatted": "Wednesday, April 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fire%20and%20Motion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFire%20and%20Motion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSnGmTK4bSmtPTuZee%2Ffire-and-motion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fire%20and%20Motion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSnGmTK4bSmtPTuZee%2Ffire-and-motion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSnGmTK4bSmtPTuZee%2Ffire-and-motion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p>Related to: <a href=\"/lw/9p/rationality_its_not_that_great/\">Extreme Rationality: It's Not That Great</a></p>\n<p>On the recent topics of \"rationality is all very well but how do we translate understanding into winning?\" and \"isn't akrasia the most common limiting factor?\", one of the best (non-recent) articles on practical rationality that I've come across is:</p>\n<p><a href=\"http://www.joelonsoftware.com/articles/fog0000000339.html\">http://www.joelonsoftware.com/articles/fog0000000339.html</a></p>\n<p>Interestingly, it uses a different kind of martial art as a metaphor. I conjecture it to be the sort of metaphor that just works well for humans.</p>\n<p>(Most of Spolsky's posts are good reading even if you're not a programmer. I'm not in the New York real estate market but I still enjoyed his posts on that topic. He's just that good a writer.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3QnDqGSdRMA5mdMM6": 1, "r7qAjcbfhj2256EHH": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SnGmTK4bSmtPTuZee", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 4.909627371312122e-07, "legacy": true, "legacyId": "468", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LgavAYtzFQZKg95WC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-29T18:47:59.414Z", "modifiedAt": null, "url": null, "title": "Fiction of interest", "slug": "fiction-of-interest", "viewCount": null, "lastCommentedAt": "2020-11-16T08:56:35.198Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dclayh", "createdAt": "2009-03-07T01:16:38.966Z", "isAdmin": false, "displayName": "dclayh"}, "userId": "E7xnxwP5EPuGiP99X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qMYjfAaYQddsqc3gS/fiction-of-interest", "pageUrlRelative": "/posts/qMYjfAaYQddsqc3gS/fiction-of-interest", "linkUrl": "https://www.lesswrong.com/posts/qMYjfAaYQddsqc3gS/fiction-of-interest", "postedAtFormatted": "Wednesday, April 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fiction%20of%20interest&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFiction%20of%20interest%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMYjfAaYQddsqc3gS%2Ffiction-of-interest%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fiction%20of%20interest%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMYjfAaYQddsqc3gS%2Ffiction-of-interest", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMYjfAaYQddsqc3gS%2Ffiction-of-interest", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 52, "htmlBody": "<p>The <a href=\"http://www.newyorker.com/fiction/features/2009/05/04/090504fi_fiction_hareven\">fiction piece</a> in this week's <em>New Yorker </em>deals with some of the same themes as Eliezer's \"<a href=\"http://www.overcomingbias.com/2009/01/three-worlds-collide.html\">Three Worlds Collide</a>\"; viz., the clash of value systems (and the difficulty of seeing those with a different value system as rational), and the idea of humanity developing in ways that seem bizarre/grotesque/evil to us.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 1, "wzgcQCrwKfETcBpR9": 1, "ouT6wKhACJRouGokM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qMYjfAaYQddsqc3gS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 14, "extendedScore": null, "score": 4.909867273937738e-07, "legacy": true, "legacyId": "503", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-29T19:15:01.162Z", "modifiedAt": null, "url": null, "title": "How Not to be Stupid: Adorable Maybes", "slug": "how-not-to-be-stupid-adorable-maybes", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:47.248Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/afZHsMD26ufh6BuaB/how-not-to-be-stupid-adorable-maybes", "pageUrlRelative": "/posts/afZHsMD26ufh6BuaB/how-not-to-be-stupid-adorable-maybes", "linkUrl": "https://www.lesswrong.com/posts/afZHsMD26ufh6BuaB/how-not-to-be-stupid-adorable-maybes", "postedAtFormatted": "Wednesday, April 29th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Not%20to%20be%20Stupid%3A%20Adorable%20Maybes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Not%20to%20be%20Stupid%3A%20Adorable%20Maybes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FafZHsMD26ufh6BuaB%2Fhow-not-to-be-stupid-adorable-maybes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Not%20to%20be%20Stupid%3A%20Adorable%20Maybes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FafZHsMD26ufh6BuaB%2Fhow-not-to-be-stupid-adorable-maybes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FafZHsMD26ufh6BuaB%2Fhow-not-to-be-stupid-adorable-maybes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 821, "htmlBody": "<p>Previous: <a href=\"/lw/dm/how_not_to_be_stupid_know_what_you_want_what_you/\">Know What You Want</a></p>\n<p>Ah wahned yah, ah wahned yah about the titles. &lt;/some enchanter named Tim&gt;</p>\n<p>(Oh, a note: the idea here is to establish general rules for what sorts of decisions one in principle ought to make, and how one in principle ought to know stuff, given that one wants to avoid Being Stupid. (in the sense described in earlier posts)&nbsp;So I'm giving some general and contrived hypothetical situations to throw at the system to try to break it, to see what properties it would have to have to not automatically fail.)</p>\n<p>Okay, so assuming you buy the argument in favor of ranked preferences, let's see what else we can learn by considering sources of, ahem, randomness:</p>\n<p>Suppose that either via indexical uncertainty, or it turns out there really is some nondeterminism in the universe, or there's some source of bits such that the only thing you're able to determine about it is that the ratio of 1s it puts out to total bits is p. You're not able to determine anything else about the pattern of bits, they seem unconnected to each other. In other words, you've got some source of uncertainty that leaves you only knowing that some outcomes happen more often than others, and potentially you know something about the precise relative rates of those outcomes.</p>\n<p>I'm trying here to avoid actually assuming epistemic probabilities. (If I've inserted an invisible assumption for such that I didn't notice, let me know.) Instead I'm trying to construct a situation in which that specific situation can be accepted as at least validly describable by something resembling probabilities (propensity or frequencies. (frequencies? aieeee! Burn the heretic, or at least flame them without mercy! :))) So,&nbsp;for whatever reason, suppose the universe or your opponent or whatever has access to such a source of bits. Let's consider some of the implications of this.</p>\n<p>For instance, suppose you prefer A &gt; B.</p>\n<p>Now, suppose you are somehow presented with the following choice: Choose B, or choose a situation in which if, at a specific instance, the source outputs a 1, A will occur. Otherwise, B occurs.&nbsp;We'll call this sort of situation a p*A + (1-p)*B lottery, or simply p*A + (1-p)*B</p>\n<p>So, which should you prefer? B or the above lottery? (assume there's no other cost other than declaring your choice. Or just wanting the choice. It's not a \"pay for a lottery ticket\" scenario yet. Just a \"assuming you simply choose one or the other... which do you choose?\")</p>\n<p>Consider our holy law of \"Don't Be Stupid\", specifcally in the manifestation of \"Don't automatically lose when you could potentially do better without risking doing worse. It would seem the correct answer would be \"choose the lottery, dangit!\" The only possible outcomes of it are A or B. So it can't possibly be worse than B, since you actually prefer A. Further, choosing B is accepting an automatic loss compared to chosing the above lottery which at least gives you a chance of to do better. (obviously we assume here that p is nonzero. In the degenerate case of p = 0, you'd presumably be indifferent between the lottery and B since, well... choosing that actually is the same thing as choosing B)</p>\n<p>By an exactly analogous argument, you should prefer A more than the lottery. Specifically, A is an automatic WIN compared to the lottery, which doesn't give you any hope of doing better than A, but does give you a chance of doing worse.</p>\n<p>Example: Imagine you're dying horribly of some really nasty disease that know isn't going to heal on its own and you're offered a possible medication for it. Assume there's no other medication available, and assume that somehow you know as a fact that none of the ways it could fail could possibly be worse. Further, assume that you know as a fact no one else on the planet has this disease, and the medication is availible for free to you and has already been prepared. (These last few assumptions are to remove any possible considerations like altruistically giving up your dose of the med to save another or similar.)</p>\n<p>Do you choose to take the medication or no? Well, by assumption, the outcome can't possibly be worse than what the disease will do to you, and there's the possibility that it will cure you. Further, there're no other options availible that may potentially be better than taking this med. (oh, assume for whatever reason cryo, so taking an ambulance ride to the future in hope of a better treatment is also not an option. Basically, assume your choices are \"die really really horribly\" or \"some chance of that, and some chance of making a full recovery. No chance of partially surviving in a state worse than death.\"</p>\n<p>So the obviously obvious choice is \"choose to take the medication.\"</p>\n<p>Next time: We actually do a bit more math based on what we've got so far and begin to actually construct utilities.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bh7uxTTqmsQ8jZJdB": 1, "hLp77TQsRkooioj86": 1, "HAFdXkW4YW4KRe2Gx": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "afZHsMD26ufh6BuaB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "502", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["H6d6Be4MzRxvz9eZT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-30T05:12:01.391Z", "modifiedAt": null, "url": null, "title": "Test", "slug": "test-56", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wmoore", "createdAt": "2009-02-17T05:49:50.396Z", "isAdmin": false, "displayName": "wmoore"}, "userId": "EgQZcMBqxf6sGmKfi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FyGaAy5jxu7LWEZzT/test-56", "pageUrlRelative": "/posts/FyGaAy5jxu7LWEZzT/test-56", "linkUrl": "https://www.lesswrong.com/posts/FyGaAy5jxu7LWEZzT/test-56", "postedAtFormatted": "Thursday, April 30th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Test&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATest%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFyGaAy5jxu7LWEZzT%2Ftest-56%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Test%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFyGaAy5jxu7LWEZzT%2Ftest-56", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFyGaAy5jxu7LWEZzT%2Ftest-56", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3, "htmlBody": "<p>asf <strong>bold</strong> asf</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FyGaAy5jxu7LWEZzT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 4.910800154975224e-07, "legacy": true, "legacyId": "505", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-30T12:48:52.437Z", "modifiedAt": null, "url": null, "title": "Rationalistic Losing", "slug": "rationalistic-losing", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:47.204Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MrHen", "createdAt": "2009-04-01T17:47:41.337Z", "isAdmin": false, "displayName": "MrHen"}, "userId": "HriC2mR9onYvGtwWr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XTmZbosXr3hRLT37x/rationalistic-losing", "pageUrlRelative": "/posts/XTmZbosXr3hRLT37x/rationalistic-losing", "linkUrl": "https://www.lesswrong.com/posts/XTmZbosXr3hRLT37x/rationalistic-losing", "postedAtFormatted": "Thursday, April 30th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalistic%20Losing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalistic%20Losing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXTmZbosXr3hRLT37x%2Frationalistic-losing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalistic%20Losing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXTmZbosXr3hRLT37x%2Frationalistic-losing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXTmZbosXr3hRLT37x%2Frationalistic-losing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1377, "htmlBody": "<h2>Playing to learn</h2>\n<p>I <em>like</em> losing. I don't even think that losing is necessarily evil. Personally, I believe this has less to do with a <a title=\"Stuck in the middle with Bruce\" href=\"/lw/9o/recommended_reading_stuck_in_the_middle_with_bruce/\">desire to lose</a> and more to do with curiosity about the game-space.</p>\n<p>Technically, my goals are probably shifted into some form of meta-winning &mdash; I like to understand winning or non-winning moves, strategies, and tactics. Actually <em>winning</em> is icing on the cake. The cake is learning as much as I can about whatever subject in which I am competing. I can do that if I win; I can do that if I lose.</p>\n<p>I still <em>prefer</em> winning and I <em>want</em> to win and I <a title=\"playing to win\" href=\"/lw/9r/playing_to_win/\">play to win</a>, but I <em>also</em> like losing. When I dive into a competition I will like the outcome. No matter what happens I will be happy because I will either (a) win or (b) lose and satiate my curiosity. Of course, learning is also possible while watching someone else lose and this generally makes winning more valuable than losing (I can watch them lose). It also provides a solid reason to watch and study other people play (or play myself and watch me \"lose\").</p>\n<p>The catch is that the valuable knowledge contained within winning has diminishing returns. When I fight I either (a) win or (b) lose and, as a completely separate event, (c) may have an interesting match to study. Ideally I get (a) and (c) but the odds of (c) get lower the more I dominate because my opponents could lose in a known fashion (by me winning in an \"old\" method). (c) should <em>always</em> be found next to (b). If there is a reason I lost I should learn the reason. If I knew the reason I should not have lost. Because of this, (c) offsets the negative of (b) and losing is valuable. This makes winning <em>and</em> losing worth the effort. When I lose, I win.</p>\n<p>Personally, I find (c) so valuable that I start getting bored when I no longer see anything to learn. If I keep winning over and over and never learn anything from the contest I have to find someone stronger to play or start losing creatively so that I can start learning again. Both of these solutions set up scenarios where I am increasing my chances to lose. Mathematically, this starts to make sense if the value of knowledge gained and the penalty of losing combine into something greater than winning without learning anything. (c - b &gt; a) My hunches tell me that I value winning too little and curiosity is starting to curb my desire to win. I am not playing to win; I am playing to learn.</p>\n<p><a href=\"/lw/cc/rationalistic_losing/#losingSummary\">skip to summary</a> <a name=\"losing1\"></a></p>\n<p><a id=\"more\"></a><br /> <a name=\"losing2\"></a></p>\n<h2>Losing is good</h2>\n<p>To be fair, I am specifically talking about winning within organized systems of competition. This generally means something like Magic: The Gathering, Go, or Mafia. Translating this onto Life is harder because I have more emotional investment in the outcome. The penalty of losing is stronger. If I lose a Game I know that the next round is entirely independent of this loss and there are minimal long-term effects to worry about. The consequences of losing will be much more severe if I screw up an investment portfolio or fail at attempting the perfect murder. To draw a finer line between life and gaming: If the win or loss means placing in a tournament with cash prizes the incentive for winning jumps well beyond the incentive to learn something new and I start playing to win. But is the pain of a loss inversely proportional to the value of a win? No, not necessarily.</p>\n<p>To map a tournament into payouts, say it costs $10 for entering and the prize for winning is $20. Losing at any point in the tournament has no monetary costs assigned to it. The $10 is a <a href=\"/lw/at/sunk_cost_fallacy/\">sunk cost</a> and the $20 is only eligible to winners. Losing has some intrinsic emotional penalty but, other than feeling icky, the loss simply gives another opportunity to learn. The value of winning is greater than that of losing, but losing still has value. Because it has value, losing is <em>good</em>.</p>\n<p>Life works the same way. If I am applying for a competitive job I should be playing to win because the payouts are enormous. Losing is a bummer, but the value in the loss is learning new information within the game-space of applying for jobs. Namely, this could mean properly building past experience or learning to sell yourself well. Because you learned something, you are better off than when you started <em>even though you lost</em>. Therefore, losing is good. Winning is <em>better</em>, but losing is still valuable. The cost of losing is not the same as flipping the value of winning negative. You did not \"lose\" the job because you never had it. You failed simply failed to win.</p>\n<p><br /> <a name=\"losing3\"></a></p>\n<h2>Irrational winning</h2>\n<p>Winning is great, but if there is no value in winning other than simply being the winner, losing may be worth more. Winning for the sake of winning is noble but useless. In such a scenario, playing to win may not be the most beneficial course. Playing to learn can result in a gain even if it means you \"lose\" the game. Looking at it rationalistically, \"losing\" is winning.</p>\n<p>If I play <a href=\"http://en.wikipedia.org/wiki/Carcassonne_(board_game)\">Carcassonne</a> against my opponents and whomp them thirty times in a row by repeating my best known strategies I will have gained nothing. If I decide to use the game as a learning experience to test new strategies I can create an opportunity to learn, but am no longer playing to win. If I play just strong enough to win I can learn <em>and</em> win but this is less valuable than simply learning as much as you can because the win <em>still means nothing</em>. And if it did than you should have played to win.</p>\n<p>A better example would be a movie ticket that you purchased for $10. The game-space revolves around whether or not you get more value out of watching a movie than what you spent on the ticket. If you purchase a non-refundable ticket in advance but, on the day of the movie, you do not feel like going to the movie the \"win\" would be staying home which is actually a \"loss\" in the original game. The losing scenario has changed because \"losing\" now has more value.</p>\n<p><em>Note:</em> This example is directly borrowed from Z_M_Davis's <a href=\"/lw/at/sunk_cost_fallacy/\">Sunk Cost Fallacy</a> article.</p>\n<p><em>Minor point:</em> In this example, the value of \"losing\" could be learning to not prepay for tickets or checking the weather first or learning from whatever caused you to mispredict your mood.</p>\n<p><br /> <a name=\"losing4\"></a></p>\n<h2>Rationalistic losing</h2>\n<p>Rationalistic losing is essentially acknowledging and playing a super-game so that no matter what happens, you win. In this super-game, playing to win does not mean winning the contest. It means getting something <em>valuable</em> from the contest. In the above examples, even though the contests were lost, the rationalist should still win by learning the information available. Losing should be good. If it wasn't, something went wrong before you got to this point. Do not rob yourself of the value of losing by focusing on the lost win.</p>\n<p>This principle is hard to see when it applies to something you really, really wanted to win. If you really, really wanted that job than losing <em>feels</em> like losing the job. If you skip the movie it <em>feels</em> like losing $10. But you never had the job and you already spent the $10. The only thing left to lose is information. You can still win the super-game if you are able to gather this information. This is rationalistic losing.</p>\n<p>There are many examples of, and exceptions to, this principle but the whole point can be boiled into this: <a name=\"losingSummary\"></a></p>\n<ol>\n<li>Assume a contest where you can win or lose.</li>\n<li>If there is value in winning the contest, play to win, otherwise play to learn.</li>\n<li>If you play to win and lose, learn why you lost.</li>\n<li>If you already knew why you lost, you were not playing to win.</li>\n<li>Learning why you lost is valuable.</li>\n<li>Learning after a loss means the loss was valuable.</li>\n<li>If the loss was valuable, the loss was \"good\".</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 1, "5f5c37ee1b5cdee568cfb117": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XTmZbosXr3hRLT37x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 7, "extendedScore": null, "score": 1.1e-05, "legacy": true, "legacyId": "444", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Playing_to_learn\">Playing to learn</h2>\n<p>I <em>like</em> losing. I don't even think that losing is necessarily evil. Personally, I believe this has less to do with a <a title=\"Stuck in the middle with Bruce\" href=\"/lw/9o/recommended_reading_stuck_in_the_middle_with_bruce/\">desire to lose</a> and more to do with curiosity about the game-space.</p>\n<p>Technically, my goals are probably shifted into some form of meta-winning \u2014 I like to understand winning or non-winning moves, strategies, and tactics. Actually <em>winning</em> is icing on the cake. The cake is learning as much as I can about whatever subject in which I am competing. I can do that if I win; I can do that if I lose.</p>\n<p>I still <em>prefer</em> winning and I <em>want</em> to win and I <a title=\"playing to win\" href=\"/lw/9r/playing_to_win/\">play to win</a>, but I <em>also</em> like losing. When I dive into a competition I will like the outcome. No matter what happens I will be happy because I will either (a) win or (b) lose and satiate my curiosity. Of course, learning is also possible while watching someone else lose and this generally makes winning more valuable than losing (I can watch them lose). It also provides a solid reason to watch and study other people play (or play myself and watch me \"lose\").</p>\n<p>The catch is that the valuable knowledge contained within winning has diminishing returns. When I fight I either (a) win or (b) lose and, as a completely separate event, (c) may have an interesting match to study. Ideally I get (a) and (c) but the odds of (c) get lower the more I dominate because my opponents could lose in a known fashion (by me winning in an \"old\" method). (c) should <em>always</em> be found next to (b). If there is a reason I lost I should learn the reason. If I knew the reason I should not have lost. Because of this, (c) offsets the negative of (b) and losing is valuable. This makes winning <em>and</em> losing worth the effort. When I lose, I win.</p>\n<p>Personally, I find (c) so valuable that I start getting bored when I no longer see anything to learn. If I keep winning over and over and never learn anything from the contest I have to find someone stronger to play or start losing creatively so that I can start learning again. Both of these solutions set up scenarios where I am increasing my chances to lose. Mathematically, this starts to make sense if the value of knowledge gained and the penalty of losing combine into something greater than winning without learning anything. (c - b &gt; a) My hunches tell me that I value winning too little and curiosity is starting to curb my desire to win. I am not playing to win; I am playing to learn.</p>\n<p><a href=\"/lw/cc/rationalistic_losing/#losingSummary\">skip to summary</a> <a name=\"losing1\"></a></p>\n<p><a id=\"more\"></a><br> <a name=\"losing2\"></a></p>\n<h2 id=\"Losing_is_good\">Losing is good</h2>\n<p>To be fair, I am specifically talking about winning within organized systems of competition. This generally means something like Magic: The Gathering, Go, or Mafia. Translating this onto Life is harder because I have more emotional investment in the outcome. The penalty of losing is stronger. If I lose a Game I know that the next round is entirely independent of this loss and there are minimal long-term effects to worry about. The consequences of losing will be much more severe if I screw up an investment portfolio or fail at attempting the perfect murder. To draw a finer line between life and gaming: If the win or loss means placing in a tournament with cash prizes the incentive for winning jumps well beyond the incentive to learn something new and I start playing to win. But is the pain of a loss inversely proportional to the value of a win? No, not necessarily.</p>\n<p>To map a tournament into payouts, say it costs $10 for entering and the prize for winning is $20. Losing at any point in the tournament has no monetary costs assigned to it. The $10 is a <a href=\"/lw/at/sunk_cost_fallacy/\">sunk cost</a> and the $20 is only eligible to winners. Losing has some intrinsic emotional penalty but, other than feeling icky, the loss simply gives another opportunity to learn. The value of winning is greater than that of losing, but losing still has value. Because it has value, losing is <em>good</em>.</p>\n<p>Life works the same way. If I am applying for a competitive job I should be playing to win because the payouts are enormous. Losing is a bummer, but the value in the loss is learning new information within the game-space of applying for jobs. Namely, this could mean properly building past experience or learning to sell yourself well. Because you learned something, you are better off than when you started <em>even though you lost</em>. Therefore, losing is good. Winning is <em>better</em>, but losing is still valuable. The cost of losing is not the same as flipping the value of winning negative. You did not \"lose\" the job because you never had it. You failed simply failed to win.</p>\n<p><br> <a name=\"losing3\"></a></p>\n<h2 id=\"Irrational_winning\">Irrational winning</h2>\n<p>Winning is great, but if there is no value in winning other than simply being the winner, losing may be worth more. Winning for the sake of winning is noble but useless. In such a scenario, playing to win may not be the most beneficial course. Playing to learn can result in a gain even if it means you \"lose\" the game. Looking at it rationalistically, \"losing\" is winning.</p>\n<p>If I play <a href=\"http://en.wikipedia.org/wiki/Carcassonne_(board_game)\">Carcassonne</a> against my opponents and whomp them thirty times in a row by repeating my best known strategies I will have gained nothing. If I decide to use the game as a learning experience to test new strategies I can create an opportunity to learn, but am no longer playing to win. If I play just strong enough to win I can learn <em>and</em> win but this is less valuable than simply learning as much as you can because the win <em>still means nothing</em>. And if it did than you should have played to win.</p>\n<p>A better example would be a movie ticket that you purchased for $10. The game-space revolves around whether or not you get more value out of watching a movie than what you spent on the ticket. If you purchase a non-refundable ticket in advance but, on the day of the movie, you do not feel like going to the movie the \"win\" would be staying home which is actually a \"loss\" in the original game. The losing scenario has changed because \"losing\" now has more value.</p>\n<p><em>Note:</em> This example is directly borrowed from Z_M_Davis's <a href=\"/lw/at/sunk_cost_fallacy/\">Sunk Cost Fallacy</a> article.</p>\n<p><em>Minor point:</em> In this example, the value of \"losing\" could be learning to not prepay for tickets or checking the weather first or learning from whatever caused you to mispredict your mood.</p>\n<p><br> <a name=\"losing4\"></a></p>\n<h2 id=\"Rationalistic_losing\">Rationalistic losing</h2>\n<p>Rationalistic losing is essentially acknowledging and playing a super-game so that no matter what happens, you win. In this super-game, playing to win does not mean winning the contest. It means getting something <em>valuable</em> from the contest. In the above examples, even though the contests were lost, the rationalist should still win by learning the information available. Losing should be good. If it wasn't, something went wrong before you got to this point. Do not rob yourself of the value of losing by focusing on the lost win.</p>\n<p>This principle is hard to see when it applies to something you really, really wanted to win. If you really, really wanted that job than losing <em>feels</em> like losing the job. If you skip the movie it <em>feels</em> like losing $10. But you never had the job and you already spent the $10. The only thing left to lose is information. You can still win the super-game if you are able to gather this information. This is rationalistic losing.</p>\n<p>There are many examples of, and exceptions to, this principle but the whole point can be boiled into this: <a name=\"losingSummary\"></a></p>\n<ol>\n<li>Assume a contest where you can win or lose.</li>\n<li>If there is value in winning the contest, play to win, otherwise play to learn.</li>\n<li>If you play to win and lose, learn why you lost.</li>\n<li>If you already knew why you lost, you were not playing to win.</li>\n<li>Learning why you lost is valuable.</li>\n<li>Learning after a loss means the loss was valuable.</li>\n<li>If the loss was valuable, the loss was \"good\".</li>\n</ol>", "sections": [{"title": "Playing to learn", "anchor": "Playing_to_learn", "level": 1}, {"title": "Losing is good", "anchor": "Losing_is_good", "level": 1}, {"title": "Irrational winning", "anchor": "Irrational_winning", "level": 1}, {"title": "Rationalistic losing", "anchor": "Rationalistic_losing", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "17 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FZaDFYbnRoHmde7F6", "Zrg8zohTAJKGAo5if", "tyMdPwd8x2RygcheE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-04-30T18:24:24.865Z", "modifiedAt": null, "url": null, "title": "Rationalist Role in the Information Age", "slug": "rationalist-role-in-the-information-age", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:52.569Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "byrnema", "createdAt": "2009-03-20T18:02:38.305Z", "isAdmin": false, "displayName": "byrnema"}, "userId": "SCnD6W8NiztYBN39M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jLCtiGwmMJR4ktwbY/rationalist-role-in-the-information-age", "pageUrlRelative": "/posts/jLCtiGwmMJR4ktwbY/rationalist-role-in-the-information-age", "linkUrl": "https://www.lesswrong.com/posts/jLCtiGwmMJR4ktwbY/rationalist-role-in-the-information-age", "postedAtFormatted": "Thursday, April 30th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20Role%20in%20the%20Information%20Age&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20Role%20in%20the%20Information%20Age%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLCtiGwmMJR4ktwbY%2Frationalist-role-in-the-information-age%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20Role%20in%20the%20Information%20Age%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLCtiGwmMJR4ktwbY%2Frationalist-role-in-the-information-age", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLCtiGwmMJR4ktwbY%2Frationalist-role-in-the-information-age", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 809, "htmlBody": "<p><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> </w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" LatentStyleCount=\"156\"> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\"; mso-ansi-language:#0400; mso-fareast-language:#0400; mso-bidi-language:#0400;} --> <!--[endif]--><span style=\"font-size: 12pt; font-weight: normal;\">In response to <a href=\"/lw/ay/marketing_rationalism\">Marketing rationalism</a>, <a href=\"/lw/9j/bystander_apathy\">Bystander Apathy</a>, Step N1 in </span><a href=\"/lw/9t/extreme_rationality_it_could_be_great\">Extreme Rationality: It Could Be Great</a>, and<a href=\"../lw/66/rationality_common_interest_of_many_causes/\"> Rationality: Common Interest of Many Causes.</a></p>\n<p class=\"MsoNormal\">The problem that motivates this post is:<br />&nbsp;&ldquo;Given a controversial question in which there are good and bad arguments on both sides, as well as unreliable and conflicting information, how do you determine the answer when you&rsquo;re not yourself an expert in the subject?&rdquo;</p>\n<p class=\"MsoNormal\">Well into the information age, we are still not pooling our resources in the most efficient way to get to the bottom of things. It would be enormously useful to develop some kind of group strategy to answer questions that have solutions somewhere <a href=\"http://www.beyondthemap.ca/english/explore_web.html\">in there</a>.</p>\n<p class=\"MsoNormal\">The idea I'm presenting is a way to apply our intellectual (and rational) resources in a niche way, that I will shortly describe, to facilitate public (non-expert) understanding of real world problems.</p>\n<p class=\"MsoNormal\"><strong>The Niche and the Need</strong></p>\n<p class=\"MsoNormal\">Science, obviously, does the best job of solving problems. I'm confident that epidemiologists are effectively and efficiently working on the best models for pandemics as I write this post.</p>\n<p class=\"MsoNormal\">And journalists do a pretty good job of what they do: providing information about what the scientists are doing. What's best about how journalists do that is that they always provide the source of the information, so that a rational person can judge the truth-value of that information. A qualified and rational person can then put the information in perspective.</p>\n<p class=\"MsoNormal\">Alas, people are not so good at interpreting the information: they are neither rational in weighting the information nor qualified to put it in perspective. (Presumably, the epidemiologists are too busy to do this.)</p>\n<p class=\"MsoNormal\">Interpreting information correctly is a service that rationalists could provide.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\"><strong>How we could do it:</strong></p>\n<p class=\"MsoNormal\">1. Information culled from various sources would be posted in the first half of a post titled P and updated continuously.</p>\n<p class=\"MsoNormal\">2. As a rational group, within threads, we would discuss interpretations and implications of the available information.</p>\n<p class=\"MsoNormal\">3. Only consensus views would be presented in the second half of the post P, updated continuously to prioritize the most relevant information on top.</p>\n<p class=\"MsoNormal\"><strong>Why we would do it</strong></p>\n<p class=\"MsoNormal\">1. It would be objectively and enormously useful to cull useful and consensus interpretations. It is a time-consuming task even for a qualified person, as a group we would be effective.</p>\n<p class=\"MsoNormal\">2. It would be a good demonstration of the usefulness of rationality.</p>\n<p class=\"MsoNormal\">3. I would strongly recommend against any kind of advertisement, but if people from the general public <em>happened </em>to come there and <em>happened</em> to find the information exceptionally useful, rationality would be considered a useful and practical thing (and they would be inclined to fund the organization that provided this service).</p>\n<p class=\"MsoNormal\">I'm motivated to do this because I feel like this is exactly what is missing in the information age. We have science and we have journalism but we need something more. Blogs are doing it, but not effectively because they are doing it as individuals (with comments, which is helpful), and they're not generally responsive to feedback and new information. I think LW has the intellectual resources and the correct problem solving paradigm to be successful.</p>\n<p class=\"MsoNormal\"><strong>Small Scale verses Large Scale</strong></p>\n<p class=\"MsoNormal\">On a small scale, it could be done here, just among ourselves. If on a large scale, eventually, it would be done <em>somewhere else</em>. There, I see Huge Opportunity.</p>\n<p class=\"MsoNormal\"><em>Large Scale Idea:</em></p>\n<p class=\"MsoNormal\">A library of posts. Each post would address a different problem and would be mediated by a particular individual. If someone in the general public is interested in a particular problem, they will go to that post for information. More important and relevant topics will have more activity.</p>\n<p class=\"MsoNormal\">There would be interaction between the post and the public via threads, and between the post and other blogs on the internet via <em>people</em> navigating back and forth and sharing information.</p>\n<p class=\"MsoNormal\">A post is mediated by a person or group concerned about that topic. There will be limitations associated (the mediator may not be rational enough, the mediator might be biased), so we would allow competition by allowing several posts on one topic. Here, the karma scoring would be enormously useful to help people decide which post is worth going to.</p>\n<p class=\"MsoNormal\">Popular and relevant posts would get traffic and funding.</p>\n<p class=\"MsoNormal\">The reason why this has <em>a chance of working</em>, if it isn't obvious, is because of the karma system. The problem in the information age is TMI (too much information), and the karma system solves that. We would have to instruct people, until it becomes the ethical standard, that noise and errors get down-voted, new information and plausible dissenting views get upvoted.</p>\n<p class=\"MsoNormal\"><em>Small scale idea:</em></p>\n<p class=\"MsoNormal\">If there is interest in this idea, either small scale or large scale, I would like to suggest beginning with a post on swine flu. Volunteers to mediate the post could submit credentials and we would choose a team. We would open a new LW account to be shared by the team so that they can mediate the post collectively.</p>\n<p class=\"MsoNormal\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YPZCAs9Axp9PtrF22": 1, "Ng8Gice9KNkncxqcj": 1, "izp6eeJJEg9v5zcur": 1, "xgpBASEThXPuKRhbS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jLCtiGwmMJR4ktwbY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 7, "extendedScore": null, "score": 1.1e-05, "legacy": true, "legacyId": "509", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> </w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" LatentStyleCount=\"156\"> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\"; mso-ansi-language:#0400; mso-fareast-language:#0400; mso-bidi-language:#0400;} --> <!--[endif]--><span style=\"font-size: 12pt; font-weight: normal;\">In response to <a href=\"/lw/ay/marketing_rationalism\">Marketing rationalism</a>, <a href=\"/lw/9j/bystander_apathy\">Bystander Apathy</a>, Step N1 in </span><a href=\"/lw/9t/extreme_rationality_it_could_be_great\">Extreme Rationality: It Could Be Great</a>, and<a href=\"../lw/66/rationality_common_interest_of_many_causes/\"> Rationality: Common Interest of Many Causes.</a></p>\n<p class=\"MsoNormal\">The problem that motivates this post is:<br>&nbsp;\u201cGiven a controversial question in which there are good and bad arguments on both sides, as well as unreliable and conflicting information, how do you determine the answer when you\u2019re not yourself an expert in the subject?\u201d</p>\n<p class=\"MsoNormal\">Well into the information age, we are still not pooling our resources in the most efficient way to get to the bottom of things. It would be enormously useful to develop some kind of group strategy to answer questions that have solutions somewhere <a href=\"http://www.beyondthemap.ca/english/explore_web.html\">in there</a>.</p>\n<p class=\"MsoNormal\">The idea I'm presenting is a way to apply our intellectual (and rational) resources in a niche way, that I will shortly describe, to facilitate public (non-expert) understanding of real world problems.</p>\n<p class=\"MsoNormal\"><strong id=\"The_Niche_and_the_Need\">The Niche and the Need</strong></p>\n<p class=\"MsoNormal\">Science, obviously, does the best job of solving problems. I'm confident that epidemiologists are effectively and efficiently working on the best models for pandemics as I write this post.</p>\n<p class=\"MsoNormal\">And journalists do a pretty good job of what they do: providing information about what the scientists are doing. What's best about how journalists do that is that they always provide the source of the information, so that a rational person can judge the truth-value of that information. A qualified and rational person can then put the information in perspective.</p>\n<p class=\"MsoNormal\">Alas, people are not so good at interpreting the information: they are neither rational in weighting the information nor qualified to put it in perspective. (Presumably, the epidemiologists are too busy to do this.)</p>\n<p class=\"MsoNormal\">Interpreting information correctly is a service that rationalists could provide.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\"><strong id=\"How_we_could_do_it_\">How we could do it:</strong></p>\n<p class=\"MsoNormal\">1. Information culled from various sources would be posted in the first half of a post titled P and updated continuously.</p>\n<p class=\"MsoNormal\">2. As a rational group, within threads, we would discuss interpretations and implications of the available information.</p>\n<p class=\"MsoNormal\">3. Only consensus views would be presented in the second half of the post P, updated continuously to prioritize the most relevant information on top.</p>\n<p class=\"MsoNormal\"><strong id=\"Why_we_would_do_it\">Why we would do it</strong></p>\n<p class=\"MsoNormal\">1. It would be objectively and enormously useful to cull useful and consensus interpretations. It is a time-consuming task even for a qualified person, as a group we would be effective.</p>\n<p class=\"MsoNormal\">2. It would be a good demonstration of the usefulness of rationality.</p>\n<p class=\"MsoNormal\">3. I would strongly recommend against any kind of advertisement, but if people from the general public <em>happened </em>to come there and <em>happened</em> to find the information exceptionally useful, rationality would be considered a useful and practical thing (and they would be inclined to fund the organization that provided this service).</p>\n<p class=\"MsoNormal\">I'm motivated to do this because I feel like this is exactly what is missing in the information age. We have science and we have journalism but we need something more. Blogs are doing it, but not effectively because they are doing it as individuals (with comments, which is helpful), and they're not generally responsive to feedback and new information. I think LW has the intellectual resources and the correct problem solving paradigm to be successful.</p>\n<p class=\"MsoNormal\"><strong id=\"Small_Scale_verses_Large_Scale\">Small Scale verses Large Scale</strong></p>\n<p class=\"MsoNormal\">On a small scale, it could be done here, just among ourselves. If on a large scale, eventually, it would be done <em>somewhere else</em>. There, I see Huge Opportunity.</p>\n<p class=\"MsoNormal\"><em>Large Scale Idea:</em></p>\n<p class=\"MsoNormal\">A library of posts. Each post would address a different problem and would be mediated by a particular individual. If someone in the general public is interested in a particular problem, they will go to that post for information. More important and relevant topics will have more activity.</p>\n<p class=\"MsoNormal\">There would be interaction between the post and the public via threads, and between the post and other blogs on the internet via <em>people</em> navigating back and forth and sharing information.</p>\n<p class=\"MsoNormal\">A post is mediated by a person or group concerned about that topic. There will be limitations associated (the mediator may not be rational enough, the mediator might be biased), so we would allow competition by allowing several posts on one topic. Here, the karma scoring would be enormously useful to help people decide which post is worth going to.</p>\n<p class=\"MsoNormal\">Popular and relevant posts would get traffic and funding.</p>\n<p class=\"MsoNormal\">The reason why this has <em>a chance of working</em>, if it isn't obvious, is because of the karma system. The problem in the information age is TMI (too much information), and the karma system solves that. We would have to instruct people, until it becomes the ethical standard, that noise and errors get down-voted, new information and plausible dissenting views get upvoted.</p>\n<p class=\"MsoNormal\"><em>Small scale idea:</em></p>\n<p class=\"MsoNormal\">If there is interest in this idea, either small scale or large scale, I would like to suggest beginning with a post on swine flu. Volunteers to mediate the post could submit credentials and we would choose a team. We would open a new LW account to be shared by the team so that they can mediate the post collectively.</p>\n<p class=\"MsoNormal\">&nbsp;</p>", "sections": [{"title": "The Niche and the Need", "anchor": "The_Niche_and_the_Need", "level": 1}, {"title": "How we could do it:", "anchor": "How_we_could_do_it_", "level": 1}, {"title": "Why we would do it", "anchor": "Why_we_would_do_it", "level": 1}, {"title": "Small Scale verses Large Scale", "anchor": "Small_Scale_verses_Large_Scale", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "19 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["G5bDjtSbJwbXuji4r", "K5nq3KcDXaGm7QQWR", "B3b29FJboqnANJRDz", "4PPE6D635iBcGPGRy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-01T01:41:14.146Z", "modifiedAt": null, "url": null, "title": "Conventions and Confusing Continuity Conundrums", "slug": "conventions-and-confusing-continuity-conundrums", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:47.368Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/25AYXth87fCN6w8zJ/conventions-and-confusing-continuity-conundrums", "pageUrlRelative": "/posts/25AYXth87fCN6w8zJ/conventions-and-confusing-continuity-conundrums", "linkUrl": "https://www.lesswrong.com/posts/25AYXth87fCN6w8zJ/conventions-and-confusing-continuity-conundrums", "postedAtFormatted": "Friday, May 1st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Conventions%20and%20Confusing%20Continuity%20Conundrums&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConventions%20and%20Confusing%20Continuity%20Conundrums%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F25AYXth87fCN6w8zJ%2Fconventions-and-confusing-continuity-conundrums%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Conventions%20and%20Confusing%20Continuity%20Conundrums%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F25AYXth87fCN6w8zJ%2Fconventions-and-confusing-continuity-conundrums", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F25AYXth87fCN6w8zJ%2Fconventions-and-confusing-continuity-conundrums", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 265, "htmlBody": "<p>The next \"How Not to be Stupid\" may be a bit delayed for a couple of reasons.</p>\n<p>First, there appears to be a certain unstated continuity assumption in the material I've been working from that would probably be relevant for the next posting. As I said in the intro post, I'm working from Stephen Omhunduro's vulnerability argument, but filling in what I viewed as missing bits, generalizing one or two things, and so on. Anyways, the short of it is I thought that I was able to how to derive the relevant continuity condition, but turns out I need to think about that a bit more carefully.</p>\n<p>If I remain stumped on that bit, I'll just post and explicitly state the assumption, pointing it out as a potential problem area that needs to be dealt with one way or another. ie, either solved somehow, or demonstrate that it actually is invalid (thus causing some issues for decision theory...)</p>\n<p>Also, I'm going to be at Penguicon the next few days.</p>\n<p>Actually, I think I'll right now state the continuity condition I need, let others play with it too:</p>\n<p>Basically, I need it to be that if there's a preference ranking A &gt; C &gt; B, there must exist some p such that the p*A + (1-p)*B lottery ranks equal to C. (That is, that the mixing lotteries correspond to a smooth spectrum of preferences between, well, the things they are a mixing of rather than having any discontinuous jumps.)</p>\n<p>Anyways, I hope we can put this little trouble bit behind us and resume climbing the shining path of awakening to nonstupidity. :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zs4nYLkNr7Rbo4mAP": 1, "ouT6wKhACJRouGokM": 1, "MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "25AYXth87fCN6w8zJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 7e-06, "legacy": true, "legacyId": "510", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-01T16:16:35.156Z", "modifiedAt": null, "url": null, "title": "Open Thread: May 2009", "slug": "open-thread-may-2009", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:06.882Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "steven0461", "createdAt": "2009-02-27T16:16:38.980Z", "isAdmin": false, "displayName": "steven0461"}, "userId": "cn4SiEmqWbu7K9em5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/n3xFPYWaPfNqMwRwC/open-thread-may-2009", "pageUrlRelative": "/posts/n3xFPYWaPfNqMwRwC/open-thread-may-2009", "linkUrl": "https://www.lesswrong.com/posts/n3xFPYWaPfNqMwRwC/open-thread-may-2009", "postedAtFormatted": "Friday, May 1st 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%3A%20May%202009&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%3A%20May%202009%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fn3xFPYWaPfNqMwRwC%2Fopen-thread-may-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%3A%20May%202009%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fn3xFPYWaPfNqMwRwC%2Fopen-thread-may-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fn3xFPYWaPfNqMwRwC%2Fopen-thread-may-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p>Here is our monthly place to discuss Less Wrong topics that have not appeared in recent posts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "n3xFPYWaPfNqMwRwC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 4.913943501231766e-07, "legacy": true, "legacyId": "515", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 210, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-02T00:17:55.558Z", "modifiedAt": null, "url": null, "title": "Second London Rationalist Meeting upcoming - Sunday 14:00", "slug": "second-london-rationalist-meeting-upcoming-sunday-14-00", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:48.344Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7PAAJofAe5hTMeSFT/second-london-rationalist-meeting-upcoming-sunday-14-00", "pageUrlRelative": "/posts/7PAAJofAe5hTMeSFT/second-london-rationalist-meeting-upcoming-sunday-14-00", "linkUrl": "https://www.lesswrong.com/posts/7PAAJofAe5hTMeSFT/second-london-rationalist-meeting-upcoming-sunday-14-00", "postedAtFormatted": "Saturday, May 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Second%20London%20Rationalist%20Meeting%20upcoming%20-%20Sunday%2014%3A00&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASecond%20London%20Rationalist%20Meeting%20upcoming%20-%20Sunday%2014%3A00%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7PAAJofAe5hTMeSFT%2Fsecond-london-rationalist-meeting-upcoming-sunday-14-00%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Second%20London%20Rationalist%20Meeting%20upcoming%20-%20Sunday%2014%3A00%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7PAAJofAe5hTMeSFT%2Fsecond-london-rationalist-meeting-upcoming-sunday-14-00", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7PAAJofAe5hTMeSFT%2Fsecond-london-rationalist-meeting-upcoming-sunday-14-00", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<p>The second meeting will take place on Sunday (2009-05-03) 14:00, in cafe on top of the Waterstones bookstore near the Piccadilly Circus Tube station.</p>\n<p>If you want to know more, email me (Tomasz.Wegrzanowski@gmail.com) for details. Or just come straight away.</p>\n<p>If you're wondering what it will be like - <a href=\"/lw/7r/the_first_london_rationalist_meetup/\">here's summary of the first meeting</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7PAAJofAe5hTMeSFT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 3, "extendedScore": null, "score": 4.914661404626223e-07, "legacy": true, "legacyId": "516", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DMmzrGnxaPs4mtFsH"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-02T03:32:09.269Z", "modifiedAt": null, "url": null, "title": "TED Talks for Less Wrong", "slug": "ted-talks-for-less-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:33.273Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8JEuBXi3gCT5ZpDBr/ted-talks-for-less-wrong", "pageUrlRelative": "/posts/8JEuBXi3gCT5ZpDBr/ted-talks-for-less-wrong", "linkUrl": "https://www.lesswrong.com/posts/8JEuBXi3gCT5ZpDBr/ted-talks-for-less-wrong", "postedAtFormatted": "Saturday, May 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20TED%20Talks%20for%20Less%20Wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATED%20Talks%20for%20Less%20Wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8JEuBXi3gCT5ZpDBr%2Fted-talks-for-less-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=TED%20Talks%20for%20Less%20Wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8JEuBXi3gCT5ZpDBr%2Fted-talks-for-less-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8JEuBXi3gCT5ZpDBr%2Fted-talks-for-less-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<p><a href=\"http://www.youtube.com/watch?v=nUdsTizSxSI\">Dan Ariely talks about pain and cheating.</a> In a nutshell: people report less pain when (i) they experience the strongest pain first; (ii) they experience less pain for a longer interval rather than more pain for a shorter interval; (iii) they can take breaks. The data falsifies the common intuition that people will prefer short, high intensity pain. In general, people tend to&nbsp;cheat more when (i) they obtain things other than actual cash; (ii) they observe in-group members cheating successfully; they tend to cheat less when (i) they take away cash; (ii) they observe out-group members cheating successfully; (iii) they experience priming with moral concepts such as the Ten Commandments.</p>\n<p>Post yours in comments. I've put a couple with the theme \"how brains work\" down there.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"LaDu5bKDpe8LxaR7C": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8JEuBXi3gCT5ZpDBr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 15, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "401", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-02T16:49:19.539Z", "modifiedAt": null, "url": null, "title": "The mind-killer", "slug": "the-mind-killer", "viewCount": null, "lastCommentedAt": "2017-06-17T03:55:51.161Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yfxp4Y6YETjjtChFh/the-mind-killer", "pageUrlRelative": "/posts/yfxp4Y6YETjjtChFh/the-mind-killer", "linkUrl": "https://www.lesswrong.com/posts/yfxp4Y6YETjjtChFh/the-mind-killer", "postedAtFormatted": "Saturday, May 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20mind-killer&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20mind-killer%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyfxp4Y6YETjjtChFh%2Fthe-mind-killer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20mind-killer%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyfxp4Y6YETjjtChFh%2Fthe-mind-killer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyfxp4Y6YETjjtChFh%2Fthe-mind-killer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 562, "htmlBody": "<p>Can we talk about changing the world? Or saving the world?</p>\n<p>I think few here would give an estimate higher than 95% for the probability that humanity will survive the next 100 years; plenty might put a figure less than 50% on it.  So if you place any non-negligible value on future generations whose existence is threatened, reducing existential risk has to be the best possible contribution to humanity you are in a position to make.  Given that existential risk is also one of the major themes of Overcoming Bias and of Eliezer's work, it's striking that we don't talk about it more here.</p>\n<p>One reason of course was the bar until yesterday on talking about artificial general intelligence; another factor are the many who state in terms that they are not concerned about their contribution to humanity.  But I think a third is that many of the things we might do to address existential risk, or other issues of concern to all humanity, get us into politics, and we've all had too much of <a href=\"http://www.overcomingbias.com/2007/02/politics_is_the.html\">a certain kind of argument about politics online</a> that gets into a stale rehashing of talking points and point scoring.</p>\n<p>If we here can't do better than that, then this whole rationality discussion we've been having comes to no more than how we can best get out of bed in the morning, solve a puzzle set by a powerful superintelligence in the afternoon, and get laid in the evening.  How can we use what we discuss here to be able to talk about politics without spiralling down the plughole?</p>\n<p>I think it will help in several ways that we are a largely community of materialists and expected utility consequentialists.  For a start, we are freed from the concept of \"deserving\" that dogs political arguments on inequality, on human rights, on criminal sentencing and so many other issues; while I can imagine a consequentialism that valued the \"deserving\" more than the \"undeserving\", I don't get the impression that's a popular position among materialists because of the <a href=\"http://en.wikipedia.org/wiki/Phineas_Gage\">Phineas Gage</a> problem.  We need not ask whether the rich deserve their wealth, or who is ultimately to blame for a thing; every question must come down only to what decision will maximize utility.</p>\n<p>For example, framed this way inequality of wealth is not justice or injustice.  The consequentialist defence of the market recognises that because of the diminishing marginal utility of wealth, today's unequal distribution of wealth has a cost in utility compared to the same wealth divided equally, a cost that we could in principle measure given a wealth/utility curve, and goes on to argue that the total extra output resulting from this inequality more than pays for it.</p>\n<p>However, I'm more confident of the need to talk about this question than I am of my own answers. There's very little we can do about existential risk that doesn't have to do with changing the decisions made by public servants, businesses, and/or large numbers of people, and all of these activities get us straight into the world of politics, as well as the world of going out and changing minds.  There has to be a way for rationalists to talk about it and actually make a difference.  Before we start to talk about specific ideas to do with what one does in order to change or save the world, what traps can we defuse in advance?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FkzScn5byCs9PxGsA": 1, "Rz5jb3cYHTSRmqNnN": 1, "ZFrgTgzwEfStg26JL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yfxp4Y6YETjjtChFh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 29, "extendedScore": null, "score": 4.2e-05, "legacy": true, "legacyId": "518", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 160, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-02T23:47:32.013Z", "modifiedAt": null, "url": null, "title": "What I Tell You Three Times Is True", "slug": "what-i-tell-you-three-times-is-true", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:26.852Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B4AyJXYPpGbBmxQzd/what-i-tell-you-three-times-is-true", "pageUrlRelative": "/posts/B4AyJXYPpGbBmxQzd/what-i-tell-you-three-times-is-true", "linkUrl": "https://www.lesswrong.com/posts/B4AyJXYPpGbBmxQzd/what-i-tell-you-three-times-is-true", "postedAtFormatted": "Saturday, May 2nd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20I%20Tell%20You%20Three%20Times%20Is%20True&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20I%20Tell%20You%20Three%20Times%20Is%20True%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB4AyJXYPpGbBmxQzd%2Fwhat-i-tell-you-three-times-is-true%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20I%20Tell%20You%20Three%20Times%20Is%20True%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB4AyJXYPpGbBmxQzd%2Fwhat-i-tell-you-three-times-is-true", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB4AyJXYPpGbBmxQzd%2Fwhat-i-tell-you-three-times-is-true", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1261, "htmlBody": "<p><em>\"The human brain evidently operates on some variation of the famous principle enunciated in 'The Hunting of the Snark</em><em>': 'What I tell you three times is true.'\"</em></p>\n<p>&nbsp;&nbsp; -- Norbert Weiner, from <em>Cybernetics</em></p>\n<p>Ask for a high-profile rationalist, and you'll hear about Richard Dawkins or James Randi or maybe Peter Thiel. Not a lot of people would immediately name Scott Adams, creator of Dilbert. But as readers of <a href=\"http://www.dilbert.com/blog\">his blog</a> know, he's got a deep interest in rationality, and sometimes it shows up in his comics: for example, <a href=\"http://www.dilbert.com/2009-04-27/\">this one from last week</a>. How many people can expose several million people to the phrase \"Boltzmann brain hypothesis\" and have them enjoy it?<br /><br />So I was very surprised to find Adams <a href=\"http://mindhacks.org/scott-adams-affirmations/135/\">was a believer in and evangelist of something that sounded a lot like pseudoscience</a>. \"Affirmations\" are positive statements made with the belief that saying the statement loud enough and long enough will help it come true. For example, you might say \"I will become a syndicated cartoonist\" fifteen times before bed every night, thinking that this will in fact make you a syndicated cartoonist. Adams partially credits his success as a cartoonist to doing exactly this.<br /><br />He admits \"it sounds as if I believe in some sort of voodoo or magic\", and acknowledges that \"skeptics have suggested, and reasonably so, that this is a classic case of selective memory\" but still swears that it works. He also has \"received thousands of e-mails from people recounting their own experiences with affirmations. Most people seem to be amazed at how well they worked.\"<br /><br />None of this should be taken too seriously without a controlled scientific study investigating it, of course. But is it worth the effort of a study, or should it be filed under \"so stupid that it's not worth anyone's time to investigate further\"?<br /><br />I think there's a good case to be made from within a rationalist/scientific worldview that affirmations may in fact be effective for certain goals. Not miraculously effective, but not totally useless either.</p>\n<p><a id=\"more\"></a></p>\n<p>To build this case, I want to provide evidence for two propositions. First, that whether we subconsciously believe we can succeed affects whether or not we succeed. Second, that repeating a statement verbally can make the subconscious believe it.<br /><br />The link between belief in success and success has progressed beyond the motivational speaker stage and into the scientific evidence stage. The best-known of these links is the placebo effect. For certain diseases, believing that you will get better does increase your probability of getting better. This works not only subjectively (ie you feel less pain) but objectively (ie ulcers heal more quickly, inflammation decreases).<br /><br />The placebo effect applies in some stranger cases outside simple curative drugs. A placebo stop-smoking pill <a href=\"http://www.ncbi.nlm.nih.gov/sites/entrez?cmd=retrieve&amp;db=pubmed&amp;list_uids=15796644&amp;dopt=Abstract\">does increase your chance of successfully quitting tobacco</a>. Placebo strength pills enable you to <a href=\"http://www.cababstractsplus.org/abstracts/Abstract.aspx?AcNo=20073179143\">run faster</a> and lift more weight. Placebo alcohol <a href=\"http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1403295\">makes you more gregarious and less inhibited</a><sup>1</sup>. Placebo therapies for phobia can desensitize you to otherwise terrifying stimuli.<br /><br />There are some great studies about the effect of belief in school settings. Pick a student at random and tell the teacher that she's especially smart, and by the end of the year she will be doing exceptionally well; tell the teacher that she is exceptionally stupid, and by the end of the year she'll be doing exceptionally poorly. The experimenters theorized that the teacher's belief about the student's intelligence was subconsciously detected by the student, and that the student was somehow <a href=\"http://en.wikipedia.org/wiki/Pygmalion_effect\">adjusted her performance to fit that belief</a>. In a similar study, <a href=\"http://en.wikipedia.org/wiki/Stereotype_threat\">minority students were found to do worse on tests</a> when reminded of stereotypes that minorities are stupid, and better when tested in contexts that downplayed their minority status, suggesting that the students' belief that they would fail was enough to make them fail.<br /><br />Belief can also translate to success when mediated by signals of dominance and confidence. We've already discussed how hard-to-fake signals of confidence can help someone pick up women<sup>2</sup>. Although I don't know of any studies proving that confidence/dominance signals help a businessperson get promoted or a politician get elected, common sense suggests they do. For example, height does have a proven effect in this area, suggesting that our ancestral algorithms for assessing dominance play a major role.<br /><br />MBlume<a href=\"/lw/cn/instrumental_vs_epistemic_a_bardic_perspective/\"> has already discussed</a> how one cannot simply choose to consciously project dominance signals. The expressions and postures involved are too complicated and too far from the normal domain of conscious control. He suggests using imagination and self-deception to trick the subconscious mind into adopting the necessary role.<br /><br />So I hope it is not too controversial when I say that subconscious beliefs can significantly affect disease, willpower, physical strength, intelligence, and romantic and financial success.<br /><br />The second part of my case is that repeating something makes the brain believe it on a subconscious level.<br /><br />Say Anna Salamon and Steve Rayhawk: \"Any random thing you say or do in the absence of obvious outside pressure, can hijack your self-concept for the medium- to long-term future.\" That's from their excellent post <a href=\"/lw/4e/cached_selves/\">Cached Selves</a>, where they explain that once you say something, even if you don't really mean it, it affects all your beliefs and behaviors afterwards. If you haven't read it yet, read it now: it is one of Less Wrong's growing number of classics.<br /><br />There's also <a href=\"http://www.lps.uci.edu/~johnsonk/philpsych/readings/nisbett.pdf\">this study</a> which someone linked me to on Overcoming Bias and to which I keep returning. It demonstrates pretty clearly that we don't have a lot of access to our own beliefs, and tend to make them up based on our behavior. So if I am repeating \"I will become a syndicated cartoonist\", and my subconscious is not subtle enough to realize I am doing it as part of a complex plot, it might very well assume I am doing it because, well, I think I will become a syndicated cartoonist. And the subconscious quite likes to keep beliefs consistent, so once it \"discovers\" I have that belief, it may edit whatever it needs to edit to become more consistent with it.<br /><br />There have been a few studies vaguely related to affirmations. One that came out just a few weeks ago found that minorities who wrote 'value affirmation' essays<a href=\"http://www.scientificamerican.com/podcast/episode.cfm?id=affirmations-improve-minority-stude-09-04-21\"> did significantly better in school</a> (although the same effect did not apply to Caucasians) . Another found that some similar sort of 'value affirmation' <a href=\"http://www.pdfdownload.org/pdf2html/pdf2html.php?url=http%3A%2F%2Fwww.psychologicalscience.org%2Fpdf%2Fps%2Fpersonal_values.pdf&amp;images=yes\">decreased stress as measured in cortisol</a> and other physiological measures . But AFAIK no one's ever done a study on Adams-variety simple personal affirmations in all of their counter-intuitive weirdness, <a href=\"http://www.overcomingbias.com/2008/02/what-is-worth-s.html\">probably because it sounds so silly</a>, and I think that's a shame. If they works, it's a useful self-help technique and akrasia-buster. If they don't work, that blocks off a few theories about how the mind works and helps us start looking for alternatives.</p>\n<p>&nbsp;</p>\n<p><strong>Footnote</strong></p>\n<p><strong>1: </strong>A story I like: in one of the studies that discovered the placebo effect for alcohol, one of the male participants who falsely believed he was drunk tried to cop a feel of a female researcher's breasts. That must have been the most awkward debriefing ever.</p>\n<p><strong>2:</strong> Here I'm not just making my usual mistake and  being accidentally sexist; I really mean \"pick up women\". There is less research suggesting the same thing works on men. See Chapter 6 of The Adapted Mind, \"The Evolution of Sexual Attraction: Evaluative Mechanisms in Women\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XYHzLjwYiqpeqaf4c": 1, "YTCrHWYHAsAD74EHo": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B4AyJXYPpGbBmxQzd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": 55, "extendedScore": null, "score": 9e-05, "legacy": true, "legacyId": "520", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 55, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AGP9PwnhQcuYMKyMm", "BHYBdijDcAKQ6e45Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-03T02:10:43.448Z", "modifiedAt": null, "url": null, "title": "Return of the Survey", "slug": "return-of-the-survey", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:51.546Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2AuvBPw6Rb7yxkvKc/return-of-the-survey", "pageUrlRelative": "/posts/2AuvBPw6Rb7yxkvKc/return-of-the-survey", "linkUrl": "https://www.lesswrong.com/posts/2AuvBPw6Rb7yxkvKc/return-of-the-survey", "postedAtFormatted": "Sunday, May 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Return%20of%20the%20Survey&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReturn%20of%20the%20Survey%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2AuvBPw6Rb7yxkvKc%2Freturn-of-the-survey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Return%20of%20the%20Survey%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2AuvBPw6Rb7yxkvKc%2Freturn-of-the-survey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2AuvBPw6Rb7yxkvKc%2Freturn-of-the-survey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 248, "htmlBody": "<p><strong>[UPDATE: Survey is now closed. Thanks to everyone who took it. Results soon. Ignore everything below.]</strong></p>\n<p>Last week, I asked people for help writing a survey. I've since taken some of your suggestions. Not all, because I wanted to keep the survey short, and because the survey software I'm using made certain types of questions inconvenient, but some. I hope no one's too angry about their contributions being left out.</p>\n<p>Please note that, due to what was very possibly a bad decision on my part as to what would be most intuitive, I've requested all probabilities be in percentage format. So if you think something has a 1/2 chance of being true, please list 50 instead of .5.</p>\n<p>Please take the survey now; it <a href=\"http://spreadsheets.google.com/viewform?hl=en&amp;formkey=cF9KNGNtbFJXQ1JKM0RqTkxQNUY3Y3c6MA..\">can be found here</a> and it shouldn't take more than fifteen or twenty minutes. Unless perhaps you need to spend a lot of time determining your opinions on controversial issues, in which case it will be time well spent!</p>\n<p>Several people, despite the BOLD ALL CAPS TEXT saying not to take the survey in the last post, went ahead and took the survey. Your results have been deleted. Please take it again. Thank you.</p>\n<p>I'll leave this open for about a week, calculate some results, then send out the data. There is an option to make your data private at the bottom of the survey.</p>\n<p>Thanks to everyone who takes this. If you want, post a comment saying you took it below, and I'll give you a karma point :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"kJrjorSx3hXa7q7CJ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2AuvBPw6Rb7yxkvKc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 16, "extendedScore": null, "score": 4.916985047123337e-07, "legacy": true, "legacyId": "521", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-03T15:27:26.437Z", "modifiedAt": null, "url": null, "title": "Essay-Question Poll: Dietary Choices", "slug": "essay-question-poll-dietary-choices", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:29.442Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gERucNHtgfaJ6HMhd/essay-question-poll-dietary-choices", "pageUrlRelative": "/posts/gERucNHtgfaJ6HMhd/essay-question-poll-dietary-choices", "linkUrl": "https://www.lesswrong.com/posts/gERucNHtgfaJ6HMhd/essay-question-poll-dietary-choices", "postedAtFormatted": "Sunday, May 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Essay-Question%20Poll%3A%20Dietary%20Choices&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEssay-Question%20Poll%3A%20Dietary%20Choices%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgERucNHtgfaJ6HMhd%2Fessay-question-poll-dietary-choices%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Essay-Question%20Poll%3A%20Dietary%20Choices%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgERucNHtgfaJ6HMhd%2Fessay-question-poll-dietary-choices", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgERucNHtgfaJ6HMhd%2Fessay-question-poll-dietary-choices", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 435, "htmlBody": "<p>I have noticed that among philosophers, vegetarianism of one form or another is quite common.&nbsp; In fact, I became a vegetarian (technically a pescetarian) myself partly out of respect for an undergraduate philosophy professor.&nbsp; I am interested in finding out if there is a similar disproportion in the Less Wrong community.</p>\n<p>I didn't request that this go into Yvain's survey because I want more information than just what animal products you do or don't eat; I'd also like to see nuances of the reasons behind your diet.&nbsp; There are a lot more shades than carnivore/vegetarian/vegan - if you want to be a vegetarian but are allergic to soy and gluten, that's a compelling reason to diversify protein sources, for instance.&nbsp; I'd also like to hear about if you avoid any plant foods (if you think they're farmed in a way that's environmentally destructive or that hurts people or if you have warm fuzzy feelings for plants, maybe).&nbsp; Here are some questions that come to mind:</p>\n<ol>\n<li>What foods, if any, do you normally avoid for reasons other than pure culinary taste, cost, individual health concerns (allergies, diabetes, etc.) or ease of preparation?&nbsp; (Avoiding foods that are considered revolting or just non-food in your culture of origin, like balut or fried locusts, counts as \"culinary taste\".)</li>\n<li>What are your reasons for avoiding those foods?</li>\n<li>How strictly do you avoid them?&nbsp; For instance, will you eat them if you are served them while a guest at a meal, or if you are hungry and there is nothing else available?&nbsp; Do you check to see if they're in potentially questionable dishes at restaurants (and if so, do you trust what the server says?)<a id=\"more\"></a></li>\n<li>If you have children or plan to have children, will you expect or encourage them to avoid the same foods?</li>\n<li>Do you try to convince your friends and family members to make dietary choices similar to yours?&nbsp; If so, have you ever succeeded?</li>\n<li>If you avoid a class of foods with valuable nutritive content (as opposed to Twinkies), what do you replace it with to get complete nutrition?</li>\n<li>What are your attitudes to people who are more restrictive in their diets than you are?&nbsp; Less restrictive?</li>\n<li>What is the timeline of your dietary restrictions?&nbsp; (Transitions, lapses, increases or decreases in restrictiveness, etc.)</li>\n<li>If you have not avoided these foods for your entire life, how much did you enjoy them when you ate them, and do you still sometimes want to eat them?</li>\n<li>Is there anything else about your choice of diet that might be relevant or interesting?</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ouT6wKhACJRouGokM": 1, "kJrjorSx3hXa7q7CJ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gERucNHtgfaJ6HMhd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 17, "extendedScore": null, "score": 3.2e-05, "legacy": true, "legacyId": "522", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 244, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-03T22:37:13.238Z", "modifiedAt": null, "url": null, "title": "Allais Hack -- Transform Your Decisions!", "slug": "allais-hack-transform-your-decisions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:48.908Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/39bD65my8GvEiXQ9o/allais-hack-transform-your-decisions", "pageUrlRelative": "/posts/39bD65my8GvEiXQ9o/allais-hack-transform-your-decisions", "linkUrl": "https://www.lesswrong.com/posts/39bD65my8GvEiXQ9o/allais-hack-transform-your-decisions", "postedAtFormatted": "Sunday, May 3rd 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Allais%20Hack%20--%20Transform%20Your%20Decisions!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAllais%20Hack%20--%20Transform%20Your%20Decisions!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F39bD65my8GvEiXQ9o%2Fallais-hack-transform-your-decisions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Allais%20Hack%20--%20Transform%20Your%20Decisions!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F39bD65my8GvEiXQ9o%2Fallais-hack-transform-your-decisions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F39bD65my8GvEiXQ9o%2Fallais-hack-transform-your-decisions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 589, "htmlBody": "<p>The <a href=\"http://www.overcomingbias.com/2008/01/allais-paradox.html\">Allais Paradox</a>, though not actually a paradox, was a classic experiment which showed that decisions made by humans do not demonstrate consistent preferences. If you <a href=\"http://www.overcomingbias.com/2008/01/circular-altrui.html\">actually want to accomplish something</a>, rather than simply feel good about your decisions, this is rather disturbing.</p>\n<p>When something like the Allais Paradox is presented all in one go, it's <em>fairly easy</em> to see that the two cases are equivalent, and ensure that your decisions are consistent. But if I clone you right now, present one of you with gamble 1, and one of you with gamble 2, you might not fare so well. The question is how to consistently advance your own preferences <a href=\"http://www.overcomingbias.com/2007/09/burdensome-deta.html\">even when you're only looking at one side of the problem</a>.</p>\n<p>Obviously, one solution is to actually construct a utility function in money, and apply it rigorously to all decisions. Logarithmic in your total net worth is usually a good place to start. Next you can assign a number of utilons to each year you live, a negative number to each day you are sick, a number for each sunrise you witness...</p>\n<p>I would humbly suggest that a less drastic strategy might be to familiarize yourself with the ways in which you can transform a decision which should make no difference unto decision theory, and actually get in the habit of applying these transformations to decisions you make in real life.</p>\n<p>So, let us say that I present you with Allais Gamble #2: choose between A: 34% chance of winning $24,000, and 66% chance of winning nothing, and B: 33% chance of winning $27,000, and 67% chance of winning nothing.</p>\n<p>Before snapping to a judgment, try some of the following transforms:<a id=\"more\"></a></p>\n<p><strong>Assume your decision matters:</strong></p>\n<p>The gamble, as given, contains lots of probability mass in which your decision will not matter one way or the other -- shave it off!</p>\n<p>Two possible resulting scenarios:</p>\n<p>A: $24,000 with certainty, B: 33/34 chance of $27,000</p>\n<p>Or, less obviously: I spin a wheel with 67 notches, 34 marked A and 33 marked B. Choose A and win $24,000 if the wheel comes up A, nothing otherwise. Choose B and win $27,000 if the wheel comes up B, nothing otherwise.</p>\n<p><strong>Assume your decision <em>probably doesn't</em> matter:</strong></p>\n<p>Tiny movements away from certainty tend to be more strongly felt -- try shifting all your probabilities <em>down</em> and see how you feel about them.</p>\n<p>A: 3.4% chance of winning $24,000, 96.6% chance of nothing. B: 3.3% chance of winning $27,000, 96.7% chance of nothing.</p>\n<p><strong>Convert potential wins into potential losses, and vice versa:</strong></p>\n<p>Suppose I simply <em>give</em> you the $24,000 today. You spend the rest of the day counting your bills and planning wonderful ways of spending it. Tomorrow, I come to you and offer you an additional $3,000, with the proviso that there is a 1/34 chance that you will lose everything.</p>\n<p>(If 1/34 is hard to emotionally weight, also feel free to imagine a fair coin coming up heads five times in a row)</p>\n<p>Or, suppose I give you the full $27,000 today, and tomorrow, a mugger comes, grabs $3,000 from your wallet, and then offers it back for a 1/34 shot at the whole thing.</p>\n<p>&nbsp;</p>\n<hr />\n<p>I'm not saying that there is one way of transforming a decision such that your inner Bayesian master will suddenly snap to attention and make the decision for you. This method is simply a diagnostic. If you make one of these transforms and find the emotional weight of the decision switching sides, <em>something is going wrong in your reasoning</em>, and you should fight to understand what it is before making a decision either way.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"L3NcKBNTvQaFXwv9u": 1, "HAFdXkW4YW4KRe2Gx": 1, "5f5c37ee1b5cdee568cfb0e9": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "39bD65my8GvEiXQ9o", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 22, "extendedScore": null, "score": 4.918820576583219e-07, "legacy": true, "legacyId": "523", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>The <a href=\"http://www.overcomingbias.com/2008/01/allais-paradox.html\">Allais Paradox</a>, though not actually a paradox, was a classic experiment which showed that decisions made by humans do not demonstrate consistent preferences. If you <a href=\"http://www.overcomingbias.com/2008/01/circular-altrui.html\">actually want to accomplish something</a>, rather than simply feel good about your decisions, this is rather disturbing.</p>\n<p>When something like the Allais Paradox is presented all in one go, it's <em>fairly easy</em> to see that the two cases are equivalent, and ensure that your decisions are consistent. But if I clone you right now, present one of you with gamble 1, and one of you with gamble 2, you might not fare so well. The question is how to consistently advance your own preferences <a href=\"http://www.overcomingbias.com/2007/09/burdensome-deta.html\">even when you're only looking at one side of the problem</a>.</p>\n<p>Obviously, one solution is to actually construct a utility function in money, and apply it rigorously to all decisions. Logarithmic in your total net worth is usually a good place to start. Next you can assign a number of utilons to each year you live, a negative number to each day you are sick, a number for each sunrise you witness...</p>\n<p>I would humbly suggest that a less drastic strategy might be to familiarize yourself with the ways in which you can transform a decision which should make no difference unto decision theory, and actually get in the habit of applying these transformations to decisions you make in real life.</p>\n<p>So, let us say that I present you with Allais Gamble #2: choose between A: 34% chance of winning $24,000, and 66% chance of winning nothing, and B: 33% chance of winning $27,000, and 67% chance of winning nothing.</p>\n<p>Before snapping to a judgment, try some of the following transforms:<a id=\"more\"></a></p>\n<p><strong id=\"Assume_your_decision_matters_\">Assume your decision matters:</strong></p>\n<p>The gamble, as given, contains lots of probability mass in which your decision will not matter one way or the other -- shave it off!</p>\n<p>Two possible resulting scenarios:</p>\n<p>A: $24,000 with certainty, B: 33/34 chance of $27,000</p>\n<p>Or, less obviously: I spin a wheel with 67 notches, 34 marked A and 33 marked B. Choose A and win $24,000 if the wheel comes up A, nothing otherwise. Choose B and win $27,000 if the wheel comes up B, nothing otherwise.</p>\n<p><strong id=\"Assume_your_decision_probably_doesn_t_matter_\">Assume your decision <em>probably doesn't</em> matter:</strong></p>\n<p>Tiny movements away from certainty tend to be more strongly felt -- try shifting all your probabilities <em>down</em> and see how you feel about them.</p>\n<p>A: 3.4% chance of winning $24,000, 96.6% chance of nothing. B: 3.3% chance of winning $27,000, 96.7% chance of nothing.</p>\n<p><strong id=\"Convert_potential_wins_into_potential_losses__and_vice_versa_\">Convert potential wins into potential losses, and vice versa:</strong></p>\n<p>Suppose I simply <em>give</em> you the $24,000 today. You spend the rest of the day counting your bills and planning wonderful ways of spending it. Tomorrow, I come to you and offer you an additional $3,000, with the proviso that there is a 1/34 chance that you will lose everything.</p>\n<p>(If 1/34 is hard to emotionally weight, also feel free to imagine a fair coin coming up heads five times in a row)</p>\n<p>Or, suppose I give you the full $27,000 today, and tomorrow, a mugger comes, grabs $3,000 from your wallet, and then offers it back for a 1/34 shot at the whole thing.</p>\n<p>&nbsp;</p>\n<hr>\n<p>I'm not saying that there is one way of transforming a decision such that your inner Bayesian master will suddenly snap to attention and make the decision for you. This method is simply a diagnostic. If you make one of these transforms and find the emotional weight of the decision switching sides, <em>something is going wrong in your reasoning</em>, and you should fight to understand what it is before making a decision either way.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Assume your decision matters:", "anchor": "Assume_your_decision_matters_", "level": 1}, {"title": "Assume your decision probably doesn't matter:", "anchor": "Assume_your_decision_probably_doesn_t_matter_", "level": 1}, {"title": "Convert potential wins into potential losses, and vice versa:", "anchor": "Convert_potential_wins_into_potential_losses__and_vice_versa_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "19 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-04T11:31:38.399Z", "modifiedAt": null, "url": null, "title": "Without models", "slug": "without-models", "viewCount": null, "lastCommentedAt": "2020-03-30T00:03:13.857Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RichardKennaway", "createdAt": "2009-03-09T13:46:28.196Z", "isAdmin": false, "displayName": "RichardKennaway"}, "userId": "unnmqpwtrwhyDt6q5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ba6buPA3u2btdKS82/without-models", "pageUrlRelative": "/posts/Ba6buPA3u2btdKS82/without-models", "linkUrl": "https://www.lesswrong.com/posts/Ba6buPA3u2btdKS82/without-models", "postedAtFormatted": "Monday, May 4th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Without%20models&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWithout%20models%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa6buPA3u2btdKS82%2Fwithout-models%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Without%20models%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa6buPA3u2btdKS82%2Fwithout-models", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa6buPA3u2btdKS82%2Fwithout-models", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1959, "htmlBody": "<p>Followup to: <a href=\"/lw/dj/what_is_control_theory_and_why_do_you_need_to/\">What is control theory?</a></p>\n<p>I mentioned in <a href=\"/lw/c0/the_ideas_youre_not_ready_to_post/934\">my post testing the water on this subject</a> that control systems are not intuitive until one has learnt to understand them. The point I am going to talk about is one of those non-intuitive features of the subject. It is (a) basic to the very idea of a control system, and (b) something that almost everyone gets wrong when they first encounter control systems.</p>\n<p>I'm going to address just this one point, not in order to ignore the rest, but because the discussion arising from <a href=\"/lw/dj/what_is_control_theory_and_why_do_you_need_to/\">my last post</a> has shown that this is presently the most important thing.</p>\n<p>There is a great temptation to think that to control a variable -- that is, to keep it at a desired value in spite of disturbing influences -- the controller must contain a model of the process to be controlled and use it to calculate what actions will have the desired effect. In addition, it must measure the disturbances or better still, predict them in advance and what effect they will have, and take those into account in deciding its actions.</p>\n<p>In terms more familiar here, the temptation to think that to bring about desired effects in the world, one must have a model of the relevant parts of the world and predict what actions will produce the desired results.</p>\n<p>However, this is absolutely wrong. This is not a minor mistake or a small misunderstanding; it is the pons asinorum of the subject.</p>\n<p>Note the word \"must\". It is not disputed that one can use models and predictions, only that one must, that the task inherently requires it.</p>\n<p><a id=\"more\"></a></p>\n<p><em>A control system can work without having any model of what it is controlling.</em></p>\n<p>The designer will have a model. For the room thermostat, he must know that the heating should turn on when the room is too cold and off when it is too hot, rather than the other way around, and he must arrange that the source of heat is powerful enough. The controller he designs does not know that; it merely does that. (Compare the similar <a href=\"http://www.overcomingbias.com/2007/11/adaptation-exec.html\">relationship between evolution and evolved organisms</a>. How evolution works is not how the evolved organism works, nor is how a designer works how the designed system works.) For a cruise control, he must choose the parameters of the controller, taking into account the engine's response to the accelerator pedal. The resulting control system, however, contains no representation of that. According to the <a href=\"http://www.howstuffworks.com/cruise-control.htm\">HowStuffWorks</a> article, they typically use nothing more complicated than proportional or PID control. The parameters are chosen by the designer according to his knowledge about the system; the parameters themselves are not something the controller knows about the system.</p>\n<p>It is possible to design control systems that do contain models, but it is not inherent to the task of control. <a href=\"http://blg.eng.cam.ac.uk/t/pub/Public/Wolpert/Publications/WolMiaKaw98.pdf\">This</a> is what model-based controllers look like. (Thanks to <a href=\"/lw/dj/what_is_control_theory_and_why_do_you_need_to/al9\">Tom Talbot</a> for that reference.) Pick up any book on model-based control to see more examples. There are signals within the control system that are designed to relate to each other in the same way as do corresponding properties of the world outside. That is what a model is. There is nothing even slightly resembling that in a thermostat or a cruise control. Nor is there in the knee-jerk tendon reflex. Whether there are models elsewhere in the human body is an empirical matter, to be decided by investigations such as those in the linked paper. To merely be entangled with the outside world is not what it is, to be a model.</p>\n<p>Within the Alien Space Bat Prison Cell, the thermostat is flicking a switch one way when the needle is to the left of the mark, and the other when it is to the right. The cruise control is turning a knob by an amount proportional to the distance between the needle and the mark. Neither of them knows why. Neither of them knows what is outside the cell. Neither of them cares whether what they are doing is working. They just do it, and they work.</p>\n<p><em>A control system can work without having any knowledge of the external disturbances.</em></p>\n<p>The thermostat does not know that the sun is shining in through the window. It only knows the current temperature. The cruise control does not sense the gradient of the road, nor the head wind. It senses the speed of the car. It may be tuned for some broad characteristics of the vehicle, but it does not itself know those characteristics, or sense when they change, such as when passengers get in and out.</p>\n<p>Again, it is possible to design controllers that do sense at least some of the disturbances, but it is not inherent to the task of control.</p>\n<p><em>A control system can work without making any predictions about anything.</em></p>\n<p>The room thermostat does not know that the sun is shining, nor the cruise control the gradient. A fortiori, they do not predict that the sun will come out in a few minutes, nor that there is a hill in the distance.</p>\n<p>It is possible to design controllers that make predictions, but it is not an inherent requirement of the task of control. The fact that a controller works does not constitute a prediction, by the controller, that it will work. I am belabouring this point, because the error has already been belaboured.</p>\n<p>But (it was maintained) doesn't the control system have an implicit model, implicit knowledge, and implicitly make predictions?</p>\n<p>No. None of these things are true. The very concepts of implicit model, implicit knowledge, and implicit prediction are problematic. The phrases do have sensible meanings in some other contexts, but not here. An implicit model is one in which functional relationships are expressed not as explicit functions y=f(x), but as relations g(x,y)=k. Implicit knowledge is knowledge that one has but cannot express in words. Implicit prediction is an unarticulated belief about the effect of the actions one is taking.</p>\n<p>In the present context, \"implicit\" is indistinguishable from \"not\". Just because a system was made a certain way in order to interact with some other system a certain way, it does not make the one a model of the other. As well say that a hammer is a model of a nail. The examples I am using, the thermostat and the cruise control, sense temperature and speed respectively, compare them with their set points, and apply a rule for determining their action. In the rule for a proportional controller:</p>\n<p><em>output = constant &times; (reference - perception)</em></p>\n<p>there is no model of anything. The gain constant is not a model. The perception, the reference, and the output are not models. The equation relating them is my model of the controller. It is not the controller's model of anything: it is what the controller is.</p>\n<p>The only knowledge these systems have is their perceptions and their references, for temperature or speed. They contain no \"implicit knowledge\".</p>\n<p>They do not \"implicitly\" make predictions. The designer can predict that they will work. The controllers themselves predict nothing. They do what they do whether it works or not. Sometimes, in fact, these systems do not work. The thermostat will fail to control if the outside temperature is above the set point. The cruise control will fail to control on a sufficiently steep downhill gradient. They will not notice that they are not working. They will not behave any differently as a result. They will just carry on doing <em>o=c&times;(r-p)</em>, or whatever their output rule is.</p>\n<p>I don't know if anyone tried my <a href=\"http://www2.cmp.uea.ac.uk/~jrk/Robotics/Archy/Archy.html\">robot simulation applet</a> that I linked to, but I've noticed that people I show it to readily anthropomorphise it.&nbsp;(BTW, if its interface appears scrambled, resize the browser window a little and it should sort itself out.)&nbsp;They see the robot apparently going around the side of a hill to get to a food particle and think it planned that, when in fact it knows absolutely nothing about the shape of the terrain ahead. They see it go to one food particle rather than another and think it made a decision, when in fact it does not know how many food particles there are or where. There is almost nothing inside the robot, compared to what people imagine: no planning, no adaptation, no prediction, no sensing of disturbances, and no model of anything but its own geometry. The 6-legged version contains 44 proportional controllers. The 44 gain constants are not a model, they merely work.</p>\n<p>(A tangent: people look at other people and think they can see those other people's purposes, thoughts, and feelings. Are their projections any more accurate than they are when they look at that robot? If you think that they are, how do you know?)</p>\n<p>Now, I am not explaining control systems merely to explain control systems. The relevance to rationality is that they funnel reality into a narrow path in configuration space by entirely arational means, and thus constitute a proof by example that this is possible. This must raise the question, how much of the neural functioning of a living organism, human or lesser, operates by similar means? And how much of the functioning of an artificial organism must be designed to use these means? It appears inescapable that all of what a brain does consists of control systems. To what extent these may be model-based is an empirical question, and is not implied merely by the fact of control. Likewise, the extent to which these methods are useful in the design of artificial systems embodying the <a href=\"http://www.overcomingbias.com/2008/10/mundane-magic.html\">Ultimate Art</a>.</p>\n<p>Evolution operates statistically; I would be entirely unsurprised by Bayesian analyses of evolution. But <em>how evolution works</em> <a href=\"http://www.overcomingbias.com/2007/11/adaptation-exec.html\">is not</a> <em>how the evolved organism works</em>. That must be studied separately.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/11/adaptation-exec.html\"> </a></p>\n<p>I may post something more on the relationship between Bayesian reasoning and control systems neither designed by nor performing the same when I've digested <a href=\"/lw/dj/what_is_control_theory_and_why_do_you_need_to/af3\">the material that Steve_Rayhawk pointed to</a>. For the moment, though, I'll just remark that \"Bayes!\" is merely a <a href=\"http://www.overcomingbias.com/2007/08/mysterious-answ.html\">mysterious answer</a>, unless backed up by actual mathematical application to the specific case.</p>\n<p><strong>Exercises.</strong></p>\n<p>1. A room thermostat is set to turn the heating on at 20 degrees and off at 21. The ambient temperature outside is 10 degrees. You place a candle near the thermostat, whose effect is to raise its temperature 5 degrees relative to the body of the room. What will happen to (a) the temperature of the room and (b) the temperature of the thermostat?</p>\n<p>2. A cruise control is set to maintain the speed at 50 mph. It is mechanically connected to the accelerator pedal -- it moves it up and down, operating the throttle just as you would be doing if you were controlling the speed yourself. It is designed to disengage the moment you depress the brake. Suppose that that switch fails: the cruise control continues to operate when you apply the brake. As you gently apply the brake, what will happen to (a) the accelerator pedal, and (b) the speed of the car? What will happen if you attempt to keep the speed down to 40 mph?</p>\n<p>3. An employee is paid an hourly rate for however many hours he wishes to work. What will happen to the number of hours per week he works if the rate is increased?</p>\n<p>4. A target is imposed on a doctor's practice, of never having a waiting list for appointments more than four weeks long. What effect will this have on (a) how long a patient must wait to see the doctor, and (b) the length of the appointments book?</p>\n<p>5. What relates questions 3 and 4 to the subject of this article?</p>\n<p>6. Controller: <em>o = c&times;(r-p)</em>. Environment: <em>dp/dt = k&times;o + d</em>. <em>o</em>, <em>r</em>, and <em>p</em> as above; <em>c</em> and <em>k</em> are constants; <em>d</em> is an arbitrary function of time (the disturbance). How fast and how accurately does this controller reject the disturbance and track the reference?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 1, "6nS8oYmSMuFMaiowF": 1, "9mShmhRFzBat3523A": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ba6buPA3u2btdKS82", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 21, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "524", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fJKbCXrCPwAR5wjL8"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-04T18:59:56.768Z", "modifiedAt": null, "url": null, "title": "Bead Jar Guesses", "slug": "bead-jar-guesses", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:45.899Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mXaPPjud9MuuboWgd/bead-jar-guesses", "pageUrlRelative": "/posts/mXaPPjud9MuuboWgd/bead-jar-guesses", "linkUrl": "https://www.lesswrong.com/posts/mXaPPjud9MuuboWgd/bead-jar-guesses", "postedAtFormatted": "Monday, May 4th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bead%20Jar%20Guesses&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABead%20Jar%20Guesses%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmXaPPjud9MuuboWgd%2Fbead-jar-guesses%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bead%20Jar%20Guesses%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmXaPPjud9MuuboWgd%2Fbead-jar-guesses", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmXaPPjud9MuuboWgd%2Fbead-jar-guesses", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 636, "htmlBody": "<p>Let's say Omega turns up and sets you a puzzle, since this seems to be what Omega does in his spare time.&nbsp; He has with him an opaque jar, which he says contains some solid-colored beads, and he's going to draw one bead out of the jar.&nbsp; He would like to know what your probability is that the bead will be red.</p>\n<p>Well, now there is an interesting question.&nbsp; We'll bypass the novice mistake of calling it .5, of course; just because the options are binary (red or non-red) doesn't make them equally likely.&nbsp; It's not like you have any information.&nbsp; Assuming you don't think Omega is out to deliberately screw with you, you <em>could</em> say that the probability is .083 based on the fact that \"red\" is one of twelve <a href=\"http://en.wikipedia.org/wiki/Color_naming\">basic color words</a> in English.&nbsp; (If he had asked for the probability that the bead would be <em>lilac</em>, you'd be in a bit more trouble.)&nbsp; If you were obliged to make a bet that the bead is red, you would probably take the most conservative bet available (even if you're still assuming Omega isn't deliberately screwing with you), but .083 sounds okay.</p>\n<p>But because you start with no information, it's very hard to gather more.&nbsp; Suppose Omega reaches into the jar and pulls out a red bead.&nbsp; Does your probability that the <em>second</em> bead will be red go up (obviously the beads come in red)?&nbsp; Does it go down (that might have been the only one, and however many red beads there were before, there are fewer now)?&nbsp; Does it stay the same (the beads are all - as far as you know - independent of one another; removing this one bead has an effect on the <em>actual</em> probabilities of what the next one will be, but it can't affect your <em>epistemic</em> probability)?&nbsp; What if he pulled out a gray bead first, instead of a red one?&nbsp; How many beads would he have to pull, and in what colors, for you to start making confident predictions?<a id=\"more\"></a></p>\n<p>So that's one kind of probability: the bead jar guess.&nbsp; It has a basis, but it's a terribly flimsy one, and guessing right (or wrong) doesn't help much to confirm or disconfirm the guess.&nbsp; Even if Omega <em>had</em> asked about the bead being lilac, and you'd dutifully given a <a href=\"http://en.wikipedia.org/wiki/List_of_colors\">tiny</a> probability, it would not have <em>surprised </em>you to see a lilac bead emerge from the jar.</p>\n<p>A non-bead-jar-guess probability yields surprise when it turns out to be true even if it's just the same size.&nbsp; Say your probability for lilac was .003.&nbsp; That's tiny.&nbsp; If you had a probability of .003 that it would rain on a particular day, you would be right to be <em>astonished </em>if you turned out to need the umbrella you left at home.</p>\n<p>Bead jar guesses vacillate more easily.&nbsp; Although in the case of the bead jar, you are in an extremely disadvantageous position when it comes to getting more information, we can fix that: somebody who says she's peeked into the jar says all the beads in the jar are red.&nbsp; Just like that, you'll discard the .083 and swap it for a solid .99 (adjusted as you like for the possibility that she is lying or can't see well).&nbsp; It would take considerable evidence to move a probability that far if it were not a wild guess, not just a single person's say-so, but that's all you've got.&nbsp; <em>Then</em> Omega pulling out a bead can give you information: the minute he pulls out the gray bead you know you can't rely on your informant, at least not completely.&nbsp; You can start making decent inferences.</p>\n<p>I think more of our beliefs are bead jar guesses than we realize, but because of assorted insidious psychological tendencies, we don't recognize that and we hold onto them tighter than baseless suppositions deserve.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xgpBASEThXPuKRhbS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mXaPPjud9MuuboWgd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 21, "extendedScore": null, "score": 3.6e-05, "legacy": true, "legacyId": "526", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 134, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-04T22:59:59.183Z", "modifiedAt": null, "url": null, "title": "Special Status Needs Special Support", "slug": "special-status-needs-special-support", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:19.168Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jaW5XerRuYRhzjDLE/special-status-needs-special-support", "pageUrlRelative": "/posts/jaW5XerRuYRhzjDLE/special-status-needs-special-support", "linkUrl": "https://www.lesswrong.com/posts/jaW5XerRuYRhzjDLE/special-status-needs-special-support", "postedAtFormatted": "Monday, May 4th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Special%20Status%20Needs%20Special%20Support&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpecial%20Status%20Needs%20Special%20Support%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjaW5XerRuYRhzjDLE%2Fspecial-status-needs-special-support%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Special%20Status%20Needs%20Special%20Support%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjaW5XerRuYRhzjDLE%2Fspecial-status-needs-special-support", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjaW5XerRuYRhzjDLE%2Fspecial-status-needs-special-support", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 473, "htmlBody": "<p>I just recorded another BHTV with Adam Frank, though it's not out yet, and I had a thought that seems worth recording.&nbsp; At a certain point in the dialogue, Adam Frank was praising the wisdom and poetry in religion.&nbsp; I retorted, \"Tolkien's got great poetry, and some parts that are wise and some that are unwise; but you don't see people wearing little rings around their neck in memory of Frodo.\"</p>\n<p>(I don't remember whether this observation is original to me, so if anyone knows a prior source for this exact wording, please comment it!)</p>\n<p>The general structure of this critique is that Frank wants to assign a special status to the Book of Job, but he gives a reason that would be equally applicable to <em>The Lord of the Rings</em> (good poetry and some wise parts).&nbsp; So if those are his real reasons, he should feel just the same way about God and Gandalf.&nbsp; Or if not that exact particular book, then some other work of poetic fiction that was always understood to be poetic fiction.<a id=\"more\"></a></p>\n<p>Later on I did demand of Adam Frank to say whether he thought the Book of Job ought to be assigned any different status from <em>The Merchant of Venice,</em> and Frank did reply \"No\".&nbsp; I'm not sure that he lives up to this reply, frankly.&nbsp; I strongly suspect he grants the two works a different emotional status.&nbsp; One is widely revered as Sacred Religious Truth while the other is merely a Great Work of Literature.&nbsp; Frank, while not a religious believer himself, does have different modes of thought for Sacred Truth and Great Literature and he knows that Job is supposed to be Sacred Truth.</p>\n<p>When I challenged the sacredness of the Book of Job, Frank reacted by trying to praise Job's \"great poetry\", which positive affect then seems to justify the positive-affect sacred status via the <a href=\"http://www.overcomingbias.com/2007/11/affect-heuristi.html\">affect heuristic</a> / <a href=\"http://www.overcomingbias.com/2007/11/halo-effect.html\">halo effect</a>.&nbsp; But \"great poetry\" would apply to Tolkien as well; and yet if you talked about Tolkien the way that Frank talked about Job, most people would write you down as a hopeless fanboy/fangirl...</p>\n<p>So the general form of the bias that I'm critiquing is to try and justify a special positive (negative) status by pointing to positive (negative) attributes, saying, \"Therefore I can assign it this very positive status!\", but the same attributes belong to many other works that you don't grant the <em>special</em> positive status.</p>\n<p>Other places to watch out for this would be if, say, you thought that Morton Smerdley was the greatest genius ever, and someone called on you to justify this, and you replied \"Morton Smerdley became a Math Professor at just the age of 27\" - but there are other people who became math professors at 27, or even 26, and yet you don't feel the special reverence toward them that you attach to Smerdley.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 1, "Kj9q8FXoauL7mQDWt": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jaW5XerRuYRhzjDLE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 28, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "528", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 75, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-05T01:25:03.586Z", "modifiedAt": null, "url": null, "title": "How David Beats Goliath", "slug": "how-david-beats-goliath", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:49.896Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JulianMorrison", "createdAt": "2009-02-27T12:57:27.471Z", "isAdmin": false, "displayName": "JulianMorrison"}, "userId": "CeZ67D5YxAKemKhYL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rQJ7Epe6b8WpX9yeK/how-david-beats-goliath", "pageUrlRelative": "/posts/rQJ7Epe6b8WpX9yeK/how-david-beats-goliath", "linkUrl": "https://www.lesswrong.com/posts/rQJ7Epe6b8WpX9yeK/how-david-beats-goliath", "postedAtFormatted": "Tuesday, May 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20David%20Beats%20Goliath&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20David%20Beats%20Goliath%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrQJ7Epe6b8WpX9yeK%2Fhow-david-beats-goliath%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20David%20Beats%20Goliath%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrQJ7Epe6b8WpX9yeK%2Fhow-david-beats-goliath", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrQJ7Epe6b8WpX9yeK%2Fhow-david-beats-goliath", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 298, "htmlBody": "<p>From the <a href=\"http://www.newyorker.com/reporting/2009/05/11/090511fa_fact_gladwell?currentPage=all\">New Yorker</a>:</p>\n<blockquote>\n<p>It was as if there were a kind of conspiracy in the basketball world about the way the game ought to be played, and Ranadiv&eacute; thought that that conspiracy had the effect of widening the gap between good teams and weak teams. Good teams, after all, had players who were tall and could dribble and shoot well; they could crisply execute their carefully prepared plays in their opponent&rsquo;s end. Why, then, did weak teams play in a way that made it easy for good teams to do the very things that made them so good?</p>\n</blockquote>\n<p>[...]</p>\n<blockquote>\n<p>David&rsquo;s victory over Goliath, in the Biblical account, is held to be an anomaly. It was not. Davids win all the time. The political scientist Ivan Arregu&iacute;n-Toft recently looked at every war fought in the past two hundred years between strong and weak combatants. The Goliaths, he found, won in 71.5 per cent of the cases. That is a remarkable fact. Arregu&iacute;n-Toft was analyzing conflicts in which one side was at least ten times as powerful&mdash;in terms of armed might and population&mdash;as its opponent, and even in those lopsided contests the underdog won almost a third of the time.<br /><br />[...] What happened, Arregu&iacute;n-Toft wondered, when the underdogs likewise acknowledged their weakness and chose an unconventional strategy? He went back and re-analyzed his data. In those cases, David&rsquo;s winning percentage went from 28.5 to 63.6.</p>\n</blockquote>\n<p>[...]</p>\n<blockquote>\n<p>Arregu&iacute;n-Toft found the same puzzling pattern. When an underdog fought like David, he usually won. But most of the time underdogs <em>didn&rsquo;t</em> fight like David. Of the two hundred and two lopsided conflicts in Arregu&iacute;n-Toft&rsquo;s database, the underdog chose to go toe to toe with Goliath the conventional way a hundred and fifty-two times&mdash;and lost a hundred and nineteen times.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xXX3n22DQZuKqXEdT": 1, "iNqgMuoewHKMhhXAp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rQJ7Epe6b8WpX9yeK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 25, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "530", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-05T06:49:45.419Z", "modifiedAt": null, "url": null, "title": "How to use \"philosophical majoritarianism\"", "slug": "how-to-use-philosophical-majoritarianism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:49.548Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimmy", "createdAt": "2009-02-27T18:23:27.410Z", "isAdmin": false, "displayName": "jimmy"}, "userId": "JKdbpXHkv9AsuazJ3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5XMrWNGQySFdcuMsA/how-to-use-philosophical-majoritarianism", "pageUrlRelative": "/posts/5XMrWNGQySFdcuMsA/how-to-use-philosophical-majoritarianism", "linkUrl": "https://www.lesswrong.com/posts/5XMrWNGQySFdcuMsA/how-to-use-philosophical-majoritarianism", "postedAtFormatted": "Tuesday, May 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20use%20%22philosophical%20majoritarianism%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20use%20%22philosophical%20majoritarianism%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5XMrWNGQySFdcuMsA%2Fhow-to-use-philosophical-majoritarianism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20use%20%22philosophical%20majoritarianism%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5XMrWNGQySFdcuMsA%2Fhow-to-use-philosophical-majoritarianism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5XMrWNGQySFdcuMsA%2Fhow-to-use-philosophical-majoritarianism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1089, "htmlBody": "<p>The majority of people would hold more accurate beliefs if they simply <a href=\"http://www.overcomingbias.com/2007/03/on_majoritarian.html\">believed the majority</a>. To state this in a way that doesn't risk <a href=\"/lw/z/information_cascades/\">information cascades</a>, we're talking about averaging <a href=\"/lw/u/the_ethic_of_handwashing_and_community_epistemic/\">impressions</a> and coming up with the same <a href=\"http://www.overcomingbias.com/2007/07/making-beliefs-.html\">belief</a>.</p>\n<p>To the degree that you come up with different averages of the impressions, you acknowledge that your belief was just your impression of the average, and you average those metaimpressions and get closer to belief convergence. You can repeat this until you get bored, but if you're doing it right, your beliefs should get closer and closer to agreement, and you shouldn't be able to predict who is going to fall on which side.<br /><br />Of course, most of us are atypical cases, and as good rationalists, we need to<em> update</em> on this information. Even if our impressions were (on average) no better than the average, there are certain cases where <a href=\"http://www.overcomingbias.com/2006/12/the_modesty_arg.html\">we know</a> that the majority is wrong. If we're going to selectively apply majoritarianism, we need to figure out the <em>rules</em> for when to apply it, to whom, and how the weighting works.<br /><br />This much I think has been said again and again. I'm gonna attempt to describe <em>how</em>.<a id=\"more\"></a></p>\n<p>Imagine for a moment that you are a perfectly rational Bayesian, and you just need data.<br /><br />First realize that \"duplicate people\" don't count double. If you make a maximum precision copy of someone, that doesn't make him any more likely to be right- clearly we can do better than averaging over all people with equal weighting.&nbsp; By the same idea, finding out that a certain train of thought leading to a certain belief is common shouldn't make you proportionally more confident in that idea.&nbsp; The only reason it might make you <em>any</em> more confident in it is the possibility that its truth leads to its proliferation and therefore its popularity is (weak) evidence.</p>\n<p>This explains why we can dismiss the beliefs of the billions of theists. First of all, their beliefs are very well correlated so that all useful information can be learned through only a handful of theists.&nbsp; Second of all, we understand their arguments and we understand how they formed their beliefs-and have already taken them into account. The reason they continue to disagree is because the situation isn't symmetric - they don't understand the opposing arguments or the causal path that leads one to be a reductionist atheist.&nbsp;</p>\n<p>No wonder \"majoritarionism\" doesn't seem to work here.</p>\n<p>Since we're still pretending to be perfect Bayesians, we only care about people who are fairly predictable (given access to their information) and have information that we don't have. If they don't have any new information, then we can just follow the causal path and say \"and here, sir, is where you went wrong.\". Even if we don't understand their mind perfectly, we don't take them seriously since it is clear that whatever they were doing, they're doing it wrong.&nbsp; On the other hand, if the other person has a lot of data, but we have no idea how data affects their beliefs, then we can't extract any useful information.</p>\n<p>We only change our beliefs to more closely match theirs when they are not only predictable, but <em>predictably rational</em>. If you know someone is <a href=\"http://www.overcomingbias.com/2007/12/reversed-stupid.html\"><em>always</em> wrong</a>, then reversing his stupidity can help you get more accurate beliefs, but it won't bring you closer to agreement- just the opposite!</p>\n<p>If we stop kidding ourselves and realize that we aren't perfect Bayesian, then we have to start giving credit to how other people think. If you and an epistemic peer come upon the same data set and come to different conclusions, then you have no reason to think that your way of thinking is any more accurate than his (as we assumed he's an epistemic peer).&nbsp; While you may have different initial impressions, you better be able to converge to the same belief.&nbsp; And again, on each iteration, it shouldn't be predictable who is going to fall on which side.</p>\n<p>If we revisit the cases like religion, then you still understand how they came to their beliefs and exactly why they fail.&nbsp; So to the extent that you believe you can recognize stupidity when you see it, you still stick to your own belief. Even though you aren't perfect, for this case, you're good enough.<br /><br /><a href=\"http://rob-zahra.blogspot.com/2009/04/overcoming-bias-summaries.html\"><strong>One sentence summary:</strong></a> <strong>You want to shift your belief to the average over answers given by predictably rational \"Rituals of Cognition\"/data set pairs<sup>1</sup>, <em>not people</em><sup>2</sup></strong>.</p>\n<p>You weight the different \"Rituals Of Cognition\"/data pairs by how much you trust the ROC and by how large the data set is.&nbsp; You must, however, keep in mind that to trust yourself more than average, you have to have a <a href=\"http://www.overcomingbias.com/2006/12/benefit_of_doub.html\">better than average</a> reason to think that you're better than average.</p>\n<p>To the extent that everyone has a unique take on the subject, counting people and counting cognitive rituals are equivalent.&nbsp; But when it comes to a group where all people think pretty close to the same way, then they only get one \"vote\".&nbsp;</p>\n<p>You can get \"bonus points\" if you can predict the conditional response of irrational peoples action in response to data and update based on that. For practical purposes though, I don't think much of this happens as not many people are <a href=\"http://www.overcomingbias.com/2007/12/reversed-stupid.html\">intelligently stupid</a>.</p>\n<p>&nbsp;</p>\n<p><strong>ETA:</strong> This takes the anthropomorphism out of the loop. We're looking at valid ROC, and polling human beliefs is just a cheap way to <em>find</em> them. If we can come up with other ways of finding them, I expect that to be <em>very</em> valuable. The smart people that impress me most aren't the ones that learn slightly quicker, since everyone else gets there too. The smart people that impress me the most come in where everyone else is stumped and chop Gordian's knot in half with their unique way of thinking about the problem. Can we train this skill?</p>\n<p><strong>Footnotes:</strong><br /><strong>1.</strong> I'm fully aware of how hoaky this sounds without any real math there, but it seems like it should be formalizable.<br />If you're just trying to improve human rationality (as opposed to programming AI), the real math would have to be interpreted again anyway and I'm not gonna spend the time right now.<br /><br /><strong>2.</strong> Just as thinking identically to your twin doesn't help you get the right answer (and therefore is weighted less), if you can come up with more than one <em>valid</em> way of looking at things, you can expect justifiably be weighted as strongly as a small group of people.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"wzgcQCrwKfETcBpR9": 1, "YPZCAs9Axp9PtrF22": 1, "qf3kDBak4BQDDw3f2": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5XMrWNGQySFdcuMsA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 13, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "532", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DNQw596nPCX4x7xT9", "ZP2om2oWHPhvWP2Q3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-05T20:36:11.296Z", "modifiedAt": "2021-01-02T04:54:31.951Z", "url": null, "title": "Off Topic Thread: May 2009", "slug": "off-topic-thread-may-2009", "viewCount": null, "lastCommentedAt": "2009-09-04T19:46:04.888Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7K6og3ssSBbH7mrYM/off-topic-thread-may-2009", "pageUrlRelative": "/posts/7K6og3ssSBbH7mrYM/off-topic-thread-may-2009", "linkUrl": "https://www.lesswrong.com/posts/7K6og3ssSBbH7mrYM/off-topic-thread-may-2009", "postedAtFormatted": "Tuesday, May 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Off%20Topic%20Thread%3A%20May%202009&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOff%20Topic%20Thread%3A%20May%202009%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7K6og3ssSBbH7mrYM%2Foff-topic-thread-may-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Off%20Topic%20Thread%3A%20May%202009%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7K6og3ssSBbH7mrYM%2Foff-topic-thread-may-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7K6og3ssSBbH7mrYM%2Foff-topic-thread-may-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 13, "htmlBody": "<p>Here's your space to talk about anything totally unrelated to being Less Wrong</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7K6og3ssSBbH7mrYM", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "534", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 73, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-05-05T20:36:11.296Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-05T20:39:33.644Z", "modifiedAt": null, "url": null, "title": "Introduction Thread: May 2009", "slug": "introduction-thread-may-2009", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.162Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/u2JAuc3iQ2PRXSsEy/introduction-thread-may-2009", "pageUrlRelative": "/posts/u2JAuc3iQ2PRXSsEy/introduction-thread-may-2009", "linkUrl": "https://www.lesswrong.com/posts/u2JAuc3iQ2PRXSsEy/introduction-thread-may-2009", "postedAtFormatted": "Tuesday, May 5th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Introduction%20Thread%3A%20May%202009&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntroduction%20Thread%3A%20May%202009%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu2JAuc3iQ2PRXSsEy%2Fintroduction-thread-may-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Introduction%20Thread%3A%20May%202009%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu2JAuc3iQ2PRXSsEy%2Fintroduction-thread-may-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu2JAuc3iQ2PRXSsEy%2Fintroduction-thread-may-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>If you've just joined the Less Wrong community, here's a space for you to tell us a bit about yourself, and perhaps test the waters on any subjects you'd like to discuss with us. You might also want to check our <a href=\"/lw/b9/introductory_thread/\">welcome page</a>.&nbsp; Glad to have you with us =)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "u2JAuc3iQ2PRXSsEy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 4.922959035357298e-07, "legacy": true, "legacyId": "535", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CG9AEXwSjdrXPBEZ9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-06T01:49:21.389Z", "modifiedAt": null, "url": null, "title": "Consider Representative Data Sets", "slug": "consider-representative-data-sets", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:58.697Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_Nesov", "createdAt": "2009-02-27T09:55:13.458Z", "isAdmin": false, "displayName": "Vladimir_Nesov"}, "userId": "qf77EiaoMw7tH3GSr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gWG9x4GGLkm5CYaP6/consider-representative-data-sets", "pageUrlRelative": "/posts/gWG9x4GGLkm5CYaP6/consider-representative-data-sets", "linkUrl": "https://www.lesswrong.com/posts/gWG9x4GGLkm5CYaP6/consider-representative-data-sets", "postedAtFormatted": "Wednesday, May 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Consider%20Representative%20Data%20Sets&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConsider%20Representative%20Data%20Sets%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgWG9x4GGLkm5CYaP6%2Fconsider-representative-data-sets%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Consider%20Representative%20Data%20Sets%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgWG9x4GGLkm5CYaP6%2Fconsider-representative-data-sets", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgWG9x4GGLkm5CYaP6%2Fconsider-representative-data-sets", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1612, "htmlBody": "<p>In this article, I consider the standard biases in drawing factual conclusions that are not related to emotional reactions, and describe a simple model summarizing what goes wrong with the reasoning in these cases, that in turn suggests a way of systematically avoiding this kind of problems.</p>\n<p>The following model is used to describe the process of getting from a question to a (potentially biased) answer for the purposes of this article. First, you ask yourself a question. Second, in the context of the question, a <em>data set</em> is presented before your mind, either directly, by you looking at the explicit statements of fact, or indirectly, by associated facts becoming salient to your attention, triggered by the explicit data items or by the question. Third, you construct an intuitive model of some phenomenon, that allows to see its properties, as a result of considering the data set. And finally, you pronounce the answer, that is read out as one of the properties of the model you've just constructed.</p>\n<p>This description is meant to present <a href=\"http://www.overcomingbias.com/2008/03/mental-paintbru.html\">mental paintbrush handles</a>, to refer to the things you can see introspectively, and things you could operate consciously if you choose to.</p>\n<p>Most of the biases in the considered class may be seen as particular ways in which you pay attention to a wrong data set, not representative of the phenomenon you model to get to the answer you seek. As a result, the intuitive model gets systematically wrong, and the answer read out from it gets biased. Below I review the specific biases, to identify the ways in which things go wrong in each particular case, and then I summarize the classes of mistakes of reasoning playing major roles in these biases and correspondingly the ways of avoiding those mistakes.<a id=\"more\"></a></p>\n<p><a href=\"http://www.overcomingbias.com/2007/06/correspondence-.html\">Correspondence Bias</a> is a tendency to attribute to a person a <em>disposition</em> to behave in a particular way, based on observing an episode in which that person behaves in that way. The data set that gets considered consists only of the observed episode, while the target model is of the person's behavior in general, in many possible episodes, in many different possible contexts that may influence the person's behavior.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/08/hindsight-bias.html\">Hindsight bias</a> is a tendency to overestimate the a priori probability of an event that has actually happened. The data set that gets considered overemphasizes the scenario that did happen, while the model that needs to be constructed, of the a priori belief, should be indifferent to which of the options will actually get realized. From this model, you need to read out the probability of the specific event, but which event you'll read out shouldn't figure into the model itself.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/09/availability.html\">Availability bias</a> is a tendency to estimate the probability of an event based on whatever evidence about that event pops into your mind, without taking into account the ways in which some pieces of evidence are more memorable than others, or some pieces of evidence are easier to come by than others. This bias directly consists in considering a mismatched data set that leads to a distorted model, and biased estimate.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/09/planning-fallac.html\">Planning Fallacy</a> is a tendency to overestimate your efficiency in achieving a task. The data set you consider consists of simple cached ways in which you move about accomplishing the task, and lacks the unanticipated problems and more complex ways in which the process may unfold. As a result, the model fails to adequately describe the phenomenon, and the answer gets systematically wrong.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/10/fictional-evide.html\">The Logical Fallacy of Generalization from Fictional Evidence</a> consists in drawing the real-world conclusions based on statements invented and selected for the purpose of writing fiction. The data set is not at all representative of the real world, and in particular of whatever real-world phenomenon you need to understand to answer your real-world question. Considering this data set leads to an inadequate model, and inadequate answers.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/10/hold-off-solvin.html\">Proposing Solutions Prematurely</a> is dangerous, because it introduces <em>weak</em> conclusions in the pool of the facts you are considering, and as a result the data set you think about becomes weaker, overly tilted towards premature conclusions that are likely to be wrong, that are less representative of the phenomenon you are trying to model than the initial facts you started from, before coming up with the premature conclusions.</p>\n<p><a href=\"/lw/dr/generalizing_from_one_example/\">Generalization From One Example</a> is a tendency to pay too much attention to the few anecdotal pieces of evidence you experienced, and model some general phenomenon based on them. This is a special case of availability bias, and the way in which the mistake unfolds is closely related to the correspondence bias and the hindsight bias.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/10/priming-and-con.html\">Contamination by Priming</a> is a problem that relates to the process of implicitly introducing the facts in the attended data set. When you are primed with a concept, the facts related to that concept come to mind easier. As a result, the data set selected by your mind becomes tilted towards the elements related to that concept, even if it has no relation to the question you are trying to answer. Your thinking becomes contaminated, shifted in a particular direction. The data set in your focus of attention becomes less representative of the phenomenon you are trying to model, and more representative of the concepts you were primed with.</p>\n<p><a href=\"http://www.overcomingbias.com/2007/04/knowing_about_b.html\">Knowing About Biases Can Hurt People</a>. When you learn about the biases, you obtain a toolset for constructing new statements of fact. Similarly to what goes wrong when you propose solutions to a hard problem prematurely, you contaminate the data set with weak conclusions, allegations against specific data items that don't add to the understanding of phenomenon you are trying to model, distract from considering the question, take away whatever relevant knowledge you had, and in some cases even invert it.</p>\n<p>A more general technique for not making these mistakes consists in making sure that the data set you consider is representative of the phenomenon you are trying to understand. Human brain can't automatically correct for the misleading selection of data, so you need to consciously ensure that you get presented with a balanced selection.</p>\n<p><strong>The first mistake</strong> is introduction of irrelevant data items. Focus on the problem, don't let the distractions get their way. The irrelevant data may find its way in your thoughts covertly, through priming effects you don't even notice. Don't let anything distract you, even if you understand that the distraction isn't related to the problem you are working on. Don't construct the irrelevant items yourself, as byproducts of your activity. Make sure that the data items you consider are actually related to the phenomenon you are trying to understand. <a href=\"http://www.overcomingbias.com/2008/02/second-law.html\">To form accurate beliefs about something, you <em>really</em> do have to observe it.</a> Don't think about fictional evidence, don't think about the facts that look superficially relevant to the question, but actually aren't, as in the case of the hindsight bias and reasoning by <a href=\"http://www.overcomingbias.com/2008/06/surface-analogi.html\">surface analogies</a>.</p>\n<p><strong>The second mistake</strong> is to consider an unbalanced data set, overemphasizing some aspects of the phenomenon, and underemphasizing the others. The data needs to cover the whole phenomenon in a representative way, for the human mind to process it adequately. There are two sides to correcting this imbalance. First, you may take away the excessive data points, deliberatively refusing to consider them, so that your mind gets presented with less evidence, but this remaining evidence is more balanced, more representative of what you are trying to understand. This is similar to what happens when you take an <a href=\"http://www.overcomingbias.com/2007/09/planning-fallac.html\">outside view</a>, for example, to avoid planning fallacy. Second, you may generate the correct data items to fill the rest of the model, from the cluster of evidence you've got. This generation may happen either formally, through using technical models of the phenomenon that allow to explicitly calculate more facts, or informally, through training your intuition to follow reliable rules for interpreting the specific pieces of evidence as the aspects of the whole phenomenon you are studying. Together, these feats constitute expertise in the domain, an art of knowing how to make use of the data that would only confuse a naive mind. When discarding evidence to correct the imbalance of data, only parts you don't posses expertise in need to be thrown away, while the parts that you are ready to process may be kept, making your understanding of the phenomenon stronger.</p>\n<p><strong>The third mistake</strong> is to mix reliable evidence with unreliable evidence. The mind can't tell between relevant info and fictional irrelevant info, let alone between solid relevant evidence and shaky relevant evidence. If you know some facts for sure, and some facts only through indirect unreliable methods, don't consider the latter at all when forming the initial understanding of the phenomenon. Your own untrained intuition generates weak facts, on the things in which you don't have domain expertise, for example when you spontaneously think up solutions to a hard problem. You only get wild guesses when the data is too thin for your intuition to retain at least minimal reliability, when getting a few steps away from the data. You get weak evidence from applying general heuristics that don't promise exceptional precision, such as knowledge of biases. You get weak evidence from listening to the opinion of the majority, from listening to the <a href=\"/lw/u/the_ethic_of_handwashing_and_community_epistemic/\">virulent memes</a>. However, when you don't have reliable data, you need to start including less reliable evidence into consideration, but only the best of what you can come up with.</p>\n<p>Your thinking shouldn't be contaminated by unrelated facts, shouldn't tumble over from the imbalance in knowledge, and shouldn't get diluted by the abundance of weak conclusions. Instead, the understanding should grow more focused on the relevant details, more comprehensive and balanced, attending to more aspects of the problem, and more technically accurate.</p>\n<p>Think representative sets of your best data.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 1, "4R8JYu4QF2FqzJxE5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gWG9x4GGLkm5CYaP6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 12, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "537", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["baTWMegR42PAsH9qJ", "ZP2om2oWHPhvWP2Q3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-06T02:58:06.165Z", "modifiedAt": null, "url": null, "title": "No Universal Probability Space", "slug": "no-universal-probability-space", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:50.705Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gworley", "createdAt": "2009-03-26T17:18:20.404Z", "isAdmin": false, "displayName": "G Gordon Worley III"}, "userId": "gjoi5eBQob27Lww62", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wcvWzgPRyzjLSqBM4/no-universal-probability-space", "pageUrlRelative": "/posts/wcvWzgPRyzjLSqBM4/no-universal-probability-space", "linkUrl": "https://www.lesswrong.com/posts/wcvWzgPRyzjLSqBM4/no-universal-probability-space", "postedAtFormatted": "Wednesday, May 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20No%20Universal%20Probability%20Space&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANo%20Universal%20Probability%20Space%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwcvWzgPRyzjLSqBM4%2Fno-universal-probability-space%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=No%20Universal%20Probability%20Space%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwcvWzgPRyzjLSqBM4%2Fno-universal-probability-space", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwcvWzgPRyzjLSqBM4%2Fno-universal-probability-space", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 678, "htmlBody": "<p>This afternoon I heard a news story about a middle eastern country where one person said of the defenses for a stockpile of nuclear weapons, \"even if there is only a 1% probability of the defenses failing, we should do more to strengthen them given the consequences of their failure\".&nbsp; I have nothing against this person's reasoning, but I do have an issue with where that 1% figure came from.</p>\n<p>The statement above and others like it share a common problem:&nbsp; they are phrased such that it's unclear over what probability space the measure was taken.&nbsp; In fact, many journalist and other people don't seem especially concerned by this.&nbsp; Even some commenters on Less Wrong give little indication of the probability space over which they give a probability measure of an event, and nobody calls them on it.&nbsp; So what is this probability space they are giving probability measurements over?</p>\n<p>If I'm in a generous mood, I might give the person presenting such a statement the benefit of the doubt and suppose they were unintentionally ambiguous.&nbsp; On the defenses of the nuclear weapon stockpile, the person might have meant to say \"there is only a 1% probability of the defenses failing over all attacks\", as in \"in 1 attack out of every 100 we should expect the defenses to fail\".&nbsp; But given both my experiences with how people treat probability and my knowledge of naive reasoning about probability, I am dubious of my own generosity.&nbsp; Rather, I suspect that many people act as though there were a universal probability space over which they may measure the probability of any event.</p>\n<p><a id=\"more\"></a>To illustrate the issue, consider the probability that a fair coins comes up heads.&nbsp; We typically say that there is a 1/2 chance of heads, but what we are implicitly saying is that given a probability measure P on the measurable space ({heads, tails}, {{}, {heads}, {tails}, {heads, tails}}), P({heads}) = P({tails}) = 1/2 and P({}) = 0 and P({heads, tails}) = 1.&nbsp; But if we look at the issue of a coin coming up heads from a wider angle, we could interpret it as \"what is the probability of some particular coin sitting heads-up over the span of all time\", which is another question all together.&nbsp; What this is asking is \"what is the probability of the event that this coin sits heads-up over the universal probability space\", i.e. the probability space of all events that could occur at some time during the existence of the universe, and we have no clear way to calculate the probability of such an event other than to say that the universal probability space must contain infinitely many (how infinitely is still up for debate) events of measure zero.&nbsp; So there is a universal probability space; it's just not very useful to us, hence the title of the article, since it practically doesn't exist for us.</p>\n<p>None of this is to say, though, that the people committing these crimes against probability are aware of what probability space they are taking a measure over.&nbsp; Many people act as if there is some number they can assign to any event which tells them how likely it is to occur and questions of \"probability spaces\" never enter their minds.&nbsp; What does it mean that something happens 1% of the time?&nbsp; I don't know; maybe that it doesn't happen 99% of the time?&nbsp; How is 1% of the time measured?&nbsp; I don't know; maybe one out of every 100 seconds?&nbsp; Their crime is not one of mathematical abuse but of mathematical ignorance.</p>\n<p>As aspiring rationalists, if we measure a probability, we ought to know over what probability space we're measuring.&nbsp; Otherwise a probability isn't well defined and is just another number that, at best, is meaningless and, at worst, can be used to help us <a href=\"http://www.overcomingbias.com/2008/09/childhood-spira.html\">defeat ourselves</a>.&nbsp; Even if it's not always a good stylistic choice to make the probability space explicit in our speech and writing, <a href=\"http://www.overcomingbias.com/2008/07/recursive-justi.html\">we must always know</a> over what probability space we are measuring a probability.&nbsp; Otherwise we are just making up numbers to <a href=\"http://www.overcomingbias.com/2007/04/feeling_rationa.html\">feel rational</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hLp77TQsRkooioj86": 1, "6nS8oYmSMuFMaiowF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wcvWzgPRyzjLSqBM4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 2, "extendedScore": null, "score": 4e-06, "legacy": true, "legacyId": "536", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-06T05:17:02.471Z", "modifiedAt": null, "url": null, "title": "Wiki.lesswrong.com Is Live", "slug": "wiki-lesswrong-com-is-live", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:50.722Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DebhAYmgEtncDhMLK/wiki-lesswrong-com-is-live", "pageUrlRelative": "/posts/DebhAYmgEtncDhMLK/wiki-lesswrong-com-is-live", "linkUrl": "https://www.lesswrong.com/posts/DebhAYmgEtncDhMLK/wiki-lesswrong-com-is-live", "postedAtFormatted": "Wednesday, May 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wiki.lesswrong.com%20Is%20Live&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWiki.lesswrong.com%20Is%20Live%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDebhAYmgEtncDhMLK%2Fwiki-lesswrong-com-is-live%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wiki.lesswrong.com%20Is%20Live%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDebhAYmgEtncDhMLK%2Fwiki-lesswrong-com-is-live", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDebhAYmgEtncDhMLK%2Fwiki-lesswrong-com-is-live", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<p><a href=\"http://wiki.lesswrong.com/\">http://wiki.lesswrong.com/</a> is now live, for all our Wiki needs.&nbsp; The previous Wikia wiki has been imported.&nbsp; Knock yourself out on linking there from comments or blog posts (yes, you will have to link manually, there is no CamelCase convention yet on the blog and comments).</p>\n<p>See here for <a href=\"/lw/cg/proposal_use_the_wiki_for_concepts/\">proposed wiki usage guidelines</a> - note that these do not yet seem to appear in the Wiki itself, hint hint.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DebhAYmgEtncDhMLK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 11, "extendedScore": null, "score": 4.923734994821242e-07, "legacy": true, "legacyId": "538", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cDQFK7tPDo9H4nPSE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-06T18:31:28.077Z", "modifiedAt": null, "url": null, "title": "Hardened Problems Make Brittle Models", "slug": "hardened-problems-make-brittle-models", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:27.889Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JvQniHSBr6JCbTRnj/hardened-problems-make-brittle-models", "pageUrlRelative": "/posts/JvQniHSBr6JCbTRnj/hardened-problems-make-brittle-models", "linkUrl": "https://www.lesswrong.com/posts/JvQniHSBr6JCbTRnj/hardened-problems-make-brittle-models", "postedAtFormatted": "Wednesday, May 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hardened%20Problems%20Make%20Brittle%20Models&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHardened%20Problems%20Make%20Brittle%20Models%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJvQniHSBr6JCbTRnj%2Fhardened-problems-make-brittle-models%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hardened%20Problems%20Make%20Brittle%20Models%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJvQniHSBr6JCbTRnj%2Fhardened-problems-make-brittle-models", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJvQniHSBr6JCbTRnj%2Fhardened-problems-make-brittle-models", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 358, "htmlBody": "<p>Consider a simple decision problem: you arrange a date with someone, you arrive on time, your partner isn't there. How long do you wait before giving up?</p>\n<p>Humans naturally respond to this problem by acting outside the box. Wait a little then send a text message. If that option is unavailable, pluck a reasonable waiting time from cultural context, e.g. 15 minutes. If that option is unavailable...</p>\n<p>Wait, what?</p>\n<p>The toy problem was initially supposed to help us improve ourselves - to serve as a reasonable model of something in the real world. The natural human solution seemed too messy and unformalizable so we progressively remove nuances to make the model more extreme. We introduce Omegas, billions of lives at stake, total informational isolation, perfect predictors, finally arriving at some sadistic contraption that any normal human would run away from. But did the model stay useful and instructive? Or did we lose important detail along the way?</p>\n<p>Many physical models, like gravity, have the nice property of stably approximating reality. Perturbing the positions of planets by one millimeter doesn't explode the Solar System the next second. Unfortunately, many of the models we're discussing here don't have this property. The worst offender yet seems to be Eliezer's <a href=\"http://www.overcomingbias.com/2008/09/true-pd.html\">\"True PD\"</a> which requires the whole package of hostile psychopathic AIs, nuclear-scale payoffs and informational isolation; any natural out-of-the-box solution like giving the damn thing some paperclips or bargaining with it would ruin the game. The same pattern has recurred in discussions of Newcomb's Problem where people have stated that any miniscule amount of introspection into Omega makes the problem \"no longer Newcomb's\". That naturally led to more ridiculous use of superpowers, like Alicorn's <a href=\"/lw/em/bead_jar_guesses/\">bead jar game</a> where (AFAIU) the mention of Omega is only required to enforce a certain assumption about its thought mechanism that's wildly unrealistic for a human.</p>\n<p>Artificially hardened logic problems make brittle models of reality.</p>\n<p>So I'm making a modest proposal. If you invent an interesting decision problem, please, first model it as a parlor game between normal people with stakes of around ten dollars. If the attempt fails, you have acquired a bit of information about your concoction; don't ignore it outright.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "KoXbd2HmbdRfqLngk": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JvQniHSBr6JCbTRnj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 63, "baseScore": 58, "extendedScore": null, "score": 0.00011733838436164561, "legacy": true, "legacyId": "540", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 53, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mXaPPjud9MuuboWgd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-06T22:04:02.354Z", "modifiedAt": null, "url": null, "title": "Beware Trivial Inconveniences", "slug": "beware-trivial-inconveniences", "viewCount": null, "lastCommentedAt": "2021-01-22T17:05:09.177Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences", "pageUrlRelative": "/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences", "linkUrl": "https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences", "postedAtFormatted": "Wednesday, May 6th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beware%20Trivial%20Inconveniences&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeware%20Trivial%20Inconveniences%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreitXJgJXFzKpdKyd%2Fbeware-trivial-inconveniences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beware%20Trivial%20Inconveniences%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreitXJgJXFzKpdKyd%2Fbeware-trivial-inconveniences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreitXJgJXFzKpdKyd%2Fbeware-trivial-inconveniences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1069, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Great_Firewall_of_China\">The Great Firewall of China</a>. A massive system of centralized censorship purging the Chinese version of the Internet of all potentially subversive content. Generally agreed to be a great technical achievement and political success even by the vast majority of people who find it morally abhorrent.<br /><br />I spent a few days in China. I got around it at the Internet cafe by using a free online proxy. Actual Chinese people have dozens of ways of getting around it with a minimum of technical knowledge or just the ability to read some instructions.<br /><br />The Chinese government isn't losing any sleep over this (although they also don't lose any sleep over murdering political dissidents, so maybe they're just very sound sleepers). Their theory is that by making it a little inconvenient and time-consuming to view subversive sites, they will discourage casual exploration. No one will bother to circumvent it unless they already seriously distrust the Chinese government and are specifically looking for foreign websites, and these people probably know what the foreign websites are going to say anyway.<br /><br />Think about this for a second. The human longing for freedom of information is a terrible and wonderful thing. It delineates a pivotal difference between mental emancipation and slavery. It has launched protests, rebellions, and revolutions. Thousands have devoted their lives to it, thousands of others have even died for it. And it can be stopped dead in its tracks by requiring people to search for \"how to set up proxy\" before viewing their anti-government website.</p>\n<p><a id=\"more\"></a></p>\n<p>I was reminded of this recently by Eliezer's <a href=\"http://www.overcomingbias.com/2009/04/less-wrong-progress-report.html\">Less Wrong Progress Report</a>. He mentioned how surprised he was that so many people were posting so much stuff on Less Wrong, when very few people had ever taken advantage of Overcoming Bias' policy of accepting contributions if you emailed them to a moderator and the moderator approved. Apparently all us folk brimming with ideas for posts didn't want to deal with the aggravation.<br /><br />Okay, in my case at least it was a bit more than that. There's a sense of going out on a limb and drawing attention to yourself, of arrogantly claiming some sort of equivalence to Robin Hanson and Eliezer Yudkowsky. But it's still interesting that this potential embarrassment and awkwardness was enough to keep the several dozen people who have blogged on here so far from sending that \"I have something I'd like to post...\" email.<br /><br />Companies frequently offer \"free rebates\". For example, an $800 television with a $200 rebate. There are a few reasons companies like rebates, but one is that you'll be attracted to the television because it appears to have a net cost only $600, but then filling out the paperwork to get the rebate is too inconvenient and you won't get around to it. This is basically a free $200 for filling out an annoying form, but companies can predict that customers will continually fail to complete it. This might make some sense if you're a high-powered lawyer or someone else whose time is extremely valuable, but most of us have absolutely no excuse.<br /><br />One last example: It's become a truism that people spend more when they use credit cards than when they use money. This particular truism happens to be true: in a study by Prelec and Simester<sup>1</sup>, auction participants bid twice as much for the same prize when using credit than when using cash. The trivial step of getting the money and handing it over has a major inhibitory effect on your spending habits.<br /><br />I don't know of any unifying psychological theory that explains our problem with trivial inconveniences. It seems to have something to do with loss aversion, and with the brain's general use of emotion-based hacks instead of serious cost-benefit analysis. It might be linked to akrasia; for example, you might not have enough willpower to go ahead with the unpleasant action of filling in a rebate form, and your brain may assign it low priority because it's hard to imagine the connection between the action and the reward.<br /><br />But these trivial inconveniences have major policy implications. Countries like China that want to oppress their citizens are already using \"soft\" oppression to make it annoyingly difficult to access subversive information. But there are also benefits for governments that want to help their citizens.<br /><br />\"Soft paternalism\" means a lot of things to a lot of different people. But one of the most interesting versions is the idea of \"opt-out\" government policies. For example, it would be nice if everyone put money into a pension scheme. Left to their own devices, many ignorant or lazy people might never get around to starting a pension, and in order to prevent these people's financial ruin, there is strong a moral argument for a government-mandated pension scheme. But there's also a strong libertarian argument against that idea; if someone for reasons of their own doesn't want a pension, or wants a different kind of pension, their status as a free citizen should give them that right.<br /><br />The \"soft paternalist\" solution is to have a government-mandated pension scheme, but allow individuals to opt-out of it after signing the appropriate amount of paperwork. Most people, the theory goes, would remain in the pension scheme, because they understand they're better off with a pension and it was only laziness that prevented them from getting one before. And anyone who actually goes through the trouble of opting out of the government scheme would either be the sort of intelligent person who has a good reason not to want a pension, or else deserve what they get<sup>2</sup>.<br /><br />This also reminds me of Robin's IQ-gated, test-requiring <a href=\"http://www.overcomingbias.com/2007/03/paternalism_is_.html\">would-have-been-banned store</a>, which would discourage people from certain drugs without making it impossible for the true believers to get their hands on them. I suggest such a store be located way on the outskirts of town accessible only by a potholed road with a single traffic light that changes once per presidential administration, have a surly clerk who speaks heavily accented English, and be open between the hours of two and four on weekdays.</p>\n<p>&nbsp;</p>\n<p><strong>Footnotes</strong></p>\n<p><strong>1: </strong>See Jonah Lehrer's book <em>How We Decide. </em>In fact, do this anyway. It's very good.</p>\n<p><strong>2: </strong>Note also the clever use of the status quo bias here.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 16, "CYMR6p5iZG75QAT8a": 2, "XYHzLjwYiqpeqaf4c": 1, "5f5c37ee1b5cdee568cfb23e": 9, "RffCgqtwT86pNBJof": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "reitXJgJXFzKpdKyd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 153, "baseScore": 189, "extendedScore": null, "score": 0.000289, "legacy": true, "legacyId": "541", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 189, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 115, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 13, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-07T04:26:14.714Z", "modifiedAt": null, "url": null, "title": "On the Fence? Major in CS", "slug": "on-the-fence-major-in-cs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:52.117Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "talisman", "createdAt": "2009-03-05T23:30:16.521Z", "isAdmin": false, "displayName": "talisman"}, "userId": "SXxD8wMPMJZZEdNZe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bv36xQt9FNyotpqEy/on-the-fence-major-in-cs", "pageUrlRelative": "/posts/bv36xQt9FNyotpqEy/on-the-fence-major-in-cs", "linkUrl": "https://www.lesswrong.com/posts/bv36xQt9FNyotpqEy/on-the-fence-major-in-cs", "postedAtFormatted": "Thursday, May 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20the%20Fence%3F%20Major%20in%20CS&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20the%20Fence%3F%20Major%20in%20CS%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbv36xQt9FNyotpqEy%2Fon-the-fence-major-in-cs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20the%20Fence%3F%20Major%20in%20CS%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbv36xQt9FNyotpqEy%2Fon-the-fence-major-in-cs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbv36xQt9FNyotpqEy%2Fon-the-fence-major-in-cs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 693, "htmlBody": "<p>I talk to many <a href=\"http://en.wikipedia.org/wiki/Doctor_of_Philosophy,_All_But_Dissertation\">ABD</a>s in math, physics, engineering, economics, and various other technical fields.</p>\n<p>I work with exceptional people from all those backgrounds.</p>\n<p>I would like to unreservedly say to any collegians out there, whether choosing an undergrad major or considering fields of study for grad school: if you know you want a technical major but you're not sure which, choose Computer Science.</p>\n<p>Unless you're extremely talented and motivated, <em>relative to your extremely talented and motivated peers</em>, you probably aren't going to make a career in academia even if you want to.&nbsp; And if you want a technical major but you're not sure which, you shouldn't want to!&nbsp; Academia is a huge drag in many ways.&nbsp; When a math ABD starts telling me about how she really likes her work but is sick of the slow pace and the fact that only six people in the world understand her work, I get to take a nice minute alone with my thoughts: I've heard it over and over again, in the same words and the same weary, beaten-down tone.&nbsp; You shouldn't be considering a career in academia unless you're passionately in love with your field, unless you think about it in the shower and over lunch and as you drift off to sleep, unless the problem sets are a weekly joy.&nbsp; A lesser love will abandon you and leave you stranded and heartbroken, four years into grad school.</p>\n<p>What's so great about CS, then?&nbsp; Isn't it just a bunch of glorified not-real-math and hundreds of hours of grimy debugging?</p>\n<p>Let's start with several significant, but peripheral, reasons:</p>\n<ul>\n<li>CS majors learn to <em>really program</em>.&nbsp; There's an ocean of difference between the power of a decent, desultory programmer and that of a real programmer.&nbsp; If you're not a programmer, the power of real programmers to create good stuff borders on magic.&nbsp; </li>\n<li>Not least among the good stuff is <em>time</em>.&nbsp; It's disgraceful, the amount of human effort that goes into work that could be done by a Perl one-liner.</li>\n<li>CS majors learn to be at home with the guts of computers.&nbsp; This seems to come in handy in a hundred little ways.</li>\n<li>CS majors are significantly more likely than other technical majors to get involved in startups, which are one of the best ways around to <a href=\"http://www.paulgraham.com/wealth.html\">create wealth</a>.</li>\n<li>While having abstract and intellectual sides, the good kind of CS is strongly tied to the practical.</li>\n<li>CS people can do fun side projects.&nbsp;&nbsp; I've never heard of an engineer doing a bit of engineering on the side from their management consulting job; with CS people it's rare that they <em>don't </em>have a little something cooking.</li>\n</ul>\n<p>None of that gets to my real point, which is the modes of thought that CS majors build.&nbsp; Working with intransigent computer code for years upon years, the smart ones learn a deeply careful, modular, and reductionist mindset that transfers shockingly well to all kinds of systems-oriented thinking--</p>\n<p>And most significantly to building and understanding <a href=\"/lw/cy/rational_groups_kick_ass/\"><em>human </em>systems</a>.&nbsp; The questions they learn to ask about a codebase--\"What invariants must this process satisfy?&nbsp; What's the cleanest way to organize this structure?&nbsp; How should these subsystems work together?\"--are <em>incredibly</em> powerful when applied to a complex human process.&nbsp; If I needed a CEO for my enterprise, not just my software company but my airline, my automaker, my restaurant chain, I would start by looking for candidates with a CS background.</p>\n<p>You can see some of this relevance in the multitude of analogies CS people are able to apply to non-CS areas.&nbsp; When's the last time you heard a math person refer to some real-world situation as \"a real elliptic curve\"?&nbsp; The CS people I know have a rich vocabulary of cached concepts that address real-world situations: race conditions, interrupts, stacks, queues, bandwidth, latency, and many more that go over my head, because...</p>\n<p>I didn't major in CS.&nbsp; I saw it as too \"applied,\" and went for more \"elevated\" areas.&nbsp; <a href=\"http://www.overcomingbias.com/2008/06/against-disclai.html\">I grew intellectually through that study</a>, but I've upped my practical effectiveness enormously in the last few years by working with great CS people and absorbing all I can of their mindset.</p>\n<p><a href=\"http://www.overcomingbias.com/2008/06/against-disclai.html\"><br /></a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4kQXps8dYsKJgaayN": 1, "HFou6RHqFagkyrKkW": 1, "GY5kPPpCoyt9fnTMn": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bv36xQt9FNyotpqEy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 21, "extendedScore": null, "score": 4.925819170614574e-07, "legacy": true, "legacyId": "542", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 59, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gj7Z7Zj6SMkrEaN8J"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-07T14:51:52.763Z", "modifiedAt": null, "url": null, "title": "Rationality is winning - or is it?", "slug": "rationality-is-winning-or-is-it", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:50.757Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xd5RxPuKC8WiGrJ4u/rationality-is-winning-or-is-it", "pageUrlRelative": "/posts/Xd5RxPuKC8WiGrJ4u/rationality-is-winning-or-is-it", "linkUrl": "https://www.lesswrong.com/posts/Xd5RxPuKC8WiGrJ4u/rationality-is-winning-or-is-it", "postedAtFormatted": "Thursday, May 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20is%20winning%20-%20or%20is%20it%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20is%20winning%20-%20or%20is%20it%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXd5RxPuKC8WiGrJ4u%2Frationality-is-winning-or-is-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20is%20winning%20-%20or%20is%20it%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXd5RxPuKC8WiGrJ4u%2Frationality-is-winning-or-is-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXd5RxPuKC8WiGrJ4u%2Frationality-is-winning-or-is-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p>I feel a bit silly writing an post about connotations on a rationalist website, but I really love the quote \"Rationality (is/is not) winning\". I see a few different ways of interpreting it:</p>\n<ul>\n<li>\"Rationality is winning\" - results are more important than following a particular ritual of cognition. If something doesn't work, abandon it no matter how \"rational\" is seems.</li>\n<li>\"Rationality is not winning\" - exploration is much more fun than just mindlessly going toward some goal.</li>\n<li>\"Rationality is winning\" - what matters is how good you are at reaching socially accepted criteria of \"success\" - I don't like this connotation at all.</li>\n<li>And I can think of a few others...</li>\n</ul>\n<p>I wonder, the way human brain works, is it common for there to be thoughts that are much better expressed with a short sentence full of ambiguous connotations, that by long and accurate explanations? Give me your favourite ambiguous quotes!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3QnDqGSdRMA5mdMM6": 1, "Ng8Gice9KNkncxqcj": 1, "aa3Qg7Qrp9LM7QMaz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xd5RxPuKC8WiGrJ4u", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -8, "extendedScore": null, "score": -1.2e-05, "legacy": true, "legacyId": "544", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-07T17:41:43.586Z", "modifiedAt": null, "url": null, "title": "The First Koan: Drinking the Hot Iron Ball", "slug": "the-first-koan-drinking-the-hot-iron-ball", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:51.368Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Annoyance", "createdAt": "2009-02-28T04:06:40.600Z", "isAdmin": false, "displayName": "Annoyance"}, "userId": "yEm6LWatswJYGwBFq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wCgRvyYJEF8me2QW9/the-first-koan-drinking-the-hot-iron-ball", "pageUrlRelative": "/posts/wCgRvyYJEF8me2QW9/the-first-koan-drinking-the-hot-iron-ball", "linkUrl": "https://www.lesswrong.com/posts/wCgRvyYJEF8me2QW9/the-first-koan-drinking-the-hot-iron-ball", "postedAtFormatted": "Thursday, May 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20First%20Koan%3A%20Drinking%20the%20Hot%20Iron%20Ball&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20First%20Koan%3A%20Drinking%20the%20Hot%20Iron%20Ball%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwCgRvyYJEF8me2QW9%2Fthe-first-koan-drinking-the-hot-iron-ball%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20First%20Koan%3A%20Drinking%20the%20Hot%20Iron%20Ball%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwCgRvyYJEF8me2QW9%2Fthe-first-koan-drinking-the-hot-iron-ball", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwCgRvyYJEF8me2QW9%2Fthe-first-koan-drinking-the-hot-iron-ball", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 813, "htmlBody": "<p>In the traditions of Zen in which koans are common teaching tools, it is common to use a particular story as a novice's first koan.&nbsp; It's the story of Joshu's Dog.</p>\n<blockquote>\n<p>A monk asked Joshu, a Chinese Zen master: `Has a dog Buddha-nature or not?'</p>\n<p>Joshu answered: `Mu.'&nbsp; [Mu is the negative symbol in Chinese, meaning `No-thing' or `Nay'.]</p>\n</blockquote>\n<p>What does this koan mean?&nbsp; How can we find out for ourselves?</p>\n<p>It is important to remember certain things:&nbsp; Firstly, <a href=\"http://en.wikipedia.org/wiki/Koan\">koans</a> are not meant to be puzzles, riddles, or intellectual games.&nbsp; They are examples, illustrations of the state of mind that the student is expected to internalize.&nbsp; Secondly, they often appear paradoxical.</p>\n<blockquote>\n<p>Paradox is a pointer telling you to look beyond it.&nbsp; If paradoxes bother you, that betrays your deep desire for absolutes.&nbsp; The relativist treats a paradox merely as interesting, perhaps amusing or even -- dreadful thought -- educational.</p>\n</blockquote>\n<p>Thirdly, the purpose of Zen teaching isn't to acquire new conceptual baggage, but to eliminate it; not to generate Enlightenment, but to remove the false beliefs that preventing us from recognizing what we already possess.&nbsp; Shedding error is the point, not learning something new.</p>\n<p>Take a look at Mumon's commentary for this koan:</p>\n<blockquote>\n<p>To realize Zen one has to pass through the barrier of the patriachs. Enlightenment always comes after the road of thinking is blocked. If you do not pass the barrier of the patriachs or if your thinking road is not blocked, whatever you think, whatever you do, is like a tangling ghost. You may ask: What is a barrier of a patriach? This one word, Mu, is it.</p>\n<p>This is the barrier of Zen. If you pass through it you will see Joshu face to face. Then you can work hand in hand with the whole line of patriachs. Is this not a pleasant thing to do?</p>\n<p>If you want to pass this barrier, you must work through every bone in your body, through ever pore in your skin, filled with this question: What is Mu? and carry it day and night. Do not believe it is the common negative symbol meaning nothing. It is not nothingness, the opposite of existence. If you really want to pass this barrier, you should feel like drinking a hot iron ball that you can neither swallor nor spit out.</p>\n<p>Then your previous lesser knowledge disappears. As a fruit ripening in season, your subjectivity and objectivity naturally become one. It is like a dumb man who has had a dream. He knows about it but cannot tell it.</p>\n<p>When he enters this condition his ego-shell is crushed and he can shake the heaven and move the earth. He is like a great warrior with a sharp sword. If a Buddha stands in his way, he will cut him down; if a patriach offers him any obstacle, he will kill him; and he will be free in this way of birth and death. He can enter any world as if it were his own playground. I will tell you how to do this with this koan:</p>\n<p>Just concentrate your whole energy into this Mu, and do not allow any discontinuation. When you enter this Mu and there is no discontinuation, your attainment will be as a candle burning and illuminating the whole universe.</p>\n</blockquote>\n<p>I'll give you a hint:&nbsp; Joshu's reply isn't really an answer to the monk's question, it's a response induced by it.&nbsp; Joshu answers the question the monk didn't ask but should have - the question whose answer the monk is taking for granted in what he asks.</p>\n<p>This morning I passed by a gym with a glass-walled front, and I saw within the building many people working at machines, moving weights back and forth.&nbsp; What was being accomplished?&nbsp; Superficially, nothing at all.&nbsp; Their actions would appear to be wasted; nothing was done with them.&nbsp; The real purpose, of course, was to exercise the body, to condition the muscles and strengthen the bones.</p>\n<p>The point of the koan isn't to find the 'right answer', the point of the koan is to struggle with it, and by struggling, develop one's own understanding.&nbsp; Contradiction and apparent contradiction is a powerful tool for this purpose.&nbsp; Trying to understand, we usually perceive a contradiction and let the process terminate.&nbsp; But if we keep struggling with the problem, even though we cannot expect to achieve anything, we build within ourselves ever more complex models, ways of seeing.&nbsp; Eventually the complexity will be useful in dealing with other problems, ones with solutions we didn't see before.</p>\n<p>One warning:&nbsp; the fact that a problem is used as a source of contradiction does not mean that it doesn't actually have an answer.&nbsp; Don't mistake the use for the reality.</p>\n<p><em> Has a dog Buddha-nature?<br /> This is the most serious question of all.<br /> If you say yes or no,<br /> You lose your own Buddha-nature.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xv7Bg5fbF9WppYREi": 1, "etDohXtBrXd8WqCtR": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wCgRvyYJEF8me2QW9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": -1, "extendedScore": null, "score": -2e-06, "legacy": true, "legacyId": "545", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-07T23:09:40.070Z", "modifiedAt": null, "url": null, "title": "Epistemic vs. Instrumental Rationality: Case of the Leaky Agent", "slug": "epistemic-vs-instrumental-rationality-case-of-the-leaky", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:50.831Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g2Rh4xXALjuyLqm4k/epistemic-vs-instrumental-rationality-case-of-the-leaky", "pageUrlRelative": "/posts/g2Rh4xXALjuyLqm4k/epistemic-vs-instrumental-rationality-case-of-the-leaky", "linkUrl": "https://www.lesswrong.com/posts/g2Rh4xXALjuyLqm4k/epistemic-vs-instrumental-rationality-case-of-the-leaky", "postedAtFormatted": "Thursday, May 7th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Epistemic%20vs.%20Instrumental%20Rationality%3A%20Case%20of%20the%20Leaky%20Agent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEpistemic%20vs.%20Instrumental%20Rationality%3A%20Case%20of%20the%20Leaky%20Agent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg2Rh4xXALjuyLqm4k%2Fepistemic-vs-instrumental-rationality-case-of-the-leaky%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Epistemic%20vs.%20Instrumental%20Rationality%3A%20Case%20of%20the%20Leaky%20Agent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg2Rh4xXALjuyLqm4k%2Fepistemic-vs-instrumental-rationality-case-of-the-leaky", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg2Rh4xXALjuyLqm4k%2Fepistemic-vs-instrumental-rationality-case-of-the-leaky", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 331, "htmlBody": "<p>Suppose you hire a real-estate agent to sell your house. You have to leave town so you give him the authority to negotiate with buyers on your behalf. The agent is honest and hard working. He'll work as hard to get a good price for your house as if he's selling his own house. But unfortunately, he's not very good at keeping secrets. He wants to know what is the minimum amount you're willing to sell the house for so he can do the negotiations for you. But you know that if you answer him truthfully, he's liable to leak that information to buyers, giving them a bargaining advantage and driving down the expected closing price. What should you do? Presumably most of you in this situation would give the agent a figure that's higher than the actual minimum. (How much higher involves optimizing a tradeoff between the extra money you get if the house sells, versus the probability that you can't find a buyer at the higher fictional minimum.)</p>\n<p>Now here's the kicker: that agent is actually your future self. Would you tell yourself a lie, if you could believe it (perhaps with the help of future memory modification technologies), and if you could profit from it?</p>\n<p><strong>Edit: </strong>Some commenters have pointed out that this change in \"minimum acceptable price\" may not be exactly a lie. I should have made the example a bit clearer. Let's say if you fail to sell the house by a certain date, it will be reposessed by the bank, so the minimum acceptable price is the amount left on your mortgage, since you're better off selling the house for any amount above that than not selling it. But if buyers know that, they can just offer you slightly above the minimum acceptable price. It will help you get a better bargain if you can make yourself believe that the amount left on your mortgage is higher than it really is. This should be unambigously a lie.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "Ng8Gice9KNkncxqcj": 1, "YTCrHWYHAsAD74EHo": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g2Rh4xXALjuyLqm4k", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 18, "extendedScore": null, "score": 2.8e-05, "legacy": true, "legacyId": "546", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-08T05:35:23.942Z", "modifiedAt": null, "url": null, "title": "Replaying History", "slug": "replaying-history", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:51.874Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gworley", "createdAt": "2009-03-26T17:18:20.404Z", "isAdmin": false, "displayName": "G Gordon Worley III"}, "userId": "gjoi5eBQob27Lww62", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/z37KpjFbSzogXi8d4/replaying-history", "pageUrlRelative": "/posts/z37KpjFbSzogXi8d4/replaying-history", "linkUrl": "https://www.lesswrong.com/posts/z37KpjFbSzogXi8d4/replaying-history", "postedAtFormatted": "Friday, May 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Replaying%20History&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReplaying%20History%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz37KpjFbSzogXi8d4%2Freplaying-history%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Replaying%20History%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz37KpjFbSzogXi8d4%2Freplaying-history", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz37KpjFbSzogXi8d4%2Freplaying-history", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 566, "htmlBody": "<p>One of my favorite fiction genres is alternative history.&nbsp; The basic idea of alternative history is to write a story set in an alternate universe where history played out differently.&nbsp; Popular alternate histories include those where the Nazis win World War II, the USSR wins the Cold War, and the Confederate States of America win the American Civil War.&nbsp; But most of the writing in this genre has a serious flaw:&nbsp; the author starts out by saying \"wouldn't it be cool to write a story where X had happened instead of Y\" and then works backwards to concoct historical events that will lead to the desired outcome.&nbsp; No matter how good the story is, the history is often bad because at every stage the author went looking for a reason for things to go his way.</p>\n<p>Being unsatisfied with most alternate histories, I like to play a historical \"what if\" game.&nbsp; Rather than asking the question at the conclusion, though (like \"what if the Nazis had won the war\"), I ask it at an earlier moment, ideally one where chance played an important role.&nbsp; What if Napoleon had been convinced not to invade Russia?&nbsp; What if the Continental Army had not successfully retreated from New York?<span lang=\"zh-Hans\" xml:lang=\"zh-Hans\">&nbsp; What if Viking settlements in Newfoundland had not collapsed?&nbsp; These are as opposed to \"What if Napoleon had never been defeated?\", \"What if the Colonies had lost the American Revolutionary War?\", and \"What if Vikings had developed a thriving civilization in the Americas?\".&nbsp; I find that replaying history in this way a fun use of my analytical skills, but more importantly a good test of my rationality.</span></p>\n<p><span lang=\"zh-Hans\" xml:lang=\"zh-Hans\">One of the most difficult things in thinking of an alternative history is to stay focused on the facts and likely outcomes.&nbsp; It's easy to say \"I'd really like to see a world where X happened\" and then silently or overtly bias your thinking until you find a way to achieve the desired outcome.&nbsp; Learning to avoid this takes discipline, especially in a domain like alternate history where there's no way to check if your reasoning turned out to be correct.&nbsp; But unlike imagining the future, making an alternate history does have the real history to measure up against, so it provides a good training ground for futurist who don't want to wait 20 or 30 years to get feedback on their thinking.</span></p>\n<p>Given all this, I have two suggestions.&nbsp; One, this indicates that a good way to teach history and rational thinking at the same time would be to present historical data up to a set point, ask students to reason out what they think will happen next in history, and then reveal what actually happened and use the feedback to calibrate and improve our historical reasoning (which will hopefully provide some benefit in other domains).&nbsp; Second, a good way to build experience applying the skills of rationality is publicly present and critique alternate histories.</p>\n<p>In that vein, if there appears to be sufficient interest, I'll start doing a periodic article here dedicated to the discussion of some particular alternative history.&nbsp; The discussion will be in the comments:&nbsp; people can propose outcomes, then others can revise and critique and propose other outcomes, continuing the cycle until we hit a brick wall (not enough information, question asks something that would not have changed history, etc.) or come to a consensus.</p>\n<p>What do you all think of this idea?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bY5MaF2EATwDkomvu": 1, "ZzxvopS4BwLuQy42n": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "z37KpjFbSzogXi8d4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 7, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "341", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-08T10:27:02.864Z", "modifiedAt": null, "url": null, "title": "Framing Consciousness", "slug": "framing-consciousness", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:51.274Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mkNarWtkpZdnX6MCb/framing-consciousness", "pageUrlRelative": "/posts/mkNarWtkpZdnX6MCb/framing-consciousness", "linkUrl": "https://www.lesswrong.com/posts/mkNarWtkpZdnX6MCb/framing-consciousness", "postedAtFormatted": "Friday, May 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Framing%20Consciousness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFraming%20Consciousness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkNarWtkpZdnX6MCb%2Fframing-consciousness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Framing%20Consciousness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkNarWtkpZdnX6MCb%2Fframing-consciousness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkNarWtkpZdnX6MCb%2Fframing-consciousness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 422, "htmlBody": "<p><strong>Update:</strong> you can ignore this post, it's completely wrong, I'm only leaving it up to preserve people's comments. Randallsquared has caught a crucial mistake in my reasoning: consciousness could require physical causality, rather than a property of some snapshot description. This falsifies my Point 3 below.</p>\n<p>...</p>\n<p><a id=\"more\"></a></p>\n<p>In this unabashedly geek-porn post I want to slightly expand our discussion of consciousness, as defined in the <a href=\"http://en.wikipedia.org/wiki/Hard_problem_of_consciousness\">hard problem of consciousness</a>. Don't be scared: no quantum claptrap or \"informational system\" bullshit.</p>\n<p><strong>Point 1.</strong> The existence (and maybe degree) of conscious/subjective experiences is an objective question.</p>\n<p>Justification: if you feel a human possesses as much consciousness as a rock or the number three, stop reading now. This concludes the \"proof by anthropic principle\" or \"by quantum immortality\" for those still reading.</p>\n<p><strong>Point 2.</strong> It's either possible or impossible in principle to implement consciousness on a Turing-equivalent digital computer.</p>\n<p>Justification: obvious corollary of Point 1.</p>\n<p><strong>Point 3.</strong> If consciousness is implementable on a digital computer, all imaginable conscious experiences already exist.</p>\n<p>Justification: the state of any program can be encoded as an integer. What does it mean for an integer to \"exist\"? Does three \"exist\"? If a computer program gives rise to \"actually existing\" subjective experiences, then so does the decimal expansion of the x-coordinate of some particle in the Magellanic Cloud when written out in trinary.</p>\n<p><strong>Point 4.</strong> If consciousness is implementable, the <a href=\"http://www.simulation-argument.com/simulation.html\">Simulation Argument</a> is invalid and <a href=\"http://www.overcomingbias.com/2007/10/pascals-mugging.html\">Pascal's Mugging</a> is almost certainly invalid.</p>\n<p>Justification: obvious corollary of Point 3.</p>\n<p><strong>Point 5.</strong> If consciousness is non-implementable, the Simulation Argument and <a href=\"http://hanson.gmu.edu/uploads.html\">Robin's uploads scenario</a> lose much of their punch.</p>\n<p>Justification: the extinction threat in SA and the upload transition only feel urgent due to our current rapid progress with digital computers. We don't yet have a computer peripheral for providing programs with a feeling of non-implementable consciousness.</p>\n<p><strong>Point 6.</strong> If consciousness could be implementable, Eliezer had better account for it when designing his FAI.</p>\n<p>Justification: there's no telling what the FAI will do when it realizes that actual humans have no privileged status over imaginable humans, or alternatively that they do and torturing simulated humans carries no moral weight.</p>\n<p><strong>Point 7.</strong> The implementability of currently known physics gives strong evidence that consciousness is implementable.</p>\n<p>Justification: pretty obvious. Neurons have been called \"essentially classical objects\", not even quantum.</p>\n<p><strong>Point 8.</strong> The fact that evolution gave us conscious brains rather than \"dumb computers\" gives weak evidence that consciousness is non-implementable.</p>\n<p>Justification: we currently know of no reason why organisms would need implementable consciousness, whereas using a natural phenomenon of non-implementable consciousness could give brains extra computational power.</p>\n<p>Any disagreements? Anything else interesting in this line of inquiry?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XSryTypw5Hszpa4TS": 1, "SJsXpuovvmkEqoJAJ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mkNarWtkpZdnX6MCb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": -5, "extendedScore": null, "score": -1.2e-05, "legacy": true, "legacyId": "548", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-08T13:33:29.567Z", "modifiedAt": null, "url": null, "title": "A Request for Open Problems", "slug": "a-request-for-open-problems", "viewCount": null, "lastCommentedAt": "2017-06-17T03:55:55.273Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MrHen", "createdAt": "2009-04-01T17:47:41.337Z", "isAdmin": false, "displayName": "MrHen"}, "userId": "HriC2mR9onYvGtwWr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PrajDAbSgD6SDDa6d/a-request-for-open-problems", "pageUrlRelative": "/posts/PrajDAbSgD6SDDa6d/a-request-for-open-problems", "linkUrl": "https://www.lesswrong.com/posts/PrajDAbSgD6SDDa6d/a-request-for-open-problems", "postedAtFormatted": "Friday, May 8th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Request%20for%20Open%20Problems&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Request%20for%20Open%20Problems%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPrajDAbSgD6SDDa6d%2Fa-request-for-open-problems%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Request%20for%20Open%20Problems%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPrajDAbSgD6SDDa6d%2Fa-request-for-open-problems", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPrajDAbSgD6SDDa6d%2Fa-request-for-open-problems", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 156, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Open_problems\">Open problems</a> are clearly defined problems<sup>1</sup> that have not been solved. In older fields, such as Mathematics, the <a href=\"http://en.wikipedia.org/wiki/Unsolved_problems_in_mathematics\">list is rather intimidating</a>. Rationality, on the other, seems to have <em>no</em> list.</p>\n<p>While we have all of us here together to crunch on problems, let's shoot higher than trying to think of solutions and then finding problems that match the solution. What things are unsolved questions? Is it reasonable to assume those questions have concrete, absolute answers?</p>\n<p>The catch is that these problems cannot be inherently fuzzy problems. \"How do I become less wrong?\" is not a problem that can be clearly defined. As such, it does not have a concrete, absolute answer. Does Rationality <em>have</em> a set of problems that can be clearly defined? If not, how do we work toward getting our problems clearly defined?</p>\n<p>See also: Open problems at <a title=\"LW:Wiki\" href=\"http://wiki.lesswrong.com/wiki/Open_problems_on_Less_Wrong\">LW:Wiki</a></p>\n<p><a id=\"more\"></a><sup>1</sup>: \"Clearly defined\" essentially means a formal, unambiguous&nbsp;definition. &nbsp;\"Solving\" such a problem would constitute a formal proof.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Pa2SdZsLFmqhs42Do": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PrajDAbSgD6SDDa6d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 28, "extendedScore": null, "score": 4.928803285355571e-07, "legacy": true, "legacyId": "549", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 108, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-09T08:14:18.363Z", "modifiedAt": null, "url": null, "title": "How Not to be Stupid: Brewing a Nice Cup of Utilitea", "slug": "how-not-to-be-stupid-brewing-a-nice-cup-of-utilitea", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:50.983Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RuFPGfq7QeNoeGcbs/how-not-to-be-stupid-brewing-a-nice-cup-of-utilitea", "pageUrlRelative": "/posts/RuFPGfq7QeNoeGcbs/how-not-to-be-stupid-brewing-a-nice-cup-of-utilitea", "linkUrl": "https://www.lesswrong.com/posts/RuFPGfq7QeNoeGcbs/how-not-to-be-stupid-brewing-a-nice-cup-of-utilitea", "postedAtFormatted": "Saturday, May 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Not%20to%20be%20Stupid%3A%20Brewing%20a%20Nice%20Cup%20of%20Utilitea&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Not%20to%20be%20Stupid%3A%20Brewing%20a%20Nice%20Cup%20of%20Utilitea%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRuFPGfq7QeNoeGcbs%2Fhow-not-to-be-stupid-brewing-a-nice-cup-of-utilitea%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Not%20to%20be%20Stupid%3A%20Brewing%20a%20Nice%20Cup%20of%20Utilitea%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRuFPGfq7QeNoeGcbs%2Fhow-not-to-be-stupid-brewing-a-nice-cup-of-utilitea", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRuFPGfq7QeNoeGcbs%2Fhow-not-to-be-stupid-brewing-a-nice-cup-of-utilitea", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1730, "htmlBody": "<p>Previously: <a href=\"/lw/dy/how_not_to_be_stupid_adorable_maybes/\">\"objective probabilities\"</a>, but more importantly <a href=\"/lw/dm/how_not_to_be_stupid_know_what_you_want_what_you/\">knowing what you want</a></p>\n<p>Slight change of plans: the only reason I brought up the \"objective\" probabilities as early as I did was to help establish the idea of utilities. But with all the holes that seem to need to be patched to get from one to the other (<a href=\"/lw/e6/conventions_and_confusing_continuity_conundrums/\">continuity</a>, etc), I decided to take a different route and define utilities more directly. So, for now, forget about \"objective probabilities\" and frequencies for a bit. I will get back to them a bit later on, but for now am leaving them aside.</p>\n<p>So, we've got preference rankings, but not much of a sense of scale yet. We don't have much way of asking \"how _much_ do you prefer this to that?\"&nbsp;That's what I'm going to deal with in this post. There will be some slightly roundabout abstract bits here, but they'll let me establish utilities. And once I have that, more or less all I have to do is just use utilities as a currency to apply dutch book arguments to. (That will more or less be the shape of the rest of the sequence)&nbsp;The basic idea here is to work out a way of comparing the magnitudes of the differences of preferences. ie, How much you would have prefered some A2 to A1 vs how much you would have prefered some B2 to B1. But it seems difficult to define, no? \"how much would you have wanted to switch reality to A2, if it was in state A1, vs how much would you have wanted to switch reality to B2, given that it was in B1?\"<a id=\"more\"></a></p>\n<p>So far, the best solution I can think of is to ask \"if you are equally uncertain about whether A1 or B1 is true, would you prefer to replace A1, if it would have been true, with A2, or similar for B1 to B2\"? Specifically, supposing you're in a state of complete uncertainty with regards to two possible states/outcomes A1 or B1, so that you'd be equally surprised by both.&nbsp;Then consider that, instead of keeping that particular set of two possibilities, you have to choose between two substitutions: you can choose to either conditionally replace A1 with A2 (that is, if A1 would have been the outcome, you get A2 instead) _or_ you can choose to replace B1 with B2 in the same sense. So, you have to choose between (A2 or B1) and (A1 or B2) (where, again, your state of uncertainty is such that you'd be equally surprised by either outcome. That is, you can imagine that whatever it is that's giving rise to your uncertainty is effectively controlling both possibilities. You simply get to decide which of those are wired to the source of uncertainty)&nbsp;If you choose the first, then we will say that the amount of difference in your preference between A2 and A1 is bigger than between B2 and B1. And vice versa. And if you're indifferent, we'll say the preference difference of A2 vs A1 = the preference difference of B2 vs B1.</p>\n<p>But wait! You might be saying \"oh sure, that's all nice, but why the fluff should we consider this to obey any form of transitivity? Why should we consider this sort of comparison to actually correspond to a real ordered ranking of these things?\" I'm glad you asked, because I'm about to tell you! Isn't that convinient? ;)</p>\n<p>First, I'm going to introduce a slightly unusual notation which I don't expect to ever need use again. I need it now, however, because I haven't established epistemic probabilities, yet I need to be able to talk about \"equivalent uncertainties\" without assuming \"uncertainty = probability\" (which I'll basically be establishing over the next several posts.)</p>\n<p>A v B v C v D ... will be defined to mean that you're in a state of uncertainty such that you'd be equally surprised by any of those outcomes. (Obviously, this is commutative. A v B v C is the same state as C v A v B, for instance.)</p>\n<p>Next, I need to establish the following principle:</p>\n<p>If you prefer Ai v Bi v Ci v... to Aj v Bj v Cj v..., then you should prefer&nbsp;Ai v Bi v Ci v... v Z to&nbsp;Aj v Bj v Cj v... v Z.</p>\n<p>If this seems familiar, <a href=\"http://www.overcomingbias.com/2008/01/allais-paradox.html\">it should</a>. However, this is a bit more abstract, since we don't yet have a way to measure uncertainty. I'm just assuming here that one can meaningfully say things like \"I'd be equally surprised either way.\" We'll later revisit this argument once we start to apply a numerical measure to our uncertainty.</p>\n<p>To deal with a couple possible ambiguities, first imagine you use the same source of uncertainty no matter which outcome you choose. So the only thing you get to choose is which outcomes are plugged into the \"consequence slots\". Then, imagine that you switch the source of uncertainty with an equivalent one. Unless you place some inherent value in something about whatever it is that is leading to your state of uncertainty or you have additional information (in which case it's not an equivalent amount of uncertainty, so doesn't even apply here), you should value it the same either way, right? Basically an \"it's the same, unless it's different\" principle. :)&nbsp;But for now, if it helps, imagine it's the same source of uncertainty, just different consequences plugged in. Suppose you prefer the Aj v Bj ... v Z to Ai v Bi ... v Z. You have equal amount of expectation (in the informal sense) of Z in either case, by assumption, so makes no difference which of the two you select as far as Z is concerned. And if Z doesn't happen, you're left with the rest. (Assuming appropriate mutual exclusiveness, etc...) So that leaves you back at the \"i\"s vs the \"j\"s, but by assumption you already prefered, overall, the set of \"i\"s to the set of \"j\"s. So the result of prefering the second set with Z simply means that either Z is the outcome, which could have happened the same either way or if not Z, then what you have left is equivalent to the Aj v Bj v... option, which, by assumption, you prefer less than the \"i\"s. So, effectively, you either gain nothing, or end up with a set of possibilities that you prefer less overall. By the power vested in me by Don't Be Stupid, I say that therefore if you prefer Ai v Bi v ... to Aj v Bj v ..., then you must have the same preference ordering when the Z is tacked on.</p>\n<p>There is, however, a possibility that we haven't quite eliminated via the above construction: being indifferent to Ai v Bi v... vs Aj v Bj v... while actually prefering one of the versions with the Z tacked on. All I can say to that is \"unless you, explicitly, in your preference structure have some term for certain types of sources of uncertainty set up in certain ways leading to certain preferences\" here, I don't see any reasonable way that should be happening. ie, where would the latter preference be arising from, if it's not arising from prefereces relating to the individual possibilities?</p>\n<p>I admit, this is a weak point. In fact, it may be the weakest part, so if anyone has any actual concrete objections to this bit, I'd be interested in hearing it. But the \"reasonableness\" criteria seems reasonable here. So, for now at least, I'm going to go with it as \"sufficiently established to move on.\"</p>\n<p>So let's get to building up utilities: Suppose the preference difference of A2 vs A1 is larger than preference difference B2-B1, which is larger than preference difference of C2 vs C1.</p>\n<p>Is preference difference A2 vs A1 larger than C2 vs C1, in terms of the above way for comparing the magnitudes of preference differences?</p>\n<p>Let's find out (Where &gt;, &lt;, and = are being used to represent preference relations)</p>\n<p>We have</p>\n<p>A2 v B1 &gt; A1 v B2</p>\n<p>We also have</p>\n<p>B2 v C1 &gt; B1 v C2</p>\n<p>Let's now use our above theorem of being able to tack on a \"Z\" without changing preference ordering.</p>\n<p>The first one we will transform into (by tacking an extra C1 onto both sides):</p>\n<p>A2 v B1 v C1 &gt; A1 v B2 v C1</p>\n<p>The second comparison will be transfomed into (by tacking an extra A1 onto both sides):</p>\n<p>A1 v B2 v C1 &gt; A1 v B1 v C2</p>\n<p>aha! now we've got an expression that shows up in both the top and the bottom. Specifically A1 v B2 v C1</p>\n<p>By earlier postings, we've already established that prefence rankings are transitive, so we must therefore derive:</p>\n<p>A2 v B1 v C1 &gt; A1 v B1 v C2</p>\n<p>And, again, by the above rule, we can chop off a term that shows up on both sides, specifically B1:</p>\n<p>A2 v C1 &gt; A1 v C2</p>\n<p>Which is our definition for saying the preference difference between A2 and A1 is larger than that between C2 and C1. (given equal expectation (in the informal sense) of A1 or C1, you'd prefere to replace the possibility A1 with A2 then to replace the possibility C1 with C2).&nbsp;And a similar argument applies for equality. So there, we've got transitivity for our comparisons of differences of preferences. Woooo!</p>\n<p>Well then, let us call W a utility function if it has the property that W(B2) - W(B1) &nbsp;=/&gt;/&lt; W(A2) - W(A1) implies the appropriate relation applies to the preference differences. For example, if we have this:</p>\n<p>W(B2) - W(B1) &gt; W(A2) - W(A1), then we have this:</p>\n<p>B2 v A1 &gt; B1 v A2.</p>\n<p>(and similar for equality.)</p>\n<p>In other other words, differences of utility act as an internal currency. Gaining X points of utility corresponds to a climb up your preference ranking that's worth the same no matter what the starting point is. This gives us something to work with.</p>\n<p>Also, note the relations will hold for arbitrary shifting of everything by an equal amount, and by multiplying everything by some positive number. So, basically, you can do a (positive) affine transform on the whole thing and still have all the important properties retained, since all we care about are the relationships between differences, rather than the absolute values.</p>\n<p>And there it is, that's utilities. An indexing of preference rankings with the special property that differences between those indices actually corresponds in a meaningful way to _how much_ you prefer one thing to another.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HAFdXkW4YW4KRe2Gx": 1, "6nS8oYmSMuFMaiowF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RuFPGfq7QeNoeGcbs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 2, "extendedScore": null, "score": 2e-06, "legacy": true, "legacyId": "533", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["afZHsMD26ufh6BuaB", "H6d6Be4MzRxvz9eZT", "25AYXth87fCN6w8zJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-09T18:07:34.526Z", "modifiedAt": null, "url": null, "title": "Step Back", "slug": "step-back", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:50.990Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Andy_McKenzie", "createdAt": "2009-02-28T21:46:45.283Z", "isAdmin": false, "displayName": "Andy_McKenzie"}, "userId": "7PFnr3J3uCGSfjnZJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vtkh36YtGTZcniobB/step-back", "pageUrlRelative": "/posts/vtkh36YtGTZcniobB/step-back", "linkUrl": "https://www.lesswrong.com/posts/vtkh36YtGTZcniobB/step-back", "postedAtFormatted": "Saturday, May 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Step%20Back&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStep%20Back%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvtkh36YtGTZcniobB%2Fstep-back%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Step%20Back%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvtkh36YtGTZcniobB%2Fstep-back", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvtkh36YtGTZcniobB%2Fstep-back", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 201, "htmlBody": "<p>From a recent <span style=\"font-style: italic;\">Psychological Science</span>,</p>\n<blockquote>In everyday life, individuals typically approach desired stimuli by stepping forward and avoid aversive stimuli by stepping backward... Cognitive functioning was gauged by means of a Stroop task immediately after a participant stepped in one direction... Stepping backward significantly enhanced cognitive performance compared to stepping forward or sideways. Considering the effect size, backward locomotion appears to be a very powerful trigger to mobilize cognitive resources.</blockquote>\n<p>As <a href=\"http://scienceblogs.com/developingintelligence/2009/05/cognitive_control_improves_by.php\">Chris Chatham</a> notes,</p>\n<blockquote>This work is remarkable not only for demonstrating how a very concrete and simple bodily experience can influence even the highest levels of cognitive processing (in this case, the so-called \"cognitive control\" processes that enable focused attention), but also because performance on the Stroop task is notoriously difficult to improve.</blockquote>\n<p>When you suddenly realize that a task is more difficult than you assumed it would be, or when you face a particularly difficult choice in pursuit of rationality, you may find it useful to literally take a step back. For those of us who are particularly interested in making good decisions, this may also serve the purpose of self-signaling, as Yvain and commenters <a href=\"/lw/eg/what_i_tell_you_three_times_is_true/?sort=top\">discussed earlier</a>. <br /> <br /> Chris's post<a href=\"http://scienceblogs.com/developingintelligence/\"></a> has a link to a pdf of the paper.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vtkh36YtGTZcniobB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 18, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "551", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["B4AyJXYPpGbBmxQzd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-09T21:53:26.771Z", "modifiedAt": null, "url": null, "title": "You Are A Brain", "slug": "you-are-a-brain", "viewCount": null, "lastCommentedAt": "2019-07-07T18:28:11.488Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Liron", "createdAt": "2009-02-27T04:43:11.294Z", "isAdmin": false, "displayName": "Liron"}, "userId": "AyzRrs8hNm54QptLi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r5H6YCmnn8DMtBtxt/you-are-a-brain", "pageUrlRelative": "/posts/r5H6YCmnn8DMtBtxt/you-are-a-brain", "linkUrl": "https://www.lesswrong.com/posts/r5H6YCmnn8DMtBtxt/you-are-a-brain", "postedAtFormatted": "Saturday, May 9th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20You%20Are%20A%20Brain&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYou%20Are%20A%20Brain%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr5H6YCmnn8DMtBtxt%2Fyou-are-a-brain%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=You%20Are%20A%20Brain%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr5H6YCmnn8DMtBtxt%2Fyou-are-a-brain", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr5H6YCmnn8DMtBtxt%2Fyou-are-a-brain", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 175, "htmlBody": "<p>Here is a 2-hour slide presentation I made for college students and teens:</p>\n<p><a href=\"https://docs.google.com/presentation/d/1IEzD3AfRk5Bh7Xu4NPCakgXtG2RAlhST8ToGWHU1UEI/edit?usp=sharing\" target=\"_blank\"><span style=\"font-size: large;\">You Are A Brain</span></a><span style=\"font-size:smaller\"><br /></span></p>\n<p>It's an introduction to realist thinking, a tour of all the good stuff people don't realize until they include a node for their brain's map in their brain's map. All the concepts come from Eliezer's posts on Overcoming Bias.</p>\n<p>I presented this to my old youth group while staffing one of their events. In addition to the slide show, I had a browser with various optical illusions open in tabs, and I brought in a bunch of lemons and <a href=\"http://en.wikipedia.org/wiki/Miracle_fruit\" target=\"_self\">miracle fruit</a> tablets. They had a good time and stayed engaged.</p>\n<p>I hope the slides will be of use to others trying to promote the public understanding of rationality.</p>\n<p><strong>Note:</strong> When you view the presentation, make sure you can see the speaker notes. They capture the gist of what I was saying while I was showing each slide.</p>\n<p><strong>Added 6 years later: </strong>I finally made a video of myself presenting this, except this time it was an adult audience. See <a href=\"/r/discussion/lw/mme/you_are_a_brain_intro_to_lwrationality_concepts/\">this discussion post</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"cq69M9ceLNA35ShTR": 1, "wfW6iL96u26mbatep": 1, "4R8JYu4QF2FqzJxE5": 1, "T57Qd9J3AfxmwhQtY": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r5H6YCmnn8DMtBtxt", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 126, "baseScore": 130, "extendedScore": null, "score": 0.000202, "legacy": true, "legacyId": "552", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 117, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 79, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fP3xQpzNcC5868QMm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2009-05-09T21:53:26.771Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-12T01:11:19.886Z", "modifiedAt": null, "url": null, "title": "Just making sure posts can be written", "slug": "just-making-sure-posts-can-be-written", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wmoore", "createdAt": "2009-02-17T05:49:50.396Z", "isAdmin": false, "displayName": "wmoore"}, "userId": "EgQZcMBqxf6sGmKfi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N8auz4iC2bSakGCoa/just-making-sure-posts-can-be-written", "pageUrlRelative": "/posts/N8auz4iC2bSakGCoa/just-making-sure-posts-can-be-written", "linkUrl": "https://www.lesswrong.com/posts/N8auz4iC2bSakGCoa/just-making-sure-posts-can-be-written", "postedAtFormatted": "Tuesday, May 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Just%20making%20sure%20posts%20can%20be%20written&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJust%20making%20sure%20posts%20can%20be%20written%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8auz4iC2bSakGCoa%2Fjust-making-sure-posts-can-be-written%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Just%20making%20sure%20posts%20can%20be%20written%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8auz4iC2bSakGCoa%2Fjust-making-sure-posts-can-be-written", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8auz4iC2bSakGCoa%2Fjust-making-sure-posts-can-be-written", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>Hi</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N8auz4iC2bSakGCoa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 4.936352485620142e-07, "legacy": true, "legacyId": "554", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-12T05:11:45.183Z", "modifiedAt": null, "url": null, "title": "No One Knows Stuff", "slug": "no-one-knows-stuff", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:51.890Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "talisman", "createdAt": "2009-03-05T23:30:16.521Z", "isAdmin": false, "displayName": "talisman"}, "userId": "SXxD8wMPMJZZEdNZe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oekNfPb6oQX2mR2NB/no-one-knows-stuff", "pageUrlRelative": "/posts/oekNfPb6oQX2mR2NB/no-one-knows-stuff", "linkUrl": "https://www.lesswrong.com/posts/oekNfPb6oQX2mR2NB/no-one-knows-stuff", "postedAtFormatted": "Tuesday, May 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20No%20One%20Knows%20Stuff&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANo%20One%20Knows%20Stuff%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoekNfPb6oQX2mR2NB%2Fno-one-knows-stuff%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=No%20One%20Knows%20Stuff%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoekNfPb6oQX2mR2NB%2Fno-one-knows-stuff", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoekNfPb6oQX2mR2NB%2Fno-one-knows-stuff", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 223, "htmlBody": "<p>Take a second to go upvote <a href=\"/lw/fc/you_are_a_brain/\">You Are A Brain</a> if you haven't already...</p>\n<p>Back?&nbsp; OK.</p>\n<p>Liron's post reminded me of something that I meant to say a while ago.&nbsp; In the course of giving literally hundreds of job interviews to extremely high-powered technical undergraduates over the last five years, one thing has become painfully clear to me:&nbsp; even very smart and accomplished and mathy people know <em>nothing</em> about rationality.</p>\n<p>For instance, reasoning by expected utility, which you probably consider too basic to mention, is something they absolutely fall flat on.&nbsp; Ask them why they choose as they do in simple gambles involving risk, and they stutter and mutter and fail.&nbsp; Even the Econ majors.&nbsp; Even--perhaps especially--the Putnam winners.</p>\n<p>Of those who have learned about heuristics and biases, a nontrivial minority have gotten confused to the point that they offer <a href=\"http://nobelprize.org/nobel_prizes/economics/laureates/2002/kahnemann-lecture.pdf\">Kahneman and Tversky's research</a> as <em>justifying</em> their exhibition of a bias!</p>\n<p>So foundational explanatory work like Liron's is really pivotal.&nbsp; <a href=\"/lw/4o/playing_video_games_in_shuffle_mode/\">As I've touched on before</a>, I think there's a huge amount to be done in organizing this material and making it approachable for people that don't have the basics.&nbsp; Who's going to write the <a href=\"http://yudkowsky.net/rational/bayes\">Intuitive Explanation of Utility Theory</a>?</p>\n<p>Meanwhile, I need to brush up on my <a href=\"/lw/1t/wanted_python_open_source_volunteers/\">Python</a> and find a way to upvote Liron more than once.&nbsp; <a href=\"/lw/f2/on_the_fence_major_in_cs/\">If only</a>...</p>\n<p><strong>Update: </strong>Tweaked language per <a href=\"/lw/fg/no_one_knows_stuff/c0p\">suggestion</a>, added Kahneman and Tversky link.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hLp77TQsRkooioj86": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oekNfPb6oQX2mR2NB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 9, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "556", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["r5H6YCmnn8DMtBtxt", "mY5SaNnugfEcj6957", "J2sr4tdC4ThrbJRR3", "bv36xQt9FNyotpqEy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-12T06:46:11.993Z", "modifiedAt": null, "url": null, "title": "Willpower Hax #487: Execute by Default", "slug": "willpower-hax-487-execute-by-default", "viewCount": null, "lastCommentedAt": "2020-10-24T09:08:22.559Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FHukyfMagq4HrBYNt/willpower-hax-487-execute-by-default", "pageUrlRelative": "/posts/FHukyfMagq4HrBYNt/willpower-hax-487-execute-by-default", "linkUrl": "https://www.lesswrong.com/posts/FHukyfMagq4HrBYNt/willpower-hax-487-execute-by-default", "postedAtFormatted": "Tuesday, May 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Willpower%20Hax%20%23487%3A%20Execute%20by%20Default&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWillpower%20Hax%20%23487%3A%20Execute%20by%20Default%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFHukyfMagq4HrBYNt%2Fwillpower-hax-487-execute-by-default%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Willpower%20Hax%20%23487%3A%20Execute%20by%20Default%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFHukyfMagq4HrBYNt%2Fwillpower-hax-487-execute-by-default", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFHukyfMagq4HrBYNt%2Fwillpower-hax-487-execute-by-default", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 399, "htmlBody": "<p>This is a trick that I use for getting out of bed in the morning - quite literally:&nbsp; I count down from 10 and get out of bed after the \"1\".</p>\n<p>It works because instead of deciding to get out of bed, I just have to <em>decide to implement the plan </em>to count down from 10 and then get out of bed.&nbsp; Once the plan is in motion, the final action no longer requires an effortful <em>decision</em> - that's the theory, anyway.&nbsp; And to <em>start </em>the plan doesn't require as much effort because I just have to think \"10, 9...\"</p>\n<p>As usual with such things, there's no way to tell whether it works because it's based on any sort of realistic insight or if it works because I believe it works; and in fact this is one of those cases that blurs the boundary between the two.</p>\n<p>The technique was originally inspired by reading some neurologist suggesting that what we have is not \"free will\" so much as \"free won't\": that is, frontal reflection is mainly good for suppressing the default mode of action, more than originating new actions.</p>\n<p>Pondering that for a bit inspired the idea that - if the brain carries out certain plans by default - it might conserve willpower to first visualize a sequence of actions and try to 'mark' it as the default plan, and then <em>lift</em> the attention-of-decision that agonizes whether or not to do it, thus <em>allowing</em> that default to happen.<a id=\"more\"></a></p>\n<p>For the record, I can remember a time some years ago when I would have been all enthusiastic about this sort of thing, believing that I had discovered this incredible new technique that might revolutionize my whole daily life.&nbsp; Today, while I know that there <em>are</em> discoverables with that kind of power, I also know that it usually requires beginning from <a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">firmer foundations</a> - reports of controlled experiments, a standard theory in the field, and maybe even math.&nbsp; On the scale of depth I now use, this sort of trick ranks as pretty shallow - and in fact I really <em>do</em> use it <em>just</em> for getting out of bed.</p>\n<p>I offer this trick as an example of <a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">practical advice <em>not</em> backed by deep theories</a>, of the sort that you can find on a hundred other productivity blogs.&nbsp; At best it may work for some of you some of the time.&nbsp; Consider yourself warned about the enthusiasm thing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YrLoz567b553YouZ2": 2, "fkABsGCJZ6y9qConW": 1, "WqLn4pAWi5hn6McHQ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FHukyfMagq4HrBYNt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 58, "baseScore": 59, "extendedScore": null, "score": 9.1e-05, "legacy": true, "legacyId": "557", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 59, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 59, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LqjKP255fPRY7aMzw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-12T13:32:34.455Z", "modifiedAt": null, "url": null, "title": "Rationality in the Media: Don't (New Yorker, May 2009)", "slug": "rationality-in-the-media-don-t-new-yorker-may-2009", "viewCount": null, "lastCommentedAt": "2017-06-17T03:50:53.312Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "CAGjaXD5sY7fro5gd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7eYhbDMvz5JB2FHQ4/rationality-in-the-media-don-t-new-yorker-may-2009", "pageUrlRelative": "/posts/7eYhbDMvz5JB2FHQ4/rationality-in-the-media-don-t-new-yorker-may-2009", "linkUrl": "https://www.lesswrong.com/posts/7eYhbDMvz5JB2FHQ4/rationality-in-the-media-don-t-new-yorker-may-2009", "postedAtFormatted": "Tuesday, May 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20in%20the%20Media%3A%20Don't%20(New%20Yorker%2C%20May%202009)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20in%20the%20Media%3A%20Don't%20(New%20Yorker%2C%20May%202009)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7eYhbDMvz5JB2FHQ4%2Frationality-in-the-media-don-t-new-yorker-may-2009%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20in%20the%20Media%3A%20Don't%20(New%20Yorker%2C%20May%202009)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7eYhbDMvz5JB2FHQ4%2Frationality-in-the-media-don-t-new-yorker-may-2009", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7eYhbDMvz5JB2FHQ4%2Frationality-in-the-media-don-t-new-yorker-may-2009", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 628, "htmlBody": "<p>Link: \"<a href=\"http://www.newyorker.com/reporting/2009/05/18/090518fa_fact_lehrer?currentPage=all\">Don't: The secret of self-control</a>\", Jonah Lehrer. The New Yorker. May 18, 2009.</p>\n<p><strong>Article Summary</strong></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Walter_Mischel\">Walter Mischel</a>, a psychologist at <a href=\"http://www.columbia.edu/cu/psychology/indiv_pages/mischel.html\">Columbia University</a>, has spent a long time studying what correlates with failing or passing a test intended to measure a preschooler's ability to delay gratification. The original experiment, involving a marshmallow and the promise of another if the first one remained uneaten for fifteen minutes, took place at <a href=\"http://www.stanford.edu/dept/bingschool/index.htm\">Bing Nursery School</a> in the \"late 1960's\". Mischel found several correlates, none of them really surprising. He discovered a few methods that allowed children to learn better delay gratification, but it is unclear if the learning the tricks changed any of the correlations. He and the research tradition he started are now waiting for fMRI studies, because that's <a href=\"http://thelastpsychiatrist.com/2009/04/the_woman_who_cant_forget_is_a.html\">what the discriminating 21st century psychologist does</a>.</p>\n<p>Best line: \"'I know I shouldn't like them,' she says. 'But they're just so delicious!'\"</p>\n<p><a id=\"more\"></a><strong>Article Criticism</strong></p>\n<p>The New Yorker is not exactly meant as a science journal for scientists, so it leads and weaves a couple human interest stories in with the boring science parts. We hear from a 'high delayer' (someone who did well at the test) and her 'low delayer' brother. This sort of opening seems terribly common in popular science writing, and it's so infuriating because it primes the reader with the conclusions of the science before the science is even discussed. The high delayer goes on to become a social psychologist; the low delayer goes to Hollywood and is now working on becoming a producer. So already we see anecdotal evidence that high delayers are successful, low delayers are unsuccessful, and that there's not a genetic component (because brothers and sisters share so much genetic material &amp;mdash; right?).</p>\n<p>At this point the author gives the impetus for Mischel's study as conversations he had with his daughters after they left Bing. Of course, that's not the whole story; that just explains the longitudinal part. According to Mischel's bio halfway through the article, he's been doing experiments like the marshmallow test every since his Ph. D. The article cites a chocolate bar test he did in Trinidad in 1955 that was intended to examine the racial stereotypes of Africans and East Indians.</p>\n<p>The only technique mentioned that helped increase children's ability to delay gratification was \"...a simple set of mental tricks &amp;mdash; such as pretending the candy is only a picture, surrounded by an imaginary frame ....\" However, buried on the next-to-last page of the article, we find that \"...it remains unclear if these new skills persist over the long term.\"</p>\n<p><strong>Background Literature</strong></p>\n<p>I dug up the delay test article (\"<label title=\"Select this article\" for=\"244/4907/933\">Delay of gratification in children</label><span><span style=\"font-family: verdana,arial,helvetica,sans-serif;\">\", </span></span>W Mischel, Y Shoda, and MI Rodriguez (26 May 1989)<em><span><span style=\"font-family: verdana,arial,helvetica,sans-serif;\"> </span></span>Science</em> <strong>244</strong> (4907), 933<span style=\"font-family: verdana,arial,helvetica,sans-serif;\">\"), which those without subscription can find <a href=\"http://harbaugh.uoregon.edu/Readings/UGBE/Mischel%201989%20Science,%20Delay%20of%20Gratification.pdf\">here</a>, and found a few more practical applications. Mischel et. al. found, for instance, that \"attention to the rewards consistently and substantially decreased delay time\" (934). This suggests that if you would like to delay a reward, it's best not to see the reward directly. However, another experiment showed that images of the reward made delaying gratification easier. By far, though, the best technique discovered by the study was self-distraction. Even when the reward was present in the room with them, children who sung songs to themselves or played with toys did much better at the delay test than those who didn't.</span></p>\n<p><span style=\"font-family: verdana,arial,helvetica,sans-serif;\">In conclusion, I found neither the article nor the study itself practically helpful. I was annoyed by the human-interest propaganda that littered the article and the narrowness of the original study. As far as beating <em>akrasia</em> goes, the best advice I can give is for improving short-term gratification delay, practice self-distraction and avoid tempting yourself with the actual reward. If you think a visual reminder of the reward would help, settle for a picture.<br /></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "8SfkJYYMe75MwjHzN": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7eYhbDMvz5JB2FHQ4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 4.93746939925664e-07, "legacy": true, "legacyId": "559", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Link: \"<a href=\"http://www.newyorker.com/reporting/2009/05/18/090518fa_fact_lehrer?currentPage=all\">Don't: The secret of self-control</a>\", Jonah Lehrer. The New Yorker. May 18, 2009.</p>\n<p><strong id=\"Article_Summary\">Article Summary</strong></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Walter_Mischel\">Walter Mischel</a>, a psychologist at <a href=\"http://www.columbia.edu/cu/psychology/indiv_pages/mischel.html\">Columbia University</a>, has spent a long time studying what correlates with failing or passing a test intended to measure a preschooler's ability to delay gratification. The original experiment, involving a marshmallow and the promise of another if the first one remained uneaten for fifteen minutes, took place at <a href=\"http://www.stanford.edu/dept/bingschool/index.htm\">Bing Nursery School</a> in the \"late 1960's\". Mischel found several correlates, none of them really surprising. He discovered a few methods that allowed children to learn better delay gratification, but it is unclear if the learning the tricks changed any of the correlations. He and the research tradition he started are now waiting for fMRI studies, because that's <a href=\"http://thelastpsychiatrist.com/2009/04/the_woman_who_cant_forget_is_a.html\">what the discriminating 21st century psychologist does</a>.</p>\n<p>Best line: \"'I know I shouldn't like them,' she says. 'But they're just so delicious!'\"</p>\n<p><a id=\"more\"></a><strong>Article Criticism</strong></p>\n<p>The New Yorker is not exactly meant as a science journal for scientists, so it leads and weaves a couple human interest stories in with the boring science parts. We hear from a 'high delayer' (someone who did well at the test) and her 'low delayer' brother. This sort of opening seems terribly common in popular science writing, and it's so infuriating because it primes the reader with the conclusions of the science before the science is even discussed. The high delayer goes on to become a social psychologist; the low delayer goes to Hollywood and is now working on becoming a producer. So already we see anecdotal evidence that high delayers are successful, low delayers are unsuccessful, and that there's not a genetic component (because brothers and sisters share so much genetic material &amp;mdash; right?).</p>\n<p>At this point the author gives the impetus for Mischel's study as conversations he had with his daughters after they left Bing. Of course, that's not the whole story; that just explains the longitudinal part. According to Mischel's bio halfway through the article, he's been doing experiments like the marshmallow test every since his Ph. D. The article cites a chocolate bar test he did in Trinidad in 1955 that was intended to examine the racial stereotypes of Africans and East Indians.</p>\n<p>The only technique mentioned that helped increase children's ability to delay gratification was \"...a simple set of mental tricks &amp;mdash; such as pretending the candy is only a picture, surrounded by an imaginary frame ....\" However, buried on the next-to-last page of the article, we find that \"...it remains unclear if these new skills persist over the long term.\"</p>\n<p><strong id=\"Background_Literature\">Background Literature</strong></p>\n<p>I dug up the delay test article (\"<label title=\"Select this article\" for=\"244/4907/933\">Delay of gratification in children</label><span><span style=\"font-family: verdana,arial,helvetica,sans-serif;\">\", </span></span>W Mischel, Y Shoda, and MI Rodriguez (26 May 1989)<em><span><span style=\"font-family: verdana,arial,helvetica,sans-serif;\"> </span></span>Science</em> <strong>244</strong> (4907), 933<span style=\"font-family: verdana,arial,helvetica,sans-serif;\">\"), which those without subscription can find <a href=\"http://harbaugh.uoregon.edu/Readings/UGBE/Mischel%201989%20Science,%20Delay%20of%20Gratification.pdf\">here</a>, and found a few more practical applications. Mischel et. al. found, for instance, that \"attention to the rewards consistently and substantially decreased delay time\" (934). This suggests that if you would like to delay a reward, it's best not to see the reward directly. However, another experiment showed that images of the reward made delaying gratification easier. By far, though, the best technique discovered by the study was self-distraction. Even when the reward was present in the room with them, children who sung songs to themselves or played with toys did much better at the delay test than those who didn't.</span></p>\n<p><span style=\"font-family: verdana,arial,helvetica,sans-serif;\">In conclusion, I found neither the article nor the study itself practically helpful. I was annoyed by the human-interest propaganda that littered the article and the narrowness of the original study. As far as beating <em>akrasia</em> goes, the best advice I can give is for improving short-term gratification delay, practice self-distraction and avoid tempting yourself with the actual reward. If you think a visual reminder of the reward would help, settle for a picture.<br></span></p>", "sections": [{"title": "Article Summary", "anchor": "Article_Summary", "level": 1}, {"title": "Background Literature", "anchor": "Background_Literature", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "16 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": null, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2009-05-12T22:09:39.463Z", "modifiedAt": null, "url": null, "title": "Survey Results", "slug": "survey-results", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:02.691Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZWC3n9c6v4s35rrZ3/survey-results", "pageUrlRelative": "/posts/ZWC3n9c6v4s35rrZ3/survey-results", "linkUrl": "https://www.lesswrong.com/posts/ZWC3n9c6v4s35rrZ3/survey-results", "postedAtFormatted": "Tuesday, May 12th 2009", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Survey%20Results&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASurvey%20Results%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWC3n9c6v4s35rrZ3%2Fsurvey-results%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Survey%20Results%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWC3n9c6v4s35rrZ3%2Fsurvey-results", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWC3n9c6v4s35rrZ3%2Fsurvey-results", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2194, "htmlBody": "<p><strong>Followup to: </strong><a href=\"/lw/de/excuse_me_would_you_like_to_take_a_survey/\">Excuse Me, Would You Like to Take a Survey?</a>, <a href=\"/lw/eh/return_of_the_survey/\">Return of the Survey</a></p>\n<p>Thank you to everyone who took the Less Wrong survey. I've calculated some results out on SPSS, and I've uploaded the data for anyone who wants it. I removed twelve people who wanted to remain private, removed a few people's karma upon request, and re-sorted the results so you can't figure out that the first person on the spreadsheet was the first person to post \"I took it\" on the comments thread and so on. Warning: you will probably not get exactly the same results as me, because a lot of people gave poor, barely comprehensible write in answers, which I tried to round off to the nearest bin.<br /><br /><a href=\"http://www.raikoth.net/Stuff/lwsurvey.xls\"><strong>Download the spreadsheet</strong></a> (right now it's in .xls format)<br /><br />I am not a statistician, although I occasionally have to use statistics for various things, and I will gladly accept corrections for anything I've done wrong. Any Bayesian purists may wish to avert their eyes, as the whole analysis is frequentist. What can I say? I get SPSS software and training free and I don't like rejecting free stuff. The write-up below is missing answers to a few questions that I couldn't figure out how to analyze properly; anyone who cares about them enough can look at the raw data and try it themselves. Results under the cut.</p>\n<p><a id=\"more\"></a></p>\n<p>Out of 166 respondees:</p>\n<p>160 (96.4%) were male, 5 (3%) were female, and one chose not to reveal their gender.<br /><br />The mean age was 27.16, the median was 25, and the SD was 7.68. The youngest person was 16, and the oldest was 60. Quartiles were &lt;22, 22-25, 25-30, and &gt;30.<br /><br />Of the 158 of us who disclosed our race, 148 were white (93.6%), 6 were Asian, 1 was Black, 2 were Hispanic, and one cast a write-in vote for Middle Eastern. Judging by the number who put \"Hinduism\" as their family religion, most of those Asians seem to be Indians.<br /><br />Of the 165 of us who gave readable relationship information, 55 (33.3%) are single and looking, 40 (24.2%) are single but not looking, 40 (24.2%) are in a relationship, 29 (17.6%) are married, and 1 is divorced.<br /><br />Only 138 gave readable political information (those of you who refused to identify with any party and instead sent me manifestos, thank you for enlightening me, but I was unfortunately unable to do statistics on them). We have 62 (45%) libertarians, 53 (38.4%) liberals, 17 (12.3%) socialists, 6 (4.3%) conservatives, and not one person willing to own up to being a commie.<br /><br />Of the 164 people who gave readable religious information, 134 (81.7%) were atheists and not spiritual; 5 other atheists described themselves as \"spiritual\". Counting deists and pantheists, we had 11 believers in a supreme being (6.7%), of whom 2 were deist/pantheist, 2 were lukewarm theists, and 6 were committed theists. 14 of us (8.5%) were agnostic.<br /><br />53 of us were raised in families of \"about average religiousity\" (31.9%). 24 (14.5%) were from extremely religious families, 45 (27.1%) from nonreligious families, and 9 (5.4%) from explicitly atheist families. 30 (18.1%) were from families less religious than average. The remainder wrote in some hard to categorize responses, like an atheist father and religious mother, or vice versa.<br /><br />Of the 106 of us who listed our family's religious background, 92 (87%) were Christian. Of the Christians, 29 (31.5% of Christians) described their backgrounds as Catholic, 30 (32.6% of Christians) described it as Protestant, and the rest gave various hard-to-classify denominations or simply described themselves as \"Christian\". There were also 9 Jews, 3 Hindus, 1 Muslim, and one New Ager.<br /><br />I didn't run the \"how much of Overcoming Bias have you read\" question so well, and people ended up responding things like \"Oh, most of it\", which are again hard to average. After interpreting things extremely liberally and unscientifically (\"most\" was estimated as 75%, \"a bit\" was estimated at 25%, et cetera) I got that the average LWer has read about half of OB, with a slight tendency to read more of Eliezer's posts than Robin's. <br /><br />Average time in the OB/LW community was 13.6 &plusmn; 9.2 months. Average time spent on the site per day was 30.7 &plusmn; 30.4 minutes.<br /><br />IQs (warning: self-reported numbers for notoriously hard-to-measure statistic) ranged from 120 to 180. The mean was 145.88, median was 141.50, and SD was 14.02. Quartiles were &lt;133, 133-141.5, 141.5-155, and &gt;155.<br /><br />77 people were willing to go out on a limb and guess whether their IQ would be above the median or not. The mean confidence level was 54.4, and the median confidence level was 55 - which shows a remarkable lack of self-promoting bias. The quartiles were &lt;40, 40-55, 55-70, &gt;70. There was a .453 correlation between this number and actual IQ. This number was significant at the &lt;.001 level.<br /><br />Probability of Many Worlds being more or less correct (given as mean, median, SD; all probabilities in percentage format): 55.65, 65, 32.9.<br /><br />Probability of aliens in the observable Universe: 70.3, 90, 35.7.<br /><br />Probability of aliens in our galaxy: 40.9, 35, 38.5. Notice the huge standard deviations here; the alien questions were remarkable both for the high number of people who put answers above 99.9, and the high number of people who put answers below 0.1. My guess: people who read about <a href=\"http://hanson.gmu.edu/greatfilter.html\">The Great Filter</a> versus those who didn't.<br /><br />Probability of some revealed religion being true: 3.8, 0, 12.6.<br /><br />Probability of some Creator God: 4.2, 0, 14.6.<br /><br />Probability of something supernatural existing: 4.1, 0, 12.8.<br /><br />Probability of an average person cryonically frozen today being successfully revived: 22.3, 10, 26.2.<br /><br />Probability of anti-agathic drugs allowing the current generation to live beyond 1000: 29.2, 20, 30.8.<br /><br />Probability that we live in a simulation: 16.9, 5, 23.7.<br /><br />Probability of anthropic global warming: 69.4, 80, 27.8.<br /><br />Probability that we make it to 2100 without a catastrophe killing &gt;90% of us: 73.1, 80, 24.6.<br /><br />When asked to determine a year in which the Singularity might take place, the mean guess was 9,899 AD, but this is only because one person insisted on putting 100,000 AD. The median might be a better measure in this case; it was mid-2067.<br /><br />Thomas Edison patented the lightbulb in 1880. I've never before been a firm believer in the wisdom of crowds, but it really came through in this case. Even though this was clearly not an easy question and many people got really far-off answers, the mean was 1879.3 and the median was 1880. The standard deviation was 36.1. Person who put \"2172\", you probably thought you were screwing up the results, but in fact you managed to counterbalance the other person who put \"1700\", allowing the mean to revert back to within one year of the correct value :P<br /><br />The average person was 26.77% sure they got within 5 years of the correct answer on the lightbulb question. 30% of people did get within 5 years. I'm not sure how much to trust the result, because several people put the exact correct year down and gave it 100% confidence. Either they were really paying attention in history class, or they checked Wikipedia. There was a high correlation between high levels of confidence on the question and actually getting the question right, significant at the &lt;.001 level.<br /><br />I ran some correlations between different things, but they're nothing very interesting. I'm listing the ones that are significant at the &lt;.05 level, but keep in mind that since I just tried correlating everything with everything else, there are a couple hundred correlations and it's absolutely plausible that many things would achieve that significance level by pure chance.<br /><br />How long you've been in the community obviously correlates very closely with how much of Robin and Eliezer's posts you've read (and both correlate with each other).<br /><br />People who have read more of Robin and Eliezer's posts have higher karma. People who spend more time per day on Less Wrong have higher karma (with very strong significance, at the &lt;.001 level.)<br /><br />People who have been in the community a long time and read many of EY and RH's posts are more likely to believe in Many Worlds and Cryonics, two unusual topics that were addressed particularly well on Overcoming Bias. That suggests if you're a new person who doesn't currently believe in those two ideas, and they're important to you, you might want to go back and find the OB sequences about them (here's <a href=\"http://www.overcomingbias.com/2008/06/mwi-wins.html\">Many Worlds</a>, and here's some <a href=\"http://www.overcomingbias.com/2008/12/we-agree-get-froze.html\">cryonics</a>). There were no similar effects on things like belief in God or belief in aliens.<br /><br />Older people were less likely to spend a lot of time on the site, less likely to believe in Many Worlds, less likely to believe in global warming, and more likely to believe in aliens. <br /><br />Everything in the God/revealed religion/supernatural cluster correlated pretty well with each other. Belief in cryonics correlated pretty well with belief in anti-agathics.<br /><br />Here is an anomalous finding I didn't expect: the higher a probability you assign to the truth of revealed religion, the less confident you are that your IQ is above average (even though no correlation between this religious belief and IQ was actually found). Significance is at the .025 level. I have two theories on this: first, that we've been telling religious people they're stupid for so long that it's finally starting to sink in :) Second, that most people here are not religious, and so the people who put a \"high\" probability for revealed religion may be assigning it 5% or 10%, not because they believe it but because they're just underconfident people who maybe overadjust for their biases a little much. This same underconfidence leads them to underestimate the possibility that their IQ is above average.<br /><br />The higher probability you assign to the existence of aliens in the universe, the more likely you are to think we'll survive until 2100 (p=.002). There is no similar correlation for aliens in the galaxy. I credit the Great Filter article for this one too - if no other species exist, it could mean something killed them off.<br /><br />And, uh, the higher probability you assign to the existence of aliens in the galaxy (but not in the universe) the more likely you are (at a .05 sig) to think global warming is man-made. I have no explanation for this one. Probably one of those coincidences.<br /><br />Moving on - of the 102 people who cared about the ending to 3 Worlds Collide, 68 (66.6%) prefered to see the humans blow up Huygens, while 34 (33.3%) thought we'd be better off cooperating with the aliens and eating delicious babies.<br /><br />Of the 114 people who had opinions about the Singularity, 85 (74.6%) go with Eliezer's version, and 29 (25.4%) go with Robin's.<br /><br />If you're playing another Less Wronger in the Prisoner's Dilemma, you should know that of the 133 who provided valid information for this question, 96 (72.2%) would cooperate and 37 (27.8%) would defect. The numbers switch when one player becomes an evil paper-clip loving robot; out of 126 willing to play the \"true\" Prisoner's Dilemma, only 42% cooperate and 58% defect.<br /><br />Of the 124 of us willing to play the Counterfactual Mugging, 53 (42.7%) would give Omega the money, and 71 (57.3%) would laugh in his face.<br /><br />Of the 146 of us who had an opinion on aid to Africa, 24 (16.4%) thought it was almost always a good thing, 42 (27.8%) thought it was almost always a bad thing, and 80 (54.8%) took a middle-of-the-road approach and said it could be good, but only in a few cases where it was done right.<br /><br />Of 128 of us who wanted to talk about our moral theories, 94 (73.4%) were consequentialists, about evenly split between garden-variety or Eliezer-variety (many complained they didn't know what Eliezer's interpretation was, or what the generic interpretation was, or that all they knew was that they were consequentialists). 15 (9%) said with more or fewer disclaimers that they were basically deontologists, and 5 (3.9%) wrote-in virtue ethics, and objected to their beliefs being left out (sorry!). 14 people (10.9%) didn't believe in morality.<br /><br />Despite the seemingly overwhelming support for cryonics any time someone mentions it, only three of us are actually signed up! Of the 161 of us who admitted we weren't, 11 (6.8%) just never thought about it, 99 (59.6%) are still considering it, and 51 (31.7%) have decided against it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"kJrjorSx3hXa7q7CJ": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZWC3n9c6v4s35rrZ3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 54, "baseScore": 60, "extendedScore": null, "score": 9.5e-05, "legacy": true, "legacyId": "560", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 61, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 214, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["H6LnGwjKiGvDyR5yo", "2AuvBPw6Rb7yxkvKc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 13, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}